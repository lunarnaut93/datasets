{"2017-01-02-507922179": {"title": "What 2017 Holds For Technology News : NPR", "url": "https://www.npr.org/2017/01/02/507922179/what-2017-holds-for-technology-news", "author": "No author found", "published_date": "2017-01-02", "content": "AUDIE CORNISH, HOST:  Technology was front and center in many of 2016's biggest stories. Just look at the headlines from last week with President Obama announcing measures to punish Russia for cyber meddling in our presidential election. There's no reason to think 2017 will be any different. So on this first All Tech Considered segment of the new year, we listen in as members of NPR's tech team discuss what developments they'll cover in the year ahead. (SOUNDBITE OF MUSIC)AARTI SHAHANI, BYLINE: This is Aarti Shahani. I'm the tech reporter for NPR, and I am in San Francisco. ALINA SELYUKH, BYLINE: I'm Alina Selyukh, and I'm the tech blogger in Washington. URI BERLINER, BYLINE: And I'm Uri Berliner. I'm the tech editor, and I'm here in Washington, too. Hey, Aarti, you're out there in California. You're covering some of the most powerful companies in the world, and as this new year starts, what are the big stories you're following? SHAHANI: Oh, first of all, Happy New Year to everyone. SELYUKH: Happy New Year. BERLINER: Happy New Year. SHAHANI: (Laughter) I think that I'm continuing this year with what I ended on last year, which is a lot of focus on Facebook. It is a company that is doing extraordinarily well I mean financially, in terms of users. And at the same time, I mean if you stop and think about Facebook's reputation right now, it's been through some real damage. People question whether Facebook cares about real news and wants to, you know, protect people against fake news. And I do wonder if they're going to take more seriously the crisis they're having with managing their content and also if they're going to start changing who they hire, creating new kinds of positions that show inside the company that they want to change their culture. SELYUKH: Do you think they're going to have sort of a year of mea culpa at Facebook? Do you think this will really shake them up? SHAHANI: You know, mea culpa I think is a sort of non-celebratory way to put it (laughter). And from what I gather, the company - they tend to feel pretty good about themselves. And so, you know, if I were to put it this way - I was kind of thinking of an analogy. And of course I'm going to bring it back to a party because I like to go out. But I remember when I first moved to Silicon Valley from New York. Something that really blew my mind was I kept meeting these engineers who were brilliant but also very low EQ - what we call emotional intelligence. And in some ways, I think that Facebook embodies that exact same kind of person but at a company level. BERLINER: Aarti, are those fun people to hang out with at parties? SHAHANI: (Laughter) For a bit. They get things done. They get things done and more than they even expect, right? I mean, like, one of the big lessons of Facebook is you could call it a kind of Frankenstein's monster at some point. They've grown so rapidly and had way more impact than they ever imagined. BERLINER: So Alina, it's almost like we've become numb to hacks, or we're still reeling from all the hacks. And I know you've covered a lot of them. And just what are the ramifications of all the hacks that we've just been through in the past year? SELYUKH: I think you're right that there is this sort of numbness. There's this sort of sense of complacency almost among people about these hacks. Nobody's surprised by them anymore. We had major hacks last year. The first of the Yahoo hacks was supposed to be the largest known in history. Then came the second Yahoo hack, which blew that record completely. SHAHANI: (Laughter). SELYUKH: And then of course we had another hack that just completely surprised everyone, which was a hack of this company called Dyn. And they just got bombarded with denial of service attack. And I think that was a moment a lot of people realized that all of these Wi-Fi connected things in our homes, in our wrists or whatever could become part of a major hack that we as people who follow this industry may not have anticipated a couple of years ago. BERLINER: That's the one that kind of freaked me out. Like, you look at that cool new thermostat you put in your house, and all of a sudden, that's the conduit through which hackers get at you. And it's like it becomes kind of a little more ominous, the whole thing, right? SELYUKH: And I think. . . SHAHANI: I got to say. Like, my big lesson in the hack-fest is that our numbness is largely because we're not really sure (laughter), you know, what the harm is. But I also think we're beginning to see how powerful hacked information can be, whether it's in the form of swinging an election or swinging the stock market. BERLINER: Well, let's just talk about it. I mean 2017 - we're about to have a new president. And President Obama was an ally, a friend of Silicon Valley. They liked him. President Trump - he's much more of a wildcard. What's going on in Silicon Valley? What are the leaders there thinking about with this new administration? SHAHANI: We don't know how different it's going to be. We just know that Trump is a wildcard. I mean, like, you know, it's funny. The companies here - the major companies - they did not think he was going to win. You talk to people over there - you know, off-the-record conversations with some very high-level people - and they just felt blindsided, which is very interesting for business leaders because business leaders take pride in sort of knowing what's going to happen in the world and making the right bets. BERLINER: So they didn't have a. . . SHAHANI: And that's not what happened. BERLINER: So they didn't have a plan B, like, in case Trump won? SHAHANI: I didn't hear a plan B, but I did very quickly hear, you know, over the course of a few weeks a sort of range of responses. One thing that I think is going to really happen is, I think we're going to see some of the major tech companies being forced to come out or deciding to preemptively come out and say something about job training and training people who are no longer employed because software ate their job. SELYUKH: You know, one of the first conversations you had with a tech leader was with Apple CEO Tim Cook, where he pressed for Apple to build plants in the United States. Like, that is was a very tangible conversation, but it's not one that the tech companies particularly wanted to have. And so I think there will be a recalibration of how they talk about the industry's impact on the economy. And we have heard that their interest - the thing that they're hoping to get out of this new administration is a new focus on taxes and immigration. BERLINER: OK, any, like, bets on something really unpredictable happening this year in tech? SHAHANI: I think that virtual reality headsets and software platforms will get good enough so that you can have remote dates that are a lot of fun. SELYUKH: And I was going to say that artificial intelligence is going to move on to a point where computers are going to learn all kinds of new skills like a computer. Like, an IBM Watson learns to dance. IBM Watson learns to cook you a meal. BERLINER: Yeah, I don't have a prediction. I'm going to wait and see. Any journalist worth his salt knows to stay away from predictions right now. SHAHANI: Oh, come on, Uri. BERLINER: So I'm going to bail out of that. SHAHANI: Put a little bitcoin on it. BERLINER: No, no, no. I'll bet on sports but not on tech. (SOUNDBITE OF MUSIC)CORNISH: That's NPR tech editor Uri Berliner chatting with tech reporters Aarti Shahani and Alina Selyukh. If you've got an idea you think the tech team should cover, get in touch. They're on Twitter @npralltech. (SOUNDBITE OF MUSIC) AUDIE CORNISH, HOST:   Technology was front and center in many of 2016's biggest stories. Just look at the headlines from last week with President Obama announcing measures to punish Russia for cyber meddling in our presidential election. There's no reason to think 2017 will be any different. So on this first All Tech Considered segment of the new year, we listen in as members of NPR's tech team discuss what developments they'll cover in the year ahead. (SOUNDBITE OF MUSIC) AARTI SHAHANI, BYLINE: This is Aarti Shahani. I'm the tech reporter for NPR, and I am in San Francisco. ALINA SELYUKH, BYLINE: I'm Alina Selyukh, and I'm the tech blogger in Washington. URI BERLINER, BYLINE: And I'm Uri Berliner. I'm the tech editor, and I'm here in Washington, too. Hey, Aarti, you're out there in California. You're covering some of the most powerful companies in the world, and as this new year starts, what are the big stories you're following? SHAHANI: Oh, first of all, Happy New Year to everyone. SELYUKH: Happy New Year. BERLINER: Happy New Year. SHAHANI: (Laughter) I think that I'm continuing this year with what I ended on last year, which is a lot of focus on Facebook. It is a company that is doing extraordinarily well I mean financially, in terms of users. And at the same time, I mean if you stop and think about Facebook's reputation right now, it's been through some real damage. People question whether Facebook cares about real news and wants to, you know, protect people against fake news. And I do wonder if they're going to take more seriously the crisis they're having with managing their content and also if they're going to start changing who they hire, creating new kinds of positions that show inside the company that they want to change their culture. SELYUKH: Do you think they're going to have sort of a year of mea culpa at Facebook? Do you think this will really shake them up? SHAHANI: You know, mea culpa I think is a sort of non-celebratory way to put it (laughter). And from what I gather, the company - they tend to feel pretty good about themselves. And so, you know, if I were to put it this way - I was kind of thinking of an analogy. And of course I'm going to bring it back to a party because I like to go out. But I remember when I first moved to Silicon Valley from New York. Something that really blew my mind was I kept meeting these engineers who were brilliant but also very low EQ - what we call emotional intelligence. And in some ways, I think that Facebook embodies that exact same kind of person but at a company level. BERLINER: Aarti, are those fun people to hang out with at parties? SHAHANI: (Laughter) For a bit. They get things done. They get things done and more than they even expect, right? I mean, like, one of the big lessons of Facebook is you could call it a kind of Frankenstein's monster at some point. They've grown so rapidly and had way more impact than they ever imagined. BERLINER: So Alina, it's almost like we've become numb to hacks, or we're still reeling from all the hacks. And I know you've covered a lot of them. And just what are the ramifications of all the hacks that we've just been through in the past year? SELYUKH: I think you're right that there is this sort of numbness. There's this sort of sense of complacency almost among people about these hacks. Nobody's surprised by them anymore. We had major hacks last year. The first of the Yahoo hacks was supposed to be the largest known in history. Then came the second Yahoo hack, which blew that record completely. SHAHANI: (Laughter). SELYUKH: And then of course we had another hack that just completely surprised everyone, which was a hack of this company called Dyn. And they just got bombarded with denial of service attack. And I think that was a moment a lot of people realized that all of these Wi-Fi connected things in our homes, in our wrists or whatever could become part of a major hack that we as people who follow this industry may not have anticipated a couple of years ago. BERLINER: That's the one that kind of freaked me out. Like, you look at that cool new thermostat you put in your house, and all of a sudden, that's the conduit through which hackers get at you. And it's like it becomes kind of a little more ominous, the whole thing, right? SELYUKH: And I think. . . SHAHANI: I got to say. Like, my big lesson in the hack-fest is that our numbness is largely because we're not really sure (laughter), you know, what the harm is. But I also think we're beginning to see how powerful hacked information can be, whether it's in the form of swinging an election or swinging the stock market. BERLINER: Well, let's just talk about it. I mean 2017 - we're about to have a new president. And President Obama was an ally, a friend of Silicon Valley. They liked him. President Trump - he's much more of a wildcard. What's going on in Silicon Valley? What are the leaders there thinking about with this new administration? SHAHANI: We don't know how different it's going to be. We just know that Trump is a wildcard. I mean, like, you know, it's funny. The companies here - the major companies - they did not think he was going to win. You talk to people over there - you know, off-the-record conversations with some very high-level people - and they just felt blindsided, which is very interesting for business leaders because business leaders take pride in sort of knowing what's going to happen in the world and making the right bets. BERLINER: So they didn't have a. . . SHAHANI: And that's not what happened. BERLINER: So they didn't have a plan B, like, in case Trump won? SHAHANI: I didn't hear a plan B, but I did very quickly hear, you know, over the course of a few weeks a sort of range of responses. One thing that I think is going to really happen is, I think we're going to see some of the major tech companies being forced to come out or deciding to preemptively come out and say something about job training and training people who are no longer employed because software ate their job. SELYUKH: You know, one of the first conversations you had with a tech leader was with Apple CEO Tim Cook, where he pressed for Apple to build plants in the United States. Like, that is was a very tangible conversation, but it's not one that the tech companies particularly wanted to have. And so I think there will be a recalibration of how they talk about the industry's impact on the economy. And we have heard that their interest - the thing that they're hoping to get out of this new administration is a new focus on taxes and immigration. BERLINER: OK, any, like, bets on something really unpredictable happening this year in tech? SHAHANI: I think that virtual reality headsets and software platforms will get good enough so that you can have remote dates that are a lot of fun. SELYUKH: And I was going to say that artificial intelligence is going to move on to a point where computers are going to learn all kinds of new skills like a computer. Like, an IBM Watson learns to dance. IBM Watson learns to cook you a meal. BERLINER: Yeah, I don't have a prediction. I'm going to wait and see. Any journalist worth his salt knows to stay away from predictions right now. SHAHANI: Oh, come on, Uri. BERLINER: So I'm going to bail out of that. SHAHANI: Put a little bitcoin on it. BERLINER: No, no, no. I'll bet on sports but not on tech. (SOUNDBITE OF MUSIC) CORNISH: That's NPR tech editor Uri Berliner chatting with tech reporters Aarti Shahani and Alina Selyukh. If you've got an idea you think the tech team should cover, get in touch. They're on Twitter @npralltech. (SOUNDBITE OF MUSIC)", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-01-02-507922186": {"title": "Yes, This Is A Thing: A Self-Tying Shoe : NPR", "url": "https://www.npr.org/2017/01/02/507922186/yes-this-is-a-thing-a-self-tying-shoe", "author": "No author found", "published_date": "2017-01-02", "content": "AUDIE CORNISH, HOST:  Let's take a moment to recognize one of last year's tech breakthroughs. TIFFANY BEERS: We have what we call a lace engine. CORNISH: That's Tiffany Beers, a senior innovator with Nike. The lace engine she's referring to is a motor, battery and control board combo hidden in the bottom of a new Nike shoe. BEERS: When a user steps into the shoe, when their heel touches the foot bed, it triggers a sensor. What that sensor does is it tells it that the foot's there and that go ahead and tighten. CORNISH: And after that, with the press of a button, hands are no longer required for tying shoelaces. Beers says it's more than a high-tech fashion statement. BEERS: If you don't have any challenges tying your shoes, it maybe doesn't change your life very much. But for anyone that has any trouble tying their shoes and getting into their shoes, you know, spending 20 minutes a day maybe putting on your shoes, I get letters from kids all the time that have various challenges. For them, this is a complete game changer. CORNISH: Now if you want this technology in your sneakers, you can buy it, but it'll cost you $720. AUDIE CORNISH, HOST:   Let's take a moment to recognize one of last year's tech breakthroughs. TIFFANY BEERS: We have what we call a lace engine. CORNISH: That's Tiffany Beers, a senior innovator with Nike. The lace engine she's referring to is a motor, battery and control board combo hidden in the bottom of a new Nike shoe. BEERS: When a user steps into the shoe, when their heel touches the foot bed, it triggers a sensor. What that sensor does is it tells it that the foot's there and that go ahead and tighten. CORNISH: And after that, with the press of a button, hands are no longer required for tying shoelaces. Beers says it's more than a high-tech fashion statement. BEERS: If you don't have any challenges tying your shoes, it maybe doesn't change your life very much. But for anyone that has any trouble tying their shoes and getting into their shoes, you know, spending 20 minutes a day maybe putting on your shoes, I get letters from kids all the time that have various challenges. For them, this is a complete game changer. CORNISH: Now if you want this technology in your sneakers, you can buy it, but it'll cost you $720.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-01-05-508355408": {"title": "Intelligence Chiefs Stand Behind Finding That Russia Hacked U.S. Political System : NPR", "url": "https://www.npr.org/2017/01/05/508355408/intelligence-chiefs-stand-more-resolutely-behind-finding-of-russia-election-hack", "author": "No author found", "published_date": "2017-01-05", "content": "", "section": "Politics", "disclaimer": ""}, "2017-01-06-508520414": {"title": "Donald Trump To Get Intelligence Briefing On Russian Hacking Even As He's Cast Doubt On It : NPR", "url": "https://www.npr.org/2017/01/06/508520414/on-intelligence-and-election-hacking-trump-and-his-team-continue-to-miss-the-poi", "author": "No author found", "published_date": "2017-01-06", "content": "", "section": "Opinion", "disclaimer": ""}, "2017-01-09-509001342": {"title": "Apple's iPhone Turns 10 Years Old : NPR", "url": "https://www.npr.org/2017/01/09/509001342/apples-iphone-turns-10-years-old", "author": "No author found", "published_date": "2017-01-09", "content": "AUDIE CORNISH, HOST: Now let's note an anniversary. KELLY MCEVERS, HOST: To do that, imagine a world where no one is bent over a little glowing screen. CORNISH: Or where confronted with a question at a dinner party, no one Googles the answer right at the table. MCEVERS: Or where you can go on a hike and not see a person taking a selfie. CORNISH: That was the world that existed 10 years ago, before this man introduced, as he said, three new things. (SOUNDBITE OF ARCHIVED RECORDING)STEVE JOBS: A widescreen iPod with touch controls, a revolutionary mobile phone and a breakthrough internet communications device. MCEVERS: That, of course, is the late Steve Jobs, who was then the head of Apple. (SOUNDBITE OF ARCHIVED RECORDING)JOBS: These are not three separate devices. (APPLAUSE)JOBS: This is one device. . . (APPLAUSE)JOBS: . . . And we are calling it iPhone. MCEVERS: IPhone, unveiled on January 9, 2007. CORNISH: Steven Levy was in that audience. He's now editor of the tech publication Backchannel. He says back then, there were cell phones, even smartphones, but not like the iPhone. STEVEN LEVY: Smartphones, at the time, weren't really all that smart. MCEVERS: He says they couldn't smoothly browse the web, play music easily or edit photos very well. LEVY: It was a challenge to really get things done besides making phone calls on these other phones that called themselves smart. MCEVERS: After Jobs' famous speech, Levy went backstage to talk to the Apple CEO. LEVY: I said, why did you do a phone? And he said, well, we did a lot of market research and, you know, talked to all the analysts and buying people and decided we can make a lot of money. And then he laughed (laughter) and he said, no, totally that's not us. And, of course, that's not the way Apple operates at all. They do what they think is the right thing to do and assume people will follow. MCEVERS: And people did follow. Other companies followed, too. Today it would be hard to find a smartphone that doesn't have a touch screen. Steven Levy got his first iPhone shortly after hearing Jobs' talk. He's upgraded since. He still likes the iPhone but says there's a downside to the technology. LEVY: We are now cyborgs. We can't exist without these things. We're very dependent on them. It's like a limb. And it's a little odd to be out there where you're a very strong person with your mobile smart device but you're weaker without it. CORNISH: Steven Levy of Backchannel. The iPhone was introduced 10 years ago today. AUDIE CORNISH, HOST:  Now let's note an anniversary. KELLY MCEVERS, HOST:  To do that, imagine a world where no one is bent over a little glowing screen. CORNISH: Or where confronted with a question at a dinner party, no one Googles the answer right at the table. MCEVERS: Or where you can go on a hike and not see a person taking a selfie. CORNISH: That was the world that existed 10 years ago, before this man introduced, as he said, three new things. (SOUNDBITE OF ARCHIVED RECORDING) STEVE JOBS: A widescreen iPod with touch controls, a revolutionary mobile phone and a breakthrough internet communications device. MCEVERS: That, of course, is the late Steve Jobs, who was then the head of Apple. (SOUNDBITE OF ARCHIVED RECORDING) JOBS: These are not three separate devices. (APPLAUSE) JOBS: This is one device. . . (APPLAUSE) JOBS: . . . And we are calling it iPhone. MCEVERS: IPhone, unveiled on January 9, 2007. CORNISH: Steven Levy was in that audience. He's now editor of the tech publication Backchannel. He says back then, there were cell phones, even smartphones, but not like the iPhone. STEVEN LEVY: Smartphones, at the time, weren't really all that smart. MCEVERS: He says they couldn't smoothly browse the web, play music easily or edit photos very well. LEVY: It was a challenge to really get things done besides making phone calls on these other phones that called themselves smart. MCEVERS: After Jobs' famous speech, Levy went backstage to talk to the Apple CEO. LEVY: I said, why did you do a phone? And he said, well, we did a lot of market research and, you know, talked to all the analysts and buying people and decided we can make a lot of money. And then he laughed (laughter) and he said, no, totally that's not us. And, of course, that's not the way Apple operates at all. They do what they think is the right thing to do and assume people will follow. MCEVERS: And people did follow. Other companies followed, too. Today it would be hard to find a smartphone that doesn't have a touch screen. Steven Levy got his first iPhone shortly after hearing Jobs' talk. He's upgraded since. He still likes the iPhone but says there's a downside to the technology. LEVY: We are now cyborgs. We can't exist without these things. We're very dependent on them. It's like a limb. And it's a little odd to be out there where you're a very strong person with your mobile smart device but you're weaker without it. CORNISH: Steven Levy of Backchannel. The iPhone was introduced 10 years ago today.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-01-09-508237086": {"title": "Low Pay In State Legislatures Means Some Can't Afford The Job : NPR", "url": "https://www.npr.org/2017/01/09/508237086/low-pay-in-state-legislatures-means-some-cant-afford-the-job", "author": "No author found", "published_date": "2017-01-09", "content": "STEVE INSKEEP, HOST: Many state legislatures around this country have a serious human resources problem. Salaries for being a state legislator are relatively low. And as Johnny Kauffman of member station WABE reports, not everybody can afford to do the job. JOHNNY KAUFFMAN, BYLINE: On top of raising two kids, LaDawn Jones runs a law practice. She's busy, but loved serving in the Georgia legislature. She had to leave, though, after one term because it just didn't pay enough. LADAWN JONES: I absolutely believe that we need to increase the wage for legislators to keep up with the times. KAUFFMAN: Lawmakers in Georgia make $17,000 a year. It's considered a part-time job, but it took much more of her time than that. When the legislature was in session, Jones couldn't work at her law firm and had to hire extra help. That cost her. JONES: If I really sat down and did the math, I'm certain that the amount that I paid out was equal or more than what I received. KAUFFMAN: A few big states like Pennsylvania or California have full-time lawmakers who earn $80,000 or even $100,000 a year. But in most states, legislators are paid like it's part-time. That can keep people from getting into state politics, says Neil Malhotra of Stanford University. NEIL MALHOTRA: There's very, very few working-class people in legislatures. And this might have something to do with why a lot of legislation does not seem very friendly towards working-class people. KAUFFMAN: And it's not just working-class people who are left out, Malhotra says. Anyone with a regular job has a hard time taking several months a year off to work in a state capital. Mike Dudgeon just retired from the legislature because the requirements of his job at a videogame company were too great. MIKE DUDGEON: Some people suggested that I sort of do the phone-it-in thing and just keep my seat in the legislature and just do the bare minimum, just go down and vote and kind of do that. But that's - I just can't do that. It's not my personality. I'm going to do anything, I'm going to do it well. KAUFFMAN: Many lawmakers own businesses or they work in law, medicine or agriculture, professions where they can control their schedules. People with experience in fields like technology or finance have a harder time serving. Malhotra says when it comes to those issues, lobbyists are the only experts at the statehouse. And that gives them an edge in the legislative process. MALHOTRA: You don't really write these bills. The lobbyists kind of write the bills for you. KAUFFMAN: In Georgia, there's no sign lawmakers will get a raise anytime soon. David Shafer is a leader in the Georgia Senate. DAVID SHAFER: I'm not in favor of increasing legislative pay. I don't know that anyone serves in the General Assembly because of the pay, and I don't know that we would attract a better legislator if the pay were higher. KAUFFMAN: Georgia lawmakers are set to pass a more than $20 billion budget this year and grapple with a failing hospital system. Jones would love to be a part of those debates. JONES: I could not dare ask my family to continue to make such a big sacrifice without that help. KAUFFMAN: So instead of focusing on statewide issues from the capital, Jones plans to focus her political energy on her community. For NPR News, I'm Johnny Kauffman in Atlanta. (SOUNDBITE OF ALWAYS THE RUNNER'S \"SHOULD A BEAR INTERRUPT YOUR PICNIC\") STEVE INSKEEP, HOST:  Many state legislatures around this country have a serious human resources problem. Salaries for being a state legislator are relatively low. And as Johnny Kauffman of member station WABE reports, not everybody can afford to do the job. JOHNNY KAUFFMAN, BYLINE: On top of raising two kids, LaDawn Jones runs a law practice. She's busy, but loved serving in the Georgia legislature. She had to leave, though, after one term because it just didn't pay enough. LADAWN JONES: I absolutely believe that we need to increase the wage for legislators to keep up with the times. KAUFFMAN: Lawmakers in Georgia make $17,000 a year. It's considered a part-time job, but it took much more of her time than that. When the legislature was in session, Jones couldn't work at her law firm and had to hire extra help. That cost her. JONES: If I really sat down and did the math, I'm certain that the amount that I paid out was equal or more than what I received. KAUFFMAN: A few big states like Pennsylvania or California have full-time lawmakers who earn $80,000 or even $100,000 a year. But in most states, legislators are paid like it's part-time. That can keep people from getting into state politics, says Neil Malhotra of Stanford University. NEIL MALHOTRA: There's very, very few working-class people in legislatures. And this might have something to do with why a lot of legislation does not seem very friendly towards working-class people. KAUFFMAN: And it's not just working-class people who are left out, Malhotra says. Anyone with a regular job has a hard time taking several months a year off to work in a state capital. Mike Dudgeon just retired from the legislature because the requirements of his job at a videogame company were too great. MIKE DUDGEON: Some people suggested that I sort of do the phone-it-in thing and just keep my seat in the legislature and just do the bare minimum, just go down and vote and kind of do that. But that's - I just can't do that. It's not my personality. I'm going to do anything, I'm going to do it well. KAUFFMAN: Many lawmakers own businesses or they work in law, medicine or agriculture, professions where they can control their schedules. People with experience in fields like technology or finance have a harder time serving. Malhotra says when it comes to those issues, lobbyists are the only experts at the statehouse. And that gives them an edge in the legislative process. MALHOTRA: You don't really write these bills. The lobbyists kind of write the bills for you. KAUFFMAN: In Georgia, there's no sign lawmakers will get a raise anytime soon. David Shafer is a leader in the Georgia Senate. DAVID SHAFER: I'm not in favor of increasing legislative pay. I don't know that anyone serves in the General Assembly because of the pay, and I don't know that we would attract a better legislator if the pay were higher. KAUFFMAN: Georgia lawmakers are set to pass a more than $20 billion budget this year and grapple with a failing hospital system. Jones would love to be a part of those debates. JONES: I could not dare ask my family to continue to make such a big sacrifice without that help. KAUFFMAN: So instead of focusing on statewide issues from the capital, Jones plans to focus her political energy on her community. For NPR News, I'm Johnny Kauffman in Atlanta. (SOUNDBITE OF ALWAYS THE RUNNER'S \"SHOULD A BEAR INTERRUPT YOUR PICNIC\")", "section": "Politics", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-01-10-509086451": {"title": "Humans Worry About Self-Driving Cars. Maybe It Should Be The Reverse : NPR", "url": "https://www.npr.org/2017/01/10/509086451/humans-worry-about-self-driving-cars-maybe-it-should-be-the-reverse", "author": "No author found", "published_date": "2017-01-10", "content": "RACHEL MARTIN, HOST: I don't know about you, but when I've seen these images of self-driving cars in TV ads or in some other way, it's a little bit disconcerting, I mean, the idea that this thing is just out there making life-and-death decisions at every turn. So apparently there's some new social science research that is examining something that's a little counterintuitive. Instead of cars terrorizing people, one researcher is asking whether people might be terrorizing self-driving cars. I need some help explaining this, so our own NPR Shankar Vedantam is here to help me. Hi, Shankar. SHANKAR VEDANTAM, BYLINE: Hi, Rachel. MARTIN: What does this mean, people terrorizing self-driving cars? VEDANTAM: Well, let me set this up for you. I was talking with Adam Millard-Ball - he's a professor of environmental studies at the University of California at Santa Cruz - and he's modeled what's going to happen when self-driving cars start showing up on the road. MARTIN: OK. VEDANTAM: He told me that, at its core, driving is not just about the physics of moving objects and the law of who can do what on the road. It's also about psychology. People have developed really complex and often unspoken rules of how to interact with one another on the road. You can teach a self-driving car all the rules and give it the tools to navigate around obstacles, but can these cars deal with all the psychological games that human drivers and pedestrians play on the roads? MARTIN: I mean, I know that there's psychological warfare on the road for sure, but tell me how that applies to this situation. VEDANTAM: So when we think of all the technologies that self-driving cars need, we often make a big assumption and that big assumption is that rational behavior is always the right course of action on the road. Millard-Ball told me he once took a taxicab ride in New York. Unlike the standard issue New York cab driver, this one actually drove his car rationally, deliberately and followed all the rules of the road. In other words, he drove like a self-driving car. ADAM MILLARD-BALL: He didn't try and cut in. He'd yielded to pedestrians and cyclists when he should, and in a journey (ph) that two or three times as long to get across Manhattan as it would have done otherwise. MARTIN: (Laughter) But it was a safer experience. And we note that because that feels exceptional - right? - because you can get in a cab and think that your life's on the line sometimes. VEDANTAM: Exactly. Now, no one in their right mind would program a self-driving car to behave irrationally. But when you think about it, a good part of driving today involves the unspoken assumption that other drivers may not always behave rationally. When it comes to interacting with self-driving cars, humans will know that the robot who's operating the car will always do the rational thing. MILLARD-BALL: A self-driving car is not going to be drunk. It's not going to look down to check it's phone. It's not going to be distracted, and it's not going to be sociopathic in that it's not going to kind of dare a pedestrian to walk out in front of it. MARTIN: And so is that going to make us, the pedestrians, or just the other drivers, less cautious? VEDANTAM: I think so. I mean, if you know the other car is always going to stop, even if you are in the wrong, you now have a psychological incentive to play a game of chicken because in the game of chicken, crazy beats sane when you're playing chicken. Or think of pedestrians. You know, today I know that if I step into a busy intersection, some crazy driver who is texting his girlfriend is going to hit me, so I do the rational thing and I stay on the sidewalk. But if I was certain the car is always going to stop, and presumably self-driving cars will be programmed to stop, shouldn't we expect lots of pedestrians to boldly step in front of cars? MARTIN: I'm going to drive the bus. VEDANTAM: (Laughter). MARTIN: I don't know if that's going to make me safer or not. Shankar Vedantam, NPR's social science correspondent, he's also the host of a podcast that explores the unseen patterns in human behavior. It's called Hidden Brain. Thanks, Shankar. VEDANTAM: Thank you, Rachel. RACHEL MARTIN, HOST:  I don't know about you, but when I've seen these images of self-driving cars in TV ads or in some other way, it's a little bit disconcerting, I mean, the idea that this thing is just out there making life-and-death decisions at every turn. So apparently there's some new social science research that is examining something that's a little counterintuitive. Instead of cars terrorizing people, one researcher is asking whether people might be terrorizing self-driving cars. I need some help explaining this, so our own NPR Shankar Vedantam is here to help me. Hi, Shankar. SHANKAR VEDANTAM, BYLINE: Hi, Rachel. MARTIN: What does this mean, people terrorizing self-driving cars? VEDANTAM: Well, let me set this up for you. I was talking with Adam Millard-Ball - he's a professor of environmental studies at the University of California at Santa Cruz - and he's modeled what's going to happen when self-driving cars start showing up on the road. MARTIN: OK. VEDANTAM: He told me that, at its core, driving is not just about the physics of moving objects and the law of who can do what on the road. It's also about psychology. People have developed really complex and often unspoken rules of how to interact with one another on the road. You can teach a self-driving car all the rules and give it the tools to navigate around obstacles, but can these cars deal with all the psychological games that human drivers and pedestrians play on the roads? MARTIN: I mean, I know that there's psychological warfare on the road for sure, but tell me how that applies to this situation. VEDANTAM: So when we think of all the technologies that self-driving cars need, we often make a big assumption and that big assumption is that rational behavior is always the right course of action on the road. Millard-Ball told me he once took a taxicab ride in New York. Unlike the standard issue New York cab driver, this one actually drove his car rationally, deliberately and followed all the rules of the road. In other words, he drove like a self-driving car. ADAM MILLARD-BALL: He didn't try and cut in. He'd yielded to pedestrians and cyclists when he should, and in a journey (ph) that two or three times as long to get across Manhattan as it would have done otherwise. MARTIN: (Laughter) But it was a safer experience. And we note that because that feels exceptional - right? - because you can get in a cab and think that your life's on the line sometimes. VEDANTAM: Exactly. Now, no one in their right mind would program a self-driving car to behave irrationally. But when you think about it, a good part of driving today involves the unspoken assumption that other drivers may not always behave rationally. When it comes to interacting with self-driving cars, humans will know that the robot who's operating the car will always do the rational thing. MILLARD-BALL: A self-driving car is not going to be drunk. It's not going to look down to check it's phone. It's not going to be distracted, and it's not going to be sociopathic in that it's not going to kind of dare a pedestrian to walk out in front of it. MARTIN: And so is that going to make us, the pedestrians, or just the other drivers, less cautious? VEDANTAM: I think so. I mean, if you know the other car is always going to stop, even if you are in the wrong, you now have a psychological incentive to play a game of chicken because in the game of chicken, crazy beats sane when you're playing chicken. Or think of pedestrians. You know, today I know that if I step into a busy intersection, some crazy driver who is texting his girlfriend is going to hit me, so I do the rational thing and I stay on the sidewalk. But if I was certain the car is always going to stop, and presumably self-driving cars will be programmed to stop, shouldn't we expect lots of pedestrians to boldly step in front of cars? MARTIN: I'm going to drive the bus. VEDANTAM: (Laughter). MARTIN: I don't know if that's going to make me safer or not. Shankar Vedantam, NPR's social science correspondent, he's also the host of a podcast that explores the unseen patterns in human behavior. It's called Hidden Brain. Thanks, Shankar. VEDANTAM: Thank you, Rachel.", "section": "Hidden Brain", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-01-12-509485046": {"title": "Rudy Giuliani To Advise Trump On Cyber Issues : NPR", "url": "https://www.npr.org/2017/01/12/509485046/rudy-giuliani-to-advise-trump-on-cyber-issues", "author": "No author found", "published_date": "2017-01-12", "content": "", "section": "Politics", "disclaimer": ""}, "2017-01-13-509355546": {"title": "Avi Rubin: What Happens When Hackers Hijack Our Smart Devices? : NPR", "url": "https://www.npr.org/2017/01/13/509355546/what-happens-when-hackers-hijack-our-smart-devices", "author": "No author found", "published_date": "2017-01-13", "content": "GUY RAZ, HOST: On the show today, ideas about the Power Of Networks how those connections, those pathways define the world around us. AVI RUBIN: Well, in my house, my doorbell is connected to my cell phone which is connected to my laptop which is connected to. . . RAZ: This is computer scientist Avi Rubin. RUBIN: . . . The thermostat which is connected to the alarm system, and I can sit in my bathroom after I've taken a shower and before I've gotten dressed and pick up my phone and turn on the heat in my car. And then turn on the coffeemaker and the toaster. RAZ: And we're all headed in this direction, right? RUBIN: Yeah. RAZ: I mean, our homes and our appliances - they are basically becoming extensions of us. RUBIN: Yes. It's known as the internet of things, and all these devices are not only connected to each other, but they're connected to pretty much every other device on the Internet. RAZ: So I should probably mention here that Avi's area of expertise is computer security which means he understands how all of this connectivity can also make us incredibly vulnerable. Is everything that we own that's connected to the internet, can all of that in theory be hacked? RUBIN: I would say that that's a fair assumption. RAZ: That's totally crazy. RUBIN: Yes. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED REPORTER #1: If you had internet trouble this morning, you weren't alone. Hackers disrupted. . . UNIDENTIFIED REPORTER #2: A series of cyber attacks today against the internet. RAZ: You might remember this. It was a few months ago. Some of the biggest sites on the internet like Amazon and Google went down across large parts of the U. S. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED REPORTER #3: The attacks began early this morning as websites from Twitter to Netflix. . . RAZ: And that disruption was caused by an attack, an attack that actually began inside the internet of things, inside the devices we use every day. RUBIN: Unbeknownst to us, hackers out there were able to put malicious software on these devices by taking advantage of bugs in the software when these things were manufactured. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED WOMAN: Basically your everyday household things. UNIDENTIFIED REPORTER #4: Experts say cheap, generic devices are usually the most susceptible. . . UNIDENTIFIED WOMAN: Like routers, security cameras, DVRs. . . RUBIN: So some attacker sent the command to all these devices at the same time saying attack. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED REPORTER #5: The attacks focused on Dyn Inc. , an internet switchboard for numerous major websites. The attacks continued throughout the day. RUBIN: And so that attack was able to produce a situation where a lot of users were not able to communicate with some of the services that they rely on the most, like Twitter and Google and other sites. The service simply wasn't available. RAZ: Just not available. RUBIN: And it's not in most people's threat model. RAZ: Yeah. RUBIN: People don't say, well, I'll watch Netflix if it's available. They just say, I'm going to watch Netflix. You assume it's going to be there. RAZ: OK, losing Netflix for a day or two - not the end of the world, right? But what Avi is worried about is that hackers can exploit our growing dependence on the internet of things to do some really serious damage, which he explained on the TED stage. (SOUNDBITE OF TED TALK)RUBIN: So let me talk about a couple of more interesting internet of things hacks. One of them is Samsung's new smart fridge, OK? Samsung realized that in order to know what's on your calendar, people don't want to have to pull out their phone or go look on their computer. They can just look on their fridge. And so they designed a smart fridge that you could log into with your Google credentials and see your calendar right there on your fridge. The only problem is the people that built that may not have had a lot of security training. And they don't validate the SSL certificates. For those of you that are not technical, trust me, that means bad stuff will happen. (LAUGHTER)RUBIN: And what you can do is if the certificates aren't validated, you can create a man-in-the-middle attack which will allow somebody to get the person's Gmail email, all the history of all of their email, and to log into their Gmail account, basically, because they have a smart fridge. Now, we've all seen these fitness trackers that are all the rage. Everybody is tracking their steps and their running and their health and their fitness. What I'm showing you here is a fitness tracker, one of the top models, that had a bug in the software. And it causes the sensors to sample way too much. And it injured this person. Another device that is in the health and fitness space that I purchased was this blood pressure monitor. You use your iPhone, and then you can see - you know, say start and you can see your progress, et cetera. So I put this thing on and I activated it, and it started squeezing my arm. And it squeezed really, really hard. And I tend to be pretty claustrophobic, and I was starting to wonder if this thing was going to rip my arm off. I mean, it really, really, really hurt. So it didn't rip off my arm, fortunately, but I got a really scary reading. I was supposed to be dead in about three minutes based on my blood pressure reading when I did that. And there are even things like implantable devices, like defibrillators that go right into a person, and those have connectivity to devices that can control them. And if you think about it, it makes sense, right? If somebody needs to change their defibrillator settings because their medical condition changed, you shouldn't have to cut the person open and do that if you can do it wirelessly. But at the same time, you have to design that system so that someone can't sit in, you know, Grand Central Station and put out wireless signals and have people dropping all around them because they just killed them. RAZ: I mean, it seems like if you're a sophisticated hacker this is, like, a golden age because everybody is connected, everything around the world is connected, and more so every day. And we haven't even thought about what that means. RUBIN: I think we're living in a honeymoon phase where we get most of the benefits of the internet without the hackers completely taking over and destroying all of this. But, you know, most people are not security specialists. And so they see software as an enabler. And you see more and more devices that you wouldn't normally consider to be smart or things that you would even want to be smart. You wonder, why would somebody make a smart one of those? And yet they do. RAZ: Right. I mean, we were just hearing from Wanis Kabbaj and, I mean, he was saying how driverless cars could solve all these problems for us. And now I'm thinking, I mean, how vulnerable they would be to hacking, right? And not even driverless cars - all cars, the cars that are on the road today. RUBIN: Well, some of that's already happened. There have been demonstrations - numerous demonstrations of being able to hack into cars, actual commercially deployed vehicles that people are driving, and getting them to break, getting them to run up to very high speeds, disabling the brakes. All of that can be done today. RAZ: Avi Rubin will be back in just a moment to explain how pretty much any modern car can be hacked. On the show today, the Power Of Networks for good and for not so good. I'm Guy Raz, and you're listening to the TED Radio Hour from NPR. (SOUNDBITE OF MUSIC)RAZ: It's the TED Radio Hour from NPR. I'm Guy Raz. And on the show today, ideas about the Power Of Networks, the ones in the natural world and the ones we build for ourselves. And we were just hearing from computer science professor Avi Rubin about how so many of the things in our lives, even our cars, are networked, connected to the internet, which makes those things incredibly vulnerable to hackers. (SOUNDBITE OF TED TALK)RUBIN: This is a car, and it has a lot of components, a lot of electronics in it today. In fact, it's got many, many different computers inside of it, more Pentiums than my lab did when I was in college. And they're connected by a wired network. There's also a wireless network, which can be reached from many different ways. So there's Bluetooth. There's the FM and XM radio. There's actually Wi-Fi. There are sensors in the wheels that wirelessly communicate the tire pressure to a controller onboard. And what happens if somebody wanted to attack this? Well, that's what the researchers that I'm going to talk about today did. They actually carried out their attack in real life. They bought two cars, and I guess they have better budgets than I do. The first threat model was to see what someone could do if an attacker actually got access to the internal network on the car, OK? So think of that as someone gets to go to your car, they get to mess around with it and then they leave. And now what kind of trouble are you in? And so they connected to the diagnostic unit on the in-car network, and they did all kinds of silly things. Like, here's a picture of the speedometer showing 140 miles an hour when the car's in park. Now, you might say, OK, that's silly. Well, what if you make the car always say it's going 20 miles an hour slower than it's actually going? You might produce a lot of speeding tickets. Then they went out to an abandoned airstrip with two cars, the target victim car and the chase car, and they launched a bunch of other attacks simply by hacking the computer. One of the things they were able to do from the chase car is apply the brakes on the other car. They were able to disable the brakes. They also were able to install malware that wouldn't kick in and wouldn't trigger until the car was doing something like going over 20 miles an hour or something like that. They were able to compromise every single one of the pieces of software that controlled every single one of the wireless capabilities of the car. And when they gave this talk, even though they gave this talk at a conference to a bunch of computer security researchers, everybody was gasping. Am I scaring you yet? (SOUNDBITE OF MUSIC)RAZ: Yeah, this is pretty scary stuff. Like, has this actually happened in the real world? Like, have hackers been able to do this? RUBIN: Well, so far, all of those have happened in the lab and they've happened by responsible people who have published their work. But the car companies are scrambling. I know, firsthand, that they are spending millions of dollars on security. And there has been research that's shown that the car manufacturers have a bit of a ways to go to get their cars to be secure against hackers. RAZ: You're basically saying that we're in for a pretty dark period in the future. RUBIN: Well, if I want to try to be optimistic, I would say that the security guys are going to come through. And I think that the way that we'll come through is we're going to have to change the internet infrastructure. We're going to have to change the way software is developed. Some of these changes are happening already but not as fast as the attacks are happening. But once the attackers are able to regularly disable the internet, once we go two weeks without any connectivity whatsoever, by necessity, we will invent ways to communicate once again in a much more secure and protected way. RAZ: You're saying that we, in our lifetimes, may witness weeks without the internet. RUBIN: Yeah, I think we'll someday long for the days where we only had a few-hour outage of the internet. RAZ: Is there any argument to be made that, like, maybe we should just put the genie back in the bottle, like, maybe we should unnetwork parts of our world? RUBIN: I think the genie is out for good. I don't think there's any way to do that. Unfortunately, the bad guys might do that for us. But there's no way to impede progress. You can't, for example, propose that we eliminate electricity and not use electricity. And just as we can't go back to the days before electricity, we're never going to go back to the days before networks and connectivity. (SOUNDBITE OF MUSIC)RAZ: Avi Rubin is a professor of computer science at Johns Hopkins University. You can see his entire talk at ted. com. GUY RAZ, HOST:  On the show today, ideas about the Power Of Networks how those connections, those pathways define the world around us. AVI RUBIN: Well, in my house, my doorbell is connected to my cell phone which is connected to my laptop which is connected to. . . RAZ: This is computer scientist Avi Rubin. RUBIN: . . . The thermostat which is connected to the alarm system, and I can sit in my bathroom after I've taken a shower and before I've gotten dressed and pick up my phone and turn on the heat in my car. And then turn on the coffeemaker and the toaster. RAZ: And we're all headed in this direction, right? RUBIN: Yeah. RAZ: I mean, our homes and our appliances - they are basically becoming extensions of us. RUBIN: Yes. It's known as the internet of things, and all these devices are not only connected to each other, but they're connected to pretty much every other device on the Internet. RAZ: So I should probably mention here that Avi's area of expertise is computer security which means he understands how all of this connectivity can also make us incredibly vulnerable. Is everything that we own that's connected to the internet, can all of that in theory be hacked? RUBIN: I would say that that's a fair assumption. RAZ: That's totally crazy. RUBIN: Yes. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED REPORTER #1: If you had internet trouble this morning, you weren't alone. Hackers disrupted. . . UNIDENTIFIED REPORTER #2: A series of cyber attacks today against the internet. RAZ: You might remember this. It was a few months ago. Some of the biggest sites on the internet like Amazon and Google went down across large parts of the U. S. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED REPORTER #3: The attacks began early this morning as websites from Twitter to Netflix. . . RAZ: And that disruption was caused by an attack, an attack that actually began inside the internet of things, inside the devices we use every day. RUBIN: Unbeknownst to us, hackers out there were able to put malicious software on these devices by taking advantage of bugs in the software when these things were manufactured. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED WOMAN: Basically your everyday household things. UNIDENTIFIED REPORTER #4: Experts say cheap, generic devices are usually the most susceptible. . . UNIDENTIFIED WOMAN: Like routers, security cameras, DVRs. . . RUBIN: So some attacker sent the command to all these devices at the same time saying attack. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED REPORTER #5: The attacks focused on Dyn Inc. , an internet switchboard for numerous major websites. The attacks continued throughout the day. RUBIN: And so that attack was able to produce a situation where a lot of users were not able to communicate with some of the services that they rely on the most, like Twitter and Google and other sites. The service simply wasn't available. RAZ: Just not available. RUBIN: And it's not in most people's threat model. RAZ: Yeah. RUBIN: People don't say, well, I'll watch Netflix if it's available. They just say, I'm going to watch Netflix. You assume it's going to be there. RAZ: OK, losing Netflix for a day or two - not the end of the world, right? But what Avi is worried about is that hackers can exploit our growing dependence on the internet of things to do some really serious damage, which he explained on the TED stage. (SOUNDBITE OF TED TALK) RUBIN: So let me talk about a couple of more interesting internet of things hacks. One of them is Samsung's new smart fridge, OK? Samsung realized that in order to know what's on your calendar, people don't want to have to pull out their phone or go look on their computer. They can just look on their fridge. And so they designed a smart fridge that you could log into with your Google credentials and see your calendar right there on your fridge. The only problem is the people that built that may not have had a lot of security training. And they don't validate the SSL certificates. For those of you that are not technical, trust me, that means bad stuff will happen. (LAUGHTER) RUBIN: And what you can do is if the certificates aren't validated, you can create a man-in-the-middle attack which will allow somebody to get the person's Gmail email, all the history of all of their email, and to log into their Gmail account, basically, because they have a smart fridge. Now, we've all seen these fitness trackers that are all the rage. Everybody is tracking their steps and their running and their health and their fitness. What I'm showing you here is a fitness tracker, one of the top models, that had a bug in the software. And it causes the sensors to sample way too much. And it injured this person. Another device that is in the health and fitness space that I purchased was this blood pressure monitor. You use your iPhone, and then you can see - you know, say start and you can see your progress, et cetera. So I put this thing on and I activated it, and it started squeezing my arm. And it squeezed really, really hard. And I tend to be pretty claustrophobic, and I was starting to wonder if this thing was going to rip my arm off. I mean, it really, really, really hurt. So it didn't rip off my arm, fortunately, but I got a really scary reading. I was supposed to be dead in about three minutes based on my blood pressure reading when I did that. And there are even things like implantable devices, like defibrillators that go right into a person, and those have connectivity to devices that can control them. And if you think about it, it makes sense, right? If somebody needs to change their defibrillator settings because their medical condition changed, you shouldn't have to cut the person open and do that if you can do it wirelessly. But at the same time, you have to design that system so that someone can't sit in, you know, Grand Central Station and put out wireless signals and have people dropping all around them because they just killed them. RAZ: I mean, it seems like if you're a sophisticated hacker this is, like, a golden age because everybody is connected, everything around the world is connected, and more so every day. And we haven't even thought about what that means. RUBIN: I think we're living in a honeymoon phase where we get most of the benefits of the internet without the hackers completely taking over and destroying all of this. But, you know, most people are not security specialists. And so they see software as an enabler. And you see more and more devices that you wouldn't normally consider to be smart or things that you would even want to be smart. You wonder, why would somebody make a smart one of those? And yet they do. RAZ: Right. I mean, we were just hearing from Wanis Kabbaj and, I mean, he was saying how driverless cars could solve all these problems for us. And now I'm thinking, I mean, how vulnerable they would be to hacking, right? And not even driverless cars - all cars, the cars that are on the road today. RUBIN: Well, some of that's already happened. There have been demonstrations - numerous demonstrations of being able to hack into cars, actual commercially deployed vehicles that people are driving, and getting them to break, getting them to run up to very high speeds, disabling the brakes. All of that can be done today. RAZ: Avi Rubin will be back in just a moment to explain how pretty much any modern car can be hacked. On the show today, the Power Of Networks for good and for not so good. I'm Guy Raz, and you're listening to the TED Radio Hour from NPR. (SOUNDBITE OF MUSIC) RAZ: It's the TED Radio Hour from NPR. I'm Guy Raz. And on the show today, ideas about the Power Of Networks, the ones in the natural world and the ones we build for ourselves. And we were just hearing from computer science professor Avi Rubin about how so many of the things in our lives, even our cars, are networked, connected to the internet, which makes those things incredibly vulnerable to hackers. (SOUNDBITE OF TED TALK) RUBIN: This is a car, and it has a lot of components, a lot of electronics in it today. In fact, it's got many, many different computers inside of it, more Pentiums than my lab did when I was in college. And they're connected by a wired network. There's also a wireless network, which can be reached from many different ways. So there's Bluetooth. There's the FM and XM radio. There's actually Wi-Fi. There are sensors in the wheels that wirelessly communicate the tire pressure to a controller onboard. And what happens if somebody wanted to attack this? Well, that's what the researchers that I'm going to talk about today did. They actually carried out their attack in real life. They bought two cars, and I guess they have better budgets than I do. The first threat model was to see what someone could do if an attacker actually got access to the internal network on the car, OK? So think of that as someone gets to go to your car, they get to mess around with it and then they leave. And now what kind of trouble are you in? And so they connected to the diagnostic unit on the in-car network, and they did all kinds of silly things. Like, here's a picture of the speedometer showing 140 miles an hour when the car's in park. Now, you might say, OK, that's silly. Well, what if you make the car always say it's going 20 miles an hour slower than it's actually going? You might produce a lot of speeding tickets. Then they went out to an abandoned airstrip with two cars, the target victim car and the chase car, and they launched a bunch of other attacks simply by hacking the computer. One of the things they were able to do from the chase car is apply the brakes on the other car. They were able to disable the brakes. They also were able to install malware that wouldn't kick in and wouldn't trigger until the car was doing something like going over 20 miles an hour or something like that. They were able to compromise every single one of the pieces of software that controlled every single one of the wireless capabilities of the car. And when they gave this talk, even though they gave this talk at a conference to a bunch of computer security researchers, everybody was gasping. Am I scaring you yet? (SOUNDBITE OF MUSIC) RAZ: Yeah, this is pretty scary stuff. Like, has this actually happened in the real world? Like, have hackers been able to do this? RUBIN: Well, so far, all of those have happened in the lab and they've happened by responsible people who have published their work. But the car companies are scrambling. I know, firsthand, that they are spending millions of dollars on security. And there has been research that's shown that the car manufacturers have a bit of a ways to go to get their cars to be secure against hackers. RAZ: You're basically saying that we're in for a pretty dark period in the future. RUBIN: Well, if I want to try to be optimistic, I would say that the security guys are going to come through. And I think that the way that we'll come through is we're going to have to change the internet infrastructure. We're going to have to change the way software is developed. Some of these changes are happening already but not as fast as the attacks are happening. But once the attackers are able to regularly disable the internet, once we go two weeks without any connectivity whatsoever, by necessity, we will invent ways to communicate once again in a much more secure and protected way. RAZ: You're saying that we, in our lifetimes, may witness weeks without the internet. RUBIN: Yeah, I think we'll someday long for the days where we only had a few-hour outage of the internet. RAZ: Is there any argument to be made that, like, maybe we should just put the genie back in the bottle, like, maybe we should unnetwork parts of our world? RUBIN: I think the genie is out for good. I don't think there's any way to do that. Unfortunately, the bad guys might do that for us. But there's no way to impede progress. You can't, for example, propose that we eliminate electricity and not use electricity. And just as we can't go back to the days before electricity, we're never going to go back to the days before networks and connectivity. (SOUNDBITE OF MUSIC) RAZ: Avi Rubin is a professor of computer science at Johns Hopkins University. You can see his entire talk at ted. com.", "section": "TED Radio Hour", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-01-13-509353176": {"title": "Wanis Kabbaj: Can We Improve Our Transportation Network Using.. Biology?  : NPR", "url": "https://www.npr.org/2017/01/13/509353176/can-we-improve-our-transportation-network-using-biology", "author": "No author found", "published_date": "2017-01-13", "content": "GUY RAZ, HOST: It's the TED Radio Hour from NPR. I'm Guy Raz. And on the show today the Power of Networks, the forces that connect us and the connections we build for ourselves. Can you tell me about your - like, your typical morning drive into work? WANIS KABBAJ: (Laughter) Absolutely terrible, mind-numbing. For one thing, it lasts at least an hour and a half. And the interesting thing is that six years ago over the same distance, you know, my commute was 45 minutes. RAZ: This is Wanis Kabbaj. KABBAJ: And I'm a director of health care strategy at UPS. RAZ: Wanis works at UPS headquarters in Atlanta. And, yes, every day he spends three hours in his car going to and from work. So what is the distance from your home to your office? KABBAJ: Every morning, I drive for 25 miles. RAZ: So 25 miles takes you about an hour and a half every day? KABBAJ: Yes. Yes. RAZ: What is the problem? Is it just more people? Is it - or is it just more people who don't know how to drive or what? KABBAJ: I think it's the success of a system that was invented in the late 19th century, beginning of the 20th century. You know, we're reaching the point where the productivity of the system is going down. And the basic problem is that the idea that most people living in a city can use their own individual car to go to work. It's just impossible with the infrastructure that has been built. RAZ: Now, Wanis happens to know a lot about transportation networks. Of course he would. He works at UPS, and he works mainly with health care clients. These are customers that need UPS to deliver medicine all over the world. KABBAJ: Exactly. It goes from the very familiar process of distributing flu vaccines every year at flu season to things that are very unpredictable like the Ebola crisis or. . . RAZ: Yeah. KABBAJ: . . . Where you have to intervene very quickly with no infrastructure, and you have to come up with solutions. RAZ: And the more he talked to these companies, the more Wanis started to change the way he thinks about transportation networks. KABBAJ: I work with pharmaceutical companies, and they occasionally talk about drug delivery and when they talk about drug delivery, we say, yeah, yeah. We can do that. We deliver all sorts of drugs, and the customer will typically say, no, no, no, we're not talking about the drug delivery to the patient. We're talking about the drug delivery to the cells inside the body. And so this type of conversation just made me realize that, you know, you have a fascinating transportation system within our body where if you ingest a pill, it will go from your digestive system to your bloodstream, and ultimately needs to go to potentially a specific area to produce and affect. RAZ: The human body has a pretty efficient network to move things around inside of us. And this idea made Wanis think maybe we could take some of those lessons from biology and use them to improve the transportation networks in our cities. Here's Wanis on the TED stage. (SOUNDBITE OF TED TALK)KABBAJ: Biology has been in the transportation business for billions of years. It has been testing countless solutions to move nutrients, gases and proteins. It really is the world's most sophisticated transportation laboratory. So what if the solution to our traffic challenges was inside us? I wanted to know why is it that blood flows in our veins most of our life when our big cities get clogged on a daily basis? Each of us has 60,000 miles of blood vessels in our bodies - 60,000 miles. That's two and a half times the Earth's circumference inside you. What it means is that blood vessels are everywhere inside us, not just under the surface of our skin. But if you look at our cities, yes, we have some underground subway systems, tunnels and bridges, but the vast majority of our traffic is focused on the ground, on the surface. So in other words while our vascular system uses the three dimensions inside us, our urban transportation is mostly two-dimensional. The reason blood is so incredibly efficient is that our red blood cells are not dedicated to specific organs or tissues. Otherwise, we would probably have traffic jams in our veins. Now, they're shared. They are shared by all the cells of our body. And because our network is so extensive, each one of our 37 trillion cells get its own deliveries of oxygen precisely when it needs them. Blood is both a collective and an individual form of transportation. But for our cities, we've been stuck in an endless debate between creating a car-centric society or extensive mass transit systems. RAZ: I mean, it really is amazing when you think about it like how incredibly efficient the human body is at moving things around, right? KABBAJ: Absolutely. I mean it is absolutely incredible. One thing that I was curious about was the heart. The heart is a pump, and I was curious to estimate how much it would cost us to operate it, you know, if we plugged it on the electrical grid. And I made some calculations and the estimate that I found, you know, in order to operate your heart on a four-year on the electrical grid system, it would cost you $1. 10. RAZ: Wow. KABBAJ: And I just was mind blown by the - how little energy our body uses to transport oxygen, to transport nutrients. And it just was an impetus for me to dig into it and try to learn more about different components of that transportation system. RAZ: So I mean what could a - like could the future look like? Like, a future where streets and highways work like our bodies do? Like if you took a city like Atlanta in a hundred years from now, what would all the transport options be like? KABBAJ: So, I mean, if you think about a city like Atlanta that has a very dense core with very high buildings and high rises, one first striking thing is that you will see more and more vehicles in the air. It doesn't make sense that we've built higher and higher buildings in order to create density, but that our transportation is still mostly flat, mostly horizontal. So you will see flying vehicles, companies like Airbus today are working on flying urban taxis. You have more and more ventures working on drones that can transport people. You may have other layers, horizontal layers of transportation beside the roads. You may have suspended magnetic trains or parts that transport people. So I think that's one component. A second component is that you will have more driverless pods that people can use that move at a very fast pace in a very smart way that communicate with each other, communicate with the infrastructure. So it will be mesmerizing, but it will be fast-moving and definitely more fluidity in the system. RAZ: I mean, once driverless cars are real, these cars presumably will be networked. They'll be communicating with each other, there'll be no traffic, there'll be no accidents, there'll be no slowdowns. The car will know exactly where to go, where to park. I mean, won't that sort of fix the problem? KABBAJ: I think it will be a major solution to our problem. There are already studies that are being made around sharing platforms so vehicles that are shared by multiple users, and we already can see that it has a very positive effect on the congestion level in cities, that one shared vehicle can replace five to seven individual vehicles on the road. That's a big improvement, and the perspective of having these vehicles driverless will push to savings even further once we have these large driverless, infrastructure built in and available. (SOUNDBITE OF TED TALK)KABBAJ: Just imagine a very familiar scene. You've been driving for 42 minutes. The two kids behind you are getting restless, and you are late. Do you see that slow car in front of you? Always comes when you're late, right? That driver is looking for parking. There is no parking spot available in the area, but how would he know? It is estimated that up to 30 percent of urban traffic is generated by drivers looking for parking. Do you see the hundred cars around you? Eighty-five of them only have one passenger. Biology would never do this. Space inside our arteries is fully utilized, and the tiny space inside our red blood cells is not wasted either. In healthy conditions, more than 95 percent of their oxygen capacity is utilized. Red blood cells are not flowing in lanes. They never stop at red lights in the first driverless cities, you would have no red lights and no lanes. And when all the cars are driverless and connected, everything is predictable and reaction time - minimum. They can drive much faster and can take any rational initiative that can speed them up or the cars around them. So instead of rigid traffic rules, flow will be regulated by a mesh of dynamic and constantly self-improving algorithms. The result - a strange traffic that mixes the fast and smooth rigor of German autobahns and the creative vitality of the intersections of Mumbai. Traffic will be functionally exuberant. It will be liquid like our blood and by a strange paradox, the more robotized our traffic grid will be, the more organic and alive its movement will feel. RAZ: Do you think that in your lifetime, in my lifetime do you think we'll be able to see these networks of connected, driverless cars? I mean, do you think we'll be able to actually solve the transit problem in our cities? KABBAJ: So, I mean, today, you can hop on a driverless car in Singapore and have a ride in Singapore. You have a city like Dubai that is committed to test autonomous pods to transport people and in our sort of buses that are modular. So I definitely think that we're going to see that. The problem is big enough, the congestion problem is big enough and has such high economic cost that I think the incentive will be pretty high for some very competitive cities to implement innovative solutions. So the combinations of intelligence, capital and the magnitude of this problem just makes me convinced that we are definitely going to see in our lifetime driverless cities that are more fluid. I'm - yeah - absolutely convinced of it. RAZ: Wanis Kabbaj lives in Atlanta. You can see his entire talk at ted. com. GUY RAZ, HOST:  It's the TED Radio Hour from NPR. I'm Guy Raz. And on the show today the Power of Networks, the forces that connect us and the connections we build for ourselves. Can you tell me about your - like, your typical morning drive into work? WANIS KABBAJ: (Laughter) Absolutely terrible, mind-numbing. For one thing, it lasts at least an hour and a half. And the interesting thing is that six years ago over the same distance, you know, my commute was 45 minutes. RAZ: This is Wanis Kabbaj. KABBAJ: And I'm a director of health care strategy at UPS. RAZ: Wanis works at UPS headquarters in Atlanta. And, yes, every day he spends three hours in his car going to and from work. So what is the distance from your home to your office? KABBAJ: Every morning, I drive for 25 miles. RAZ: So 25 miles takes you about an hour and a half every day? KABBAJ: Yes. Yes. RAZ: What is the problem? Is it just more people? Is it - or is it just more people who don't know how to drive or what? KABBAJ: I think it's the success of a system that was invented in the late 19th century, beginning of the 20th century. You know, we're reaching the point where the productivity of the system is going down. And the basic problem is that the idea that most people living in a city can use their own individual car to go to work. It's just impossible with the infrastructure that has been built. RAZ: Now, Wanis happens to know a lot about transportation networks. Of course he would. He works at UPS, and he works mainly with health care clients. These are customers that need UPS to deliver medicine all over the world. KABBAJ: Exactly. It goes from the very familiar process of distributing flu vaccines every year at flu season to things that are very unpredictable like the Ebola crisis or. . . RAZ: Yeah. KABBAJ: . . . Where you have to intervene very quickly with no infrastructure, and you have to come up with solutions. RAZ: And the more he talked to these companies, the more Wanis started to change the way he thinks about transportation networks. KABBAJ: I work with pharmaceutical companies, and they occasionally talk about drug delivery and when they talk about drug delivery, we say, yeah, yeah. We can do that. We deliver all sorts of drugs, and the customer will typically say, no, no, no, we're not talking about the drug delivery to the patient. We're talking about the drug delivery to the cells inside the body. And so this type of conversation just made me realize that, you know, you have a fascinating transportation system within our body where if you ingest a pill, it will go from your digestive system to your bloodstream, and ultimately needs to go to potentially a specific area to produce and affect. RAZ: The human body has a pretty efficient network to move things around inside of us. And this idea made Wanis think maybe we could take some of those lessons from biology and use them to improve the transportation networks in our cities. Here's Wanis on the TED stage. (SOUNDBITE OF TED TALK) KABBAJ: Biology has been in the transportation business for billions of years. It has been testing countless solutions to move nutrients, gases and proteins. It really is the world's most sophisticated transportation laboratory. So what if the solution to our traffic challenges was inside us? I wanted to know why is it that blood flows in our veins most of our life when our big cities get clogged on a daily basis? Each of us has 60,000 miles of blood vessels in our bodies - 60,000 miles. That's two and a half times the Earth's circumference inside you. What it means is that blood vessels are everywhere inside us, not just under the surface of our skin. But if you look at our cities, yes, we have some underground subway systems, tunnels and bridges, but the vast majority of our traffic is focused on the ground, on the surface. So in other words while our vascular system uses the three dimensions inside us, our urban transportation is mostly two-dimensional. The reason blood is so incredibly efficient is that our red blood cells are not dedicated to specific organs or tissues. Otherwise, we would probably have traffic jams in our veins. Now, they're shared. They are shared by all the cells of our body. And because our network is so extensive, each one of our 37 trillion cells get its own deliveries of oxygen precisely when it needs them. Blood is both a collective and an individual form of transportation. But for our cities, we've been stuck in an endless debate between creating a car-centric society or extensive mass transit systems. RAZ: I mean, it really is amazing when you think about it like how incredibly efficient the human body is at moving things around, right? KABBAJ: Absolutely. I mean it is absolutely incredible. One thing that I was curious about was the heart. The heart is a pump, and I was curious to estimate how much it would cost us to operate it, you know, if we plugged it on the electrical grid. And I made some calculations and the estimate that I found, you know, in order to operate your heart on a four-year on the electrical grid system, it would cost you $1. 10. RAZ: Wow. KABBAJ: And I just was mind blown by the - how little energy our body uses to transport oxygen, to transport nutrients. And it just was an impetus for me to dig into it and try to learn more about different components of that transportation system. RAZ: So I mean what could a - like could the future look like? Like, a future where streets and highways work like our bodies do? Like if you took a city like Atlanta in a hundred years from now, what would all the transport options be like? KABBAJ: So, I mean, if you think about a city like Atlanta that has a very dense core with very high buildings and high rises, one first striking thing is that you will see more and more vehicles in the air. It doesn't make sense that we've built higher and higher buildings in order to create density, but that our transportation is still mostly flat, mostly horizontal. So you will see flying vehicles, companies like Airbus today are working on flying urban taxis. You have more and more ventures working on drones that can transport people. You may have other layers, horizontal layers of transportation beside the roads. You may have suspended magnetic trains or parts that transport people. So I think that's one component. A second component is that you will have more driverless pods that people can use that move at a very fast pace in a very smart way that communicate with each other, communicate with the infrastructure. So it will be mesmerizing, but it will be fast-moving and definitely more fluidity in the system. RAZ: I mean, once driverless cars are real, these cars presumably will be networked. They'll be communicating with each other, there'll be no traffic, there'll be no accidents, there'll be no slowdowns. The car will know exactly where to go, where to park. I mean, won't that sort of fix the problem? KABBAJ: I think it will be a major solution to our problem. There are already studies that are being made around sharing platforms so vehicles that are shared by multiple users, and we already can see that it has a very positive effect on the congestion level in cities, that one shared vehicle can replace five to seven individual vehicles on the road. That's a big improvement, and the perspective of having these vehicles driverless will push to savings even further once we have these large driverless, infrastructure built in and available. (SOUNDBITE OF TED TALK) KABBAJ: Just imagine a very familiar scene. You've been driving for 42 minutes. The two kids behind you are getting restless, and you are late. Do you see that slow car in front of you? Always comes when you're late, right? That driver is looking for parking. There is no parking spot available in the area, but how would he know? It is estimated that up to 30 percent of urban traffic is generated by drivers looking for parking. Do you see the hundred cars around you? Eighty-five of them only have one passenger. Biology would never do this. Space inside our arteries is fully utilized, and the tiny space inside our red blood cells is not wasted either. In healthy conditions, more than 95 percent of their oxygen capacity is utilized. Red blood cells are not flowing in lanes. They never stop at red lights in the first driverless cities, you would have no red lights and no lanes. And when all the cars are driverless and connected, everything is predictable and reaction time - minimum. They can drive much faster and can take any rational initiative that can speed them up or the cars around them. So instead of rigid traffic rules, flow will be regulated by a mesh of dynamic and constantly self-improving algorithms. The result - a strange traffic that mixes the fast and smooth rigor of German autobahns and the creative vitality of the intersections of Mumbai. Traffic will be functionally exuberant. It will be liquid like our blood and by a strange paradox, the more robotized our traffic grid will be, the more organic and alive its movement will feel. RAZ: Do you think that in your lifetime, in my lifetime do you think we'll be able to see these networks of connected, driverless cars? I mean, do you think we'll be able to actually solve the transit problem in our cities? KABBAJ: So, I mean, today, you can hop on a driverless car in Singapore and have a ride in Singapore. You have a city like Dubai that is committed to test autonomous pods to transport people and in our sort of buses that are modular. So I definitely think that we're going to see that. The problem is big enough, the congestion problem is big enough and has such high economic cost that I think the incentive will be pretty high for some very competitive cities to implement innovative solutions. So the combinations of intelligence, capital and the magnitude of this problem just makes me convinced that we are definitely going to see in our lifetime driverless cities that are more fluid. I'm - yeah - absolutely convinced of it. RAZ: Wanis Kabbaj lives in Atlanta. You can see his entire talk at ted. com.", "section": "TED Radio Hour", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-01-16-510128857": {"title": "Takeaways From The Day Dyn Was Attacked And We Couldn't Tweet : NPR", "url": "https://www.npr.org/2017/01/16/510128857/takeaways-from-the-day-dyn-was-attacked-and-we-couldnt-tweet", "author": "No author found", "published_date": "2017-01-16", "content": "KELLY MCEVERS, HOST: October 21, 2016 - it started like a regular day for Kyle York. KYLE YORK: I can remember driving into our headquarters in Manchester, N. H. and, actually, our largest customer in the world called saying they were experiencing some issues with their application. MCEVERS: York is used to fielding calls about clients' internet problems. He's the chief strategy officer at Dyn. It is an internet performance company. Basically, it makes sure that when you type in one of its clients' web addresses, that company's site pops up on your screen. Once York got to work that day, he learned many websites were having the same problem. Soon, it was all over the news. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED MAN #1: A series of cyberattacks today against the internet. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED MAN #2: U. S. interest in cyberspace is monitoring the situation. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED MAN #3: Websites from Twitter to Netflix slowed to a crawl or even stopped. MCEVERS: Those attacks were aimed at Dyn's servers. YORK: What happened was that the company was basically under siege. Internet of things devices were being taken over in people's homes and pointing a lot of traffic at our infrastructure specifically, which, again, is infrastructure running services for, you know, many major enterprise brands online. MCEVERS: The hackers had turned millions of web-connected thermostats, cameras, DVRs and other smart devices into attack weapons all pointed at Dyn. It took the company nearly all day to get things under control. YORK: You know, we see these events every single day. It just so happened that that one was, you know, complex and unprecedented and moving around the world and, you know, it was basically bringing our infrastructure under attack. And in turn, customers that rely on that infrastructure to serve websites and web applications were having performance issues on a global level. MCEVERS: Do you think people in this country are sufficiently aware that these devices, these internet connected things are vulnerable? YORK: No, absolutely not. MCEVERS: No? (LAUGHTER)YORK: No, I mean - and you and I are on the internet every day, right? I mean, think about the amount of things in your home that are connected to the internet, you know, the phone in your pocket. I just think that, you know, we as the average consumer - and I'm one of them, I think I just know a little bit more about tech - we sort of take the internet for granted and the fact that we're always interconnected. I think in this attack, one of the major issues was the vulnerable devices were being hacked because many of them were using admin for username and admin for password out of the box from the manufacturer. So it was pretty easy to hijack them and take them over. So I think making sure you always update your passwords and be vigilant on not using the same password across every single internet property you engage with is just critical. And then lastly, make sure you update the software on those devices, you know, and pressure your manufacturers to be taking security very seriously because the internet of things, as a commercial market, sort of ran ahead of internet standards and policy and governance. MCEVERS: Kyle York says he still doesn't know who launched this attack against Dyn. He thinks that's pretty irrelevant anyway. More concerning to him, he says, is that these sorts of attacks are happening more and more every day as web-connected cars and other devices become part of our daily lives. KELLY MCEVERS, HOST:  October 21, 2016 - it started like a regular day for Kyle York. KYLE YORK: I can remember driving into our headquarters in Manchester, N. H. and, actually, our largest customer in the world called saying they were experiencing some issues with their application. MCEVERS: York is used to fielding calls about clients' internet problems. He's the chief strategy officer at Dyn. It is an internet performance company. Basically, it makes sure that when you type in one of its clients' web addresses, that company's site pops up on your screen. Once York got to work that day, he learned many websites were having the same problem. Soon, it was all over the news. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED MAN #1: A series of cyberattacks today against the internet. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED MAN #2: U. S. interest in cyberspace is monitoring the situation. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED MAN #3: Websites from Twitter to Netflix slowed to a crawl or even stopped. MCEVERS: Those attacks were aimed at Dyn's servers. YORK: What happened was that the company was basically under siege. Internet of things devices were being taken over in people's homes and pointing a lot of traffic at our infrastructure specifically, which, again, is infrastructure running services for, you know, many major enterprise brands online. MCEVERS: The hackers had turned millions of web-connected thermostats, cameras, DVRs and other smart devices into attack weapons all pointed at Dyn. It took the company nearly all day to get things under control. YORK: You know, we see these events every single day. It just so happened that that one was, you know, complex and unprecedented and moving around the world and, you know, it was basically bringing our infrastructure under attack. And in turn, customers that rely on that infrastructure to serve websites and web applications were having performance issues on a global level. MCEVERS: Do you think people in this country are sufficiently aware that these devices, these internet connected things are vulnerable? YORK: No, absolutely not. MCEVERS: No? (LAUGHTER) YORK: No, I mean - and you and I are on the internet every day, right? I mean, think about the amount of things in your home that are connected to the internet, you know, the phone in your pocket. I just think that, you know, we as the average consumer - and I'm one of them, I think I just know a little bit more about tech - we sort of take the internet for granted and the fact that we're always interconnected. I think in this attack, one of the major issues was the vulnerable devices were being hacked because many of them were using admin for username and admin for password out of the box from the manufacturer. So it was pretty easy to hijack them and take them over. So I think making sure you always update your passwords and be vigilant on not using the same password across every single internet property you engage with is just critical. And then lastly, make sure you update the software on those devices, you know, and pressure your manufacturers to be taking security very seriously because the internet of things, as a commercial market, sort of ran ahead of internet standards and policy and governance. MCEVERS: Kyle York says he still doesn't know who launched this attack against Dyn. He thinks that's pretty irrelevant anyway. More concerning to him, he says, is that these sorts of attacks are happening more and more every day as web-connected cars and other devices become part of our daily lives.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-01-16-510096767": {"title": "'Robot Lawyer' Makes The Case Against Parking Tickets : NPR", "url": "https://www.npr.org/2017/01/16/510096767/robot-lawyer-makes-the-case-against-parking-tickets", "author": "No author found", "published_date": "2017-01-16", "content": "KELLY MCEVERS, HOST: You get a ticket even though you thought you parked in a legitimate spot. NPR's Arezou Rezvani reports that an online robot might be able to help. AREZOU REZVANI, BYLINE: It was the first day of school for Dan Lear's kids. In a scramble, this lawyer from Seattle parked where he could and got his three boys to class. DAN LEAR: There was a fire hydrant, but the curb wasn't painted and the fire hydrant was painted kind of a funny color. And so I thought - maybe it was wishful thinking - but I thought I would be OK to park there. REZVANI: Sure enough, Lear returned to a ticket. LEAR: I was bummed. I mean, obviously no one's really happy when they get a ticket. But I went home, I put it on my fridge and I just let it sit there 'cause I just didn't want to deal with it. REZVANI: So he found something that would. He had heard about DoNotPay, a free online robot that helped drivers in London and New York City appeal parking tickets. It had just expanded into Seattle, and Lear decided to give it a go. He logged on, answered the bot's questions and within minutes, he had a 500-word letter to send to the city. Verdict? LEAR: Ultimately, yeah, they let me off. REZVANI: The mind behind DoNotPay belongs to Joshua Browder, a 20-year-old student at Stanford originally from London. JOSHUA BROWDER: This is automatic. REZVANI: It is automatic. BROWDER: OK, thank God. REZVANI: Newly licensed, he offered to take me to one city he wants to expand into next, San Francisco. Browder combs the streets, peeks at parking tickets, studies signs. BROWDER: Oh, there we go. I think there's one. REZVANI: It's field research he programs into what he calls the world's first robot lawyer. BROWDER: So there's two signs. The first one says that from 7 to 9 a. m. and 4 to 6 p. m. , you can't park. And that one is fine and clearly marked. But then there's a sign below it that says no parking up to 6 a. m. , but there's no start time. REZVANI: It's covered up. BROWDER: It's covered up, and it looks like it's actually been covered up by the local authority. REZVANI: Browder's bot has so far helped drivers overturn more than 200,000 parking tickets. This month, it will enter several more cities, including the capital of cars and traffic, Los Angeles, where right now about 40 percent of challenged citations are dismissed. Compare that to DoNotPay's success rate of 60 percent, and it's easy to see why drivers would flock to this service. But cities. . . WAYNE GARCIA: Currently we have four part-time field investigators to do the investigations for signs and curbs in the city of Los Angeles. REZVANI: Wayne Garcia is chief of parking operations for the city of Los Angeles. He says he's anxious to see what will soon come through the mail, given how even a modest uptick in appeals could overload resources. But he admits there could be an upside. GARCIA: Our staff spend a great deal of time reviewing letters from motorists and trying to decipher what they're actually contesting about. REZVANI: And that's because most people just don't write like lawyers. GARCIA: If this process will help the motorists really focus in on why they're contesting their parking citation, it would also help our staff in reviewing the contested parking citation. BROWDER: I want to level the playing field so that anyone can have the same legal access under the law. REZVANI: DoNotPay's creator Joshua Browder wants this kind of legal help to go beyond parking tickets. And in some cities, he's already done that with landlord-tenant disputes and unexplained banking charges. Right now he's working on the bot's ability to help refugees apply for asylum. BROWDER: If one day, like, someone can have the same standard of legal representation as the richest in society, then I think that's a really good aim. REZVANI: Which Browder says is part of an even larger ambition to one day make justice free. Arezou Rezvani, NPR News. KELLY MCEVERS, HOST:  You get a ticket even though you thought you parked in a legitimate spot. NPR's Arezou Rezvani reports that an online robot might be able to help. AREZOU REZVANI, BYLINE: It was the first day of school for Dan Lear's kids. In a scramble, this lawyer from Seattle parked where he could and got his three boys to class. DAN LEAR: There was a fire hydrant, but the curb wasn't painted and the fire hydrant was painted kind of a funny color. And so I thought - maybe it was wishful thinking - but I thought I would be OK to park there. REZVANI: Sure enough, Lear returned to a ticket. LEAR: I was bummed. I mean, obviously no one's really happy when they get a ticket. But I went home, I put it on my fridge and I just let it sit there 'cause I just didn't want to deal with it. REZVANI: So he found something that would. He had heard about DoNotPay, a free online robot that helped drivers in London and New York City appeal parking tickets. It had just expanded into Seattle, and Lear decided to give it a go. He logged on, answered the bot's questions and within minutes, he had a 500-word letter to send to the city. Verdict? LEAR: Ultimately, yeah, they let me off. REZVANI: The mind behind DoNotPay belongs to Joshua Browder, a 20-year-old student at Stanford originally from London. JOSHUA BROWDER: This is automatic. REZVANI: It is automatic. BROWDER: OK, thank God. REZVANI: Newly licensed, he offered to take me to one city he wants to expand into next, San Francisco. Browder combs the streets, peeks at parking tickets, studies signs. BROWDER: Oh, there we go. I think there's one. REZVANI: It's field research he programs into what he calls the world's first robot lawyer. BROWDER: So there's two signs. The first one says that from 7 to 9 a. m. and 4 to 6 p. m. , you can't park. And that one is fine and clearly marked. But then there's a sign below it that says no parking up to 6 a. m. , but there's no start time. REZVANI: It's covered up. BROWDER: It's covered up, and it looks like it's actually been covered up by the local authority. REZVANI: Browder's bot has so far helped drivers overturn more than 200,000 parking tickets. This month, it will enter several more cities, including the capital of cars and traffic, Los Angeles, where right now about 40 percent of challenged citations are dismissed. Compare that to DoNotPay's success rate of 60 percent, and it's easy to see why drivers would flock to this service. But cities. . . WAYNE GARCIA: Currently we have four part-time field investigators to do the investigations for signs and curbs in the city of Los Angeles. REZVANI: Wayne Garcia is chief of parking operations for the city of Los Angeles. He says he's anxious to see what will soon come through the mail, given how even a modest uptick in appeals could overload resources. But he admits there could be an upside. GARCIA: Our staff spend a great deal of time reviewing letters from motorists and trying to decipher what they're actually contesting about. REZVANI: And that's because most people just don't write like lawyers. GARCIA: If this process will help the motorists really focus in on why they're contesting their parking citation, it would also help our staff in reviewing the contested parking citation. BROWDER: I want to level the playing field so that anyone can have the same legal access under the law. REZVANI: DoNotPay's creator Joshua Browder wants this kind of legal help to go beyond parking tickets. And in some cities, he's already done that with landlord-tenant disputes and unexplained banking charges. Right now he's working on the bot's ability to help refugees apply for asylum. BROWDER: If one day, like, someone can have the same standard of legal representation as the richest in society, then I think that's a really good aim. REZVANI: Which Browder says is part of an even larger ambition to one day make justice free. Arezou Rezvani, NPR News.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-01-20-510847064": {"title": "Trump Administration Takes Over White House Website, Angers Opponents On Internet : NPR", "url": "https://www.npr.org/2017/01/20/510847064/digital-transition-of-power-is-not-so-peaceful", "author": "No author found", "published_date": "2017-01-20", "content": "", "section": "Politics", "disclaimer": ""}, "2017-01-20-510625135": {"title": "Tristram Wyatt: How Do Pheromones Really Work? : NPR", "url": "https://www.npr.org/2017/01/20/510625135/how-do-pheromones-really-work", "author": "No author found", "published_date": "2017-01-20", "content": "GUY RAZ, HOST: On the show today, we're exploring ideas about the five senses, and next step? Smell. See, so you know how some people get more mosquito bites than others? TRISTRAM WYATT: Oh, yes. RAZ: The reason is smell. WYATT: Because we give off different smells. RAZ: We give off different smells that mosquitoes are attracted to. WYATT: There is a group in the U. K. that's been wrapping people up in silver foil, collecting the smells and seeing if the smells attract mosquitoes. And what they found is that, yes, some people are much more attractive than others. RAZ: This, by the way, is professor Tristram Wyatt. WYATT: I'm based in the Zoology Department at the University of Oxford. RAZ: And professor Wyatt, he studies smells. WYATT: Indeed, and my interest is in animals right the way across the animal kingdom through to people. RAZ: And he says just like people smell different to different mosquitoes, lots of things smell different to different people. WYATT: Each of us does smell a different world because when we're smelling, say, strawberries, there are hundreds of different smell molecules that have been given off by the strawberries. And what our brain is very good at is interpreting the many nerves that are stimulated by those different smells and remembering, ah, that's strawberry. RAZ: And the amazing thing is that it's only in the last 30 years that scientists have really understood how smell works. Tristram Wyatt explains from the TED stage. (SOUNDBITE OF TED TALK)WYATT: Smell was the hardest of the senses to crack. And the Nobel Prize awarded to Richard Axel and Linda Buck was only awarded in 2004 for their discovery of how smell works. It's really hard, but in essence, nerves from the brain go up into the nose, and on these nerves exposed in the nose to the outside air are receptors. And odor molecules coming in on a sniff interact with these receptors, and if they bond, they send the nerve a signal which goes back into the brain. We don't just have one kind of receptor. If you're a human, you have about 400 different kinds of receptors. And the brain knows what you're smiling because of the combination of receptors and nerve cells that they trigger, sending messages up to the brain in a combinatorial fashion. But it's a bit more complicated because each of those 400 comes in various variants. And depending which variant you have, you might smell cilantro, that herb, either as something delicious or something like soap. So we each have an individual world of smell, and that complicates anything when we're studying smell. (SOUNDBITE OF MUSIC)RAZ: I mean, it's crazy to think that, like, some of us taste this delicious herb that I just used last night in my guacamole, and then some of us taste soap. WYATT: Yes. It turns out that about 20 percent of people have a different version of the smell receptor, it's just a simply a matter of genetics. RAZ: Wow. WYATT: Now, we're familiar with colorblindness, and that's just with three receptors, the red, green and blue. Well, imagine what's going on in the nose where you have 400 receptors, and quite a few of those come in different forms that might or might not work for a particular kind of smell. Which means that the solution is don't add cilantro to all of the guacamole you're producing. RAZ: (Laughter) Yeah. WYATT: And an enterprising cafe in California offers two versions. RAZ: OK, so that's how humans smell things, but what about what we smell like? You know, of course there's sweat, and the way a baby's head smells. But there's one human smell scientists have not been able to find. WYATT: Pheromones. RAZ: Pheromones, what most of us think of as the scent of attraction. And in just a minute, we'll hear about the scientific quest to find it. On the show today, we're exploring ideas about the five senses. I'm Guy Raz, and you're listening to the TED Radio Hour from NPR. RAZ: It's the TED Radio Hour from NPR. I'm Guy Raz. And on the show today, ideas about how our senses shape our perceptions of the world around us. And we were just hearing from Oxford zoologist Tristram Wyatt about smell. He's been studying one aspect of smell from the animal world that we know far less about when it comes to us, pheromones. Here's Tristram on the TED stage. (SOUNDBITE OF TED TALK)WYATT: Pheromone - it conjures up sex abandon, loss of control. And you can see it's a very powerful word. Now, if you put that word into the web, as you may have done, you'll come up with millions of hits. And almost all of those sites are trying to sell you something to make you irresistible for $10 or more. Now, this is a very attractive idea. And the molecules they mention sound really science-y. (ph). They've got lots of syllables. It's things like androstenol, androstenone, androstenedione. And when you combine that with white lab coats, you must imagine that there is fantastic science behind this. But sadly, these are fraudulent claims supported by dodgy science. So the ancient Greeks knew that dogs sent invisible signals between each other. A female dog in heat sent an invisible signal to male dogs for miles around. And it wasn't a sound. It was a smell. You could take the smell from the female dog, and the dogs would chase the cloth. And it was only in 1959 that a German team, after spending 20 years in search of these molecules, discovered - identified - the first pheromone. And this was the sex pheromone of a silk moth. Adolf Butenandt and his team created the model for how you should go about pheromone analysis. He basically went through systematically, showing that only the molecule in question was the one that stimulated the males, not all the others. He synthesized the molecule and then tried the synthesize molecule and the males and showed it was indeed that molecule. That's closing the circle. With that new concept, we needed a new word, and that was the word pheromone. And it's basically transferred excitement transferred between individuals. And since 1959, pheromones have been found right the way across the animal kingdom in male animals, in female animals. It works just as well underwater for goldfish and lobsters. And almost every mammal you can think of has had a pheromone identified. That's the thing which has never been done with humans. Nothing systematic - no real demonstration. RAZ: How is it that we have discovered pheromones in virtually - you know, across the animal kingdom. But we just can't figure it out in humans. What's the problem? WYATT: I think it's we've not looked seriously. And that is strange. But, generally speaking, if you look at things like NIH funding, there is much more going towards vision and hearing. And relatively small amounts of money go towards studying smell. And pheromones would come under that area of research. The other thing is that, generally, studying pheromones in mammals is much harder. And that's because mammals, including us, are incredibly smelly. And that means if you start looking at the smells, you become overwhelmed by the number of potential molecules. RAZ: Wow. WYATT: So if you look in somebody's armpit, I mean, after asking them first. . . RAZ: Yeah, of course. WYATT: . . . And count the different kinds of molecules, there are hundreds, if not thousands. And that complicates things because you don't know at the beginning which molecules to look at. RAZ: So what are scientists looking for, like, exactly when they're searching for pheromones? WYATT: So pheromones are chemical signals, something that has evolved for communication. So the way you find a pheromone is by looking for the molecules that stay the same in every male or every female, molecules that are consistent. And the rest - that's individual odors. Now, some may have more of that molecule than others. And so it's almost the success of the smelliest. RAZ: Are we - I mean, are we getting closer to finding them, to identifying human pheromones? WYATT: We actually do not know any sex pheromones. But at some point, we may well find them. But there is another pheromone that is actually really exciting. And it's all to do with mothers and babies. And it's some work that's coming out of France from Dijon. And they found something really neat. (SOUNDBITE OF TED TALK)WYATT: So this is a baby having a drink of milk from its mother's breast. But what you'll notice is a white droplet. And that's the secretion from the areola glands. Now, we all have them - men and women. And these are the little bumps around the nipple. And if you're a lactating woman, these start to secrete. It's a very interesting secretion. So this is a sleeping baby. And under its nose, we've put a clean glass rod. The baby remains sleeping, showing no interest at all. But if we go to any mother who is secreting from the areola glands, if we take the secretion and now put it under the baby's nose, we get a very different reaction. It opens its mouth and sticks out its tongue and starts to suck. Now, since this is from any mother, it could really be a pheromone. It's not about individual recognition. Any mother will do. Now, why is this important, apart from being simply very interesting? It's because if you're a mammal, the most dangerous time in life is the first few hours after birth. You have to get that first drink of milk. And if you don't get it, you won't survive. You'll be dead. Since many babies actually find it difficult to take that first meal because they're not getting the right stimulus, if we could identify the molecule, synthesize it, it would then mean premature babies would be more likely to suckle, and every baby would have a better chance of survival. This is one example of where a systematic, really scientific approach can actually bring you a real understanding of pheromones. There could be all sorts of medical interventions. There could be all sorts of things that humans are doing with pheromones that we simply don't know at the moment. So do go forward and do search for more. There's lots to find. Thank you very much. (APPLAUSE)RAZ: Tristram Wyatt - he's a senior researcher at Oxford, where he studies smell. You can see his entire talk at ted. com. GUY RAZ, HOST:  On the show today, we're exploring ideas about the five senses, and next step? Smell. See, so you know how some people get more mosquito bites than others? TRISTRAM WYATT: Oh, yes. RAZ: The reason is smell. WYATT: Because we give off different smells. RAZ: We give off different smells that mosquitoes are attracted to. WYATT: There is a group in the U. K. that's been wrapping people up in silver foil, collecting the smells and seeing if the smells attract mosquitoes. And what they found is that, yes, some people are much more attractive than others. RAZ: This, by the way, is professor Tristram Wyatt. WYATT: I'm based in the Zoology Department at the University of Oxford. RAZ: And professor Wyatt, he studies smells. WYATT: Indeed, and my interest is in animals right the way across the animal kingdom through to people. RAZ: And he says just like people smell different to different mosquitoes, lots of things smell different to different people. WYATT: Each of us does smell a different world because when we're smelling, say, strawberries, there are hundreds of different smell molecules that have been given off by the strawberries. And what our brain is very good at is interpreting the many nerves that are stimulated by those different smells and remembering, ah, that's strawberry. RAZ: And the amazing thing is that it's only in the last 30 years that scientists have really understood how smell works. Tristram Wyatt explains from the TED stage. (SOUNDBITE OF TED TALK) WYATT: Smell was the hardest of the senses to crack. And the Nobel Prize awarded to Richard Axel and Linda Buck was only awarded in 2004 for their discovery of how smell works. It's really hard, but in essence, nerves from the brain go up into the nose, and on these nerves exposed in the nose to the outside air are receptors. And odor molecules coming in on a sniff interact with these receptors, and if they bond, they send the nerve a signal which goes back into the brain. We don't just have one kind of receptor. If you're a human, you have about 400 different kinds of receptors. And the brain knows what you're smiling because of the combination of receptors and nerve cells that they trigger, sending messages up to the brain in a combinatorial fashion. But it's a bit more complicated because each of those 400 comes in various variants. And depending which variant you have, you might smell cilantro, that herb, either as something delicious or something like soap. So we each have an individual world of smell, and that complicates anything when we're studying smell. (SOUNDBITE OF MUSIC) RAZ: I mean, it's crazy to think that, like, some of us taste this delicious herb that I just used last night in my guacamole, and then some of us taste soap. WYATT: Yes. It turns out that about 20 percent of people have a different version of the smell receptor, it's just a simply a matter of genetics. RAZ: Wow. WYATT: Now, we're familiar with colorblindness, and that's just with three receptors, the red, green and blue. Well, imagine what's going on in the nose where you have 400 receptors, and quite a few of those come in different forms that might or might not work for a particular kind of smell. Which means that the solution is don't add cilantro to all of the guacamole you're producing. RAZ: (Laughter) Yeah. WYATT: And an enterprising cafe in California offers two versions. RAZ: OK, so that's how humans smell things, but what about what we smell like? You know, of course there's sweat, and the way a baby's head smells. But there's one human smell scientists have not been able to find. WYATT: Pheromones. RAZ: Pheromones, what most of us think of as the scent of attraction. And in just a minute, we'll hear about the scientific quest to find it. On the show today, we're exploring ideas about the five senses. I'm Guy Raz, and you're listening to the TED Radio Hour from NPR. RAZ: It's the TED Radio Hour from NPR. I'm Guy Raz. And on the show today, ideas about how our senses shape our perceptions of the world around us. And we were just hearing from Oxford zoologist Tristram Wyatt about smell. He's been studying one aspect of smell from the animal world that we know far less about when it comes to us, pheromones. Here's Tristram on the TED stage. (SOUNDBITE OF TED TALK) WYATT: Pheromone - it conjures up sex abandon, loss of control. And you can see it's a very powerful word. Now, if you put that word into the web, as you may have done, you'll come up with millions of hits. And almost all of those sites are trying to sell you something to make you irresistible for $10 or more. Now, this is a very attractive idea. And the molecules they mention sound really science-y. (ph). They've got lots of syllables. It's things like androstenol, androstenone, androstenedione. And when you combine that with white lab coats, you must imagine that there is fantastic science behind this. But sadly, these are fraudulent claims supported by dodgy science. So the ancient Greeks knew that dogs sent invisible signals between each other. A female dog in heat sent an invisible signal to male dogs for miles around. And it wasn't a sound. It was a smell. You could take the smell from the female dog, and the dogs would chase the cloth. And it was only in 1959 that a German team, after spending 20 years in search of these molecules, discovered - identified - the first pheromone. And this was the sex pheromone of a silk moth. Adolf Butenandt and his team created the model for how you should go about pheromone analysis. He basically went through systematically, showing that only the molecule in question was the one that stimulated the males, not all the others. He synthesized the molecule and then tried the synthesize molecule and the males and showed it was indeed that molecule. That's closing the circle. With that new concept, we needed a new word, and that was the word pheromone. And it's basically transferred excitement transferred between individuals. And since 1959, pheromones have been found right the way across the animal kingdom in male animals, in female animals. It works just as well underwater for goldfish and lobsters. And almost every mammal you can think of has had a pheromone identified. That's the thing which has never been done with humans. Nothing systematic - no real demonstration. RAZ: How is it that we have discovered pheromones in virtually - you know, across the animal kingdom. But we just can't figure it out in humans. What's the problem? WYATT: I think it's we've not looked seriously. And that is strange. But, generally speaking, if you look at things like NIH funding, there is much more going towards vision and hearing. And relatively small amounts of money go towards studying smell. And pheromones would come under that area of research. The other thing is that, generally, studying pheromones in mammals is much harder. And that's because mammals, including us, are incredibly smelly. And that means if you start looking at the smells, you become overwhelmed by the number of potential molecules. RAZ: Wow. WYATT: So if you look in somebody's armpit, I mean, after asking them first. . . RAZ: Yeah, of course. WYATT: . . . And count the different kinds of molecules, there are hundreds, if not thousands. And that complicates things because you don't know at the beginning which molecules to look at. RAZ: So what are scientists looking for, like, exactly when they're searching for pheromones? WYATT: So pheromones are chemical signals, something that has evolved for communication. So the way you find a pheromone is by looking for the molecules that stay the same in every male or every female, molecules that are consistent. And the rest - that's individual odors. Now, some may have more of that molecule than others. And so it's almost the success of the smelliest. RAZ: Are we - I mean, are we getting closer to finding them, to identifying human pheromones? WYATT: We actually do not know any sex pheromones. But at some point, we may well find them. But there is another pheromone that is actually really exciting. And it's all to do with mothers and babies. And it's some work that's coming out of France from Dijon. And they found something really neat. (SOUNDBITE OF TED TALK) WYATT: So this is a baby having a drink of milk from its mother's breast. But what you'll notice is a white droplet. And that's the secretion from the areola glands. Now, we all have them - men and women. And these are the little bumps around the nipple. And if you're a lactating woman, these start to secrete. It's a very interesting secretion. So this is a sleeping baby. And under its nose, we've put a clean glass rod. The baby remains sleeping, showing no interest at all. But if we go to any mother who is secreting from the areola glands, if we take the secretion and now put it under the baby's nose, we get a very different reaction. It opens its mouth and sticks out its tongue and starts to suck. Now, since this is from any mother, it could really be a pheromone. It's not about individual recognition. Any mother will do. Now, why is this important, apart from being simply very interesting? It's because if you're a mammal, the most dangerous time in life is the first few hours after birth. You have to get that first drink of milk. And if you don't get it, you won't survive. You'll be dead. Since many babies actually find it difficult to take that first meal because they're not getting the right stimulus, if we could identify the molecule, synthesize it, it would then mean premature babies would be more likely to suckle, and every baby would have a better chance of survival. This is one example of where a systematic, really scientific approach can actually bring you a real understanding of pheromones. There could be all sorts of medical interventions. There could be all sorts of things that humans are doing with pheromones that we simply don't know at the moment. So do go forward and do search for more. There's lots to find. Thank you very much. (APPLAUSE) RAZ: Tristram Wyatt - he's a senior researcher at Oxford, where he studies smell. You can see his entire talk at ted. com.", "section": "TED Radio Hour", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-01-24-510811662": {"title": "How To Make Broadcast Towers More Bird-Friendly: Turn Off Some Lights : NPR", "url": "https://www.npr.org/2017/01/24/510811662/how-to-make-broadcast-towers-more-bird-friendly-turn-off-some-lights", "author": "No author found", "published_date": "2017-01-24", "content": "STEVE INSKEEP, HOST: There are more than 100,000 broadcast and cell towers across this country. You use them every time you make a cellphone call or turn on the radio in your car. They're a problem, though, for migrating birds. Every year, millions of birds slam into those towers at night. Ben Thorp of our member station WCMU reports on a simple way to prevent that. BEN THORP, BYLINE: Likely the only time you really notice one of your neighborhood towers is at night when they're lit up with conspicuous bright red lights. Those lights help airplane pilots see the huge metal structures that can reach a thousand feet into the air, but can spell disaster for birds. CALEB PUTNAM: For example, in 1976 in Gun Lake, Mich. , one tower in one night killed over 2,300 birds. THORP: That's Caleb Putnam. He works for the Michigan Department of Natural Resources, and says for reasons scientists still can't quite figure out, birds kept flying headlong into towers. PUTNAM: If that many are dying at one night at one tower, and yet there are thousands of towers across the country and as you go across the world, the numbers are staggering. THORP: Putnam says in North America alone, it's estimated that 7 million birds smash into towers every year, but until recently scientists didn't know why it was happening. Figuring that out became biologist Joelle Gehring\u2019s mission. She helped conduct a study in 2003 to find out what could be done. (SOUNDBITE OF MUDDY FOOTSTEPS)JOELLE GEHRING: I can't not look at the ground when I'm underneath these towers (laughter). THORP: It's an unusually warm January morning, and the farm fields surrounding this tower are oozing mud. Gehring is standing at a broadcast tower in rural northeast Michigan that belongs to the local radio station. Gehring says every morning in the spring or fall, the peak migration season, she and others had the unpleasant job of counting dead birds at the base of these towers. What she discovered was surprising. GEHRING: So we were able to reduce the numbers of bird fatalities on communications towers by simply extinguishing those non-flashing lights, and those fatalities were reduced by as much as 70 percent. THORP: You heard that right - simply turning off the steady beam lights on towers reduce bird fatalities by 70 percent. Exactly why isn't yet clear, but she has a theory. GEHRING: Some research has documented that when birds are exposed to long wavelengths of light such as red or white, that it actually interferes with their ability to use magnetic fields for navigation. THORP: Joelle Gehring says that's especially true on cloudy nights when birds can't navigate by the stars. The tower's steady red lights seem to confuse them, flashing red lights don't. In 2015, the Federal Aviation Administration changed regulations on new towers, requiring they all be built with only flashing lights. Gehring, who now works for the Federal Communications Commission, spends much of her time contacting people who run towers built before 2015, encouraging them to switch to blinking lights. GEHRING: And when we drive back and forth around those beautiful Great Lakes at night, we see more and more communications towers that are lit with only flashing lights at night. And my son always points out - another bird-friendly tower, mom (laughter). THORP: There are still tens of thousands of towers, though, that aren't bird-friendly, as birds are drawn to the solid red lights. Gehring and others will continue to try to save those birds by doing one simple thing - changing those tower lights. For NPR News, I'm Ben Thorp. STEVE INSKEEP, HOST:  There are more than 100,000 broadcast and cell towers across this country. You use them every time you make a cellphone call or turn on the radio in your car. They're a problem, though, for migrating birds. Every year, millions of birds slam into those towers at night. Ben Thorp of our member station WCMU reports on a simple way to prevent that. BEN THORP, BYLINE: Likely the only time you really notice one of your neighborhood towers is at night when they're lit up with conspicuous bright red lights. Those lights help airplane pilots see the huge metal structures that can reach a thousand feet into the air, but can spell disaster for birds. CALEB PUTNAM: For example, in 1976 in Gun Lake, Mich. , one tower in one night killed over 2,300 birds. THORP: That's Caleb Putnam. He works for the Michigan Department of Natural Resources, and says for reasons scientists still can't quite figure out, birds kept flying headlong into towers. PUTNAM: If that many are dying at one night at one tower, and yet there are thousands of towers across the country and as you go across the world, the numbers are staggering. THORP: Putnam says in North America alone, it's estimated that 7 million birds smash into towers every year, but until recently scientists didn't know why it was happening. Figuring that out became biologist Joelle Gehring\u2019s mission. She helped conduct a study in 2003 to find out what could be done. (SOUNDBITE OF MUDDY FOOTSTEPS) JOELLE GEHRING: I can't not look at the ground when I'm underneath these towers (laughter). THORP: It's an unusually warm January morning, and the farm fields surrounding this tower are oozing mud. Gehring is standing at a broadcast tower in rural northeast Michigan that belongs to the local radio station. Gehring says every morning in the spring or fall, the peak migration season, she and others had the unpleasant job of counting dead birds at the base of these towers. What she discovered was surprising. GEHRING: So we were able to reduce the numbers of bird fatalities on communications towers by simply extinguishing those non-flashing lights, and those fatalities were reduced by as much as 70 percent. THORP: You heard that right - simply turning off the steady beam lights on towers reduce bird fatalities by 70 percent. Exactly why isn't yet clear, but she has a theory. GEHRING: Some research has documented that when birds are exposed to long wavelengths of light such as red or white, that it actually interferes with their ability to use magnetic fields for navigation. THORP: Joelle Gehring says that's especially true on cloudy nights when birds can't navigate by the stars. The tower's steady red lights seem to confuse them, flashing red lights don't. In 2015, the Federal Aviation Administration changed regulations on new towers, requiring they all be built with only flashing lights. Gehring, who now works for the Federal Communications Commission, spends much of her time contacting people who run towers built before 2015, encouraging them to switch to blinking lights. GEHRING: And when we drive back and forth around those beautiful Great Lakes at night, we see more and more communications towers that are lit with only flashing lights at night. And my son always points out - another bird-friendly tower, mom (laughter). THORP: There are still tens of thousands of towers, though, that aren't bird-friendly, as birds are drawn to the solid red lights. Gehring and others will continue to try to save those birds by doing one simple thing - changing those tower lights. For NPR News, I'm Ben Thorp.", "section": "National", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-01-25-511507434": {"title": "Why Some Silicon Valley Tech Executives Are Bunkering Down For Doomsday : NPR", "url": "https://www.npr.org/2017/01/25/511507434/why-some-silicon-valley-tech-executives-are-bunkering-down-for-doomsday", "author": "No author found", "published_date": "2017-01-25", "content": "TERRY GROSS, HOST: This is FRESH AIR. I'm Terry Gross. Fears about politics, the economy, the environment, water shortages, the weather, dirty bombs, all-out nuclear war and the final apocalypse and end of days have led some individuals and groups known as survivalists to prepare for ways to defend themselves. Survivalists are often considered pretty fringy, but now it's become a thing for some of the super-rich. My guest, Evan Osnos, has written a new article in The New Yorker called \"Survival Of The Richest,\" about Silicon Valley executives, venture capitalists and hedge fund managers who are stockpiling food, water and ammunition and creating luxury escape havens. Osnos is a staff writer for The New Yorker and previously joined us to discuss his articles about white nationalists' support for the Trump campaign and executive orders President Trump could sign undoing existing agreements on climate change, immigration and foreign policy. We'll get some of Osnos' current reflections on the president a little later. Evan Osnos, welcome back to FRESH AIR. How did you find out about these superwealthy survivalists? How did you know this had become a thing? EVAN OSNOS: Well, I came upon it sort of by chance. Actually, I was sitting on an airplane and the person in the seat next to me just coincidentally was the CEO of a technology company in Silicon Valley. And this was a couple of years ago. And we got to talking. And I said, is there a story in Silicon Valley that people aren't writing about that you think is interesting? And he said, you should take a look at survivalism. And I didn't know exactly what he meant. And he said, you should look at survivalists in Silicon Valley. And he said, you won't find much about it publicly, but you may find something there. And, you know, I thought it was a kind of an oddball subject, but it also stayed with me because it seemed interesting. The idea that this place where people talk so much about the future and talk about the idea of changing the world that there might be this other form of thinking and discussion in private about survival was interesting. So I decided to start a project and began to start talking to people about it. GROSS: So what are Silicon Valley executives and former executives especially worried about regarding, you know, doomsday scenarios, the kind of thing that they have to prepare for by stocking up and building secret hideaways? OSNOS: So some of the things that they talk about are the kind of stuff of ordinary disaster movies, the idea - but, you know, there is some real element to it. The idea, for instance, that there could be a pandemic if the Ebola virus, for instance, had affected a much larger part of the population or an earthquake on the San Andreas in San Francisco - that's not a completely unreasonable fear - or the possibility of some sort of civil unrest. They take what they've seen in some American cities and extrapolate onto a larger scale and they say, well, what would happen? But they pay less attention to what the initial event might be than what the aftermath would be, which is to say as one person put it in this story, I worry about the temporary collapse of our government and its systems. What he means is that they feel a sense of fragility in our politics. Our politics have become disorderly, they've become hard to predict. And they look at it and they think, well, we're not entirely sure that our institutions are as sound as we've always assumed they are. And then there's another piece of it which is specific to technology. And that is a fairly prevalent fear in this community, which is that the growth and the development of artificial intelligence, which has become such a big subject of discussion, the idea that you will soon have a car that has no driver and eventually your goods will be delivered to a store by a truck that has no driver, that this kind of fundamental change in the American labor force will continue to produce tensions particularly between people who are losing their jobs and people who are responsible for the technology that is bringing about that change. And so there is a quiet and constant conversation in Silicon Valley today about the idea that some of this extraordinary technology that's been created, like artificial intelligence, might, in fact, produce extraordinary social tension that they haven't yet figured out how to absorb. GROSS: So you're talking about a kind of literal class warfare. OSNOS: Yeah, that's the way that they talk about it. I mean, Max Levchin, who was a co-founder of PayPal, is the CEO of a firm, a lending startup who is opposed, actually, to this trend of survivalist thinking but is surrounded by it. He said, you know, what people worry about is, to use Max's word, the pitchforks. And by that, he means the idea that the sort of tension that we saw with the Occupy movement a few years ago would take on a wider, more virulent form. GROSS: But it seems from your article that especially the Silicon Valley superwealthy know so much about the vulnerabilities within the electric grid and within the internet as a whole that they're worried that those systems can be hacked, that there's flaws, that the internet can kind of be disrupted, the electric grid can be disrupted, the whole society can collapse as a result. How much is that the motivation for this new superwealthy survivalism? OSNOS: Well, that's a big piece of it. If you're somebody who works in technology, then you got into that business in part because you tend to think about how systems fit together. And as one CEO of a multi-billion dollar technology company put it to me, he said, look, the truth is that our lives today are dependent on systems that are integrated, interdependent in ways that they simply weren't even 20 or 30 years ago. To give you an example, he said, the food that's on the shelves in our grocery stores depends on a supply chain that depends on GPS. And GPS, the Global Positioning System, depends to some degree on the internet. And the internet depends to some degree on another system known as DNS. And each one of these is vulnerable in its own ways. And so what he said, and this is - you know, he's a highly rational person who lives his life in very sophisticated ways in his business all the time, and he said, look, I'm not rushing out and, you know, declaring that the end of the world is near. But what I am saying is that it is, in his view, logically rational to talk about the fragility of these digital and electrical systems, which are really sort of second nature and largely on unexamined as we go about our daily lives. GROSS: So are these new superwealthy survivalists kind of equally divided between liberals and conservatives between the right and the left? Those people who have, like, political fears and fear that there's going to be a political breakdown, that's going to lead to a rift in the social fabric of society. OSNOS: One of the surprises to me was that this was not something that was occupying one political wing or another. It seems to actually draw from both sides. Traditionally, most survivalists would describe themselves as libertarians somewhere out typically on the conservative end of the spectrum. They put a high premium on self-reliance, on sort of distance from government. But there is a new element here, which is partly reflected in the success in the candidacy of Donald Trump. And that's the idea that there are, certainly in the case of Donald Trump, somebody who defies all of the conventional expectations and descriptions of politics, the sorts of experience required, the kind of standard to which he would be held for accuracy in what he says, all of the things that we used to assume would be absolutely fundamental about politics, those no longer obtain at the moment. And so to give you a literal example, Justin Kan, who is a technology entrepreneur in Silicon Valley who co-founded a company called Twitch, which was later sold to Amazon for a billion dollars, he told me that after the election of Donald Trump, he got a call from a friend at a hedge fund who said to him, you know, if Donald Trump turns out to be, in Justin's words, a fascist dictator, well, the expected value of having an escape hatch, meaning having a home overseas, will be very high. So while it used to be a phenomenon that was principally associated, I think, on the far-right end of the political spectrum, now you have people on the left who feel deeply uneasy about the direction that politics have taken. GROSS: So let's talk about some of the measures some of the superwealthy are taking to prepare for the doomsday scenarios that they fear. Tell us about one of the Silicon Valley executives that you spoke to. OSNOS: Sure. I'll tell you about somebody named Steve Huffman who is the CEO and a co-founder of Reddit, which is a very popular discussion site. It's valued at about $600 million. Steve graduated from the University of Virginia. He and his roommate ended up founding Reddit, which went on to become this very popular destination, one of the most popular sites on the internet. And Steve is concerned about what he describes as the sort of temporary loss of our government and institutions to the point that he got eye surgery so that he's no longer near-sighted because he believes that if you have contacts or glasses in the event of some sort of crackup of civilization, then that will make you likely to be a victim. GROSS: Because you'll lose your glasses and your contact lenses, so you'd better be able to just see. OSNOS: Right. His - the theory is that if you're overly dependent on something like contact lenses, which - let's say they're no longer being delivered to the store anymore, then that reduces your chances of survival. And he said - you know, he added, I also have a lot of food. He has a couple of motorcycles so that he could get out of town in a hurry. He has guns, and he has ammunition. So he said, I think I could probably sort of hole up and protect myself for a while. GROSS: Let me ask you about another superwealthy Silicon Valley exec. And this is Antonio Garcia Martinez - what is he doing to prepare for the doomsday scenario he's envisioning? OSNOS: Antonio Garcia Martinez, who worked at Facebook, later was an adviser to Twitter - in the midst of the presidential campaign, when it was getting really toxic between supporters of Donald Trump and Hillary Clinton, he decided to buy five acres on an island in the Pacific Northwest. And he brought in generators and solar panels and, as he put it, thousands of rounds of ammunition because, as he says, when a society loses its founding myth - you know, the thing that holds it together - well, then it can descend into chaos. And that's his. . . GROSS: What's the founding myth he was referring to? Do you know? OSNOS: Well, one of the things - yeah. What he was referring to is something that you hear across these conversations, and that's the idea that we are ultimately held together by a kind of commitment to the United States as a functioning entity. It's a sort of consensus, a belief that our politics are possible, that it's worth participating, that it's - you know, that our institutions are sound, that the president, for instance, will will abide by the Constitution, that the courts will have the say over the things which the Constitution allows them to govern. So what they feel - the survivalists in Silicon Valley and in finance circles in New York who are expressing this view - is that they are worried that there's been this kind of creeping disrespect for fairly basic institutions in American life, the things that people used to believe were sources of authority. So for instance, today, you know, there is fake news, which is completely, you know, sort of obviously false and made up, intended to deceive people. But that term has already been misappropriated by people who are using it, including - it's worth saying - clearly including the president the United States, to describe things that he doesn't agree with. And the idea and the concern is that if we're entering into a period in which some of the most traditional sources of authority in American life, including the intelligence community and a free press, are no longer considered sacred and trustworthy, well, then we're entering a really uncertain period in which it becomes hard to know, for instance, whether there will be, you know, talk about fake evidence or whether contracts will be honored. And so people whose livelihoods depend so much on the sanctity of these kinds of basic institutions are worried, and they're, in their words, hedging. GROSS: Yes, but - the people who we're talking about, the superwealthy - they have enough money that they could really help support social institutions. They could help support any social change that they believe in. They could help support institutions whose funding is in jeopardy. They can do a lot to help bolster the society that they fear is going to crack up and fall apart. OSNOS: Yeah, that is very much the argument among those who are opposed to this phenomenon. In Silicon Valley, for instance, Max Levchin, who is a prominent investor and entrepreneur says that this is - this idea, this kind of survivalist thinking is, as he puts it, one of the things that bothers him most about life in Silicon Valley today. He says, I often ask people, when they say to me what they're going to do in the, quote, unquote, \"apocalypse,\" I say, well, how much have you donated to your local homeless shelter? How much have you actually really tried to address the underlying sources of social tension that are the cause of this anxiety? Because, as he puts it - look, we're at a relatively benign point in the economy right now and the concern would be, instead of talking about what you're going to do if, you know, some faintly sci-fi scenario emerges, why don't you talk about what you could do right now to actually invest in the American project to try to strengthen these institutions and to help people in need? GROSS: If you're just joining us, my guest is Evan Osnos, a staff writer for The New Yorker. And we've been talking about his new piece in The New Yorker, which is called \"Survival Of The Richest. \" And it's about how some of the wealthiest people in America, in Silicon Valley and the finance industry, are getting ready for doomsday scenarios and stocking up on, like, food and arms and are building homes in hidden enclaves. We'll be right back. This is FRESH AIR. (SOUNDBITE OF MATT ULERY'S \"GAVE PROOF\")GROSS: This is FRESH AIR. And if you're just joining us, my guest is Evan Osnos, a staff writer for The New Yorker. His new piece is called \"Survival Of The Richest. \" It's about how some of the wealthiest people in America, including in the Silicon Valley and the finance industry, have become basically survivalists, stocking up on food and ammunition, weapons and also building, like, enclaves that they can retreat to in case society falls apart. One of the most interesting enclaves that you write about in case society falls apart is this, like, superluxury condo that's actually in a former nuclear missile silo. Would you describe this? OSNOS: Yeah. This is called the Survival Condo Project. And it is a couple of hours north of Wichita, Kan. , in an old missile silo complex that was built in 1961, at the height of the Cold War. And the missile silo was decommissioned in 1965, as a lot of them were around the country. And there was sort of no obvious use for them until a few years ago. It was developed by somebody named Larry Hall, who was a developer and a survivalist himself. And what he realized was that there was a certain kind of buyer out there, a potential buyer who would be willing to spend, in this case, about $3 million for an apartment underground or a million and a half dollars for half an apartment. And so he bought this silo and invested about $20 million into turning it into, essentially, a kind of luxury condo that's underground. And it can support 75 people on the food and the fuel that it has. And then it can, he said, operate indefinitely because you'll have hydroponic vegetables, and it will grow its own fish in farms and also be able to generate power with renewable energy because it's got wind turbines and also uses geothermal energy. GROSS: So I was going to ask you if all of this is a big secret. But there's a website (laughter) for this Survival Condo Project. On the website, it says, this is the safety you need with a kind of comfort you'd come to expect from a luxury condo. And I thought, wow (laughter), that's - what a sales pitch. I mean, it's - I never expected there to be a website for this describing all the advantages of buying a condo in this former nuclear missile silo. OSNOS: Yeah, I kind of scratched my head when I first heard about this. And I wasn't sure if it was real, so I went out to go see it - to go spend a night in this and sort of get a feel for it. And sure enough, it does exist. And Larry Hall has sold every unit in it except one for himself, he says. And it is true that if you go down and you go to these apartments, they look more or less like apartments that you would find at any sort of high-end apartment building. They just happen to be underground. And they don't have windows, and so what they've done is install video screens as windows so that you don't get claustrophobic. And the video screens show a scene that is a live feed of the sky and the surface above, or you can have it play whatever you want. At one point, they had a prospective customer who wanted to see the view from her window in New York City. And so the idea was to take footage of Central Park that she could see out her window and then have it projected from these kind of video windows underground. GROSS: It's a screensaver basically. (LAUGHTER)OSNOS: It's essentially a screensaver - an apocalyptic screensaver. GROSS: Exactly (laughter). So how did it feel to spend the night there? OSNOS: I mean, perhaps surprisingly, it was not as odd as you might expect. Once you're in there, you kind of forget at certain moments that you're underground. He relied on some of the interior decorating tricks that they use for cruise ships so that you can use a compact space very efficiently. There were a lot of lights, for instance, to keep it very bright so that it didn't feel gloomy. And, you know - and it has a library. And it has a movie theater, and it has a classroom and so on. But you know, you have to kind of remind yourself every once in a while that the only reason why a person would be in this facility is that something really dreadful has happened to the world above. And so you sort of remember every few minutes - well, let's hope that nobody is ever, ever required to be inside this thing. GROSS: So I don't know much about flying, but it seems to me, you know, if something's happened to, like, the internet system and GPSs aren't operating, which is one of the fears in the Silicon Valley, how are you going to be able to navigate your private plane to get to this place? OSNOS: Well, one of the scenarios that is, I think, pretty common - that I heard about over and over again from, sort of, ultra-wealthy survivalists is that they think that this doesn't generally happen overnight. You know, that sure, there are scenarios like an internet blackout, some sort of major technical collapse. But the real risk, the thing that they worry about is more fundamental. And that's basically the erosion of social stability. They really do feel - on some level, they sense that there is - because of income inequality and the unaddressed feeling of haves and have-nots in this country, that there really is a source of tension that were something to happen, it wouldn't happen overnight. And it would happen gradually. And it would become - you know, there would come a point at which they would no longer feel safe being in the cities and being in the homes where they live. And that's the point at which they would go into these compounds, either in the U. S. or they would fly abroad. GROSS: My guest is Evan Osnos. His new article about superwealthy Silicon Valley survivalists is called \"Survival Of The Richest. \" He's a staff writer for The New Yorker. After a break, we'll talk more about survivalists, and we'll talk about fake news in America, including fake facts coming from the Trump administration. And we'll discuss the direction the president is heading in with China and why it could lead to a shooting war. Osnos reported from China for eight years. I'm Terry Gross, and this is FRESH AIR. (SOUNDBITE OF ZUBATTO SYNDICATE'S \"SATURN 9\")GROSS: This is FRESH AIR. I'm Terry Gross, back with Evan Osnos, a staff writer for The New Yorker. His new article, \"Survival Of The Richest,\" is about super-rich Silicon Valley executives, venture capitalists and hedge fund managers who have become survivalists. They're preparing for doomsday scenarios, including dirty bombs, environmental disasters, the hacking of our digital infrastructure, political extremism and the social collapse of America. They're stockpiling food and weapons or hiring security, and they're creating luxury escape havens. One of the things you write about that has led a lot of people to seriously worry about the total social collapse of America and then that there'll be no one to help us was Hurricane Katrina, which you say people have told you have totally, like, decreased their faith in government's ability to handle catastrophe. And FEMA, which stands for the Federal Emergency Management Agency, is sometimes referred to now as FEMA, foolishly expecting meaningful aid (laughter). So a vote of no confidence in the government. OSNOS: Right, yeah, this is an element of survivalist thinking that has both early roots and then a contemporary phenomenon. The early roots of this is that, you know, when did survivalism begin? It basically began in the 1970s during the oil shock, during this fear of inflation that there were writers out there who figured out that there was a market for this kind of idea. And they managed to sell some bestsellers that were called things like \"How To Prosper During The Bad Times. \"And, you know, what they did is they celebrated frontier thinking and these kinds of, you know, forgotten arts of how to make your own house or grow your own food. And then that sort of took on a new life, a larger life during Ronald Reagan's presidency because what Ronald Reagan said, as Richard Mitchell, who's a great sociologist of the survivalist phenomenon, described to me, Ronald Reagan was the first president who said to people actively, your government is the problem. Your government is not here to solve your problems. Your government is your problem. And as Mitchell documented over the course of a number of years, this contributed to a new kind of energy for their survivalist movement what reached beyond the old - the sort of smallest community and began to grow into a larger phenomenon. And then you had a new incarnation in the last few years, which was expressed to me by several people who've adopted this survivalist lifestyle is that watching how the George W. Bush administration mishandled the response to Hurricane Katrina told them that a government today, even if it knows everything, it has full awareness that there's a hurricane bearing down on an American city, that it was incapable of protecting its citizens. Well, they took that experience and they turned that into a general theory. And the general theory was the government is no longer able to protect me, therefore I need to protect myself. GROSS: So, you know, when the web started and even when, like, the internet started in terms of being accessible to regular people and not just people in government, it seemed to be or at least have the potential of becoming a utopian community where things are free and accessible and people, like, chat online and form affinity groups and it's just, like, you know, a lovely, wonderful utopian idea. Stewart Brand, who created the Whole Earth Catalog, co-founded something called The WELL, which was one of the first, like, online communities. And it was amazing. And now there's this, like, totally dark (laughter) underside to the internet. You've got Silicon Valley executives preparing for, you know, the social apocalypse. So what happened to that utopian vision? Like, the last people to have it now seem to be some of the people in Silicon Valley. OSNOS: Yeah, it's - that is the most interesting question at the center of this. I mean, in some ways, Stewart Brand, who was this sage of Silicon Valley, really - I mean, he was one of Steve Jobs' great heroes. And the reason he was an icon was that he published a magazine called the Whole Earth Catalog, which was this kind of combination of techie thinking and hippie thinking. And his motto was we are as gods and we better get good at it. What did he mean? He meant that the tools that we've created for ourselves, both as technologists and also the literal tools on the farm, these are powerful things. And they can make tremendous difference in our lives, but it's not altogether clear if it's going to be good or bad. And what we've discovered, I think, over the last several years and certainly over the course of the last several months where we've discovered that the internet became a kind of high-speed conveyor belt, in some cases, for absolutely fraudulent information, which, you know, what's now known as fake news zipped around the country in ways that it never could have a generation ago. And people believed it. We now know that. The survey data's quite clear. And as a result, they believed things about political candidates that were not true. I had a fascinating conversation with Stewart Brand for this story about survivalism in Silicon Valley. And I called him up and I said, what do you make of this? He's been in that community for 40 years. And I said, what do you make of this? And he said, you know, I dabbled in survivalism, he said, in the '70s. He tried it for a little while. But he decided it was kind of strange, the idea that walking around believing that the world was about to end. And what he said is that over the years, he's become much more impressed by examples of resilience rather than examples of frailty. For example, in the last 10 years, the United States has weathered a recession, the largest recession since the Great Depression. It now has unemployment at low, manageable levels. There was an Ebola crisis, which was predicted to be much worse in the end than it ultimately was. It was certainly costly, but it was nowhere near what it could have been. And that was because people took it upon themselves to do something about it. And then another example would be Japan that suffered this tsunami and a cascade of nuclear meltdowns. And from that, yet, it has soldiered on. And so what Stewart Brand said is that the hardest problem that we face today is not the idea that the world is about to end, this idea which we circulate among ourselves, let's say, online in these communities. But it actually is the much more mundane but more likely scenario, which is that we chug on, that we continue and we are faced with these practical problems, social problems about how do we help the neediest members of our society and how do we make sure that people are taken care of who need it? GROSS: My guest is Evan Osnos, a staff writer for The New Yorker. His new article is called \"Survival Of The Richest. \" We'll talk more after a break. This is FRESH AIR. (SOUNDBITE OF DAN AUERBACH SONG, \"HIDDEN, IN DISREPAIR\")GROSS: This is FRESH AIR. My guest is Evan Osnos, a staff writer for The New Yorker. His new article, \"Survival Of The Richest,\" is about superwealthy Silicon Valley executives who've become survivalists. Osnos has also written about candidate and now President Donald Trump. After Trump announced his candidacy, Osnos wrote about why he was championed by white nationalists and far-right groups who rebranded as the alt-right. So Steve Bannon, who is President Trump's chief strategist and the former head of Breitbart News, just hired Julia Hahn as his aide. And she was a Breitbart staff writer. She wrote an article about Paul Ryan last October, October 21, 2016, that was headlined, \"He's With Her: Inside Paul Ryan's Months-Long Campaign To Elect Hillary Clinton President. \" I really don't think Paul Ryan wanted to elect. . . OSNOS: (Laughter). GROSS: . . . Hillary Clinton president. I really doubt that he had a campaign to elect her. And, you know, he's, you know, the leader of the Republican Party in many ways. OSNOS: Right. GROSS: I mean - so, like, of course, I'm really wondering what is going through his mind. I can't ask you to tell me that (laughter). OSNOS: Right. GROSS: But I can't help but wonder, like, why would he not say something about this? Why would he not object to this? OSNOS: Do you mean Paul Ryan, or do you mean. . . GROSS: Paul Ryan. OSNOS: . . . Donald Trump? Paul Ryan's initial reaction to the appointment of Julia Hahn was basically - he adopted the posture that it doesn't matter. And his office put out a statement saying, we don't care about this in the slightest. The reality is, of course, that they do care. She has been out here in this relatively small media organization - but an influential one in Paul Ryan's world, has been his most fierce critic and has been sort of promoting a version of events that would qualify as a kind of odd-ball thinking. And it's certainly not conventional political analysis. Nobody else was saying that Paul Ryan was trying to promote Hillary Clinton's candidacy for president. So the question, I think, becomes - well, why is this entering the White House? What is Donald Trump actually doing by bringing this into the White House? And the answer is that, in some ways, he is now caught between these two impulses and these two necessities. On one side, Donald Trump was elected by this populist, nationalist phenomenon that was articulated by Breitbart Media. It sort of took the form of Steve Bannon as a person and as an adviser. But at the same time, there's this other side, which is the very practical side of being, now, the head of the Republican Party in America and also the president of the United States. And Donald Trump is faced, in a sense, with a difficult problem, which is that in his inauguration, you remember he said that the time for empty talk is over and the hour of action has arrived. What he meant was politics. But actually, it could be used to describe his own predicament because Donald Trump has campaigned, in a sense, brilliantly. I mean, whether we like him or not, he succeeded in becoming the president of the United States. But now all of the things which he said, which in many cases - and it's not an exaggeration to say many cases - were not based on fact, were not based on reliable statistics, were not based on reasonable expectations of policy prescriptions. He now faces the problem of - how do you actually achieve these? And if he can't achieve them, then he's going to have to rely on that other pillar of his support. So he's not going to be able to rely on competence and achievement and success. Well, if that won't work, he's going to have to rely on this populist, nationalist surge of sentimental energy which got him into the White House in the first place. GROSS: Are you concerned that with Steve Bannon as President Trump's strategist and with Steve Bannon's aide as a former writer for Breitbart News, that they're going to be encouraging fake news, which is something Breitbart News is famous for? OSNOS: Absolutely. I think, you know, this is the kind of concern that it's easy for journalists to talk about but, in fact, is of immense importance to people in finance, in medicine, you know, if you are a schoolteacher. And all of these worlds that I just described, which depend fundamentally on the sanctity and the precision of numbers, you know, on whether or not we are being honest with ourselves about the country we inhabit - for the presidential spokesman, Sean Spicer, to get up as he did on the very first day after the inauguration and to provide false information, to falsely claim that the inauguration was larger than any crowd in history for an inauguration or to say that the ridership on the local subways, for instance, was higher that day than the ridership for Barack Obama's inauguration, those were numbers which were just patently false and easy to verify that they were false. And for him to do that represents such a break with political culture that it really becomes hard to know how a White House that is willing to adopt and promote ideas, which even a sort of rudimentary check would know to be false - how it is that they are going to govern successfully because you can only rely on faulty information for so long before it begins to produce, basically, failure. GROSS: So what is your position - as a journalist and just as a citizen, you're very skeptical that Donald Trump will be able to fulfill his promises. You're very concerned about fake news that has come and might continue to come from the Trump administration. You're concerned about Trump's relationship with white nationalists. He is the president of the United States, and he was elected. So what kind of dissonance, if any, are you facing between respecting that he is the president of the United States and fearing some of his ambitions and methods and alliances? OSNOS: In some ways, you know, I have so much respect for the institution, for the presidency, that it is, as a journalist, energizing right now to say this is an amazing thing we created in the country. You know, the U. S. presidency is a powerful office and an honorable office and a dignified office. And it's one that has been conducted brilliantly over the course of our history. But it is also one that is - ultimately, it works for us, you know. It is subject to public approval and support. And one of the things that you saw on the day after Donald Trump's inauguration was that people voiced their sort of most elementary commitment as citizens to stand up and say, I care. I care enough to march. I care enough to come out and express myself. And you saw it in vast numbers. And I think - strangely enough, you know, this is a time when journalism, obviously, is much maligned at the moment. People say that they don't trust much of what they read in the media and they really don't have much respect for journalism. And yet, at the same time, journalism has been, historically, one of the ways that presidents have been brought to account. Were it not for journalism, Richard Nixon and the break-in at the Watergate would never have been discovered. So I think - you know, I can't speak for my colleagues more broadly, but I do find that among people in Washington who write about politics and think about it, we feel like this is exactly the kind of work that we were trained to do. This is exactly the kind of thing we all set out to do, which is to say we work for the public. Our job here is to hold people in power accountable. And we're going to do the best we can to do it. GROSS: So after Trump was elected, you wrote a piece that was titled \"When Tyranny Takes Hold. \" The piece was about China. You wrote (reading) what is the precise moment in the life of a country when tyranny takes hold? It rarely happens in an instant. It arrives like twilight and at first, the eyes adjust. Tyranny does not begin with the violence. It begins with the first gesture of collaboration. Its most enduring crime is drawing decent men and women into its siege of the truth. Since you were making a comparison, in some ways, a silent comparison between what happened in China and what you fear could happen in the U. S. , what's the analogy to the U. S. that you fear in that line? OSNOS: What worries me is that we sometimes take for granted how unbelievably important simple truth and facts really are. If you've ever lived in a country, an authoritarian country, for instance, like where I've lived in China, I lived in Egypt and I worked in Iraq, one of the things that unifies these countries is that they all have basically no reliable source of authority. There is no fact that people believe. You know, if you wake up in the morning in Cairo and you pick up a newspaper, you don't believe what the newspaper's really telling you. What you believe is that this is some set of, you know, that there's some group behind that newspaper and that they're, you know, projecting one set of ideas and that there's another newspaper with another set of ideas and that there is no such thing as fact. And I think we make a mistake by kind of drifting in America almost into a mode of thinking that facts are obsolete, that they are just opinions dressed up as something more reliable. No, that's not true. I mean, one of the things that's knowable is that there are such things as facts. It's just a fact that the number of people who rode the subway on the day of Barack Obama's inauguration was larger than the number of people who rode the subway on Donald Trump's inauguration. Why does it matter? I mean, it could not be a more, you know, it feels like it's the smallest statistic in the world except that it's absolutely essential that we remind the people who serve in our name that they cannot lie to us, that if they lie to us and if we allow it to happen, then we're giving up this basic sort of cellular building block of our political society because if you can't rely on the information by which public servants are making decisions, you know, if they have de-legitimized the sources of those information, then all of the other institutions that we depend on, the courts, contracts, good schools, all of those things begin to unravel. And so it all begins, in the end, with making sure that politicians are as much as possible held to account for the facts that they dispense. GROSS: What are some of the things that you're really looking at right now in terms of the Trump administration, Trump's decisions so far and what clues they might give about the future? OSNOS: Well, one of the things that I'm very focused on is that, you know, we have to know very, very clearly and transparently what Donald Trump's business obligations are. And I use that word advisedly. Obligations includes, for instance, who holds his debt, who has given the Trump Organization money over the years. And I know it has by now been said a thousand times, but the idea that Donald Trump is now president and has not released his tax returns puts us into a constant state of uncertainty about his political decision-making. And it cannot be allowed to be ignored. I mean, this is the kind of thing that - his adviser Kellyanne Conway indicated last weekend that he may never release his tax returns. He had promised that he would when there was an audit completed. But now she has indicated that, well, he may never do that because, as she put it, the public doesn't care. Actually, surveys are very clear, that's an untrue statement. You know, the surveys are quite clear that the public does care. The majority of Americans want Donald Trump to release his tax returns. The majority of Republicans, in fact, want Donald Trump to release his tax returns. And until he does, it's not just that we want to know if he paid any taxes. That's actually sort of one of the smallest issues at this point. All indications are that he paid very little in tax. The bigger issue is who is he in business with? Who was he in business with in the past? And who is his family in business with today? And until we know the answers to those questions, we can't honestly evaluate his presidency without concern about conflicts of interest. GROSS: My guest is Evan Osnos, a staff writer for The New Yorker. His new article is called \"Survival Of The Richest. \" We'll talk more after a short break. This is FRESH AIR. (SOUNDBITE OF YO LA TENGO SONG, \"WEATHER SHY\")GROSS: This is FRESH AIR. My guest is Evan Osnos, a staff writer for The New Yorker. His new article, \"Survival Of The Richest,\" is about superwealthy Silicon Valley executives who've become survivalists. Osnos has also written about candidate and now President Donald Trump. You lived in and reported from China for eight years. What are you looking at now and trying to understand what Trump's policy toward China is likely to be? OSNOS: Well, the China relationship, I suspect, is going to end up being a big subject of discussion. We don't talk about it very much today because we're focused, for instance, on his early appointments and perhaps his relationship with Russia, since he talks so much about Vladimir Putin. But when you talk to his advisers, as I've done over the last few months, they believe that a confrontation with China, some sort of confrontation over trade, perhaps over territory in the South China Sea, which China believes is its own, all of those issues are likely to grow. And I - you've begun to hear this. Rex Tillerson, who will probably be the secretary of state, said in his confirmation hearings that the United States would seek to prevent - and that's an important word - that it would seek to prevent China from getting access to these manmade islands in the South China Sea. Why does this matter? Because if that's in fact the case, if the Trump administration is interested in trying to draw a much harder line on China, well, then that will become the biggest foreign policy question that they face. When it comes to China, Donald Trump's administration has said something very surprising and I think something that will have long-term consequences we'll be hearing more about. And that's that they do not believe fundamentally in what's known as the one-China policy. That's the idea that China and Taiwan are ultimately part of one country. And that's been a principle that has been the foundation of peace in East Asia for about 40 years. What the Trump administration has said is that they would consider abandoning that policy, which would be a source of enormous concern in Beijing, if they don't get what they want on trade. Beijing has responded to that by saying this is a non-negotiable issue. This caused a huge amount of attention and concern among China specialists over the last sort of early days of the Trump administration because that if he believes that the one-China policy is a bargaining chip, well, then he's operating in a completely different reality from what the leaders of China are operating in. And that's the recipe for a confrontation down the road. GROSS: By confrontation, do you mean trade war, diplomatic dispute, war - what do you mean? OSNOS: It's too early to know. But it's - anybody who studies China seriously will agree that the one-China policy, meaning Taiwan, is the one issue on which China would be willing, at this moment, to go into a shooting war. There's just no question. They regard that as an existential matter of their survival. If they lose Taiwan, they worry about the future of the country. And so for them, this is not a small issue. GROSS: You mean like a shooting war with us? OSNOS: Yes. China is not willing to give up Taiwan. It's probably the one issue on which they would, at the moment, be willing to get into a conflict with the United States, which is not something they want. You know, they really don't. They don't regard themselves as militarily our equal. They know they're not. You know, the United States has about a dozen aircraft carriers. China has one. But if there was a case in which China was confronted by a U. S. president who had made it his stated position to try to allow or permit or encourage Taiwan to seek independence from China, I think you would find that the Chinese government would be willing to do much more than we've ever really imagined in order to try to defend what it regards as its territory. GROSS: So if this is kind of like a path to some kind of war - trade war, shooting war - why would the Trump administration want to do it? OSNOS: I don't think that they intend to get into a conflict, certainly an armed conflict, with China. When you talk to the administration's China specialists, people like Peter Navarro, who is now the head of the National Trade Council, what he tells you is that we regard this as a negotiation. And Donald Trump, if you look over the course of his candidacy and certainly over his business career, when he goes into a negotiation, he will sometimes stake out a position that is wildly out of bounds. Just, you know - he knows he's not going to get it. But it begins the conversation, and the other party is on the defensive. And then he sort of begins to, you know, march forward until eventually he reaches an accommodation that he thinks is to his advantage. The difference here is, this is not a real estate negotiation. And if you come out with a position at the outset that the other party regards as an existential threat, national threat, well, then that's a totally different process. That's not a, you know, a negotiation where you end up with a kind of, you know, mutually acceptable conclusion. That's one in which the other party believes at the outset that you are truly not inclined to defend their national security but that you're pursuing a position that might imperil them. That's why it's worrisome - because it implies that if you take the toolbox that Donald Trump used as a business person and then as a candidate and you just apply it wholesale to what he will be called upon to do as president, it's a real mismatch. And it's not the same set of tools that would allow him to succeed in national security and other issues. GROSS: Well, Evan Osnos, thank you so much for talking with us. OSNOS: My pleasure. Thanks for having me, Terry. GROSS: Evan Osnos is a staff writer for The New Yorker. His latest article, \"Survival Of The Richest,\" is about Silicon Valley executives, venture capitalists and hedge fund managers who have become survivalists. Tomorrow on FRESH AIR, my guest will be Luke Harding who reported on Russia for four years for The Guardian before being expelled. We'll talk about the Russian dossier alleging connections between the Donald Trump campaign and Russia. We'll hear how Luke Harding was spied on when he was in Russia, and we'll talk about his current reporting on Russia's connections to the European far-right and what the Trump presidency means for England. He's now The Guardian's senior international correspondent. I hope you'll join us. FRESH AIR's executive producer is Danny Miller. Our technical director and engineer is Audrey Bentham. Our associate producer for online media is Molly Seavy-Nesper. Roberta Shorrock directs the show. I'm Terry Gross. (SOUNDBITE OF ERIK FRIEDLANDER'S \"OSCALYPSO\") TERRY GROSS, HOST:  This is FRESH AIR. I'm Terry Gross. Fears about politics, the economy, the environment, water shortages, the weather, dirty bombs, all-out nuclear war and the final apocalypse and end of days have led some individuals and groups known as survivalists to prepare for ways to defend themselves. Survivalists are often considered pretty fringy, but now it's become a thing for some of the super-rich. My guest, Evan Osnos, has written a new article in The New Yorker called \"Survival Of The Richest,\" about Silicon Valley executives, venture capitalists and hedge fund managers who are stockpiling food, water and ammunition and creating luxury escape havens. Osnos is a staff writer for The New Yorker and previously joined us to discuss his articles about white nationalists' support for the Trump campaign and executive orders President Trump could sign undoing existing agreements on climate change, immigration and foreign policy. We'll get some of Osnos' current reflections on the president a little later. Evan Osnos, welcome back to FRESH AIR. How did you find out about these superwealthy survivalists? How did you know this had become a thing? EVAN OSNOS: Well, I came upon it sort of by chance. Actually, I was sitting on an airplane and the person in the seat next to me just coincidentally was the CEO of a technology company in Silicon Valley. And this was a couple of years ago. And we got to talking. And I said, is there a story in Silicon Valley that people aren't writing about that you think is interesting? And he said, you should take a look at survivalism. And I didn't know exactly what he meant. And he said, you should look at survivalists in Silicon Valley. And he said, you won't find much about it publicly, but you may find something there. And, you know, I thought it was a kind of an oddball subject, but it also stayed with me because it seemed interesting. The idea that this place where people talk so much about the future and talk about the idea of changing the world that there might be this other form of thinking and discussion in private about survival was interesting. So I decided to start a project and began to start talking to people about it. GROSS: So what are Silicon Valley executives and former executives especially worried about regarding, you know, doomsday scenarios, the kind of thing that they have to prepare for by stocking up and building secret hideaways? OSNOS: So some of the things that they talk about are the kind of stuff of ordinary disaster movies, the idea - but, you know, there is some real element to it. The idea, for instance, that there could be a pandemic if the Ebola virus, for instance, had affected a much larger part of the population or an earthquake on the San Andreas in San Francisco - that's not a completely unreasonable fear - or the possibility of some sort of civil unrest. They take what they've seen in some American cities and extrapolate onto a larger scale and they say, well, what would happen? But they pay less attention to what the initial event might be than what the aftermath would be, which is to say as one person put it in this story, I worry about the temporary collapse of our government and its systems. What he means is that they feel a sense of fragility in our politics. Our politics have become disorderly, they've become hard to predict. And they look at it and they think, well, we're not entirely sure that our institutions are as sound as we've always assumed they are. And then there's another piece of it which is specific to technology. And that is a fairly prevalent fear in this community, which is that the growth and the development of artificial intelligence, which has become such a big subject of discussion, the idea that you will soon have a car that has no driver and eventually your goods will be delivered to a store by a truck that has no driver, that this kind of fundamental change in the American labor force will continue to produce tensions particularly between people who are losing their jobs and people who are responsible for the technology that is bringing about that change. And so there is a quiet and constant conversation in Silicon Valley today about the idea that some of this extraordinary technology that's been created, like artificial intelligence, might, in fact, produce extraordinary social tension that they haven't yet figured out how to absorb. GROSS: So you're talking about a kind of literal class warfare. OSNOS: Yeah, that's the way that they talk about it. I mean, Max Levchin, who was a co-founder of PayPal, is the CEO of a firm, a lending startup who is opposed, actually, to this trend of survivalist thinking but is surrounded by it. He said, you know, what people worry about is, to use Max's word, the pitchforks. And by that, he means the idea that the sort of tension that we saw with the Occupy movement a few years ago would take on a wider, more virulent form. GROSS: But it seems from your article that especially the Silicon Valley superwealthy know so much about the vulnerabilities within the electric grid and within the internet as a whole that they're worried that those systems can be hacked, that there's flaws, that the internet can kind of be disrupted, the electric grid can be disrupted, the whole society can collapse as a result. How much is that the motivation for this new superwealthy survivalism? OSNOS: Well, that's a big piece of it. If you're somebody who works in technology, then you got into that business in part because you tend to think about how systems fit together. And as one CEO of a multi-billion dollar technology company put it to me, he said, look, the truth is that our lives today are dependent on systems that are integrated, interdependent in ways that they simply weren't even 20 or 30 years ago. To give you an example, he said, the food that's on the shelves in our grocery stores depends on a supply chain that depends on GPS. And GPS, the Global Positioning System, depends to some degree on the internet. And the internet depends to some degree on another system known as DNS. And each one of these is vulnerable in its own ways. And so what he said, and this is - you know, he's a highly rational person who lives his life in very sophisticated ways in his business all the time, and he said, look, I'm not rushing out and, you know, declaring that the end of the world is near. But what I am saying is that it is, in his view, logically rational to talk about the fragility of these digital and electrical systems, which are really sort of second nature and largely on unexamined as we go about our daily lives. GROSS: So are these new superwealthy survivalists kind of equally divided between liberals and conservatives between the right and the left? Those people who have, like, political fears and fear that there's going to be a political breakdown, that's going to lead to a rift in the social fabric of society. OSNOS: One of the surprises to me was that this was not something that was occupying one political wing or another. It seems to actually draw from both sides. Traditionally, most survivalists would describe themselves as libertarians somewhere out typically on the conservative end of the spectrum. They put a high premium on self-reliance, on sort of distance from government. But there is a new element here, which is partly reflected in the success in the candidacy of Donald Trump. And that's the idea that there are, certainly in the case of Donald Trump, somebody who defies all of the conventional expectations and descriptions of politics, the sorts of experience required, the kind of standard to which he would be held for accuracy in what he says, all of the things that we used to assume would be absolutely fundamental about politics, those no longer obtain at the moment. And so to give you a literal example, Justin Kan, who is a technology entrepreneur in Silicon Valley who co-founded a company called Twitch, which was later sold to Amazon for a billion dollars, he told me that after the election of Donald Trump, he got a call from a friend at a hedge fund who said to him, you know, if Donald Trump turns out to be, in Justin's words, a fascist dictator, well, the expected value of having an escape hatch, meaning having a home overseas, will be very high. So while it used to be a phenomenon that was principally associated, I think, on the far-right end of the political spectrum, now you have people on the left who feel deeply uneasy about the direction that politics have taken. GROSS: So let's talk about some of the measures some of the superwealthy are taking to prepare for the doomsday scenarios that they fear. Tell us about one of the Silicon Valley executives that you spoke to. OSNOS: Sure. I'll tell you about somebody named Steve Huffman who is the CEO and a co-founder of Reddit, which is a very popular discussion site. It's valued at about $600 million. Steve graduated from the University of Virginia. He and his roommate ended up founding Reddit, which went on to become this very popular destination, one of the most popular sites on the internet. And Steve is concerned about what he describes as the sort of temporary loss of our government and institutions to the point that he got eye surgery so that he's no longer near-sighted because he believes that if you have contacts or glasses in the event of some sort of crackup of civilization, then that will make you likely to be a victim. GROSS: Because you'll lose your glasses and your contact lenses, so you'd better be able to just see. OSNOS: Right. His - the theory is that if you're overly dependent on something like contact lenses, which - let's say they're no longer being delivered to the store anymore, then that reduces your chances of survival. And he said - you know, he added, I also have a lot of food. He has a couple of motorcycles so that he could get out of town in a hurry. He has guns, and he has ammunition. So he said, I think I could probably sort of hole up and protect myself for a while. GROSS: Let me ask you about another superwealthy Silicon Valley exec. And this is Antonio Garcia Martinez - what is he doing to prepare for the doomsday scenario he's envisioning? OSNOS: Antonio Garcia Martinez, who worked at Facebook, later was an adviser to Twitter - in the midst of the presidential campaign, when it was getting really toxic between supporters of Donald Trump and Hillary Clinton, he decided to buy five acres on an island in the Pacific Northwest. And he brought in generators and solar panels and, as he put it, thousands of rounds of ammunition because, as he says, when a society loses its founding myth - you know, the thing that holds it together - well, then it can descend into chaos. And that's his. . . GROSS: What's the founding myth he was referring to? Do you know? OSNOS: Well, one of the things - yeah. What he was referring to is something that you hear across these conversations, and that's the idea that we are ultimately held together by a kind of commitment to the United States as a functioning entity. It's a sort of consensus, a belief that our politics are possible, that it's worth participating, that it's - you know, that our institutions are sound, that the president, for instance, will will abide by the Constitution, that the courts will have the say over the things which the Constitution allows them to govern. So what they feel - the survivalists in Silicon Valley and in finance circles in New York who are expressing this view - is that they are worried that there's been this kind of creeping disrespect for fairly basic institutions in American life, the things that people used to believe were sources of authority. So for instance, today, you know, there is fake news, which is completely, you know, sort of obviously false and made up, intended to deceive people. But that term has already been misappropriated by people who are using it, including - it's worth saying - clearly including the president the United States, to describe things that he doesn't agree with. And the idea and the concern is that if we're entering into a period in which some of the most traditional sources of authority in American life, including the intelligence community and a free press, are no longer considered sacred and trustworthy, well, then we're entering a really uncertain period in which it becomes hard to know, for instance, whether there will be, you know, talk about fake evidence or whether contracts will be honored. And so people whose livelihoods depend so much on the sanctity of these kinds of basic institutions are worried, and they're, in their words, hedging. GROSS: Yes, but - the people who we're talking about, the superwealthy - they have enough money that they could really help support social institutions. They could help support any social change that they believe in. They could help support institutions whose funding is in jeopardy. They can do a lot to help bolster the society that they fear is going to crack up and fall apart. OSNOS: Yeah, that is very much the argument among those who are opposed to this phenomenon. In Silicon Valley, for instance, Max Levchin, who is a prominent investor and entrepreneur says that this is - this idea, this kind of survivalist thinking is, as he puts it, one of the things that bothers him most about life in Silicon Valley today. He says, I often ask people, when they say to me what they're going to do in the, quote, unquote, \"apocalypse,\" I say, well, how much have you donated to your local homeless shelter? How much have you actually really tried to address the underlying sources of social tension that are the cause of this anxiety? Because, as he puts it - look, we're at a relatively benign point in the economy right now and the concern would be, instead of talking about what you're going to do if, you know, some faintly sci-fi scenario emerges, why don't you talk about what you could do right now to actually invest in the American project to try to strengthen these institutions and to help people in need? GROSS: If you're just joining us, my guest is Evan Osnos, a staff writer for The New Yorker. And we've been talking about his new piece in The New Yorker, which is called \"Survival Of The Richest. \" And it's about how some of the wealthiest people in America, in Silicon Valley and the finance industry, are getting ready for doomsday scenarios and stocking up on, like, food and arms and are building homes in hidden enclaves. We'll be right back. This is FRESH AIR. (SOUNDBITE OF MATT ULERY'S \"GAVE PROOF\") GROSS: This is FRESH AIR. And if you're just joining us, my guest is Evan Osnos, a staff writer for The New Yorker. His new piece is called \"Survival Of The Richest. \" It's about how some of the wealthiest people in America, including in the Silicon Valley and the finance industry, have become basically survivalists, stocking up on food and ammunition, weapons and also building, like, enclaves that they can retreat to in case society falls apart. One of the most interesting enclaves that you write about in case society falls apart is this, like, superluxury condo that's actually in a former nuclear missile silo. Would you describe this? OSNOS: Yeah. This is called the Survival Condo Project. And it is a couple of hours north of Wichita, Kan. , in an old missile silo complex that was built in 1961, at the height of the Cold War. And the missile silo was decommissioned in 1965, as a lot of them were around the country. And there was sort of no obvious use for them until a few years ago. It was developed by somebody named Larry Hall, who was a developer and a survivalist himself. And what he realized was that there was a certain kind of buyer out there, a potential buyer who would be willing to spend, in this case, about $3 million for an apartment underground or a million and a half dollars for half an apartment. And so he bought this silo and invested about $20 million into turning it into, essentially, a kind of luxury condo that's underground. And it can support 75 people on the food and the fuel that it has. And then it can, he said, operate indefinitely because you'll have hydroponic vegetables, and it will grow its own fish in farms and also be able to generate power with renewable energy because it's got wind turbines and also uses geothermal energy. GROSS: So I was going to ask you if all of this is a big secret. But there's a website (laughter) for this Survival Condo Project. On the website, it says, this is the safety you need with a kind of comfort you'd come to expect from a luxury condo. And I thought, wow (laughter), that's - what a sales pitch. I mean, it's - I never expected there to be a website for this describing all the advantages of buying a condo in this former nuclear missile silo. OSNOS: Yeah, I kind of scratched my head when I first heard about this. And I wasn't sure if it was real, so I went out to go see it - to go spend a night in this and sort of get a feel for it. And sure enough, it does exist. And Larry Hall has sold every unit in it except one for himself, he says. And it is true that if you go down and you go to these apartments, they look more or less like apartments that you would find at any sort of high-end apartment building. They just happen to be underground. And they don't have windows, and so what they've done is install video screens as windows so that you don't get claustrophobic. And the video screens show a scene that is a live feed of the sky and the surface above, or you can have it play whatever you want. At one point, they had a prospective customer who wanted to see the view from her window in New York City. And so the idea was to take footage of Central Park that she could see out her window and then have it projected from these kind of video windows underground. GROSS: It's a screensaver basically. (LAUGHTER) OSNOS: It's essentially a screensaver - an apocalyptic screensaver. GROSS: Exactly (laughter). So how did it feel to spend the night there? OSNOS: I mean, perhaps surprisingly, it was not as odd as you might expect. Once you're in there, you kind of forget at certain moments that you're underground. He relied on some of the interior decorating tricks that they use for cruise ships so that you can use a compact space very efficiently. There were a lot of lights, for instance, to keep it very bright so that it didn't feel gloomy. And, you know - and it has a library. And it has a movie theater, and it has a classroom and so on. But you know, you have to kind of remind yourself every once in a while that the only reason why a person would be in this facility is that something really dreadful has happened to the world above. And so you sort of remember every few minutes - well, let's hope that nobody is ever, ever required to be inside this thing. GROSS: So I don't know much about flying, but it seems to me, you know, if something's happened to, like, the internet system and GPSs aren't operating, which is one of the fears in the Silicon Valley, how are you going to be able to navigate your private plane to get to this place? OSNOS: Well, one of the scenarios that is, I think, pretty common - that I heard about over and over again from, sort of, ultra-wealthy survivalists is that they think that this doesn't generally happen overnight. You know, that sure, there are scenarios like an internet blackout, some sort of major technical collapse. But the real risk, the thing that they worry about is more fundamental. And that's basically the erosion of social stability. They really do feel - on some level, they sense that there is - because of income inequality and the unaddressed feeling of haves and have-nots in this country, that there really is a source of tension that were something to happen, it wouldn't happen overnight. And it would happen gradually. And it would become - you know, there would come a point at which they would no longer feel safe being in the cities and being in the homes where they live. And that's the point at which they would go into these compounds, either in the U. S. or they would fly abroad. GROSS: My guest is Evan Osnos. His new article about superwealthy Silicon Valley survivalists is called \"Survival Of The Richest. \" He's a staff writer for The New Yorker. After a break, we'll talk more about survivalists, and we'll talk about fake news in America, including fake facts coming from the Trump administration. And we'll discuss the direction the president is heading in with China and why it could lead to a shooting war. Osnos reported from China for eight years. I'm Terry Gross, and this is FRESH AIR. (SOUNDBITE OF ZUBATTO SYNDICATE'S \"SATURN 9\") GROSS: This is FRESH AIR. I'm Terry Gross, back with Evan Osnos, a staff writer for The New Yorker. His new article, \"Survival Of The Richest,\" is about super-rich Silicon Valley executives, venture capitalists and hedge fund managers who have become survivalists. They're preparing for doomsday scenarios, including dirty bombs, environmental disasters, the hacking of our digital infrastructure, political extremism and the social collapse of America. They're stockpiling food and weapons or hiring security, and they're creating luxury escape havens. One of the things you write about that has led a lot of people to seriously worry about the total social collapse of America and then that there'll be no one to help us was Hurricane Katrina, which you say people have told you have totally, like, decreased their faith in government's ability to handle catastrophe. And FEMA, which stands for the Federal Emergency Management Agency, is sometimes referred to now as FEMA, foolishly expecting meaningful aid (laughter). So a vote of no confidence in the government. OSNOS: Right, yeah, this is an element of survivalist thinking that has both early roots and then a contemporary phenomenon. The early roots of this is that, you know, when did survivalism begin? It basically began in the 1970s during the oil shock, during this fear of inflation that there were writers out there who figured out that there was a market for this kind of idea. And they managed to sell some bestsellers that were called things like \"How To Prosper During The Bad Times. \" And, you know, what they did is they celebrated frontier thinking and these kinds of, you know, forgotten arts of how to make your own house or grow your own food. And then that sort of took on a new life, a larger life during Ronald Reagan's presidency because what Ronald Reagan said, as Richard Mitchell, who's a great sociologist of the survivalist phenomenon, described to me, Ronald Reagan was the first president who said to people actively, your government is the problem. Your government is not here to solve your problems. Your government is your problem. And as Mitchell documented over the course of a number of years, this contributed to a new kind of energy for their survivalist movement what reached beyond the old - the sort of smallest community and began to grow into a larger phenomenon. And then you had a new incarnation in the last few years, which was expressed to me by several people who've adopted this survivalist lifestyle is that watching how the George W. Bush administration mishandled the response to Hurricane Katrina told them that a government today, even if it knows everything, it has full awareness that there's a hurricane bearing down on an American city, that it was incapable of protecting its citizens. Well, they took that experience and they turned that into a general theory. And the general theory was the government is no longer able to protect me, therefore I need to protect myself. GROSS: So, you know, when the web started and even when, like, the internet started in terms of being accessible to regular people and not just people in government, it seemed to be or at least have the potential of becoming a utopian community where things are free and accessible and people, like, chat online and form affinity groups and it's just, like, you know, a lovely, wonderful utopian idea. Stewart Brand, who created the Whole Earth Catalog, co-founded something called The WELL, which was one of the first, like, online communities. And it was amazing. And now there's this, like, totally dark (laughter) underside to the internet. You've got Silicon Valley executives preparing for, you know, the social apocalypse. So what happened to that utopian vision? Like, the last people to have it now seem to be some of the people in Silicon Valley. OSNOS: Yeah, it's - that is the most interesting question at the center of this. I mean, in some ways, Stewart Brand, who was this sage of Silicon Valley, really - I mean, he was one of Steve Jobs' great heroes. And the reason he was an icon was that he published a magazine called the Whole Earth Catalog, which was this kind of combination of techie thinking and hippie thinking. And his motto was we are as gods and we better get good at it. What did he mean? He meant that the tools that we've created for ourselves, both as technologists and also the literal tools on the farm, these are powerful things. And they can make tremendous difference in our lives, but it's not altogether clear if it's going to be good or bad. And what we've discovered, I think, over the last several years and certainly over the course of the last several months where we've discovered that the internet became a kind of high-speed conveyor belt, in some cases, for absolutely fraudulent information, which, you know, what's now known as fake news zipped around the country in ways that it never could have a generation ago. And people believed it. We now know that. The survey data's quite clear. And as a result, they believed things about political candidates that were not true. I had a fascinating conversation with Stewart Brand for this story about survivalism in Silicon Valley. And I called him up and I said, what do you make of this? He's been in that community for 40 years. And I said, what do you make of this? And he said, you know, I dabbled in survivalism, he said, in the '70s. He tried it for a little while. But he decided it was kind of strange, the idea that walking around believing that the world was about to end. And what he said is that over the years, he's become much more impressed by examples of resilience rather than examples of frailty. For example, in the last 10 years, the United States has weathered a recession, the largest recession since the Great Depression. It now has unemployment at low, manageable levels. There was an Ebola crisis, which was predicted to be much worse in the end than it ultimately was. It was certainly costly, but it was nowhere near what it could have been. And that was because people took it upon themselves to do something about it. And then another example would be Japan that suffered this tsunami and a cascade of nuclear meltdowns. And from that, yet, it has soldiered on. And so what Stewart Brand said is that the hardest problem that we face today is not the idea that the world is about to end, this idea which we circulate among ourselves, let's say, online in these communities. But it actually is the much more mundane but more likely scenario, which is that we chug on, that we continue and we are faced with these practical problems, social problems about how do we help the neediest members of our society and how do we make sure that people are taken care of who need it? GROSS: My guest is Evan Osnos, a staff writer for The New Yorker. His new article is called \"Survival Of The Richest. \" We'll talk more after a break. This is FRESH AIR. (SOUNDBITE OF DAN AUERBACH SONG, \"HIDDEN, IN DISREPAIR\") GROSS: This is FRESH AIR. My guest is Evan Osnos, a staff writer for The New Yorker. His new article, \"Survival Of The Richest,\" is about superwealthy Silicon Valley executives who've become survivalists. Osnos has also written about candidate and now President Donald Trump. After Trump announced his candidacy, Osnos wrote about why he was championed by white nationalists and far-right groups who rebranded as the alt-right. So Steve Bannon, who is President Trump's chief strategist and the former head of Breitbart News, just hired Julia Hahn as his aide. And she was a Breitbart staff writer. She wrote an article about Paul Ryan last October, October 21, 2016, that was headlined, \"He's With Her: Inside Paul Ryan's Months-Long Campaign To Elect Hillary Clinton President. \" I really don't think Paul Ryan wanted to elect. . . OSNOS: (Laughter). GROSS: . . . Hillary Clinton president. I really doubt that he had a campaign to elect her. And, you know, he's, you know, the leader of the Republican Party in many ways. OSNOS: Right. GROSS: I mean - so, like, of course, I'm really wondering what is going through his mind. I can't ask you to tell me that (laughter). OSNOS: Right. GROSS: But I can't help but wonder, like, why would he not say something about this? Why would he not object to this? OSNOS: Do you mean Paul Ryan, or do you mean. . . GROSS: Paul Ryan. OSNOS: . . . Donald Trump? Paul Ryan's initial reaction to the appointment of Julia Hahn was basically - he adopted the posture that it doesn't matter. And his office put out a statement saying, we don't care about this in the slightest. The reality is, of course, that they do care. She has been out here in this relatively small media organization - but an influential one in Paul Ryan's world, has been his most fierce critic and has been sort of promoting a version of events that would qualify as a kind of odd-ball thinking. And it's certainly not conventional political analysis. Nobody else was saying that Paul Ryan was trying to promote Hillary Clinton's candidacy for president. So the question, I think, becomes - well, why is this entering the White House? What is Donald Trump actually doing by bringing this into the White House? And the answer is that, in some ways, he is now caught between these two impulses and these two necessities. On one side, Donald Trump was elected by this populist, nationalist phenomenon that was articulated by Breitbart Media. It sort of took the form of Steve Bannon as a person and as an adviser. But at the same time, there's this other side, which is the very practical side of being, now, the head of the Republican Party in America and also the president of the United States. And Donald Trump is faced, in a sense, with a difficult problem, which is that in his inauguration, you remember he said that the time for empty talk is over and the hour of action has arrived. What he meant was politics. But actually, it could be used to describe his own predicament because Donald Trump has campaigned, in a sense, brilliantly. I mean, whether we like him or not, he succeeded in becoming the president of the United States. But now all of the things which he said, which in many cases - and it's not an exaggeration to say many cases - were not based on fact, were not based on reliable statistics, were not based on reasonable expectations of policy prescriptions. He now faces the problem of - how do you actually achieve these? And if he can't achieve them, then he's going to have to rely on that other pillar of his support. So he's not going to be able to rely on competence and achievement and success. Well, if that won't work, he's going to have to rely on this populist, nationalist surge of sentimental energy which got him into the White House in the first place. GROSS: Are you concerned that with Steve Bannon as President Trump's strategist and with Steve Bannon's aide as a former writer for Breitbart News, that they're going to be encouraging fake news, which is something Breitbart News is famous for? OSNOS: Absolutely. I think, you know, this is the kind of concern that it's easy for journalists to talk about but, in fact, is of immense importance to people in finance, in medicine, you know, if you are a schoolteacher. And all of these worlds that I just described, which depend fundamentally on the sanctity and the precision of numbers, you know, on whether or not we are being honest with ourselves about the country we inhabit - for the presidential spokesman, Sean Spicer, to get up as he did on the very first day after the inauguration and to provide false information, to falsely claim that the inauguration was larger than any crowd in history for an inauguration or to say that the ridership on the local subways, for instance, was higher that day than the ridership for Barack Obama's inauguration, those were numbers which were just patently false and easy to verify that they were false. And for him to do that represents such a break with political culture that it really becomes hard to know how a White House that is willing to adopt and promote ideas, which even a sort of rudimentary check would know to be false - how it is that they are going to govern successfully because you can only rely on faulty information for so long before it begins to produce, basically, failure. GROSS: So what is your position - as a journalist and just as a citizen, you're very skeptical that Donald Trump will be able to fulfill his promises. You're very concerned about fake news that has come and might continue to come from the Trump administration. You're concerned about Trump's relationship with white nationalists. He is the president of the United States, and he was elected. So what kind of dissonance, if any, are you facing between respecting that he is the president of the United States and fearing some of his ambitions and methods and alliances? OSNOS: In some ways, you know, I have so much respect for the institution, for the presidency, that it is, as a journalist, energizing right now to say this is an amazing thing we created in the country. You know, the U. S. presidency is a powerful office and an honorable office and a dignified office. And it's one that has been conducted brilliantly over the course of our history. But it is also one that is - ultimately, it works for us, you know. It is subject to public approval and support. And one of the things that you saw on the day after Donald Trump's inauguration was that people voiced their sort of most elementary commitment as citizens to stand up and say, I care. I care enough to march. I care enough to come out and express myself. And you saw it in vast numbers. And I think - strangely enough, you know, this is a time when journalism, obviously, is much maligned at the moment. People say that they don't trust much of what they read in the media and they really don't have much respect for journalism. And yet, at the same time, journalism has been, historically, one of the ways that presidents have been brought to account. Were it not for journalism, Richard Nixon and the break-in at the Watergate would never have been discovered. So I think - you know, I can't speak for my colleagues more broadly, but I do find that among people in Washington who write about politics and think about it, we feel like this is exactly the kind of work that we were trained to do. This is exactly the kind of thing we all set out to do, which is to say we work for the public. Our job here is to hold people in power accountable. And we're going to do the best we can to do it. GROSS: So after Trump was elected, you wrote a piece that was titled \"When Tyranny Takes Hold. \" The piece was about China. You wrote (reading) what is the precise moment in the life of a country when tyranny takes hold? It rarely happens in an instant. It arrives like twilight and at first, the eyes adjust. Tyranny does not begin with the violence. It begins with the first gesture of collaboration. Its most enduring crime is drawing decent men and women into its siege of the truth. Since you were making a comparison, in some ways, a silent comparison between what happened in China and what you fear could happen in the U. S. , what's the analogy to the U. S. that you fear in that line? OSNOS: What worries me is that we sometimes take for granted how unbelievably important simple truth and facts really are. If you've ever lived in a country, an authoritarian country, for instance, like where I've lived in China, I lived in Egypt and I worked in Iraq, one of the things that unifies these countries is that they all have basically no reliable source of authority. There is no fact that people believe. You know, if you wake up in the morning in Cairo and you pick up a newspaper, you don't believe what the newspaper's really telling you. What you believe is that this is some set of, you know, that there's some group behind that newspaper and that they're, you know, projecting one set of ideas and that there's another newspaper with another set of ideas and that there is no such thing as fact. And I think we make a mistake by kind of drifting in America almost into a mode of thinking that facts are obsolete, that they are just opinions dressed up as something more reliable. No, that's not true. I mean, one of the things that's knowable is that there are such things as facts. It's just a fact that the number of people who rode the subway on the day of Barack Obama's inauguration was larger than the number of people who rode the subway on Donald Trump's inauguration. Why does it matter? I mean, it could not be a more, you know, it feels like it's the smallest statistic in the world except that it's absolutely essential that we remind the people who serve in our name that they cannot lie to us, that if they lie to us and if we allow it to happen, then we're giving up this basic sort of cellular building block of our political society because if you can't rely on the information by which public servants are making decisions, you know, if they have de-legitimized the sources of those information, then all of the other institutions that we depend on, the courts, contracts, good schools, all of those things begin to unravel. And so it all begins, in the end, with making sure that politicians are as much as possible held to account for the facts that they dispense. GROSS: What are some of the things that you're really looking at right now in terms of the Trump administration, Trump's decisions so far and what clues they might give about the future? OSNOS: Well, one of the things that I'm very focused on is that, you know, we have to know very, very clearly and transparently what Donald Trump's business obligations are. And I use that word advisedly. Obligations includes, for instance, who holds his debt, who has given the Trump Organization money over the years. And I know it has by now been said a thousand times, but the idea that Donald Trump is now president and has not released his tax returns puts us into a constant state of uncertainty about his political decision-making. And it cannot be allowed to be ignored. I mean, this is the kind of thing that - his adviser Kellyanne Conway indicated last weekend that he may never release his tax returns. He had promised that he would when there was an audit completed. But now she has indicated that, well, he may never do that because, as she put it, the public doesn't care. Actually, surveys are very clear, that's an untrue statement. You know, the surveys are quite clear that the public does care. The majority of Americans want Donald Trump to release his tax returns. The majority of Republicans, in fact, want Donald Trump to release his tax returns. And until he does, it's not just that we want to know if he paid any taxes. That's actually sort of one of the smallest issues at this point. All indications are that he paid very little in tax. The bigger issue is who is he in business with? Who was he in business with in the past? And who is his family in business with today? And until we know the answers to those questions, we can't honestly evaluate his presidency without concern about conflicts of interest. GROSS: My guest is Evan Osnos, a staff writer for The New Yorker. His new article is called \"Survival Of The Richest. \" We'll talk more after a short break. This is FRESH AIR. (SOUNDBITE OF YO LA TENGO SONG, \"WEATHER SHY\") GROSS: This is FRESH AIR. My guest is Evan Osnos, a staff writer for The New Yorker. His new article, \"Survival Of The Richest,\" is about superwealthy Silicon Valley executives who've become survivalists. Osnos has also written about candidate and now President Donald Trump. You lived in and reported from China for eight years. What are you looking at now and trying to understand what Trump's policy toward China is likely to be? OSNOS: Well, the China relationship, I suspect, is going to end up being a big subject of discussion. We don't talk about it very much today because we're focused, for instance, on his early appointments and perhaps his relationship with Russia, since he talks so much about Vladimir Putin. But when you talk to his advisers, as I've done over the last few months, they believe that a confrontation with China, some sort of confrontation over trade, perhaps over territory in the South China Sea, which China believes is its own, all of those issues are likely to grow. And I - you've begun to hear this. Rex Tillerson, who will probably be the secretary of state, said in his confirmation hearings that the United States would seek to prevent - and that's an important word - that it would seek to prevent China from getting access to these manmade islands in the South China Sea. Why does this matter? Because if that's in fact the case, if the Trump administration is interested in trying to draw a much harder line on China, well, then that will become the biggest foreign policy question that they face. When it comes to China, Donald Trump's administration has said something very surprising and I think something that will have long-term consequences we'll be hearing more about. And that's that they do not believe fundamentally in what's known as the one-China policy. That's the idea that China and Taiwan are ultimately part of one country. And that's been a principle that has been the foundation of peace in East Asia for about 40 years. What the Trump administration has said is that they would consider abandoning that policy, which would be a source of enormous concern in Beijing, if they don't get what they want on trade. Beijing has responded to that by saying this is a non-negotiable issue. This caused a huge amount of attention and concern among China specialists over the last sort of early days of the Trump administration because that if he believes that the one-China policy is a bargaining chip, well, then he's operating in a completely different reality from what the leaders of China are operating in. And that's the recipe for a confrontation down the road. GROSS: By confrontation, do you mean trade war, diplomatic dispute, war - what do you mean? OSNOS: It's too early to know. But it's - anybody who studies China seriously will agree that the one-China policy, meaning Taiwan, is the one issue on which China would be willing, at this moment, to go into a shooting war. There's just no question. They regard that as an existential matter of their survival. If they lose Taiwan, they worry about the future of the country. And so for them, this is not a small issue. GROSS: You mean like a shooting war with us? OSNOS: Yes. China is not willing to give up Taiwan. It's probably the one issue on which they would, at the moment, be willing to get into a conflict with the United States, which is not something they want. You know, they really don't. They don't regard themselves as militarily our equal. They know they're not. You know, the United States has about a dozen aircraft carriers. China has one. But if there was a case in which China was confronted by a U. S. president who had made it his stated position to try to allow or permit or encourage Taiwan to seek independence from China, I think you would find that the Chinese government would be willing to do much more than we've ever really imagined in order to try to defend what it regards as its territory. GROSS: So if this is kind of like a path to some kind of war - trade war, shooting war - why would the Trump administration want to do it? OSNOS: I don't think that they intend to get into a conflict, certainly an armed conflict, with China. When you talk to the administration's China specialists, people like Peter Navarro, who is now the head of the National Trade Council, what he tells you is that we regard this as a negotiation. And Donald Trump, if you look over the course of his candidacy and certainly over his business career, when he goes into a negotiation, he will sometimes stake out a position that is wildly out of bounds. Just, you know - he knows he's not going to get it. But it begins the conversation, and the other party is on the defensive. And then he sort of begins to, you know, march forward until eventually he reaches an accommodation that he thinks is to his advantage. The difference here is, this is not a real estate negotiation. And if you come out with a position at the outset that the other party regards as an existential threat, national threat, well, then that's a totally different process. That's not a, you know, a negotiation where you end up with a kind of, you know, mutually acceptable conclusion. That's one in which the other party believes at the outset that you are truly not inclined to defend their national security but that you're pursuing a position that might imperil them. That's why it's worrisome - because it implies that if you take the toolbox that Donald Trump used as a business person and then as a candidate and you just apply it wholesale to what he will be called upon to do as president, it's a real mismatch. And it's not the same set of tools that would allow him to succeed in national security and other issues. GROSS: Well, Evan Osnos, thank you so much for talking with us. OSNOS: My pleasure. Thanks for having me, Terry. GROSS: Evan Osnos is a staff writer for The New Yorker. His latest article, \"Survival Of The Richest,\" is about Silicon Valley executives, venture capitalists and hedge fund managers who have become survivalists. Tomorrow on FRESH AIR, my guest will be Luke Harding who reported on Russia for four years for The Guardian before being expelled. We'll talk about the Russian dossier alleging connections between the Donald Trump campaign and Russia. We'll hear how Luke Harding was spied on when he was in Russia, and we'll talk about his current reporting on Russia's connections to the European far-right and what the Trump presidency means for England. He's now The Guardian's senior international correspondent. I hope you'll join us. FRESH AIR's executive producer is Danny Miller. Our technical director and engineer is Audrey Bentham. Our associate producer for online media is Molly Seavy-Nesper. Roberta Shorrock directs the show. I'm Terry Gross. (SOUNDBITE OF ERIK FRIEDLANDER'S \"OSCALYPSO\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-02-01-512919975": {"title": "Facebook Helps Regular People Make Money In The Internet Economy : NPR", "url": "https://www.npr.org/2017/02/01/512919975/facebook-helps-regular-people-make-money-in-the-internet-economy", "author": "No author found", "published_date": "2017-02-01", "content": "ARI SHAPIRO, HOST: The technology sector sometimes gets criticized for killing jobs by creating robots and algorithms to replace human labor. There is a new kind of work in tech that Facebook has made possible. Through this work, regular Americans without a computer science degree can actually make a really good living. NPR's Aarti Shahani has the story of these jobs, and why some of them are already in jeopardy. AARTI SHAHANI, BYLINE: First, let's meet Tim Lawler. He weighs about 230 pounds and likes to lift. TIM LAWLER: If Bruce Willis and The Rock had a baby, it would look like me. SHAHANI: Lawler is in Florida. I'm in California. And note - Facebook pays NPR and other news organizations to make live video. I can see from Lawler's Facebook profile that he's a towering bald man with a dark brown beard that's graying in the middle. His job is something you've likely never heard of before. LAWLER: What I do is make memes and content on Facebook for people's enjoyment and pleasure. . . SHAHANI: And for some cash. LAWLER: . . . And I make money that way. SHAHANI: Call him a meme master. Memes are, of course, the carbs of the internet - dumb, funny pictures that keep you going and may or may not be good for you. Lawler used to work as a manager for a Harley Davidson shop. When his store got bought out, he lost his job. He was 40, a tough time to make a career change. When he first got on Facebook, it was just for fun, he had a regular account. Then he decided to try out a special feature to make something called a page. He made one in honor of a personal passion - skulls. LAWLER: I think that skulls are just like a universal symbol of our - either mortality or immortality. And every person that's ever been around in this world past, present or future has a skull. SHAHANI: Turns out it was a stroke of brilliance. Lawler built a base of 350,000 fans who like skulls. Another page, his most popular one, was called Unlawful Humor. And one day a friend gave him a tip. LAWLER: Look, I'm making money off of a page of similar size, you should try it. SHAHANI: Here's how the money part works. You know how Google and Facebook get paid to post advertisements in your search and your news feed? Well, Tim Lawler posts ads too in his Facebook page. This is a standard practice for businesses on Facebook. Just like you might share a baby picture, he'll share a link, could be for a juice company or a news site. Every time a fan clicks on that link, he gets less than a penny, but the money adds up. Lawler made anywhere from a couple hundred dollars a day to a thousand. Last year he raked in about a hundred thousand dollars. He showed NPR proof of his earnings. Lawler felt he had a knack for this work when he saw celebrities sharing his memes, like this one about Barbie and Ken. LAWLER: They're in like a household setting, like a little play house, only Barbie's on the toilet and the meme says Long-Term Relationship Barbie. SHAHANI: People who create pages the way Lawler did are a small but vital part of Facebook's business. If Facebook is a publisher, these are the writers who post, reliably, multiple times an hour. Facebook wants businesses to make pages because that gives the platform traffic. NPR interviewed more than two dozen people who operate pages on all kinds of topics - 1980s movies, diesel engines, mommy support groups. Maureen Camfield, a nurse, started a page for the brokenhearted. MAUREEN CAMFIELD: It was called Broken, Beaten, and Scarred But Not Giving Up. SHAHANI: We all hear about how the internet is full of bullies. Well, Camfield says there are so many lonely people online who just want a friend. You can build a real business by being kind. She'd sometimes refer a fan on her page to the National Suicide Hotline and get a message in return like. . . CAMFIELD: It helped, you made a difference. I wanted to kill myself that night and I didn't. SHAHANI: These page owners sound like Facebook success stories, exactly the people CEO Mark Zuckerberg would want to brag about. While algorithms do take away jobs - boring, repetitive jobs - Facebook is making jobs and creative ones. This is the promise of technology, but that is not where this story goes. Tim Lawler. LAWLER: October 25. SHAHANI: You remember the specific date? LAWLER: (Laughter) I absolutely do. SHAHANI: Lawler was sitting on his couch last year posting to his Facebook pages, and all of a sudden he got a stream of notifications. LAWLER: This page has been unpublished. This page has been unpublished. This page has been unpublished. This page has been unpublished. And I was like oh, my God. SHAHANI: More than two dozen entrepreneurs tell NPR they received similar generic messages. They'd violated Facebook's Terms of Service, and their business was shut down. The notices did not state what the person did wrong exactly, and if there was a way to rectify the situation to get the page back. They read like form letters. Users already know this Silicon Valley giant that's woven its way into the lives of more than a billion people can be a black box, silent about how it makes decisions. For some, that's unsettling. For people like Tim Lawler, it's a matter of livelihood. When he opens his Facebook account, he can still see his old pages, the rest of the world can't. It makes him sad. LAWLER: Because there's nothing happening over there. All that's happening is I'm losing likes that I built. SHAHANI: Now, you could say tough luck. Facebook is a free app, people don't pay, and they're not entitled to use it. But Tim Lawler and others - they did pay. Facebook makes money by sticking ads in your news feed. You've likely seen that. Facebook also makes money by charging page owners to promote a post. Pay five bucks to get your post in more people's news feeds. LAWLER: Facebook is asking for my money. I will then in turn give them some money. SHAHANI: Lawler paid thousands of dollars in ad money. He thought it was a kind of safety valve. When you advertise you get a point person, a human at Facebook. Lawler tried reaching his human, and even got a callback which he missed. CHAD: Hi, this message is for Tim. This is Chad calling you with Facebook ad support. Give me a call today. . . SHAHANI: Chad from the advertising team left this voicemail while Lawler was driving. Chad didn't leave a number and didn't call back, Lawler says. His emails to Facebook went nowhere. CHAD: And I will await your reply. Thanks so much, and have a great day. SHAHANI: Facebook declined to discuss the specifics of any case, citing privacy concerns, but the company did say last April they posted a new rule online stating that users have to get special approval from them to post advertisements. And Lawler got dozens of notices that his account was sending out spam. Lawler says he didn't know about this big new rule, and the notices he got are just little pop-ups that disappear in seconds. If he were in bad standing, he figured, someone in the advertising department would have told him and they would have stopped taking his money. Lawler has not been able to get the company to speak with him about his case. I ask him. Imagine you're talking directly with Mark Zuckerberg. . . LAWLER: Yes. SHAHANI: . . . CEO Mark Zuckerberg. LAWLER: Mark, hire me. SHAHANI: He doesn't even let me finish the question, and he doesn't speak to just his case. He wants to talk big picture. LAWLER: You need someone that's been on the ground, that's rolled their sleeves up, that's done the dirty work. SHAHANI: You think you're that guy? LAWLER: I know I'm that guy. SHAHANI: Whether he is or he isn't, he's got a provocative idea - that Facebook needs a better way to listen to customers, small advertisers who aren't the superstars, the Coca-Colas and Kim Kardashians of the world. For now, Lawler is selling coffee mugs with skulls on them to get by. Aarti Shahani, NPR News, San Francisco. SHAPIRO: While she was reporting this story, Aarti decided to start a page on Facebook for people to share their concerns, it's called TellZuck. So if you use Facebook for work and have an issue, tell Aarti your story at facebook. com/tellzuck. ARI SHAPIRO, HOST:  The technology sector sometimes gets criticized for killing jobs by creating robots and algorithms to replace human labor. There is a new kind of work in tech that Facebook has made possible. Through this work, regular Americans without a computer science degree can actually make a really good living. NPR's Aarti Shahani has the story of these jobs, and why some of them are already in jeopardy. AARTI SHAHANI, BYLINE: First, let's meet Tim Lawler. He weighs about 230 pounds and likes to lift. TIM LAWLER: If Bruce Willis and The Rock had a baby, it would look like me. SHAHANI: Lawler is in Florida. I'm in California. And note - Facebook pays NPR and other news organizations to make live video. I can see from Lawler's Facebook profile that he's a towering bald man with a dark brown beard that's graying in the middle. His job is something you've likely never heard of before. LAWLER: What I do is make memes and content on Facebook for people's enjoyment and pleasure. . . SHAHANI: And for some cash. LAWLER: . . . And I make money that way. SHAHANI: Call him a meme master. Memes are, of course, the carbs of the internet - dumb, funny pictures that keep you going and may or may not be good for you. Lawler used to work as a manager for a Harley Davidson shop. When his store got bought out, he lost his job. He was 40, a tough time to make a career change. When he first got on Facebook, it was just for fun, he had a regular account. Then he decided to try out a special feature to make something called a page. He made one in honor of a personal passion - skulls. LAWLER: I think that skulls are just like a universal symbol of our - either mortality or immortality. And every person that's ever been around in this world past, present or future has a skull. SHAHANI: Turns out it was a stroke of brilliance. Lawler built a base of 350,000 fans who like skulls. Another page, his most popular one, was called Unlawful Humor. And one day a friend gave him a tip. LAWLER: Look, I'm making money off of a page of similar size, you should try it. SHAHANI: Here's how the money part works. You know how Google and Facebook get paid to post advertisements in your search and your news feed? Well, Tim Lawler posts ads too in his Facebook page. This is a standard practice for businesses on Facebook. Just like you might share a baby picture, he'll share a link, could be for a juice company or a news site. Every time a fan clicks on that link, he gets less than a penny, but the money adds up. Lawler made anywhere from a couple hundred dollars a day to a thousand. Last year he raked in about a hundred thousand dollars. He showed NPR proof of his earnings. Lawler felt he had a knack for this work when he saw celebrities sharing his memes, like this one about Barbie and Ken. LAWLER: They're in like a household setting, like a little play house, only Barbie's on the toilet and the meme says Long-Term Relationship Barbie. SHAHANI: People who create pages the way Lawler did are a small but vital part of Facebook's business. If Facebook is a publisher, these are the writers who post, reliably, multiple times an hour. Facebook wants businesses to make pages because that gives the platform traffic. NPR interviewed more than two dozen people who operate pages on all kinds of topics - 1980s movies, diesel engines, mommy support groups. Maureen Camfield, a nurse, started a page for the brokenhearted. MAUREEN CAMFIELD: It was called Broken, Beaten, and Scarred But Not Giving Up. SHAHANI: We all hear about how the internet is full of bullies. Well, Camfield says there are so many lonely people online who just want a friend. You can build a real business by being kind. She'd sometimes refer a fan on her page to the National Suicide Hotline and get a message in return like. . . CAMFIELD: It helped, you made a difference. I wanted to kill myself that night and I didn't. SHAHANI: These page owners sound like Facebook success stories, exactly the people CEO Mark Zuckerberg would want to brag about. While algorithms do take away jobs - boring, repetitive jobs - Facebook is making jobs and creative ones. This is the promise of technology, but that is not where this story goes. Tim Lawler. LAWLER: October 25. SHAHANI: You remember the specific date? LAWLER: (Laughter) I absolutely do. SHAHANI: Lawler was sitting on his couch last year posting to his Facebook pages, and all of a sudden he got a stream of notifications. LAWLER: This page has been unpublished. This page has been unpublished. This page has been unpublished. This page has been unpublished. And I was like oh, my God. SHAHANI: More than two dozen entrepreneurs tell NPR they received similar generic messages. They'd violated Facebook's Terms of Service, and their business was shut down. The notices did not state what the person did wrong exactly, and if there was a way to rectify the situation to get the page back. They read like form letters. Users already know this Silicon Valley giant that's woven its way into the lives of more than a billion people can be a black box, silent about how it makes decisions. For some, that's unsettling. For people like Tim Lawler, it's a matter of livelihood. When he opens his Facebook account, he can still see his old pages, the rest of the world can't. It makes him sad. LAWLER: Because there's nothing happening over there. All that's happening is I'm losing likes that I built. SHAHANI: Now, you could say tough luck. Facebook is a free app, people don't pay, and they're not entitled to use it. But Tim Lawler and others - they did pay. Facebook makes money by sticking ads in your news feed. You've likely seen that. Facebook also makes money by charging page owners to promote a post. Pay five bucks to get your post in more people's news feeds. LAWLER: Facebook is asking for my money. I will then in turn give them some money. SHAHANI: Lawler paid thousands of dollars in ad money. He thought it was a kind of safety valve. When you advertise you get a point person, a human at Facebook. Lawler tried reaching his human, and even got a callback which he missed. CHAD: Hi, this message is for Tim. This is Chad calling you with Facebook ad support. Give me a call today. . . SHAHANI: Chad from the advertising team left this voicemail while Lawler was driving. Chad didn't leave a number and didn't call back, Lawler says. His emails to Facebook went nowhere. CHAD: And I will await your reply. Thanks so much, and have a great day. SHAHANI: Facebook declined to discuss the specifics of any case, citing privacy concerns, but the company did say last April they posted a new rule online stating that users have to get special approval from them to post advertisements. And Lawler got dozens of notices that his account was sending out spam. Lawler says he didn't know about this big new rule, and the notices he got are just little pop-ups that disappear in seconds. If he were in bad standing, he figured, someone in the advertising department would have told him and they would have stopped taking his money. Lawler has not been able to get the company to speak with him about his case. I ask him. Imagine you're talking directly with Mark Zuckerberg. . . LAWLER: Yes. SHAHANI: . . . CEO Mark Zuckerberg. LAWLER: Mark, hire me. SHAHANI: He doesn't even let me finish the question, and he doesn't speak to just his case. He wants to talk big picture. LAWLER: You need someone that's been on the ground, that's rolled their sleeves up, that's done the dirty work. SHAHANI: You think you're that guy? LAWLER: I know I'm that guy. SHAHANI: Whether he is or he isn't, he's got a provocative idea - that Facebook needs a better way to listen to customers, small advertisers who aren't the superstars, the Coca-Colas and Kim Kardashians of the world. For now, Lawler is selling coffee mugs with skulls on them to get by. Aarti Shahani, NPR News, San Francisco. SHAPIRO: While she was reporting this story, Aarti decided to start a page on Facebook for people to share their concerns, it's called TellZuck. So if you use Facebook for work and have an issue, tell Aarti your story at facebook. com/tellzuck.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-02-01-512788585": {"title": "Even Without A Headphone Jack, iPhone 7 Boosts Apple's Sales : NPR", "url": "https://www.npr.org/2017/02/01/512788585/even-without-a-headphone-jack-iphone-7-boosts-apple-s-sales", "author": "No author found", "published_date": "2017-02-01", "content": "STEVE INSKEEP, HOST: IPhones are still cool - or at least people are still buying them a lot, which is good news for Apple, which took a gamble on the latest version. NPR's Laura Sydell reports. LAURA SYDELL, BYLINE: It was a dramatic market entry for the iPhone 7 last year. Many Apple customers grumbled when Apple took away the headphone jack and it gave everyone an adapter to plug its earbuds into the lightning, or charging, connector. But everyone seems to have adjusted. Apple sold 78 million iPhones over the holiday season. And in an earnings call, CEO Tim Cook implied they could have sold more of them if they'd had enough in stock, says Gartner analyst Brian Blau. BRIAN BLAU: So that was encouraging news. And that means that there's built up demand out there. And that means that it's very possible that that demand will be continued into this quarter. SYDELL: Apple has more than a billion activated mobile devices around the world. So along with the increased iPhone sales, it's also bringing in more revenue from its AppStore, iTunes and cloud services. CEO Cook mentioned the current political climate in the U. S. in connection with future growth. He seems to feel it's likely Congress and the Trump administration will make it less pricey for Apple to bring billions of dollars back into the U. S. by decreasing the tax penalties. Apple is expected to move into creating original film and TV content, so Forrester analyst James McQuivey could imagine a way for Apple to spend that money. JAMES MCQUIVEY: Perhaps investing in a major studio in the U. S. in such a way that you can start making original content right away. Having more of that money here locally to do that would be one way to spend that money. SYDELL: Earlier this week, Cook was less sanguine about the Trump administration. He criticized it for the executive order banning immigration from certain countries, which would affect some Apple employees. Laura Sydell, NPR News, San Francisco. (SOUNDBITE OF HARRIS NEWMAN'S \"LAKE SHORE DRIVE (SLIGHT RETURN)\") STEVE INSKEEP, HOST:  IPhones are still cool - or at least people are still buying them a lot, which is good news for Apple, which took a gamble on the latest version. NPR's Laura Sydell reports. LAURA SYDELL, BYLINE: It was a dramatic market entry for the iPhone 7 last year. Many Apple customers grumbled when Apple took away the headphone jack and it gave everyone an adapter to plug its earbuds into the lightning, or charging, connector. But everyone seems to have adjusted. Apple sold 78 million iPhones over the holiday season. And in an earnings call, CEO Tim Cook implied they could have sold more of them if they'd had enough in stock, says Gartner analyst Brian Blau. BRIAN BLAU: So that was encouraging news. And that means that there's built up demand out there. And that means that it's very possible that that demand will be continued into this quarter. SYDELL: Apple has more than a billion activated mobile devices around the world. So along with the increased iPhone sales, it's also bringing in more revenue from its AppStore, iTunes and cloud services. CEO Cook mentioned the current political climate in the U. S. in connection with future growth. He seems to feel it's likely Congress and the Trump administration will make it less pricey for Apple to bring billions of dollars back into the U. S. by decreasing the tax penalties. Apple is expected to move into creating original film and TV content, so Forrester analyst James McQuivey could imagine a way for Apple to spend that money. JAMES MCQUIVEY: Perhaps investing in a major studio in the U. S. in such a way that you can start making original content right away. Having more of that money here locally to do that would be one way to spend that money. SYDELL: Earlier this week, Cook was less sanguine about the Trump administration. He criticized it for the executive order banning immigration from certain countries, which would affect some Apple employees. Laura Sydell, NPR News, San Francisco. (SOUNDBITE OF HARRIS NEWMAN'S \"LAKE SHORE DRIVE (SLIGHT RETURN)\")", "section": "Business", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-02-02-513105021": {"title": "Facebook Confronts Role In Providing Entrepreneurs Access To Online World : NPR", "url": "https://www.npr.org/2017/02/02/513105021/facebook-confronts-role-in-providing-entrepreneurs-access-to-online-world", "author": "No author found", "published_date": "2017-02-02", "content": "AUDIE CORNISH, HOST: It's tempting to think of Facebook as pure entertainment, but that's not quite true these days. This week, NPR's Aarti Shahani reported on people who rely on the app for work to make a living. Their stories illustrate just how powerful the Facebook empire has become in controlling access to the online world and how opaque the company is about this power. Just a note - Facebook pays NPR and other leading news organizations to produce live videos. Here's Aarti. AARTI SHAHANI, BYLINE: Earlier this week, we introduced you to two very different people. The first, Tim Lawler in Florida, started some goofy pages on Facebook to share PG humor, memes and make money that way. One day, he got a stream of pop-up notifications from Facebook. TIM LAWLER: This page has been unpublished. This page has been unpublished. And I was like, oh, my God. SHAHANI: Sandra Nyaira, an investigative reporter from Zimbabwe, got expelled from the platform because Facebook's software thought she was a child pornographer. While reporting a story, she made the honest mistake of sharing a horrible picture of children being abused. It made total sense to her that she'd get kicked off temporarily, and she thought. . . SANDRA NYAIRA: . . . That's fine. I'll contact Facebook and tell the moderators what's going on and provide them with all the information. SHAHANI: What the Florida meme-maker and the Zimbabwean reporter have in common is that they both use Facebook for their careers. And when they got blocked, they found it was impossible to reach a human being and reconnect. Tim Wu suspects more people will have this experience. He's a professor at Columbia Law School and writes about the online economy. Wu says think of Facebook as an industrial park. Users could be a farmer, a salesman, a journalist. Users set up offices in the park, use the roads, treat it like a public utility, but legally, it's private. So the landowner, Facebook. . . TIM WU: . . . Very randomly they could just, like, shut off the road that goes to your business. Or suddenly you're just evicted, you know, and you have no idea why. And that's it. You're done. SHAHANI: Many people fear technology is destroying jobs, not creating them. This year, Facebook CEO Mark Zuckerberg made a new year's resolution. He's going to tour Middle America and talk to real people about their concerns. I asked Tim Wu what he'd say to the CEO on tour, and he poses these questions. WU: What are you doing for the economic development of Middle America? What can you offer them, other than a chance to see their friends' kids and make ad revenue off people's children? He can do better (laughter). He can do better. SHAHANI: He's not just asking about individual cases, but about how Facebook, which is the sixth largest company on Earth, sees its role in promoting commerce, creating opportunities for others. A few months ago, onstage at Stanford University, Zuckerberg got asked pretty much the same thing by former President Barack Obama. (SOUNDBITE OF ARCHIVED RECORDING)BARACK OBAMA: How's Facebook thinking about its own role in creating this platform for entrepreneurship around the world? SHAHANI: Obama was interviewing the CEO at a conference for entrepreneurs. Zuckerberg did not talk about Facebook's role. Instead, he defined the word entrepreneurship. (SOUNDBITE OF ARCHIVED RECORDING)MARK ZUCKERBERG: You know, the most effective entrepreneurs who I've met care deeply about some mission and some change that they're trying to create. And often, they don't even start because they're trying to create a company. SHAHANI: Of course, lots of people do want to create a company or earn a living and use Facebook to help them do it. Mark Zuckerberg will have many more opportunities to explain to them how - even if - Facebook can help as he tours the U. S. NPR requested an interview with him to discuss the situation of users who rely on Facebook for work. The company declined. Aarti Shahani, NPR News, San Francisco. (SOUNDBITE OF STRFKR SONG, \"OPEN YOUR EYES\") AUDIE CORNISH, HOST:  It's tempting to think of Facebook as pure entertainment, but that's not quite true these days. This week, NPR's Aarti Shahani reported on people who rely on the app for work to make a living. Their stories illustrate just how powerful the Facebook empire has become in controlling access to the online world and how opaque the company is about this power. Just a note - Facebook pays NPR and other leading news organizations to produce live videos. Here's Aarti. AARTI SHAHANI, BYLINE: Earlier this week, we introduced you to two very different people. The first, Tim Lawler in Florida, started some goofy pages on Facebook to share PG humor, memes and make money that way. One day, he got a stream of pop-up notifications from Facebook. TIM LAWLER: This page has been unpublished. This page has been unpublished. And I was like, oh, my God. SHAHANI: Sandra Nyaira, an investigative reporter from Zimbabwe, got expelled from the platform because Facebook's software thought she was a child pornographer. While reporting a story, she made the honest mistake of sharing a horrible picture of children being abused. It made total sense to her that she'd get kicked off temporarily, and she thought. . . SANDRA NYAIRA: . . . That's fine. I'll contact Facebook and tell the moderators what's going on and provide them with all the information. SHAHANI: What the Florida meme-maker and the Zimbabwean reporter have in common is that they both use Facebook for their careers. And when they got blocked, they found it was impossible to reach a human being and reconnect. Tim Wu suspects more people will have this experience. He's a professor at Columbia Law School and writes about the online economy. Wu says think of Facebook as an industrial park. Users could be a farmer, a salesman, a journalist. Users set up offices in the park, use the roads, treat it like a public utility, but legally, it's private. So the landowner, Facebook. . . TIM WU: . . . Very randomly they could just, like, shut off the road that goes to your business. Or suddenly you're just evicted, you know, and you have no idea why. And that's it. You're done. SHAHANI: Many people fear technology is destroying jobs, not creating them. This year, Facebook CEO Mark Zuckerberg made a new year's resolution. He's going to tour Middle America and talk to real people about their concerns. I asked Tim Wu what he'd say to the CEO on tour, and he poses these questions. WU: What are you doing for the economic development of Middle America? What can you offer them, other than a chance to see their friends' kids and make ad revenue off people's children? He can do better (laughter). He can do better. SHAHANI: He's not just asking about individual cases, but about how Facebook, which is the sixth largest company on Earth, sees its role in promoting commerce, creating opportunities for others. A few months ago, onstage at Stanford University, Zuckerberg got asked pretty much the same thing by former President Barack Obama. (SOUNDBITE OF ARCHIVED RECORDING) BARACK OBAMA: How's Facebook thinking about its own role in creating this platform for entrepreneurship around the world? SHAHANI: Obama was interviewing the CEO at a conference for entrepreneurs. Zuckerberg did not talk about Facebook's role. Instead, he defined the word entrepreneurship. (SOUNDBITE OF ARCHIVED RECORDING) MARK ZUCKERBERG: You know, the most effective entrepreneurs who I've met care deeply about some mission and some change that they're trying to create. And often, they don't even start because they're trying to create a company. SHAHANI: Of course, lots of people do want to create a company or earn a living and use Facebook to help them do it. Mark Zuckerberg will have many more opportunities to explain to them how - even if - Facebook can help as he tours the U. S. NPR requested an interview with him to discuss the situation of users who rely on Facebook for work. The company declined. Aarti Shahani, NPR News, San Francisco. (SOUNDBITE OF STRFKR SONG, \"OPEN YOUR EYES\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-02-02-512998428": {"title": "Facebook Mistakes Investigative Reporter For Child Pornographer : NPR", "url": "https://www.npr.org/2017/02/02/512998428/facebook-mistakes-investigative-reporter-for-child-pornographer", "author": "No author found", "published_date": "2017-02-02", "content": "RACHEL MARTIN, HOST: Facebook uses computers to spot pornography and wipe it away in milliseconds. Software is quicker than human beings and cheaper, but mistakes can still happen. That's exactly what happened recently when Facebook mistook a reporter for a child pornographer and expelled her. NPR's Aarti Shahani reports. And a warning - the story does include a description of disturbing images. AARTI SHAHANI, BYLINE: On June 17, 2016, it was Friday afternoon, investigative reporter Sandra Nyaira recalls. She received three photographs, very explicit pictures of two young girls. SANDRA NYAIRA: Yeah, horrible, horrible pictures. SHAHANI: The girls look maybe 7 years old. They're on a bed being sexually abused by a man. NYAIRA: So when I received the pictures, I was pained. I actually cried because I, you know, I looked them and I was like, who does this? Obviously these kids were being abused by someone who was very, very close to them. SHAHANI: According to news sources in Zimbabwe, the country where this is happening, the man takes his phone to a repair shop and a clerk sees the photos in the photo gallery. Now if it were you, you might go to the police. But in Zimbabwe, Nyaira says, people don't trust the police to do their jobs. That's how she winds up with the photos. She's an award-winning reporter, and she wanted to get justice done. Nyaira reaches out to a woman in Parliament, a feminist who demands an investigation and who goes on Facebook to talk about the case. In less than 24 hours, they've launched a national discussion. NYAIRA: So many women in Zimbabwe - women activists and ordinary women - started following the debate and speaking with her, responding to her debate on Facebook. SHAHANI: People reach out to Nyaira to ask how they can help. A fellow journalist says he can tap his sources, get officials he knows involved in the search. So Nyaira decides to share the photos with him on Messenger, Facebook's private chat tool. That was a big mistake. Almost instantly, Facebook computers deactivate her. She realizes, oh, no, they think I'm distributing child pornography. She feels mortified. NYAIRA: Why did you do that? You know, you start blaming yourself, but for not doing anything wrong really, but for trying to help. SHAHANI: Nyaira needs Facebook for her job. It's how she communicates with sources and promotes her stories. She tells herself it'll be OK. I'll contact the company and explain, but she realizes she can't reach a person at Facebook. There is no hotline to call, so she fills out a form on the website which asks her to scan and upload a copy of her passport. She does that, still gets a generic rejection. Nyaira is now more worried. NYAIRA: OK. I have sent Facebook my passport information, so what are they going to do with it? Are they going to go to the police without even talking to me about why they have blocked my account? SHAHANI: She fears she could be arrested. In desperation, she turns to one of the most powerful institutions she knows - Harvard University. She used to be a fellow there at Harvard's Shorenstein Center on Media, even sat at a luncheon with Facebook CEO Mark Zuckerberg there. Nicco Mele directs the center. NICCO MELE: So I reached out to a friend at Facebook and said, hey, is there anything you can do to help us? I can vouch for Sandra. She is the real deal. She wasn't doing anything untoward or anything bad. SHAHANI: Mele assumes the matter will get resolved quickly, but that doesn't happen. He reaches out to a second friend at Facebook thinking, come on, this is silly. And then. . . MELE: And then nothing happened. SHAHANI: Hi, I'm Aarti Shahani with NPR, and I'm here to interview David Marcus. A few weeks after learning of Nyaira's case, I happened to be at Facebook headquarters to interview the head of the Messenger app about a totally different topic, and at the end I brought her up. There's a Messenger user I know. Her name is. . . And without batting an eyelash, the head of Messenger, David Marcus, said he'd look into it. DAVID MARCUS: Of course. And generally those are cases that are really easy to resolve because we have a really good team that looks into these cases and resolve them generally pretty quickly. So I'm shocked that in this specific case, it wasn't done, but of course I'd be more than happy to help solve that. SHAHANI: Facebook is now in the process of contacting Nyaira directly about her account. Meanwhile, in Zimbabwe, a man was arrested as the alleged pedophile. As the country talked about it on Facebook, Sandra Nyaira, whose work helped lead to his capture, could not join in. Aarti Shahani, NPR News, San Francisco. MARTIN: In the course of her reporting, Aarti started a page on Facebook for people to share concerns about the platform. It's called TellZuck. That's facebook. com/tellzuck. We'll link to it at npr. org. RACHEL MARTIN, HOST:  Facebook uses computers to spot pornography and wipe it away in milliseconds. Software is quicker than human beings and cheaper, but mistakes can still happen. That's exactly what happened recently when Facebook mistook a reporter for a child pornographer and expelled her. NPR's Aarti Shahani reports. And a warning - the story does include a description of disturbing images. AARTI SHAHANI, BYLINE: On June 17, 2016, it was Friday afternoon, investigative reporter Sandra Nyaira recalls. She received three photographs, very explicit pictures of two young girls. SANDRA NYAIRA: Yeah, horrible, horrible pictures. SHAHANI: The girls look maybe 7 years old. They're on a bed being sexually abused by a man. NYAIRA: So when I received the pictures, I was pained. I actually cried because I, you know, I looked them and I was like, who does this? Obviously these kids were being abused by someone who was very, very close to them. SHAHANI: According to news sources in Zimbabwe, the country where this is happening, the man takes his phone to a repair shop and a clerk sees the photos in the photo gallery. Now if it were you, you might go to the police. But in Zimbabwe, Nyaira says, people don't trust the police to do their jobs. That's how she winds up with the photos. She's an award-winning reporter, and she wanted to get justice done. Nyaira reaches out to a woman in Parliament, a feminist who demands an investigation and who goes on Facebook to talk about the case. In less than 24 hours, they've launched a national discussion. NYAIRA: So many women in Zimbabwe - women activists and ordinary women - started following the debate and speaking with her, responding to her debate on Facebook. SHAHANI: People reach out to Nyaira to ask how they can help. A fellow journalist says he can tap his sources, get officials he knows involved in the search. So Nyaira decides to share the photos with him on Messenger, Facebook's private chat tool. That was a big mistake. Almost instantly, Facebook computers deactivate her. She realizes, oh, no, they think I'm distributing child pornography. She feels mortified. NYAIRA: Why did you do that? You know, you start blaming yourself, but for not doing anything wrong really, but for trying to help. SHAHANI: Nyaira needs Facebook for her job. It's how she communicates with sources and promotes her stories. She tells herself it'll be OK. I'll contact the company and explain, but she realizes she can't reach a person at Facebook. There is no hotline to call, so she fills out a form on the website which asks her to scan and upload a copy of her passport. She does that, still gets a generic rejection. Nyaira is now more worried. NYAIRA: OK. I have sent Facebook my passport information, so what are they going to do with it? Are they going to go to the police without even talking to me about why they have blocked my account? SHAHANI: She fears she could be arrested. In desperation, she turns to one of the most powerful institutions she knows - Harvard University. She used to be a fellow there at Harvard's Shorenstein Center on Media, even sat at a luncheon with Facebook CEO Mark Zuckerberg there. Nicco Mele directs the center. NICCO MELE: So I reached out to a friend at Facebook and said, hey, is there anything you can do to help us? I can vouch for Sandra. She is the real deal. She wasn't doing anything untoward or anything bad. SHAHANI: Mele assumes the matter will get resolved quickly, but that doesn't happen. He reaches out to a second friend at Facebook thinking, come on, this is silly. And then. . . MELE: And then nothing happened. SHAHANI: Hi, I'm Aarti Shahani with NPR, and I'm here to interview David Marcus. A few weeks after learning of Nyaira's case, I happened to be at Facebook headquarters to interview the head of the Messenger app about a totally different topic, and at the end I brought her up. There's a Messenger user I know. Her name is. . . And without batting an eyelash, the head of Messenger, David Marcus, said he'd look into it. DAVID MARCUS: Of course. And generally those are cases that are really easy to resolve because we have a really good team that looks into these cases and resolve them generally pretty quickly. So I'm shocked that in this specific case, it wasn't done, but of course I'd be more than happy to help solve that. SHAHANI: Facebook is now in the process of contacting Nyaira directly about her account. Meanwhile, in Zimbabwe, a man was arrested as the alleged pedophile. As the country talked about it on Facebook, Sandra Nyaira, whose work helped lead to his capture, could not join in. Aarti Shahani, NPR News, San Francisco. MARTIN: In the course of her reporting, Aarti started a page on Facebook for people to share concerns about the platform. It's called TellZuck. That's facebook. com/tellzuck. We'll link to it at npr. org.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-02-04-513469456": {"title": "When Trump Tweets, This Bot Makes Money : NPR", "url": "https://www.npr.org/2017/02/04/513469456/when-trump-tweets-this-bot-makes-money", "author": "No author found", "published_date": "2017-02-04", "content": "MICHEL MARTIN, HOST: Well, one thing is for sure. People will be mad tweeting during the game tomorrow, and we don't know whether President Trump will be among them. But whether you are a supporter, who thinks the president's tweets keep it real, or a critic, who thinks Trump is crude and mean, you probably noticed by now that the president keeps his followers on their toes because he's unpredictable. But the effect of those tweets is becoming more predictable, according to one company that is trading on them. On Monday, President Trump tweeted that Delta Airlines computer failure was partly to blame for the chaos in airports over the weekend. By the end of the day, Delta's stock was down 4 percent, and one company says it is making a lot of money on that tweet. Ben Gaddis is the president of the advertising company T3. That company has built a bot that analyzes the president's tweets and short sells stocks in companies that he attacks. And we reached Ben Gaddis in Austin. Welcome. BEN GADDIS: Thanks for having me, Michel. MARTIN: So, Ben, just define terms briefly for people who don't follow this stuff. What's a bot? GADDIS: A bot is - it's a program, and it's actually based on an algorithm. And the bot listens to President Trump's tweets. So anytime he tweets, it takes the tweet and determines if there's a publicly traded company in - mentioned in it. And if it's negative, we've seen the stock drop very quickly, so the bot actually shorts that stock in real time. And it all happens in less than 20 milliseconds. MARTIN: Twenty milliseconds. So OK, and for those who don't follow this stuff, what does short selling mean? GADDIS: Short selling means that you essentially buy the stock, or borrow the stock, at a high price predicting that it's going to go down. And then as the stock goes down, you actually buy back shares of that at a lower price and close out your short. And the difference between the two is your profit. MARTIN: So you basically - you're profiting off of the stock dropping in value. . . GADDIS: That's correct. MARTIN: . . . Predicting it's going to drop. You're predicting that it's going to drop in value. So you call your algorithm the Trump and Dump Bot. It's actually able to detect whether a tweet is positive or negative. OK. Now, without giving away any company secrets, how? GADDIS: So we do what's called sentiment analysis, and it's actually a pretty standard practice. We actually use sentiment analysis for our large clients, like UPS and Capital One and Allstate, as we look at their Twitter feeds and social presence. So what we do is we're able to measure, based on key words, the type of sentiment associated with the tweet. So when President Trump tweeted about Toyota, on a scale of one to 100 - one being very negative and 100 being very positive - that tweet had a 17. 9 percent sentiment ranking, meaning it's very low. So we're able to extract that and then put a threshold. And if anything is below that, then we actually make the trade. MARTIN: Now, what would you say to people who might argue that that's kind of a messed up way to earn money? GADDIS: Well, I would say that we agree that the negativity around a stock and their prices going down is not a good thing, but it's happening. And so the bot that we built actually donates all its profits to the ASPCA. So our belief now is if President Trump tweets something negative, we save a puppy. So that's something that I think almost anybody can get behind. MARTIN: OK. Well, that's Ben Gaddis. He is the president of the advertising company - they actually prefer the term innovation company - T3. He was kind enough to join us from Austin, Texas. Ben Gaddis, thanks so much for speaking with us. GADDIS: Thank you, Michel. MICHEL MARTIN, HOST:  Well, one thing is for sure. People will be mad tweeting during the game tomorrow, and we don't know whether President Trump will be among them. But whether you are a supporter, who thinks the president's tweets keep it real, or a critic, who thinks Trump is crude and mean, you probably noticed by now that the president keeps his followers on their toes because he's unpredictable. But the effect of those tweets is becoming more predictable, according to one company that is trading on them. On Monday, President Trump tweeted that Delta Airlines computer failure was partly to blame for the chaos in airports over the weekend. By the end of the day, Delta's stock was down 4 percent, and one company says it is making a lot of money on that tweet. Ben Gaddis is the president of the advertising company T3. That company has built a bot that analyzes the president's tweets and short sells stocks in companies that he attacks. And we reached Ben Gaddis in Austin. Welcome. BEN GADDIS: Thanks for having me, Michel. MARTIN: So, Ben, just define terms briefly for people who don't follow this stuff. What's a bot? GADDIS: A bot is - it's a program, and it's actually based on an algorithm. And the bot listens to President Trump's tweets. So anytime he tweets, it takes the tweet and determines if there's a publicly traded company in - mentioned in it. And if it's negative, we've seen the stock drop very quickly, so the bot actually shorts that stock in real time. And it all happens in less than 20 milliseconds. MARTIN: Twenty milliseconds. So OK, and for those who don't follow this stuff, what does short selling mean? GADDIS: Short selling means that you essentially buy the stock, or borrow the stock, at a high price predicting that it's going to go down. And then as the stock goes down, you actually buy back shares of that at a lower price and close out your short. And the difference between the two is your profit. MARTIN: So you basically - you're profiting off of the stock dropping in value. . . GADDIS: That's correct. MARTIN: . . . Predicting it's going to drop. You're predicting that it's going to drop in value. So you call your algorithm the Trump and Dump Bot. It's actually able to detect whether a tweet is positive or negative. OK. Now, without giving away any company secrets, how? GADDIS: So we do what's called sentiment analysis, and it's actually a pretty standard practice. We actually use sentiment analysis for our large clients, like UPS and Capital One and Allstate, as we look at their Twitter feeds and social presence. So what we do is we're able to measure, based on key words, the type of sentiment associated with the tweet. So when President Trump tweeted about Toyota, on a scale of one to 100 - one being very negative and 100 being very positive - that tweet had a 17. 9 percent sentiment ranking, meaning it's very low. So we're able to extract that and then put a threshold. And if anything is below that, then we actually make the trade. MARTIN: Now, what would you say to people who might argue that that's kind of a messed up way to earn money? GADDIS: Well, I would say that we agree that the negativity around a stock and their prices going down is not a good thing, but it's happening. And so the bot that we built actually donates all its profits to the ASPCA. So our belief now is if President Trump tweets something negative, we save a puppy. So that's something that I think almost anybody can get behind. MARTIN: OK. Well, that's Ben Gaddis. He is the president of the advertising company - they actually prefer the term innovation company - T3. He was kind enough to join us from Austin, Texas. Ben Gaddis, thanks so much for speaking with us. GADDIS: Thank you, Michel.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-02-06-513769927": {"title": "Tech Companies Unite Against Trump Administration's Immigration Ban : NPR", "url": "https://www.npr.org/2017/02/06/513769927/tech-companies-unite-against-trump-administrations-immigration-ban", "author": "No author found", "published_date": "2017-02-06", "content": "ROBERT SIEGEL, HOST:  I'm Robert Siegel with All Tech Considered. (SOUNDBITE OF MUSIC)SIEGEL: Nearly 100 technology companies have signed on to a legal brief challenging President Trump's executive order restricting immigration. The companies include Google, Apple, Facebook and Microsoft, Uber and Lyft. The brief filed in the 9th Circuit Court of Appeals claims the order is discriminatory and will harm American businesses, as NPR's Aarti Shahani reports. AARTI SHAHANI, BYLINE: Companies that are often at odds - suing each other, divided on policy - have joined together, 97 signers in total. And here's a little bit of the backstory on the amicus brief. AARON LEVIE: It got kicked off last weekend by a number of leading technology firms, and then throughout the week, many, many more joined in. SHAHANI: That's Aaron Levie, CEO of Box, a cloud storage company that joined in. Two weekends ago when President Trump's new executive order went clumsily into effect, technology leaders in Silicon Valley began talking to each other about the industry response. Levie says his company didn't have workers turned away at airports, but he does employ people from the seven predominantly-Muslim countries listed in the order. And even if he didn't, he says he doesn't like that the order came out of nowhere. LEVIE: If you look at how hastily this was put together and how little judgment there seems to have been, I think that creates a lot of concern for anybody that we don't know what the next similar orders might be in the future. SHAHANI: The largest tech companies declined interview requests today, saying the brief speaks for itself. But in fact, employees at the same companies tell NPR the companies don't want to risk being singled out and attacked by the president on Twitter. The uncertainty created by the Trump administration has rocked Silicon Valley. Right before the president took office, as Levie explains, tech leaders didn't think he was actually going to follow through on campaign promises to curtail immigration. What he and others thought was. . . LEVIE: Even in the worst case scenario, you know, Trump's rhetoric would actually align with ultimate policy or action, and that it would - you know, meant to really kind of stir up his base and ultimately get elected. SHAHANI: The business leaders argue to the 9th Circuit that Trump's order is a sudden shift that inflicts substantial harm on U. S. companies, and that it puts too much discretion to decide who gets to enter the country in the hands of the government. While the order says there can be case-by-case exceptions, it doesn't lay out the criteria for issuing exceptions. And leaders argue the move gives multinationals a new, significant incentive to set up shop abroad outside the U. S. Aarti Shahani, NPR News, San Francisco. ROBERT SIEGEL, HOST:   I'm Robert Siegel with All Tech Considered. (SOUNDBITE OF MUSIC) SIEGEL: Nearly 100 technology companies have signed on to a legal brief challenging President Trump's executive order restricting immigration. The companies include Google, Apple, Facebook and Microsoft, Uber and Lyft. The brief filed in the 9th Circuit Court of Appeals claims the order is discriminatory and will harm American businesses, as NPR's Aarti Shahani reports. AARTI SHAHANI, BYLINE: Companies that are often at odds - suing each other, divided on policy - have joined together, 97 signers in total. And here's a little bit of the backstory on the amicus brief. AARON LEVIE: It got kicked off last weekend by a number of leading technology firms, and then throughout the week, many, many more joined in. SHAHANI: That's Aaron Levie, CEO of Box, a cloud storage company that joined in. Two weekends ago when President Trump's new executive order went clumsily into effect, technology leaders in Silicon Valley began talking to each other about the industry response. Levie says his company didn't have workers turned away at airports, but he does employ people from the seven predominantly-Muslim countries listed in the order. And even if he didn't, he says he doesn't like that the order came out of nowhere. LEVIE: If you look at how hastily this was put together and how little judgment there seems to have been, I think that creates a lot of concern for anybody that we don't know what the next similar orders might be in the future. SHAHANI: The largest tech companies declined interview requests today, saying the brief speaks for itself. But in fact, employees at the same companies tell NPR the companies don't want to risk being singled out and attacked by the president on Twitter. The uncertainty created by the Trump administration has rocked Silicon Valley. Right before the president took office, as Levie explains, tech leaders didn't think he was actually going to follow through on campaign promises to curtail immigration. What he and others thought was. . . LEVIE: Even in the worst case scenario, you know, Trump's rhetoric would actually align with ultimate policy or action, and that it would - you know, meant to really kind of stir up his base and ultimately get elected. SHAHANI: The business leaders argue to the 9th Circuit that Trump's order is a sudden shift that inflicts substantial harm on U. S. companies, and that it puts too much discretion to decide who gets to enter the country in the hands of the government. While the order says there can be case-by-case exceptions, it doesn't lay out the criteria for issuing exceptions. And leaders argue the move gives multinationals a new, significant incentive to set up shop abroad outside the U. S. Aarti Shahani, NPR News, San Francisco.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-02-08-514049699": {"title": "Update On The Journalist Kicked Off Facebook : NPR", "url": "https://www.npr.org/2017/02/08/514049699/update-on-the-journalist-kicked-off-facebook", "author": "No author found", "published_date": "2017-02-08", "content": "STEVE INSKEEP, HOST: We have an update on the investigative journalist who was kicked off Facebook. She's a reporter from Zimbabwe. And as we have reported, she was in the midst of working on a story about child abuse when Facebook's software detected her activity and expelled her. NPR'S Aarti Shahani reports on what's happened since. AARTI SHAHANI, BYLINE: Sandra Nyaira got kicked off about eight months ago. She was investigating a child abuser. She tried to use Facebook Messenger, the private chat tool, to share pictures of two little girls being abused with a fellow journalist. And Facebook's computer software did not approve. Nyaira pleaded to Facebook through emails and forms, but her pleas went nowhere - until, that is, last week. SANDRA NYAIRA: When Facebook - you know, when they called me to say they wanted to talk to me. . . SHAHANI: That was a big surprise. NYAIRA: (Laughter) It was. SHAHANI: Nyaira was contacted by three Facebook employees. It was quite multinational. One employee was in London, the other in Nigeria and the last in South Africa. Two of them set up a time to interview Nyaira by video chat. NYAIRA: Yeah, it was long meeting. It started by them, you know, explaining to me their policies as Facebook. SHAHANI: The meeting lasted 45 minutes, Nyaira says. And the Facebook officials spent a chunk of that time laying out the ban on child pornography, a ban Nyaira agrees with wholeheartedly. The officials did not explain why her many efforts to get reinstated failed, why she slipped through their cracks. NYAIRA: No. No, no, no, no. They didn't explain the mistake. But of course, you know, I could read in between the lines. Without saying it in words, they were accepting that, you know, it was a mistake. SHAHANI: The mistake was not blocking her from sharing the horrific pictures. It was keeping her expelled despite the circumstances of her case. Nyaira let me be there on the phone as she logged back in after so many months away. NYAIRA: I hope I remember the password. SHAHANI: And an interesting thing happened when she got back on. In an earlier interview, perhaps out of frustration, Nyaira said she didn't need Facebook in her life - good riddance. But now, she got downright giddy scrolling through her newsfeed. The first post that caught her eye was spiritual. NYAIRA: When in doubt, pray it out. SHAHANI: Nyaira is a Christian. And it turns out she really missed this one Facebook group for Christian women who share their everyday struggles and prayers. She also loves seeing what her colleagues in other countries were doing. One friend had a baby. Another was giving a talk on anti-terrorism in Africa. The feeling she's having, the feeling of being sent to the corner and then allowed to come back to the group, it's palpable. NYAIRA: I realized - you know what? - there are things that you cannot do by yourself. You - we live in communities. And this is the biggest ever community that we have. You are connected to people all over the world. SHAHANI: For now, Nyaira can look but not post. She has to wait 72 hours after her first login to start messaging her friends again. Aarti Shahani, NPR News, San Francisco. (SOUNDBITE OF ARM AND SLEEPERS' \"WHEN THE BODY\") STEVE INSKEEP, HOST:  We have an update on the investigative journalist who was kicked off Facebook. She's a reporter from Zimbabwe. And as we have reported, she was in the midst of working on a story about child abuse when Facebook's software detected her activity and expelled her. NPR'S Aarti Shahani reports on what's happened since. AARTI SHAHANI, BYLINE: Sandra Nyaira got kicked off about eight months ago. She was investigating a child abuser. She tried to use Facebook Messenger, the private chat tool, to share pictures of two little girls being abused with a fellow journalist. And Facebook's computer software did not approve. Nyaira pleaded to Facebook through emails and forms, but her pleas went nowhere - until, that is, last week. SANDRA NYAIRA: When Facebook - you know, when they called me to say they wanted to talk to me. . . SHAHANI: That was a big surprise. NYAIRA: (Laughter) It was. SHAHANI: Nyaira was contacted by three Facebook employees. It was quite multinational. One employee was in London, the other in Nigeria and the last in South Africa. Two of them set up a time to interview Nyaira by video chat. NYAIRA: Yeah, it was long meeting. It started by them, you know, explaining to me their policies as Facebook. SHAHANI: The meeting lasted 45 minutes, Nyaira says. And the Facebook officials spent a chunk of that time laying out the ban on child pornography, a ban Nyaira agrees with wholeheartedly. The officials did not explain why her many efforts to get reinstated failed, why she slipped through their cracks. NYAIRA: No. No, no, no, no. They didn't explain the mistake. But of course, you know, I could read in between the lines. Without saying it in words, they were accepting that, you know, it was a mistake. SHAHANI: The mistake was not blocking her from sharing the horrific pictures. It was keeping her expelled despite the circumstances of her case. Nyaira let me be there on the phone as she logged back in after so many months away. NYAIRA: I hope I remember the password. SHAHANI: And an interesting thing happened when she got back on. In an earlier interview, perhaps out of frustration, Nyaira said she didn't need Facebook in her life - good riddance. But now, she got downright giddy scrolling through her newsfeed. The first post that caught her eye was spiritual. NYAIRA: When in doubt, pray it out. SHAHANI: Nyaira is a Christian. And it turns out she really missed this one Facebook group for Christian women who share their everyday struggles and prayers. She also loves seeing what her colleagues in other countries were doing. One friend had a baby. Another was giving a talk on anti-terrorism in Africa. The feeling she's having, the feeling of being sent to the corner and then allowed to come back to the group, it's palpable. NYAIRA: I realized - you know what? - there are things that you cannot do by yourself. You - we live in communities. And this is the biggest ever community that we have. You are connected to people all over the world. SHAHANI: For now, Nyaira can look but not post. She has to wait 72 hours after her first login to start messaging her friends again. Aarti Shahani, NPR News, San Francisco. (SOUNDBITE OF ARM AND SLEEPERS' \"WHEN THE BODY\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-02-09-514175464": {"title": "John Kelly, Homeland Security Secretary, Says Travel Vetting Could Include Passwords, Tweets : NPR", "url": "https://www.npr.org/2017/02/09/514175464/homeland-security-secretary-travel-vetting-could-include-passwords-tweets", "author": "No author found", "published_date": "2017-02-09", "content": "STEVE INSKEEP, HOST: President Trump has made a point of talking about how much he respects the retired generals in his Cabinet. Secretary of Homeland Security John Kelly is at the top of that list. RACHEL MARTIN, HOST: But only a week or so into the administration, their relationship had its first big test when the president signed the executive order on immigration. It was pushed through fast - so fast that there was confusion at airports across the country and around the world about who could and could not come into the U. S. INSKEEP: Fixing the chaos felt to Secretary John Kelly. This week, when he was testifying before a congressional committee, the retired Marine Corps general took blame for the way it was rolled out. (SOUNDBITE OF ARCHIVED RECORDING)JOHN KELLY: I should have - this is all on me, by the way. I should have delayed it just a bit so that I could talk to members of Congress, particularly the leadership of committees like this. MARTIN: In the days that followed the rollout and widespread protest, the Department of Homeland Security modified the order. Exceptions were carved out for green card holders and Iraqis who had worked alongside the U. S. military. I sat down with Secretary John Kelly yesterday in our studios to talk about the ban, what he would do differently and his belief that tightening the borders doesn't mean changing who we are. KELLY: The reason we're doing this is to just really take a pause, take a hard look at how we vet people overseas. Again, the seven countries involved here were identified, you know, by the United States Congress. And the seven countries were identified by the Obama administration, so it's certainly a good start point. MARTIN: Starting point - does that mean you expect to expand the list of countries? KELLY: You know, I don't. But again, we're looking. In some cases - particularly with these seven countries, because of the chaos and disorder they're in internally, we may not be able to get there for a while. In other cases among the seven countries, I think it's entirely possible one or two could come off at the end of the evaluation period. MARTIN: So what does that change look like? Can you give me some specifics? KELLY: Yeah. MARTIN: We hear the president talking a lot about extreme vetting. But what does that mean on the ground? KELLY: Yeah. You know, pick a country. The thing that we're looking for is when a person comes in, the State Department does these interviews. Someone comes in and says, I want to come to the United States. Then we ask them to give us a list of websites that they visit and the passwords to get on those websites to see what they're looking at. This is. . . MARTIN: You require that of anyone who is looking to immigrate to the U. S. ? KELLY: Well, considering that, yeah - social media to see what they tweet; cell phones - cell phone conversations or cell phone contact books to where we can run them against databases, telephone numbers, people's names. Europe, the United States maintains databases and shares those databases. So these are some of the things we're thinking about. MARTIN: And you're thinking about them as it pertains to these seven countries and places where refugees are fleeing from. But also, do I hear you saying it could be expanded? KELLY: It could be, yeah. It could be. It all comes down to the confidence we have in the individual we're talking to is a person who is coming to the United States for the right reasons. MARTIN: When you were before Congress this week, you said that it was your responsibility - that you took the blame for not delaying the implementation of the ban so you could inform Congress of what it was really going to look like. KELLY: Yeah. MARTIN: Does that extend to how it was rolled out? KELLY: You know, I'm new to this, this federal civilian side. You know, my first real day at work was Monday that week. I had a small number of staff at Homeland Security that were working with the White House in the final stages of the development of the three EOs, executive orders. That was consistent with certainly most things that the president had said during the election, and then I knew it was coming out on Friday. In retrospect, I should have said - and I will do in the future for sure - to say, OK, give that to me, and I will roll it out. And I will tell you how I'm going to do it. But I will roll that out. And that rollout would have included notification to select members of Congress - the leadership for sure, as I say - and even a press rollout. I mean, I think it's very, very important to engage the press. MARTIN: Did you communicate this now to the White House? Does the White House understand that, moving forward, that this is how you'd like to operate? KELLY: I would say that we have an agreement. We developed a policy jointly. It goes to the president. He says OK, I like this. Go with it. Once you've given it - again, this is kind of a military thing - once you give it to the commander to execute, get out of the way. I'll keep you informed. So in future, we will do it a better way. MARTIN: More than a hundred former national security officials that served under presidents from both parties signed a letter. It was addressed to you, as one of three recipients, saying that this executive order makes America less safe. And the signatories included former acting heads at State and Justice Departments. They are people who you know, people you have worked with. Did that give you pause? KELLY: Well, I haven't seen the letter yet. What did it say? MARTIN: It said that the executive order puts America at risk, that it reinforces a narrative about the West being embroiled in a battle with ISIS that ISIS welcomes because it reinforces the story they use to recruit. KELLY: Yeah. You know, with respect to well-meaning people who signed the letter, you know, I ran Guantanamo, as you know. If that logic is accurate, then, you know, why did 9/11 happened? Because we - I mean, there are people in the world - a small, small percentage of people who follow a different radical Islamic faith, who hate us. And they hate us for a lot of different reasons. And I say it all the time - it's because of who we are, the way we live our lives, the way we worship any god we want or no god. They just hate us. MARTIN: Do you think that in light of what you just said and the security risks that are out there, can America still afford to be a multicultural, pluralistic society? KELLY: Can we still afford to be? Of course. You know, the great success of our country has been people from diverse backgrounds coming to the United States and becoming Americans. The strength has been the melting pot. So I like to think everyone in this country should consider themselves Irish on St. Patrick's Day. Everyone in this country should consider themselves Jewish at Hanukkah. Everyone in this country should consider themselves. . . MARTIN: Muslim on Eid. KELLY: On Eid. Every one of them. I've been to Eid dinners where we were almost blown up to get there in Iraq. Sure, they go to a mosque or they go to a synagogue or a church. But 364 days a year, they're Americans. And then on the day that we celebrate being Irish or Jewish or Muslim, then we're all Irish or Jewish or Muslim - or Mexican on Cinco de Mayo. MARTIN: So much of this is about who is able to come into this country and who is not. And also under your purview as secretary of Homeland Security is the U. S. -Mexico border. President Trump, this week, said when he talked to police chiefs that the wall is currently under design. This is something that Congress has yet to approve - and that's constitutionally mandated. KELLY: Right, of course. MARTIN: There is no plan yet on how to pay for this. Is the wall currently under design? KELLY: What I'm doing - in fact, I was down on the Texas border last week, met with the Texas governor, his public safety people. And I go to the Tucson sector of the border and meet with, again, sheriffs, local police. MARTIN: So you've got meetings. KELLY: I got what? MARTIN: But is the wall currently under design? KELLY: Absolute - well, the wall is, I'd say, designed but, first, evaluations. So what are they telling me? What do I CBP, the great men and women of the Customs and Border Protection, what are they telling me? They're saying - hey, boss, I'm sure a wall will be great. Barrier would be great may be a better way to say it right now. MARTIN: So what does the president mean when he says the wall is being designed? KELLY: We're in the process now of deciding - you know, we can't build it all at once in the same place. But we're deciding where to put it immediately given financing and given, you know, construction capability, capacity. MARTIN: Retired Marine Corps General John Kelly - he is now the secretary of Homeland Security. Thank you so much for coming in, sir. KELLY: Of course. Anytime, Rachel. Thanks a lot. STEVE INSKEEP, HOST:  President Trump has made a point of talking about how much he respects the retired generals in his Cabinet. Secretary of Homeland Security John Kelly is at the top of that list. RACHEL MARTIN, HOST:  But only a week or so into the administration, their relationship had its first big test when the president signed the executive order on immigration. It was pushed through fast - so fast that there was confusion at airports across the country and around the world about who could and could not come into the U. S. INSKEEP: Fixing the chaos felt to Secretary John Kelly. This week, when he was testifying before a congressional committee, the retired Marine Corps general took blame for the way it was rolled out. (SOUNDBITE OF ARCHIVED RECORDING) JOHN KELLY: I should have - this is all on me, by the way. I should have delayed it just a bit so that I could talk to members of Congress, particularly the leadership of committees like this. MARTIN: In the days that followed the rollout and widespread protest, the Department of Homeland Security modified the order. Exceptions were carved out for green card holders and Iraqis who had worked alongside the U. S. military. I sat down with Secretary John Kelly yesterday in our studios to talk about the ban, what he would do differently and his belief that tightening the borders doesn't mean changing who we are. KELLY: The reason we're doing this is to just really take a pause, take a hard look at how we vet people overseas. Again, the seven countries involved here were identified, you know, by the United States Congress. And the seven countries were identified by the Obama administration, so it's certainly a good start point. MARTIN: Starting point - does that mean you expect to expand the list of countries? KELLY: You know, I don't. But again, we're looking. In some cases - particularly with these seven countries, because of the chaos and disorder they're in internally, we may not be able to get there for a while. In other cases among the seven countries, I think it's entirely possible one or two could come off at the end of the evaluation period. MARTIN: So what does that change look like? Can you give me some specifics? KELLY: Yeah. MARTIN: We hear the president talking a lot about extreme vetting. But what does that mean on the ground? KELLY: Yeah. You know, pick a country. The thing that we're looking for is when a person comes in, the State Department does these interviews. Someone comes in and says, I want to come to the United States. Then we ask them to give us a list of websites that they visit and the passwords to get on those websites to see what they're looking at. This is. . . MARTIN: You require that of anyone who is looking to immigrate to the U. S. ? KELLY: Well, considering that, yeah - social media to see what they tweet; cell phones - cell phone conversations or cell phone contact books to where we can run them against databases, telephone numbers, people's names. Europe, the United States maintains databases and shares those databases. So these are some of the things we're thinking about. MARTIN: And you're thinking about them as it pertains to these seven countries and places where refugees are fleeing from. But also, do I hear you saying it could be expanded? KELLY: It could be, yeah. It could be. It all comes down to the confidence we have in the individual we're talking to is a person who is coming to the United States for the right reasons. MARTIN: When you were before Congress this week, you said that it was your responsibility - that you took the blame for not delaying the implementation of the ban so you could inform Congress of what it was really going to look like. KELLY: Yeah. MARTIN: Does that extend to how it was rolled out? KELLY: You know, I'm new to this, this federal civilian side. You know, my first real day at work was Monday that week. I had a small number of staff at Homeland Security that were working with the White House in the final stages of the development of the three EOs, executive orders. That was consistent with certainly most things that the president had said during the election, and then I knew it was coming out on Friday. In retrospect, I should have said - and I will do in the future for sure - to say, OK, give that to me, and I will roll it out. And I will tell you how I'm going to do it. But I will roll that out. And that rollout would have included notification to select members of Congress - the leadership for sure, as I say - and even a press rollout. I mean, I think it's very, very important to engage the press. MARTIN: Did you communicate this now to the White House? Does the White House understand that, moving forward, that this is how you'd like to operate? KELLY: I would say that we have an agreement. We developed a policy jointly. It goes to the president. He says OK, I like this. Go with it. Once you've given it - again, this is kind of a military thing - once you give it to the commander to execute, get out of the way. I'll keep you informed. So in future, we will do it a better way. MARTIN: More than a hundred former national security officials that served under presidents from both parties signed a letter. It was addressed to you, as one of three recipients, saying that this executive order makes America less safe. And the signatories included former acting heads at State and Justice Departments. They are people who you know, people you have worked with. Did that give you pause? KELLY: Well, I haven't seen the letter yet. What did it say? MARTIN: It said that the executive order puts America at risk, that it reinforces a narrative about the West being embroiled in a battle with ISIS that ISIS welcomes because it reinforces the story they use to recruit. KELLY: Yeah. You know, with respect to well-meaning people who signed the letter, you know, I ran Guantanamo, as you know. If that logic is accurate, then, you know, why did 9/11 happened? Because we - I mean, there are people in the world - a small, small percentage of people who follow a different radical Islamic faith, who hate us. And they hate us for a lot of different reasons. And I say it all the time - it's because of who we are, the way we live our lives, the way we worship any god we want or no god. They just hate us. MARTIN: Do you think that in light of what you just said and the security risks that are out there, can America still afford to be a multicultural, pluralistic society? KELLY: Can we still afford to be? Of course. You know, the great success of our country has been people from diverse backgrounds coming to the United States and becoming Americans. The strength has been the melting pot. So I like to think everyone in this country should consider themselves Irish on St. Patrick's Day. Everyone in this country should consider themselves Jewish at Hanukkah. Everyone in this country should consider themselves. . . MARTIN: Muslim on Eid. KELLY: On Eid. Every one of them. I've been to Eid dinners where we were almost blown up to get there in Iraq. Sure, they go to a mosque or they go to a synagogue or a church. But 364 days a year, they're Americans. And then on the day that we celebrate being Irish or Jewish or Muslim, then we're all Irish or Jewish or Muslim - or Mexican on Cinco de Mayo. MARTIN: So much of this is about who is able to come into this country and who is not. And also under your purview as secretary of Homeland Security is the U. S. -Mexico border. President Trump, this week, said when he talked to police chiefs that the wall is currently under design. This is something that Congress has yet to approve - and that's constitutionally mandated. KELLY: Right, of course. MARTIN: There is no plan yet on how to pay for this. Is the wall currently under design? KELLY: What I'm doing - in fact, I was down on the Texas border last week, met with the Texas governor, his public safety people. And I go to the Tucson sector of the border and meet with, again, sheriffs, local police. MARTIN: So you've got meetings. KELLY: I got what? MARTIN: But is the wall currently under design? KELLY: Absolute - well, the wall is, I'd say, designed but, first, evaluations. So what are they telling me? What do I CBP, the great men and women of the Customs and Border Protection, what are they telling me? They're saying - hey, boss, I'm sure a wall will be great. Barrier would be great may be a better way to say it right now. MARTIN: So what does the president mean when he says the wall is being designed? KELLY: We're in the process now of deciding - you know, we can't build it all at once in the same place. But we're deciding where to put it immediately given financing and given, you know, construction capability, capacity. MARTIN: Retired Marine Corps General John Kelly - he is now the secretary of Homeland Security. Thank you so much for coming in, sir. KELLY: Of course. Anytime, Rachel. Thanks a lot.", "section": "Politics", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-02-10-514566974": {"title": "'Wired' Declares Coding As Next Blue-Collar Job Boom : NPR", "url": "https://www.npr.org/2017/02/10/514566974/wired-declares-coding-as-next-blue-collar-job-boom", "author": "No author found", "published_date": "2017-02-10", "content": "KELLY MCEVERS, HOST: This week an article on wired. com declared that the next blue collar job is coding - like computer languages, making websites and programming apps. The author of the piece is Clive Thompson. He's a tech writer, and he's working on a book about how coders think. He joins us from New York. Welcome. CLIVE THOMPSON: Hi. MCEVERS: So one part of your argument is about lifestyle. You say do not picture coders as these, like, Mark Zuckerberg types who are, you know, taking big risks for big rewards. Instead you say we should picture, like, stable straightforward office jobs. Explain that. THOMPSON: Yeah. There's this, I guess, popular, almost romantic idea of the coder as this lone hero who's just sort of sitting there and, you know, frantically bashing out this amazing code that makes this amazing app. But the truth is, you know, an awful lot of programming doesn't really require or need that type of, you know, crazy pouring out of creativity. It's more like, I guess, maintenance or the slow, stable, making sure that a company is sort of moving along, that its software is working. You know, like your local bank has a login page. And that page is written in HTML and JavaScript. And, you know, every few months someone has to make sure that any changes to the way JavaScript works, you know, it's compliant with them. And that is a - that's actually a quite intellectually interesting job, but it's not the type of thing people think about when they think, you know, programmer. MCEVERS: So are you saying that a lot of the coding jobs are not actually in Silicon Valley, that they're out at the local bank and other places across the country? THOMPSON: Yeah, that's exactly right. In fact, Silicon Valley really - in that area really only employs about maybe 8 percent of the nation's coders and programmers. The rest are all over the place, every, you know, town of any size. MCEVERS: You peace talks about education. And I wonder how much education do you need for this kind of work? Do you have to have a four-year college degree? THOMPSON: Probably not. You know, you could really easily be trained to at least start in on that work with a much shorter community college degree or even one of these, quote, unquote, \"boot camps,\" like - where you leave your job and you spend three to six months, you know, very intensively 9 a. m. to 9 in the evening studying and being taught programming. And at the end of it, you are, you know, qualified enough to sort of take a junior position. And those programs are growing quite rapidly. And many of them have extremely good hiring rates. MCEVERS: Because obviously one of the huge issues in the election last year was the changing economy, the loss of so many blue collar jobs over the years. Because I've spent some time, you know, before and during and since the election talking to people in some of these parts of the country, and they're just like, you know, you can talk about retraining, but I don't see it. Like, you know what I mean? THOMPSON: Yeah. MCEVERS: So give me an example of a place where that's happened and where it's worked. THOMPSON: Sure. Well, a really fun example is done in coal country, a guy named Rusty Justice (ph). He'd been a coal miner involved in mining for 30 years. And he saw all the jobs vanishing. He knew that the demand for coal's going down. But he also knew that coal miners are in many ways really terrific at the types of things you need to do to be a good programmer. They're patient. They can sit in one place for 10 hours. You know, that's what you do when you're down in a mine. They are accustomed to working with technology. As he told me, coal miners are just tech workers who get dirty. And so he decided he was going to set up a new company. He was going to hire, you know, these coal miners to become coders, to learn JavaScript and Python and all these languages that you use to make apps and websites. And then he would have, you know, a shop that would go out and do work for clients. And he - it's been working. He - in fact, he had a small handful of positions that he got hundreds and hundreds of applications from coal miners who wanted to do this. MCEVERS: Clive Thompson wrote about coding as blue collar work for Wired. Thanks for coming on. THOMPSON: Glad to be here. (SOUNDBITE OF APHEX TWIN SONG, \"ALBERTO BALSALM\") KELLY MCEVERS, HOST:  This week an article on wired. com declared that the next blue collar job is coding - like computer languages, making websites and programming apps. The author of the piece is Clive Thompson. He's a tech writer, and he's working on a book about how coders think. He joins us from New York. Welcome. CLIVE THOMPSON: Hi. MCEVERS: So one part of your argument is about lifestyle. You say do not picture coders as these, like, Mark Zuckerberg types who are, you know, taking big risks for big rewards. Instead you say we should picture, like, stable straightforward office jobs. Explain that. THOMPSON: Yeah. There's this, I guess, popular, almost romantic idea of the coder as this lone hero who's just sort of sitting there and, you know, frantically bashing out this amazing code that makes this amazing app. But the truth is, you know, an awful lot of programming doesn't really require or need that type of, you know, crazy pouring out of creativity. It's more like, I guess, maintenance or the slow, stable, making sure that a company is sort of moving along, that its software is working. You know, like your local bank has a login page. And that page is written in HTML and JavaScript. And, you know, every few months someone has to make sure that any changes to the way JavaScript works, you know, it's compliant with them. And that is a - that's actually a quite intellectually interesting job, but it's not the type of thing people think about when they think, you know, programmer. MCEVERS: So are you saying that a lot of the coding jobs are not actually in Silicon Valley, that they're out at the local bank and other places across the country? THOMPSON: Yeah, that's exactly right. In fact, Silicon Valley really - in that area really only employs about maybe 8 percent of the nation's coders and programmers. The rest are all over the place, every, you know, town of any size. MCEVERS: You peace talks about education. And I wonder how much education do you need for this kind of work? Do you have to have a four-year college degree? THOMPSON: Probably not. You know, you could really easily be trained to at least start in on that work with a much shorter community college degree or even one of these, quote, unquote, \"boot camps,\" like - where you leave your job and you spend three to six months, you know, very intensively 9 a. m. to 9 in the evening studying and being taught programming. And at the end of it, you are, you know, qualified enough to sort of take a junior position. And those programs are growing quite rapidly. And many of them have extremely good hiring rates. MCEVERS: Because obviously one of the huge issues in the election last year was the changing economy, the loss of so many blue collar jobs over the years. Because I've spent some time, you know, before and during and since the election talking to people in some of these parts of the country, and they're just like, you know, you can talk about retraining, but I don't see it. Like, you know what I mean? THOMPSON: Yeah. MCEVERS: So give me an example of a place where that's happened and where it's worked. THOMPSON: Sure. Well, a really fun example is done in coal country, a guy named Rusty Justice (ph). He'd been a coal miner involved in mining for 30 years. And he saw all the jobs vanishing. He knew that the demand for coal's going down. But he also knew that coal miners are in many ways really terrific at the types of things you need to do to be a good programmer. They're patient. They can sit in one place for 10 hours. You know, that's what you do when you're down in a mine. They are accustomed to working with technology. As he told me, coal miners are just tech workers who get dirty. And so he decided he was going to set up a new company. He was going to hire, you know, these coal miners to become coders, to learn JavaScript and Python and all these languages that you use to make apps and websites. And then he would have, you know, a shop that would go out and do work for clients. And he - it's been working. He - in fact, he had a small handful of positions that he got hundreds and hundreds of applications from coal miners who wanted to do this. MCEVERS: Clive Thompson wrote about coding as blue collar work for Wired. Thanks for coming on. THOMPSON: Glad to be here. (SOUNDBITE OF APHEX TWIN SONG, \"ALBERTO BALSALM\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-02-10-514158225": {"title": "Jennifer Brea: Can The Internet Help You Get The Right Diagnosis?  : NPR", "url": "https://www.npr.org/2017/02/10/514158225/can-the-internet-help-you-get-the-right-diagnosis", "author": "No author found", "published_date": "2017-02-10", "content": "GUY RAZ, HOST: Earlier in the show, we heard from Jennifer Brea who caught a virus on a trip to Kenya and came down with a really high fever. JENNIFER BREA: At its highest was 104. 7 degrees. RAZ: But Jen never got better. She started getting strange symptoms. She would feel dizzy and numb. And she'd have moments when she couldn't even speak or write. She went from doing 20-mile bike rides to collapsing after just a short walk. BREA: And it just kind of got worse and worse and worse. RAZ: Jen went to all kinds of specialists who didn't know what was wrong with her. And then one of them came up with a diagnosis, conversion disorder. BREA: He told me, everything that you've been experiencing is psychosomatic, that the symptoms are real but that they have no biological cause. RAZ: That diagnosis, the idea that her symptoms were all in her head, left Jen feeling even more helpless. And then on top of that, she would later find out that her diagnosis, conversion disorder, used to be called hysteria. Jennifer Brea picks up the story from the TED stage. (SOUNDBITE OF TED TALK)BREA: When my doctor diagnosed me with conversion disorder, he was invoking a lineage of ideas about women's bodies that are over 2,500 years old. The Roman physician Galen thought that hysteria was caused by sexual deprivation in particularly passionate women. The Greeks thought that the uterus would literally dry up and wander around the body in search of moisture, pressing on internal organs - yes (laughter) - causing symptoms from extreme emotions to dizziness then paralysis. These ideas went largely unchanged for several millennia, until the 1880s when neurologists tried to modernize the theory of hysteria. Sigmund Freud developed a theory that the unconscious mind could produce physical symptoms when dealing with memories or emotions too painful for the conscious mind to handle. It converted these emotions into physical symptoms. This meant that men can now get hysteria. But of course, women were still the most susceptible. Why has this idea had such staying power? I do think it has to do with sexism. But I also think that, fundamentally, doctors want to help. They want to know the answer. And this category allows doctors to treat what would otherwise be untreatable, to explain illnesses that have no explanation. The problem is that this can cause real harm. In the 1950s, a psychiatrist named Eliot Slater studied a cohort at 85 patients who had been diagnosed with hysteria. Nine years later, 12 of them were dead and 30 had become disabled. Many had undiagnosed conditions, like multiple sclerosis, epilepsy, brain tumors. In 1980 hysteria was officially renamed conversion disorder. When my neurologist gave me that diagnosis in 2012, he was echoing Freud's words verbatim. The problem with the theory of hysteria, or psychogenic illness, is that it can never be proven. It is, by definition, the absence of evidence. RAZ: Jen, of course, didn't believe she had conversion disorder. But she had trouble convincing doctors that her symptoms were serious. BREA: I had this problem of when I was well enough to go to a doctor, I would look pretty normal. And then when I was experiencing my symptoms, I would never be able to go in. RAZ: So she decided to start filming herself at home with her iPhone. (SOUNDBITE OF VIDEO)BREA: I don't think I can get up off the couch. And when I was able to bring in these videos. . . (SOUNDBITE OF VIDEO)BREA: The right side of my face feels numb. I fell like my brain is misfiring. It just - it changed the conversation when they could really see what it was like. RAZ: Yeah. (SOUNDBITE OF VIDEO)BREA: I figure it's good to just keep documenting. OK. Turn off the light. RAZ: But even then, her doctors couldn't make sense of her symptoms. BREA: So, like, in the doctor's office, there was all of these strange symptoms that had no pattern, that they couldn't understand or describe or categorize or name. RAZ: So Jen did something that a lot of doctors don't particularly like. BREA: I think one of the most annoying things for doctors that a patient can do is go on the internet and Google their symptoms. (LAUGHTER)BREA: And even though oftentimes I was Googling PubMed and Nature and Science and bringing them into my doctors, there was the sense that, you know, the internet is really unreliable, which it is. It's like a Wild West. And you'll find all kinds of information. RAZ: But along with those studies, Jen found something else online. BREA: There are literally thousands of people that all have the same pattern of symptoms. RAZ: The same symptoms Jen's doctors couldn't make sense of. BREA: This community of people who all had ME, myalgic encephalomyelitis. RAZ: Myalgic encephalomyelitis, a disease that seemed to fit with the symptoms Jen was experiencing - so through that online community, Jen connected with ME experts across the country. BREA: I found a doctor in Boston at Mass General, a doctor in Miami, in New York, a doctor in Nevada and a doctor in California. So I've actually been (laughter) diagnosed five times with ME. RAZ: Why is it so difficult to diagnose? BREA: It's difficult to diagnose because it's not really a part of the medical school curricula. So at most medical schools, you're not required to learn about the symptoms and the pathophysiology of the disease. So one doctor that I saw in Miami - when she was a professor in immunology, she had to sort of teach medical students during their lunch hour because it wasn't a part of the curriculum. (SOUNDBITE OF TED TALK)BREA: Myalgic encephalomyelitis - you've probably heard it called chronic fatigue syndrome. The key symptom we all share is that whenever we exert ourselves, physically, mentally, we pay and we pay hard. If my husband goes for a run, he might be sore for a couple of days. If I try to walk half a block, I might be bedridden for a week. It is the perfect custom prison. I know ballet dancers who can't dance, accountants who can't add, medical students who never became doctors. It doesn't matter what you once were. You can't do it any more. It's estimated that about 15 to 30 million people around the world have this disease. In the U. S. , where I'm from, it's about 1 million people. That makes it roughly twice as common as multiple sclerosis. Patients can live for decades with the physical function of someone with congestive heart failure. Twenty-five percent of us are homebound or bedridden and 75 to 85 percent of us can't even work part time. How could a disease this common and this devastating have been forgotten by medicine? All around the world, ME is one of the least-funded diseases. So in the U. S. , we spend each year roughly $2,500 per AIDS patient, $250 per MS patient and just $5 per year per ME patient. (SOUNDBITE OF MUSIC)RAZ: It feels like ME patients face this kind of dilemma. Because it's sort of mysterious, no one is funding research into it. But then the only way to figure out what the mystery is is to fund it, right? BREA: Yeah. It's this sort of really weird situation where people say, well, we don't know anything about it yet. And I - whenever anyone says that to me, I kind of feel like I'm standing next to this, like, giant rock and everyone's like, well, we don't know what's underneath that rock. Like, what could possibly be under that? And like, lift it up. Just, like, lift it up and look, you know? You can't answer the questions that you don't ask. You can't understand what you don't study. You can't find what you're not looking for. RAZ: Yeah. And I wonder if, like, on a more personal level, you were - like, you were going to this process constantly where you were asking yourself, like, you know, what's wrong with me? What's happening to me? And then finding this community of people online probably made you feel like you weren't the only one asking those questions. BREA: You know, it's a funny thing because being able to connect to people who are sharing your experience is profound. I thought I had a rare disease. For those first two years, I thought maybe I'm dying. No one could tell me what my prognosis was. No one could tell me what this was going to be like. Even if in that moment what I was grappling with felt so big and so terrifying that I wouldn't survive it, the fact that other people had gone through that and had survived gave me hope that I would be able to find a way. RAZ: What else - what else gives you hope? BREA: I think what is hard to sort of see from the outside is that humans are really adaptable, and I've kind of grown into this. And so on the one hand, every day I try to live the life that I have as well as I possibly can. I'm also fighting for a better life at the same time. And I know that there are so many drugs I have never tried. I know that there are so many experiments that have never been run. And so I believe that if we just started trying to answer these basic questions that we could find treatments and explanations for this disease within a matter of years. So I think that I could get a lot better and I think that I could get a lot better while I'm still young, and that's really what I'm fighting for every day. RAZ: That's Jennifer Brea. You can see her entire talk at ted. com. And by the way, those iPhone videos she took of herself at home, those actually inspired her to make a documentary about chronic fatigue syndrome. It's done mostly from her bedside at home. It's called \"Unrest,\" and it premiered earlier this year at Sundance. (SOUNDBITE OF SONG, \"DOCTOR, DOCTOR\")THE WHO: (Singing) Doctor, there's something wrong with me. My health is not all that it used to be. My heart is out of beat. I got chokers on my feet. My eyesight's getting dimmer. I can't see. RAZ: Thanks for listening to our show, Getting Better, this week. If you want to find out more about who was on it, go to ted. npr. org. To see hundreds more TED talks, check out ted. com or the TED app. Our production staff at NPR includes Jeff Rogers, Brent Baughman, Megan Kane, Neva Grant, Sanaz Meshkinpour, Casey Herman, Rachel Faulkner and Rund Abdel-Fattah (ph), with help from Camilo Garzon and Daniel Shukin. Our intern is Thomas Lu. Our partners at TED Chris Anderson, Kelly Stoetzel, Anna Phelan and Janet Lee. If you want to let us know what you think about the show, you can write us at tedradiohour@npr. org. And you can follow us on Twitter. It's @TEDRadioHour. I'm Guy Raz, and you've been listening to ideas worth spreading right here on the TED Radio Hour from NPR. GUY RAZ, HOST:  Earlier in the show, we heard from Jennifer Brea who caught a virus on a trip to Kenya and came down with a really high fever. JENNIFER BREA: At its highest was 104. 7 degrees. RAZ: But Jen never got better. She started getting strange symptoms. She would feel dizzy and numb. And she'd have moments when she couldn't even speak or write. She went from doing 20-mile bike rides to collapsing after just a short walk. BREA: And it just kind of got worse and worse and worse. RAZ: Jen went to all kinds of specialists who didn't know what was wrong with her. And then one of them came up with a diagnosis, conversion disorder. BREA: He told me, everything that you've been experiencing is psychosomatic, that the symptoms are real but that they have no biological cause. RAZ: That diagnosis, the idea that her symptoms were all in her head, left Jen feeling even more helpless. And then on top of that, she would later find out that her diagnosis, conversion disorder, used to be called hysteria. Jennifer Brea picks up the story from the TED stage. (SOUNDBITE OF TED TALK) BREA: When my doctor diagnosed me with conversion disorder, he was invoking a lineage of ideas about women's bodies that are over 2,500 years old. The Roman physician Galen thought that hysteria was caused by sexual deprivation in particularly passionate women. The Greeks thought that the uterus would literally dry up and wander around the body in search of moisture, pressing on internal organs - yes (laughter) - causing symptoms from extreme emotions to dizziness then paralysis. These ideas went largely unchanged for several millennia, until the 1880s when neurologists tried to modernize the theory of hysteria. Sigmund Freud developed a theory that the unconscious mind could produce physical symptoms when dealing with memories or emotions too painful for the conscious mind to handle. It converted these emotions into physical symptoms. This meant that men can now get hysteria. But of course, women were still the most susceptible. Why has this idea had such staying power? I do think it has to do with sexism. But I also think that, fundamentally, doctors want to help. They want to know the answer. And this category allows doctors to treat what would otherwise be untreatable, to explain illnesses that have no explanation. The problem is that this can cause real harm. In the 1950s, a psychiatrist named Eliot Slater studied a cohort at 85 patients who had been diagnosed with hysteria. Nine years later, 12 of them were dead and 30 had become disabled. Many had undiagnosed conditions, like multiple sclerosis, epilepsy, brain tumors. In 1980 hysteria was officially renamed conversion disorder. When my neurologist gave me that diagnosis in 2012, he was echoing Freud's words verbatim. The problem with the theory of hysteria, or psychogenic illness, is that it can never be proven. It is, by definition, the absence of evidence. RAZ: Jen, of course, didn't believe she had conversion disorder. But she had trouble convincing doctors that her symptoms were serious. BREA: I had this problem of when I was well enough to go to a doctor, I would look pretty normal. And then when I was experiencing my symptoms, I would never be able to go in. RAZ: So she decided to start filming herself at home with her iPhone. (SOUNDBITE OF VIDEO) BREA: I don't think I can get up off the couch. And when I was able to bring in these videos. . . (SOUNDBITE OF VIDEO) BREA: The right side of my face feels numb. I fell like my brain is misfiring. It just - it changed the conversation when they could really see what it was like. RAZ: Yeah. (SOUNDBITE OF VIDEO) BREA: I figure it's good to just keep documenting. OK. Turn off the light. RAZ: But even then, her doctors couldn't make sense of her symptoms. BREA: So, like, in the doctor's office, there was all of these strange symptoms that had no pattern, that they couldn't understand or describe or categorize or name. RAZ: So Jen did something that a lot of doctors don't particularly like. BREA: I think one of the most annoying things for doctors that a patient can do is go on the internet and Google their symptoms. (LAUGHTER) BREA: And even though oftentimes I was Googling PubMed and Nature and Science and bringing them into my doctors, there was the sense that, you know, the internet is really unreliable, which it is. It's like a Wild West. And you'll find all kinds of information. RAZ: But along with those studies, Jen found something else online. BREA: There are literally thousands of people that all have the same pattern of symptoms. RAZ: The same symptoms Jen's doctors couldn't make sense of. BREA: This community of people who all had ME, myalgic encephalomyelitis. RAZ: Myalgic encephalomyelitis, a disease that seemed to fit with the symptoms Jen was experiencing - so through that online community, Jen connected with ME experts across the country. BREA: I found a doctor in Boston at Mass General, a doctor in Miami, in New York, a doctor in Nevada and a doctor in California. So I've actually been (laughter) diagnosed five times with ME. RAZ: Why is it so difficult to diagnose? BREA: It's difficult to diagnose because it's not really a part of the medical school curricula. So at most medical schools, you're not required to learn about the symptoms and the pathophysiology of the disease. So one doctor that I saw in Miami - when she was a professor in immunology, she had to sort of teach medical students during their lunch hour because it wasn't a part of the curriculum. (SOUNDBITE OF TED TALK) BREA: Myalgic encephalomyelitis - you've probably heard it called chronic fatigue syndrome. The key symptom we all share is that whenever we exert ourselves, physically, mentally, we pay and we pay hard. If my husband goes for a run, he might be sore for a couple of days. If I try to walk half a block, I might be bedridden for a week. It is the perfect custom prison. I know ballet dancers who can't dance, accountants who can't add, medical students who never became doctors. It doesn't matter what you once were. You can't do it any more. It's estimated that about 15 to 30 million people around the world have this disease. In the U. S. , where I'm from, it's about 1 million people. That makes it roughly twice as common as multiple sclerosis. Patients can live for decades with the physical function of someone with congestive heart failure. Twenty-five percent of us are homebound or bedridden and 75 to 85 percent of us can't even work part time. How could a disease this common and this devastating have been forgotten by medicine? All around the world, ME is one of the least-funded diseases. So in the U. S. , we spend each year roughly $2,500 per AIDS patient, $250 per MS patient and just $5 per year per ME patient. (SOUNDBITE OF MUSIC) RAZ: It feels like ME patients face this kind of dilemma. Because it's sort of mysterious, no one is funding research into it. But then the only way to figure out what the mystery is is to fund it, right? BREA: Yeah. It's this sort of really weird situation where people say, well, we don't know anything about it yet. And I - whenever anyone says that to me, I kind of feel like I'm standing next to this, like, giant rock and everyone's like, well, we don't know what's underneath that rock. Like, what could possibly be under that? And like, lift it up. Just, like, lift it up and look, you know? You can't answer the questions that you don't ask. You can't understand what you don't study. You can't find what you're not looking for. RAZ: Yeah. And I wonder if, like, on a more personal level, you were - like, you were going to this process constantly where you were asking yourself, like, you know, what's wrong with me? What's happening to me? And then finding this community of people online probably made you feel like you weren't the only one asking those questions. BREA: You know, it's a funny thing because being able to connect to people who are sharing your experience is profound. I thought I had a rare disease. For those first two years, I thought maybe I'm dying. No one could tell me what my prognosis was. No one could tell me what this was going to be like. Even if in that moment what I was grappling with felt so big and so terrifying that I wouldn't survive it, the fact that other people had gone through that and had survived gave me hope that I would be able to find a way. RAZ: What else - what else gives you hope? BREA: I think what is hard to sort of see from the outside is that humans are really adaptable, and I've kind of grown into this. And so on the one hand, every day I try to live the life that I have as well as I possibly can. I'm also fighting for a better life at the same time. And I know that there are so many drugs I have never tried. I know that there are so many experiments that have never been run. And so I believe that if we just started trying to answer these basic questions that we could find treatments and explanations for this disease within a matter of years. So I think that I could get a lot better and I think that I could get a lot better while I'm still young, and that's really what I'm fighting for every day. RAZ: That's Jennifer Brea. You can see her entire talk at ted. com. And by the way, those iPhone videos she took of herself at home, those actually inspired her to make a documentary about chronic fatigue syndrome. It's done mostly from her bedside at home. It's called \"Unrest,\" and it premiered earlier this year at Sundance. (SOUNDBITE OF SONG, \"DOCTOR, DOCTOR\") THE WHO: (Singing) Doctor, there's something wrong with me. My health is not all that it used to be. My heart is out of beat. I got chokers on my feet. My eyesight's getting dimmer. I can't see. RAZ: Thanks for listening to our show, Getting Better, this week. If you want to find out more about who was on it, go to ted. npr. org. To see hundreds more TED talks, check out ted. com or the TED app. Our production staff at NPR includes Jeff Rogers, Brent Baughman, Megan Kane, Neva Grant, Sanaz Meshkinpour, Casey Herman, Rachel Faulkner and Rund Abdel-Fattah (ph), with help from Camilo Garzon and Daniel Shukin. Our intern is Thomas Lu. Our partners at TED Chris Anderson, Kelly Stoetzel, Anna Phelan and Janet Lee. If you want to let us know what you think about the show, you can write us at tedradiohour@npr. org. And you can follow us on Twitter. It's @TEDRadioHour. I'm Guy Raz, and you've been listening to ideas worth spreading right here on the TED Radio Hour from NPR.", "section": "TED Radio Hour", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-02-11-514732239": {"title": "Ajit Pai Starts To Roll Back Latest Internet Regulations From Obama's Team : NPR", "url": "https://www.npr.org/2017/02/11/514732239/ajit-pai-starts-to-roll-back-latest-internet-regulations-from-obamas-team", "author": "No author found", "published_date": "2017-02-11", "content": "LAKSHMI SINGH, HOST: The future of the internet and telecommunications is now in new hands. In his first two weeks, the newly appointed Republican chairman of the Federal Communications Commission, Ajit Pai has started to undo some of the actions of his Democratic predecessor. Ajit Pai is widely known as a skeptic of heavy government regulation. Consumer advocacy groups warn that with Pai now at the helm of the FCC, the internet, they say, will likely be less competitive and less accessible. To help us understand what to expect from the new FCC, we are joined now by All Tech Considered's Alina Selyukh. Alina, Hi. ALINA SELYUKH, BYLINE: Hi. SINGH: So the big debate over Ajit Pai's new role at the FCC is what that might mean for the internet as we know it. So help us understand what is at stake? SELYUKH: Well, sure - and this gets at the issue - and I'm going to say this term, net neutrality. This is where everybody starts snoozing, but let me lay it out. So there's the guidelines that, say, internet service providers shouldn't block or throttle anything on the web, and they can't really give special treatment to companies that pay extra. And this has been the bureaucratic back and forth for many years. In 2015, the Obama administration set net neutrality principles into law by reclassifying internet service providers in a way that treats them more like utilities, the really stringent restrictions on the industry. Well, now we've got a new administration coming in that's taking sort of an 180-degree look at all regulations. And Pai has even said that now is the time to, quote, \"fire up the weed whacker\" and remove those unnecessary rules from the books. SINGH: Alina, I think the immediate question is what does that mean for people like you and me, for consumers and their internet access? SELYUKH: Well, sure. What we are expecting from Pai is to work with Congress to set new rules that could mean that the FCC loses some of the oversight power over the internet service providers. SINGH: All this sounds like a major shift in how the U. S. government actually treats cable and telecom companies. SELYUKH: Pai definitely has a very different view of the government's role. For instance, when the Obama administration would set regulations and they would be lauded as consumer protections, Pai would come out and say, well, did you really show evidence that people were actually being harmed without these regulations in place? He would advocate for companies to come together and solve various problems, rather than the government coming in and sorting it out. SINGH: So we know a little more about Ajit Pai now and where he's going - or at least what he's signaling. Tell me a little more about Ajit Pai the person. SELYUKH: So he comes from Kansas. He's a son of Indian immigrants. He is a career lawyer. He's worked at the Department of Justice in the Senate. He worked for Verizon for a short period of time, and he has been on the FCC for the past four years. He's the guy who lightens it up with pop culture references. It's kind of funny. You'll be reading his opinions, and, like, in the footnotes, he will be citing \"Seinfeld\" or \"The Big Lebowski. \" At one point, he started his address with the part 15 notice of proposed rule-making reminds me of a scene from the 2003 movie \"The Matrix Reloaded\" and then he proceeded to describe the scene. SINGH: Dear goodness (laughter). SELYUKH: So we might be in for some really colorful chairman's opinions in the next four years. SINGH: OK. Alina Selyukh is a reporter for NPR's All Tech Considered. Thank you for joining us, Alina. SELYUKH: Thank you. LAKSHMI SINGH, HOST:  The future of the internet and telecommunications is now in new hands. In his first two weeks, the newly appointed Republican chairman of the Federal Communications Commission, Ajit Pai has started to undo some of the actions of his Democratic predecessor. Ajit Pai is widely known as a skeptic of heavy government regulation. Consumer advocacy groups warn that with Pai now at the helm of the FCC, the internet, they say, will likely be less competitive and less accessible. To help us understand what to expect from the new FCC, we are joined now by All Tech Considered's Alina Selyukh. Alina, Hi. ALINA SELYUKH, BYLINE: Hi. SINGH: So the big debate over Ajit Pai's new role at the FCC is what that might mean for the internet as we know it. So help us understand what is at stake? SELYUKH: Well, sure - and this gets at the issue - and I'm going to say this term, net neutrality. This is where everybody starts snoozing, but let me lay it out. So there's the guidelines that, say, internet service providers shouldn't block or throttle anything on the web, and they can't really give special treatment to companies that pay extra. And this has been the bureaucratic back and forth for many years. In 2015, the Obama administration set net neutrality principles into law by reclassifying internet service providers in a way that treats them more like utilities, the really stringent restrictions on the industry. Well, now we've got a new administration coming in that's taking sort of an 180-degree look at all regulations. And Pai has even said that now is the time to, quote, \"fire up the weed whacker\" and remove those unnecessary rules from the books. SINGH: Alina, I think the immediate question is what does that mean for people like you and me, for consumers and their internet access? SELYUKH: Well, sure. What we are expecting from Pai is to work with Congress to set new rules that could mean that the FCC loses some of the oversight power over the internet service providers. SINGH: All this sounds like a major shift in how the U. S. government actually treats cable and telecom companies. SELYUKH: Pai definitely has a very different view of the government's role. For instance, when the Obama administration would set regulations and they would be lauded as consumer protections, Pai would come out and say, well, did you really show evidence that people were actually being harmed without these regulations in place? He would advocate for companies to come together and solve various problems, rather than the government coming in and sorting it out. SINGH: So we know a little more about Ajit Pai now and where he's going - or at least what he's signaling. Tell me a little more about Ajit Pai the person. SELYUKH: So he comes from Kansas. He's a son of Indian immigrants. He is a career lawyer. He's worked at the Department of Justice in the Senate. He worked for Verizon for a short period of time, and he has been on the FCC for the past four years. He's the guy who lightens it up with pop culture references. It's kind of funny. You'll be reading his opinions, and, like, in the footnotes, he will be citing \"Seinfeld\" or \"The Big Lebowski. \" At one point, he started his address with the part 15 notice of proposed rule-making reminds me of a scene from the 2003 movie \"The Matrix Reloaded\" and then he proceeded to describe the scene. SINGH: Dear goodness (laughter). SELYUKH: So we might be in for some really colorful chairman's opinions in the next four years. SINGH: OK. Alina Selyukh is a reporter for NPR's All Tech Considered. Thank you for joining us, Alina. SELYUKH: Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-02-16-515376114": {"title": "Wind Power: The South Has Been Slow To Harness Its Wind, But That's Changing : NPR", "url": "https://www.npr.org/2017/02/16/515376114/the-south-has-been-slow-to-harness-its-wind-but-thats-changing", "author": "No author found", "published_date": "2017-02-16", "content": "DAVID GREENE, HOST:  Wind power is the largest source of renewable energy in the United States, but much of the country has not had those large commercial wind farms until now. A new 22,000-acre farm is up and running in North Carolina. It is considered the first of its kind in the Southeastern U. S. , and NPR's Sarah McCammon went for a visit. SARAH MCCAMMON, BYLINE: At Horace Pritchard's farm, there is a new crop one that won't wither in the hot August heat or be washed away by big storms. HORACE PRITCHARD: When corn's down, to - that you're not making any ends meet, this will help us pull through a bad year or a hurricane or a drought. MCCAMMON: This is wind power. Pritchard is one of about 60 landowners who are leasing property to the site known as the Amazon Wind Farm. U. S. East. Developers say it will generate enough power for 61,000 homes per year, power that the internet retailer Amazon has agreed to buy from the electric grid. Pritchard says he knew it was windy here about 30 miles from the Atlantic coast, but he didn't expect this. PRITCHARD: I'd seen on TV in other countries and all where they'd done - kinds of projects. And had just kind of run through my mind that this would be something back here, but never had no idea that it would come. MCCAMMON: Alongside Pritchard's tractors, the tall white towers dot the landscape, their blades whooshing faintly as they cut through the blue sky. The tip of the highest blade stretches close to 500 feet in the air above the base, longer than a football field. Craig Poff is with the developer Avangrid Renewables. CRAIG POFF: They've gotten a little bit taller, and the blades have gotten a little bit longer. MCCAMMON: That extra length is possible because of technological advances. It's important says, Michael Goggin of the American Wind Energy Association, because the strongest winds in the region tend to be higher up. MICHAEL GOGGIN: Thus far, we just haven't had turbines that were large enough to get up there to capture those winds. MCCAMMON: That's partly a quirk of geography, Goggin says, and partly because the Southeast has a lot of trees, unlike the Great Plains with its wide open spaces. Which explains why, aside from a small amount of wind power in Tennessee, the Southeast has lagged far behind the rest of the country in wind energy. GOGGIN: I think it has changed the energy map of the country. Traditionally, people didn't think there was wind in the Southeast. And now, you know, there are projects being built there. MCCAMMON: For the project in North Carolina, there were other obstacles. Republican state lawmakers raised concerns that it might interfere with military radar, something the Navy has said is unlikely. Lawmakers then made a last ditch request to President Trump to block the project. That failed, but Trump has expressed skepticism about wind power. He famously objected to a wind farm he said would disrupt the view near one of his golf courses in Scotland. Those concerns, along with worries about the impact on birds and other wildlife often pop up around new wind developments, but Craig Poff says he hopes the project will pave the way for more in the region. POFF: Our hope is that this project, being the first in the Southeast, is going to enable people to see how it works and get a little more comfortable with it. MCCAMMON: Farmer Horace Pritchard says some of his neighbors here in rural North Carolina worried about noise from the wind farm and wondered how much land it would use. He says the $54,000 dollars he get each year for the nine towers on his property more than offsets the land taken out of production underneath that. PRITCHARD: Over the long term, nothing I could grow legal would produce what these are doing. MCCAMMON: Pritchard says some of the neighbors who initially scoffed at the windfarm are now asking if they can get in on the deal. Sarah McCammon, NPR News. DAVID GREENE, HOST:   Wind power is the largest source of renewable energy in the United States, but much of the country has not had those large commercial wind farms until now. A new 22,000-acre farm is up and running in North Carolina. It is considered the first of its kind in the Southeastern U. S. , and NPR's Sarah McCammon went for a visit. SARAH MCCAMMON, BYLINE: At Horace Pritchard's farm, there is a new crop one that won't wither in the hot August heat or be washed away by big storms. HORACE PRITCHARD: When corn's down, to - that you're not making any ends meet, this will help us pull through a bad year or a hurricane or a drought. MCCAMMON: This is wind power. Pritchard is one of about 60 landowners who are leasing property to the site known as the Amazon Wind Farm. U. S. East. Developers say it will generate enough power for 61,000 homes per year, power that the internet retailer Amazon has agreed to buy from the electric grid. Pritchard says he knew it was windy here about 30 miles from the Atlantic coast, but he didn't expect this. PRITCHARD: I'd seen on TV in other countries and all where they'd done - kinds of projects. And had just kind of run through my mind that this would be something back here, but never had no idea that it would come. MCCAMMON: Alongside Pritchard's tractors, the tall white towers dot the landscape, their blades whooshing faintly as they cut through the blue sky. The tip of the highest blade stretches close to 500 feet in the air above the base, longer than a football field. Craig Poff is with the developer Avangrid Renewables. CRAIG POFF: They've gotten a little bit taller, and the blades have gotten a little bit longer. MCCAMMON: That extra length is possible because of technological advances. It's important says, Michael Goggin of the American Wind Energy Association, because the strongest winds in the region tend to be higher up. MICHAEL GOGGIN: Thus far, we just haven't had turbines that were large enough to get up there to capture those winds. MCCAMMON: That's partly a quirk of geography, Goggin says, and partly because the Southeast has a lot of trees, unlike the Great Plains with its wide open spaces. Which explains why, aside from a small amount of wind power in Tennessee, the Southeast has lagged far behind the rest of the country in wind energy. GOGGIN: I think it has changed the energy map of the country. Traditionally, people didn't think there was wind in the Southeast. And now, you know, there are projects being built there. MCCAMMON: For the project in North Carolina, there were other obstacles. Republican state lawmakers raised concerns that it might interfere with military radar, something the Navy has said is unlikely. Lawmakers then made a last ditch request to President Trump to block the project. That failed, but Trump has expressed skepticism about wind power. He famously objected to a wind farm he said would disrupt the view near one of his golf courses in Scotland. Those concerns, along with worries about the impact on birds and other wildlife often pop up around new wind developments, but Craig Poff says he hopes the project will pave the way for more in the region. POFF: Our hope is that this project, being the first in the Southeast, is going to enable people to see how it works and get a little more comfortable with it. MCCAMMON: Farmer Horace Pritchard says some of his neighbors here in rural North Carolina worried about noise from the wind farm and wondered how much land it would use. He says the $54,000 dollars he get each year for the nine towers on his property more than offsets the land taken out of production underneath that. PRITCHARD: Over the long term, nothing I could grow legal would produce what these are doing. MCCAMMON: Pritchard says some of the neighbors who initially scoffed at the windfarm are now asking if they can get in on the deal. Sarah McCammon, NPR News.", "section": "Energy", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-02-17-515841069": {"title": "Local Police Departments Invest In Cell Phone Spy Tools : NPR", "url": "https://www.npr.org/2017/02/17/515841069/local-police-departments-invest-in-cell-phone-spy-tools", "author": "No author found", "published_date": "2017-02-17", "content": "ROBERT SIEGEL, HOST: Increasingly, police departments are turning to military-grade surveillance tools to help fight crime - a trend that worries privacy advocates. A new investigation by CityLab, which is part of Atlantic Media, documents the spread of tools that let police collect cellphone data. CityLab reporter George Joseph joins me in the studio now. Welcome to the program. GEORGE JOSEPH: Thanks for having me. SIEGEL: And you we're looking at the 50 largest police departments in the country. What did you find out about the use of these tools? JOSEPH: Well, we found through public records requests that the majority of the largest police departments across the country have primarily two types of devices - cellphone-interception devices, which are used to grab our phone data, such as our call logs and text logs out of the air, and cellphone-extraction devices, which are used when police have phones in their possession to actually suck up content from our phones, such as deleted messages, deleted photos, Google location history - that type of thing. SIEGEL: One of the tools you write about is called a dirtbox. Describe a dirtbox. JOSEPH: So a dirtbox is a favorite tool of the NSA and the military. And what it does is it can be put in a plane or a helicopter to fly overhead - for example, over a protest - and it can track almost 10,000 phones at once and also scoop up your text messages, your phone calls - like, really intimate types of data that we haven't really seen in use in the domestic circle before. SIEGEL: And is the rationale for police using a device like a dirtbox - is it for combating ordinary crime? Is it counterterrorism? Is it crowd control? What would you say? JOSEPH: Well, for the use of these cell-site simulators in general, which is the larger sort of term for these tools, police really like them because they give them a lot of data that can then allow them to do things like, in the future, look for suspect leads and witness leads. So the more data you have, the more powerful you're able to sort of analyze a crime scene and look retroactively at a community and what crimes are happening. SIEGEL: To the extent that I'm concerned about privacy, I find this a little worrying. On the other hand, to the extent that I'm concerned about terrorism on native soil and having police departments that have to deal with it, perhaps I should be reassured that they have these tools. JOSEPH: Well, certainly, if your opinion is that police need to have as much data as they possibly can to fight terrorism or to find suspects, then these tools are great because they allow us to take so much information and thus sort of map out our social networks - figure out who our friends are, where we've been - very intimate data. But it's sort of leading us to a new threshold of power where, you know, in the past, this type of information would've taken weeks for a whole team of police just to acquire. Now it takes a few keystrokes. SIEGEL: Are police department's use of these tools - is it governed by law? JOSEPH: Yes, to some degree, it's governed by law. But the laws are often very locally specific. So it's not one clear federal sort of guideline for how these tools should be used. SIEGEL: And in the course of your reporting, have you come up with claims of great success that police have made based on their use of these tools? JOSEPH: Certainly. I mean, when you look at the usage logs that police put out from time to time about the use of these tools, we see them using it for, for example, kidnapping cases, for armed-robbery cases - that sort of thing, which a lot of people would support the use in. We also see them for things that seem like much lower crimes like cellphone robberies and that type of thing. And the question is, if police are using these very powerful tools for very low-level crimes also, not just for extreme emergencies, what's then happening to the innocent people whose data is then being searched constantly? And we've also seen in past reporting that these tools are mostly being used in African-American and low-income communities. So it's not a shared burden that everyone in society is sharing in terms of being searched by these tools. SIEGEL: Could somebody who's very concerned about her privacy or somebody who's a very savvy criminal, download something to thwart these devices? JOSEPH: To some degree, you can use certain apps that help protect you, such as Signal. That's something a lot of people are turning to. But to other degrees, just having a phone in general is always going to be providing some data trail. So for those who are particularly concerned about being followed or tracked, most people advise you, don't carry a phone on you at all times. SIEGEL: CityLab reporter George Joseph, thank you very much. JOSEPH: Oh, appreciate it. Thank you. ROBERT SIEGEL, HOST:  Increasingly, police departments are turning to military-grade surveillance tools to help fight crime - a trend that worries privacy advocates. A new investigation by CityLab, which is part of Atlantic Media, documents the spread of tools that let police collect cellphone data. CityLab reporter George Joseph joins me in the studio now. Welcome to the program. GEORGE JOSEPH: Thanks for having me. SIEGEL: And you we're looking at the 50 largest police departments in the country. What did you find out about the use of these tools? JOSEPH: Well, we found through public records requests that the majority of the largest police departments across the country have primarily two types of devices - cellphone-interception devices, which are used to grab our phone data, such as our call logs and text logs out of the air, and cellphone-extraction devices, which are used when police have phones in their possession to actually suck up content from our phones, such as deleted messages, deleted photos, Google location history - that type of thing. SIEGEL: One of the tools you write about is called a dirtbox. Describe a dirtbox. JOSEPH: So a dirtbox is a favorite tool of the NSA and the military. And what it does is it can be put in a plane or a helicopter to fly overhead - for example, over a protest - and it can track almost 10,000 phones at once and also scoop up your text messages, your phone calls - like, really intimate types of data that we haven't really seen in use in the domestic circle before. SIEGEL: And is the rationale for police using a device like a dirtbox - is it for combating ordinary crime? Is it counterterrorism? Is it crowd control? What would you say? JOSEPH: Well, for the use of these cell-site simulators in general, which is the larger sort of term for these tools, police really like them because they give them a lot of data that can then allow them to do things like, in the future, look for suspect leads and witness leads. So the more data you have, the more powerful you're able to sort of analyze a crime scene and look retroactively at a community and what crimes are happening. SIEGEL: To the extent that I'm concerned about privacy, I find this a little worrying. On the other hand, to the extent that I'm concerned about terrorism on native soil and having police departments that have to deal with it, perhaps I should be reassured that they have these tools. JOSEPH: Well, certainly, if your opinion is that police need to have as much data as they possibly can to fight terrorism or to find suspects, then these tools are great because they allow us to take so much information and thus sort of map out our social networks - figure out who our friends are, where we've been - very intimate data. But it's sort of leading us to a new threshold of power where, you know, in the past, this type of information would've taken weeks for a whole team of police just to acquire. Now it takes a few keystrokes. SIEGEL: Are police department's use of these tools - is it governed by law? JOSEPH: Yes, to some degree, it's governed by law. But the laws are often very locally specific. So it's not one clear federal sort of guideline for how these tools should be used. SIEGEL: And in the course of your reporting, have you come up with claims of great success that police have made based on their use of these tools? JOSEPH: Certainly. I mean, when you look at the usage logs that police put out from time to time about the use of these tools, we see them using it for, for example, kidnapping cases, for armed-robbery cases - that sort of thing, which a lot of people would support the use in. We also see them for things that seem like much lower crimes like cellphone robberies and that type of thing. And the question is, if police are using these very powerful tools for very low-level crimes also, not just for extreme emergencies, what's then happening to the innocent people whose data is then being searched constantly? And we've also seen in past reporting that these tools are mostly being used in African-American and low-income communities. So it's not a shared burden that everyone in society is sharing in terms of being searched by these tools. SIEGEL: Could somebody who's very concerned about her privacy or somebody who's a very savvy criminal, download something to thwart these devices? JOSEPH: To some degree, you can use certain apps that help protect you, such as Signal. That's something a lot of people are turning to. But to other degrees, just having a phone in general is always going to be providing some data trail. So for those who are particularly concerned about being followed or tracked, most people advise you, don't carry a phone on you at all times. SIEGEL: CityLab reporter George Joseph, thank you very much. JOSEPH: Oh, appreciate it. Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-02-21-516484639": {"title": "Are Cyborgs In Our Future? 'Homo Deus' Author Thinks So : NPR", "url": "https://www.npr.org/2017/02/21/516484639/are-cyborgs-in-our-future-homo-deus-author-thinks-so", "author": "No author found", "published_date": "2017-02-21", "content": "ARI SHAPIRO, HOST: The human species is about to change dramatically. That's the argument Yuval Noah Harari makes in his new book \"Homo Deus: A Brief History Of Tomorrow. \" Harari is a history professor at Hebrew University in Israel. He expects we will soon engineer our bodies, brains and minds in the same way that we now design products. YUVAL NOAH HARARI: There are three main ways of doing that. First of all is to take our organic body and start tinkering with it with things like genetic engineering, speeding up natural selection and actually replacing it with intelligent design - not the intelligent design of some God above the clouds but our intelligent design. The other way is to start combining organic with inorganic parts and creating cyborgs. For 4 billion years, all of evolution - not just of humans but of all beings - was confined to the organic realm. But very soon, we might be able to break out of the organic realm using things like brain-computer interfaces which combine organic parts like an organic brain with inorganic parts like bionic hands or eyes or ears. And then the third and most extreme path is to create completely inorganic beings not even needing an organic brain but using instead artificial intelligence. SHAPIRO: One of the ideas that stood out to me from your book is that there is no clear line that separates healing from upgrading. So for example, plastic surgery may have begun as a tool to repair people, and it quickly became a tool to improve people. And you suggest that physical improvements of other kinds will likely follow the same path. Give me an example. HARARI: I think in general, medicine in the 21st century will switch from healing the sick to upgrading the healthy. This is true not only of plastic surgery and improvements to the body but also improvements to our cognitive abilities - for example, memory. If you find ways to repair the memory damaged by Alzheimers disease or dementia and so forth, it is very likely that the same methods could be used to upgrade the memory of completely healthy people. And if you find ways to connect brains and computers, you can rely on memories in immense databases outside your own brain. We are starting to do it in a way with our smartphones and computers, but what we may see in coming decades is humans actually merging completely with their smartphones and computers. SHAPIRO: As you imagine this world in the not-too-distant future where people have the option of upgrading their bodies and upgrading their minds, what happens to people who don't exercise that option, who decide to stay natural? HARARI: The real problem is not those who choose to stay natural but the fact that I think very few people at least in the beginning will have that choice at all. It's likely that all the upgrades, at least at first, will cost a lot and will be available only to a small elite. So for the first time in human history, we might see economic inequality being translated into biological inequality. And once such a gap opens, it becomes almost impossible to close it because then the rich will really be far more capable than everybody else. SHAPIRO: This near-future that you describe can quite quickly start to feel very frightening, dystopian, like a future that nobody would want to live in. Was there any moment when you were writing this book and thought, you know what; I really just don't want to immerse myself in this world. I mean you go deep into it. Was the experience of writing it as harrowing as the experience of reading it can be? HARARI: (Laughter) No because these are not prophecies. We can still do something about it. SHAPIRO: What can we do? HARARI: One thing that we need to do is start thinking far more seriously about global governance because the only solution to such problems will be on a global level, not on a national level. I mean actually of course in the last year or two, we are seeing a retrograde movement away from global thinking and into more nationalist and isolationist thinking. And this is very dangerous. I mean traditionally, people said that nationalism is dangerous because it leads to war, but now nationalism is far more dangerous because not only it leads to war. It also may prevent us from having any effective answer that can help us cope with dangers like the rise of artificial intelligence or the implications of bioengineering. SHAPIRO: Yuval Noah Harari's new book is called \"Homo Deus: A Brief History Of Tomorrow. \" Thank you for the enlightening and slightly terrifying read. (LAUGHTER)HARARI: Thank you. ARI SHAPIRO, HOST:  The human species is about to change dramatically. That's the argument Yuval Noah Harari makes in his new book \"Homo Deus: A Brief History Of Tomorrow. \" Harari is a history professor at Hebrew University in Israel. He expects we will soon engineer our bodies, brains and minds in the same way that we now design products. YUVAL NOAH HARARI: There are three main ways of doing that. First of all is to take our organic body and start tinkering with it with things like genetic engineering, speeding up natural selection and actually replacing it with intelligent design - not the intelligent design of some God above the clouds but our intelligent design. The other way is to start combining organic with inorganic parts and creating cyborgs. For 4 billion years, all of evolution - not just of humans but of all beings - was confined to the organic realm. But very soon, we might be able to break out of the organic realm using things like brain-computer interfaces which combine organic parts like an organic brain with inorganic parts like bionic hands or eyes or ears. And then the third and most extreme path is to create completely inorganic beings not even needing an organic brain but using instead artificial intelligence. SHAPIRO: One of the ideas that stood out to me from your book is that there is no clear line that separates healing from upgrading. So for example, plastic surgery may have begun as a tool to repair people, and it quickly became a tool to improve people. And you suggest that physical improvements of other kinds will likely follow the same path. Give me an example. HARARI: I think in general, medicine in the 21st century will switch from healing the sick to upgrading the healthy. This is true not only of plastic surgery and improvements to the body but also improvements to our cognitive abilities - for example, memory. If you find ways to repair the memory damaged by Alzheimers disease or dementia and so forth, it is very likely that the same methods could be used to upgrade the memory of completely healthy people. And if you find ways to connect brains and computers, you can rely on memories in immense databases outside your own brain. We are starting to do it in a way with our smartphones and computers, but what we may see in coming decades is humans actually merging completely with their smartphones and computers. SHAPIRO: As you imagine this world in the not-too-distant future where people have the option of upgrading their bodies and upgrading their minds, what happens to people who don't exercise that option, who decide to stay natural? HARARI: The real problem is not those who choose to stay natural but the fact that I think very few people at least in the beginning will have that choice at all. It's likely that all the upgrades, at least at first, will cost a lot and will be available only to a small elite. So for the first time in human history, we might see economic inequality being translated into biological inequality. And once such a gap opens, it becomes almost impossible to close it because then the rich will really be far more capable than everybody else. SHAPIRO: This near-future that you describe can quite quickly start to feel very frightening, dystopian, like a future that nobody would want to live in. Was there any moment when you were writing this book and thought, you know what; I really just don't want to immerse myself in this world. I mean you go deep into it. Was the experience of writing it as harrowing as the experience of reading it can be? HARARI: (Laughter) No because these are not prophecies. We can still do something about it. SHAPIRO: What can we do? HARARI: One thing that we need to do is start thinking far more seriously about global governance because the only solution to such problems will be on a global level, not on a national level. I mean actually of course in the last year or two, we are seeing a retrograde movement away from global thinking and into more nationalist and isolationist thinking. And this is very dangerous. I mean traditionally, people said that nationalism is dangerous because it leads to war, but now nationalism is far more dangerous because not only it leads to war. It also may prevent us from having any effective answer that can help us cope with dangers like the rise of artificial intelligence or the implications of bioengineering. SHAPIRO: Yuval Noah Harari's new book is called \"Homo Deus: A Brief History Of Tomorrow. \" Thank you for the enlightening and slightly terrifying read. (LAUGHTER) HARARI: Thank you.", "section": "Author Interviews", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-02-22-516695456": {"title": "After Making History In Space, Mae Jemison Works To Prime Future Scientists  : NPR", "url": "https://www.npr.org/2017/02/22/516695456/after-making-history-in-space-mae-jemison-works-to-prime-future-scientists", "author": "No author found", "published_date": "2017-02-22", "content": "ARI SHAPIRO, HOST: At the Oscars this weekend, one spotlight will shine on African-American women in the space race. The movie \"Hidden Figures\" is nominated for three Academy Awards, including best picture. We're going to talk now with someone who made history in this field. Dr. Mae Jemison was the first African-American woman in space. She was on the space shuttle Endeavor in 1992 and joins us now. Welcome to ALL THINGS CONSIDERED. MAE JEMISON: Thank you very much. SHAPIRO: You were hardly a hidden figure, and yet there does seem to be new interest today in women who broke boundaries in space, particularly women of color. What's it like to see all of this attention paid to the field that you entered decades ago? JEMISON: Well, I think it's one of those things that's - really needs to be done. And this is because people of all types have made contributions across the spectrum of the sciences, across the spectrum of exploration, and they have been left out many times purposefully. SHAPIRO: I want to get to how best to take advantage of hidden talents that exist across the population. But first, can you take us back to 1987, when you entered the NASA space program? Was the fact that you were a groundbreaking figure something you were reminded of daily? Or were you able to let that recede into the background and focus on the work? JEMISON: I always think of it as like, what do you do with your place at the table? If you act just like everyone else, what difference does it make that you're there? And so for me - having grown up on the South Side of Chicago, gone to public schools, having been a medical doctor, having worked in Cambodian refugee camps, as well as being an engineer, as well as being someone who was very first in dance and the arts - yes, I'm supposed to bring those perspectives to bear on the questions that we ask about space exploration. How do we get more people involved? How do we understand how the various technologies can help benefit people across the world? Those were important things for me. So I was aware of that, yet at the same time you have a job to do. SHAPIRO: Since you left NASA about 25 years ago, you have taken on a lot of projects. And one consistent focus of yours has been getting more women and minorities into math and science fields. What did you learn from your own experience about what works? JEMISON: I think that there are really important things that we have to do with students to get them to succeed in science, to go on and stay with careers. And that includes the idea of being exposed to something. So if you know that those things exist, it makes it easier for you to get involved. For example, it helps to know what an engineer is. It helps to know what a biotechnician is so you're not afraid of it. Then it's experience. When you do hands-on science, you learn to - you learn about electricity by wiring a flashlight. And then it's expectation. And that expectation is we should expect our kids to succeed and to achieve. Children live up or down to our expectations. And so I always call it the three Es - right? - experience, expectation and exposure. SHAPIRO: The National Science Foundation says 84 percent of working professionals in science and engineering jobs today are white or Asian men. Why do you think the efforts to diversify this pool have not been more successful? JEMISON: So the efforts to diversify the pool very often are couched in things like we want them to behave and act like we do. Or there are people who get degrees and then they're not included because there's a - it's a bevy of things. There's no one single thing. Let me give you the results of a Bayer Corporation survey as part of its Making Science Make Sense program. They surveyed women and minority members of the American Chemical Society. And what was found is that the place where these people had the most discouragement from studying science was in college by a college professor. Over 40 percent of them had that happen to them. I want to make sure that that future that we're creating is one that's as best can be for people around the world, and also one that includes the full range of our talent and our skills and, you know, gender and ethnicity, geography to solving the world's problems. SHAPIRO: Dr. Mae Jemison, thank you so much for your time. JEMISON: You're welcome. (SOUNDBITE OF BOMBAY DUB ORCHESTRA SONG, \"STRANGE CONSTELLATIONS\") ARI SHAPIRO, HOST:  At the Oscars this weekend, one spotlight will shine on African-American women in the space race. The movie \"Hidden Figures\" is nominated for three Academy Awards, including best picture. We're going to talk now with someone who made history in this field. Dr. Mae Jemison was the first African-American woman in space. She was on the space shuttle Endeavor in 1992 and joins us now. Welcome to ALL THINGS CONSIDERED. MAE JEMISON: Thank you very much. SHAPIRO: You were hardly a hidden figure, and yet there does seem to be new interest today in women who broke boundaries in space, particularly women of color. What's it like to see all of this attention paid to the field that you entered decades ago? JEMISON: Well, I think it's one of those things that's - really needs to be done. And this is because people of all types have made contributions across the spectrum of the sciences, across the spectrum of exploration, and they have been left out many times purposefully. SHAPIRO: I want to get to how best to take advantage of hidden talents that exist across the population. But first, can you take us back to 1987, when you entered the NASA space program? Was the fact that you were a groundbreaking figure something you were reminded of daily? Or were you able to let that recede into the background and focus on the work? JEMISON: I always think of it as like, what do you do with your place at the table? If you act just like everyone else, what difference does it make that you're there? And so for me - having grown up on the South Side of Chicago, gone to public schools, having been a medical doctor, having worked in Cambodian refugee camps, as well as being an engineer, as well as being someone who was very first in dance and the arts - yes, I'm supposed to bring those perspectives to bear on the questions that we ask about space exploration. How do we get more people involved? How do we understand how the various technologies can help benefit people across the world? Those were important things for me. So I was aware of that, yet at the same time you have a job to do. SHAPIRO: Since you left NASA about 25 years ago, you have taken on a lot of projects. And one consistent focus of yours has been getting more women and minorities into math and science fields. What did you learn from your own experience about what works? JEMISON: I think that there are really important things that we have to do with students to get them to succeed in science, to go on and stay with careers. And that includes the idea of being exposed to something. So if you know that those things exist, it makes it easier for you to get involved. For example, it helps to know what an engineer is. It helps to know what a biotechnician is so you're not afraid of it. Then it's experience. When you do hands-on science, you learn to - you learn about electricity by wiring a flashlight. And then it's expectation. And that expectation is we should expect our kids to succeed and to achieve. Children live up or down to our expectations. And so I always call it the three Es - right? - experience, expectation and exposure. SHAPIRO: The National Science Foundation says 84 percent of working professionals in science and engineering jobs today are white or Asian men. Why do you think the efforts to diversify this pool have not been more successful? JEMISON: So the efforts to diversify the pool very often are couched in things like we want them to behave and act like we do. Or there are people who get degrees and then they're not included because there's a - it's a bevy of things. There's no one single thing. Let me give you the results of a Bayer Corporation survey as part of its Making Science Make Sense program. They surveyed women and minority members of the American Chemical Society. And what was found is that the place where these people had the most discouragement from studying science was in college by a college professor. Over 40 percent of them had that happen to them. I want to make sure that that future that we're creating is one that's as best can be for people around the world, and also one that includes the full range of our talent and our skills and, you know, gender and ethnicity, geography to solving the world's problems. SHAPIRO: Dr. Mae Jemison, thank you so much for your time. JEMISON: You're welcome. (SOUNDBITE OF BOMBAY DUB ORCHESTRA SONG, \"STRANGE CONSTELLATIONS\")", "section": "Space", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-02-24-516710048": {"title": "Kevin Jones: Can Embracing Uncertainty Lead To Better Medicine? : NPR", "url": "https://www.npr.org/2017/02/24/516710048/kevin-jones-can-embracing-uncertainty-lead-to-better-medicine", "author": "No author found", "published_date": "2017-02-24", "content": "GUY RAZ, HOST: On the show today, the Spirit of Inquiry, why the question is often more important than the answer and what happens when one question leads to another? KEVIN JONES: That's how every medical interview that I have with a patient begins - questions that they have, questions I have for them, trying to put the pieces together and understand what's happening. RAZ: This is Kevin Jones. He's a surgeon who specializes in a rare group of cancers called sarcomas. And he says doctors, no matter how many questions they ask, definitely don't have all the answers. JONES: I mean, there's been a fairly paternalistic view of medicine where we just kind of - we take care of patients, you know. We manage all this uncertainty and things for them. And I just - I react unhappily to that because I think that there is an element of - certainly not malintent, but there's an element of dishonesty when we presume to know more than we know. RAZ: I mean, somebody in your position is sought out to give answers, right? Like patients come to you, they say Dr. Jones, you know, am I going to die? And you don't always have the answers. JONES: Absolutely. No, I mean, we - especially when it comes down to predictions, I mean, just like the weathermen, we're terrible at making predictions. And yet we have to. RAZ: Here's Kevin Jones on the TED stage. (SOUNDBITE OF TED TALK)JONES: Medicine is science. Medicine is knowledge in process. Sometimes in the media and even more rarely, but sometimes even scientists will say that something or other has been scientifically proven. But I hope that you understand that science never proves anything definitively forever. Now, I am a surgeon, and I would tell you that every one of my patients is an outlier is an exception. People talk about thinking outside the box, but we don't even have a box in sarcoma. What we do have is we take a bath in the uncertainty and unknowns and exceptions and outliers that surround us in sarcoma is easy access to what I think are those two most important values for any science - humility and curiosity. Because if I am humble and curious when a patient asks me a question and I don't know the answer, I'll ask a colleague who may have a similar albeit distinct patient with sarcoma. We'll even establish international collaborations. Those patients will start to talk to each other through chat rooms and support groups. It's through this kind of humbly curious communication that we begin to try and learn new things. Hopefully, science remains curious enough to look for and humble enough to recognize when we have found the next outlier, the next exception which teaches us what we don't actually know. A colleague of mine removed a tumor from a patient's limb. He was concerned about this tumor, but his conversations with the patient were exactly what a patient might want. He said I got it all, and you're good to go. She and her husband were thrilled. They went out celebrated, fancy dinner, opened a bottle of champagne. The only problem was a few weeks later, she started to notice another nodule in the same area. Turned out, he hadn't gotten it all, and she wasn't good to go. My colleague came to me and said, Kevin, would you mind looking after this patient for me? I said why? You know the right thing to do as well as I do. You haven't done anything wrong. He said please just look after this patient for me. He was embarrassed, not by what he had done, but by the conversation that he had had, by the overconfidence. So I performed a much more invasive surgery and had a very different conversation with the patient afterwards. I said most likely I've gotten it all, and you're most likely good to go. But this is the experiment that we're doing. We're going to work together to find out if this surgery will work to get rid of your cancer. (SOUNDBITE OF MUSIC)RAZ: So basically, you just told her, like, she would always need to be a little uncertain? JONES: Yeah. We never know completely. We have to be careful about coming across as overly confident. I mean, patients respond very well to physicians who are brimming with confidence. But if it doesn't work - you know, they're taking whatever pill and whatever it was is not getting better - they're kind of banging their head against a wall. And they say, either I did something wrong or my physician's an idiot or (laughter), you know, they start to have incredible distrust of the process. RAZ: So, I mean, you're saying, like, acknowledge, you know, the room for error - right? - for uncertainty with patients. JONES: Absolutely, absolutely. You know, you could either have a physician who's a used car salesman or something who says don't pay attention to all these holes that are in our abilities and in our our knowledge. Or you can have a physician that basically functions as a teacher, as a mentor, in the process of going through this experience and sort of standing next to the patient and pointing out the holes (laughter). This is what we don't know. This is what we're yet to find out. And I still think that we can acknowledge, look, I don't have a black-and-white answer for you because it doesn't exist. Anybody who gives you a black-and-white answer is either bluffing or is making up some part of it. (SOUNDBITE OF TED TALK)JONES: Almost 20 billion times each year, a person walks into a doctor's office, and that person becomes a patient. You or someone you love will be that patient sometime very soon. How will you talk to your doctors? What will they tell you? I have conversations with these patients with rare and deadly diseases. These conversations are terribly fraught. They're fraught with horrible phrases like I have bad news or there's nothing more we can do. Sometimes these conversations turn on a single word - terminal. Silence can also be rather uncomfortable. Where the blanks are in medicine can be just as important as the words that we use in these conversations. What are the unknowns? What are the experiments that are being done? I'll never forget the night that I walked into one of my patients' rooms. He was a boy I had diagnosed with a bone cancer a few days before. It was almost midnight when I got to his room. He was asleep. But I found his mother reading by flashlight next to his bed. Turned out that what she had been reading was the protocol that the chemotherapy doctors had given her that day. She had memorized it. She said, Dr. Jones, you told me that we don't always win with this type of cancer. But I've been studying this protocol, and I think I can do it. I think I can comply with these very difficult treatments. I'm going to quit my job. I'm going to move in with my parents. I'm going to keep my baby safe. I didn't tell her. I didn't stop to correct her thinking. She was trusting in a protocol that, even if complied with, wouldn't necessarily save her son. I didn't fill in that blank. But a year and a half later, her boy, nonetheless, died of his cancer. Should I have told her? (SOUNDBITE OF MUSIC)RAZ: One of the things you said in another part of your talk, Kevin, is that you see every patient as, like, a new experiment, right? And every time, it's a gamble of if it's going to work or not. JONES: Yeah. We're going to find out with someone's life and health, and so it counts. It matters. You know, it's interesting because I think we all like stories, right? We like a beginning and a middle and an end. And so scientists are wanting to tell a story. And the challenge is that sometimes the story can carry us away. And so if we don't have humility, then we will stop honestly inquiring about things. And so that's why I really think that the humility is critical because we have to sort of hold ourselves back. We have to rein ourselves in when we are so excited about a story that we can start to see things where they aren't really there. RAZ: Yeah. Yeah, I mean, we're wired to ask questions, right? Like as Michael Stevens said earlier, you know, like, we sort of emerged from the savannas of East Africa out into the wider world because we were curious. JONES: Yeah. We ask questions, yeah, totally agree. And what's so critical, I think, is asking the correct questions. And really, we cannot really say with science what is going to happen. We can guess and then we can test it and see what happens. So I really think the key is asking the correct questions. What can I do? What can I choose? And can I test that moving forward? I love that about scientific inquiry is that it is intrinsically forward-looking. (SOUNDBITE OF MUSIC)RAZ: Dr. Kevin Jones - you can see his full talk at ted. com. On the show today, ideas about The Spirit Of Inquiry. I'm Guy Raz, and you're listening to the TED Radio Hour from NPR. GUY RAZ, HOST:  On the show today, the Spirit of Inquiry, why the question is often more important than the answer and what happens when one question leads to another? KEVIN JONES: That's how every medical interview that I have with a patient begins - questions that they have, questions I have for them, trying to put the pieces together and understand what's happening. RAZ: This is Kevin Jones. He's a surgeon who specializes in a rare group of cancers called sarcomas. And he says doctors, no matter how many questions they ask, definitely don't have all the answers. JONES: I mean, there's been a fairly paternalistic view of medicine where we just kind of - we take care of patients, you know. We manage all this uncertainty and things for them. And I just - I react unhappily to that because I think that there is an element of - certainly not malintent, but there's an element of dishonesty when we presume to know more than we know. RAZ: I mean, somebody in your position is sought out to give answers, right? Like patients come to you, they say Dr. Jones, you know, am I going to die? And you don't always have the answers. JONES: Absolutely. No, I mean, we - especially when it comes down to predictions, I mean, just like the weathermen, we're terrible at making predictions. And yet we have to. RAZ: Here's Kevin Jones on the TED stage. (SOUNDBITE OF TED TALK) JONES: Medicine is science. Medicine is knowledge in process. Sometimes in the media and even more rarely, but sometimes even scientists will say that something or other has been scientifically proven. But I hope that you understand that science never proves anything definitively forever. Now, I am a surgeon, and I would tell you that every one of my patients is an outlier is an exception. People talk about thinking outside the box, but we don't even have a box in sarcoma. What we do have is we take a bath in the uncertainty and unknowns and exceptions and outliers that surround us in sarcoma is easy access to what I think are those two most important values for any science - humility and curiosity. Because if I am humble and curious when a patient asks me a question and I don't know the answer, I'll ask a colleague who may have a similar albeit distinct patient with sarcoma. We'll even establish international collaborations. Those patients will start to talk to each other through chat rooms and support groups. It's through this kind of humbly curious communication that we begin to try and learn new things. Hopefully, science remains curious enough to look for and humble enough to recognize when we have found the next outlier, the next exception which teaches us what we don't actually know. A colleague of mine removed a tumor from a patient's limb. He was concerned about this tumor, but his conversations with the patient were exactly what a patient might want. He said I got it all, and you're good to go. She and her husband were thrilled. They went out celebrated, fancy dinner, opened a bottle of champagne. The only problem was a few weeks later, she started to notice another nodule in the same area. Turned out, he hadn't gotten it all, and she wasn't good to go. My colleague came to me and said, Kevin, would you mind looking after this patient for me? I said why? You know the right thing to do as well as I do. You haven't done anything wrong. He said please just look after this patient for me. He was embarrassed, not by what he had done, but by the conversation that he had had, by the overconfidence. So I performed a much more invasive surgery and had a very different conversation with the patient afterwards. I said most likely I've gotten it all, and you're most likely good to go. But this is the experiment that we're doing. We're going to work together to find out if this surgery will work to get rid of your cancer. (SOUNDBITE OF MUSIC) RAZ: So basically, you just told her, like, she would always need to be a little uncertain? JONES: Yeah. We never know completely. We have to be careful about coming across as overly confident. I mean, patients respond very well to physicians who are brimming with confidence. But if it doesn't work - you know, they're taking whatever pill and whatever it was is not getting better - they're kind of banging their head against a wall. And they say, either I did something wrong or my physician's an idiot or (laughter), you know, they start to have incredible distrust of the process. RAZ: So, I mean, you're saying, like, acknowledge, you know, the room for error - right? - for uncertainty with patients. JONES: Absolutely, absolutely. You know, you could either have a physician who's a used car salesman or something who says don't pay attention to all these holes that are in our abilities and in our our knowledge. Or you can have a physician that basically functions as a teacher, as a mentor, in the process of going through this experience and sort of standing next to the patient and pointing out the holes (laughter). This is what we don't know. This is what we're yet to find out. And I still think that we can acknowledge, look, I don't have a black-and-white answer for you because it doesn't exist. Anybody who gives you a black-and-white answer is either bluffing or is making up some part of it. (SOUNDBITE OF TED TALK) JONES: Almost 20 billion times each year, a person walks into a doctor's office, and that person becomes a patient. You or someone you love will be that patient sometime very soon. How will you talk to your doctors? What will they tell you? I have conversations with these patients with rare and deadly diseases. These conversations are terribly fraught. They're fraught with horrible phrases like I have bad news or there's nothing more we can do. Sometimes these conversations turn on a single word - terminal. Silence can also be rather uncomfortable. Where the blanks are in medicine can be just as important as the words that we use in these conversations. What are the unknowns? What are the experiments that are being done? I'll never forget the night that I walked into one of my patients' rooms. He was a boy I had diagnosed with a bone cancer a few days before. It was almost midnight when I got to his room. He was asleep. But I found his mother reading by flashlight next to his bed. Turned out that what she had been reading was the protocol that the chemotherapy doctors had given her that day. She had memorized it. She said, Dr. Jones, you told me that we don't always win with this type of cancer. But I've been studying this protocol, and I think I can do it. I think I can comply with these very difficult treatments. I'm going to quit my job. I'm going to move in with my parents. I'm going to keep my baby safe. I didn't tell her. I didn't stop to correct her thinking. She was trusting in a protocol that, even if complied with, wouldn't necessarily save her son. I didn't fill in that blank. But a year and a half later, her boy, nonetheless, died of his cancer. Should I have told her? (SOUNDBITE OF MUSIC) RAZ: One of the things you said in another part of your talk, Kevin, is that you see every patient as, like, a new experiment, right? And every time, it's a gamble of if it's going to work or not. JONES: Yeah. We're going to find out with someone's life and health, and so it counts. It matters. You know, it's interesting because I think we all like stories, right? We like a beginning and a middle and an end. And so scientists are wanting to tell a story. And the challenge is that sometimes the story can carry us away. And so if we don't have humility, then we will stop honestly inquiring about things. And so that's why I really think that the humility is critical because we have to sort of hold ourselves back. We have to rein ourselves in when we are so excited about a story that we can start to see things where they aren't really there. RAZ: Yeah. Yeah, I mean, we're wired to ask questions, right? Like as Michael Stevens said earlier, you know, like, we sort of emerged from the savannas of East Africa out into the wider world because we were curious. JONES: Yeah. We ask questions, yeah, totally agree. And what's so critical, I think, is asking the correct questions. And really, we cannot really say with science what is going to happen. We can guess and then we can test it and see what happens. So I really think the key is asking the correct questions. What can I do? What can I choose? And can I test that moving forward? I love that about scientific inquiry is that it is intrinsically forward-looking. (SOUNDBITE OF MUSIC) RAZ: Dr. Kevin Jones - you can see his full talk at ted. com. On the show today, ideas about The Spirit Of Inquiry. I'm Guy Raz, and you're listening to the TED Radio Hour from NPR.", "section": "TED Radio Hour", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-02-24-516726045": {"title": "Liz Coleman: How Do We Teach College Students To Ask Big Questions? : NPR", "url": "https://www.npr.org/2017/02/24/516726045/liz-coleman-how-do-we-teach-college-students-to-ask-big-questions", "author": "No author found", "published_date": "2017-02-24", "content": "GUY RAZ, HOST: It's the TED Radio Hour from NPR. I'm Guy Raz, and on the show today, ideas about the Spirit Of Inquiry. (SOUNDBITE OF MUSIC)RAZ: And when it comes to the unknown on any subject, we're all kind of trained to seek out experts. LIZ COLEMAN: The model of the expert, which has dominated our intellectual life for a century now, is not a model of inquiry at all. RAZ: This is Liz Coleman. COLEMAN: It's a model of command. It's a model of knowing more than the other person. It's a model in which what the expert does is what matters. And the job of the, quote, \"student\" is to absorb. RAZ: Liz was president of Bennington College in Vermont for more than 25 years. And she argues that we've lost this desire to be interested in many different things because we live in an age where the expert is king. COLEMAN: It's not easy when a system is built on that version of accomplishment, when narrowing your sights is treated as a virtue. We all use the language of experts and of separating things. RAZ: Here's how Liz Coleman put it on the TED stage. (SOUNDBITE OF TED TALK)COLEMAN: The progression of today's college student is to jettison every interest except one and within that one, to continually narrow the focus, learning more and more about less and less. This, despite the evidence all around us of the interconnectedness of things. As one moves up the ladder, values other than technical competence are viewed with increasing suspicion. Questions such as, what kind of a world are we making, what kind of a world should we be making, what kind of a world can we be making, are treated with more and more skepticism and move off the table. (SOUNDBITE OF MUSIC)RAZ: Liz Coleman says that by narrowing the focus of our questions, we lose out on how they connect to the big ones. And without people thinking about the big questions, there will be consequences. Take, for example, climate change. COLEMAN: So we have this absurd idea that the scientists should figure out what's wrong with the situation vis-a-vis the environment. And then they hand it over to the politicians that are supposed to figure out what to do. Until the thinking and the action become inseparable, we're not going to get where we need to get. RAZ: When you think about the people who discover things - right? - the people who we depend on for information, and most of those people are academics or researchers, but then you think about the people who - I'm trying to think of the best way to put it - like 360-degree people who could really communicate a variety of ideas, Renaissance people, in sort of the modern age. I can think of, like, Richard Feynman or Stephen Jay Gould or Neil deGrasse Tyson or Vera Rubin. COLEMAN: RightRAZ: Like, they stand out because they felt like they could talk about literature and science and the cosmos and philosophy all at the same time. COLEMAN: Yeah, it's very interesting, and one of the most intriguing things about that - almost all of them are scientists. And it's fascinating that we think of the sciences as the most highly technical of any of the disciplines. So, for example, we think about literature, history, psychology as more available, but in fact, the great leaders who have really made some of their wisdom and their insight available to the largest number of people are almost all scientists. (SOUNDBITE OF MUSIC)COLEMAN: Einstein spent a lot of time talking about his ideas and indeed other ideas. That's itself very interesting. What's even more interesting and disconcerting is - what's happened in literature is the opposite so that in literature the criticism has become less and less something that has possible resonance for people across the divides. (SOUNDBITE OF TED TALK)COLEMAN: The importance of coming to grips with values like justice, equity, truth, becomes increasingly evident as students discover that interest alone cannot tell them what they need to know when the issue is rethinking education, our approach to health or strategies for achieving an economics of equity. The value of the past also comes alive. You are not the first to try to figure this out, just as you are unlikely to be the last. Even more valuable, history provides a laboratory in which we see played out the actual as well as the intended consequences of ideas. In the language of my students, deep thought matters when you are contemplating what to do about things that matter. (SOUNDBITE OF MUSIC)RAZ: Liz, when you gave this talk eight years ago, it was cautionary. I mean, you were warning. It was a warning. And it was. . . COLEMAN: Yeah. RAZ: And some people in the audience might've thought you were being alarmist. And I wonder now, you know, eight years on, when you look at sort of the future and where we're headed as a country, as a culture, are you worried? COLEMAN: Of course because the risks are huge. And when the risks are huge, you worry. At the same time, I do think that there is a different sense of urgency. What is important is that there is an awakening in this country to the dimensions both of what's at stake and how much it is in danger. One of the most powerful things to me about the act of thinking and about democracy, actually, is the extent to which being able to engage the challenge of that with other people is an extraordinary experience. It's what's called deliberation. It began the United States. It's a very powerful part of our history and very relevant today because of its absence. And hopefully one of the things that the evident urgencies of our time may generate is a return to that art of people collecting and thinking out loud together. RAZ: Liz Coleman, former president of Bennington College in Vermont. You can hear her full talk at ted. com. (SOUNDBITE OF MUSIC) GUY RAZ, HOST:  It's the TED Radio Hour from NPR. I'm Guy Raz, and on the show today, ideas about the Spirit Of Inquiry. (SOUNDBITE OF MUSIC) RAZ: And when it comes to the unknown on any subject, we're all kind of trained to seek out experts. LIZ COLEMAN: The model of the expert, which has dominated our intellectual life for a century now, is not a model of inquiry at all. RAZ: This is Liz Coleman. COLEMAN: It's a model of command. It's a model of knowing more than the other person. It's a model in which what the expert does is what matters. And the job of the, quote, \"student\" is to absorb. RAZ: Liz was president of Bennington College in Vermont for more than 25 years. And she argues that we've lost this desire to be interested in many different things because we live in an age where the expert is king. COLEMAN: It's not easy when a system is built on that version of accomplishment, when narrowing your sights is treated as a virtue. We all use the language of experts and of separating things. RAZ: Here's how Liz Coleman put it on the TED stage. (SOUNDBITE OF TED TALK) COLEMAN: The progression of today's college student is to jettison every interest except one and within that one, to continually narrow the focus, learning more and more about less and less. This, despite the evidence all around us of the interconnectedness of things. As one moves up the ladder, values other than technical competence are viewed with increasing suspicion. Questions such as, what kind of a world are we making, what kind of a world should we be making, what kind of a world can we be making, are treated with more and more skepticism and move off the table. (SOUNDBITE OF MUSIC) RAZ: Liz Coleman says that by narrowing the focus of our questions, we lose out on how they connect to the big ones. And without people thinking about the big questions, there will be consequences. Take, for example, climate change. COLEMAN: So we have this absurd idea that the scientists should figure out what's wrong with the situation vis-a-vis the environment. And then they hand it over to the politicians that are supposed to figure out what to do. Until the thinking and the action become inseparable, we're not going to get where we need to get. RAZ: When you think about the people who discover things - right? - the people who we depend on for information, and most of those people are academics or researchers, but then you think about the people who - I'm trying to think of the best way to put it - like 360-degree people who could really communicate a variety of ideas, Renaissance people, in sort of the modern age. I can think of, like, Richard Feynman or Stephen Jay Gould or Neil deGrasse Tyson or Vera Rubin. COLEMAN: Right RAZ: Like, they stand out because they felt like they could talk about literature and science and the cosmos and philosophy all at the same time. COLEMAN: Yeah, it's very interesting, and one of the most intriguing things about that - almost all of them are scientists. And it's fascinating that we think of the sciences as the most highly technical of any of the disciplines. So, for example, we think about literature, history, psychology as more available, but in fact, the great leaders who have really made some of their wisdom and their insight available to the largest number of people are almost all scientists. (SOUNDBITE OF MUSIC) COLEMAN: Einstein spent a lot of time talking about his ideas and indeed other ideas. That's itself very interesting. What's even more interesting and disconcerting is - what's happened in literature is the opposite so that in literature the criticism has become less and less something that has possible resonance for people across the divides. (SOUNDBITE OF TED TALK) COLEMAN: The importance of coming to grips with values like justice, equity, truth, becomes increasingly evident as students discover that interest alone cannot tell them what they need to know when the issue is rethinking education, our approach to health or strategies for achieving an economics of equity. The value of the past also comes alive. You are not the first to try to figure this out, just as you are unlikely to be the last. Even more valuable, history provides a laboratory in which we see played out the actual as well as the intended consequences of ideas. In the language of my students, deep thought matters when you are contemplating what to do about things that matter. (SOUNDBITE OF MUSIC) RAZ: Liz, when you gave this talk eight years ago, it was cautionary. I mean, you were warning. It was a warning. And it was. . . COLEMAN: Yeah. RAZ: And some people in the audience might've thought you were being alarmist. And I wonder now, you know, eight years on, when you look at sort of the future and where we're headed as a country, as a culture, are you worried? COLEMAN: Of course because the risks are huge. And when the risks are huge, you worry. At the same time, I do think that there is a different sense of urgency. What is important is that there is an awakening in this country to the dimensions both of what's at stake and how much it is in danger. One of the most powerful things to me about the act of thinking and about democracy, actually, is the extent to which being able to engage the challenge of that with other people is an extraordinary experience. It's what's called deliberation. It began the United States. It's a very powerful part of our history and very relevant today because of its absence. And hopefully one of the things that the evident urgencies of our time may generate is a return to that art of people collecting and thinking out loud together. RAZ: Liz Coleman, former president of Bennington College in Vermont. You can hear her full talk at ted. com. (SOUNDBITE OF MUSIC)", "section": "TED Radio Hour", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-02-27-517563127": {"title": "Can Sex Offenders Be Barred From Social Media? Justices Lean Toward No : NPR", "url": "https://www.npr.org/2017/02/27/517563127/can-sex-offenders-be-barred-from-social-media-justices-lean-toward-no", "author": "No author found", "published_date": "2017-02-27", "content": "", "section": "Law", "disclaimer": ""}, "2017-02-27-517563179": {"title": "Privacy Paradox: How To Gain More Control Over Your Data : NPR", "url": "https://www.npr.org/2017/02/27/517563179/privacy-paradox-how-to-gain-more-control-over-your-data", "author": "No author found", "published_date": "2017-02-27", "content": "AUDIE CORNISH, HOST: We've been working with our friends at WNYC's podcast \"Note To Self\" on a little experiment to give people more control over the information they share online. It's called The Privacy Paradox. And Manoush Zomorodi is back to talk more about it. Hey there, Manoush. MANOUSH ZOMORODI, BYLINE: Hello, Audie. CORNISH: So first just remind us what you were having people do in the way of an experiment. ZOMORODI: OK. So digital privacy - obviously it's a huge topic. And so what we did is we broke it down into five parts to really explain how we all get tracked and profiled online. And then we had easy tasks that listeners could do that would help them take back a little bit of control over their digital identity. For example, we explain the difference between all the data versus the metadata coming out of our phones. And then we ask people to do something that many of us just don't bother with. Really dig down into the app settings on your phone. See what information these apps are collecting that they don't actually need to function, like a recipe app that wants access to your contacts. Here's what happened to one listener, Dan Clarkson, in Manhattan. DAN CLARKSON: The best thing I discovered was that my flashlight app had access to my microphone and my contacts and my location. That app got the ax. CORNISH: OK, this is crazy to me (laughter) because this is the kind of app you would not go digging in the settings for - right? - for this precise reason. You're like, I just need light. That's enough. What were some of the other kind of more common responses you heard from people as they started rooting around in the settings? ZOMORODI: Surprise, irritation at how greedy some of these apps are that they want to sell all kinds of your digital behavior, not just the product. And we heard from listeners how frustrating it is that they have to specifically opt out of being tracked. CORNISH: And I should say, people do do this, right? This is kind of digital privacy 101. So how did you guys step it up from there? ZOMORODI: We asked advanced people to text us using an encrypted text messaging app called Signal because as we explained, even if you don't think that you need private texting, there are people in this country who are worried that their beliefs or origins could be held against them, and they do want private communication. So the idea being that the more people who use apps like Signal, the less suspect they become. And I heard this great metaphor from a cryptographer, Audie, that if everyone uses a postcard, then an envelope is suspicious. But if everyone uses an envelope, it's just an envelope. And by the way, Audie, reportedly there are some under the new administration, like scientists at the EPA, who are using encrypted text messaging, too, to discuss now-divisive issues like the country's environmental agenda. CORNISH: And I should note many journalists are using it, including me. So you're kind of making me feel better about that with that envelope analogy. ZOMORODI: Good. That makes me happy. CORNISH: Now, after completing your Privacy Paradox experiment, did people say they actually felt that they were more in control of their personal information online? Is that even possible actually? ZOMORODI: Well, I think people felt they did get back some control, or at least they understood what it feels like to have a little control. But also, they realized how much privacy does matter to them. So before the project, 43 percent of those we surveyed said they knew how to get more privacy into their life. After the project, that number went up to 80 percent. CORNISH: Wow. ZOMORODI: Yeah. Many of them told us they felt inspired to change the way they live online. So one listener said that she went through; she deleted all the old social media accounts that are floating around the web that she doesn't use anymore. Another person said she got an email from her IT department, and instead of just going ahead and doing what they asked her to do, she called them back and asked questions. We heard from digital marketers who said that actually they have decided to maybe look for another job - so all kinds of different ways that people reacted. CORNISH: Well, we should tell people that they can still get involved. The Privacy Paradox experiment is still going on. What happens next? ZOMORODI: Well, Audie, we spend nearly half of every day in front of a screen. And so I think more and more of us are understanding that our right to privacy needs to be protected online as well as off. Seventy-four percent of those we surveyed said that learning more about this issue has made them want to take action. And, yes, as you said, the project lives on. You can join any time. CORNISH: That's Manoush Zomorodi, host of the podcast \"Note To Self\" from member station WNYC. You can sign up for The Privacy Paradox at the All Tech Considered blog on npr. org. Manoush, thanks so much. ZOMORODI: Always a pleasure, Audie. (SOUNDBITE OF NATIONAL SYMPHONY ORCHESTRA PERFORMANCE OF ROSSINI'S \"LA DANZA\") AUDIE CORNISH, HOST:  We've been working with our friends at WNYC's podcast \"Note To Self\" on a little experiment to give people more control over the information they share online. It's called The Privacy Paradox. And Manoush Zomorodi is back to talk more about it. Hey there, Manoush. MANOUSH ZOMORODI, BYLINE: Hello, Audie. CORNISH: So first just remind us what you were having people do in the way of an experiment. ZOMORODI: OK. So digital privacy - obviously it's a huge topic. And so what we did is we broke it down into five parts to really explain how we all get tracked and profiled online. And then we had easy tasks that listeners could do that would help them take back a little bit of control over their digital identity. For example, we explain the difference between all the data versus the metadata coming out of our phones. And then we ask people to do something that many of us just don't bother with. Really dig down into the app settings on your phone. See what information these apps are collecting that they don't actually need to function, like a recipe app that wants access to your contacts. Here's what happened to one listener, Dan Clarkson, in Manhattan. DAN CLARKSON: The best thing I discovered was that my flashlight app had access to my microphone and my contacts and my location. That app got the ax. CORNISH: OK, this is crazy to me (laughter) because this is the kind of app you would not go digging in the settings for - right? - for this precise reason. You're like, I just need light. That's enough. What were some of the other kind of more common responses you heard from people as they started rooting around in the settings? ZOMORODI: Surprise, irritation at how greedy some of these apps are that they want to sell all kinds of your digital behavior, not just the product. And we heard from listeners how frustrating it is that they have to specifically opt out of being tracked. CORNISH: And I should say, people do do this, right? This is kind of digital privacy 101. So how did you guys step it up from there? ZOMORODI: We asked advanced people to text us using an encrypted text messaging app called Signal because as we explained, even if you don't think that you need private texting, there are people in this country who are worried that their beliefs or origins could be held against them, and they do want private communication. So the idea being that the more people who use apps like Signal, the less suspect they become. And I heard this great metaphor from a cryptographer, Audie, that if everyone uses a postcard, then an envelope is suspicious. But if everyone uses an envelope, it's just an envelope. And by the way, Audie, reportedly there are some under the new administration, like scientists at the EPA, who are using encrypted text messaging, too, to discuss now-divisive issues like the country's environmental agenda. CORNISH: And I should note many journalists are using it, including me. So you're kind of making me feel better about that with that envelope analogy. ZOMORODI: Good. That makes me happy. CORNISH: Now, after completing your Privacy Paradox experiment, did people say they actually felt that they were more in control of their personal information online? Is that even possible actually? ZOMORODI: Well, I think people felt they did get back some control, or at least they understood what it feels like to have a little control. But also, they realized how much privacy does matter to them. So before the project, 43 percent of those we surveyed said they knew how to get more privacy into their life. After the project, that number went up to 80 percent. CORNISH: Wow. ZOMORODI: Yeah. Many of them told us they felt inspired to change the way they live online. So one listener said that she went through; she deleted all the old social media accounts that are floating around the web that she doesn't use anymore. Another person said she got an email from her IT department, and instead of just going ahead and doing what they asked her to do, she called them back and asked questions. We heard from digital marketers who said that actually they have decided to maybe look for another job - so all kinds of different ways that people reacted. CORNISH: Well, we should tell people that they can still get involved. The Privacy Paradox experiment is still going on. What happens next? ZOMORODI: Well, Audie, we spend nearly half of every day in front of a screen. And so I think more and more of us are understanding that our right to privacy needs to be protected online as well as off. Seventy-four percent of those we surveyed said that learning more about this issue has made them want to take action. And, yes, as you said, the project lives on. You can join any time. CORNISH: That's Manoush Zomorodi, host of the podcast \"Note To Self\" from member station WNYC. You can sign up for The Privacy Paradox at the All Tech Considered blog on npr. org. Manoush, thanks so much. ZOMORODI: Always a pleasure, Audie. (SOUNDBITE OF NATIONAL SYMPHONY ORCHESTRA PERFORMANCE OF ROSSINI'S \"LA DANZA\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-02-28-517779794": {"title": "HMD Global Plans To Bring Back Nokia 3310 Cellphone : NPR", "url": "https://www.npr.org/2017/02/28/517779794/hmd-global-plans-to-bring-back-nokia-3310-cell-phone", "author": "No author found", "published_date": "2017-02-28", "content": "ARI SHAPIRO, HOST: Now the story of a surprising comeback. (SOUNDBITE OF RINGTONE)AUDIE CORNISH, HOST: That beautiful sound is the ring tone of the trusty Nokia 3310. SHAPIRO: The 3310 was once one of the most ubiquitous cell phones. It's the definition of no frills, chunky, small, with a screen just an inch and a half across above a number keypad. CORNISH: Nokia sold more than 126 million of the little bricks before discontinuing production in 2005, as smartphones were starting to take off. SHAPIRO: Now the Nokia 3310 is back. Last weekend, a Finnish company called HMD Global announced that it would be relaunching the phone. CORNISH: Yahoo Finance tech critic David Pogue says the 3310 has not been updated for the times. DAVID POGUE: You can't install apps on it. You can't use GPS on it. The camera is terrible. It has no alphabet keyboards or the inability to type words in text messages in an efficient way. (Laughter) I'm not sure even your tween would want it. SHAPIRO: But it can still do the basics, send texts, set an alarm, even make phone calls. POGUE: It has a really long battery life. So 22 hours of talking and a month of standby. So it's literally the phone that you can toss in your glove compartment or your kitchen drawer and just use it when you need it. SHAPIRO: Also very important - it can play \"Snake\" in color. CORNISH: Tech critic David Pogue also says the phone can help people in developing countries. POGUE: This phone is intended for the farmer in Kenya who needs to wire money back to his family in the village. For a lot of these folks, having a color screen and a camera would actually be an upgrade. SHAPIRO: And that's what HMD Global, the phone's newest maker, is counting on. CORNISH: That and a little nostalgia. POGUE: It knows what it wants to be. It has a personality. It has a target audience. And it has a purpose in life. SHAPIRO: And, really, can a phone ask for any more? CORNISH: There's no word on whether the phone will be sold in American stores yet. But it can be purchased online later this year. (SOUNDBITE OF FRANCSICO TARREGA SONG, \"GRAN VALS\") ARI SHAPIRO, HOST:  Now the story of a surprising comeback. (SOUNDBITE OF RINGTONE) AUDIE CORNISH, HOST:  That beautiful sound is the ring tone of the trusty Nokia 3310. SHAPIRO: The 3310 was once one of the most ubiquitous cell phones. It's the definition of no frills, chunky, small, with a screen just an inch and a half across above a number keypad. CORNISH: Nokia sold more than 126 million of the little bricks before discontinuing production in 2005, as smartphones were starting to take off. SHAPIRO: Now the Nokia 3310 is back. Last weekend, a Finnish company called HMD Global announced that it would be relaunching the phone. CORNISH: Yahoo Finance tech critic David Pogue says the 3310 has not been updated for the times. DAVID POGUE: You can't install apps on it. You can't use GPS on it. The camera is terrible. It has no alphabet keyboards or the inability to type words in text messages in an efficient way. (Laughter) I'm not sure even your tween would want it. SHAPIRO: But it can still do the basics, send texts, set an alarm, even make phone calls. POGUE: It has a really long battery life. So 22 hours of talking and a month of standby. So it's literally the phone that you can toss in your glove compartment or your kitchen drawer and just use it when you need it. SHAPIRO: Also very important - it can play \"Snake\" in color. CORNISH: Tech critic David Pogue also says the phone can help people in developing countries. POGUE: This phone is intended for the farmer in Kenya who needs to wire money back to his family in the village. For a lot of these folks, having a color screen and a camera would actually be an upgrade. SHAPIRO: And that's what HMD Global, the phone's newest maker, is counting on. CORNISH: That and a little nostalgia. POGUE: It knows what it wants to be. It has a personality. It has a target audience. And it has a purpose in life. SHAPIRO: And, really, can a phone ask for any more? CORNISH: There's no word on whether the phone will be sold in American stores yet. But it can be purchased online later this year. (SOUNDBITE OF FRANCSICO TARREGA SONG, \"GRAN VALS\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-03-01-517988142": {"title": "Uber CEO Apologizes Over Video Of Dispute With Driver : NPR", "url": "https://www.npr.org/2017/03/01/517988142/uber-ceo-apologizes-over-video-of-dispute-with-driver", "author": "No author found", "published_date": "2017-03-01", "content": "ROBERT SIEGEL, HOST: The ride share company Uber has been under fire, and the newest source of controversy is a video recorded by an Uber driver. It's a dash camera video that shows a testy argument with an aggravated, cursing passenger. The passenger was Travis Kalanick, the company's CEO. NPR's Alina Selyukh reports. ALINA SELYUKH, BYLINE: It starts out as a normal kind of Uber ride - civil, a bit awkward. Uber CEO is in center-back seat flanked by two women. They chat. One woman mentions the rough year Uber is having. CEO Travis Kalanick says, if it were easy, then he's not pushing hard enough. The trip wraps up next. (SOUNDBITE OF ARCHIVED RECORDING)TRAVIS KALANICK: There it is. There it is. So we. . . SELYUKH: The women get out, and Kalanick shakes hands with the driver who says he's been with Uber since 2010. He drives for the higher-end UberBLACK service. (SOUNDBITE OF ARCHIVED RECORDING)FAWZI KAMEL: But you, you're raising the standards, and you're dropping the prices. KALANICK: We're not dropping the price on Black. SELYUKH: The driver says he's lost money, even gone bankrupt. He and the CEO debate for a bit, but then Kalanick gets annoyed and winds up cursing. (SOUNDBITE OF ARCHIVED RECORDING)KALANICK: What have I changed about Black? What have I changed? KAMEL: You changed the whole business. KALANICK: What? What? KAMEL: You dropped the prices. KALANICK: On Black? KAMEL: Yes. KALANICK: [Expletive]. KAMEL: We started with $20. KALANICK: [Expletive]. KAMEL: Started with $20. KALANICK: You know what? KAMEL: How much is the mile now, $2. 75? KALANICK: You know what? KAMEL: What? KALANICK: Some people don't like to take responsibility for their own [expletive]. KAMEL: (Unintelligible). KALANICK: They blame everything in their life on somebody else. KAMEL: But why you sending an email for town car? KALANICK: Good luck. SELYUKH: The driver sent this dash cam video to Bloomberg, prompting a public apology from Kalanick. His email to staff is frank. He says he's ashamed for treating the driver disrespectfully, that he needs to change as a leader and, quote, \"grow up. \"FREADA KAPOR KLEIN: It's embarrassing. It's not CEO-like behavior. SELYUKH: That's Freada Kapor Klein, a partner at Kapor Capital, one of the earliest investors in Uber. I caught her as she was commuting to work, and she says Uber became a success on a no-holds-barred strategy - breaking into a regulated industry. But it's dangerous when it runs amok, especially internally. KAPOR: One has to be very thoughtful about managing business aggression and giving it very clear boundaries of how it gets expressed and where its limits are. SELYUKH: And you think that has not happened at Uber yet. KAPOR: No. SELYUKH: In fact, Kalanick has been apologizing a lot lately. He stepped down from President Trump's business council after a massive delete Uber campaign protesting the company's response to the refugee ban. He's launched an internal investigation after a female former engineer publicly detailed a sustained culture of sexism. And there are lots of other ongoing legal and regulatory battles over self-driving cars and driver benefits. ROSABETH MOSS KANTER: Adult supervision might have been a good idea. SELYUKH: Rosabeth Moss Kanter is a business professor at Harvard, and she echoes a common argument about Uber. Eventually startup founders need seasoned diplomatic oversight. KANTER: That's why Google, Larry Page, went to Eric Schmidt, and that's why Mark Zuckerberg got Sheryl Sandberg. SELYUKH: And Uber investor Kapor hopes that if the company actually makes changes and tackles its bro culture, it might set an example to the whole industry. Alina Selyukh, NPR News. (SOUNDBITE OF STRFKR SONG, \"MIRACLE MILE\") ROBERT SIEGEL, HOST:  The ride share company Uber has been under fire, and the newest source of controversy is a video recorded by an Uber driver. It's a dash camera video that shows a testy argument with an aggravated, cursing passenger. The passenger was Travis Kalanick, the company's CEO. NPR's Alina Selyukh reports. ALINA SELYUKH, BYLINE: It starts out as a normal kind of Uber ride - civil, a bit awkward. Uber CEO is in center-back seat flanked by two women. They chat. One woman mentions the rough year Uber is having. CEO Travis Kalanick says, if it were easy, then he's not pushing hard enough. The trip wraps up next. (SOUNDBITE OF ARCHIVED RECORDING) TRAVIS KALANICK: There it is. There it is. So we. . . SELYUKH: The women get out, and Kalanick shakes hands with the driver who says he's been with Uber since 2010. He drives for the higher-end UberBLACK service. (SOUNDBITE OF ARCHIVED RECORDING) FAWZI KAMEL: But you, you're raising the standards, and you're dropping the prices. KALANICK: We're not dropping the price on Black. SELYUKH: The driver says he's lost money, even gone bankrupt. He and the CEO debate for a bit, but then Kalanick gets annoyed and winds up cursing. (SOUNDBITE OF ARCHIVED RECORDING) KALANICK: What have I changed about Black? What have I changed? KAMEL: You changed the whole business. KALANICK: What? What? KAMEL: You dropped the prices. KALANICK: On Black? KAMEL: Yes. KALANICK: [Expletive]. KAMEL: We started with $20. KALANICK: [Expletive]. KAMEL: Started with $20. KALANICK: You know what? KAMEL: How much is the mile now, $2. 75? KALANICK: You know what? KAMEL: What? KALANICK: Some people don't like to take responsibility for their own [expletive]. KAMEL: (Unintelligible). KALANICK: They blame everything in their life on somebody else. KAMEL: But why you sending an email for town car? KALANICK: Good luck. SELYUKH: The driver sent this dash cam video to Bloomberg, prompting a public apology from Kalanick. His email to staff is frank. He says he's ashamed for treating the driver disrespectfully, that he needs to change as a leader and, quote, \"grow up. \" FREADA KAPOR KLEIN: It's embarrassing. It's not CEO-like behavior. SELYUKH: That's Freada Kapor Klein, a partner at Kapor Capital, one of the earliest investors in Uber. I caught her as she was commuting to work, and she says Uber became a success on a no-holds-barred strategy - breaking into a regulated industry. But it's dangerous when it runs amok, especially internally. KAPOR: One has to be very thoughtful about managing business aggression and giving it very clear boundaries of how it gets expressed and where its limits are. SELYUKH: And you think that has not happened at Uber yet. KAPOR: No. SELYUKH: In fact, Kalanick has been apologizing a lot lately. He stepped down from President Trump's business council after a massive delete Uber campaign protesting the company's response to the refugee ban. He's launched an internal investigation after a female former engineer publicly detailed a sustained culture of sexism. And there are lots of other ongoing legal and regulatory battles over self-driving cars and driver benefits. ROSABETH MOSS KANTER: Adult supervision might have been a good idea. SELYUKH: Rosabeth Moss Kanter is a business professor at Harvard, and she echoes a common argument about Uber. Eventually startup founders need seasoned diplomatic oversight. KANTER: That's why Google, Larry Page, went to Eric Schmidt, and that's why Mark Zuckerberg got Sheryl Sandberg. SELYUKH: And Uber investor Kapor hopes that if the company actually makes changes and tackles its bro culture, it might set an example to the whole industry. Alina Selyukh, NPR News. (SOUNDBITE OF STRFKR SONG, \"MIRACLE MILE\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-03-02-518197167": {"title": "Snapchat Goes Public In Largest Tech IPO Since Alibaba : NPR", "url": "https://www.npr.org/2017/03/02/518197167/snapchat-goes-public-in-largest-tech-ipo-since-alibaba", "author": "No author found", "published_date": "2017-03-02", "content": "AUDIE CORNISH, HOST: The company behind the popular video messaging service Snapchat went public today, and it was a rousing debut. Shares of Snap closed up 44 percent on its first day of trading. The company's core audience, 18- to 34-year-olds, is highly sought after by advertisers. And despite the exuberance, Snap faces the perennial challenge for all tech companies - how to make money. NPR's Sonari Glinton and Youth Radio's Natalie Bettendorf report. SONARI GLINTON, BYLINE: In the interest of full disclosure, I'm on Snapchat, but I don't understand it that much. And what I do know I've learned from my best friend's 17-year-old and my colleagues at Youth Radio like Natalie Bettendorf. NATALIE BETTENDORF, BYLINE: It's been something that I've been on since middle school. The problem is that there's this huge generation gap where young people are kind of understanding it intuitively while older people are just completely clueless. So I actually went and talked to Seth Marceau. He's 18. He's one of my co-workers here at Youth Radio. And he says that immediacy is actually really important. SETH MARCEAU, BYLINE: I think it's hard for older people to understand how to use Snapchat because it's so fast moving. BETTENDORF: Despite what older people might think, studies show that young people actually are pretty engaged in the news. But we're just not getting it from traditional places. I know that I get most of my news from Snapchat and same with 21-year-old Noel Anaya. NOEL ANAYA: The way they do their news is really straight-to-the-point, very quick, very brief. You get the main idea of a story. And it can be really juicy at times. BETTENDORF: The thing about Snapchat is that it's immediate. It forces you to live in the moment on that one picture, that one video that you're watching because after it closes, it's gone forever. GLINTON: All those things that Natalie described - how photos disappear and how engaged she and her colleagues are - have made Snapchat super valuable on Wall Street. LANCE ULANOFF: They always talk about 18 - that's their core market. But I really think it pushes more to, like, 13- to 25-year-olds. That's really the heart of Snapchat's audience. GLINTON: Lance Ulanoff is with the tech website Mashable. ULANOFF: And there's good news and bad news in that. The good news is super desirable. But about half of that audience doesn't have its own money to spend, which is a bit of an alarm bell for advertisers who want to advertise things and then have these people turn around and buy that stuff. GLINTON: Snapchat has gone public sooner in its evolution than Facebook or Twitter. And what makes it popular is that it is ephemeral, and that's long been a drawback and an advantage since the company's origins. Again, Lance Ulanoff. . . ULANOFF: Yeah (laughter), it's - you know, like with superheroes, they like to do the origin story. They might not want to do the Snapchat origin story because it would include all this sexting. You know, when Snapchat first came along, it was really thought of as a sexting app. GLINTON: The app makes it easy to seamlessly advertise in ways that people just don't notice. The problem for snapchat, though, is making money. The company lost more than $500 million last year even though now it's valued at more than $28 billion. Ulanoff says the challenge for Snapchat is not really making money but how to grow. He says it won't and can't stay a niche company for tweens and 20-somethings. It needs adults. ULANOFF: And, of course the real challenge will be, as it does that and as it becomes successful as a content platform, to maintain contact with the younger users who got it there in the first place. GLINTON: Yeah, it's like, Nathalie's having fun on Snapchat, but will she stop having fun if I'm there and the rest of America is? ULANOFF: That is a real question. It was a question with Facebook as well - as parents started flooding into Facebook and teens started pulling back. Snapchat is a much smaller platform, faces much tougher odds, especially on the competition side. GLINTON: For my Youth Radio colleague Natalie Bettendorf who had run to class, I'm Sonari Glinton, NPR News. AUDIE CORNISH, HOST:  The company behind the popular video messaging service Snapchat went public today, and it was a rousing debut. Shares of Snap closed up 44 percent on its first day of trading. The company's core audience, 18- to 34-year-olds, is highly sought after by advertisers. And despite the exuberance, Snap faces the perennial challenge for all tech companies - how to make money. NPR's Sonari Glinton and Youth Radio's Natalie Bettendorf report. SONARI GLINTON, BYLINE: In the interest of full disclosure, I'm on Snapchat, but I don't understand it that much. And what I do know I've learned from my best friend's 17-year-old and my colleagues at Youth Radio like Natalie Bettendorf. NATALIE BETTENDORF, BYLINE: It's been something that I've been on since middle school. The problem is that there's this huge generation gap where young people are kind of understanding it intuitively while older people are just completely clueless. So I actually went and talked to Seth Marceau. He's 18. He's one of my co-workers here at Youth Radio. And he says that immediacy is actually really important. SETH MARCEAU, BYLINE: I think it's hard for older people to understand how to use Snapchat because it's so fast moving. BETTENDORF: Despite what older people might think, studies show that young people actually are pretty engaged in the news. But we're just not getting it from traditional places. I know that I get most of my news from Snapchat and same with 21-year-old Noel Anaya. NOEL ANAYA: The way they do their news is really straight-to-the-point, very quick, very brief. You get the main idea of a story. And it can be really juicy at times. BETTENDORF: The thing about Snapchat is that it's immediate. It forces you to live in the moment on that one picture, that one video that you're watching because after it closes, it's gone forever. GLINTON: All those things that Natalie described - how photos disappear and how engaged she and her colleagues are - have made Snapchat super valuable on Wall Street. LANCE ULANOFF: They always talk about 18 - that's their core market. But I really think it pushes more to, like, 13- to 25-year-olds. That's really the heart of Snapchat's audience. GLINTON: Lance Ulanoff is with the tech website Mashable. ULANOFF: And there's good news and bad news in that. The good news is super desirable. But about half of that audience doesn't have its own money to spend, which is a bit of an alarm bell for advertisers who want to advertise things and then have these people turn around and buy that stuff. GLINTON: Snapchat has gone public sooner in its evolution than Facebook or Twitter. And what makes it popular is that it is ephemeral, and that's long been a drawback and an advantage since the company's origins. Again, Lance Ulanoff. . . ULANOFF: Yeah (laughter), it's - you know, like with superheroes, they like to do the origin story. They might not want to do the Snapchat origin story because it would include all this sexting. You know, when Snapchat first came along, it was really thought of as a sexting app. GLINTON: The app makes it easy to seamlessly advertise in ways that people just don't notice. The problem for snapchat, though, is making money. The company lost more than $500 million last year even though now it's valued at more than $28 billion. Ulanoff says the challenge for Snapchat is not really making money but how to grow. He says it won't and can't stay a niche company for tweens and 20-somethings. It needs adults. ULANOFF: And, of course the real challenge will be, as it does that and as it becomes successful as a content platform, to maintain contact with the younger users who got it there in the first place. GLINTON: Yeah, it's like, Nathalie's having fun on Snapchat, but will she stop having fun if I'm there and the rest of America is? ULANOFF: That is a real question. It was a question with Facebook as well - as parents started flooding into Facebook and teens started pulling back. Snapchat is a much smaller platform, faces much tougher odds, especially on the competition side. GLINTON: For my Youth Radio colleague Natalie Bettendorf who had run to class, I'm Sonari Glinton, NPR News.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-03-05-518663843": {"title": "Does Nintendo's New Console Signal A 'Switch' For The Video Game Market? : NPR", "url": "https://www.npr.org/2017/03/05/518663843/does-nintendos-new-console-signal-a-switch-for-the-video-game-market", "author": "No author found", "published_date": "2017-03-05", "content": "MICHEL MARTIN, HOST:  Moving on to technology. . . (SOUNDBITE OF SONG, \"SUPER MARIO THEME\")MARTIN: \"Super Mario\" and \"The Legend Of Zelda\" are all part of the Nintendo legacy. But now, beloved games from 30 years ago are getting a facelift to compete against Xbox and PlayStation, not to mention the hundreds of mobile apps that have frankly put Nintendo a bit on the back foot. Nintendo has unveiled what many game reviewers are calling a game-changer. It's called Switch, but let's see if the Nintendo Switch is worth all the hype. To find out more about it, we called Wall Street Journal technology reporter Nathan Olivarez-Giles. He's with us now from San Francisco. Nathan, thanks so much for joining us. NATHAN OLIVAREZ-GILES: Yeah. My pleasure. MARTIN: So why is this Switch such a big deal? OLIVAREZ-GILES: Well, the Switch is the first home console to really balance being a system that you can play on your television in high definition, but then something you can take on the road with you as well. The Switch also reintroduces motion-sensing controllers that were made popular by the Wii, Nintendo's last big hit in a new way. And they're smaller, they're lighter, they're untethered. And it's a bit of a nostalgia play, but it also really looks towards the future with a console unlike anything we've seen before. MARTIN: How much does it cost? OLIVAREZ-GILES: Just the console itself costs $299, and what you get is the tablet with its 6. 2-inch touch screen. You get the two joy-con motion controllers which allow you to play with a friend easily. But if you slide them onto either side of the tablet, it creates one solid on-the-go console. And then you get a dock that you put the tablet into when you want to play on a television set. So that's a pretty fair price. And that's what videogame systems are going for these days. MARTIN: So you've played it. What do you think? OLIVAREZ-GILES: Well, at this point, the hardware is the best that Nintendo has ever made. And I've had a total blast playing it. The standout game for me was \"The Legend Of Zelda: Breath Of The Wild. \" If you're a \"Zelda\" fan, this is one of the best \"Zelda\" games ever made. But at this point, there's just not enough to play on it. So the hardware has massive potential, but I think a lot of people should wait until the games get better. MARTIN: They have to because what I'm reading in the business press - yours included - is that it's already sold out almost everywhere. Why is that? OLIVAREZ-GILES: Well, you know, the hype is really strong. And Nintendo has a lot of hearts and minds because of decades worth of games and relationships they've built with gamers. You know, people hear \"Mario,\" and they hear \"Zelda\" and there's a almost romantic and fun idea of what's going to be happening there. So the Wii U, which was the previous Nintendo console fell flat on its face. I think they sold about 13 million units worldwide where the Wii before that sold about 100 million units. So Nintendo needs a big hit, and this is one of those make-or-break moments for the company. MARTIN: Before we let you go, do we expect competitors like Sony and Microsoft to - makers of the PlayStation the Xbox - to follow suit? OLIVAREZ-GILES: Microsoft and Sony so far don't have anything like this in the works that we know of or that they've spoken publicly about. What they're doing is they're beefing up their consoles with even more processing power, and then they're making them compatible with virtual reality headsets. Nintendo hasn't gone the VR route yet. They say they're open to it in the future, but they're kind of steering clear of it. Nintendo's always really been more about fun game play with other people around you, rather than teraflops worth of processing power inside of a VCR-like box. And that's really the route that Microsoft and Sony are battling in right now. MARTIN: That was Wall Street Journal tech reporter Nathan Olivarez-Giles joining us from San Francisco. Nathan, thanks so much. OLIVAREZ-GILES: My pleasure. MICHEL MARTIN, HOST:   Moving on to technology. . . (SOUNDBITE OF SONG, \"SUPER MARIO THEME\") MARTIN: \"Super Mario\" and \"The Legend Of Zelda\" are all part of the Nintendo legacy. But now, beloved games from 30 years ago are getting a facelift to compete against Xbox and PlayStation, not to mention the hundreds of mobile apps that have frankly put Nintendo a bit on the back foot. Nintendo has unveiled what many game reviewers are calling a game-changer. It's called Switch, but let's see if the Nintendo Switch is worth all the hype. To find out more about it, we called Wall Street Journal technology reporter Nathan Olivarez-Giles. He's with us now from San Francisco. Nathan, thanks so much for joining us. NATHAN OLIVAREZ-GILES: Yeah. My pleasure. MARTIN: So why is this Switch such a big deal? OLIVAREZ-GILES: Well, the Switch is the first home console to really balance being a system that you can play on your television in high definition, but then something you can take on the road with you as well. The Switch also reintroduces motion-sensing controllers that were made popular by the Wii, Nintendo's last big hit in a new way. And they're smaller, they're lighter, they're untethered. And it's a bit of a nostalgia play, but it also really looks towards the future with a console unlike anything we've seen before. MARTIN: How much does it cost? OLIVAREZ-GILES: Just the console itself costs $299, and what you get is the tablet with its 6. 2-inch touch screen. You get the two joy-con motion controllers which allow you to play with a friend easily. But if you slide them onto either side of the tablet, it creates one solid on-the-go console. And then you get a dock that you put the tablet into when you want to play on a television set. So that's a pretty fair price. And that's what videogame systems are going for these days. MARTIN: So you've played it. What do you think? OLIVAREZ-GILES: Well, at this point, the hardware is the best that Nintendo has ever made. And I've had a total blast playing it. The standout game for me was \"The Legend Of Zelda: Breath Of The Wild. \" If you're a \"Zelda\" fan, this is one of the best \"Zelda\" games ever made. But at this point, there's just not enough to play on it. So the hardware has massive potential, but I think a lot of people should wait until the games get better. MARTIN: They have to because what I'm reading in the business press - yours included - is that it's already sold out almost everywhere. Why is that? OLIVAREZ-GILES: Well, you know, the hype is really strong. And Nintendo has a lot of hearts and minds because of decades worth of games and relationships they've built with gamers. You know, people hear \"Mario,\" and they hear \"Zelda\" and there's a almost romantic and fun idea of what's going to be happening there. So the Wii U, which was the previous Nintendo console fell flat on its face. I think they sold about 13 million units worldwide where the Wii before that sold about 100 million units. So Nintendo needs a big hit, and this is one of those make-or-break moments for the company. MARTIN: Before we let you go, do we expect competitors like Sony and Microsoft to - makers of the PlayStation the Xbox - to follow suit? OLIVAREZ-GILES: Microsoft and Sony so far don't have anything like this in the works that we know of or that they've spoken publicly about. What they're doing is they're beefing up their consoles with even more processing power, and then they're making them compatible with virtual reality headsets. Nintendo hasn't gone the VR route yet. They say they're open to it in the future, but they're kind of steering clear of it. Nintendo's always really been more about fun game play with other people around you, rather than teraflops worth of processing power inside of a VCR-like box. And that's really the route that Microsoft and Sony are battling in right now. MARTIN: That was Wall Street Journal tech reporter Nathan Olivarez-Giles joining us from San Francisco. Nathan, thanks so much. OLIVAREZ-GILES: My pleasure.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-03-06-518858280": {"title": "Smartphone Software Makes It Cheaper To Spy From A Distance : NPR", "url": "https://www.npr.org/2017/03/06/518858280/smartphone-software-makes-it-cheaper-to-spy-from-a-distance", "author": "No author found", "published_date": "2017-03-06", "content": "ROBERT SIEGEL, HOST: It has gotten cheaper to spy on people from a distance. That's what a writer for the tech website Motherboard found out. This isn't about looking through walls or eavesdropping next door. It's reading messages and seeing call logs, looking at pictures from anywhere in the globe. One nasty trick is turning on a smartphone's microphone. In this case, the spy and the victims, Motherboard reporter Joseph Cox and a friend, were all in cahoots with the spy in New York opening a mic on Cox's phone in Berlin, where he and the friend were in a bar. (SOUNDBITE OF ARCHIVED RECORDING)JOSEPH COX: Do you want another drink? UNIDENTIFIED WOMAN: Yeah, sure. I'd like - I'm going to have another drink, like a beer or something. COX: OK. SIEGEL: Well, to tell us about this spyware, we welcome Joseph Cox to the program via Skype. Welcome to the program. COX: Hey, thanks a lot. SIEGEL: And walk us through what we just heard. What exactly was happening to enable that recording to be made? COX: Sure. So I had loaded malware onto the Android device by going to a website, downloading a special app, installing that. I then went to a bar with my friend. My colleague in New York just sent a very specific text message which then activated the microphone and recorded everything around us for about three minutes. SIEGEL: And how easy was it for you to set all that up? COX: Incredibly easy. All you need is physical access to the device you want to monitor. SIEGEL: That was a very good quality recording, by the way. (SOUNDBITE OF ARCHIVED RECORDING)COX: What camera did you buy? UNIDENTIFIED WOMAN: Like, a 4K camera. A system camera. COX: But, like, where are you going to be using that? UNIDENTIFIED WOMAN: It's really nice because, like, the resolution is so. . . COX: Yeah, but why are you going to put 4K film on a website? SIEGEL: Were you holding the phone up and passing it between each other, or was it on the bar, or. . . COX: We were literally sat in a corner of the bar at a table. The Android device was just on the table in between our drinks. And it picked up our entire conversation as this - and the sort of ambience around us as well. SIEGEL: Where do you get spyware like that - not that I'm interested in it personally - and how expensive is it? COX: You can get it pretty much anywhere on the internet. You Google spyware to buy, malware to spy on spouse, you're going to get dozens of websites that'll happily send you a download link in exchange for about $60, $150, $200. It's exceptionally cheap for the power of the malware. SIEGEL: Who's this being marketed to, this kind of spyware? COX: Some companies market towards those people who want to spy on their lovers, their wives or their spouses, predominately men, it seems from the marketing. Others push it as a solution for keeping tabs on your children. Or if you're an employer and you want to monitor your staff, that's how they also market it as well. SIEGEL: How easy is it to figure out that somebody is doing this to your phone? COX: I mean, you'll probably see suspicious apps. If it's an iPhone it may be jailbroken, which is somebody's installed a new operating system or software on it. Those are both pretty good signs. Or sometimes the attacker will put the software on the phone itself before giving it to the target. So if somebody else is giving you your mobile phone, that's a pretty good indicator as well. SIEGEL: But it - would it be simple to look at your phone and tell that this has happened? Or would that take a more skilled eye? COX: You would need to look pretty deep into the phone for a casual user. A forensics examiner would be able to find it with special software or hardware as well. SIEGEL: If I actually did this to somebody else's phone and then listened in on that person's conversations, am I violating all sorts of laws when I do that? COX: And it's certainly illegal under U. S. law. The malware itself, buying it, possibly selling it in some context may not be illegal, but using it to intercept communications certainly is a federal offense under U. S. law. SIEGEL: Well, thanks for talking with us about it. COX: No worries. Thank you so much. SIEGEL: Joseph Cox writes for Motherboard, and he spoke to us from Berlin. Motherboard will be exploring spyware further on a podcast called \"pluspluspodcast. \"(SOUNDBITE OF BOOMBOX SONG, \"INDIA\") ROBERT SIEGEL, HOST:  It has gotten cheaper to spy on people from a distance. That's what a writer for the tech website Motherboard found out. This isn't about looking through walls or eavesdropping next door. It's reading messages and seeing call logs, looking at pictures from anywhere in the globe. One nasty trick is turning on a smartphone's microphone. In this case, the spy and the victims, Motherboard reporter Joseph Cox and a friend, were all in cahoots with the spy in New York opening a mic on Cox's phone in Berlin, where he and the friend were in a bar. (SOUNDBITE OF ARCHIVED RECORDING) JOSEPH COX: Do you want another drink? UNIDENTIFIED WOMAN: Yeah, sure. I'd like - I'm going to have another drink, like a beer or something. COX: OK. SIEGEL: Well, to tell us about this spyware, we welcome Joseph Cox to the program via Skype. Welcome to the program. COX: Hey, thanks a lot. SIEGEL: And walk us through what we just heard. What exactly was happening to enable that recording to be made? COX: Sure. So I had loaded malware onto the Android device by going to a website, downloading a special app, installing that. I then went to a bar with my friend. My colleague in New York just sent a very specific text message which then activated the microphone and recorded everything around us for about three minutes. SIEGEL: And how easy was it for you to set all that up? COX: Incredibly easy. All you need is physical access to the device you want to monitor. SIEGEL: That was a very good quality recording, by the way. (SOUNDBITE OF ARCHIVED RECORDING) COX: What camera did you buy? UNIDENTIFIED WOMAN: Like, a 4K camera. A system camera. COX: But, like, where are you going to be using that? UNIDENTIFIED WOMAN: It's really nice because, like, the resolution is so. . . COX: Yeah, but why are you going to put 4K film on a website? SIEGEL: Were you holding the phone up and passing it between each other, or was it on the bar, or. . . COX: We were literally sat in a corner of the bar at a table. The Android device was just on the table in between our drinks. And it picked up our entire conversation as this - and the sort of ambience around us as well. SIEGEL: Where do you get spyware like that - not that I'm interested in it personally - and how expensive is it? COX: You can get it pretty much anywhere on the internet. You Google spyware to buy, malware to spy on spouse, you're going to get dozens of websites that'll happily send you a download link in exchange for about $60, $150, $200. It's exceptionally cheap for the power of the malware. SIEGEL: Who's this being marketed to, this kind of spyware? COX: Some companies market towards those people who want to spy on their lovers, their wives or their spouses, predominately men, it seems from the marketing. Others push it as a solution for keeping tabs on your children. Or if you're an employer and you want to monitor your staff, that's how they also market it as well. SIEGEL: How easy is it to figure out that somebody is doing this to your phone? COX: I mean, you'll probably see suspicious apps. If it's an iPhone it may be jailbroken, which is somebody's installed a new operating system or software on it. Those are both pretty good signs. Or sometimes the attacker will put the software on the phone itself before giving it to the target. So if somebody else is giving you your mobile phone, that's a pretty good indicator as well. SIEGEL: But it - would it be simple to look at your phone and tell that this has happened? Or would that take a more skilled eye? COX: You would need to look pretty deep into the phone for a casual user. A forensics examiner would be able to find it with special software or hardware as well. SIEGEL: If I actually did this to somebody else's phone and then listened in on that person's conversations, am I violating all sorts of laws when I do that? COX: And it's certainly illegal under U. S. law. The malware itself, buying it, possibly selling it in some context may not be illegal, but using it to intercept communications certainly is a federal offense under U. S. law. SIEGEL: Well, thanks for talking with us about it. COX: No worries. Thank you so much. SIEGEL: Joseph Cox writes for Motherboard, and he spoke to us from Berlin. Motherboard will be exploring spyware further on a podcast called \"pluspluspodcast. \" (SOUNDBITE OF BOOMBOX SONG, \"INDIA\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-03-06-518858273": {"title": "Emojis Begin Cropping Up Outside Of Your Smartphone : NPR", "url": "https://www.npr.org/2017/03/06/518858273/emojis-begin-cropping-up-outside-of-your-smartphone", "author": "No author found", "published_date": "2017-03-06", "content": "ARI SHAPIRO, HOST: Emojis are no longer just for smartphones. Those smiley faces, thumbs up and pizza slices are now cropping up in the real world. That's where we start this week's All Tech Considered. (SOUNDBITE OF MUSIC)SHAPIRO: These days, there are emoji backpacks, emoji light switches. There's even an emoji movie on the way. NPR's Stephan Bisaha reports on the spread of these cartoon-like images. STEPHAN BISAHA, BYLINE: Roberto Hoyos started selling emoji pillows online with his company Throwboy about three years ago. The pillows quickly established themselves as his top seller, and not just with the standard smiley face. ROBERTO HOYOS: In that line we have a poop emoji pillow, and I would say that's probably been our biggest hit to date. BISAHA: Since then, lots of companies have hopped onto the emoji bandwagon, selling an emoji version of just about everything - emoji slippers, speakers, perfume. TARA ALBA: Key chains, bracelets, purses. RUSS RUSSO: Blankets, soap, ChapStick. BISAHA: Russ Russo and Tara Alba sit on her bed in her New Jersey home. Nearly everything in the room has an emoji face on it, from the purse hanging on the wall to the blanket spread across the bed. They've been dating for about a year, and their go-to gift for each other is anything emoji. Part of the appeal is how universal emojis are. RUSSO: You should tell the story about the car. ALBA: Oh, I just bought a car from somebody in New York, and he was sending me a message. And instead of using the words he would actually use the emoji. BISAHA: After finalizing the deal, the seller sent Alba a message to pick up the car. Instead of typing the word cash, he used a bag of money emoji. Instead of typing car. . . ALBA: It was an actual emoji car. He spoke in emoji. RUSSO: Yeah. BISAHA: And you understood perfectly what he was saying? ALBA: Yes. BISAHA: But the main reason Alba and Russo keep buying emoji products is how important emojis were to the start of their relationship. ALBA: We didn't get to see each other a lot in the beginning, so it was unsure about our relationship. But when someone's sending you a kissy face or hearts then it makes you know. BISAHA: Consumers like Alba and Russo are why emoji products have taken off. But that caused Roberto Hoyos to worry. He didn't know if legally he could sell emoji pillows. HOYOS: And that's kind of like a lot of startups (laughter), to be honest. They'll kind of get the ball rolling and then, you know, cross their T's and dot their I's when they get there. BISAHA: Usually manufacturers have to get permission from and pay royalties to whoever owns a brand. But emojis aren't a brand, at least not a traditional one. When Hoyos eventually did look into it, he found out that no one actually owns emojis. HOYOS: We've talked to many, many people, many lawyers just to try to make sure, like, we have this, like, we're cool. And it is. JEREMY BURGE: You can't say the idea of a pizza emoji is mine. BISAHA: Jeremy Burge sits on something called the Unicode Emoji Subcommittee. He spoke to us over Skype. Unicode is a nonprofit responsible for maintaining and releasing new emojis. Burge says they're free to use. It's like an alphabet, and you can't copyright letters. But what you can copyright is a font, as in the design of an emoji. BURGE: If I draw a specific version in an emoji font of a pizza I own in that image. So Apple owns their emoji images and so does every company. BISAHA: Some manufacturers do pay for emoji designs, but the companies that design their own don't have to pay royalties, one of the reasons so many have joined the emoji boom. But for all the success, it could still be just another fad, leaving companies to wonder if the emoji future is a smile or frown. Stephan Bisaha, NPR News, Washington. ARI SHAPIRO, HOST:  Emojis are no longer just for smartphones. Those smiley faces, thumbs up and pizza slices are now cropping up in the real world. That's where we start this week's All Tech Considered. (SOUNDBITE OF MUSIC) SHAPIRO: These days, there are emoji backpacks, emoji light switches. There's even an emoji movie on the way. NPR's Stephan Bisaha reports on the spread of these cartoon-like images. STEPHAN BISAHA, BYLINE: Roberto Hoyos started selling emoji pillows online with his company Throwboy about three years ago. The pillows quickly established themselves as his top seller, and not just with the standard smiley face. ROBERTO HOYOS: In that line we have a poop emoji pillow, and I would say that's probably been our biggest hit to date. BISAHA: Since then, lots of companies have hopped onto the emoji bandwagon, selling an emoji version of just about everything - emoji slippers, speakers, perfume. TARA ALBA: Key chains, bracelets, purses. RUSS RUSSO: Blankets, soap, ChapStick. BISAHA: Russ Russo and Tara Alba sit on her bed in her New Jersey home. Nearly everything in the room has an emoji face on it, from the purse hanging on the wall to the blanket spread across the bed. They've been dating for about a year, and their go-to gift for each other is anything emoji. Part of the appeal is how universal emojis are. RUSSO: You should tell the story about the car. ALBA: Oh, I just bought a car from somebody in New York, and he was sending me a message. And instead of using the words he would actually use the emoji. BISAHA: After finalizing the deal, the seller sent Alba a message to pick up the car. Instead of typing the word cash, he used a bag of money emoji. Instead of typing car. . . ALBA: It was an actual emoji car. He spoke in emoji. RUSSO: Yeah. BISAHA: And you understood perfectly what he was saying? ALBA: Yes. BISAHA: But the main reason Alba and Russo keep buying emoji products is how important emojis were to the start of their relationship. ALBA: We didn't get to see each other a lot in the beginning, so it was unsure about our relationship. But when someone's sending you a kissy face or hearts then it makes you know. BISAHA: Consumers like Alba and Russo are why emoji products have taken off. But that caused Roberto Hoyos to worry. He didn't know if legally he could sell emoji pillows. HOYOS: And that's kind of like a lot of startups (laughter), to be honest. They'll kind of get the ball rolling and then, you know, cross their T's and dot their I's when they get there. BISAHA: Usually manufacturers have to get permission from and pay royalties to whoever owns a brand. But emojis aren't a brand, at least not a traditional one. When Hoyos eventually did look into it, he found out that no one actually owns emojis. HOYOS: We've talked to many, many people, many lawyers just to try to make sure, like, we have this, like, we're cool. And it is. JEREMY BURGE: You can't say the idea of a pizza emoji is mine. BISAHA: Jeremy Burge sits on something called the Unicode Emoji Subcommittee. He spoke to us over Skype. Unicode is a nonprofit responsible for maintaining and releasing new emojis. Burge says they're free to use. It's like an alphabet, and you can't copyright letters. But what you can copyright is a font, as in the design of an emoji. BURGE: If I draw a specific version in an emoji font of a pizza I own in that image. So Apple owns their emoji images and so does every company. BISAHA: Some manufacturers do pay for emoji designs, but the companies that design their own don't have to pay royalties, one of the reasons so many have joined the emoji boom. But for all the success, it could still be just another fad, leaving companies to wonder if the emoji future is a smile or frown. Stephan Bisaha, NPR News, Washington.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-03-10-519270280": {"title": "Dan Ariely: When Are Our Decisions Made For Us? : NPR", "url": "https://www.npr.org/2017/03/10/519270280/dan-ariely-when-are-our-decisions-made-for-us", "author": "No author found", "published_date": "2017-03-10", "content": "GUY RAZ, HOST: So Ruth Chang was just saying that she used to be terrible at making decisions. How about you? Are you good at making decisions? DAN ARIELY: Some - I'm really good about giving other people advice about how to make their decisions. RAZ: This is Dan Ariely. ARIELY: Officially, I'm the James B. Duke professor of psychology and behavioral economics at Duke University. RAZ: And this entire show, we've been talking about how to make decisions. But Dan says, even though we think we are making decisions, a lot of decisions are actually made for us in ways we don't even realize and can't control. It's an idea called choice architecture. ARIELY: Choice architecture is the idea that the decisions we make are a function of the environment that we're in. RAZ: And on the TED stage, Dan explained one example. He showed the audience a chart. It's a chart that plots the percentage of Europeans who signed up for organ donation. (SOUNDBITE OF TED TALK)ARIELY: And this is one of my favorite plots in social sciences. And these are different countries in Europe. And you basically see two types of countries - countries on the right, that seems to be giving a lot, and countries on the left, that seems to be giving very little, or, you know, not much less. The question is, why? Why do some countries give a lot and some countries give a little? When you ask people this question, they usually think that it has to be something about culture, right? How much do you care about people? Giving your organs to somebody else is probably about how much you care about society, or maybe 'cause about religion. But if you look at this plot, you could see that countries that we think about as very similar actually exhibit very different behavior. For example, Sweden is all the way on the right. And Denmark, that we think is culturally very similar, is all the way on the left. Germany's on the left, and Austria is on the right. The Netherlands is on the left, and Belgium is on the right. And by the way, the Netherlands is an interesting story. You see the Netherlands is kind of the biggest of the small group. Turns out that they got the 28 percent after mailing every household in the country a letter begging people to join this organ donation program. Right, so you know the expression, begging only gets you so far. It's 28 percent in organ donation. (LAUGHTER)ARIELY: But whatever the countries on the right are doing, they're doing a much better job than begging. So what are they doing? Turns out, the secret has to do with the form at the DMV. And here's the story. The countries on the left have a form at the DMV that looks something like this. Check the box below if you want to participate in the organ donor program. And what happens? People don't check, and they don't join. The countries on the right, the one that give a lot, have a slightly different form. It says check the box below if you don't want to participate. Interestingly enough, when people get this they, again, don't check, but now they join. . . (LAUGHTER)ARIELY: . . . The program. Now, think about what this means. You know, we wake up in the morning and we feel we make decisions. We wake up in the morning. And we open the closet, and we feel that we decide what to wear. And we open the refrigerator, and we feel that we decide what to eat. And what this is actually saying is that much of these decisions are not residing within us. They're residing by the person who's designing that form. When you walk into the DMV, the person who designed the form will have a huge influence on what you'll end up doing. (SOUNDBITE OF MUSIC)RAZ: So most or all of the decisions we make are made for us? ARIELY: Absolutely. It's kind of a very stressful thought. RAZ: Yeah. ARIELY: But this is choice architecture, this notion that we make decisions as a function of the environment that we're in. So if I put you in one kind of buffet, you would eat in this way. If I put you in another kind of buffet, you will eat very differently. If I'll set up your phone with some kind of notifications, you'll end up spending much more time on Facebook. If I set it with another kind of notification, you will spend much more time reading the news or something else. But this example with organ donation has a couple of important things. Imagine the following study. We have a group of people. We send them to the Department of Motor Vehicle, half of them get the opt-in form, half of them get the opt-out form. And then, you stop people when they come out. And you say, excuse me, can you tell me - I see that you didn't donate, I see you donated - you - and I say can you explain to me why - why you did what you did? Does anybody says I have no idea, this was the default choice? I didn't - anybody says I was too lazy? No. What happens is that people tell stories about why they made those decisions. They portray them as - as if they spent the whole week on that decision. RAZ: Yeah. ARIELY: So people who were in the opt-in form say things like, you know, I'm really worried about the medical system and whether some physicians will pull the plug a little too early if I do this. And people in the opt-out form says, you know, my parents raised me to be a caring, wonderful human being. And what happens - we don't make the decision, but we tell up story about why we do it. And the stories are so good that we even convince ourselves that the decisions we make are actually because of our preferences and not because somebody else made something. RAZ: Most decisions are unconscious. Like, I woke up this morning and I took a shower and I made breakfast and coffee. And I didn't think about - I mean, I thought about what breakfast to make for my kids and - but these were things that I had already decided even before I started to do them. ARIELY: Yes. And, you know, we have to make lots of decisions all the time, and we don't have the capacity or the resources to do it, so we make the easy decision. And I'll tell you a story about a company called Express Scripts. They manage pharmaceutical benefits. They do all kinds of things. But one of the things they do is they send people with chronic illness medication over the mail every 90 days. And what Express Scripts tries to do is to switch you from taking branded medication to generic medication. And they write you a letter, and they say, dear Guy, you're going to save money, your employer will save money, we will save money if you only switch to generic. And people don't switch. And they try all kinds of approaches, and people don't switch. So for one year, they offer people zero co-pay. Less than 10 percent of the people switched, right? So they said, look, you give people free medications, free generic medication, and even with free, they're not getting it. And they say could it be that people really hate generic medications so much that even free is not helpful? And the answer was to say, look, it could be that people hate generic medication, but it could be that people hate doing anything. I said, let's look at the detail, the choice architecture of what you're doing. Right now people start with branded. They can do nothing and stay with branded, or they could do something and move to generics. So the first thought was to say, let's reverse it. Let's send people a letter and say, we are going to switch you to generics. This is the path of least resistance. You don't have to do anything. It turns out this is illegal in this domain. But instead, what they did was they sent people a letter and they say, if you don't return this letter, we will be forced to stop your medications. But when you return this letter, you could choose branded at this price or generic at this price. What happened now? Between 70 and 80 percent of the people switched depending on the employer. So what does it tell you? Do people like branded or generics? Well, it tells people don't care. RAZ: Yeah. ARIELY: Right? People don't care so much. And the big issue in the whole thing was returning a letter. Now, when we set up the decision, we think it's a decision about branded versus generic. But the reality is it's a decision about choice architecture. And as long as we understand this, we could re-engineer the environment in a different way. RAZ: Yeah, so really, I mean, the person doing that engineering, like, the form designer - right? - they have a lot of power to kind of shape our decisions to their own advantage. I mean, companies that are trying to sell us stuff, certainly they must know this, right? ARIELY: Yeah, you know, and think about the following. Think about this notion of choice architecture. Every store, every restaurant, every kiosk, every app is an actor in our environment. Now, you can say what is the goal of these actors? Are they working in our long-term best interest? Or are they working in their short-term best interest? And the answer is, of course, that they're working in their short-term best interest, right? All of them want our time, money and attention right now. And because they control our environment, we fail. Now, do we fail all the time? No, but we certainly fail a lot. (SOUNDBITE OF TED TALK)ARIELY: I'll give you one more example for this. This was an ad from The Economist a few years ago that gave us three choices - an online subscription for $59, a print subscription for 125 or you could get both 125. (LAUGHTER)ARIELY: Now, I looked at this and I decided to do the experiment that I would have loved The Economist to do with me. I took this and I gave it to a hundred students. I said, what would you choose? Most people wanted the combo deal. Thankfully, nobody wanted the dominated option. That means our students can read. But now if you have an option that nobody wants, you would take it off, right? So I took - I printed another version of this when I eliminated the middle option. And I gave it to another hundred students. Now the most popular option became the least popular and the least popular became the most popular. What was happening is that option that was useless was useless in a sense that nobody wanted it. But it wasn't useless in the sense that it helped people figure out what they wanted. In fact, relative to the option in the middle, which was you get only the print for $125, the print and web for $125 looked like a fantastic deal. And as a consequence, people chose it. The general idea here, by the way, is that we actually don't know our preferences that well. And because we don't know our preferences that well, we're susceptible to all of these influences from the external forces, the defaults, the particular options that are presented to us and so on. RAZ: So if we wanted to - right? - like, how could we resist those external forces that clearly influence our decisions? ARIELY: Yeah. So, first of all, I think we have to admit that we can't resist all forces. And it's true that we don't make our own decision. The environment does. But it's also true that we have a choice of what environments we want to create for ourselves. So think about something like doughnuts. RAZ: OK. ARIELY: Imagine I came every morning to your office and I layered your desk with fresh doughnuts and croissants. What are the odds that at the end of the year you'll be as trim and healthy as you are right now? RAZ: Very low - very low odds. ARIELY: And human will - right? - our ability to make decisions is not in resisting the doughnuts when they're there. It's about deciding not to have doughnuts on the desk. So, you know, it's very sad that we really are influenced dramatically by the environment, but each one of us is really a choice architect. And this is the strength and the importance of choice architecture, that the environment that we put people in matters a great, great deal, much more than we understand. RAZ: Yeah. ARIELY: Very few kids grow up and say when I grow up I want to be a form designer, but I want to be a form designer. They are the place where we make decisions, and if we think about those forms and we say how do we design those forms to help people make the best decisions, there's lots of room there for improvement. (SOUNDBITE OF MUSIC)RAZ: Dan Ariely is a professor of psychology and behavioral economics at Duke University. He's given many, many TED talks. You can find all of them at ted. com. (SOUNDBITE OF SONG, \"SHOULD I STAY OR SHOULD I GO\")THE CLASH: (Singing) Should I stay or should I go now? Should I stay or should I go now? RAZ: Hey, thanks for listening to our show on Decisions this week. If you want to find out more about who was on it, go to ted. npr. org. To see hundreds more TED talks, check out ted. com or the TED app. Our production staff at NPR includes Jeff Rogers, Brent Baughman, Sanaz Meshkinpour, Neva Grant, Casey Herman, Jinae West and Rachel Faulkner, with help from Daniel Shukin. Our intern is Thomas Lu. Our partners at TED are Chris Anderson, Kelly Steotzel, Anna Phelan and Janet Lee. If you want to let us know what you think about the show, you can write us at tedradiohour@npr. org. And you can follow us on Twitter. It's @tedradiohour. And if you haven't already done so, be sure to subscribe to our podcast on iTunes. I'm Guy Raz, and you've been listening to ideas worth spreading right here on the TED Radio Hour, NPR. (SOUNDBITE OF SONG, \"SHOULD I STAY OR SHOULD I GO\")THE CLASH: (Singing) So you got to let me know, should I stay or should I go? GUY RAZ, HOST:  So Ruth Chang was just saying that she used to be terrible at making decisions. How about you? Are you good at making decisions? DAN ARIELY: Some - I'm really good about giving other people advice about how to make their decisions. RAZ: This is Dan Ariely. ARIELY: Officially, I'm the James B. Duke professor of psychology and behavioral economics at Duke University. RAZ: And this entire show, we've been talking about how to make decisions. But Dan says, even though we think we are making decisions, a lot of decisions are actually made for us in ways we don't even realize and can't control. It's an idea called choice architecture. ARIELY: Choice architecture is the idea that the decisions we make are a function of the environment that we're in. RAZ: And on the TED stage, Dan explained one example. He showed the audience a chart. It's a chart that plots the percentage of Europeans who signed up for organ donation. (SOUNDBITE OF TED TALK) ARIELY: And this is one of my favorite plots in social sciences. And these are different countries in Europe. And you basically see two types of countries - countries on the right, that seems to be giving a lot, and countries on the left, that seems to be giving very little, or, you know, not much less. The question is, why? Why do some countries give a lot and some countries give a little? When you ask people this question, they usually think that it has to be something about culture, right? How much do you care about people? Giving your organs to somebody else is probably about how much you care about society, or maybe 'cause about religion. But if you look at this plot, you could see that countries that we think about as very similar actually exhibit very different behavior. For example, Sweden is all the way on the right. And Denmark, that we think is culturally very similar, is all the way on the left. Germany's on the left, and Austria is on the right. The Netherlands is on the left, and Belgium is on the right. And by the way, the Netherlands is an interesting story. You see the Netherlands is kind of the biggest of the small group. Turns out that they got the 28 percent after mailing every household in the country a letter begging people to join this organ donation program. Right, so you know the expression, begging only gets you so far. It's 28 percent in organ donation. (LAUGHTER) ARIELY: But whatever the countries on the right are doing, they're doing a much better job than begging. So what are they doing? Turns out, the secret has to do with the form at the DMV. And here's the story. The countries on the left have a form at the DMV that looks something like this. Check the box below if you want to participate in the organ donor program. And what happens? People don't check, and they don't join. The countries on the right, the one that give a lot, have a slightly different form. It says check the box below if you don't want to participate. Interestingly enough, when people get this they, again, don't check, but now they join. . . (LAUGHTER) ARIELY: . . . The program. Now, think about what this means. You know, we wake up in the morning and we feel we make decisions. We wake up in the morning. And we open the closet, and we feel that we decide what to wear. And we open the refrigerator, and we feel that we decide what to eat. And what this is actually saying is that much of these decisions are not residing within us. They're residing by the person who's designing that form. When you walk into the DMV, the person who designed the form will have a huge influence on what you'll end up doing. (SOUNDBITE OF MUSIC) RAZ: So most or all of the decisions we make are made for us? ARIELY: Absolutely. It's kind of a very stressful thought. RAZ: Yeah. ARIELY: But this is choice architecture, this notion that we make decisions as a function of the environment that we're in. So if I put you in one kind of buffet, you would eat in this way. If I put you in another kind of buffet, you will eat very differently. If I'll set up your phone with some kind of notifications, you'll end up spending much more time on Facebook. If I set it with another kind of notification, you will spend much more time reading the news or something else. But this example with organ donation has a couple of important things. Imagine the following study. We have a group of people. We send them to the Department of Motor Vehicle, half of them get the opt-in form, half of them get the opt-out form. And then, you stop people when they come out. And you say, excuse me, can you tell me - I see that you didn't donate, I see you donated - you - and I say can you explain to me why - why you did what you did? Does anybody says I have no idea, this was the default choice? I didn't - anybody says I was too lazy? No. What happens is that people tell stories about why they made those decisions. They portray them as - as if they spent the whole week on that decision. RAZ: Yeah. ARIELY: So people who were in the opt-in form say things like, you know, I'm really worried about the medical system and whether some physicians will pull the plug a little too early if I do this. And people in the opt-out form says, you know, my parents raised me to be a caring, wonderful human being. And what happens - we don't make the decision, but we tell up story about why we do it. And the stories are so good that we even convince ourselves that the decisions we make are actually because of our preferences and not because somebody else made something. RAZ: Most decisions are unconscious. Like, I woke up this morning and I took a shower and I made breakfast and coffee. And I didn't think about - I mean, I thought about what breakfast to make for my kids and - but these were things that I had already decided even before I started to do them. ARIELY: Yes. And, you know, we have to make lots of decisions all the time, and we don't have the capacity or the resources to do it, so we make the easy decision. And I'll tell you a story about a company called Express Scripts. They manage pharmaceutical benefits. They do all kinds of things. But one of the things they do is they send people with chronic illness medication over the mail every 90 days. And what Express Scripts tries to do is to switch you from taking branded medication to generic medication. And they write you a letter, and they say, dear Guy, you're going to save money, your employer will save money, we will save money if you only switch to generic. And people don't switch. And they try all kinds of approaches, and people don't switch. So for one year, they offer people zero co-pay. Less than 10 percent of the people switched, right? So they said, look, you give people free medications, free generic medication, and even with free, they're not getting it. And they say could it be that people really hate generic medications so much that even free is not helpful? And the answer was to say, look, it could be that people hate generic medication, but it could be that people hate doing anything. I said, let's look at the detail, the choice architecture of what you're doing. Right now people start with branded. They can do nothing and stay with branded, or they could do something and move to generics. So the first thought was to say, let's reverse it. Let's send people a letter and say, we are going to switch you to generics. This is the path of least resistance. You don't have to do anything. It turns out this is illegal in this domain. But instead, what they did was they sent people a letter and they say, if you don't return this letter, we will be forced to stop your medications. But when you return this letter, you could choose branded at this price or generic at this price. What happened now? Between 70 and 80 percent of the people switched depending on the employer. So what does it tell you? Do people like branded or generics? Well, it tells people don't care. RAZ: Yeah. ARIELY: Right? People don't care so much. And the big issue in the whole thing was returning a letter. Now, when we set up the decision, we think it's a decision about branded versus generic. But the reality is it's a decision about choice architecture. And as long as we understand this, we could re-engineer the environment in a different way. RAZ: Yeah, so really, I mean, the person doing that engineering, like, the form designer - right? - they have a lot of power to kind of shape our decisions to their own advantage. I mean, companies that are trying to sell us stuff, certainly they must know this, right? ARIELY: Yeah, you know, and think about the following. Think about this notion of choice architecture. Every store, every restaurant, every kiosk, every app is an actor in our environment. Now, you can say what is the goal of these actors? Are they working in our long-term best interest? Or are they working in their short-term best interest? And the answer is, of course, that they're working in their short-term best interest, right? All of them want our time, money and attention right now. And because they control our environment, we fail. Now, do we fail all the time? No, but we certainly fail a lot. (SOUNDBITE OF TED TALK) ARIELY: I'll give you one more example for this. This was an ad from The Economist a few years ago that gave us three choices - an online subscription for $59, a print subscription for 125 or you could get both 125. (LAUGHTER) ARIELY: Now, I looked at this and I decided to do the experiment that I would have loved The Economist to do with me. I took this and I gave it to a hundred students. I said, what would you choose? Most people wanted the combo deal. Thankfully, nobody wanted the dominated option. That means our students can read. But now if you have an option that nobody wants, you would take it off, right? So I took - I printed another version of this when I eliminated the middle option. And I gave it to another hundred students. Now the most popular option became the least popular and the least popular became the most popular. What was happening is that option that was useless was useless in a sense that nobody wanted it. But it wasn't useless in the sense that it helped people figure out what they wanted. In fact, relative to the option in the middle, which was you get only the print for $125, the print and web for $125 looked like a fantastic deal. And as a consequence, people chose it. The general idea here, by the way, is that we actually don't know our preferences that well. And because we don't know our preferences that well, we're susceptible to all of these influences from the external forces, the defaults, the particular options that are presented to us and so on. RAZ: So if we wanted to - right? - like, how could we resist those external forces that clearly influence our decisions? ARIELY: Yeah. So, first of all, I think we have to admit that we can't resist all forces. And it's true that we don't make our own decision. The environment does. But it's also true that we have a choice of what environments we want to create for ourselves. So think about something like doughnuts. RAZ: OK. ARIELY: Imagine I came every morning to your office and I layered your desk with fresh doughnuts and croissants. What are the odds that at the end of the year you'll be as trim and healthy as you are right now? RAZ: Very low - very low odds. ARIELY: And human will - right? - our ability to make decisions is not in resisting the doughnuts when they're there. It's about deciding not to have doughnuts on the desk. So, you know, it's very sad that we really are influenced dramatically by the environment, but each one of us is really a choice architect. And this is the strength and the importance of choice architecture, that the environment that we put people in matters a great, great deal, much more than we understand. RAZ: Yeah. ARIELY: Very few kids grow up and say when I grow up I want to be a form designer, but I want to be a form designer. They are the place where we make decisions, and if we think about those forms and we say how do we design those forms to help people make the best decisions, there's lots of room there for improvement. (SOUNDBITE OF MUSIC) RAZ: Dan Ariely is a professor of psychology and behavioral economics at Duke University. He's given many, many TED talks. You can find all of them at ted. com. (SOUNDBITE OF SONG, \"SHOULD I STAY OR SHOULD I GO\") THE CLASH: (Singing) Should I stay or should I go now? Should I stay or should I go now? RAZ: Hey, thanks for listening to our show on Decisions this week. If you want to find out more about who was on it, go to ted. npr. org. To see hundreds more TED talks, check out ted. com or the TED app. Our production staff at NPR includes Jeff Rogers, Brent Baughman, Sanaz Meshkinpour, Neva Grant, Casey Herman, Jinae West and Rachel Faulkner, with help from Daniel Shukin. Our intern is Thomas Lu. Our partners at TED are Chris Anderson, Kelly Steotzel, Anna Phelan and Janet Lee. If you want to let us know what you think about the show, you can write us at tedradiohour@npr. org. And you can follow us on Twitter. It's @tedradiohour. And if you haven't already done so, be sure to subscribe to our podcast on iTunes. I'm Guy Raz, and you've been listening to ideas worth spreading right here on the TED Radio Hour, NPR. (SOUNDBITE OF SONG, \"SHOULD I STAY OR SHOULD I GO\") THE CLASH: (Singing) So you got to let me know, should I stay or should I go?", "section": "TED Radio Hour", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-03-10-519269147": {"title": "Ruth Chang: How Can Making Hard Choices Empower Us? : NPR", "url": "https://www.npr.org/2017/03/10/519269147/ruth-chang-how-can-making-hard-choices-empower-us", "author": "No author found", "published_date": "2017-03-10", "content": "GUY RAZ, HOST: Do you have a hard time making choices? Or is it, like, pretty easy for you to do that? RUTH CHANG: I cannot make a decision to save my life. RAZ: Oh, wow, really? You're the decision-choice person. CHANG: I'm a terrible decision maker. RAZ: That leaves no hope for the rest of us. CHANG: Yeah (laughter). RAZ: This is Ruth Chang. She's a professor of philosophy at Rutgers University. And she studies hard choices. CHANG: So what I should say is I used to be a terrible decision maker. RAZ: OK. CHANG: But that's how I got interested in thinking about hard choices. RAZ: Can you help me make a decision about something? CHANG: Sure. RAZ: I can't tell you exactly what it is. I just need to know what to do. CHANG: So I believe that there are five steps to confronting a difficult decision. RAZ: OK. CHANG: Do you want to hear the five steps? RAZ: Yeah, I do. CHANG: OK. The first thing you have to do when you're confronting a hard choice is to figure out what matters in the choice between the alternatives. RAZ: So, like, write them down? CHANG: Write them down. And they'll be a mishmash. RAZ: OK. CHANG: Then you lather, rinse and repeat. You go back. And you think, well, gee, did I miss something that matters in the choice? RAZ: Yeah. CHANG: Then you recognize that you're in a hard choice. There is no best answer. The next step - commit to one of the options. Create a reason for yourself to pursue that option. RAZ: Ok. So what's five? CHANG: So five is not really a step. It's more of a consequence. When you commit to something, you create your own identity. You make yourself into who you are. Those are the five steps. RAZ: OK. I admit, a five-step plan might sound way too simple, especially when you have to make a big choice. But Ruth Chang says it doesn't actually have to be that hard. Here she is on the TED stage. (SOUNDBITE OF TED TALK)CHANG: I think we've misunderstood hard choices and the role they play in our lives. We shouldn't think that all hard choices are big. Let's say you're deciding what to have for breakfast. You could have high-fiber bran cereal or a chocolate doughnut. The cereal is better for you. A doughnut tastes way better. But neither is better than the other overall, a hard choice. Realizing that small choices can also be hard may make big hard choices seem less intractable. What makes a choice hard is the way the alternatives relate. In an easy choice, one alternative is better than the other. In a hard choice, one alternative is better in some ways. The other alternative is better in other ways. And neither is better than the other overall. When I graduated from college, I couldn't decide between two careers - philosophy and law. So I got out my yellow pad. I drew a line down the middle. And I tried my best to think of the reasons for and against each alternative. I did what many of us do in hard choices. I took the safest option. And as I discovered, lawyering didn't quite fit. It wasn't who I was. So now I'm a philosopher. And I study hard choices. And I can tell you that fear of the unknown, while a common motivational default in dealing with hard choices, rests on a misconception of them. Hard choices are hard not because of us or our ignorance. They're hard because there is no best option. (SOUNDBITE OF MUSIC)RAZ: OK. Here's a recent example from my own life. This is a small decision. It was actually really hard. We were at a fish restaurant where they're really famous for their fish and chips. But the haddock was really fresh that night. So I ordered the haddock. But then they brought the fish and chips to my son. And when I watched him eat it, I was really regretting the choice I made. CHANG: OK. Two things that might be happening in that case - one is that you just made a mistake, all right? The cod was better. RAZ: The haddock was pretty good, I have to say. CHANG: But if the cod was better than the haddock, then you made a mistake. RAZ: But how would I know, right? I mean, I guess I could taste them and then decide. CHANG: Yeah. I mean, that's like asking how do we know when one thing is better than the other? That's very difficult. How do we know anything? What I'm interested in is the second possibility, which is suppose the cod was better in some of those respects, the haddock was better in other respects and yet, neither seemed to you at least as good as the other overall. And it's going to sound crazy when we're talking about fish dinners. RAZ: Yeah. CHANG: But one possibility is to commit to one of the dinners, right? I commit to cod. I'm a cod guy. And by committing to the cod, you actually can create a reason for you to have the cod, which then may give you most reason to choose the cod over the haddock. Now, that seems less crazy when we're talking about careers - right? - or people to marry or places to live. RAZ: Yeah. CHANG: But the structure of each of those choices will be the same. (SOUNDBITE OF MUSIC)RAZ: When we come back, Ruth Chang on why committing to a decision not only helps you make the right choice but helps define who you are. I'm Guy Raz. And you're listening to the TED Radio Hour from NPR. (SOUNDBITE OF MUSIC)RAZ: It's the TED Radio Hour from NPR. I'm Guy Raz. And on the show today - Decisions. And we were just hearing from philosopher Ruth Chang on why both big and small decisions can be hard. But one way to make them easier is to commit. CHANG: So suppose you spent your whole life never committing to anything, never putting your agency behind something. You drift through life, which most of us do. Well, what's sad is that you've never exercised this amazing power you have to create reasons for yourself. When you drift through life, you're never the author of your own life. You're just something being buffeted around by your circumstances. I think that what we've missed is that we have this other capacity to commit to things and to actually write the story of our own lives by committing to people and projects and plans of actions that then create reasons for ourselves to live one way as opposed to another. RAZ: Here's more from Ruth saying on the TED stage. (SOUNDBITE OF TED TALK)CHANG: I think the puzzle arises because of an unreflective assumption we make about value. If what matters to us can't be represented by real numbers, then there's no reason to believe that, in choice, there are only three possibilities - that one alternative is better, worse or equal to the other. We need to introduce a new, fourth relation, beyond being better, worse or equal, that describes what's going on in hard choices. I like to say that the alternatives are on a par. When alternatives are on a par, it may matter very much which you choose, but one alternative isn't better than the other. That's why the choice is hard. Understanding hard choices in this way uncovers something about ourselves we didn't know. You faced alternatives that were on a par, hard choices. And you made reasons for yourself to choose the exact hobbies you do, to live in the exact house you do, to work at the exact job you do. It's here, in the space of hard choices, that we get to exercise our normative power. We can put our very selves behind an option. Here's where I stand. Here's who I am. Far from being sources of agony and dread, hard choices are precious opportunities for us to celebrate what is special about the human condition, that we have the power to create reasons for ourselves to become the distinctive people that we are. (SOUNDBITE OF MUSIC)RAZ: So I completely hear you. And I heard Sheena, and I heard Malcolm. But it's still hard. Like, making a big decision is still sometimes agonizing. So how do we make peace with it? CHANG: So when people agonize over a hard choices, the source of the agony is usually lack of information. If only I knew how this alternative would work out I would know that this is better than that. And what I want to say is, that's a mistake, that even if you had a video of your two possible futures and you could watch them side by side, it could be the case that your two future careers - let's say being a lumberjack and being an accountant - are on a par. Even some omniscient being couldn't determine, look, this life for you - this future life is better than that one. And now the question is, well, what do you do? And I think what you should do is turn inwards and ask yourself what can I commit to? If you can commit to one of the options, then by putting your agency behind that option, you could actually do this incredible thing, which is you can confer a value on that option. You can make it the case that now you have this reason to pursue that option that you didn't have before. And I think that's a power all rational agents have. (SOUNDBITE OF MUSIC)RAZ: Ruth Chang - she's a professor of philosophy at Rutgers University. You can find her talk at ted. com. GUY RAZ, HOST:  Do you have a hard time making choices? Or is it, like, pretty easy for you to do that? RUTH CHANG: I cannot make a decision to save my life. RAZ: Oh, wow, really? You're the decision-choice person. CHANG: I'm a terrible decision maker. RAZ: That leaves no hope for the rest of us. CHANG: Yeah (laughter). RAZ: This is Ruth Chang. She's a professor of philosophy at Rutgers University. And she studies hard choices. CHANG: So what I should say is I used to be a terrible decision maker. RAZ: OK. CHANG: But that's how I got interested in thinking about hard choices. RAZ: Can you help me make a decision about something? CHANG: Sure. RAZ: I can't tell you exactly what it is. I just need to know what to do. CHANG: So I believe that there are five steps to confronting a difficult decision. RAZ: OK. CHANG: Do you want to hear the five steps? RAZ: Yeah, I do. CHANG: OK. The first thing you have to do when you're confronting a hard choice is to figure out what matters in the choice between the alternatives. RAZ: So, like, write them down? CHANG: Write them down. And they'll be a mishmash. RAZ: OK. CHANG: Then you lather, rinse and repeat. You go back. And you think, well, gee, did I miss something that matters in the choice? RAZ: Yeah. CHANG: Then you recognize that you're in a hard choice. There is no best answer. The next step - commit to one of the options. Create a reason for yourself to pursue that option. RAZ: Ok. So what's five? CHANG: So five is not really a step. It's more of a consequence. When you commit to something, you create your own identity. You make yourself into who you are. Those are the five steps. RAZ: OK. I admit, a five-step plan might sound way too simple, especially when you have to make a big choice. But Ruth Chang says it doesn't actually have to be that hard. Here she is on the TED stage. (SOUNDBITE OF TED TALK) CHANG: I think we've misunderstood hard choices and the role they play in our lives. We shouldn't think that all hard choices are big. Let's say you're deciding what to have for breakfast. You could have high-fiber bran cereal or a chocolate doughnut. The cereal is better for you. A doughnut tastes way better. But neither is better than the other overall, a hard choice. Realizing that small choices can also be hard may make big hard choices seem less intractable. What makes a choice hard is the way the alternatives relate. In an easy choice, one alternative is better than the other. In a hard choice, one alternative is better in some ways. The other alternative is better in other ways. And neither is better than the other overall. When I graduated from college, I couldn't decide between two careers - philosophy and law. So I got out my yellow pad. I drew a line down the middle. And I tried my best to think of the reasons for and against each alternative. I did what many of us do in hard choices. I took the safest option. And as I discovered, lawyering didn't quite fit. It wasn't who I was. So now I'm a philosopher. And I study hard choices. And I can tell you that fear of the unknown, while a common motivational default in dealing with hard choices, rests on a misconception of them. Hard choices are hard not because of us or our ignorance. They're hard because there is no best option. (SOUNDBITE OF MUSIC) RAZ: OK. Here's a recent example from my own life. This is a small decision. It was actually really hard. We were at a fish restaurant where they're really famous for their fish and chips. But the haddock was really fresh that night. So I ordered the haddock. But then they brought the fish and chips to my son. And when I watched him eat it, I was really regretting the choice I made. CHANG: OK. Two things that might be happening in that case - one is that you just made a mistake, all right? The cod was better. RAZ: The haddock was pretty good, I have to say. CHANG: But if the cod was better than the haddock, then you made a mistake. RAZ: But how would I know, right? I mean, I guess I could taste them and then decide. CHANG: Yeah. I mean, that's like asking how do we know when one thing is better than the other? That's very difficult. How do we know anything? What I'm interested in is the second possibility, which is suppose the cod was better in some of those respects, the haddock was better in other respects and yet, neither seemed to you at least as good as the other overall. And it's going to sound crazy when we're talking about fish dinners. RAZ: Yeah. CHANG: But one possibility is to commit to one of the dinners, right? I commit to cod. I'm a cod guy. And by committing to the cod, you actually can create a reason for you to have the cod, which then may give you most reason to choose the cod over the haddock. Now, that seems less crazy when we're talking about careers - right? - or people to marry or places to live. RAZ: Yeah. CHANG: But the structure of each of those choices will be the same. (SOUNDBITE OF MUSIC) RAZ: When we come back, Ruth Chang on why committing to a decision not only helps you make the right choice but helps define who you are. I'm Guy Raz. And you're listening to the TED Radio Hour from NPR. (SOUNDBITE OF MUSIC) RAZ: It's the TED Radio Hour from NPR. I'm Guy Raz. And on the show today - Decisions. And we were just hearing from philosopher Ruth Chang on why both big and small decisions can be hard. But one way to make them easier is to commit. CHANG: So suppose you spent your whole life never committing to anything, never putting your agency behind something. You drift through life, which most of us do. Well, what's sad is that you've never exercised this amazing power you have to create reasons for yourself. When you drift through life, you're never the author of your own life. You're just something being buffeted around by your circumstances. I think that what we've missed is that we have this other capacity to commit to things and to actually write the story of our own lives by committing to people and projects and plans of actions that then create reasons for ourselves to live one way as opposed to another. RAZ: Here's more from Ruth saying on the TED stage. (SOUNDBITE OF TED TALK) CHANG: I think the puzzle arises because of an unreflective assumption we make about value. If what matters to us can't be represented by real numbers, then there's no reason to believe that, in choice, there are only three possibilities - that one alternative is better, worse or equal to the other. We need to introduce a new, fourth relation, beyond being better, worse or equal, that describes what's going on in hard choices. I like to say that the alternatives are on a par. When alternatives are on a par, it may matter very much which you choose, but one alternative isn't better than the other. That's why the choice is hard. Understanding hard choices in this way uncovers something about ourselves we didn't know. You faced alternatives that were on a par, hard choices. And you made reasons for yourself to choose the exact hobbies you do, to live in the exact house you do, to work at the exact job you do. It's here, in the space of hard choices, that we get to exercise our normative power. We can put our very selves behind an option. Here's where I stand. Here's who I am. Far from being sources of agony and dread, hard choices are precious opportunities for us to celebrate what is special about the human condition, that we have the power to create reasons for ourselves to become the distinctive people that we are. (SOUNDBITE OF MUSIC) RAZ: So I completely hear you. And I heard Sheena, and I heard Malcolm. But it's still hard. Like, making a big decision is still sometimes agonizing. So how do we make peace with it? CHANG: So when people agonize over a hard choices, the source of the agony is usually lack of information. If only I knew how this alternative would work out I would know that this is better than that. And what I want to say is, that's a mistake, that even if you had a video of your two possible futures and you could watch them side by side, it could be the case that your two future careers - let's say being a lumberjack and being an accountant - are on a par. Even some omniscient being couldn't determine, look, this life for you - this future life is better than that one. And now the question is, well, what do you do? And I think what you should do is turn inwards and ask yourself what can I commit to? If you can commit to one of the options, then by putting your agency behind that option, you could actually do this incredible thing, which is you can confer a value on that option. You can make it the case that now you have this reason to pursue that option that you didn't have before. And I think that's a power all rational agents have. (SOUNDBITE OF MUSIC) RAZ: Ruth Chang - she's a professor of philosophy at Rutgers University. You can find her talk at ted. com.", "section": "TED Radio Hour", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-03-10-519266687": {"title": "Sheena Iyengar: Why Are Some Choices So Paralyzing? : NPR", "url": "https://www.npr.org/2017/03/10/519266687/sheena-iyengar-why-are-some-choices-so-paralyzing", "author": "No author found", "published_date": "2017-03-10", "content": "GUY RAZ, HOST: It's the TED Radio Hour from NPR. I'm Guy Raz, and on the show today, ideas about decisions - how we make them, why they can be so hard and how lots of choices don't necessarily help, like when you're standing in the grocery aisle paralyzed by the prospect of choosing from 36 varieties of spaghetti sauce. SHEENA IYENGAR: Yeah, we should try to minimize the number of times we're paralyzed over what ought to be mundane choices. RAZ: This is Sheena Iyengar. IYENGAR: Look, at the end of the day, the stakes on this aren't really very high, so just choose. RAZ: Sheena is a professor at Columbia Business School. IYENGAR: I study why choice matters to people and how they can get the most from this thing called choice. (SOUNDBITE OF MUSIC)RAZ: But even though Sheena says we shouldn't get paralyzed by things like spaghetti sauce, she still admits that it happens all the time. She even has a term for it. (SOUNDBITE OF TED TALK)IYENGAR: The choice overload problem. RAZ: The choice overload problem. Sheena explained that idea from the TED stage. (SOUNDBITE OF TED TALK)IYENGAR: So when I was a graduate student at Stanford University, I used to go to this very, very upscale grocery store. It was a store called Draeger's. They had 250 different kinds of mustards and vinegars and over 500 different kinds of fruits and vegetables and more than two dozen different kinds of bottled water. I used to love going to this store, but on one occasion, I asked myself, well, how come you never buy anything? So I one day decided to do a little experiment, and we picked jam for our experiment. They had 348 different kinds of jam. We set up a little tasting booth right near the entrance of the store. We either put out six different flavors of jam or 24 different flavors of jam, and we looked at two things. First, in which case were people more likely to, you know, stop, sample some jam? More people stopped when there were 24 - about 60 percent - than when there were six - about 40 percent. The next thing we looked at is in which case were people more likely to buy a jar of jam? Now we see the opposite effect. Of the people who stopped when there were 24, only 3 percent of them actually bought a jar of jam. Of the people who stopped when there were six, well, now we saw that 30 percent of them actually bought a jar of jam. Now, if you do the math, people were at least six times more likely to buy a jar of jam if they encountered six than if they encountered 24. Now, the main reason for this is because, well, we might enjoy gazing at those giant walls of mayonnaises, mustards, vinegars, jams, but we can't actually do the math of comparing and contrasting and actually picking from that stunning display. (SOUNDBITE OF MUSIC)RAZ: So it was this study that made Sheena think maybe we've gone too far. Maybe companies are overloading consumers with choice, which is why Sheena's advice to companies today is to cut. (SOUNDBITE OF TED TALK)IYENGAR: Cut. You've heard it said before, but it's never been more true than today that less is more. When Procter & Gamble went from 26 different kinds of Head & Shoulders to 15, they saw an increase in sales by 10 percent. When the Golden Cat Corporation got rid of their 10 worst-selling cat litter products, they saw an increase in profits by 87 percent. You know, the average grocery store today offers you 45,000 products, but the ninth biggest retailer in the world today is Aldi, and it offers you only 1,400 products - one kind of canned tomato sauce. (SOUNDBITE OF MUSIC)RAZ: Wow. That's totally counterintuitive. But, I mean, companies are actually seeing an increase in sales when when they reduce the number of choices. IYENGAR: Yes. It just looks less overwhelming. I can now see that, oh, OK, this is the Head & Shoulder I want. And when Cotsco recently reduced their number of choices, they actually saw an increase in sales. RAZ: Really? They just, like, cut back things they offer? IYENGAR: They just cut across the board, yeah. Even Wal-Mart is beginning to cut across. RAZ: So what is it about choice that overwhelms us, that can paralyze us? IYENGAR: So I think there's a few things that happen when we get paralyzed by choice. Sometimes when we're trying to choose amongst really minor things, like, let's say you're looking at a menu in a restaurant and you start deliberating over - I don't know - the steak versus the salmon versus the salad and you start contemplating all different kinds of criteria by which you want to compare and contrast your options. RAZ: Yeah. IYENGAR: But I think the other times when we get paralyzed is because it really is something that we are very aware is very, very consequential. Like, should I get married or not? Should I have a child or not? There's a lot of unknowns there. RAZ: So how is it that both of those scenarios produce agony? IYENGAR: Because there's this thing called heart versus mind or gut versus reason, however you want to label it. Even though they're both working in concert, I think the reality is you're constantly asking yourself two questions. What do I want? And what should I choose? And those don't give you the same answers because when you ask yourself what should I choose, it tells you what you ought to want tomorrow or the day after tomorrow. When you ask yourself what you want, we're very aware of the fact that what I want right now may not be what I want in five minutes. RAZ: So that's what it's about? It's about what I want and what I should want. IYENGAR: That's the inherent conflict. RAZ: Do all of us feel this conflict, you know, when it comes to, say, you know, choosing jam or choosing an entree? Like, is this just part of human behavior? IYENGAR: The desire for personal control and competency is innate, but everything else about choice is learned. RAZ: Wow. IYENGAR: And a lot of what your culture teaches you is how to think about your life and whether to perceive things in terms of choice or in terms of something else, right? RAZ: Yeah. IYENGAR: I think to the extent that you see a choice is how you frame your life. That's not a given. We, as Americans, think that choice is a, quote, \"objective thing. \" It's not. It's a very subjective thing. RAZ: And because choice is learned, Sheena Iyengar says choice can work differently in different cultures. And she got a glimpse of that early on in her career when she was doing some research in Japan. (SOUNDBITE OF TED TALK)IYENGAR: On my first day, I went to a restaurant, and I ordered a cup of green tea with sugar. After a pause, the waiter said, one does not put sugar in green tea. I know, I said. I'm aware of this custom, but I really like my tea sweet. In response, he gave me an even more courteous version of the same explanation. (LAUGHTER)IYENGAR: One does not put sugar in green tea. I understand, I said, that the Japanese do not put sugar in their green tea, but I'd like to put some sugar in my green tea. (LAUGHTER)IYENGAR: Surprised by my insistence, the waiter took up the issue with the manager. Pretty soon. . . (LAUGHTER)IYENGAR: . . . A lengthy discussion ensued. And finally, the manager came over to me and said, I am very sorry. We do not have sugar. (LAUGHTER)IYENGAR: Well, since I couldn't have my tea the way I wanted it, I ordered a cup of coffee, which the waiter brought over promptly. Resting on the saucer were two packets of sugar. (LAUGHTER)IYENGAR: My failure to procure myself a cup of sweet green tea was not due to a simple misunderstanding. This was due to a fundamental difference in our ideas about choice. The American way, to quote Burger King, is to have it your way because, as Starbucks says, happiness is in your choices. (LAUGHTER)IYENGAR: But from the Japanese perspective, it's their duty to protect those who don't know any better. (LAUGHTER)IYENGAR: In this case, the ignorant gaijin for making the wrong choice. Americans tend to believe that they have reached some sort of pinnacle in the way they practice choice. They think that choice as seen through the American lens best fulfills an innate and universal desire for choice in all humans. (SOUNDBITE OF MUSIC)RAZ: So why is choice seen as like this great American virtue? IYENGAR: Well, you could argue that the unique history of this country made us more likely to have it than any other country. And that is because in 1776, our forefathers began to think about what a political democratic institution might look like. But at the same time, you have Adam Smith and capitalism and the idea of the independent individual consumer. And pretty shortly thereafter, you have Ralph Waldo Emerson with the ideas of self-reliance. RAZ: I mean, there must be a correlation between an emphasis on choice and a culture that elevates the individual over the collective? IYENGAR: Oh, there is. So certainly in cultures that are more collectivistic, they tend to value more social conformity, more of a sense of duty and responsibility. And so you ask yourself, what are my responsibilities? And what would other people expect of me, whereas cultures that value more independence or individualism value more self-reliance, personal preference-matching. What's really good for me? What's the right fit for me? What is it that I really care about? What do I want? That being said, individualism is on the rise. And that's probably one of our biggest exports around the globe. (SOUNDBITE OF MUSIC)RAZ: The question is - does everyone want that export? Does everyone want lots of choices? Sheena decided to go to Eastern Europe to find out. (SOUNDBITE OF TED TALK)IYENGAR: Here, I interviewed people who were residents of formerly Communist countries who had all faced the challenge of transitioning to a more democratic and capitalistic society. For Eastern Europeans, the sudden availability of all these consumer products on the marketplace was a deluge. When asked what words and images do you associate with choice, Grzegorz (ph) from Warsaw said, ah, for me it is fear. There are some dilemmas, you see. I am used to no choice. Bohdan (ph) from Kiev said in response to how he felt about the new consumer marketplace, it is too much. We do not need everything that is there. And Tomasz (ph), a young Polish man said, I do not need 20 kinds of chewing gum. I don't mean to say that I want no choice. But many of these choices are quite artificial. The value of choice depends on our ability to perceive differences between the options. When there are too many choices to compare and contrast, instead of making better choices, we become overwhelmed by choice, sometimes even afraid of it. Americans have so often tried to disseminate their ideas of choice, believing that they will be or ought to be welcomed with open hearts and minds. But the history books and the daily news tell us it doesn't always work out that way. Americans themselves are discovering that unlimited choice seems more attractive in theory than in practice. No matter where we're from, we all have a responsibility to open ourselves up to a wider array of what choice can do and what it can represent. It teaches us when and how to act. It brings us that much closer to inspiring the hope and achieving the freedom that choice promises but doesn't always deliver. If we learn to speak to one another, then we can begin to see choice in all its strangeness, complexity and compelling beauty. Thank you. (APPLAUSE)RAZ: Sheena Iyengar teaches at Columbia Business School. You can see all of her talks at ted. com Have you ever been to TGI Friday's? I mean, talk about paralysis. IYENGAR: I actually have not been in a TGIF's. RAZ: (Laughter). IYENGAR: I am a big Shake Shack girl. And I am a big In-N-Out Burger girl. And I guess that is because there really is just one choice. RAZ: Yeah. You would have a nervous breakdown at TGI Fridays. IYENGAR: no. I'd probably just ask the waiter or waitress to tell me what to get. And I'd be happy with that. GUY RAZ, HOST:  It's the TED Radio Hour from NPR. I'm Guy Raz, and on the show today, ideas about decisions - how we make them, why they can be so hard and how lots of choices don't necessarily help, like when you're standing in the grocery aisle paralyzed by the prospect of choosing from 36 varieties of spaghetti sauce. SHEENA IYENGAR: Yeah, we should try to minimize the number of times we're paralyzed over what ought to be mundane choices. RAZ: This is Sheena Iyengar. IYENGAR: Look, at the end of the day, the stakes on this aren't really very high, so just choose. RAZ: Sheena is a professor at Columbia Business School. IYENGAR: I study why choice matters to people and how they can get the most from this thing called choice. (SOUNDBITE OF MUSIC) RAZ: But even though Sheena says we shouldn't get paralyzed by things like spaghetti sauce, she still admits that it happens all the time. She even has a term for it. (SOUNDBITE OF TED TALK) IYENGAR: The choice overload problem. RAZ: The choice overload problem. Sheena explained that idea from the TED stage. (SOUNDBITE OF TED TALK) IYENGAR: So when I was a graduate student at Stanford University, I used to go to this very, very upscale grocery store. It was a store called Draeger's. They had 250 different kinds of mustards and vinegars and over 500 different kinds of fruits and vegetables and more than two dozen different kinds of bottled water. I used to love going to this store, but on one occasion, I asked myself, well, how come you never buy anything? So I one day decided to do a little experiment, and we picked jam for our experiment. They had 348 different kinds of jam. We set up a little tasting booth right near the entrance of the store. We either put out six different flavors of jam or 24 different flavors of jam, and we looked at two things. First, in which case were people more likely to, you know, stop, sample some jam? More people stopped when there were 24 - about 60 percent - than when there were six - about 40 percent. The next thing we looked at is in which case were people more likely to buy a jar of jam? Now we see the opposite effect. Of the people who stopped when there were 24, only 3 percent of them actually bought a jar of jam. Of the people who stopped when there were six, well, now we saw that 30 percent of them actually bought a jar of jam. Now, if you do the math, people were at least six times more likely to buy a jar of jam if they encountered six than if they encountered 24. Now, the main reason for this is because, well, we might enjoy gazing at those giant walls of mayonnaises, mustards, vinegars, jams, but we can't actually do the math of comparing and contrasting and actually picking from that stunning display. (SOUNDBITE OF MUSIC) RAZ: So it was this study that made Sheena think maybe we've gone too far. Maybe companies are overloading consumers with choice, which is why Sheena's advice to companies today is to cut. (SOUNDBITE OF TED TALK) IYENGAR: Cut. You've heard it said before, but it's never been more true than today that less is more. When Procter & Gamble went from 26 different kinds of Head & Shoulders to 15, they saw an increase in sales by 10 percent. When the Golden Cat Corporation got rid of their 10 worst-selling cat litter products, they saw an increase in profits by 87 percent. You know, the average grocery store today offers you 45,000 products, but the ninth biggest retailer in the world today is Aldi, and it offers you only 1,400 products - one kind of canned tomato sauce. (SOUNDBITE OF MUSIC) RAZ: Wow. That's totally counterintuitive. But, I mean, companies are actually seeing an increase in sales when when they reduce the number of choices. IYENGAR: Yes. It just looks less overwhelming. I can now see that, oh, OK, this is the Head & Shoulder I want. And when Cotsco recently reduced their number of choices, they actually saw an increase in sales. RAZ: Really? They just, like, cut back things they offer? IYENGAR: They just cut across the board, yeah. Even Wal-Mart is beginning to cut across. RAZ: So what is it about choice that overwhelms us, that can paralyze us? IYENGAR: So I think there's a few things that happen when we get paralyzed by choice. Sometimes when we're trying to choose amongst really minor things, like, let's say you're looking at a menu in a restaurant and you start deliberating over - I don't know - the steak versus the salmon versus the salad and you start contemplating all different kinds of criteria by which you want to compare and contrast your options. RAZ: Yeah. IYENGAR: But I think the other times when we get paralyzed is because it really is something that we are very aware is very, very consequential. Like, should I get married or not? Should I have a child or not? There's a lot of unknowns there. RAZ: So how is it that both of those scenarios produce agony? IYENGAR: Because there's this thing called heart versus mind or gut versus reason, however you want to label it. Even though they're both working in concert, I think the reality is you're constantly asking yourself two questions. What do I want? And what should I choose? And those don't give you the same answers because when you ask yourself what should I choose, it tells you what you ought to want tomorrow or the day after tomorrow. When you ask yourself what you want, we're very aware of the fact that what I want right now may not be what I want in five minutes. RAZ: So that's what it's about? It's about what I want and what I should want. IYENGAR: That's the inherent conflict. RAZ: Do all of us feel this conflict, you know, when it comes to, say, you know, choosing jam or choosing an entree? Like, is this just part of human behavior? IYENGAR: The desire for personal control and competency is innate, but everything else about choice is learned. RAZ: Wow. IYENGAR: And a lot of what your culture teaches you is how to think about your life and whether to perceive things in terms of choice or in terms of something else, right? RAZ: Yeah. IYENGAR: I think to the extent that you see a choice is how you frame your life. That's not a given. We, as Americans, think that choice is a, quote, \"objective thing. \" It's not. It's a very subjective thing. RAZ: And because choice is learned, Sheena Iyengar says choice can work differently in different cultures. And she got a glimpse of that early on in her career when she was doing some research in Japan. (SOUNDBITE OF TED TALK) IYENGAR: On my first day, I went to a restaurant, and I ordered a cup of green tea with sugar. After a pause, the waiter said, one does not put sugar in green tea. I know, I said. I'm aware of this custom, but I really like my tea sweet. In response, he gave me an even more courteous version of the same explanation. (LAUGHTER) IYENGAR: One does not put sugar in green tea. I understand, I said, that the Japanese do not put sugar in their green tea, but I'd like to put some sugar in my green tea. (LAUGHTER) IYENGAR: Surprised by my insistence, the waiter took up the issue with the manager. Pretty soon. . . (LAUGHTER) IYENGAR: . . . A lengthy discussion ensued. And finally, the manager came over to me and said, I am very sorry. We do not have sugar. (LAUGHTER) IYENGAR: Well, since I couldn't have my tea the way I wanted it, I ordered a cup of coffee, which the waiter brought over promptly. Resting on the saucer were two packets of sugar. (LAUGHTER) IYENGAR: My failure to procure myself a cup of sweet green tea was not due to a simple misunderstanding. This was due to a fundamental difference in our ideas about choice. The American way, to quote Burger King, is to have it your way because, as Starbucks says, happiness is in your choices. (LAUGHTER) IYENGAR: But from the Japanese perspective, it's their duty to protect those who don't know any better. (LAUGHTER) IYENGAR: In this case, the ignorant gaijin for making the wrong choice. Americans tend to believe that they have reached some sort of pinnacle in the way they practice choice. They think that choice as seen through the American lens best fulfills an innate and universal desire for choice in all humans. (SOUNDBITE OF MUSIC) RAZ: So why is choice seen as like this great American virtue? IYENGAR: Well, you could argue that the unique history of this country made us more likely to have it than any other country. And that is because in 1776, our forefathers began to think about what a political democratic institution might look like. But at the same time, you have Adam Smith and capitalism and the idea of the independent individual consumer. And pretty shortly thereafter, you have Ralph Waldo Emerson with the ideas of self-reliance. RAZ: I mean, there must be a correlation between an emphasis on choice and a culture that elevates the individual over the collective? IYENGAR: Oh, there is. So certainly in cultures that are more collectivistic, they tend to value more social conformity, more of a sense of duty and responsibility. And so you ask yourself, what are my responsibilities? And what would other people expect of me, whereas cultures that value more independence or individualism value more self-reliance, personal preference-matching. What's really good for me? What's the right fit for me? What is it that I really care about? What do I want? That being said, individualism is on the rise. And that's probably one of our biggest exports around the globe. (SOUNDBITE OF MUSIC) RAZ: The question is - does everyone want that export? Does everyone want lots of choices? Sheena decided to go to Eastern Europe to find out. (SOUNDBITE OF TED TALK) IYENGAR: Here, I interviewed people who were residents of formerly Communist countries who had all faced the challenge of transitioning to a more democratic and capitalistic society. For Eastern Europeans, the sudden availability of all these consumer products on the marketplace was a deluge. When asked what words and images do you associate with choice, Grzegorz (ph) from Warsaw said, ah, for me it is fear. There are some dilemmas, you see. I am used to no choice. Bohdan (ph) from Kiev said in response to how he felt about the new consumer marketplace, it is too much. We do not need everything that is there. And Tomasz (ph), a young Polish man said, I do not need 20 kinds of chewing gum. I don't mean to say that I want no choice. But many of these choices are quite artificial. The value of choice depends on our ability to perceive differences between the options. When there are too many choices to compare and contrast, instead of making better choices, we become overwhelmed by choice, sometimes even afraid of it. Americans have so often tried to disseminate their ideas of choice, believing that they will be or ought to be welcomed with open hearts and minds. But the history books and the daily news tell us it doesn't always work out that way. Americans themselves are discovering that unlimited choice seems more attractive in theory than in practice. No matter where we're from, we all have a responsibility to open ourselves up to a wider array of what choice can do and what it can represent. It teaches us when and how to act. It brings us that much closer to inspiring the hope and achieving the freedom that choice promises but doesn't always deliver. If we learn to speak to one another, then we can begin to see choice in all its strangeness, complexity and compelling beauty. Thank you. (APPLAUSE) RAZ: Sheena Iyengar teaches at Columbia Business School. You can see all of her talks at ted. com Have you ever been to TGI Friday's? I mean, talk about paralysis. IYENGAR: I actually have not been in a TGIF's. RAZ: (Laughter). IYENGAR: I am a big Shake Shack girl. And I am a big In-N-Out Burger girl. And I guess that is because there really is just one choice. RAZ: Yeah. You would have a nervous breakdown at TGI Fridays. IYENGAR: no. I'd probably just ask the waiter or waitress to tell me what to get. And I'd be happy with that.", "section": "TED Radio Hour", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-03-10-519593195": {"title": "WikiLeaks Reveal Demonstrates Encryption Apps' Vulnerabilities : NPR", "url": "https://www.npr.org/2017/03/10/519593195/wikileaks-reveal-demonstrates-encryption-apps-have-vulnerabilities", "author": "No author found", "published_date": "2017-03-10", "content": "DAVID GREENE, HOST:  More and more people are using encryption apps like Signal and WhatsApp to secure their text messages, or to try to do that at least. The latest batch of WikiLeaks prove that those programs essentially become irrelevant if a hacker takes control of your smartphone. MOXIE MARLINSPIKE: If you're, you know, sending an encrypted text message to somebody and someone else is standing behind you looking over your shoulder, encryption doesn't help you there. GREENE: That is Moxie Marlinspike, the founder of Signal, an encrypted messaging app. WikiLeaks did not expose any vulnerabilities in Signal's technology, but it did reveal that when the CIA hacks into a smartphone, it can easily exploit the phone itself. And that means a hacker can read your messages as you're typing them before they even get encrypted. Think of it like a computer virus that's infected your phone. MARLINSPIKE: It's not the kind of thing where, you know, some CIA agent presses a button and suddenly has access to your phone. You would have had to be involved somehow, either by getting tricked into installing an app that's like the CIA's app or clicking on a link or something and getting something installed that way. It's not mass surveillance, you know? And that's really a big distinction that I think is worth trying. GREENE: Now that there's been this revelation that, even as unlikely as it is, you say, that the CIA has malware, that they can be in a phone when someone is using Signal, are you developing more secure technology taking this into account? MARLINSPIKE: You know, the vulnerabilities that the CIA have are in, like, the operating system. You know, they're in things like Android. The other thing to say is that, like, the information in this release was pretty technically unimpressive. If anything, it was obviously embarrassing to the CIA that this information got out, but it's also somewhat embarrassing that this is their level of sophistication. There's a tendency to sort of think, oh, my God, you know, the CIA has these insane capabilities, and I think the truth is somewhat different. GREENE: Julian Assange, the founder of WikiLeaks, said that there's more coming. And he has just made this offer saying that he'll let tech companies have a look at the documents before he actually releases them to the public so you could fix things if there are any vulnerabilities. Are you going to take him up on that? MARLINSPIKE: Well, I mean, like I said, these aren't vulnerabilities in anything that we've developed. So, you know, I presume he's talking about Google and Microsoft. I would imagine that most of the things have already been fixed. GREENE: But is there an argument that what Julian Assange is offering is something that the government should be doing, that if they know about vulnerabilities in technology that they might tell you or, you know, Android about them, and that's not a role WikiLeaks should be playing? MARLINSPIKE: Absolutely. I think - certainly I agree that it is irresponsible to hoard these vulnerabilities and to, A, think that, you know, no one else has discovered these vulnerabilities or to, B, think that they can manage them securely because, you know, obviously they can't. If what the CIA is interested in doing is protecting Americans, then I think it should be in the CIA's interest to disclose these vulnerabilities to American companies so that they can fix them and protect their users. GREENE: I just find this so interesting because you created a technology that makes leakers in the government or elsewhere feel safer. But after this revelation, you know, the Trump administration is now saying we have to crack down on leaking. So your technology is at the heart of a question about leaking. So which is it for you? I mean, should the Trump administration crack down on leaking or is leaking something that you think should happen more and more? MARLINSPIKE: Our objective is not necessarily to enable leakers. You know, all types of people use Signal. And really what we're trying to do is make private communication simple and to make mass surveillance impossible. So it's true that, you know, there are probably some people in government who use Signal for leaks. But, you know, it's also true that the Trump transition team used Signal during the transition. It's also true that the Hillary Clinton campaign used Signal. Local police departments use Signal and Black Lives Matter uses Signal. Edward Snowden uses Signal. So, you know, there's a lot of people who are interested in private communication and making that as simple as possible, and that's what we're trying to enable. GREENE: Moxie Marlinspike, thanks so much for joining us. We appreciate it. MARLINSPIKE: Thank you. GREENE: He is the creator of the messaging app Signal. DAVID GREENE, HOST:   More and more people are using encryption apps like Signal and WhatsApp to secure their text messages, or to try to do that at least. The latest batch of WikiLeaks prove that those programs essentially become irrelevant if a hacker takes control of your smartphone. MOXIE MARLINSPIKE: If you're, you know, sending an encrypted text message to somebody and someone else is standing behind you looking over your shoulder, encryption doesn't help you there. GREENE: That is Moxie Marlinspike, the founder of Signal, an encrypted messaging app. WikiLeaks did not expose any vulnerabilities in Signal's technology, but it did reveal that when the CIA hacks into a smartphone, it can easily exploit the phone itself. And that means a hacker can read your messages as you're typing them before they even get encrypted. Think of it like a computer virus that's infected your phone. MARLINSPIKE: It's not the kind of thing where, you know, some CIA agent presses a button and suddenly has access to your phone. You would have had to be involved somehow, either by getting tricked into installing an app that's like the CIA's app or clicking on a link or something and getting something installed that way. It's not mass surveillance, you know? And that's really a big distinction that I think is worth trying. GREENE: Now that there's been this revelation that, even as unlikely as it is, you say, that the CIA has malware, that they can be in a phone when someone is using Signal, are you developing more secure technology taking this into account? MARLINSPIKE: You know, the vulnerabilities that the CIA have are in, like, the operating system. You know, they're in things like Android. The other thing to say is that, like, the information in this release was pretty technically unimpressive. If anything, it was obviously embarrassing to the CIA that this information got out, but it's also somewhat embarrassing that this is their level of sophistication. There's a tendency to sort of think, oh, my God, you know, the CIA has these insane capabilities, and I think the truth is somewhat different. GREENE: Julian Assange, the founder of WikiLeaks, said that there's more coming. And he has just made this offer saying that he'll let tech companies have a look at the documents before he actually releases them to the public so you could fix things if there are any vulnerabilities. Are you going to take him up on that? MARLINSPIKE: Well, I mean, like I said, these aren't vulnerabilities in anything that we've developed. So, you know, I presume he's talking about Google and Microsoft. I would imagine that most of the things have already been fixed. GREENE: But is there an argument that what Julian Assange is offering is something that the government should be doing, that if they know about vulnerabilities in technology that they might tell you or, you know, Android about them, and that's not a role WikiLeaks should be playing? MARLINSPIKE: Absolutely. I think - certainly I agree that it is irresponsible to hoard these vulnerabilities and to, A, think that, you know, no one else has discovered these vulnerabilities or to, B, think that they can manage them securely because, you know, obviously they can't. If what the CIA is interested in doing is protecting Americans, then I think it should be in the CIA's interest to disclose these vulnerabilities to American companies so that they can fix them and protect their users. GREENE: I just find this so interesting because you created a technology that makes leakers in the government or elsewhere feel safer. But after this revelation, you know, the Trump administration is now saying we have to crack down on leaking. So your technology is at the heart of a question about leaking. So which is it for you? I mean, should the Trump administration crack down on leaking or is leaking something that you think should happen more and more? MARLINSPIKE: Our objective is not necessarily to enable leakers. You know, all types of people use Signal. And really what we're trying to do is make private communication simple and to make mass surveillance impossible. So it's true that, you know, there are probably some people in government who use Signal for leaks. But, you know, it's also true that the Trump transition team used Signal during the transition. It's also true that the Hillary Clinton campaign used Signal. Local police departments use Signal and Black Lives Matter uses Signal. Edward Snowden uses Signal. So, you know, there's a lot of people who are interested in private communication and making that as simple as possible, and that's what we're trying to enable. GREENE: Moxie Marlinspike, thanks so much for joining us. We appreciate it. MARLINSPIKE: Thank you. GREENE: He is the creator of the messaging app Signal.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-03-13-519983877": {"title": "As Braille Literacy Declines, Reading Competitions Held To Boost Interest : NPR", "url": "https://www.npr.org/2017/03/13/519983877/as-braille-literacy-declines-reading-competitions-held-to-boost-interest", "author": "No author found", "published_date": "2017-03-13", "content": "ROBERT SIEGEL, HOST: If you've already filled out your brackets and need something competitive to watch between now and the first games of Match Madness, try reading - Braille reading. It's now a competitive sport of sorts. And as Blake Farmer of member station WPLN in Nashville reports, that's not because there's so much excitement about Braille but rather because there isn't. BLAKE FARMER, BYLINE: Right now, the Los Angeles-based Braille Institute is putting on regional competitions like this one in a classroom at the Tennessee School for the Blind. And a Braille reading competition actually looks more like a typing contest. UNIDENTIFIED WOMAN: Everyone have their paper in their machines? You may begin. (SOUNDBITE OF BRAILLE TYPEWRITER KEYS)FARMER: Students flip through their packets, their spread fingers sweep over the square pages. In some events, they proofread Braille. In this session, they interpret charts and graphs, typing their answers into mechanical nine-key Braille writers. (SOUNDBITE OF BRAILLE TYPEWRITER KEYS)FARMER: The old-school equipment is akin to taking a math test without a calculator these days. Digital technology, especially a computer's ability to read text aloud, makes Braille seem more and more antiquated. But 12th grader Marcus Johnson finds it a necessary skill. MARCUS JOHNSON: Because you cannot use technology for every aspect of education, so sometimes you just have to have that physical writing there. FARMER: For Johnson, there's also something about the written word, even as an alphabet of dots. JOHNSON: To me, it's kind of reminiscent. I've had vision before in my life. I lost my vision while I was young. But, I mean, it kind of just - it helps to bring back the feeling, you know, of actually having a physical book. FARMER: But it's not easy, even for someone who is blind since birth. Sydney Walker made her middle school-aged son learn Braille as a baby, putting raised labels on things all over the house. SYDNEY WALKER: It wasn't easy, I'll say. I think some people have the idea that if you're born blind, you're automatically going to be a great Braille reader. FARMER: It's far from automatic, and Braille literacy has fallen to around 10 percent for children. JOANNE WEATHERALL: And the kids are not wanting to do it because it takes extra time and it's harder. FARMER: Joanne Weatherall is a retired teacher from the Tennessee School for the Blind who comes back to be a scorekeeper each year. She's blind herself. She says no sighted person would ever think they could forget about learning to write with pencil and paper just because they type most of the time. WEATHERALL: It should not occur to a blind person to not be where they can't write something down. FARMER: Well, then why would people even be entertaining the idea of getting through life without knowing Braille? WEATHERALL: That is an excellent question. The only thing I would think is because kids that start out in school very young learning technology, it's very easy for them. It's faster than reading and writing in Braille because that can be very slow and cumbersome. FARMER: This national competition that's fed by these regional events was set up 16 years ago as a fun way to make sure Braille didn't fall out of use. And Weatherall says she still has to convince students to compete. WEATHERALL: What to do to really get the kids charged up about Braille? I don't know because many of them hate it, which just makes me crazy. FARMER: What makes Weatherall grin ear to ear are Braille lovers like Marcus Johnson, who plans to attend a local university in the fall, though he says Braille will not be particularly useful in his college classes. For NPR News, I'm Blake Farmer in Nashville. (SOUNDBITE OF CHARLES BRADLEY SONG, \"TELEPHONE SONG\") ROBERT SIEGEL, HOST:  If you've already filled out your brackets and need something competitive to watch between now and the first games of Match Madness, try reading - Braille reading. It's now a competitive sport of sorts. And as Blake Farmer of member station WPLN in Nashville reports, that's not because there's so much excitement about Braille but rather because there isn't. BLAKE FARMER, BYLINE: Right now, the Los Angeles-based Braille Institute is putting on regional competitions like this one in a classroom at the Tennessee School for the Blind. And a Braille reading competition actually looks more like a typing contest. UNIDENTIFIED WOMAN: Everyone have their paper in their machines? You may begin. (SOUNDBITE OF BRAILLE TYPEWRITER KEYS) FARMER: Students flip through their packets, their spread fingers sweep over the square pages. In some events, they proofread Braille. In this session, they interpret charts and graphs, typing their answers into mechanical nine-key Braille writers. (SOUNDBITE OF BRAILLE TYPEWRITER KEYS) FARMER: The old-school equipment is akin to taking a math test without a calculator these days. Digital technology, especially a computer's ability to read text aloud, makes Braille seem more and more antiquated. But 12th grader Marcus Johnson finds it a necessary skill. MARCUS JOHNSON: Because you cannot use technology for every aspect of education, so sometimes you just have to have that physical writing there. FARMER: For Johnson, there's also something about the written word, even as an alphabet of dots. JOHNSON: To me, it's kind of reminiscent. I've had vision before in my life. I lost my vision while I was young. But, I mean, it kind of just - it helps to bring back the feeling, you know, of actually having a physical book. FARMER: But it's not easy, even for someone who is blind since birth. Sydney Walker made her middle school-aged son learn Braille as a baby, putting raised labels on things all over the house. SYDNEY WALKER: It wasn't easy, I'll say. I think some people have the idea that if you're born blind, you're automatically going to be a great Braille reader. FARMER: It's far from automatic, and Braille literacy has fallen to around 10 percent for children. JOANNE WEATHERALL: And the kids are not wanting to do it because it takes extra time and it's harder. FARMER: Joanne Weatherall is a retired teacher from the Tennessee School for the Blind who comes back to be a scorekeeper each year. She's blind herself. She says no sighted person would ever think they could forget about learning to write with pencil and paper just because they type most of the time. WEATHERALL: It should not occur to a blind person to not be where they can't write something down. FARMER: Well, then why would people even be entertaining the idea of getting through life without knowing Braille? WEATHERALL: That is an excellent question. The only thing I would think is because kids that start out in school very young learning technology, it's very easy for them. It's faster than reading and writing in Braille because that can be very slow and cumbersome. FARMER: This national competition that's fed by these regional events was set up 16 years ago as a fun way to make sure Braille didn't fall out of use. And Weatherall says she still has to convince students to compete. WEATHERALL: What to do to really get the kids charged up about Braille? I don't know because many of them hate it, which just makes me crazy. FARMER: What makes Weatherall grin ear to ear are Braille lovers like Marcus Johnson, who plans to attend a local university in the fall, though he says Braille will not be particularly useful in his college classes. For NPR News, I'm Blake Farmer in Nashville. (SOUNDBITE OF CHARLES BRADLEY SONG, \"TELEPHONE SONG\")", "section": "Education", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-03-13-520021434": {"title": "Developers Create 'Panic Button' For Immigrants Being Detained : NPR", "url": "https://www.npr.org/2017/03/13/520021434/developers-create-panic-button-for-immigrants-being-detained", "author": "No author found", "published_date": "2017-03-13", "content": "ROBERT SIEGEL, HOST: That black three-ring binder is one way to do it. Later this week, a more high-tech version by the digital design agency Huge is launching. Developer Natalia Margolis says she got the idea after talking with an advocate for people here illegally. NATALIA MARGOLIS: Undocumented immigrants already have networks that they can activate in case of an emergency, and they wanted a way to be able to activate those networks quickly. AUDIE CORNISH, HOST: The app called Notifica will serve as a one-stop beacon for people suddenly facing arrest or deportation, a sort of panic button if immigration agents come to the door. MARGOLIS: Someone still needs to pick up your kids. You need to contact your lawyer immediately. You need to let your friends and loved ones know. And there's often not enough time to send out all of those messages at once. So this app lets you have a plan in place and lets you activate those messages immediately with the press of one button. CORNISH: Margolis and her team are working with the advocacy group United We Dream to spread the word. MARGOLIS: Hopefully people can talk about this at places of worship, at community centers, local organizations. So we're hoping there will be a kind of grassroots spread. SIEGEL: Natalia Margolis says she also expects word to get around to kids who can help their parents download and set up Notifica. ROBERT SIEGEL, HOST:  That black three-ring binder is one way to do it. Later this week, a more high-tech version by the digital design agency Huge is launching. Developer Natalia Margolis says she got the idea after talking with an advocate for people here illegally. NATALIA MARGOLIS: Undocumented immigrants already have networks that they can activate in case of an emergency, and they wanted a way to be able to activate those networks quickly. AUDIE CORNISH, HOST:  The app called Notifica will serve as a one-stop beacon for people suddenly facing arrest or deportation, a sort of panic button if immigration agents come to the door. MARGOLIS: Someone still needs to pick up your kids. You need to contact your lawyer immediately. You need to let your friends and loved ones know. And there's often not enough time to send out all of those messages at once. So this app lets you have a plan in place and lets you activate those messages immediately with the press of one button. CORNISH: Margolis and her team are working with the advocacy group United We Dream to spread the word. MARGOLIS: Hopefully people can talk about this at places of worship, at community centers, local organizations. So we're hoping there will be a kind of grassroots spread. SIEGEL: Natalia Margolis says she also expects word to get around to kids who can help their parents download and set up Notifica.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-03-15-242277334": {"title": "FAA Eases Up On Electronic Devices On Flights : NPR", "url": "https://www.npr.org/2017/03/15/242277334/faa-eases-up-on-electronic-devices-on-flights", "author": "No author found", "published_date": "2017-03-15", "content": "RENEE MONTAGNE (HOST): Over the next few minutes, we're going to hear about the problems and possibilities of electronic devices when it comes to school rooms. First, though, some loosening of a longtime limit. The FAA says it's now OK for passengers to use their portable electronic devices from gate to gate, though not for everything. NPR's Brian Naylor has more. BRIAN NAYLOR (BYLINE): No longer will passengers be told to shut off their portable electronic devices in preparation for takeoff or landing. The new FAA rules end a long debate over the safety of the devices; and they mean air travelers can read their e-books, play games or watch movies on their tablets throughout their flights. The action comes just 30 days after an advisory group recommended the old rules be scrapped. FAA Administrator Michael Huerta. MICHAEL HUERTA (FAA ADMINISTRATOR): Like any regulation that has been around for a long time - the world has changed a lot in the last 50 years; let's take a fresh look. And that's why we did. NAYLOR: The new rule does not apply to cellphones. Phone calls will still not be allowed. But owners of smartphones can use them as long as they're in airplane mode. Flight attendants, the travel industry and the airlines are all welcoming the changes. It's up to each airline to implement them. The CEO of Delta, Richard Anderson, says his airline is ready to go, and intends to make easy use of the device as a marketing tool. RICHARD ANDERSON (CEO, DELTA AIRLINES): Every one of our airplanes will have Wi-Fi, it'll have a plug, and then that Wi-Fi will also give the customers free access to a lot of free content. NAYLOR: Laptop users will still have to continue to stow their devices on takeoff and landings because their heavier weight makes them a safety concern, and passengers will be asked to look up and pay attention to the flight attendant safety presentations. RENEE MONTAGNE (HOST): Over the next few minutes, we're going to hear about the problems and possibilities of electronic devices when it comes to school rooms. First, though, some loosening of a longtime limit. The FAA says it's now OK for passengers to use their portable electronic devices from gate to gate, though not for everything. NPR's Brian Naylor has more. BRIAN NAYLOR (BYLINE): No longer will passengers be told to shut off their portable electronic devices in preparation for takeoff or landing. The new FAA rules end a long debate over the safety of the devices; and they mean air travelers can read their e-books, play games or watch movies on their tablets throughout their flights. The action comes just 30 days after an advisory group recommended the old rules be scrapped. FAA Administrator Michael Huerta. MICHAEL HUERTA (FAA ADMINISTRATOR): Like any regulation that has been around for a long time - the world has changed a lot in the last 50 years; let's take a fresh look. And that's why we did. NAYLOR: The new rule does not apply to cellphones. Phone calls will still not be allowed. But owners of smartphones can use them as long as they're in airplane mode. Flight attendants, the travel industry and the airlines are all welcoming the changes. It's up to each airline to implement them. The CEO of Delta, Richard Anderson, says his airline is ready to go, and intends to make easy use of the device as a marketing tool. RICHARD ANDERSON (CEO, DELTA AIRLINES): Every one of our airplanes will have Wi-Fi, it'll have a plug, and then that Wi-Fi will also give the customers free access to a lot of free content. NAYLOR: Laptop users will still have to continue to stow their devices on takeoff and landings because their heavier weight makes them a safety concern, and passengers will be asked to look up and pay attention to the flight attendant safety presentations. RENEE MONTAGNE (HOST): Over the next few minutes, we're going to hear about the problems and possibilities of electronic devices when it comes to school rooms. First, though, some loosening of a longtime limit. The FAA says it's now OK for passengers to use their portable electronic devices from gate to gate, though not for everything. NPR's Brian Naylor has more.  BRIAN NAYLOR (BYLINE): No longer will passengers be told to shut off their portable electronic devices in preparation for takeoff or landing. The new FAA rules end a long debate over the safety of the devices; and they mean air travelers can read their e-books, play games or watch movies on their tablets throughout their flights. The action comes just 30 days after an advisory group recommended the old rules be scrapped. FAA Administrator Michael Huerta.  MICHAEL HUERTA (FAA ADMINISTRATOR): Like any regulation that has been around for a long time - the world has changed a lot in the last 50 years; let's take a fresh look. And that's why we did.  NAYLOR: The new rule does not apply to cellphones. Phone calls will still not be allowed. But owners of smartphones can use them as long as they're in airplane mode. Flight attendants, the travel industry and the airlines are all welcoming the changes. It's up to each airline to implement them. The CEO of Delta, Richard Anderson, says his airline is ready to go, and intends to make easy use of the device as a marketing tool.  RICHARD ANDERSON (CEO, DELTA AIRLINES): Every one of our airplanes will have Wi-Fi, it'll have a plug, and then that Wi-Fi will also give the customers free access to a lot of free content.  NAYLOR: Laptop users will still have to continue to stow their devices on takeoff and landings because their heavier weight makes them a safety concern, and passengers will be asked to look up and pay attention to the flight attendant safety presentations.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-03-18-520672697": {"title": "Tech Companies Have Mixed Feelings Toward Trump Administration : NPR", "url": "https://www.npr.org/2017/03/18/520672697/tech-companies-have-mixed-feelings-toward-trump-administration", "author": "No author found", "published_date": "2017-03-18", "content": "MICHEL MARTIN, HOST: As we've mentioned, technology is a big part of South by Southwest. And it's also front and center in a tech conference that happened last week in Austin called South by Southwest Interactive. NPR's Laura Sydell was there, and she says there's a lot of interest in how the Trump administration will deal with tech companies. Some tech leaders say they're nervous, but others say they're optimistic. LAURA SYDELL, BYLINE: There's a long list of reasons why Donald Trump wasn't the candidate of choice for most techies. He recommended a boycott of Apple when it wouldn't help the FBI break into the iPhone of a terrorist. Tech businesses rely heavily on immigrants. Then there's tech's commitment to green energy, which doesn't seem to interest the pro-oil and coal Trump administration. Hugh Forrest, the chief programming officer for South by Southwest, says he's hearing a lot of nervousness from, say, companies that make electric cars. HUGH FORREST: I would imagine that the idea of a nationwide or a more robust nationwide network of charging stations will not move as fast as it would have under a different administration. SYDELL: Forrest says he's added last-minute panels on the Trump administration and tech to this year's conference because many people are nervous and because it's not clear how the president, who doesn't even use a computer, will treat tech. FORREST: I think that this administration at the top isn't as interested in tech as the last one was. SYDELL: But some of the speakers here found reasons for optimism. Gary Shapiro is head of the Consumer Technology Association, or CTA, a trade group that represents a wide spectrum of tech companies from Verizon to Google. GARY SHAPIRO: President Obama was great for tech, but he was bad for business. President Trump could be great for business, and we're not sure where he'll be for tech. SYDELL: Shapiro says the uptick in the stock market means there's more money to invest in startups. On taxes, Shapiro says Trump wants American companies to bring money back into the country without facing a huge tax burden. SHAPIRO: He's talking about repatriation of funds that are overseas, most of which are held by tech companies - big amounts of money. SYDELL: And even on immigration, Shapiro sees an opening to work with Trump. SHAPIRO: He's willing to look at merit-based immigration, which is the first time we've heard this phrase, which we've been advocating. Let's look at who we want here. Let's go get those - the best and the brightest from around the world. Let's burn down the barriers that stop them from coming here. SYDELL: There are some areas in tech where regulation has gotten in the way, and so Trump's anti-regulatory bent could be helpful. Jesse Blumenthal is the manager of tech and innovation at the Charles Koch Institute. Blumenthal says drone companies, even ones that might help save lives, face a lot of regulatory hurdles. He points to a company called Zipline. It's already in Rwanda, where its drones deliver blood for emergencies. JESSE BLUMENTHAL: And they've got a good portion of the country covered with these drones that can travel something like 60 miles an hour and get the blood in a matter of minutes or hours to a place that might have taken days to reach. SYDELL: And Zipline designs and builds its product in California. And yet, regulations prevent it from launching drones in the U. S. Still, the culture of tech companies tend to be socially liberal and global in its ambitions, values that aren't in sync with the Trump administration. So even if tech and Trump find some common interests, they aren't likely to be BFFs. Laura Sydell, NPR News. MICHEL MARTIN, HOST:  As we've mentioned, technology is a big part of South by Southwest. And it's also front and center in a tech conference that happened last week in Austin called South by Southwest Interactive. NPR's Laura Sydell was there, and she says there's a lot of interest in how the Trump administration will deal with tech companies. Some tech leaders say they're nervous, but others say they're optimistic. LAURA SYDELL, BYLINE: There's a long list of reasons why Donald Trump wasn't the candidate of choice for most techies. He recommended a boycott of Apple when it wouldn't help the FBI break into the iPhone of a terrorist. Tech businesses rely heavily on immigrants. Then there's tech's commitment to green energy, which doesn't seem to interest the pro-oil and coal Trump administration. Hugh Forrest, the chief programming officer for South by Southwest, says he's hearing a lot of nervousness from, say, companies that make electric cars. HUGH FORREST: I would imagine that the idea of a nationwide or a more robust nationwide network of charging stations will not move as fast as it would have under a different administration. SYDELL: Forrest says he's added last-minute panels on the Trump administration and tech to this year's conference because many people are nervous and because it's not clear how the president, who doesn't even use a computer, will treat tech. FORREST: I think that this administration at the top isn't as interested in tech as the last one was. SYDELL: But some of the speakers here found reasons for optimism. Gary Shapiro is head of the Consumer Technology Association, or CTA, a trade group that represents a wide spectrum of tech companies from Verizon to Google. GARY SHAPIRO: President Obama was great for tech, but he was bad for business. President Trump could be great for business, and we're not sure where he'll be for tech. SYDELL: Shapiro says the uptick in the stock market means there's more money to invest in startups. On taxes, Shapiro says Trump wants American companies to bring money back into the country without facing a huge tax burden. SHAPIRO: He's talking about repatriation of funds that are overseas, most of which are held by tech companies - big amounts of money. SYDELL: And even on immigration, Shapiro sees an opening to work with Trump. SHAPIRO: He's willing to look at merit-based immigration, which is the first time we've heard this phrase, which we've been advocating. Let's look at who we want here. Let's go get those - the best and the brightest from around the world. Let's burn down the barriers that stop them from coming here. SYDELL: There are some areas in tech where regulation has gotten in the way, and so Trump's anti-regulatory bent could be helpful. Jesse Blumenthal is the manager of tech and innovation at the Charles Koch Institute. Blumenthal says drone companies, even ones that might help save lives, face a lot of regulatory hurdles. He points to a company called Zipline. It's already in Rwanda, where its drones deliver blood for emergencies. JESSE BLUMENTHAL: And they've got a good portion of the country covered with these drones that can travel something like 60 miles an hour and get the blood in a matter of minutes or hours to a place that might have taken days to reach. SYDELL: And Zipline designs and builds its product in California. And yet, regulations prevent it from launching drones in the U. S. Still, the culture of tech companies tend to be socially liberal and global in its ambitions, values that aren't in sync with the Trump administration. So even if tech and Trump find some common interests, they aren't likely to be BFFs. Laura Sydell, NPR News.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-03-20-520862696": {"title": "The Voder: The First Machine To Produce Human Speech : NPR", "url": "https://www.npr.org/2017/03/20/520862696/the-voder-the-first-machine-to-produce-human-speech", "author": "No author found", "published_date": "2017-03-20", "content": "AUDIE CORNISH, HOST: Before Siri spoke up as the iPhone's digital assistant or the Amazon Echo was taking requests in people's homes, there was the granddaddy of all talking devices. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED MAN #1: Helen (ph), will you have the Voder say, greetings everybody? COMPUTER-GENERATED VOICE: Greetings, everybody. KELLY MCEVERS, HOST: (Laughter) Everybody that robotic voice is the Voder - V-O-D-E-R - full name - voice-operating demonstrator. It was developed by an engineer, Homer Dudley, at Bell Labs about 90 years ago. ERIC GRUNDHAUSER: It's interesting as a stepping stone, in terms of the speech synthesis that we experience every day now. CORNISH: That's Eric Grundhauser, a staff writer for Atlas Obscura. GRUNDHAUSER: To create this synthetic speech, you had have an operator who was working the Voder, not unlike an ultra-complicated piano or organ. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED WOMAN: Well, for example, in producing the word concentration on the Voder, I have to form 13 different sounds in succession. MCEVERS: In this promotional film, the female Voder operator presses down on what looks like piano keys. There were also foot pedals. Learning to manipulate them to produce words was not easy. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED MAN #2: About how long it take you to become an expert in operating the Voder? UNIDENTIFIED WOMAN: It took me about a year of constant practice. MCEVERS: Remember that the next time you get frustrated trying to learn how to use a new digital device. CORNISH: In any case, Grundhauser says the Voder was never marketed to the public. GRUNDHAUSER: They were always meant as sort of an experiment, as a - as a show piece. CORNISH: The Voder appeared in public only twice - at the 1939 World's Fair in New York and at an exposition in San Francisco the same year. MCEVERS: And although the Voder was considered revolutionary at the time, none of the machines are known to have survived. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED MAN #1: Suppose you sing a song for us? (SOUNDBITE OF SONG, \"AULD LANG SYNE\")COMPUTER-GENERATED VOICE: (Singing) Should auld acquaintance be forgot and never brought. . . MCEVERS: Unlike today's devices, the Voder was far too big, far too complicated to make it into our lives. (SOUNDBITE OF SONG, \"AULD LANG SYNE\")COMPUTER-GENERATED VOICE: (Singing) Should auld acquaintance be forgot and auld lang syne. AUDIE CORNISH, HOST:  Before Siri spoke up as the iPhone's digital assistant or the Amazon Echo was taking requests in people's homes, there was the granddaddy of all talking devices. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED MAN #1: Helen (ph), will you have the Voder say, greetings everybody? COMPUTER-GENERATED VOICE: Greetings, everybody. KELLY MCEVERS, HOST:  (Laughter) Everybody that robotic voice is the Voder - V-O-D-E-R - full name - voice-operating demonstrator. It was developed by an engineer, Homer Dudley, at Bell Labs about 90 years ago. ERIC GRUNDHAUSER: It's interesting as a stepping stone, in terms of the speech synthesis that we experience every day now. CORNISH: That's Eric Grundhauser, a staff writer for Atlas Obscura. GRUNDHAUSER: To create this synthetic speech, you had have an operator who was working the Voder, not unlike an ultra-complicated piano or organ. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED WOMAN: Well, for example, in producing the word concentration on the Voder, I have to form 13 different sounds in succession. MCEVERS: In this promotional film, the female Voder operator presses down on what looks like piano keys. There were also foot pedals. Learning to manipulate them to produce words was not easy. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED MAN #2: About how long it take you to become an expert in operating the Voder? UNIDENTIFIED WOMAN: It took me about a year of constant practice. MCEVERS: Remember that the next time you get frustrated trying to learn how to use a new digital device. CORNISH: In any case, Grundhauser says the Voder was never marketed to the public. GRUNDHAUSER: They were always meant as sort of an experiment, as a - as a show piece. CORNISH: The Voder appeared in public only twice - at the 1939 World's Fair in New York and at an exposition in San Francisco the same year. MCEVERS: And although the Voder was considered revolutionary at the time, none of the machines are known to have survived. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED MAN #1: Suppose you sing a song for us? (SOUNDBITE OF SONG, \"AULD LANG SYNE\") COMPUTER-GENERATED VOICE: (Singing) Should auld acquaintance be forgot and never brought. . . MCEVERS: Unlike today's devices, the Voder was far too big, far too complicated to make it into our lives. (SOUNDBITE OF SONG, \"AULD LANG SYNE\") COMPUTER-GENERATED VOICE: (Singing) Should auld acquaintance be forgot and auld lang syne.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-03-21-520861834": {"title": "Researchers Test Hotter, Faster And Cleaner Way To Fight Oil Spills : NPR", "url": "https://www.npr.org/2017/03/21/520861834/researchers-test-hotter-faster-and-cleaner-way-to-fight-oil-spills", "author": "No author found", "published_date": "2017-03-21", "content": "AUDIE CORNISH, HOST: The BP disaster in the Gulf of Mexico seven years ago showed just how hard it is to combat a massive oil spill. Cleaning oil from water is a challenge, especially on the open sea. Now the federal government is backing research on a new method to burn oil off of the water. NPR's Debbie Elliott watched the first test outside the laboratory. DEBBIE ELLIOTT, BYLINE: This is what the scientists call a relevant environment - a cold and windy day in Mobile Bay. Researchers from WPI, Worcester Polytechnic Institute in Massachusetts, have come here to Little Sand Island off the Alabama coast to test a new technology for burning oil floating on water. UNIDENTIFIED MAN: So let's all start getting ready to light a fire. ELLIOTT: Lighting it on fire is one of three ways to clean up an oil spill. You can use skimmers and oil booms to soak it up, dispersants to break it up or fire to burn it up. Fire protection engineering professor Ali Rangwala leads the WPI team that's testing what they call the Flame Refluxer, a faster way to burn an oil slick. ALI RANGWALA: It's very simple. ELLIOTT: He shows me a copper blanket. RANGWALA: Two meshes of copper, and in between that is copper wool. ELLIOTT: Imagine a giant Brillo pad sandwiched between layers of copper screen. Springy copper coils are attached to the top. RANGWALA: The coils collect the heat from the flame, and they transmit it to the copper blanket. ELLIOTT: The goal is to make a hotter, faster and more complete burn that leaves less pollution. Workers place the blanket inside a ring of floating fire barrier in a concrete pool, part of the U. S. Coast Guard's joint maritime test facility on the island. Oil is pumped from a nearby tank, and a long, torch-like lighter sets it afire. The flames reach up to 12 feet high. Professor Rangwala monitors by video nearby. RANGWALA: Very good. It's looking very good. ELLIOTT: Engineers are tracking the fire's heat and emissions being captured by a strategically placed wind saw. RANGWALA: What does the fume level look like? Is it regressing, or is it constant underwater? ELLIOTT: The potential here is to reduce both air pollution and the layer of tar that's left over and sinks to the ocean floor threatening marine life. Rangwala says the copper blanket was designed to capture any remaining residue. But they're finding that the tar is burning off as well. He says the test indicates a hotter, quicker and cleaner burn. RANGWALA: It guarantees about three times faster than baseline. And the smoke is also grayish in color compared to black. ELLIOTT: That gray smoke with less soot is one of the things that Karen Stone is looking for. KAREN STONE: So the lighter it is, the cleaner it is. ELLIOTT: Stone is an oil spill response engineer with BSEE, the Federal Bureau of Safety and Environmental Enforcement. The agency has invested $1. 5 million to develop the Flame Refluxer and is also paying for other new technology. It's an effort to be better prepared to respond since the 2010 BP disaster in the Gulf revealed some major gaps. For example, the country didn't have enough fire boom on hand and had to scramble to borrow supply from other countries. STONE: Once you have a spill, it really gets the attention, and we realize, wow, we really need to advance it and make it better, improve it for when it happens again. ELLIOTT: Stone says the technology that's working here in the Gulf environment also shows promise for responding to oil spills in the Arctic, but it's likely five to 10 years from being used in an actual disaster. The next step is finding the best way to deploy and test it in open water. Debbie Elliott, NPR News, Mobile. AUDIE CORNISH, HOST:  The BP disaster in the Gulf of Mexico seven years ago showed just how hard it is to combat a massive oil spill. Cleaning oil from water is a challenge, especially on the open sea. Now the federal government is backing research on a new method to burn oil off of the water. NPR's Debbie Elliott watched the first test outside the laboratory. DEBBIE ELLIOTT, BYLINE: This is what the scientists call a relevant environment - a cold and windy day in Mobile Bay. Researchers from WPI, Worcester Polytechnic Institute in Massachusetts, have come here to Little Sand Island off the Alabama coast to test a new technology for burning oil floating on water. UNIDENTIFIED MAN: So let's all start getting ready to light a fire. ELLIOTT: Lighting it on fire is one of three ways to clean up an oil spill. You can use skimmers and oil booms to soak it up, dispersants to break it up or fire to burn it up. Fire protection engineering professor Ali Rangwala leads the WPI team that's testing what they call the Flame Refluxer, a faster way to burn an oil slick. ALI RANGWALA: It's very simple. ELLIOTT: He shows me a copper blanket. RANGWALA: Two meshes of copper, and in between that is copper wool. ELLIOTT: Imagine a giant Brillo pad sandwiched between layers of copper screen. Springy copper coils are attached to the top. RANGWALA: The coils collect the heat from the flame, and they transmit it to the copper blanket. ELLIOTT: The goal is to make a hotter, faster and more complete burn that leaves less pollution. Workers place the blanket inside a ring of floating fire barrier in a concrete pool, part of the U. S. Coast Guard's joint maritime test facility on the island. Oil is pumped from a nearby tank, and a long, torch-like lighter sets it afire. The flames reach up to 12 feet high. Professor Rangwala monitors by video nearby. RANGWALA: Very good. It's looking very good. ELLIOTT: Engineers are tracking the fire's heat and emissions being captured by a strategically placed wind saw. RANGWALA: What does the fume level look like? Is it regressing, or is it constant underwater? ELLIOTT: The potential here is to reduce both air pollution and the layer of tar that's left over and sinks to the ocean floor threatening marine life. Rangwala says the copper blanket was designed to capture any remaining residue. But they're finding that the tar is burning off as well. He says the test indicates a hotter, quicker and cleaner burn. RANGWALA: It guarantees about three times faster than baseline. And the smoke is also grayish in color compared to black. ELLIOTT: That gray smoke with less soot is one of the things that Karen Stone is looking for. KAREN STONE: So the lighter it is, the cleaner it is. ELLIOTT: Stone is an oil spill response engineer with BSEE, the Federal Bureau of Safety and Environmental Enforcement. The agency has invested $1. 5 million to develop the Flame Refluxer and is also paying for other new technology. It's an effort to be better prepared to respond since the 2010 BP disaster in the Gulf revealed some major gaps. For example, the country didn't have enough fire boom on hand and had to scramble to borrow supply from other countries. STONE: Once you have a spill, it really gets the attention, and we realize, wow, we really need to advance it and make it better, improve it for when it happens again. ELLIOTT: Stone says the technology that's working here in the Gulf environment also shows promise for responding to oil spills in the Arctic, but it's likely five to 10 years from being used in an actual disaster. The next step is finding the best way to deploy and test it in open water. Debbie Elliott, NPR News, Mobile.", "section": "Environment", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-03-21-520996091": {"title": "Google Vows To Remove Ads From Offensive YouTube Content : NPR", "url": "https://www.npr.org/2017/03/21/520996091/google-vows-to-remove-ads-from-offensive-youtube-content", "author": "No author found", "published_date": "2017-03-21", "content": "KELLY MCEVERS, HOST: Marks and Spencer, The Guardian and the British government are just some of the advertisers in the United Kingdom that are fighting with Google. They have pulled ads from Google and its platform YouTube because they're concerned that these ads appear next to content that promotes hate. Today, NPR's Aarti Shahani reports, Google responded. They promised to hire, quote, \"significant numbers of people to help solve the problem. \"AARTI SHAHANI, BYLINE: Google just made a very public concession, saying in a memo that the company will remove ads more effectively and tightened safeguards and invest in more staff. But interestingly, behind the scenes, people deep inside Europe's multi-billion dollar advertising industry disagree about who is really to blame. Curt Simon Harlinghausen with Publicis Media in Munich advises big brands and blames Google. CURT SIMON HARLINGHAUSEN: They struggle with organizing and administrating content and advertisements in the big scale. If you do a lot of automatization, you cannot guarantee things getting right because you still have a lot of misinterpretation of information. SHAHANI: Meaning Google relies on software to ID what content is OK, what's an ISIS video versus a trailer for a new Vin Diesel movie. And he says Google's software lets too much slip through the cracks and pairs advertisers with bad content, hate content. But Andre Alpar of Performics in Berlin, which also represents advertisers, says while it's easy to blame Google - they are the giant - the big brands are really at fault. ANDRE ALPAR: The advertisers have to make sure to put the money where the mouth is. SHAHANI: Meaning, in the old days of Google, advertisers would pay to put ads on specific websites. Then Google developed new products to let you chase eyeballs instead of pages. So if I'm BMW, I can pay Google to put me in front of a thousand high-net-worth consumers, whatever sites they may visit across the vast and growing internet. This whole system is based on a well-known fact. ALPAR: That you don't actually know where you're going to reach your customer. SHAHANI: It could be a white supremacist blog or a golf lovers page. Big brands could decide to take it upon themselves to keep a short list - or a very long list - of sites that are incompatible with their brand values and block ads accordingly. But as with many problems that appear to be about values and principles, there's an economic reality at play. If you want to, say, reach a thousand people, it's more expensive to do that when you limit the number of sites you're willing to advertise on. So Alpar says big brands have a financial incentive to turn a blind eyeALPAR: As long as nobody raises an issue, then I can do the same thing for $2 that I can do for six. It's OK. But if somebody starts raising the issue then (clicking). SHAHANI: Then you haven't invested enough. The issue is being raised at a time when Europe is in the middle of its election season, and the public there, witnessing what happened in the U. S. , has its own concerns about the impact of fake news and extremist content. A Google spokesperson says the company is committed to making it easier for brands to control where their ads go and is moving really quickly. The company plans to reveal more details about its new systems in the coming weeks. Aarti Shahani, NPR News, San Francisco. KELLY MCEVERS, HOST:  Marks and Spencer, The Guardian and the British government are just some of the advertisers in the United Kingdom that are fighting with Google. They have pulled ads from Google and its platform YouTube because they're concerned that these ads appear next to content that promotes hate. Today, NPR's Aarti Shahani reports, Google responded. They promised to hire, quote, \"significant numbers of people to help solve the problem. \" AARTI SHAHANI, BYLINE: Google just made a very public concession, saying in a memo that the company will remove ads more effectively and tightened safeguards and invest in more staff. But interestingly, behind the scenes, people deep inside Europe's multi-billion dollar advertising industry disagree about who is really to blame. Curt Simon Harlinghausen with Publicis Media in Munich advises big brands and blames Google. CURT SIMON HARLINGHAUSEN: They struggle with organizing and administrating content and advertisements in the big scale. If you do a lot of automatization, you cannot guarantee things getting right because you still have a lot of misinterpretation of information. SHAHANI: Meaning Google relies on software to ID what content is OK, what's an ISIS video versus a trailer for a new Vin Diesel movie. And he says Google's software lets too much slip through the cracks and pairs advertisers with bad content, hate content. But Andre Alpar of Performics in Berlin, which also represents advertisers, says while it's easy to blame Google - they are the giant - the big brands are really at fault. ANDRE ALPAR: The advertisers have to make sure to put the money where the mouth is. SHAHANI: Meaning, in the old days of Google, advertisers would pay to put ads on specific websites. Then Google developed new products to let you chase eyeballs instead of pages. So if I'm BMW, I can pay Google to put me in front of a thousand high-net-worth consumers, whatever sites they may visit across the vast and growing internet. This whole system is based on a well-known fact. ALPAR: That you don't actually know where you're going to reach your customer. SHAHANI: It could be a white supremacist blog or a golf lovers page. Big brands could decide to take it upon themselves to keep a short list - or a very long list - of sites that are incompatible with their brand values and block ads accordingly. But as with many problems that appear to be about values and principles, there's an economic reality at play. If you want to, say, reach a thousand people, it's more expensive to do that when you limit the number of sites you're willing to advertise on. So Alpar says big brands have a financial incentive to turn a blind eye ALPAR: As long as nobody raises an issue, then I can do the same thing for $2 that I can do for six. It's OK. But if somebody starts raising the issue then (clicking). SHAHANI: Then you haven't invested enough. The issue is being raised at a time when Europe is in the middle of its election season, and the public there, witnessing what happened in the U. S. , has its own concerns about the impact of fake news and extremist content. A Google spokesperson says the company is committed to making it easier for brands to control where their ads go and is moving really quickly. The company plans to reveal more details about its new systems in the coming weeks. Aarti Shahani, NPR News, San Francisco.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-03-25-521102557": {"title": "Police Videos Aren't Going Away. How Can We Learn From Them? : NPR", "url": "https://www.npr.org/2017/03/25/521102557/police-videos-arent-going-away-how-can-we-learn-from-them", "author": "No author found", "published_date": "2017-03-25", "content": "", "section": "Embedded", "disclaimer": ""}, "2017-03-26-521550411": {"title": "Prosecutor Makes The Case For Law Enforcement Access To Data : NPR", "url": "https://www.npr.org/2017/03/26/521550411/prosecutor-makes-the-case-for-law-enforcement-access-to-data", "author": "No author found", "published_date": "2017-03-26", "content": "LOURDES GARCIA-NAVARRO, HOST: The fight for privacy isn't just between consumers and tech companies or hackers. It often involves the government. If you recall, one of the most high-profile battles between law enforcement and privacy advocates came after the 2015 terrorist attack in San Bernardino, Calif. The Justice Department tried to make Apple unlock the iPhone of their suspect. In the end, that case was dropped, and the FBI had to spend over a million dollars to unlock that iPhone independently. Michael Ramos is district attorney of San Bernardino County in California, and he's president of the National Association of District Attorneys (ph). And he told us that even though that case is over, he's dealing with many more like it. MICHAEL RAMOS: It's very important, and it's still a huge issue. In fact, we are going to be talking about that at a national level in a meeting with the new Attorney General Sessions. Criminals are using phones because they know law enforcement cannot get into the phone system. GARCIA-NAVARRO: What are you going to be asking Mr. Sessions for? RAMOS: You know, I'm going to ask him if he could support legislation to come up with some kind of compromise where, in certain situations, certain circumstances, if you meet those criteria, that law enforcement should be able to get into your phones to, number one, solve a crime, such as murder or drug trafficking or, number two, prevent a crime from happening in the future. GARCIA-NAVARRO: Let me understand, sir. You want this to happen without having to go in front of a judge? RAMOS: Oh, no. I think we have a system in place. It should go in front of a judge, just like any other search warrant. You should have to write it. You should have all the elements, the probable cause to go into that phone. And with those safeguards, then I think you protect all of our rights as citizens. GARCIA-NAVARRO: You know, one of the big arguments that took place during this whole issue with the phone of Syed Farook and Apple. . . RAMOS: Yes. GARCIA-NAVARRO: . . . Is that, you know, if you allow access to iPhones through a backdoor, that could jeopardize the security of all iPhones, that could be opening a backdoor that hackers could use to steal people's information. Why do you think that that is a risk worth taking? RAMOS: I think it's not the risk that everybody thinks. There can be a system that could be put in place, a key or a key-and-a-half system where in that situation the information could be unlocked for that device only and then after the combination is used, destroyed. GARCIA-NAVARRO: All right, Michael Ramos, he's the San Bernardino County district attorney. Thank you so much for speaking with us. RAMOS: Thank you. GARCIA-NAVARRO: And next time on The Call-In, President Trump has promised to roll back environmental regulations, and he's asked Congress to slash the budget of the EPA. What are your questions about the administration's climate change policy and its possible effects? Call in at 202-216-9217. Leave us a voicemail with your full name, where you're from and your question, and we may use it on the air. That number again - 202-216-9217. (SOUNDBITE OF CORDUROI'S \"MY DEAR\") LOURDES GARCIA-NAVARRO, HOST:  The fight for privacy isn't just between consumers and tech companies or hackers. It often involves the government. If you recall, one of the most high-profile battles between law enforcement and privacy advocates came after the 2015 terrorist attack in San Bernardino, Calif. The Justice Department tried to make Apple unlock the iPhone of their suspect. In the end, that case was dropped, and the FBI had to spend over a million dollars to unlock that iPhone independently. Michael Ramos is district attorney of San Bernardino County in California, and he's president of the National Association of District Attorneys (ph). And he told us that even though that case is over, he's dealing with many more like it. MICHAEL RAMOS: It's very important, and it's still a huge issue. In fact, we are going to be talking about that at a national level in a meeting with the new Attorney General Sessions. Criminals are using phones because they know law enforcement cannot get into the phone system. GARCIA-NAVARRO: What are you going to be asking Mr. Sessions for? RAMOS: You know, I'm going to ask him if he could support legislation to come up with some kind of compromise where, in certain situations, certain circumstances, if you meet those criteria, that law enforcement should be able to get into your phones to, number one, solve a crime, such as murder or drug trafficking or, number two, prevent a crime from happening in the future. GARCIA-NAVARRO: Let me understand, sir. You want this to happen without having to go in front of a judge? RAMOS: Oh, no. I think we have a system in place. It should go in front of a judge, just like any other search warrant. You should have to write it. You should have all the elements, the probable cause to go into that phone. And with those safeguards, then I think you protect all of our rights as citizens. GARCIA-NAVARRO: You know, one of the big arguments that took place during this whole issue with the phone of Syed Farook and Apple. . . RAMOS: Yes. GARCIA-NAVARRO: . . . Is that, you know, if you allow access to iPhones through a backdoor, that could jeopardize the security of all iPhones, that could be opening a backdoor that hackers could use to steal people's information. Why do you think that that is a risk worth taking? RAMOS: I think it's not the risk that everybody thinks. There can be a system that could be put in place, a key or a key-and-a-half system where in that situation the information could be unlocked for that device only and then after the combination is used, destroyed. GARCIA-NAVARRO: All right, Michael Ramos, he's the San Bernardino County district attorney. Thank you so much for speaking with us. RAMOS: Thank you. GARCIA-NAVARRO: And next time on The Call-In, President Trump has promised to roll back environmental regulations, and he's asked Congress to slash the budget of the EPA. What are your questions about the administration's climate change policy and its possible effects? Call in at 202-216-9217. Leave us a voicemail with your full name, where you're from and your question, and we may use it on the air. That number again - 202-216-9217. (SOUNDBITE OF CORDUROI'S \"MY DEAR\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-03-26-521550404": {"title": "The Call-In: Answering Your Questions About Digital Privacy : NPR", "url": "https://www.npr.org/2017/03/26/521550404/the-call-in-answering-your-questions-about-digital-privacy", "author": "No author found", "published_date": "2017-03-26", "content": "LOURDES GARCIA-NAVARRO, HOST: This is The Call-In. (SOUNDBITE OF CORDUROI'S \"MY DEAR\")GARCIA-NAVARRO: Republican senators voted last week to undo FCC privacy rules for internet service providers. Those rules would have required telecom and cable companies to tell people what data is being collected from them and how they're using it. Telecom companies aren't the only places that collect your most important information. Google and Facebook and Apple do, too, as well as your Kindle, your thermostat, your fridge and your car. We asked for your questions about digital privacy. (SOUNDBITE OF VOICE RECORDING MONTAGE)SARAH KENWORD: Hi, my name is Sarah Kenword (ph). DAVID JACKSON: Hi, this is David Jackson (ph) in Hamakua, Hawaii. UNIDENTIFIED MAN #1: My question is, how do I protect myself and my personal information? UNIDENTIFIED WOMAN: Does clearing the app cache provide any protection? UNIDENTIFIED MAN #2: Those devices give up my personal information. UNIDENTIFIED MAN #3: I'd like to know, and I thank you much. (SOUNDBITE OF MUSIC)GARCIA-NAVARRO: In a moment, we'll get answers to those questions. But first, we're going to look at how well internet companies protect your privacy. The nonprofit Ranking Digital Rights has issued its latest ranking working with Consumer Reports. For the first time, it includes companies like Apple. I asked the group's head, Rebecca MacKinnon, how they stacked up. REBECCA MACKINNON: Well, not so great. What we're looking at in the Ranking Digital Rights corporate accountability index is companies' public commitments and disclosures about what their policies are affecting users privacy as well as their freedom of expression and the company's kind of general governance. So do they have institutional mechanisms in place to make sure that all of their managers and employees are thinking about their users' rights? And while Apple is very well known for its CEO Tim Cook making statements about user privacy and the importance and Apple's also. . . GARCIA-NAVARRO: And you've had these famous cases. . . MACKINNON: That's right. GARCIA-NAVARRO: . . . Where Apple refused to hand over. . . MACKINNON: Laudably, Apple has stood up for user privacy in the face of government demands. But when it comes to disclosing specifically what's being collected and how it's being used, they disclose less information than you'd expect. GARCIA-NAVARRO: All right, so who scored well and why? MACKINNON: Well, in this index, to say that there are leaders would also be misleading because if this were an academic test, the top two companies got D's and everybody else got F's. And so the reason why Google and Microsoft came out on top and then followed by Yahoo and Facebook, is not necessarily that they're doing all the right things. But at least they're telling us. GARCIA-NAVARRO: We're talking about massive companies, global companies, but we're seeing the internet of things. We're seeing all these devices now being internet-enabled in our homes, you know, from the microwave to the television. And those devices seem to have very little security, very little protection. What do you do about that? MACKINNON: It's a real problem because a lot of these companies that are used to being device manufacturers, their management and their boards have not been asking questions about - how do we manage risk not just to the company but to our end users. Cars can be hacked. You know, many of us now when we rent cars and you see the data on the dashboard from the last person's phone that they synced with the car, and there's so much personal information that is now in cars. I mean, cars are increasingly sort of hybrid smartphones in many ways. And do these companies have policies and practices in place to protect our rights? There is no disclosure. So at the moment, we don't really know. GARCIA-NAVARRO: Rebecca MacKinnon is the director of Ranking Digital Rights. Thanks so much. MACKINNON: Thank you. LOURDES GARCIA-NAVARRO, HOST:  This is The Call-In. (SOUNDBITE OF CORDUROI'S \"MY DEAR\") GARCIA-NAVARRO: Republican senators voted last week to undo FCC privacy rules for internet service providers. Those rules would have required telecom and cable companies to tell people what data is being collected from them and how they're using it. Telecom companies aren't the only places that collect your most important information. Google and Facebook and Apple do, too, as well as your Kindle, your thermostat, your fridge and your car. We asked for your questions about digital privacy. (SOUNDBITE OF VOICE RECORDING MONTAGE) SARAH KENWORD: Hi, my name is Sarah Kenword (ph). DAVID JACKSON: Hi, this is David Jackson (ph) in Hamakua, Hawaii. UNIDENTIFIED MAN #1: My question is, how do I protect myself and my personal information? UNIDENTIFIED WOMAN: Does clearing the app cache provide any protection? UNIDENTIFIED MAN #2: Those devices give up my personal information. UNIDENTIFIED MAN #3: I'd like to know, and I thank you much. (SOUNDBITE OF MUSIC) GARCIA-NAVARRO: In a moment, we'll get answers to those questions. But first, we're going to look at how well internet companies protect your privacy. The nonprofit Ranking Digital Rights has issued its latest ranking working with Consumer Reports. For the first time, it includes companies like Apple. I asked the group's head, Rebecca MacKinnon, how they stacked up. REBECCA MACKINNON: Well, not so great. What we're looking at in the Ranking Digital Rights corporate accountability index is companies' public commitments and disclosures about what their policies are affecting users privacy as well as their freedom of expression and the company's kind of general governance. So do they have institutional mechanisms in place to make sure that all of their managers and employees are thinking about their users' rights? And while Apple is very well known for its CEO Tim Cook making statements about user privacy and the importance and Apple's also. . . GARCIA-NAVARRO: And you've had these famous cases. . . MACKINNON: That's right. GARCIA-NAVARRO: . . . Where Apple refused to hand over. . . MACKINNON: Laudably, Apple has stood up for user privacy in the face of government demands. But when it comes to disclosing specifically what's being collected and how it's being used, they disclose less information than you'd expect. GARCIA-NAVARRO: All right, so who scored well and why? MACKINNON: Well, in this index, to say that there are leaders would also be misleading because if this were an academic test, the top two companies got D's and everybody else got F's. And so the reason why Google and Microsoft came out on top and then followed by Yahoo and Facebook, is not necessarily that they're doing all the right things. But at least they're telling us. GARCIA-NAVARRO: We're talking about massive companies, global companies, but we're seeing the internet of things. We're seeing all these devices now being internet-enabled in our homes, you know, from the microwave to the television. And those devices seem to have very little security, very little protection. What do you do about that? MACKINNON: It's a real problem because a lot of these companies that are used to being device manufacturers, their management and their boards have not been asking questions about - how do we manage risk not just to the company but to our end users. Cars can be hacked. You know, many of us now when we rent cars and you see the data on the dashboard from the last person's phone that they synced with the car, and there's so much personal information that is now in cars. I mean, cars are increasingly sort of hybrid smartphones in many ways. And do these companies have policies and practices in place to protect our rights? There is no disclosure. So at the moment, we don't really know. GARCIA-NAVARRO: Rebecca MacKinnon is the director of Ranking Digital Rights. Thanks so much. MACKINNON: Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-03-28-521831393": {"title": "Congress Overturns Internet Privacy Regulation : NPR", "url": "https://www.npr.org/2017/03/28/521831393/congress-overturns-internet-privacy-regulation", "author": "No author found", "published_date": "2017-03-28", "content": "", "section": "Politics", "disclaimer": ""}, "2017-03-28-521779864": {"title": "Inside DARPA, The Pentagon Agency Whose Technology Has 'Changed the World' : NPR", "url": "https://www.npr.org/2017/03/28/521779864/inside-darpa-the-pentagon-agency-whose-technology-has-changed-the-world", "author": "No author found", "published_date": "2017-03-28", "content": "TERRY GROSS, HOST: This is FRESH AIR. I'm Terry Gross. Thinking big can lead to breakthroughs or spectacular failures. And the Pentagon agency DARPA has had its share of both. DARPA is the acronym for the Defense Advanced Research Projects Agency. It started off as ARPA before the D was added for defense. Its mission is to create innovative defense technologies. Its projects have ranged from space-based missile shields to cyborg insects. Its innovations have had practical applications in the civilian world, ranging from the Internet to robot vacuum cleaners. My guest, Sharon Weinberger, is the author of a new book about DARPA called \"The Imagineers Of War. \" Her research includes recently declassified documents, as well as interviews she conducted with people who have worked on DARPA projects. She's the national security editor at The Intercept, a global fellow at the Woodrow Wilson International Center for Scholars and former editor-in-chief of Defense Technology International. Welcome back to FRESH AIR. What are some of the most impressive successes of DARPA? SHARON WEINBERGER: Well, let's start with the first success that has really cemented DARPA's reputation today. And that would be ARPANET, which was the precursor and laid the foundation for the modern Internet. That is undoubtedly the agency's biggest success. And because of the name itself, ARPANET is sort of synonymous with DARPA today. But there are many other innovations that they get less credit for but in fact go back directly to the agency's work. The driverless cars, autonomous self-driving cars that are now coming to fruition date back to a series of robotic car races that DARPA sponsored beginning in 2004, 2005. Some of DARPA's other biggest, quote, unquote, \"successes\" are stealth aircraft. They sponsored the development of the first stealth prototype aircraft in the 1970s. Precision weapons is another DARPA innovation. Drones, particularly the Predator drone that we now associate with the wars in Iraq, Afghanistan and elsewhere date back to DARPA sponsorship. GROSS: And there's also some pretty big failures that DARPA was responsible for. Tell us about a couple of those. WEINBERGER: There are a number of failures. I think that the ones that are sort of best known are the National Aero-Space Plane, which was a plan in the 1980s to have a single-stage-to-orbit space plane. Basically a plane that would take off from a runway, rather than being launched by a rocket, go into space where it could be anything - it could be a spy plane, it could be a space bomber - re-enter the atmosphere and then land again like an airplane. You know, at one point, you know, the cost of this program had grown to the billions of dollars and was eventually canceled. It had grown very complex, very expensive. Other notable \"failures\" - and I'll put this in quotes - are, for example, what was called the Strategic Computing Initiative. This was an effort - a billion dollar effort in the 1980s to create artificial intelligence. There was a lot of publicity around the program, a little bit of controversy around the program as well. And it ended in failure such that, well, for starters, they never created artificial intelligence. But most of the programs and companies that were sponsored under the program did not succeed. However, as with a lot of failures in DARPA, as you see now a lot of excitement about artificial intelligence, there's a strong argument to be made that DARPA laid the foundations for that. So was that program a failure? Maybe in a sense it's too early to say. GROSS: So it was created in 1958. What was the point when it was created - of DARPA? WEINBERGER: So let's take us back to that moment in time. In the fall of 1957, the Soviet Union had launched Sputnik, the first artificial satellite. And, you know, the mythology that has developed around that was it, you know, it sparked this immediate national panic with, you know, Americans looking up at the sky trying to see the Soviet satellite. And the idea was not only that the Soviets were ahead in the space race, but the ability to launch a satellite was also linked to the ability to launch intercontinental ballistic missiles, i. e. that they could launch a nuclear weapon that could reach the continental United States. So the reality was actually a bit different, that when Sputnik was launched, it was a little bit esoteric. It was in the back pages of newspapers. But it became a lightning rod in Washington, a way for critics of the Eisenhower administration to really attack the president. And so it became this political panic within a number of weeks. And so just as after 9/11 there was a push to sort of reorganize government to have the government respond - after 9/11 it was the creation of Department of Homeland Security - Eisenhower was under pressure to sort of reorganize things. And the proposal that moved forward was to create what was then called the Advanced Research Projects Agency. It was to be actually the nation's first space agency prior to the foundation of NASA. All of the satellite and rocket programs, civil and military, were put in what was called ARPA in those early days with the main goal of getting the nation into space. Now, a secondary goal that was articulated by the secretary of defense was that this new agency would also develop the, quote, \"vast weapons systems of the future. \" And that was ARPA in its beginning days in 1958, a space agency and also looking ahead to these, you know, vast weapons systems. GROSS: So it lost the function of space agency 'cause NASA took that over, and it became more dedicated to defense? WEINBERGER: Well, two things happened. Eisenhower was very heavily influenced by his science advisers. And they lobbied heavily to have a civil, you know, a civilian agency for space. So Eisenhower, when he authorized the creation of DARPA - or ARPA at the time - he specifically said that when a civilian agency is created - which was to be NASA - that the civil rocket and satellite programs would move out of DARPA and over to this new agency. But it was expected at the time that DARPA would keep the military space programs. Well, within a year and a half, that didn't happen. There was a bureaucratic war in the Pentagon. And the military services - the Army, Navy and Air Force - got their programs back. So you suddenly had, you know, it's 1959, this agency isn't even two years old and it's left without its main mission and sort of adrift at sea. GROSS: So what did it do? WEINBERGER: What DARPA had at the time was a man who eventually rose to be deputy director. And his name was William Godel. He was actually not a scientist or a scientific manager. He was an intelligence operative who'd been put at DARPA in the early days to represent the interests of the spy community, of the intelligence community. And so he looked at this young agency that now didn't really have a mission. And he thought, well, maybe we can mold this agency around the strategic threats that I see. And he looked out at the world. And for him, the space race was mostly a psychological game. You know, it was public relations. The threat of nuclear Armageddon, no matter how big a threat, was not a likely scenario. He had had a lot of experience in Asia, particularly Southeast Asia. And he looked at countries like the Philippines and particularly the Vietnam. And he thought the most likely way the United States would confront the Soviet Union would be through the sort of proxy wars, where the United States would have - would back regimes fighting Communist insurgencies. And he thought we could take DARPA to Vietnam. GROSS: And he literally did. I mean, he set up a branch of DARPA in Southeast Asia. WEINBERGER: He literally did go to Vietnam. He pitched this to President Kennedy, who approved it. And it was to be the ARPA Combat Development and Test Center. And it was to be a center based in Vietnam that would help the South Vietnamese military with jungle warfare. And it would also help the U. S. military advisers who were starting to go to Vietnam work with the South Vietnamese. And his vision of it, you know, it was the original sort of counterinsurgency mission, not what we saw in the wars in Iraq and Afghanistan, but the idea that you don't want U. S. troops in these countries. You want to work with the militaries and the governments that we are backing and teach them how to deal with these insurgencies so that U. S. troops don't have to go there. And that was his vision when he took off for Vietnam in 1961, literally with a suitcase full of cash, went to the president of South Vietnam - President Diem - and pitched this idea. GROSS: So theoretically this could have been a success, keep American troops out of Vietnam while still having the outcome America wanted in Vietnam. But what happened actually is that DARPA creates, for instance, Agent Orange, the toxic defoliant that not only just, like, parched the Earth but also had, like, really toxic side effects not only for Vietnamese people but for American troops who were exposed to it and came back with mysterious symptoms that no one could diagnose and eventually were attributed to Agent Orange. What were some of the other outcomes in Vietnam that didn't go so well? WEINBERGER: There were a number of things that didn't go so well. So let's start with the example of Agent Orange and chemical defoliation. So this is truly and sadly a DARPA innovation, meaning DARPA under William Godel proposed this idea of doing experiments with chemical defoliation and with what were called the rainbow agents of which Agent Orange was one of them. Now, William Godel's vision - this goes back to the idea of whether it was, quote, \"a good thing\" - his idea was not that you would hit crops initially. That was one idea. He had the idea of using chemical defoliation in a very specific way that you would eliminate some areas of jungle cover that were being used by the insurgents and also that you would do targets of food supply of specific crops that the Viet Cong, the communist insurgents, were using as basically subsistence. But what quickly happened is that there's always a difference between sort of the technology ideas and the political strategy. Very quickly, President Diem, the president of South Vietnam, he wanted to use chemical defoliation much more widely. He didn't really care about whose food crops he was hitting. There is this very sort of poignant scene that I recreate in the book where Jack Ruina, the director of DARPA who is sort of a classic scientist, technologist. He was not interested in this counterinsurgency work. He meets with President Diem in Vietnam, and the president pulls out this map, you know, showing where they want to do chemical defoliation. And Jack Ruina, the DARPA director says, well, how do you know which crops are the Viet Cong's crops and which crops are just, you know, sort of innocent peasants? And the president said, oh, I know. And he didn't know. He just didn't care, meaning what he wanted to do was make sure that these villages, some of which were under Viet Cong control were dependent on the South Vietnamese government for food. So already the idea that Godel had had sort of been manipulated and expanded. Now, the question of whether the original idea that Godel had was good, certainly the idea of keeping U. S. troops out of Vietnam with retrospect was a very good idea, but at the end of the day, you were working with a flawed and quite corrupt government. So whether any combination of technologies and novelties could have made that government work is much more dubious. GROSS: If you're just joining us, my guest is Sharon Weinberger. She is the author of the new book \"The Imagineers Of War: The Untold Story Of DARPA, The Pentagon Agency That Changed The World. \" We'll talk more after a break. This is FRESH AIR. (SOUNDBITE OF MUSIC)GROSS: This is FRESH AIR and if you're just joining us my guest is Sharon Weinberger, author of the new book \"The Imagineers. \" It's about the Pentagon agency called DARPA or ARPA, which was created in 1958. It was initially dedicated to getting the U. S. in space and then to tech innovation in defense. Innovations credited to DARPA or based on DARPA research include the first communications satellites, stealth aircraft, drones, the driverless car, the robot vacuum cleaner and the internet. Weinberger is the national security editor of The Intercept and former editor in chief of Defense Technology International. OK, so let's continue in our look at DARPA. So during the Vietnam era in the 1970s, DARPA was doing research on parapsychology and mind control. What were some of the things it was trying to investigate? WEINBERGER: Well, what happened was there was a great deal of interest in parapsychology in the late 1960s, early 1970s particularly from the intelligence community. So there was a man named Sidney Gottlieb who was the head of the Office of Technical Service at the CIA. He is today most famous for the MK Ultra program. These were the LSD experiments that were conducted by the CIA for, quote, unquote, \"mind control\" including on unwitting human victims. But Gottleib also had an interest in parapsychologySo I believe it was in the early 1970s that he invites Steve Lukasik who was then a director of DARPA over to his offices, and he wants to talk to Steve about this exciting program that he's doing in parapsychology. And what was going on was the Soviets, it turned out, had been doing these experiments in parapsychology including one that is as - sort of just grotesque where there was alleged to be sort of a psychic link between mothers and their offspring - or in the case of what the Soviets were allegedly doing experimenting with bunny rabbits - rabbits and their offspring. And so the idea was if a bunny was killed in a separate room, that the mother rabbit, you know, in a different laboratory, you know, in the same building would somehow react, would know that her offspring had been hurt and killed and that this was done through a sort of mind link. And so the idea - this was being taken very seriously - the idea was that, perhaps, the Soviets thought - or the U. S. believed they thought - this could be used for submarine communication. You know, submarines, nuclear-armed submarines - any the submarines when they're deep under water are very hard to communicate with. So how do you let these submarines know that, you know, nuclear Armageddon is coming, you need to surface and launch your missiles? And the idea was somehow this psychic link between the mother rabbit and its offspring would work. You could keep - I don't know a mother rabbit on the submarine, kill the offspring and that would be a sign that the nuclear submarines should surface. You know, it's hard to talk about this without laughing, but this was being seriously considered. So. . . GROSS: And as part of the research, the Soviets were killing baby rabbits to see if the mother knew it. WEINBERGER: Indeed. GROSS: If the mother in another room knew it. WEINBERGER: Indeed. That is what was going on. So that was one - I mean, the Soviets were interested across the breadth of parapsychology research - or at least the CIA thought. So the CIA had their own program that they were sponsoring at the Stanford Research Institute out in California where two physicists were working with Uri Geller, perhaps best known as the Israeli magician who also claims, you know, powers in parapsychology. And. . . GROSS: Also known as the guy who could bend spoons. WEINBERGER: The spoon-bender. GROSS: Because he claimed to be able to bend a spoon, and that was part of his magic act. . . WEINBERGER: Exactly. GROSS: . . . Was bending the spoon mentally. WEINBERGER: So Gottlieb had spoken with the DARPA director, Steve Lukasik, about how wonderful this research was. It was going great. And wouldn't DARPA be interested in sponsoring it? Now, Steve Lukasik was - you know, he likes it. He thought he was a very creative guy. And he was dubious of the work, but he thought, you know, this is an area where OK, DARPA could be sort of the truth squad in it. That yes, if there really was something, you know, DARPA might fund it. But if it was all sort of, you know, BS then DARPA could also be sort of an honest broker in that. So he went back to the agency and called together some of the personnel and said, go look at this work. Go around the country. Speak to these people doing parapsychological work not just for the CIA but, you know, there was some work at universities. Bring me anything that works. So George Lawrence, who was a psychologist employed by DARPA, went out across the country. And he looked at the work out at SRI, the Stanford Research Institute. He went to psychic conferences in Scotland. He met witches. He met psychics and looked for, quote, \"anything that worked. \"GROSS: Did anything work? WEINBERGER: No. (LAUGHTER)WEINBERGER: You know, quite - I think the most famous of his visits because it was leaked to the press was he went - he brought a - Ray Hyman, who was an amateur magician and also a university professor, and Robert Van de Castle, a professor of sleep studies who believed in premonitions and sort of the truth of premonitions that come in through your dreams. He brought this team out to SRI to meet Uri Geller and to meet the two scientists at SRI who were doing the work. And they went through these series of tests, you know, where Uri would go into a room with another person and they would draw something, put it in an envelope. And then Uri, just by having the signal through his mind, would try to redraw what the person had drawn. He would try to move, you know, compass needles just with his mind, these series of experiments. And, you know, what Ray Hyman, this amateur magician, and George Lawrence saw were basically - they saw magician tricks. And they - what they were most appalled by was that, you know, these were physicists, scientists who were supposed to be evaluating the work. And, you know, where were the scientific controls? Where was the skepticism? They didn't see any of this. And so DARPA did not fund the work. They did report back to the CIA that they didn't see anything to it. And yet the work continued on in the intelligence community I think for another 10 years. GROSS: That said, DARPA ended up doing some really exciting research and continues to do exciting research in neuroscience and neurotransmissions, neural implants. Can you describe some of that work, some of the work that's actually been very successful in subsequent years? WEINBERGER: Yeah. So the irony of what happened with that program was that George Lawrence, the DARPA program manager who was responsible for, you know, meeting the witches and psychics, you know, he was brought in 'cause he kind of was part of this. You know, he was part of this new age counterculture, which even at DARPA was unusual at the time. You know, he kind of belonged to the zeitgeist. And he was excited by the idea of communicating directly with the human brain. But rather than doing it through magicians or bunny rabbits, he said, suppose we can do it through computers. He had been a close associate of J. C. R. Licklider, who had been the DARPA program manager who had started computing networking, which led to the ARPANET. And so if you remember, the original days of computer networking was about how do we link man with machine? How do people operate directly with computers so that the computers can help their decision cycle the way we use Google as sort of our collective and individual memory? And so what George said looking at this parapsychology work is, well, suppose we could communicate directly with the human brain using sensors instead of some unknown mechanism. So he laid the foundation for the field of what's now known often as brain-computer interface, where you have sensors that read neural signals to either control computers, to control machines, what is now being developed into neuroprosthetics, prosthetics that can be, you know, handled, maneuvered with just the human brain rather than through muscles. It is also leading to - I mean, it's still very early days, but the idea of quadriplegics, of, quote, unquote, \"locked-in\" people who can operate computers just by thinking about moving the cursor or thinking about letters. That work is still early days, but it is developing. And that came out of, you know, sort of DARPA's open-minded interest in areas like parapsychology. I mean, let's think about it broadly, but let's bring real science into it and rigor. GROSS: My guest is Sharon Weinberger. Her new book, \"The Imagineers Of War,\" is about DARPA, the Pentagon agency that designs futuristic defense technologies. After a break, we'll talk about a spectacular but misguided project, and we'll hear about some of the new technologies DARPA is working on now. I'm Terry Gross and this is FRESH AIR. (SOUNDBITE OF MUSIC)GROSS: This is FRESH AIR. I'm Terry Gross back with Sharon Weinberger, author of the new book \"The Imagineers Of War. \" It's about DARPA, the Defense Advanced Projects Research Agency (ph), the Pentagon agency that designs futuristic defense technology. Its innovations include the predecessor of the internet, stealth aircraft, drones, the M-16 and the driverless car. It also came up with ideas that were too far-fetched or too dangerous to reach completion. So you were talking about how some DARPA projects spiraled out of control. I think under that category we can put the Reagan-era project commonly known as Star Wars, a space-based missile shield to protect against Soviet nuclear attacks. Would you describe what the project was? WEINBERGER: Well, the project, as it was under the Reagan administration, was the idea of creating literally a shield, some sort of shield that would take out any possible nuclear weapons coming from the Soviet Union or elsewhere. So what this actually dates back to is, again, let's take us back to the very early days of DARPA. They did lose their mission in space. But what they kept, at least in the early days, was a secondary mission in missile defense. And there was always a tension at DARPA is is DARPA a national security agency that does science or a science agency that does national security? Meaning which should be the focus? So one of the earliest projects that came out of DARPA was a project called Seesaw, which was a particle beam that was going to blast, you know, nuclear weapons out of space. And this came from a Greek scientist by the name of Nicholas Christofilos, who was sort of a favorite of DARPA. And he had proposed this particle beam that DARPA sponsored in the early days. And every DARPA director who sponsored it said, well, we knew it wasn't ever going to really work, but it was marvelous science. Well, now we're at the early 1980s with Ronald Reagan. And Reagan says, we're going to try to make it work. And DARPA is suddenly, you know, like, what? You're going to build this thing that was just sort of an idea? They were shocked. GROSS: Was President Reagan a little naive about the science that it would take to create the Star Wars defense shield that he was promoting and made it seem like this is really within reach? WEINBERGER: I don't think he cared. So naive is one word that you could use but also that it wasn't - he wasn't about the technological reality. He really kind of came from this, you know, Hollywood vision, sort of, you know, say you can build it and maybe you can build it. One of the most shocking things about the Star Wars history was that he hadn't even, you know, before making his announcement, he hadn't even consulted or listened to the top people in the Pentagon. I remember from some of the interviews I did and received for the DARPA book, you know, there was these descriptions of Caspar Weinberger, then the defense secretary, just sitting there slack-jawed hearing Reagan announce they were going to build this system because, you know, Weinberger himself had said, you know, what you want to do is just not feasible. The same thing with the DARPA director, the same thing with the Pentagon's chief technologist. They were just in shock. Reagan had not consulted with him, had not listened to them when they were saying this is not feasible. I think Reagan really had this vision, not so much that you could make it a technological reality but he could make people believe in it. And for Reagan, that was enough. GROSS: So how much money did the U. S. spend on the Star Wars initiative? WEINBERGER: Oh, my, well, don't forget, it never really ended even to this day. Now, this sort of impressive shield that Reagan talked about, I mean, I think there are numbers in the hundreds of billions that have been invested in Star Wars and all of its sort of component programs. I can say this much. There has been an incredible amount of money that has gone into missile defense based on a belief system. Even today when you look at the missile defense programs that are being built and used operational, the ones that are supposed to stop intercontinental ballistic missiles, they are doing such a small, small part of either what the particle beam weapon in 1958 was proposing or what Reagan was proposing in the 1980s. And yet we're still spending money on it. GROSS: So DARPA was initially very focused on the Cold War and then also on the war in Vietnam. So the war in Vietnam ends, the Cold War ends and DARPA has had to figure out its place in the U. S. in the era of terrorism. So what has DARPA been working on in the era that we're in now? WEINBERGER: Well, so there's two transitions that took place there. One, of course, as you mentioned, was the end of the Vietnam War, which was, you know, it had caused untold problems for the Pentagon, it'd become a lightning rod for DARPA. Congress was becoming very critical of DARPA. So DARPA took all of its technologies from the Vietnam era and renamed the office the Tactical Technology Office, i. e. an office that has nothing to do with Vietnam. And they really began to focus, as you get into the 1980s and the height of the Cold War, on weapons - precision weapons, you know, drones, stealth aircraft. So then we get to the end of the Cold War. And here is DARPA for the past decade been building weapons to fight the Soviet Union. The Soviet Union goes away, and it's sort of left just stranded and not knowing what to do. It is often called an agency that is supposed to stop technological surprise. Technological surprise meaning mostly from the Soviet Union. So what is your mission in the 1990s when that is no longer an issue? And DARPA really struggled to find its place. At one point, they renamed it back to ARPA, looking at it, well, maybe it can be sort of an engine of civil innovation. And really the 1990s were not a great period for DARPA. They did not have a lot of successful programs. Things were not going well for the agency. Then 9/11 happens, and things change again. GROSS: How did they change? WEINBERGER: Well, so the director who came in right before 9/11, Tony Tether, really had a vision. He had been at DARPA prior to that. And so he basically said, look, you know, 9/11, terrorism is clearly going to be one of the number one if not the number-one threat facing the United States in the coming years. We need to address this problem. And when he looked at what happened on 9/11, he said, this is a problem of data, that we probably had all of the information we needed to stop this attack, but we didn't have a good way of integrating it, of centralizing it, of analyzing it. And he said, this is the area we need to get into, data mining, data analysis, pattern recognition. And that's what he did. He - things went downhill from there. GROSS: My guest is Sharon Weinberger. Her new book about DARPA is called \"The Imagineers Of War. \" We'll talk more after a break. This is FRESH AIR. (SOUNDBITE OF MUSIC)GROSS: Let's get back to my interview with Sharon Weinberger, author of the new book \"The Imagineers Of War\" about the history of DARPA, the Pentagon agency that designs futuristic weapons and defense technology. The agency was created in 1958 during the Cold War, when the focus was defending against a Soviet nuclear attack. During the Vietnam War, DARPA also focused on jungle warfare. After 9/11, the agency focused on combating terrorism and tried to find ways to mine and analyze public records with the goal of discovering terrorists before they attacked. DARPA organizes the TIA - Total Information Awareness - program designed to mine data, including from American civilians and kind of, you know, coordinate and read the data. And there's a huge uproar over that. WEINBERGER: Well, exactly. One of the first things that happened was that Tony Tether, the DARPA director, hired John Poindexter. By way to refresh people's memories, this was the national security adviser to Ronald Reagan during the Iran-Contra scandal. He had - Poindexter had been convicted of lying to Congress, although that conviction was tossed out. And what people sometimes forget is that Poindexter had been trained as a physicist, really had a reputation for being quite brilliant. He had had a longtime interest in computers, had helped modernize the White House back in the day, introducing email, introducing networking. And so after he had sort of faded back into the Washingtechnocracy (ph) after the Iran-Contra scandal, he had been working in data mining. This was the very area he was working in, how do you predict terrorist attacks? And he'd been working under a DARPA contract. Well, after 9/11, Tony Tether thought no one's going to care. Like, people want - people realize how important this is. This is like a Sputnik moment, that you have to do whatever it takes to win the war. And he didn't think it would be a problem to hire John Poindexter in at DARPA to run this program called Total Information Awareness. GROSS: It did not work out. WEINBERGER: It did not work out. You know, it sort of for a few months seemed to go along fine. You know, Poindexter being hired at DARPA was a bit of a blip. And really the focus was on 9/11. You were starting a war in Afghanistan. You know, that the nation was turning to sort of, what was this threat? But there were already privacy advocates who were looking at what DARPA was proposing to do and saying this is just crazy. Poindexter had originally proposed to DARPA that there would be a two-track program. One would be a black program, meaning a heavily classified program in data analysis. And then there would be a white program, an unclassified program called Total Information Awareness that would involve academics looking at data mining. When I interviewed Poindexter, what he told me was that the black program never actually took place is what he said, that it was all a white world unclassified program that Poindexter and others began to speak very publicly about, saying, you know, we're going to take data from everything - it might be credit card records, it might be pharmacy records, travel records, car rental - and combine that with government information - might be classified information - mine it all and try to predict terrorist attacks. Now, what Poindexter's very careful to say was that they weren't actually - it was an experiment. It was research. They were not working with real world data. Instead, they created this simulation initially called Vanilla World, which was made-up data where, you know, it was, you know, millions of households in the United States and a few terrorists. And they brought in experts to sort of what's called red team it. You know, there will be some who pretend to be terrorists. And they would see if you could recognize the terrorists ahead of time. GROSS: So the program was ended. The public part of the program was ended, but it ended up going underground as a black program, as a program that's secret from the public. WEINBERGER: Well, exactly. So after The New York Times and others wrote about it, it created this huge media firestorm of, you know, people called it an Orwellian program that was going to, you know, look at all of your, you know, personal data. The very fact that it was trying to find terrorists in the United States using what people consider very sensitive data was extremely controversial. So Congress got involved and started, you know, calling up people to talk about what was going on and eventually shut down the program. Now, what Poindexter argues to me now is that in essence the nation got the worst of both worlds, that rather than an unclassified program that was also sponsoring what he considered to be privacy protection. They were looking at tools that could mask data. Instead, the privacy work was shut down. And the bulk of the program was transferred over to the National Security Agency. It, quote, unquote, \"went black. \" In his argument, you know, the exact opposite of what he wanted, which is basically highly classified work involving data mining. GROSS: DARPA has been working on issues related to the wars in Iraq and Afghanistan, trying to figure out ways to deal with traumatic brain injury, dealing with people who come home and having lost one or more limbs. So what's some of the progress they've made in that? I know they don't like to be identified as a device laboratory. On the other hand, they've created devices and created some really practical things that are really helping people. WEINBERGER: They are. I mean, this work has actually been ongoing at DARPA for a number of years. In a sense, this dates back to the 1970s work on brain computer interface, which went on and was really quite successful in laying the foundations of a scientific field. Well, now we get to the early 2000s. And there was again a revival of this brain computer interface work under Tony Tether at DARPA. Only it was really phrased as, you know, we're going to create weapons. You know, we're going to create drones and robots that will be controlled directly by the human mind. It was a very, very sort of science fiction vision. Well, after sort of the scandal around Total Information Awareness, there was a lot more scrutiny of DARPA programs. So suddenly this talk of yeah, we're going to be controlling drones with the human mind, it sort of was, you know, that went away. And so when DARPA over the past three or four years got back involved in neuroscience, the language was couched very differently. And in fact, the motivations were quite different because what we were seeing at that point were big problems with traumatic brain injury, big problems with post-traumatic stress disorder. And so a lot of the DARPA work is linked to that earlier work. It's talking about brain chips and neuroengineering and brain implants. Only instead of controlling drones, they're talking about how to recover memories, how to treat depression, how to treat traumatic brain injury. GROSS: It might be too soon to answer this question, but I'm wondering what DARPA is doing in this era of the Trump administration and if the Trump administration has had any direct communication with DARPA yet about its goals. And specifically I'm wondering about border wall technology. One of President Trump's big issues is building a wall between Mexico and the U. S. We've yet to see what, if anything, will happen with that. But has DARPA come up with things that are likely to be used if that wall is built? WEINBERGER: Well, in fact, a lot of DARPA's Vietnam-era technology is used today along the U. S. -Mexican border. The two biggest things are sensors. The sensors that are used along the U. S. -Mexican border date back directly to DARPA's work, first from its nuclear test detection technology, but then to the electronic barrier it helped with in Vietnam. There are also tethered aerostats, basically blimps that are tethered to the ground along the U. S. -Mexican border which had come - which again comes directly out of DARPA work in Vietnam. You know, DARPA has a lot of experience in this area. It forwarded the first proposals in 1964 for creating a barrier to basically cut off the supply of weapons and people coming from North Vietnam into South Vietnam. This eventually developed into what was called the McNamara Line, which was again supposed to cut off people and weapons and failed rather spectacularly. So there are a lot of lessons you can learn about, you know, what it takes to build a barrier and what goes wrong. It is very, very hard, expensive, complex and sometimes rather ruthless if you want to cut off people, supplies that are very determined to cross a border. And these are lessons one hopes are taken into account along the U. S. -Mexican border. But what's interesting about the current administration is they're not even talking about technology. The most that the wall has ever been expressed in by Trump or people around him is literally in bricks and mortar. A wall on its own doesn't do anything if it's not monitored. So it will have to involve some sort of sensor, some sort of surveillance system. But it's really too soon. We don't know. We've only heard bricks and mortars. GROSS: If you're just joining us, my guest is Sharon Weinberger, author of the new book \"The Imagineers Of War: The Untold Story of DARPA, The Pentagon Agency That Changed The World. \" We'll be back after a short break. This is FRESH AIR. (SOUNDBITE OF MUSIC)GROSS: This is FRESH AIR. And if you're just joining us, my guest is Sharon Weinberger, author of the new book \"The Imagineers. \" It's about the Pentagon agency called ARPA, which then became DARPA, which was created in 1958. It was initially dedicated to getting the U. S. in space and then turned to tech innovation in the defense field. Innovations credited to DARPA or based on DARPA research include the first communication satellite, stealth aircraft, drones, the driverless car, the robot vacuum cleaner and the internet. So Siri, the famous, like, Apple voice recognition technology who you can ask questions to and sometimes she can answer them (laughter) - so you say that she is a spinoff of a DARPA project. So when you look at DARPA you have these kind of, like, crazy schemes, crazy high-tech schemes that billions of dollars are spent on that don't pan out. But you also have things like, you know, drones for warfare, robotic technology that we're using in daily life, whether it's a vacuum cleaner or, you know, like, voice recognition technology like Siri. So you have this mix of, like, you know, grand schemes that work and schemes that end up in things that not only work for defense but that you can use, you know, in the palm of your hand or in your apartment, in your car because the driverless car is another example of something that came out of DARPA research. So when you look at the big picture, what conclusion do you draw about DARPA and its way of operating and the amount of money that's been spent on its research? WEINBERGER: I have two thoughts on that. The first is that what we consider a success and failure really has to be broken down into two things. So the name \"The Imagineers Of War\" is really based on how I saw DARPA in its early days where it was trying to think about, you know, how is the U. S. going to be fighting wars now and in the future, and how do we come up with, you know, imagineer solutions to those problems? And so if we talk about drones being a success, let's actually think about that for a second. Drones are certainly a technological success not only, you know, for what it does in the military and the civil field. Has it helped us prosecute our wars more successfully? You know, have 16 years of drones and armed drones in Iraq, Afghanistan, Yemen, other countries helped win these wars? I think that's a much more controversial statement to make to say that was a success. So it goes back to the central question I ask in my book of what is it that you want DARPA to do? If you want DARPA to solve national-level problems, to sort of solve warfare or make us more safe, then it changes the picture a lot. If you want DARPA to be an agency that produces cute technological novelties like Siri or, you know, driverless cars, to some extent - it's a great thing, but that doesn't really change, you know, the national security for the country - then it can do that. Do you want DARPA to be a science fiction agency that does nifty gadgets or do you want it to solve national-level problems? That is always the tension of DARPA and where it's supposed to go. And in that its legacy is mixed. What challenges are worthy of a DARPA-type agency? It is arguably the world's most successful research agency. So where do you want to sort of channel those talents? What do you want it to achieve? I certainly hope that it's more than just producing gadgets for the military, that the White House or the Pentagon gives it challenges to solve. I think neuroscience and the challenge of helping people with traumatic brain injury and post-traumatic stress disorder, those are very noble missions and I think DARPA can contribute a lot. But if you look at the larger problems that we're facing after 9/11 and 16 years of war, I don't think that really anyone is asking, what can DARPA contribute? What can it do to sort of stop the threats that we're facing today? And that's the unfortunate part of DARPA, this tremendously successful research agency which isn't being used the way it was in its early days to address warfare. GROSS: Sharon Weinberger, thank you so much for talking with us. WEINBERGER: Thank you for having me. GROSS: Sharon Weinberger's new book about DARPA is called \"The Imagineers Of War. \" Tomorrow on FRESH AIR, our guest will be New York Times national security correspondent David Sanger, who has been covering North Korea's nuclear and missile tests and the Trump administration response. North Korea claims that it's preparing to test an intercontinental ballistic missile that could reach the U. S. I hope you'll join us. (SOUNDBITE OF MUSIC)GROSS: And now for something I've put off doing because I haven't wanted to face the fact that it has to be done. I have to say goodbye to our producer John Sheehan, who has accepted another position. John has edited zillions of interviews, produced years of our opening billboard - that's the minute-long introduction to the show - and has produced our Weekend Edition. He's an audio wizard. And in the past year, he's written, produced and directed a wonderful podcast that's a comic adventure series for kids called The Radio Adventures Of Eleanor Amplified. (SOUNDBITE OF PODCAST, \"THE RADIO ADVENTURES OF ELEANOR AMPLIFIED\")UNIDENTIFIED CHILD: From WHYY in Philadelphia. UNIDENTIFIED MAN: In a world of no-goodnicks (ph), hucksters, charlatans and flim-flammers (ph), she's checking facts and taking names. It's The Radio Adventures of Eleanor Amplified. GROSS: Eleanor Amplified is about an investigative reporter who's trying to take down Angela Brant, the nefarious head of a giant tech company called Megablurg that's trying to take over the world. In addition to the great professional actors John has used, he's drawn on the extraordinary acting talents of the FRESH AIR family. Listen as the whole staff collectively gasps. (SOUNDBITE OF PODCAST, \"THE RADIO ADVENTURES OF ELEANOR AMPLIFIED\")UNIDENTIFIED ACTRESS #1: (As character) I'm almost ready to rest my case, congressman. I just have one final witness. I call Eleanor Amplified's Megablurg 5,000 limited edition SL smartphone. UNIDENTIFIED GROUP: (Gasping). GROSS: We did good, right? John channeled the true acting talents of Amelia (ph) and Lena (ph), our producer Ann Marie Baldonado's two daughters. Here they are quarreling in a scene from Eleanor. (SOUNDBITE OF PODCAST, \"THE RADIO ADVENTURES OF ELEANOR AMPLIFIED\")UNIDENTIFIED ACTRESS #2: (As Hannah) Hey The Rook, can we play with Norad (ph) again? UNIDENTIFIED ACTRESS #3: (As The Rook) Hannah, get out. Mom, Hannah's in my room again. UNIDENTIFIED ACTRESS #2: (As Hannah) Mom, The Rook is yelling at me. GROSS: Nice work, girls. So the good news for us is that John's new job is requiring him to move only as far as one flight up in the WHYY building where we work. He's WHYY's new manager of on-demand audio and podcasts. And part of his job is continuing to create new episodes of \"Eleanor. \" Even so, we're heartbroken he's no longer part of the FRESH AIR crew. I want to close today's show with the best FRESH AIR ending ever, which was of course conceived and produced by John. It's from last summer, when he came on the show as a guest to talk about the premiere of \"Eleanor. \" And he came up with this way to end our show. (SOUNDBITE OF ARCHIVED BROADCAST)GROSS: (As herself) FRESH AIR's executive producer is. . . (SOUNDBITE OF COMPUTER CRASHING)GROSS: I don't know. Danny, are we still on the air? UNIDENTIFIED ACTRESS #4: (As Angela Brant) FRESH AIR's executive producer is me, Megablurg CEO Angela Brant. GROSS: (As herself) What is this? What's going on here? UNIDENTIFIED ACTRESS #4: (As Angela Brant) Why, we're stealing your show, Terry Gross. (LAUGHTER)SCOTT JOHNSTON: (As Professor Ignomi) Now your listeners will hear only Megablurg-approved programming. GROSS: (As herself) No, you can't. You won't get away with this. UNIDENTIFIED ACTRESS #4: (As Angela Brant) Professor Ignomi, show Terry Gross your hypnoray. JOHNSTON: (As Professor Ignomi, laughing) With pleasure, Ms. Brant. (SOUNDBITE OF BLASTING)GROSS: (As herself) FRESH AIR listeners, would you like to hear the latest deals on internet shopping or maybe some celebrity gossip? UNIDENTIFIED ACTRESS #4: (As Angela Brant, laughing) Got you, Terry Gross. That'll show you for denying my interview request. (LAUGHTER)CHRISTA D\u2019AGOSTINO: (As Eleanor Amplified) Not so fast, evildoers. SCOTT JOHNSTON AND UNIDENTIFIED ACTRESS #4: (As characters, gasping) Eleanor Amplified. D\u2019AGOSTINO: (As Eleanor Amplified) I won't let you turn FRESH AIR into a Megablurg mouthpiece. It's a good thing I brought this anti-hypnoray. (SOUNDBITE OF BLASTING)JOHNSTON: (As Professor Ignomi) No. UNIDENTIFIED ACTRESS #4: (As Angela Brant) Curse you, Eleanor Amplified. You've spoiled my plans again. GROSS: (As herself) Eleanor, where am I? I don't think I can finish the show. I don't think I can even remember the names of our producers. D\u2019AGOSTINO: (As Eleanor Amplified) Don't worry, Terry Gross, I've got this. FRESH AIR'S executive producer is Danny Miller. Our engineer is Audrey Bentham. The interviews and reviews are produced and edited by Amy Salit, Phyllis Myers, Ann Marie Baldonado, Sam Briger, Lauren Krenzel, John Sheehan, Heidi Saman, Therese Madden and Thea Chaloner. Molly Seavy-Nesper is associate producer of online media. Roberta Shorrock directs the show. GROSS: (As herself) Thanks, Eleanor. D\u2019AGOSTINO: (As Eleanor Amplified) Sure thing, Terry Gross. (SOUNDBITE OF MUSIC)GROSS: I'm back to add Mooj Zadie's name to the credits. He wasn't yet here when we recorded that. And to thank you, John, for sharing nine years of your life with FRESH AIR. See you in the hall. I'm Terry Gross. TERRY GROSS, HOST:  This is FRESH AIR. I'm Terry Gross. Thinking big can lead to breakthroughs or spectacular failures. And the Pentagon agency DARPA has had its share of both. DARPA is the acronym for the Defense Advanced Research Projects Agency. It started off as ARPA before the D was added for defense. Its mission is to create innovative defense technologies. Its projects have ranged from space-based missile shields to cyborg insects. Its innovations have had practical applications in the civilian world, ranging from the Internet to robot vacuum cleaners. My guest, Sharon Weinberger, is the author of a new book about DARPA called \"The Imagineers Of War. \" Her research includes recently declassified documents, as well as interviews she conducted with people who have worked on DARPA projects. She's the national security editor at The Intercept, a global fellow at the Woodrow Wilson International Center for Scholars and former editor-in-chief of Defense Technology International. Welcome back to FRESH AIR. What are some of the most impressive successes of DARPA? SHARON WEINBERGER: Well, let's start with the first success that has really cemented DARPA's reputation today. And that would be ARPANET, which was the precursor and laid the foundation for the modern Internet. That is undoubtedly the agency's biggest success. And because of the name itself, ARPANET is sort of synonymous with DARPA today. But there are many other innovations that they get less credit for but in fact go back directly to the agency's work. The driverless cars, autonomous self-driving cars that are now coming to fruition date back to a series of robotic car races that DARPA sponsored beginning in 2004, 2005. Some of DARPA's other biggest, quote, unquote, \"successes\" are stealth aircraft. They sponsored the development of the first stealth prototype aircraft in the 1970s. Precision weapons is another DARPA innovation. Drones, particularly the Predator drone that we now associate with the wars in Iraq, Afghanistan and elsewhere date back to DARPA sponsorship. GROSS: And there's also some pretty big failures that DARPA was responsible for. Tell us about a couple of those. WEINBERGER: There are a number of failures. I think that the ones that are sort of best known are the National Aero-Space Plane, which was a plan in the 1980s to have a single-stage-to-orbit space plane. Basically a plane that would take off from a runway, rather than being launched by a rocket, go into space where it could be anything - it could be a spy plane, it could be a space bomber - re-enter the atmosphere and then land again like an airplane. You know, at one point, you know, the cost of this program had grown to the billions of dollars and was eventually canceled. It had grown very complex, very expensive. Other notable \"failures\" - and I'll put this in quotes - are, for example, what was called the Strategic Computing Initiative. This was an effort - a billion dollar effort in the 1980s to create artificial intelligence. There was a lot of publicity around the program, a little bit of controversy around the program as well. And it ended in failure such that, well, for starters, they never created artificial intelligence. But most of the programs and companies that were sponsored under the program did not succeed. However, as with a lot of failures in DARPA, as you see now a lot of excitement about artificial intelligence, there's a strong argument to be made that DARPA laid the foundations for that. So was that program a failure? Maybe in a sense it's too early to say. GROSS: So it was created in 1958. What was the point when it was created - of DARPA? WEINBERGER: So let's take us back to that moment in time. In the fall of 1957, the Soviet Union had launched Sputnik, the first artificial satellite. And, you know, the mythology that has developed around that was it, you know, it sparked this immediate national panic with, you know, Americans looking up at the sky trying to see the Soviet satellite. And the idea was not only that the Soviets were ahead in the space race, but the ability to launch a satellite was also linked to the ability to launch intercontinental ballistic missiles, i. e. that they could launch a nuclear weapon that could reach the continental United States. So the reality was actually a bit different, that when Sputnik was launched, it was a little bit esoteric. It was in the back pages of newspapers. But it became a lightning rod in Washington, a way for critics of the Eisenhower administration to really attack the president. And so it became this political panic within a number of weeks. And so just as after 9/11 there was a push to sort of reorganize government to have the government respond - after 9/11 it was the creation of Department of Homeland Security - Eisenhower was under pressure to sort of reorganize things. And the proposal that moved forward was to create what was then called the Advanced Research Projects Agency. It was to be actually the nation's first space agency prior to the foundation of NASA. All of the satellite and rocket programs, civil and military, were put in what was called ARPA in those early days with the main goal of getting the nation into space. Now, a secondary goal that was articulated by the secretary of defense was that this new agency would also develop the, quote, \"vast weapons systems of the future. \" And that was ARPA in its beginning days in 1958, a space agency and also looking ahead to these, you know, vast weapons systems. GROSS: So it lost the function of space agency 'cause NASA took that over, and it became more dedicated to defense? WEINBERGER: Well, two things happened. Eisenhower was very heavily influenced by his science advisers. And they lobbied heavily to have a civil, you know, a civilian agency for space. So Eisenhower, when he authorized the creation of DARPA - or ARPA at the time - he specifically said that when a civilian agency is created - which was to be NASA - that the civil rocket and satellite programs would move out of DARPA and over to this new agency. But it was expected at the time that DARPA would keep the military space programs. Well, within a year and a half, that didn't happen. There was a bureaucratic war in the Pentagon. And the military services - the Army, Navy and Air Force - got their programs back. So you suddenly had, you know, it's 1959, this agency isn't even two years old and it's left without its main mission and sort of adrift at sea. GROSS: So what did it do? WEINBERGER: What DARPA had at the time was a man who eventually rose to be deputy director. And his name was William Godel. He was actually not a scientist or a scientific manager. He was an intelligence operative who'd been put at DARPA in the early days to represent the interests of the spy community, of the intelligence community. And so he looked at this young agency that now didn't really have a mission. And he thought, well, maybe we can mold this agency around the strategic threats that I see. And he looked out at the world. And for him, the space race was mostly a psychological game. You know, it was public relations. The threat of nuclear Armageddon, no matter how big a threat, was not a likely scenario. He had had a lot of experience in Asia, particularly Southeast Asia. And he looked at countries like the Philippines and particularly the Vietnam. And he thought the most likely way the United States would confront the Soviet Union would be through the sort of proxy wars, where the United States would have - would back regimes fighting Communist insurgencies. And he thought we could take DARPA to Vietnam. GROSS: And he literally did. I mean, he set up a branch of DARPA in Southeast Asia. WEINBERGER: He literally did go to Vietnam. He pitched this to President Kennedy, who approved it. And it was to be the ARPA Combat Development and Test Center. And it was to be a center based in Vietnam that would help the South Vietnamese military with jungle warfare. And it would also help the U. S. military advisers who were starting to go to Vietnam work with the South Vietnamese. And his vision of it, you know, it was the original sort of counterinsurgency mission, not what we saw in the wars in Iraq and Afghanistan, but the idea that you don't want U. S. troops in these countries. You want to work with the militaries and the governments that we are backing and teach them how to deal with these insurgencies so that U. S. troops don't have to go there. And that was his vision when he took off for Vietnam in 1961, literally with a suitcase full of cash, went to the president of South Vietnam - President Diem - and pitched this idea. GROSS: So theoretically this could have been a success, keep American troops out of Vietnam while still having the outcome America wanted in Vietnam. But what happened actually is that DARPA creates, for instance, Agent Orange, the toxic defoliant that not only just, like, parched the Earth but also had, like, really toxic side effects not only for Vietnamese people but for American troops who were exposed to it and came back with mysterious symptoms that no one could diagnose and eventually were attributed to Agent Orange. What were some of the other outcomes in Vietnam that didn't go so well? WEINBERGER: There were a number of things that didn't go so well. So let's start with the example of Agent Orange and chemical defoliation. So this is truly and sadly a DARPA innovation, meaning DARPA under William Godel proposed this idea of doing experiments with chemical defoliation and with what were called the rainbow agents of which Agent Orange was one of them. Now, William Godel's vision - this goes back to the idea of whether it was, quote, \"a good thing\" - his idea was not that you would hit crops initially. That was one idea. He had the idea of using chemical defoliation in a very specific way that you would eliminate some areas of jungle cover that were being used by the insurgents and also that you would do targets of food supply of specific crops that the Viet Cong, the communist insurgents, were using as basically subsistence. But what quickly happened is that there's always a difference between sort of the technology ideas and the political strategy. Very quickly, President Diem, the president of South Vietnam, he wanted to use chemical defoliation much more widely. He didn't really care about whose food crops he was hitting. There is this very sort of poignant scene that I recreate in the book where Jack Ruina, the director of DARPA who is sort of a classic scientist, technologist. He was not interested in this counterinsurgency work. He meets with President Diem in Vietnam, and the president pulls out this map, you know, showing where they want to do chemical defoliation. And Jack Ruina, the DARPA director says, well, how do you know which crops are the Viet Cong's crops and which crops are just, you know, sort of innocent peasants? And the president said, oh, I know. And he didn't know. He just didn't care, meaning what he wanted to do was make sure that these villages, some of which were under Viet Cong control were dependent on the South Vietnamese government for food. So already the idea that Godel had had sort of been manipulated and expanded. Now, the question of whether the original idea that Godel had was good, certainly the idea of keeping U. S. troops out of Vietnam with retrospect was a very good idea, but at the end of the day, you were working with a flawed and quite corrupt government. So whether any combination of technologies and novelties could have made that government work is much more dubious. GROSS: If you're just joining us, my guest is Sharon Weinberger. She is the author of the new book \"The Imagineers Of War: The Untold Story Of DARPA, The Pentagon Agency That Changed The World. \" We'll talk more after a break. This is FRESH AIR. (SOUNDBITE OF MUSIC) GROSS: This is FRESH AIR and if you're just joining us my guest is Sharon Weinberger, author of the new book \"The Imagineers. \" It's about the Pentagon agency called DARPA or ARPA, which was created in 1958. It was initially dedicated to getting the U. S. in space and then to tech innovation in defense. Innovations credited to DARPA or based on DARPA research include the first communications satellites, stealth aircraft, drones, the driverless car, the robot vacuum cleaner and the internet. Weinberger is the national security editor of The Intercept and former editor in chief of Defense Technology International. OK, so let's continue in our look at DARPA. So during the Vietnam era in the 1970s, DARPA was doing research on parapsychology and mind control. What were some of the things it was trying to investigate? WEINBERGER: Well, what happened was there was a great deal of interest in parapsychology in the late 1960s, early 1970s particularly from the intelligence community. So there was a man named Sidney Gottlieb who was the head of the Office of Technical Service at the CIA. He is today most famous for the MK Ultra program. These were the LSD experiments that were conducted by the CIA for, quote, unquote, \"mind control\" including on unwitting human victims. But Gottleib also had an interest in parapsychology So I believe it was in the early 1970s that he invites Steve Lukasik who was then a director of DARPA over to his offices, and he wants to talk to Steve about this exciting program that he's doing in parapsychology. And what was going on was the Soviets, it turned out, had been doing these experiments in parapsychology including one that is as - sort of just grotesque where there was alleged to be sort of a psychic link between mothers and their offspring - or in the case of what the Soviets were allegedly doing experimenting with bunny rabbits - rabbits and their offspring. And so the idea was if a bunny was killed in a separate room, that the mother rabbit, you know, in a different laboratory, you know, in the same building would somehow react, would know that her offspring had been hurt and killed and that this was done through a sort of mind link. And so the idea - this was being taken very seriously - the idea was that, perhaps, the Soviets thought - or the U. S. believed they thought - this could be used for submarine communication. You know, submarines, nuclear-armed submarines - any the submarines when they're deep under water are very hard to communicate with. So how do you let these submarines know that, you know, nuclear Armageddon is coming, you need to surface and launch your missiles? And the idea was somehow this psychic link between the mother rabbit and its offspring would work. You could keep - I don't know a mother rabbit on the submarine, kill the offspring and that would be a sign that the nuclear submarines should surface. You know, it's hard to talk about this without laughing, but this was being seriously considered. So. . . GROSS: And as part of the research, the Soviets were killing baby rabbits to see if the mother knew it. WEINBERGER: Indeed. GROSS: If the mother in another room knew it. WEINBERGER: Indeed. That is what was going on. So that was one - I mean, the Soviets were interested across the breadth of parapsychology research - or at least the CIA thought. So the CIA had their own program that they were sponsoring at the Stanford Research Institute out in California where two physicists were working with Uri Geller, perhaps best known as the Israeli magician who also claims, you know, powers in parapsychology. And. . . GROSS: Also known as the guy who could bend spoons. WEINBERGER: The spoon-bender. GROSS: Because he claimed to be able to bend a spoon, and that was part of his magic act. . . WEINBERGER: Exactly. GROSS: . . . Was bending the spoon mentally. WEINBERGER: So Gottlieb had spoken with the DARPA director, Steve Lukasik, about how wonderful this research was. It was going great. And wouldn't DARPA be interested in sponsoring it? Now, Steve Lukasik was - you know, he likes it. He thought he was a very creative guy. And he was dubious of the work, but he thought, you know, this is an area where OK, DARPA could be sort of the truth squad in it. That yes, if there really was something, you know, DARPA might fund it. But if it was all sort of, you know, BS then DARPA could also be sort of an honest broker in that. So he went back to the agency and called together some of the personnel and said, go look at this work. Go around the country. Speak to these people doing parapsychological work not just for the CIA but, you know, there was some work at universities. Bring me anything that works. So George Lawrence, who was a psychologist employed by DARPA, went out across the country. And he looked at the work out at SRI, the Stanford Research Institute. He went to psychic conferences in Scotland. He met witches. He met psychics and looked for, quote, \"anything that worked. \" GROSS: Did anything work? WEINBERGER: No. (LAUGHTER) WEINBERGER: You know, quite - I think the most famous of his visits because it was leaked to the press was he went - he brought a - Ray Hyman, who was an amateur magician and also a university professor, and Robert Van de Castle, a professor of sleep studies who believed in premonitions and sort of the truth of premonitions that come in through your dreams. He brought this team out to SRI to meet Uri Geller and to meet the two scientists at SRI who were doing the work. And they went through these series of tests, you know, where Uri would go into a room with another person and they would draw something, put it in an envelope. And then Uri, just by having the signal through his mind, would try to redraw what the person had drawn. He would try to move, you know, compass needles just with his mind, these series of experiments. And, you know, what Ray Hyman, this amateur magician, and George Lawrence saw were basically - they saw magician tricks. And they - what they were most appalled by was that, you know, these were physicists, scientists who were supposed to be evaluating the work. And, you know, where were the scientific controls? Where was the skepticism? They didn't see any of this. And so DARPA did not fund the work. They did report back to the CIA that they didn't see anything to it. And yet the work continued on in the intelligence community I think for another 10 years. GROSS: That said, DARPA ended up doing some really exciting research and continues to do exciting research in neuroscience and neurotransmissions, neural implants. Can you describe some of that work, some of the work that's actually been very successful in subsequent years? WEINBERGER: Yeah. So the irony of what happened with that program was that George Lawrence, the DARPA program manager who was responsible for, you know, meeting the witches and psychics, you know, he was brought in 'cause he kind of was part of this. You know, he was part of this new age counterculture, which even at DARPA was unusual at the time. You know, he kind of belonged to the zeitgeist. And he was excited by the idea of communicating directly with the human brain. But rather than doing it through magicians or bunny rabbits, he said, suppose we can do it through computers. He had been a close associate of J. C. R. Licklider, who had been the DARPA program manager who had started computing networking, which led to the ARPANET. And so if you remember, the original days of computer networking was about how do we link man with machine? How do people operate directly with computers so that the computers can help their decision cycle the way we use Google as sort of our collective and individual memory? And so what George said looking at this parapsychology work is, well, suppose we could communicate directly with the human brain using sensors instead of some unknown mechanism. So he laid the foundation for the field of what's now known often as brain-computer interface, where you have sensors that read neural signals to either control computers, to control machines, what is now being developed into neuroprosthetics, prosthetics that can be, you know, handled, maneuvered with just the human brain rather than through muscles. It is also leading to - I mean, it's still very early days, but the idea of quadriplegics, of, quote, unquote, \"locked-in\" people who can operate computers just by thinking about moving the cursor or thinking about letters. That work is still early days, but it is developing. And that came out of, you know, sort of DARPA's open-minded interest in areas like parapsychology. I mean, let's think about it broadly, but let's bring real science into it and rigor. GROSS: My guest is Sharon Weinberger. Her new book, \"The Imagineers Of War,\" is about DARPA, the Pentagon agency that designs futuristic defense technologies. After a break, we'll talk about a spectacular but misguided project, and we'll hear about some of the new technologies DARPA is working on now. I'm Terry Gross and this is FRESH AIR. (SOUNDBITE OF MUSIC) GROSS: This is FRESH AIR. I'm Terry Gross back with Sharon Weinberger, author of the new book \"The Imagineers Of War. \" It's about DARPA, the Defense Advanced Projects Research Agency (ph), the Pentagon agency that designs futuristic defense technology. Its innovations include the predecessor of the internet, stealth aircraft, drones, the M-16 and the driverless car. It also came up with ideas that were too far-fetched or too dangerous to reach completion. So you were talking about how some DARPA projects spiraled out of control. I think under that category we can put the Reagan-era project commonly known as Star Wars, a space-based missile shield to protect against Soviet nuclear attacks. Would you describe what the project was? WEINBERGER: Well, the project, as it was under the Reagan administration, was the idea of creating literally a shield, some sort of shield that would take out any possible nuclear weapons coming from the Soviet Union or elsewhere. So what this actually dates back to is, again, let's take us back to the very early days of DARPA. They did lose their mission in space. But what they kept, at least in the early days, was a secondary mission in missile defense. And there was always a tension at DARPA is is DARPA a national security agency that does science or a science agency that does national security? Meaning which should be the focus? So one of the earliest projects that came out of DARPA was a project called Seesaw, which was a particle beam that was going to blast, you know, nuclear weapons out of space. And this came from a Greek scientist by the name of Nicholas Christofilos, who was sort of a favorite of DARPA. And he had proposed this particle beam that DARPA sponsored in the early days. And every DARPA director who sponsored it said, well, we knew it wasn't ever going to really work, but it was marvelous science. Well, now we're at the early 1980s with Ronald Reagan. And Reagan says, we're going to try to make it work. And DARPA is suddenly, you know, like, what? You're going to build this thing that was just sort of an idea? They were shocked. GROSS: Was President Reagan a little naive about the science that it would take to create the Star Wars defense shield that he was promoting and made it seem like this is really within reach? WEINBERGER: I don't think he cared. So naive is one word that you could use but also that it wasn't - he wasn't about the technological reality. He really kind of came from this, you know, Hollywood vision, sort of, you know, say you can build it and maybe you can build it. One of the most shocking things about the Star Wars history was that he hadn't even, you know, before making his announcement, he hadn't even consulted or listened to the top people in the Pentagon. I remember from some of the interviews I did and received for the DARPA book, you know, there was these descriptions of Caspar Weinberger, then the defense secretary, just sitting there slack-jawed hearing Reagan announce they were going to build this system because, you know, Weinberger himself had said, you know, what you want to do is just not feasible. The same thing with the DARPA director, the same thing with the Pentagon's chief technologist. They were just in shock. Reagan had not consulted with him, had not listened to them when they were saying this is not feasible. I think Reagan really had this vision, not so much that you could make it a technological reality but he could make people believe in it. And for Reagan, that was enough. GROSS: So how much money did the U. S. spend on the Star Wars initiative? WEINBERGER: Oh, my, well, don't forget, it never really ended even to this day. Now, this sort of impressive shield that Reagan talked about, I mean, I think there are numbers in the hundreds of billions that have been invested in Star Wars and all of its sort of component programs. I can say this much. There has been an incredible amount of money that has gone into missile defense based on a belief system. Even today when you look at the missile defense programs that are being built and used operational, the ones that are supposed to stop intercontinental ballistic missiles, they are doing such a small, small part of either what the particle beam weapon in 1958 was proposing or what Reagan was proposing in the 1980s. And yet we're still spending money on it. GROSS: So DARPA was initially very focused on the Cold War and then also on the war in Vietnam. So the war in Vietnam ends, the Cold War ends and DARPA has had to figure out its place in the U. S. in the era of terrorism. So what has DARPA been working on in the era that we're in now? WEINBERGER: Well, so there's two transitions that took place there. One, of course, as you mentioned, was the end of the Vietnam War, which was, you know, it had caused untold problems for the Pentagon, it'd become a lightning rod for DARPA. Congress was becoming very critical of DARPA. So DARPA took all of its technologies from the Vietnam era and renamed the office the Tactical Technology Office, i. e. an office that has nothing to do with Vietnam. And they really began to focus, as you get into the 1980s and the height of the Cold War, on weapons - precision weapons, you know, drones, stealth aircraft. So then we get to the end of the Cold War. And here is DARPA for the past decade been building weapons to fight the Soviet Union. The Soviet Union goes away, and it's sort of left just stranded and not knowing what to do. It is often called an agency that is supposed to stop technological surprise. Technological surprise meaning mostly from the Soviet Union. So what is your mission in the 1990s when that is no longer an issue? And DARPA really struggled to find its place. At one point, they renamed it back to ARPA, looking at it, well, maybe it can be sort of an engine of civil innovation. And really the 1990s were not a great period for DARPA. They did not have a lot of successful programs. Things were not going well for the agency. Then 9/11 happens, and things change again. GROSS: How did they change? WEINBERGER: Well, so the director who came in right before 9/11, Tony Tether, really had a vision. He had been at DARPA prior to that. And so he basically said, look, you know, 9/11, terrorism is clearly going to be one of the number one if not the number-one threat facing the United States in the coming years. We need to address this problem. And when he looked at what happened on 9/11, he said, this is a problem of data, that we probably had all of the information we needed to stop this attack, but we didn't have a good way of integrating it, of centralizing it, of analyzing it. And he said, this is the area we need to get into, data mining, data analysis, pattern recognition. And that's what he did. He - things went downhill from there. GROSS: My guest is Sharon Weinberger. Her new book about DARPA is called \"The Imagineers Of War. \" We'll talk more after a break. This is FRESH AIR. (SOUNDBITE OF MUSIC) GROSS: Let's get back to my interview with Sharon Weinberger, author of the new book \"The Imagineers Of War\" about the history of DARPA, the Pentagon agency that designs futuristic weapons and defense technology. The agency was created in 1958 during the Cold War, when the focus was defending against a Soviet nuclear attack. During the Vietnam War, DARPA also focused on jungle warfare. After 9/11, the agency focused on combating terrorism and tried to find ways to mine and analyze public records with the goal of discovering terrorists before they attacked. DARPA organizes the TIA - Total Information Awareness - program designed to mine data, including from American civilians and kind of, you know, coordinate and read the data. And there's a huge uproar over that. WEINBERGER: Well, exactly. One of the first things that happened was that Tony Tether, the DARPA director, hired John Poindexter. By way to refresh people's memories, this was the national security adviser to Ronald Reagan during the Iran-Contra scandal. He had - Poindexter had been convicted of lying to Congress, although that conviction was tossed out. And what people sometimes forget is that Poindexter had been trained as a physicist, really had a reputation for being quite brilliant. He had had a longtime interest in computers, had helped modernize the White House back in the day, introducing email, introducing networking. And so after he had sort of faded back into the Washingtechnocracy (ph) after the Iran-Contra scandal, he had been working in data mining. This was the very area he was working in, how do you predict terrorist attacks? And he'd been working under a DARPA contract. Well, after 9/11, Tony Tether thought no one's going to care. Like, people want - people realize how important this is. This is like a Sputnik moment, that you have to do whatever it takes to win the war. And he didn't think it would be a problem to hire John Poindexter in at DARPA to run this program called Total Information Awareness. GROSS: It did not work out. WEINBERGER: It did not work out. You know, it sort of for a few months seemed to go along fine. You know, Poindexter being hired at DARPA was a bit of a blip. And really the focus was on 9/11. You were starting a war in Afghanistan. You know, that the nation was turning to sort of, what was this threat? But there were already privacy advocates who were looking at what DARPA was proposing to do and saying this is just crazy. Poindexter had originally proposed to DARPA that there would be a two-track program. One would be a black program, meaning a heavily classified program in data analysis. And then there would be a white program, an unclassified program called Total Information Awareness that would involve academics looking at data mining. When I interviewed Poindexter, what he told me was that the black program never actually took place is what he said, that it was all a white world unclassified program that Poindexter and others began to speak very publicly about, saying, you know, we're going to take data from everything - it might be credit card records, it might be pharmacy records, travel records, car rental - and combine that with government information - might be classified information - mine it all and try to predict terrorist attacks. Now, what Poindexter's very careful to say was that they weren't actually - it was an experiment. It was research. They were not working with real world data. Instead, they created this simulation initially called Vanilla World, which was made-up data where, you know, it was, you know, millions of households in the United States and a few terrorists. And they brought in experts to sort of what's called red team it. You know, there will be some who pretend to be terrorists. And they would see if you could recognize the terrorists ahead of time. GROSS: So the program was ended. The public part of the program was ended, but it ended up going underground as a black program, as a program that's secret from the public. WEINBERGER: Well, exactly. So after The New York Times and others wrote about it, it created this huge media firestorm of, you know, people called it an Orwellian program that was going to, you know, look at all of your, you know, personal data. The very fact that it was trying to find terrorists in the United States using what people consider very sensitive data was extremely controversial. So Congress got involved and started, you know, calling up people to talk about what was going on and eventually shut down the program. Now, what Poindexter argues to me now is that in essence the nation got the worst of both worlds, that rather than an unclassified program that was also sponsoring what he considered to be privacy protection. They were looking at tools that could mask data. Instead, the privacy work was shut down. And the bulk of the program was transferred over to the National Security Agency. It, quote, unquote, \"went black. \" In his argument, you know, the exact opposite of what he wanted, which is basically highly classified work involving data mining. GROSS: DARPA has been working on issues related to the wars in Iraq and Afghanistan, trying to figure out ways to deal with traumatic brain injury, dealing with people who come home and having lost one or more limbs. So what's some of the progress they've made in that? I know they don't like to be identified as a device laboratory. On the other hand, they've created devices and created some really practical things that are really helping people. WEINBERGER: They are. I mean, this work has actually been ongoing at DARPA for a number of years. In a sense, this dates back to the 1970s work on brain computer interface, which went on and was really quite successful in laying the foundations of a scientific field. Well, now we get to the early 2000s. And there was again a revival of this brain computer interface work under Tony Tether at DARPA. Only it was really phrased as, you know, we're going to create weapons. You know, we're going to create drones and robots that will be controlled directly by the human mind. It was a very, very sort of science fiction vision. Well, after sort of the scandal around Total Information Awareness, there was a lot more scrutiny of DARPA programs. So suddenly this talk of yeah, we're going to be controlling drones with the human mind, it sort of was, you know, that went away. And so when DARPA over the past three or four years got back involved in neuroscience, the language was couched very differently. And in fact, the motivations were quite different because what we were seeing at that point were big problems with traumatic brain injury, big problems with post-traumatic stress disorder. And so a lot of the DARPA work is linked to that earlier work. It's talking about brain chips and neuroengineering and brain implants. Only instead of controlling drones, they're talking about how to recover memories, how to treat depression, how to treat traumatic brain injury. GROSS: It might be too soon to answer this question, but I'm wondering what DARPA is doing in this era of the Trump administration and if the Trump administration has had any direct communication with DARPA yet about its goals. And specifically I'm wondering about border wall technology. One of President Trump's big issues is building a wall between Mexico and the U. S. We've yet to see what, if anything, will happen with that. But has DARPA come up with things that are likely to be used if that wall is built? WEINBERGER: Well, in fact, a lot of DARPA's Vietnam-era technology is used today along the U. S. -Mexican border. The two biggest things are sensors. The sensors that are used along the U. S. -Mexican border date back directly to DARPA's work, first from its nuclear test detection technology, but then to the electronic barrier it helped with in Vietnam. There are also tethered aerostats, basically blimps that are tethered to the ground along the U. S. -Mexican border which had come - which again comes directly out of DARPA work in Vietnam. You know, DARPA has a lot of experience in this area. It forwarded the first proposals in 1964 for creating a barrier to basically cut off the supply of weapons and people coming from North Vietnam into South Vietnam. This eventually developed into what was called the McNamara Line, which was again supposed to cut off people and weapons and failed rather spectacularly. So there are a lot of lessons you can learn about, you know, what it takes to build a barrier and what goes wrong. It is very, very hard, expensive, complex and sometimes rather ruthless if you want to cut off people, supplies that are very determined to cross a border. And these are lessons one hopes are taken into account along the U. S. -Mexican border. But what's interesting about the current administration is they're not even talking about technology. The most that the wall has ever been expressed in by Trump or people around him is literally in bricks and mortar. A wall on its own doesn't do anything if it's not monitored. So it will have to involve some sort of sensor, some sort of surveillance system. But it's really too soon. We don't know. We've only heard bricks and mortars. GROSS: If you're just joining us, my guest is Sharon Weinberger, author of the new book \"The Imagineers Of War: The Untold Story of DARPA, The Pentagon Agency That Changed The World. \" We'll be back after a short break. This is FRESH AIR. (SOUNDBITE OF MUSIC) GROSS: This is FRESH AIR. And if you're just joining us, my guest is Sharon Weinberger, author of the new book \"The Imagineers. \" It's about the Pentagon agency called ARPA, which then became DARPA, which was created in 1958. It was initially dedicated to getting the U. S. in space and then turned to tech innovation in the defense field. Innovations credited to DARPA or based on DARPA research include the first communication satellite, stealth aircraft, drones, the driverless car, the robot vacuum cleaner and the internet. So Siri, the famous, like, Apple voice recognition technology who you can ask questions to and sometimes she can answer them (laughter) - so you say that she is a spinoff of a DARPA project. So when you look at DARPA you have these kind of, like, crazy schemes, crazy high-tech schemes that billions of dollars are spent on that don't pan out. But you also have things like, you know, drones for warfare, robotic technology that we're using in daily life, whether it's a vacuum cleaner or, you know, like, voice recognition technology like Siri. So you have this mix of, like, you know, grand schemes that work and schemes that end up in things that not only work for defense but that you can use, you know, in the palm of your hand or in your apartment, in your car because the driverless car is another example of something that came out of DARPA research. So when you look at the big picture, what conclusion do you draw about DARPA and its way of operating and the amount of money that's been spent on its research? WEINBERGER: I have two thoughts on that. The first is that what we consider a success and failure really has to be broken down into two things. So the name \"The Imagineers Of War\" is really based on how I saw DARPA in its early days where it was trying to think about, you know, how is the U. S. going to be fighting wars now and in the future, and how do we come up with, you know, imagineer solutions to those problems? And so if we talk about drones being a success, let's actually think about that for a second. Drones are certainly a technological success not only, you know, for what it does in the military and the civil field. Has it helped us prosecute our wars more successfully? You know, have 16 years of drones and armed drones in Iraq, Afghanistan, Yemen, other countries helped win these wars? I think that's a much more controversial statement to make to say that was a success. So it goes back to the central question I ask in my book of what is it that you want DARPA to do? If you want DARPA to solve national-level problems, to sort of solve warfare or make us more safe, then it changes the picture a lot. If you want DARPA to be an agency that produces cute technological novelties like Siri or, you know, driverless cars, to some extent - it's a great thing, but that doesn't really change, you know, the national security for the country - then it can do that. Do you want DARPA to be a science fiction agency that does nifty gadgets or do you want it to solve national-level problems? That is always the tension of DARPA and where it's supposed to go. And in that its legacy is mixed. What challenges are worthy of a DARPA-type agency? It is arguably the world's most successful research agency. So where do you want to sort of channel those talents? What do you want it to achieve? I certainly hope that it's more than just producing gadgets for the military, that the White House or the Pentagon gives it challenges to solve. I think neuroscience and the challenge of helping people with traumatic brain injury and post-traumatic stress disorder, those are very noble missions and I think DARPA can contribute a lot. But if you look at the larger problems that we're facing after 9/11 and 16 years of war, I don't think that really anyone is asking, what can DARPA contribute? What can it do to sort of stop the threats that we're facing today? And that's the unfortunate part of DARPA, this tremendously successful research agency which isn't being used the way it was in its early days to address warfare. GROSS: Sharon Weinberger, thank you so much for talking with us. WEINBERGER: Thank you for having me. GROSS: Sharon Weinberger's new book about DARPA is called \"The Imagineers Of War. \" Tomorrow on FRESH AIR, our guest will be New York Times national security correspondent David Sanger, who has been covering North Korea's nuclear and missile tests and the Trump administration response. North Korea claims that it's preparing to test an intercontinental ballistic missile that could reach the U. S. I hope you'll join us. (SOUNDBITE OF MUSIC) GROSS: And now for something I've put off doing because I haven't wanted to face the fact that it has to be done. I have to say goodbye to our producer John Sheehan, who has accepted another position. John has edited zillions of interviews, produced years of our opening billboard - that's the minute-long introduction to the show - and has produced our Weekend Edition. He's an audio wizard. And in the past year, he's written, produced and directed a wonderful podcast that's a comic adventure series for kids called The Radio Adventures Of Eleanor Amplified. (SOUNDBITE OF PODCAST, \"THE RADIO ADVENTURES OF ELEANOR AMPLIFIED\") UNIDENTIFIED CHILD: From WHYY in Philadelphia. UNIDENTIFIED MAN: In a world of no-goodnicks (ph), hucksters, charlatans and flim-flammers (ph), she's checking facts and taking names. It's The Radio Adventures of Eleanor Amplified. GROSS: Eleanor Amplified is about an investigative reporter who's trying to take down Angela Brant, the nefarious head of a giant tech company called Megablurg that's trying to take over the world. In addition to the great professional actors John has used, he's drawn on the extraordinary acting talents of the FRESH AIR family. Listen as the whole staff collectively gasps. (SOUNDBITE OF PODCAST, \"THE RADIO ADVENTURES OF ELEANOR AMPLIFIED\") UNIDENTIFIED ACTRESS #1: (As character) I'm almost ready to rest my case, congressman. I just have one final witness. I call Eleanor Amplified's Megablurg 5,000 limited edition SL smartphone. UNIDENTIFIED GROUP: (Gasping). GROSS: We did good, right? John channeled the true acting talents of Amelia (ph) and Lena (ph), our producer Ann Marie Baldonado's two daughters. Here they are quarreling in a scene from Eleanor. (SOUNDBITE OF PODCAST, \"THE RADIO ADVENTURES OF ELEANOR AMPLIFIED\") UNIDENTIFIED ACTRESS #2: (As Hannah) Hey The Rook, can we play with Norad (ph) again? UNIDENTIFIED ACTRESS #3: (As The Rook) Hannah, get out. Mom, Hannah's in my room again. UNIDENTIFIED ACTRESS #2: (As Hannah) Mom, The Rook is yelling at me. GROSS: Nice work, girls. So the good news for us is that John's new job is requiring him to move only as far as one flight up in the WHYY building where we work. He's WHYY's new manager of on-demand audio and podcasts. And part of his job is continuing to create new episodes of \"Eleanor. \" Even so, we're heartbroken he's no longer part of the FRESH AIR crew. I want to close today's show with the best FRESH AIR ending ever, which was of course conceived and produced by John. It's from last summer, when he came on the show as a guest to talk about the premiere of \"Eleanor. \" And he came up with this way to end our show. (SOUNDBITE OF ARCHIVED BROADCAST) GROSS: (As herself) FRESH AIR's executive producer is. . . (SOUNDBITE OF COMPUTER CRASHING) GROSS: I don't know. Danny, are we still on the air? UNIDENTIFIED ACTRESS #4: (As Angela Brant) FRESH AIR's executive producer is me, Megablurg CEO Angela Brant. GROSS: (As herself) What is this? What's going on here? UNIDENTIFIED ACTRESS #4: (As Angela Brant) Why, we're stealing your show, Terry Gross. (LAUGHTER) SCOTT JOHNSTON: (As Professor Ignomi) Now your listeners will hear only Megablurg-approved programming. GROSS: (As herself) No, you can't. You won't get away with this. UNIDENTIFIED ACTRESS #4: (As Angela Brant) Professor Ignomi, show Terry Gross your hypnoray. JOHNSTON: (As Professor Ignomi, laughing) With pleasure, Ms. Brant. (SOUNDBITE OF BLASTING) GROSS: (As herself) FRESH AIR listeners, would you like to hear the latest deals on internet shopping or maybe some celebrity gossip? UNIDENTIFIED ACTRESS #4: (As Angela Brant, laughing) Got you, Terry Gross. That'll show you for denying my interview request. (LAUGHTER) CHRISTA D\u2019AGOSTINO: (As Eleanor Amplified) Not so fast, evildoers. SCOTT JOHNSTON AND UNIDENTIFIED ACTRESS #4: (As characters, gasping) Eleanor Amplified. D\u2019AGOSTINO: (As Eleanor Amplified) I won't let you turn FRESH AIR into a Megablurg mouthpiece. It's a good thing I brought this anti-hypnoray. (SOUNDBITE OF BLASTING) JOHNSTON: (As Professor Ignomi) No. UNIDENTIFIED ACTRESS #4: (As Angela Brant) Curse you, Eleanor Amplified. You've spoiled my plans again. GROSS: (As herself) Eleanor, where am I? I don't think I can finish the show. I don't think I can even remember the names of our producers. D\u2019AGOSTINO: (As Eleanor Amplified) Don't worry, Terry Gross, I've got this. FRESH AIR'S executive producer is Danny Miller. Our engineer is Audrey Bentham. The interviews and reviews are produced and edited by Amy Salit, Phyllis Myers, Ann Marie Baldonado, Sam Briger, Lauren Krenzel, John Sheehan, Heidi Saman, Therese Madden and Thea Chaloner. Molly Seavy-Nesper is associate producer of online media. Roberta Shorrock directs the show. GROSS: (As herself) Thanks, Eleanor. D\u2019AGOSTINO: (As Eleanor Amplified) Sure thing, Terry Gross. (SOUNDBITE OF MUSIC) GROSS: I'm back to add Mooj Zadie's name to the credits. He wasn't yet here when we recorded that. And to thank you, John, for sharing nine years of your life with FRESH AIR. See you in the hall. I'm Terry Gross.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-03-28-521771515": {"title": "Older Workers Find Age Discrimination Built Right Into Some Job Websites : NPR", "url": "https://www.npr.org/2017/03/28/521771515/older-workers-find-age-discrimination-built-right-into-some-job-sites", "author": "No author found", "published_date": "2017-03-28", "content": "ARI SHAPIRO, HOST: A lot of people looking for work start with a website that posts job listings. A lot of those websites, though, exclude older adults who are looking for jobs. And now the Illinois attorney general is investigating. NPR's Ina Jaffe, who covers aging, has this report. INA JAFFE, BYLINE: This issue came to the attention of Illinois Attorney General Lisa Madigan the way many do. LISA MADIGAN: Somebody called us and complained. JAFFE: The man was in his 70s. He was using the resume-building service on a well-known job site. The problem was the dropdown menu that required you to pick the year when you got to your first job or graduated from high school. It didn't have dates to click for anyone over 52. Madigan found other sites excluded people over 82, but she says that's still discrimination and that the site should be changed so that. . . MADIGAN: Anybody who's alive and wants to look for a job would be able to and be able to put in accurate information. JAFFE: A couple of the sites have already made changes, but Madigan also wants to see the company's internal documents to see if the exclusions were deliberate or inadvertent. MADIGAN: Our goal is to fix the problem. Our goal is not to file a lawsuit. JAFFE: Meanwhile, a site called retirementjobs. com is trying to fix the problem in another way. Tim Driver, the founder and CEO, says his site designates some employers as age-friendly after his staff investigates their practices and culture. TIM DRIVER: There's over a hundred big American employers now that have gone through the program. You can think of Fidelity or Wells Fargo, even government organizations like the TSA or the Veterans Administration. JAFFE: But job seekers don't have to take Driver's word for it. Retirementjobs. com is the only site for older workers that lets members post comments describing their experiences, kind of like Yelp for job hunters. DRIVER: We wanted to know, are these companies truly walking the talk? JAFFE: Well, not always. There are dozens of comments about companies that push out older workers or exclude older job hunters in favor of, quote, \"recent graduates. \" On the other hand, there are also plenty of five-star reviews, most brimming with gratitude for companies that treat older workers with respect and don't hold their longer experience against them. Ina Jaffe, NPR News. ARI SHAPIRO, HOST:  A lot of people looking for work start with a website that posts job listings. A lot of those websites, though, exclude older adults who are looking for jobs. And now the Illinois attorney general is investigating. NPR's Ina Jaffe, who covers aging, has this report. INA JAFFE, BYLINE: This issue came to the attention of Illinois Attorney General Lisa Madigan the way many do. LISA MADIGAN: Somebody called us and complained. JAFFE: The man was in his 70s. He was using the resume-building service on a well-known job site. The problem was the dropdown menu that required you to pick the year when you got to your first job or graduated from high school. It didn't have dates to click for anyone over 52. Madigan found other sites excluded people over 82, but she says that's still discrimination and that the site should be changed so that. . . MADIGAN: Anybody who's alive and wants to look for a job would be able to and be able to put in accurate information. JAFFE: A couple of the sites have already made changes, but Madigan also wants to see the company's internal documents to see if the exclusions were deliberate or inadvertent. MADIGAN: Our goal is to fix the problem. Our goal is not to file a lawsuit. JAFFE: Meanwhile, a site called retirementjobs. com is trying to fix the problem in another way. Tim Driver, the founder and CEO, says his site designates some employers as age-friendly after his staff investigates their practices and culture. TIM DRIVER: There's over a hundred big American employers now that have gone through the program. You can think of Fidelity or Wells Fargo, even government organizations like the TSA or the Veterans Administration. JAFFE: But job seekers don't have to take Driver's word for it. Retirementjobs. com is the only site for older workers that lets members post comments describing their experiences, kind of like Yelp for job hunters. DRIVER: We wanted to know, are these companies truly walking the talk? JAFFE: Well, not always. There are dozens of comments about companies that push out older workers or exclude older job hunters in favor of, quote, \"recent graduates. \" On the other hand, there are also plenty of five-star reviews, most brimming with gratitude for companies that treat older workers with respect and don't hold their longer experience against them. Ina Jaffe, NPR News.", "section": "Business", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-03-29-521954026": {"title": "Congress Votes To Roll Back FCC's Internet Privacy Protections : NPR", "url": "https://www.npr.org/2017/03/29/521954026/congress-votes-to-roll-back-fccs-internet-privacy-protections", "author": "No author found", "published_date": "2017-03-29", "content": "KELLY MCEVERS, HOST: Your internet provider knows a lot about you, like everything you do and share online. And to marketers, that is really valuable information. Back in October, a rule was created saying essentially if your internet provider wants to sell your personal details they need your permission. Well, this rule hasn't even gone into effect yet and now it looks like it'll be thrown out. Congress has sent President Trump a bill to get rid of it. To understand what this means, we reached out to journalist Manoush Zomorodi, who has been following this closely. MANOUSH ZOMORODI, BYLINE: I mean, I think it's a total win for the telecom companies and this idea of turning the internet into something that is treated solely like a business for profit as opposed to a utility, like our electricity or even our phone lines or our water. I think we're kind of at a moment in the government where we're deciding as a society also - what is the internet? What role does it play in our lives? MCEVERS: So basically, internet providers want to be on the same playing field as, say, Facebook and Google, which obviously already have our information. I mean, I just bought a dress the other day online and now it seems like everywhere I go there are ads trying to get me to buy more dresses. ZOMORODI: Right. Yeah. But I would say, Kelly, the difference is that you pay for your internet connection, right? You pay for your internet connection so you can then get on Google and look for your dress. Google watches that you're looking for a dress. They sell off that information. And then you see an ad for that same dress follow you around. If that bothered you, you could say, you know what? I'm going to use a different browser that doesn't track me. But you can't change who's giving you the internet, or if you do it's a huge hassle. And you probably don't have a lot of choice, right? We know that the telecommunications industry has been really consolidated. There's not a lot of competition there. And so you don't have to use Facebook when you go online, but you do need to use your internet connection. MCEVERS: Is there going to be a way to say, hey, internet provider - hey, Comcast, AT&T, Verizon - I don't want my information sold? Can - I want to opt out. ZOMORODI: Well, it's interesting. So AT&T, for a period a couple of years ago, it charged some of its internet customers extra unless they opted into a system that let them collect information so they could deliver personalized ads. So we've yet to see how this deregulation will sort of be turned into, like, what it looks like on our bill essentially. But for now if you decide, you know, I don't want to be tracked, you can use something called a virtual private network, VPN. And what this does is it puts a layer between you and what you're doing online and your internet provider. But honestly, the most trusted ones cost money. This is yet another hassle. You know, I think of it like the telephone. Nobody can listen in on your calls. That is illegal. Well, what if I said to you, actually, they can listen in on your calls, so you should buy something that distorts your voice? You'd say, no way, I'm not doing that. It's - I need a phone. I talk on the phone. It's what I do. Well, now what do we do? We browse online. And yet the internet is not being regulated, at least in this administration, like a utility. It is seen as another business and an industry that is a growth opportunity for the economy. MCEVERS: Manoush Zomorodi is the host of WNYC's tech podcast, \"Note To Self. \" Thanks so much. ZOMORODI: Thank you, Kelly. KELLY MCEVERS, HOST:  Your internet provider knows a lot about you, like everything you do and share online. And to marketers, that is really valuable information. Back in October, a rule was created saying essentially if your internet provider wants to sell your personal details they need your permission. Well, this rule hasn't even gone into effect yet and now it looks like it'll be thrown out. Congress has sent President Trump a bill to get rid of it. To understand what this means, we reached out to journalist Manoush Zomorodi, who has been following this closely. MANOUSH ZOMORODI, BYLINE: I mean, I think it's a total win for the telecom companies and this idea of turning the internet into something that is treated solely like a business for profit as opposed to a utility, like our electricity or even our phone lines or our water. I think we're kind of at a moment in the government where we're deciding as a society also - what is the internet? What role does it play in our lives? MCEVERS: So basically, internet providers want to be on the same playing field as, say, Facebook and Google, which obviously already have our information. I mean, I just bought a dress the other day online and now it seems like everywhere I go there are ads trying to get me to buy more dresses. ZOMORODI: Right. Yeah. But I would say, Kelly, the difference is that you pay for your internet connection, right? You pay for your internet connection so you can then get on Google and look for your dress. Google watches that you're looking for a dress. They sell off that information. And then you see an ad for that same dress follow you around. If that bothered you, you could say, you know what? I'm going to use a different browser that doesn't track me. But you can't change who's giving you the internet, or if you do it's a huge hassle. And you probably don't have a lot of choice, right? We know that the telecommunications industry has been really consolidated. There's not a lot of competition there. And so you don't have to use Facebook when you go online, but you do need to use your internet connection. MCEVERS: Is there going to be a way to say, hey, internet provider - hey, Comcast, AT&T, Verizon - I don't want my information sold? Can - I want to opt out. ZOMORODI: Well, it's interesting. So AT&T, for a period a couple of years ago, it charged some of its internet customers extra unless they opted into a system that let them collect information so they could deliver personalized ads. So we've yet to see how this deregulation will sort of be turned into, like, what it looks like on our bill essentially. But for now if you decide, you know, I don't want to be tracked, you can use something called a virtual private network, VPN. And what this does is it puts a layer between you and what you're doing online and your internet provider. But honestly, the most trusted ones cost money. This is yet another hassle. You know, I think of it like the telephone. Nobody can listen in on your calls. That is illegal. Well, what if I said to you, actually, they can listen in on your calls, so you should buy something that distorts your voice? You'd say, no way, I'm not doing that. It's - I need a phone. I talk on the phone. It's what I do. Well, now what do we do? We browse online. And yet the internet is not being regulated, at least in this administration, like a utility. It is seen as another business and an industry that is a growth opportunity for the economy. MCEVERS: Manoush Zomorodi is the host of WNYC's tech podcast, \"Note To Self. \" Thanks so much. ZOMORODI: Thank you, Kelly.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-04-02-518811503": {"title": "Meet 2 Race Sleuths Trying to Keep Marathoners Honest : NPR", "url": "https://www.npr.org/2017/04/02/518811503/meet-two-race-sleuths-trying-to-keep-marathoners-honest", "author": "No author found", "published_date": "2017-04-02", "content": "", "section": "Sports", "disclaimer": ""}, "2017-04-04-522574666": {"title": "Facebook Live Gang Rape: Should Those Who Watched It Face Charges? : NPR", "url": "https://www.npr.org/2017/04/04/522574666/should-viewers-of-facebook-live-gang-rape-face-charges", "author": "No author found", "published_date": "2017-04-04", "content": "ROBERT SIEGEL, HOST: Chicago Police have made two arrests now in the sexual assault of a 15-year-old girl that was streamed on Facebook Live. Both suspects are teenage boys. The police are looking for more accomplices. As many as 40 people may have watched the rapes on Facebook as it happened. None of those witnesses reported them to police. And that is raising ethical and legal questions. From Chicago, NPR's David Schaper reports. DAVID SCHAPER, BYLINE: Chicago Police say the 15-year-old victim knew one of her attackers. He lured her to a home on the city's west side, where as many as six young men brutally raped her. Chicago Police Superintendent Eddie Johnson. . . (SOUNDBITE OF PRESS CONFERENCE)EDDIE JOHNSON: Due to the graphic content that I observed, I don't want to go into the detail of what was on the video. But I want to tell you the young men responsible, they should be ashamed of themselves. They've humiliated themselves, humiliated their families. And now they're going to be held accountable for what they did. SCHAPER: They'll be held accountable, Johnson says, because some of the suspects shot video of the vicious assault and one streamed it live on Facebook, where about 40 people watched. (SOUNDBITE OF PRESS CONFERENCE)JOHNSON: It just disgusts me that people would look at those videos and not pick up the phone and dial 911. So it makes you wonder where are we going, what are we doing as a society? SCHAPER: After the girl's mother received screenshots of the assault, community activist Andrew Holmes was able to track down the full video, and he turned it over to police. He says he thinks anyone who viewed the assaults and did not report them should be charged. ANDREW HOLMES: It tells me that they really don't give a damn, you know, what happens to a human being. You got 40-some people watching it and enjoying it. To me, you was enjoying it 'cause you didn't take the time to turn it in. SCHAPER: But legal experts say proving criminal charges against those who viewed the video might be difficult. Stephanie LaCambra is a criminal defense attorney at the Electronic Frontier Foundation. STEPHANIE LACAMBRA: Generally, ordinary citizens are not legally required to report a crime or to do anything to stop it. There is no general duty to be a good Samaritan. SCHAPER: There are some exceptions, though. Many states require people in certain jobs and fields to report suspicions of child abuse and some other crimes, but LaCambra says reporting what anyone witnesses in the digital space is even more nuanced. First of all, prosecutors would have to prove that whoever's account was used to view a stream was in fact the person who viewed it, and that the individual knew the crime was actually real. LACAMBRA: You don't know if the video you're watching has been Photoshopped or if the details you're viewing are in fact true. SCHAPER: Law professor Allen Shoenberger at Loyola University of Chicago agrees that there is no general rule requiring viewers of a crime in a live stream to report it. But he says in this case because the victim is 15, child pornography laws may apply. ALLEN SHOENBERGER: The federal statute, for example, makes it quite clear that possessing those images is grounds for culpability - criminal culpability - but also just watching them is grounds for criminal culpability. SCHAPER: The teenagers already arrested in the case are charged with both the manufacture and dissemination of child pornography in addition to aggravated criminal sexual assault. Chicago Police say they haven't yet decided if they'll pursue charges against anyone who watched the assault online, saying they're first focusing on finding the rest of those who attacked the teenage girl. David Schaper, NPR News, Chicago. (SOUNDBITE OF LAURA VEIRS SONG, \"SILO SONG\") ROBERT SIEGEL, HOST:  Chicago Police have made two arrests now in the sexual assault of a 15-year-old girl that was streamed on Facebook Live. Both suspects are teenage boys. The police are looking for more accomplices. As many as 40 people may have watched the rapes on Facebook as it happened. None of those witnesses reported them to police. And that is raising ethical and legal questions. From Chicago, NPR's David Schaper reports. DAVID SCHAPER, BYLINE: Chicago Police say the 15-year-old victim knew one of her attackers. He lured her to a home on the city's west side, where as many as six young men brutally raped her. Chicago Police Superintendent Eddie Johnson. . . (SOUNDBITE OF PRESS CONFERENCE) EDDIE JOHNSON: Due to the graphic content that I observed, I don't want to go into the detail of what was on the video. But I want to tell you the young men responsible, they should be ashamed of themselves. They've humiliated themselves, humiliated their families. And now they're going to be held accountable for what they did. SCHAPER: They'll be held accountable, Johnson says, because some of the suspects shot video of the vicious assault and one streamed it live on Facebook, where about 40 people watched. (SOUNDBITE OF PRESS CONFERENCE) JOHNSON: It just disgusts me that people would look at those videos and not pick up the phone and dial 911. So it makes you wonder where are we going, what are we doing as a society? SCHAPER: After the girl's mother received screenshots of the assault, community activist Andrew Holmes was able to track down the full video, and he turned it over to police. He says he thinks anyone who viewed the assaults and did not report them should be charged. ANDREW HOLMES: It tells me that they really don't give a damn, you know, what happens to a human being. You got 40-some people watching it and enjoying it. To me, you was enjoying it 'cause you didn't take the time to turn it in. SCHAPER: But legal experts say proving criminal charges against those who viewed the video might be difficult. Stephanie LaCambra is a criminal defense attorney at the Electronic Frontier Foundation. STEPHANIE LACAMBRA: Generally, ordinary citizens are not legally required to report a crime or to do anything to stop it. There is no general duty to be a good Samaritan. SCHAPER: There are some exceptions, though. Many states require people in certain jobs and fields to report suspicions of child abuse and some other crimes, but LaCambra says reporting what anyone witnesses in the digital space is even more nuanced. First of all, prosecutors would have to prove that whoever's account was used to view a stream was in fact the person who viewed it, and that the individual knew the crime was actually real. LACAMBRA: You don't know if the video you're watching has been Photoshopped or if the details you're viewing are in fact true. SCHAPER: Law professor Allen Shoenberger at Loyola University of Chicago agrees that there is no general rule requiring viewers of a crime in a live stream to report it. But he says in this case because the victim is 15, child pornography laws may apply. ALLEN SHOENBERGER: The federal statute, for example, makes it quite clear that possessing those images is grounds for culpability - criminal culpability - but also just watching them is grounds for criminal culpability. SCHAPER: The teenagers already arrested in the case are charged with both the manufacture and dissemination of child pornography in addition to aggravated criminal sexual assault. Chicago Police say they haven't yet decided if they'll pursue charges against anyone who watched the assault online, saying they're first focusing on finding the rest of those who attacked the teenage girl. David Schaper, NPR News, Chicago. (SOUNDBITE OF LAURA VEIRS SONG, \"SILO SONG\")", "section": "Law", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-04-05-522732036": {"title": "State And Local Officials Wary Of Federal Government's Election Security Efforts : NPR", "url": "https://www.npr.org/2017/04/05/522732036/state-and-local-officials-wary-of-federal-governments-election-security-efforts", "author": "No author found", "published_date": "2017-04-05", "content": "", "section": "Politics", "disclaimer": ""}, "2017-04-06-522826507": {"title": "Amazon To Refund Millions In Unauthorized In-App Purchases : NPR", "url": "https://www.npr.org/2017/04/06/522826507/amazon-to-refund-millions-in-unauthorized-in-app-purchases", "author": "No author found", "published_date": "2017-04-06", "content": "DAVID GREENE, HOST: You probably feel like sometimes you are literally living on your smartphone or tablet. You're catching up on the news, maybe you're playing some games. (SOUNDBITE OF CANDY CRUSH GAME)UNIDENTIFIED VOICE: Tasty. RACHEL MARTIN, HOST: Tasty. GREENE: (Laughter) That is from Candy Crush, which, like a lot of other games, you can download for free. MARTIN: Yeah. You can download for free. But then many games ask if you want to pay to get more features. Those are called in-app purchases. And Julie Comeaux made one of these when her young daughter got a Kindle for Christmas. JULIE COMEAUX: It's not something we were familiar with, but we made an in-app purchase for $5. MARTIN: Comeaux says she gave Amazon her password to make that first purchase. But here's where things went really wrong - she left the Kindle with her daughter. COMEAUX: When we checked the account and we saw hundreds of charges from Amazon. It totaled near $10,000. GREENE: Ten thousand dollars all racked up by Comeaux's daughter without having to ever type in the password again. COMEAUX: She cried. She cried. I had to calm her down. But yeah, she was very upset, didn't know she was spending real money. MALINI MITHAL: Within these apps, it can be very confusing to determine, particularly for a child, whether you're buying something that really costs money. GREENE: That is Malini Mithal of the Federal Trade Commission. After complaints from Julie Comeaux and other customers, the FTC sued Amazon and Google and Apple over these in-app purchases. MARTIN: Google and Apple both settled three years ago before the case went to court and agreed to give refunds. This week, Amazon and the FTC dropped their appeals cases in federal court. The company will now have to notify every single person who made an in-app purchase. MITHAL: Then those parents or account holders can confirm that these were charges that they didn't authorize and get a refund. MARTIN: The FTC says Amazon may refund as much as $70 million in unauthorized charges. And details of how that process will work are expected to come soon. (SOUNDBITE OF ARMS AND SLEEPERS' \"DEX\") DAVID GREENE, HOST:  You probably feel like sometimes you are literally living on your smartphone or tablet. You're catching up on the news, maybe you're playing some games. (SOUNDBITE OF CANDY CRUSH GAME) UNIDENTIFIED VOICE: Tasty. RACHEL MARTIN, HOST:  Tasty. GREENE: (Laughter) That is from Candy Crush, which, like a lot of other games, you can download for free. MARTIN: Yeah. You can download for free. But then many games ask if you want to pay to get more features. Those are called in-app purchases. And Julie Comeaux made one of these when her young daughter got a Kindle for Christmas. JULIE COMEAUX: It's not something we were familiar with, but we made an in-app purchase for $5. MARTIN: Comeaux says she gave Amazon her password to make that first purchase. But here's where things went really wrong - she left the Kindle with her daughter. COMEAUX: When we checked the account and we saw hundreds of charges from Amazon. It totaled near $10,000. GREENE: Ten thousand dollars all racked up by Comeaux's daughter without having to ever type in the password again. COMEAUX: She cried. She cried. I had to calm her down. But yeah, she was very upset, didn't know she was spending real money. MALINI MITHAL: Within these apps, it can be very confusing to determine, particularly for a child, whether you're buying something that really costs money. GREENE: That is Malini Mithal of the Federal Trade Commission. After complaints from Julie Comeaux and other customers, the FTC sued Amazon and Google and Apple over these in-app purchases. MARTIN: Google and Apple both settled three years ago before the case went to court and agreed to give refunds. This week, Amazon and the FTC dropped their appeals cases in federal court. The company will now have to notify every single person who made an in-app purchase. MITHAL: Then those parents or account holders can confirm that these were charges that they didn't authorize and get a refund. MARTIN: The FTC says Amazon may refund as much as $70 million in unauthorized charges. And details of how that process will work are expected to come soon. (SOUNDBITE OF ARMS AND SLEEPERS' \"DEX\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-04-08-523057689": {"title": "Did A Trump Aide's Tweet Violate Federal Law? The Answer's Not Clear \u2014 Or Easy. : NPR", "url": "https://www.npr.org/2017/04/08/523057689/what-is-the-hatch-act-and-what-does-it-mean-for-government-employees-and-twitter", "author": "No author found", "published_date": "2017-04-08", "content": "", "section": "Technology", "disclaimer": ""}, "2017-04-09-523170115": {"title": "How Misinformation Spreads On The Internet : NPR", "url": "https://www.npr.org/2017/04/09/523170115/how-misinformation-spreads-on-the-internet-and-how-to-stop-it", "author": "No author found", "published_date": "2017-04-09", "content": "LOURDES GARCIA-NAVARRO, HOST: Was the U. S. duped into striking Syria? No. The grisly deaths this week of women and children in what looks to be a chemical weapons attack was not carried out by opponents of President Trump in his own government - the, quote, unquote, \"deep state. \" But that is the rumor that's been circulating on social media. And of course, this isn't the first time rumors like that have spread. Kate Starbird studies the spread of rumors. She teaches at the University of Washington, and her research traces fake news back past this presidential race to at least the 2013 Boston Marathon bombing. KATE STARBIRD: We found a couple of different kinds of rumors, and one of them - there was this weird little rumor. It was kind of small but very different from the other ones and that was this theory that the Navy SEALs had perpetrated the Boston Marathon bombings. And they had been blamed on these what they called patsies, which were the suspects that were the Chechnya brothers. But it was all part of this - it was a false flag that the U. S. government or some elements of the U. S. government had perpetrated this event on itself. GARCIA-NAVARRO: What do we see happen when a tragedy occurs? Is this - did you find that this was common? STARBIRD: We did see across all of the manmade disaster events, over and over again, these same claims go from, you know, event to event to event. GARCIA-NAVARRO: What we've just seen now on the strike on Syria, saying that somehow these were actors staging the event to sort of dupe the United States to make them - to draw them into the war. It's the same kind of thing. STARBIRD: Exactly. So as soon as I saw this event, I actually posted on Facebook. I said, you know, you're seeing these images. But within, you know, a couple hours or maybe a day, you're going to see claims that this didn't really happen or that it was perpetrated by someone else. And of course, that comes to fruition. GARCIA-NAVARRO: So the question is, so if we're seeing the same thing happening over and over again, who's doing this? STARBIRD: I think you have people that are doing it for individual reasons. They have some political motivation, or they have financial motivation. They can make money selling these ideas, selling ads on their website. GARCIA-NAVARRO: Just trying to get eyeballs so that they can sell, you know, whatever product they're pushing. STARBIRD: So there's that element. Then there's people that are sincere believers in this stuff. They really - they're bought in. They think about this. They're 9/11 truthers (ph). They're JFK conspiracy theorists. And then there was elements of what seemed to be purposeful disinformation strategies. So someone who doesn't believe these things, who's got a political motivation for injecting very confusing ideas that are anti-globalist, anti-corporatist, anti-mainstream media. And they - a lot of the theories had this idea that there's a group of very powerful people that are outside of government that sort of orchestrate things. Those are the kinds of things that were actually much more problematic than the folks that were doing it for money or the sincere believers. GARCIA-NAVARRO: What does this say to you? What have you learned through looking at this? STARBIRD: I've learned a lot in the last few months. So, you know, I come from computer science and media studies, but I'm really sort of an engineer background. And I've ended up in this very politicized space looking for sort of a U. S. right versus left kind of spectrum, and that's not what I found. What I found was these kinds of theories and this way of thinking about the world is appealing to both people on the left and the right - that people are going to see one theory. Like, they're anti-vaccine or they're anti-GMO. And they're getting drawn into these other theories of, you know, deep state actors that are changing world events to manipulate you. And then getting pulled into this worldview that is very potentially dangerous. GARCIA-NAVARRO: That's Kate Starbird. She teaches at the University of Washington. And she studies the spread of misinformation online, a huge problem these days. Thanks so much for joining us. STARBIRD: Thank you. (SOUNDBITE OF ALEXANDRE DESPLAT'S \"MR. FOX IN THE FIELDS MEDLEY\") LOURDES GARCIA-NAVARRO, HOST:  Was the U. S. duped into striking Syria? No. The grisly deaths this week of women and children in what looks to be a chemical weapons attack was not carried out by opponents of President Trump in his own government - the, quote, unquote, \"deep state. \" But that is the rumor that's been circulating on social media. And of course, this isn't the first time rumors like that have spread. Kate Starbird studies the spread of rumors. She teaches at the University of Washington, and her research traces fake news back past this presidential race to at least the 2013 Boston Marathon bombing. KATE STARBIRD: We found a couple of different kinds of rumors, and one of them - there was this weird little rumor. It was kind of small but very different from the other ones and that was this theory that the Navy SEALs had perpetrated the Boston Marathon bombings. And they had been blamed on these what they called patsies, which were the suspects that were the Chechnya brothers. But it was all part of this - it was a false flag that the U. S. government or some elements of the U. S. government had perpetrated this event on itself. GARCIA-NAVARRO: What do we see happen when a tragedy occurs? Is this - did you find that this was common? STARBIRD: We did see across all of the manmade disaster events, over and over again, these same claims go from, you know, event to event to event. GARCIA-NAVARRO: What we've just seen now on the strike on Syria, saying that somehow these were actors staging the event to sort of dupe the United States to make them - to draw them into the war. It's the same kind of thing. STARBIRD: Exactly. So as soon as I saw this event, I actually posted on Facebook. I said, you know, you're seeing these images. But within, you know, a couple hours or maybe a day, you're going to see claims that this didn't really happen or that it was perpetrated by someone else. And of course, that comes to fruition. GARCIA-NAVARRO: So the question is, so if we're seeing the same thing happening over and over again, who's doing this? STARBIRD: I think you have people that are doing it for individual reasons. They have some political motivation, or they have financial motivation. They can make money selling these ideas, selling ads on their website. GARCIA-NAVARRO: Just trying to get eyeballs so that they can sell, you know, whatever product they're pushing. STARBIRD: So there's that element. Then there's people that are sincere believers in this stuff. They really - they're bought in. They think about this. They're 9/11 truthers (ph). They're JFK conspiracy theorists. And then there was elements of what seemed to be purposeful disinformation strategies. So someone who doesn't believe these things, who's got a political motivation for injecting very confusing ideas that are anti-globalist, anti-corporatist, anti-mainstream media. And they - a lot of the theories had this idea that there's a group of very powerful people that are outside of government that sort of orchestrate things. Those are the kinds of things that were actually much more problematic than the folks that were doing it for money or the sincere believers. GARCIA-NAVARRO: What does this say to you? What have you learned through looking at this? STARBIRD: I've learned a lot in the last few months. So, you know, I come from computer science and media studies, but I'm really sort of an engineer background. And I've ended up in this very politicized space looking for sort of a U. S. right versus left kind of spectrum, and that's not what I found. What I found was these kinds of theories and this way of thinking about the world is appealing to both people on the left and the right - that people are going to see one theory. Like, they're anti-vaccine or they're anti-GMO. And they're getting drawn into these other theories of, you know, deep state actors that are changing world events to manipulate you. And then getting pulled into this worldview that is very potentially dangerous. GARCIA-NAVARRO: That's Kate Starbird. She teaches at the University of Washington. And she studies the spread of misinformation online, a huge problem these days. Thanks so much for joining us. STARBIRD: Thank you. (SOUNDBITE OF ALEXANDRE DESPLAT'S \"MR. FOX IN THE FIELDS MEDLEY\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-04-10-523311405": {"title": "States Introduce New Legislation To Protect Internet Privacy : NPR", "url": "https://www.npr.org/2017/04/10/523311405/states-introduce-new-legislation-to-protect-internet-privacy", "author": "No author found", "published_date": "2017-04-10", "content": "AUDIE CORNISH, HOST: Privacy groups lost a major battle when Congress and President Trump canceled Internet privacy rules written under the Obama administration. The regulations prevented Internet service providers from selling your web browsing history to third parties, and they were stricter than rules for other kinds of Internet firms. But as NPR's Martin Kaste reports, the fight's not over. It's just moved to the states. MARTIN KASTE, BYLINE: Drew Hansen is a Democrat in the Washington State House, and Internet privacy policy is not something he usually deals with. But that's changing after this action by Congress. DREW HANSEN: One of my constituents emailed me and said, I'm outraged that Congress is going to allow Internet service providers to sell my browsing history; can we do anything about that? And I said, well, I don't know. That's a great question. Let me find out. KASTE: He talked to the lawyers, and they didn't see why he couldn't just introduce legislation for a state version of the privacy rules that Congress had just canceled. HANSEN: Well, there's no conflict here. I mean the federal entities have just chosen not to act. Federal law in this area is a floor rather than a ceiling. There's nothing to protect states from being more protective of privacy than the federal government has chosen to do. KASTE: And he's not alone in thinking this way. Legislators around the country are responding to public anger and introducing ISP privacy bills in Minnesota, Illinois, Maryland. The list keeps growing. But is it really true that there's no conflict here with the feds? Blake Reid is an expert on telecom law at the University of Colorado. BLAKE REID: Anytime states are intruding into an area or - I shouldn't say intruding but treading into an area that the federal government has got a significant role - and telecommunications is one such area - there's always this question of whether Congress has intended to preempt states' role in that. KASTE: The federal agency with authority over ISPs is the FCC, and it's not saying whether it thinks the states are intruding on its turf. Jim Halpert is a lawyer for a coalition of tech companies which includes ISP. He says it may come down to how well the states write their rules. He says some of them have been overreaching. He calls it the meat-axe approach. JIM HALPERT: If you categorically say you cannot collect information or disclose information, that's what the internet does. (Laughter) It - having a barrier to that unless a user consents is likely to result in frustrating consumers, and it's also likely to be unconstitutional. KASTE: Halpert says states can expect to spend some tax dollars defending laws like that in court. Ernesto Falcon is legislative council for the Electronic Frontier Foundation, which is one of the groups that fought to keep the stricter federal privacy rules. ERNESTO FALCON: I think in the long term this is something that either the federal judiciary or Congress will have to resolve. In the short term, though, because you really do have a clear gap in privacy protections now, the states are going to have to fill the void. KASTE: But he also agrees that the states that passed their own ISP privacy laws can expect things to get litigious. Martin Kaste, NPR News. (SOUNDBITE OF THE STROKES SONG, \"REPTILIA\") AUDIE CORNISH, HOST:  Privacy groups lost a major battle when Congress and President Trump canceled Internet privacy rules written under the Obama administration. The regulations prevented Internet service providers from selling your web browsing history to third parties, and they were stricter than rules for other kinds of Internet firms. But as NPR's Martin Kaste reports, the fight's not over. It's just moved to the states. MARTIN KASTE, BYLINE: Drew Hansen is a Democrat in the Washington State House, and Internet privacy policy is not something he usually deals with. But that's changing after this action by Congress. DREW HANSEN: One of my constituents emailed me and said, I'm outraged that Congress is going to allow Internet service providers to sell my browsing history; can we do anything about that? And I said, well, I don't know. That's a great question. Let me find out. KASTE: He talked to the lawyers, and they didn't see why he couldn't just introduce legislation for a state version of the privacy rules that Congress had just canceled. HANSEN: Well, there's no conflict here. I mean the federal entities have just chosen not to act. Federal law in this area is a floor rather than a ceiling. There's nothing to protect states from being more protective of privacy than the federal government has chosen to do. KASTE: And he's not alone in thinking this way. Legislators around the country are responding to public anger and introducing ISP privacy bills in Minnesota, Illinois, Maryland. The list keeps growing. But is it really true that there's no conflict here with the feds? Blake Reid is an expert on telecom law at the University of Colorado. BLAKE REID: Anytime states are intruding into an area or - I shouldn't say intruding but treading into an area that the federal government has got a significant role - and telecommunications is one such area - there's always this question of whether Congress has intended to preempt states' role in that. KASTE: The federal agency with authority over ISPs is the FCC, and it's not saying whether it thinks the states are intruding on its turf. Jim Halpert is a lawyer for a coalition of tech companies which includes ISP. He says it may come down to how well the states write their rules. He says some of them have been overreaching. He calls it the meat-axe approach. JIM HALPERT: If you categorically say you cannot collect information or disclose information, that's what the internet does. (Laughter) It - having a barrier to that unless a user consents is likely to result in frustrating consumers, and it's also likely to be unconstitutional. KASTE: Halpert says states can expect to spend some tax dollars defending laws like that in court. Ernesto Falcon is legislative council for the Electronic Frontier Foundation, which is one of the groups that fought to keep the stricter federal privacy rules. ERNESTO FALCON: I think in the long term this is something that either the federal judiciary or Congress will have to resolve. In the short term, though, because you really do have a clear gap in privacy protections now, the states are going to have to fill the void. KASTE: But he also agrees that the states that passed their own ISP privacy laws can expect things to get litigious. Martin Kaste, NPR News. (SOUNDBITE OF THE STROKES SONG, \"REPTILIA\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-04-11-523313829": {"title": "American Citizens Are Subject To Having Their Cellphones Searched At The Border, The Government Says : NPR", "url": "https://www.npr.org/2017/04/11/523313829/more-travelers-are-being-asked-for-their-cellphones-and-passwords-entering-u-s", "author": "No author found", "published_date": "2017-04-11", "content": "", "section": "Politics", "disclaimer": ""}, "2017-04-11-522246173": {"title": "Wireless Industry Lobbies Statehouses For Access To 'Street Furniture' : NPR", "url": "https://www.npr.org/2017/04/11/522246173/wireless-industry-lobbies-statehouses-for-access-to-street-furniture", "author": "No author found", "published_date": "2017-04-11", "content": "", "section": "Politics", "disclaimer": ""}, "2017-04-16-524177364": {"title": "Selling Your Internet Browsing History : NPR", "url": "https://www.npr.org/2017/04/16/524177364/selling-your-internet-browsing-history", "author": "No author found", "published_date": "2017-04-16", "content": "LOURDES GARCIA-NAVARRO, HOST: Congress last month repealed a set of regulations that would have put hefty restrictions on Internet service providers. So what do these companies know about us, and what can they do with that information? NPR tech reporter Alina Selyukh told us what the rules were and what the repeal means. ALINA SELYUKH, BYLINE: The rules were meant to give people more control over the data that the Internet providers collect about them. Telecom and cable companies were supposed to start getting explicit consent from customers before selling some of the more sensitive information, things related to finances or health. And there were other requirements for increased transparency and security. GARCIA-NAVARRO: So they were going to have to get your actual consent before they could sell that information, right? SELYUKH: The technical term was opt in. GARCIA-NAVARRO: So given that those rules won't be going into effect, does that mean, let's say, my Internet provider - say Comcast - can sell to an advertiser a package that says here's what Lulu Garcia-Navarro reads online and watches on TV? SELYUKH: Well, so practically that's unlikely. You might have seen some stories of activists pouncing back against the lawmakers who repealed the rules. Folks were raising tons of money online, tens of thousands of dollars, to presumably buy the browsing history and other data about those lawmakers themselves - sort of you sold our privacy, well, we will buy yours. But that's not exactly how this market works. You can't go to Comcast and say, give me everything you've got on Senator Jeff Flake. And frankly, the advertisers don't really sit around and say, let's go after Lulu or Alina. They say, let's go after all women in a particular age group in the Washington area, and then, they buy ad targeting for individuals in that cohort. GARCIA-NAVARRO: OK. So what data do Internet providers actually collect then? SELYUKH: A lot of what they know, the advertisers can actually already get elsewhere. However, in aggregate, these companies do see a lot - what websites you visit, what links your click, maybe even connect to your profile across multiple devices. GARCIA-NAVARRO: Sounds creepy. SELYUKH: One important caveat to that is that encryption blocks out some of your activity. So if you see a secured link that starts with HTPPS (ph) - the S is the important part, not just HTPP (ph) but HTTPS - that means a third party should not see what you click or do on that page. GARCIA-NAVARRO: All right. Does this activity now go completely unregulated after Congress sort of blocked this legislation taking force? SELYUKH: So since the privacy rule has been blocked, as, you say, a few things have happened. The companies themselves the Internet service providers, have gone on a campaign. They're reassuring users that they do offer opt-outs. Now, they're not opt-ins, but they're opt-outs. And also they say that they do not and will not sell people's individual browsing history. They might use this history but - to tailor ads - but they do not sell it to third parties. One thing that the angry customers have prompted is interest from lawmakers in a bunch of states - to name a few, Massachusetts, Maryland, Minnesota, I randomly picked a bunch of M's - these lawmakers are tackling Internet privacy laws. They're debating them on a state level. GARCIA-NAVARRO: So we may see a change soon. All right. Alina Selyukh, she reports on technology for NPR. Thanks so much. SELYUKH: Thank you. LOURDES GARCIA-NAVARRO, HOST:  Congress last month repealed a set of regulations that would have put hefty restrictions on Internet service providers. So what do these companies know about us, and what can they do with that information? NPR tech reporter Alina Selyukh told us what the rules were and what the repeal means. ALINA SELYUKH, BYLINE: The rules were meant to give people more control over the data that the Internet providers collect about them. Telecom and cable companies were supposed to start getting explicit consent from customers before selling some of the more sensitive information, things related to finances or health. And there were other requirements for increased transparency and security. GARCIA-NAVARRO: So they were going to have to get your actual consent before they could sell that information, right? SELYUKH: The technical term was opt in. GARCIA-NAVARRO: So given that those rules won't be going into effect, does that mean, let's say, my Internet provider - say Comcast - can sell to an advertiser a package that says here's what Lulu Garcia-Navarro reads online and watches on TV? SELYUKH: Well, so practically that's unlikely. You might have seen some stories of activists pouncing back against the lawmakers who repealed the rules. Folks were raising tons of money online, tens of thousands of dollars, to presumably buy the browsing history and other data about those lawmakers themselves - sort of you sold our privacy, well, we will buy yours. But that's not exactly how this market works. You can't go to Comcast and say, give me everything you've got on Senator Jeff Flake. And frankly, the advertisers don't really sit around and say, let's go after Lulu or Alina. They say, let's go after all women in a particular age group in the Washington area, and then, they buy ad targeting for individuals in that cohort. GARCIA-NAVARRO: OK. So what data do Internet providers actually collect then? SELYUKH: A lot of what they know, the advertisers can actually already get elsewhere. However, in aggregate, these companies do see a lot - what websites you visit, what links your click, maybe even connect to your profile across multiple devices. GARCIA-NAVARRO: Sounds creepy. SELYUKH: One important caveat to that is that encryption blocks out some of your activity. So if you see a secured link that starts with HTPPS (ph) - the S is the important part, not just HTPP (ph) but HTTPS - that means a third party should not see what you click or do on that page. GARCIA-NAVARRO: All right. Does this activity now go completely unregulated after Congress sort of blocked this legislation taking force? SELYUKH: So since the privacy rule has been blocked, as, you say, a few things have happened. The companies themselves the Internet service providers, have gone on a campaign. They're reassuring users that they do offer opt-outs. Now, they're not opt-ins, but they're opt-outs. And also they say that they do not and will not sell people's individual browsing history. They might use this history but - to tailor ads - but they do not sell it to third parties. One thing that the angry customers have prompted is interest from lawmakers in a bunch of states - to name a few, Massachusetts, Maryland, Minnesota, I randomly picked a bunch of M's - these lawmakers are tackling Internet privacy laws. They're debating them on a state level. GARCIA-NAVARRO: So we may see a change soon. All right. Alina Selyukh, she reports on technology for NPR. Thanks so much. SELYUKH: Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-04-17-524393092": {"title": "Facebook Cracks Down On 30,000 Fake Accounts In France : NPR", "url": "https://www.npr.org/2017/04/17/524393092/facebook-cracks-down-on-30-000-fake-accounts-in-france", "author": "No author found", "published_date": "2017-04-17", "content": "ROBERT SIEGEL, HOST: After the U. S. presidential election, Facebook CEO Mark Zuckerberg had dismissed the idea that his company had provided a platform for the spread of false information and conspiracy theories. But now Facebook is working with authorities in 14 countries to stop the spread of fake news. We're joined by NPR's Eleanor Beardsley in Paris to hear how this is playing out in France. And, Eleanor, is there a concern that fake news could influence the French election on Sunday? ELEANOR BEARDSLEY, BYLINE: Absolutely, yes. You know, there are alternative news sites and media of every ilk here operating. And some candidates have already been complaining about it. Emmanuel Macron, who is a frontrunner with far-right leader Marine Le Pen, says he's being targeted by conspiracy theories about his private life, also about his finances that because he's a former investment banker, he's hiding millions. He actually had to go on the radio today and dispel rumors and talk about exactly where his money came from and, you know, where it went. And so a lot of information that may be false information is - seems to support anti-immigration stances of Marine Le Pen, you know, videos showing migrants attacking a nurse in a hospital. Only it turned out this video was in a Russian hospital several months ago, even though it says a French hospital today. So there's a lot of conspiracy theories swirling also around the pro-Russian sites. There's fears that Russia will influence this election. And French President Francois Hollande publicly warned Russia not to interfere in the French election. SIEGEL: What are the sources typically of the fake news? Does it come from Russia? BEARDSLEY: Well, some of it does. Russia Today and Sputnik have been cited as perpetrators of conspiracy theories. And there are a lot of independent websites. Many are linked to far-right causes. And then Facebook because people share videos, people share news stories. And it looks like it's coming from a good friend so you can trust it. And so this is how things spread. And that's what Facebook wants to stop. SIEGEL: So what is Facebook doing to stop it? BEARDSLEY: Well, Facebook has developed an algorithm to detect accounts that are not linked to a person and a specific identity. So they're finding accounts that are just resending out masses of information, you know, spam. And that's what they're shutting down. They have shut down 30,000 false accounts in France. But there's actually no human involvement in this, Robert, it's just an algorithm that detects accounts that are sending out masses amount of the same information. SIEGEL: Now, fake news is not something new in French politics, is it? BEARDSLEY: No, Robert, it absolutely isn't. I spoke with the editorial director of newspaper Le Monde. And she said fake news has been around for a long time, identified with the far-right. She said after the terrorist attacks in 2015, there were a lot of conspiracy theories. And here's what Sylvie Kaufman told me. SYLVIE KAUFMAN: This kind of inflammatory false discourse and manipulated facts has been familiar for some time but we didn't have social networks, we didn't have the Internet. And so the amplification was not so large. So it was an issue but it was not such a big issue. And also, I would say the authority, the moral authority of mainstream media like Le Monde was bigger. BEARDSLEY: Kaufman says we're in a very different media environment. They're taking it seriously. Le Monde has a whole team now dedicated to debunking fake news. And they have online software that readers can use to verify sources. SIEGEL: That's NPR's Eleanor Beardsley in Paris. Eleanor, thanks. BEARDSLEY: You're welcome, Robert. (SOUNDBITE OF MUSIC) ROBERT SIEGEL, HOST:  After the U. S. presidential election, Facebook CEO Mark Zuckerberg had dismissed the idea that his company had provided a platform for the spread of false information and conspiracy theories. But now Facebook is working with authorities in 14 countries to stop the spread of fake news. We're joined by NPR's Eleanor Beardsley in Paris to hear how this is playing out in France. And, Eleanor, is there a concern that fake news could influence the French election on Sunday? ELEANOR BEARDSLEY, BYLINE: Absolutely, yes. You know, there are alternative news sites and media of every ilk here operating. And some candidates have already been complaining about it. Emmanuel Macron, who is a frontrunner with far-right leader Marine Le Pen, says he's being targeted by conspiracy theories about his private life, also about his finances that because he's a former investment banker, he's hiding millions. He actually had to go on the radio today and dispel rumors and talk about exactly where his money came from and, you know, where it went. And so a lot of information that may be false information is - seems to support anti-immigration stances of Marine Le Pen, you know, videos showing migrants attacking a nurse in a hospital. Only it turned out this video was in a Russian hospital several months ago, even though it says a French hospital today. So there's a lot of conspiracy theories swirling also around the pro-Russian sites. There's fears that Russia will influence this election. And French President Francois Hollande publicly warned Russia not to interfere in the French election. SIEGEL: What are the sources typically of the fake news? Does it come from Russia? BEARDSLEY: Well, some of it does. Russia Today and Sputnik have been cited as perpetrators of conspiracy theories. And there are a lot of independent websites. Many are linked to far-right causes. And then Facebook because people share videos, people share news stories. And it looks like it's coming from a good friend so you can trust it. And so this is how things spread. And that's what Facebook wants to stop. SIEGEL: So what is Facebook doing to stop it? BEARDSLEY: Well, Facebook has developed an algorithm to detect accounts that are not linked to a person and a specific identity. So they're finding accounts that are just resending out masses of information, you know, spam. And that's what they're shutting down. They have shut down 30,000 false accounts in France. But there's actually no human involvement in this, Robert, it's just an algorithm that detects accounts that are sending out masses amount of the same information. SIEGEL: Now, fake news is not something new in French politics, is it? BEARDSLEY: No, Robert, it absolutely isn't. I spoke with the editorial director of newspaper Le Monde. And she said fake news has been around for a long time, identified with the far-right. She said after the terrorist attacks in 2015, there were a lot of conspiracy theories. And here's what Sylvie Kaufman told me. SYLVIE KAUFMAN: This kind of inflammatory false discourse and manipulated facts has been familiar for some time but we didn't have social networks, we didn't have the Internet. And so the amplification was not so large. So it was an issue but it was not such a big issue. And also, I would say the authority, the moral authority of mainstream media like Le Monde was bigger. BEARDSLEY: Kaufman says we're in a very different media environment. They're taking it seriously. Le Monde has a whole team now dedicated to debunking fake news. And they have online software that readers can use to verify sources. SIEGEL: That's NPR's Eleanor Beardsley in Paris. Eleanor, thanks. BEARDSLEY: You're welcome, Robert. (SOUNDBITE OF MUSIC)", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-04-17-523772071": {"title": "At Intel, A Retirement Perk That Can Kick Off A New Career As A Paid Fellow : NPR", "url": "https://www.npr.org/2017/04/17/523772071/at-intel-a-retirement-perk-that-can-kick-off-a-new-career-as-a-paid-fellow", "author": "No author found", "published_date": "2017-04-17", "content": "STEVE INSKEEP, HOST: Not everybody who reaches the so-called retirement age is ready to retire, but they may be ready for a change. And Intel would like some of its employees to have some help. Since 2012, the tech giant has paid some of its retirees a stipend while they try out completely new jobs at nonprofit organizations. NPR's Ina Jaffe reports on encore careers. INA JAFFE, BYLINE: Sixty-one-year-old Gail Dockerty is poring over a spreadsheet on her computer at the Virginia Garcia Memorial Health Center in Oregon. The former Intel project manager is combining patient data with input from doctors and nurses. She's trying to figure out a better way of delivering care to the center's high number of patients with diabetes. GAIL DOCKERTY: So I took that body of data. And from that out of my own non-medical, non-health care world had kind of proposed a workflow that seemed like from what I was hearing might be the most helpful thing for our patients. JAFFE: Those patients are migrant workers and others who have no health insurance or who qualify for Medicaid. Dockerty says the skills from her old job fit in with the mission here, even though the two jobs couldn't be more different. DOCKERTY: At Intel, deadlines are king. You've got a product. You've got to get it out either first or by the time you promised. Schedules are key. Here, not so much because what's primary is the patient care. JAFFE: Dockerty is what's known as an Encore Fellow. She'll work at the health center part time for about a year and receive a stipend of $25,000. This is part of a nationwide program started by encore. org to bring retiring corporate workers into mission-driven organizations. You may have heard messages about it on NPR and other media outlets. But Intel is the only company that pays the stipend for its retiree's fellowships as a basic employee benefit. In the past five years, it's meant about a thousand fellowships at a cost to the company of more than $30 million. OGDEN REID: But in the scheme of our total labor costs, it's a very small number. JAFFE: Says Ogden Reid, Intel's vice president for human resources. REID: We feel like we're helping our communities. Our retirees give us really positive feedback about it. And our workforce that's here see that happening to folks who've had a long career. And I think that makes them feel good about the company. JAFFE: Right now, there are seven Encore Fellows at the Virginia Garcia Memorial Health Center. Gil Munoz, the CEO, says they play a crucial role. GIL MUNOZ: They bring a certain discipline, certain rigor to looking at problems and solving them. And having these Encore Fellows who could help lead a project can be the key to whether it's successful or not. JAFFE: That may be why 73-year-old Jinny Meade's still here. She came to the health center a couple of years ago as an Encore Fellow. Now she's a permanent part-time employee working as a project consultant. JINNY MEADE: I'm sort of the nag that helps them stay on track as much as possible. JAFFE: And it's not just the management skill she can bring to Virginia Garcia that she finds rewarding, it's what she's getting back. MEADE: It's really exciting to be part of something that's sort of bigger than ourselves. And health care for the underserved is a worthy cause. JAFFE: And in Meade's case, a second career. Ina Jaffe, NPR News. (SOUNDBITE OF U137's \"SLIDING DOORS\") STEVE INSKEEP, HOST:  Not everybody who reaches the so-called retirement age is ready to retire, but they may be ready for a change. And Intel would like some of its employees to have some help. Since 2012, the tech giant has paid some of its retirees a stipend while they try out completely new jobs at nonprofit organizations. NPR's Ina Jaffe reports on encore careers. INA JAFFE, BYLINE: Sixty-one-year-old Gail Dockerty is poring over a spreadsheet on her computer at the Virginia Garcia Memorial Health Center in Oregon. The former Intel project manager is combining patient data with input from doctors and nurses. She's trying to figure out a better way of delivering care to the center's high number of patients with diabetes. GAIL DOCKERTY: So I took that body of data. And from that out of my own non-medical, non-health care world had kind of proposed a workflow that seemed like from what I was hearing might be the most helpful thing for our patients. JAFFE: Those patients are migrant workers and others who have no health insurance or who qualify for Medicaid. Dockerty says the skills from her old job fit in with the mission here, even though the two jobs couldn't be more different. DOCKERTY: At Intel, deadlines are king. You've got a product. You've got to get it out either first or by the time you promised. Schedules are key. Here, not so much because what's primary is the patient care. JAFFE: Dockerty is what's known as an Encore Fellow. She'll work at the health center part time for about a year and receive a stipend of $25,000. This is part of a nationwide program started by encore. org to bring retiring corporate workers into mission-driven organizations. You may have heard messages about it on NPR and other media outlets. But Intel is the only company that pays the stipend for its retiree's fellowships as a basic employee benefit. In the past five years, it's meant about a thousand fellowships at a cost to the company of more than $30 million. OGDEN REID: But in the scheme of our total labor costs, it's a very small number. JAFFE: Says Ogden Reid, Intel's vice president for human resources. REID: We feel like we're helping our communities. Our retirees give us really positive feedback about it. And our workforce that's here see that happening to folks who've had a long career. And I think that makes them feel good about the company. JAFFE: Right now, there are seven Encore Fellows at the Virginia Garcia Memorial Health Center. Gil Munoz, the CEO, says they play a crucial role. GIL MUNOZ: They bring a certain discipline, certain rigor to looking at problems and solving them. And having these Encore Fellows who could help lead a project can be the key to whether it's successful or not. JAFFE: That may be why 73-year-old Jinny Meade's still here. She came to the health center a couple of years ago as an Encore Fellow. Now she's a permanent part-time employee working as a project consultant. JINNY MEADE: I'm sort of the nag that helps them stay on track as much as possible. JAFFE: And it's not just the management skill she can bring to Virginia Garcia that she finds rewarding, it's what she's getting back. MEADE: It's really exciting to be part of something that's sort of bigger than ourselves. And health care for the underserved is a worthy cause. JAFFE: And in Meade's case, a second career. Ina Jaffe, NPR News. (SOUNDBITE OF U137's \"SLIDING DOORS\")", "section": "Business", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-04-18-524569185": {"title": "Trump's Latest Executive Order Targets High Skilled Worker Visa Program : NPR", "url": "https://www.npr.org/2017/04/18/524569185/trumps-latest-executive-order-targets-high-skilled-worker-visa-program", "author": "No author found", "published_date": "2017-04-18", "content": "KELLY MCEVERS, HOST: As we just heard, one of the key parts of this new executive order has to do with a popular visa program for highly skilled workers called H-1B. The majority of these visas go to tech jobs, making this a major policy priority for companies in that field. NPR's tech reporter Alina Selyukh is here to tell us what the president's new order means for the industry. Hey there. ALINA SELYUKH, BYLINE: Hi. MCEVERS: So why are H-1Bs the focus of the president's latest immigration order? SELYUKH: Well, as we just heard Scott say earlier, the majority of H-1B workers across tech and other professions, I have to say - they are paid less than an American worker would get in the same job. And we often hear that there's a shortage of skilled tech workers in the country, but then what does it mean when H-1B workers are paid less than American workers would get paid? Here's how Daniel Costa put it. He's an immigration expert at the Economic Policy Institute which focuses on low- and middle-income workers. DANIEL COSTA: What that tells me is that either employers are using the H-1B program to hire many, many skilled workers and then underpaying them when they're here, or they're using it to hire entry-level workers. SELYUKH: And overall, this creates a really skewed workplace for everyone involved. MCEVERS: Which tech companies rely the most on H-1B visas? SELYUKH: The kinds of companies that often get singled out here are firms based in India that do IT contracting. When they get hired on, they're often accused of bringing workers from overseas to replace U. S. workers at cheaper wages, sometimes even shipping the same workers right back to completely move the job overseas. And the key problem here is that the H-1B visa is handed out by a lottery. It's totally random. And Indian IT companies flood the system with applications, and they just win with sheer volume. And so for years, there's been talk of replacing the lottery with something less arbitrary. And Trump's proposal suggests a system that would prioritize visas for the highest-paying jobs. MCEVERS: So could that be a good thing for the companies that are competing for these H-1B slots? SELYUKH: Probably. The important thing to note here is that we are just starting to receive the specifics of the order. Giving priority to higher-paying jobs could really weed out the low-skilled workers who are masquerading as irreplaceable experts who cannot be found in the United States. But how affordable this kind of competition will be to small companies, how this whole system works - all of that will be hashed out over the next few months. But most importantly, Costa and other experts always point out that the executive order can only do fixes around the margins. Trump here is directing agencies to study their power to fix the program, but whatever they do is likely to be challenged in court, and a kind of durable change really requires Congress. MCEVERS: And what have you heard from people in the tech sector about the president's order? SELYUKH: I think the favorite Washington cliche really applies here. They're saying they're cautiously optimistic. Or as one official put it, at least they're not pessimistic. There's really nothing terrible here for them. They like the idea of replacing the lottery with a merit-based system. They like the idea of reining in abuses. But frankly, what we're really likely to see is a really long process over which this gets hashed out. The tech industry does not want it to be harder for the domestic companies to hire foreign talent. Ultimately they ideally would actually want the program to be bigger and give them more H-1B slots, but those are the kinds of things that can only be hashed out in Congress. There are several bills which we may or may not see really heat up in the next few months. MCEVERS: NPR tech reporter Alina Selyukh, thank you. SELYUKH: Thank you. KELLY MCEVERS, HOST:  As we just heard, one of the key parts of this new executive order has to do with a popular visa program for highly skilled workers called H-1B. The majority of these visas go to tech jobs, making this a major policy priority for companies in that field. NPR's tech reporter Alina Selyukh is here to tell us what the president's new order means for the industry. Hey there. ALINA SELYUKH, BYLINE: Hi. MCEVERS: So why are H-1Bs the focus of the president's latest immigration order? SELYUKH: Well, as we just heard Scott say earlier, the majority of H-1B workers across tech and other professions, I have to say - they are paid less than an American worker would get in the same job. And we often hear that there's a shortage of skilled tech workers in the country, but then what does it mean when H-1B workers are paid less than American workers would get paid? Here's how Daniel Costa put it. He's an immigration expert at the Economic Policy Institute which focuses on low- and middle-income workers. DANIEL COSTA: What that tells me is that either employers are using the H-1B program to hire many, many skilled workers and then underpaying them when they're here, or they're using it to hire entry-level workers. SELYUKH: And overall, this creates a really skewed workplace for everyone involved. MCEVERS: Which tech companies rely the most on H-1B visas? SELYUKH: The kinds of companies that often get singled out here are firms based in India that do IT contracting. When they get hired on, they're often accused of bringing workers from overseas to replace U. S. workers at cheaper wages, sometimes even shipping the same workers right back to completely move the job overseas. And the key problem here is that the H-1B visa is handed out by a lottery. It's totally random. And Indian IT companies flood the system with applications, and they just win with sheer volume. And so for years, there's been talk of replacing the lottery with something less arbitrary. And Trump's proposal suggests a system that would prioritize visas for the highest-paying jobs. MCEVERS: So could that be a good thing for the companies that are competing for these H-1B slots? SELYUKH: Probably. The important thing to note here is that we are just starting to receive the specifics of the order. Giving priority to higher-paying jobs could really weed out the low-skilled workers who are masquerading as irreplaceable experts who cannot be found in the United States. But how affordable this kind of competition will be to small companies, how this whole system works - all of that will be hashed out over the next few months. But most importantly, Costa and other experts always point out that the executive order can only do fixes around the margins. Trump here is directing agencies to study their power to fix the program, but whatever they do is likely to be challenged in court, and a kind of durable change really requires Congress. MCEVERS: And what have you heard from people in the tech sector about the president's order? SELYUKH: I think the favorite Washington cliche really applies here. They're saying they're cautiously optimistic. Or as one official put it, at least they're not pessimistic. There's really nothing terrible here for them. They like the idea of replacing the lottery with a merit-based system. They like the idea of reining in abuses. But frankly, what we're really likely to see is a really long process over which this gets hashed out. The tech industry does not want it to be harder for the domestic companies to hire foreign talent. Ultimately they ideally would actually want the program to be bigger and give them more H-1B slots, but those are the kinds of things that can only be hashed out in Congress. There are several bills which we may or may not see really heat up in the next few months. MCEVERS: NPR tech reporter Alina Selyukh, thank you. SELYUKH: Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-04-19-524751641": {"title": "President Trump's New Order Gives China Tech Opportunity To 'Hire American' Too : NPR", "url": "https://www.npr.org/2017/04/19/524751641/president-trumps-new-order-gives-china-tech-opportunity-to-hire-american-too", "author": "No author found", "published_date": "2017-04-19", "content": "ROBERT SIEGEL, HOST: This week, President Trump issued a new executive order to hire American. The president of one of China's largest technology companies is echoing Trump's call. He too would like to hire American. NPR's Aarti Shahani checked out his recruitment efforts at Stanford University. AARTI SHAHANI, BYLINE: Ya-Qin Zhang was a child prodigy. He got his master's degree at age 18 in China. And he came to the U. S. for his Ph. D. in electrical engineering. He went to work for Microsoft alongside Bill Gates. And there, Zhang learned a big lesson - not about tech but about hiring, a lesson he wants to apply to his current company, Baidu. YA-QIN ZHANG: For Baidu to become a global company, we need to attract the very best, not only from China but also from companies here from the top universities in the world. SHAHANI: Baidu is one of China's Internet giants, the Google of China many say. And while at first it was focused on building products for Chinese nationals, today it wants to lead in the international race to build mobile apps and self-driving cars. But its workforce is, compared to American tech, very homogenous. Of Baidu's roughly 40,000 employees, around 1 percent are non-Chinese. ZHANG: For China to become a world leader in technology, I think China needs to attract more. And this is also being encouraged, you know, by the administration, by the Chinese government. You know, there are new visas, new green cards issued. SHAHANI: According to Chinese state media, the number of permanent residency cards issued in that country is on the rise. In 2016, about 1,500 foreigners were approved, a more than 160 percent increase from the year before. Again, these are tiny numbers in a country of 1. 4 billion people but Zhang is here at Stanford to let students know things are changing. ZHANG: We welcome, you know, students of different culture, different nationality. And, you know, talents has no border. UNIDENTIFIED WOMAN: (Speaking Chinese). (APPLAUSE)SHAHANI: When Zhang stepped out of his interview with NPR and into his recruitment event, it wasn't quite what he had in mind. He'd said he'd hoped for American students to come but the room was packed - standing room only - with Chinese students. Still, he conducted the event in English and made the same kinds of stock promises that tech execs here make to young recruits. ZHANG: Young folks, you know, who just join a company are taking big responsibilities - stretch them, give them pressure, you know, challenges. SHAHANI: When he was done, talking more than a hundred students lined up to speak with a Baidu recruiter. Among them was Angel Hu. The 22-year-old student at Stanford engineering says in the past, a person like her would have come here and wanted to get a job in Silicon Valley but now China has high growth companies. And while she is not particularly interested in U. S. politics, President Trump has had an effect on her. When he announced the ban on travel from majority Muslim countries, for example, she's not Muslim but she took it to heart. ANGEL HU: As a foreigner when I came here facing such kind of political issues and situation, I feel a little bit maybe dangerous, unpredictive (ph) and unsecure that make me think, like, maybe I should go back to some society that I'm more familiar with. SHAHANI: She and others crowded around the Baidu president to take a selfie before he left for the next leg of his U. S. recruitment tour. Aarti Shahani, NPR News, Palo Alto. ROBERT SIEGEL, HOST:  This week, President Trump issued a new executive order to hire American. The president of one of China's largest technology companies is echoing Trump's call. He too would like to hire American. NPR's Aarti Shahani checked out his recruitment efforts at Stanford University. AARTI SHAHANI, BYLINE: Ya-Qin Zhang was a child prodigy. He got his master's degree at age 18 in China. And he came to the U. S. for his Ph. D. in electrical engineering. He went to work for Microsoft alongside Bill Gates. And there, Zhang learned a big lesson - not about tech but about hiring, a lesson he wants to apply to his current company, Baidu. YA-QIN ZHANG: For Baidu to become a global company, we need to attract the very best, not only from China but also from companies here from the top universities in the world. SHAHANI: Baidu is one of China's Internet giants, the Google of China many say. And while at first it was focused on building products for Chinese nationals, today it wants to lead in the international race to build mobile apps and self-driving cars. But its workforce is, compared to American tech, very homogenous. Of Baidu's roughly 40,000 employees, around 1 percent are non-Chinese. ZHANG: For China to become a world leader in technology, I think China needs to attract more. And this is also being encouraged, you know, by the administration, by the Chinese government. You know, there are new visas, new green cards issued. SHAHANI: According to Chinese state media, the number of permanent residency cards issued in that country is on the rise. In 2016, about 1,500 foreigners were approved, a more than 160 percent increase from the year before. Again, these are tiny numbers in a country of 1. 4 billion people but Zhang is here at Stanford to let students know things are changing. ZHANG: We welcome, you know, students of different culture, different nationality. And, you know, talents has no border. UNIDENTIFIED WOMAN: (Speaking Chinese). (APPLAUSE) SHAHANI: When Zhang stepped out of his interview with NPR and into his recruitment event, it wasn't quite what he had in mind. He'd said he'd hoped for American students to come but the room was packed - standing room only - with Chinese students. Still, he conducted the event in English and made the same kinds of stock promises that tech execs here make to young recruits. ZHANG: Young folks, you know, who just join a company are taking big responsibilities - stretch them, give them pressure, you know, challenges. SHAHANI: When he was done, talking more than a hundred students lined up to speak with a Baidu recruiter. Among them was Angel Hu. The 22-year-old student at Stanford engineering says in the past, a person like her would have come here and wanted to get a job in Silicon Valley but now China has high growth companies. And while she is not particularly interested in U. S. politics, President Trump has had an effect on her. When he announced the ban on travel from majority Muslim countries, for example, she's not Muslim but she took it to heart. ANGEL HU: As a foreigner when I came here facing such kind of political issues and situation, I feel a little bit maybe dangerous, unpredictive (ph) and unsecure that make me think, like, maybe I should go back to some society that I'm more familiar with. SHAHANI: She and others crowded around the Baidu president to take a selfie before he left for the next leg of his U. S. recruitment tour. Aarti Shahani, NPR News, Palo Alto.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-04-19-524751571": {"title": "Car Design School Prepares For New Age Of Driverless Vehicles : NPR", "url": "https://www.npr.org/2017/04/19/524751571/car-design-school-prepares-for-new-age-of-driverless-vehicles", "author": "No author found", "published_date": "2017-04-19", "content": "KELLY MCEVERS, HOST: It's one thing to be uncomfortable with new apps or virtual reality. But when a car is driving itself down your street, that's different. Studies show Americans do not feel comfortable with autonomous vehicles or self-driving cars. But Detroit's Silicon Valley and Wall Street are spending billions on the new technology, and they need to figure out how to make people like it. To learn how they're doing that, NPR's Sonari Glinton went to car design school. SONARI GLINTON, BYLINE: Hello, I'm Sonari. UNIDENTIFIED MAN: Hey. GLINTON: Nice to meet you. In the hills above the Rose Bowl in Pasadena is ArtCenter College of Design. It's a very modern campus with breathtaking views. But here at this Jetsons-like campus, pardon the pun, the classrooms often look really old school. What am I not looking at? Hello. (LAUGHTER)ANSHAL MALHAN: So there's a visual communications class going on in that room right now. . . GLINTON: They design cars and almost every kind of high-tech transportation. In many ways, they've moved way beyond planes, trains and automobiles. Anshal Malhan is a graduate student in the transportation design program here at ArtCenter. MALHAN: This is where the second-term students. . . GLINTON: OK, so in here it's like there - can we go in? MALHAN: Yeah. GLINTON: I mean, it's like there's not very much of the wall that's not covered with Post-it notes or. . . MALHAN: Yeah, and what you notice is none of them have cars on it because that's not how we approach design. We approach it from the user first and then figure out what do we give them in the end. GLINTON: These grad students are working on their thesis projects. The assignment is not necessarily to design a self-driving car. That's been done many times before. It's really about making people feel comfortable. That's the hard part says Calvin Ku. His project is for the dyed in the wool driving enthusiast. CALVIN KU: Why can't our relationship with an autonomous car be more like a relationship with, say, a horse - a rider and a horse or two tango partners? GLINTON: OK, that's a big important idea to remember. The first autonomous vehicle was likely a horse. Now, in Ku's concept, there is no steering wheel. There are no pedals. But in the same sort of way you might lean back to slow down your horse, that's kind of what you would do in his car. There are these subtle knobs that help you communicate with the car, not necessarily command it. You're working with the car, influencing it the way you would influence a horse. So what are we looking at here? KU: I'm storyboarding an interaction with my enthusiast self-driving car of the future - so, say, 15 years from now. GLINTON: So you're imagining an enthusiast driving - what it looks like - this is on the Pacific Coast Highway, right? KU: Right. So this person is starting on Santa Monica. And there's a lot of traffic, so he doesn't want to drive. He's just going to read a book. But five hours later, they've reached Big Sur, a part of Big Sur where the car - since they've kind of created a relationship with each other, you know, kind of like the dog that knows your favorite spots to run with it. This car knows your favorite spot on Highway 1, you know, the windy fun roads, you know? GLINTON: The idea is that over the years, your car becomes your playmate, not just an appliance. MALHAN: This is all of ours. GLINTON: This is your wall? (Laughter) Wow. MALHAN: We can show you a package that we finalized for the family in 2030. GLINTON: Oh, look, a car designer using paper. MALHAN: Yes. So this is a lay out that we finalized after primary research with families. GLINTON: What Anshal Malhan is doing is critical. Though on the surface it seems touchy feely, well, that's because it is. The big barrier to autonomous vehicles besides the obvious legal ones is making people trust them. Until my buddy Steve feels absolutely totally completely at ease putting his family into one of these self-driving cars, he won't and neither will you. MALHAN: So your friend Steve right now has the responsibility of being a father, a driver and a route follower. What we're trying to do is, with autonomy, keep him a father in the car and outside the car. So he's able to give more family time, you know, better quality family time. GLINTON: I have a predication - the rate of pull-my-finger jokes is going to go up exponentially in the age of autonomous cars. At least that's what these students are banking their future on and ours. Sonari Glinton, NPR News. (SOUNDBITE OF IV THE POLYMATH SONG, \"BLUEBERRY SPY\") KELLY MCEVERS, HOST:  It's one thing to be uncomfortable with new apps or virtual reality. But when a car is driving itself down your street, that's different. Studies show Americans do not feel comfortable with autonomous vehicles or self-driving cars. But Detroit's Silicon Valley and Wall Street are spending billions on the new technology, and they need to figure out how to make people like it. To learn how they're doing that, NPR's Sonari Glinton went to car design school. SONARI GLINTON, BYLINE: Hello, I'm Sonari. UNIDENTIFIED MAN: Hey. GLINTON: Nice to meet you. In the hills above the Rose Bowl in Pasadena is ArtCenter College of Design. It's a very modern campus with breathtaking views. But here at this Jetsons-like campus, pardon the pun, the classrooms often look really old school. What am I not looking at? Hello. (LAUGHTER) ANSHAL MALHAN: So there's a visual communications class going on in that room right now. . . GLINTON: They design cars and almost every kind of high-tech transportation. In many ways, they've moved way beyond planes, trains and automobiles. Anshal Malhan is a graduate student in the transportation design program here at ArtCenter. MALHAN: This is where the second-term students. . . GLINTON: OK, so in here it's like there - can we go in? MALHAN: Yeah. GLINTON: I mean, it's like there's not very much of the wall that's not covered with Post-it notes or. . . MALHAN: Yeah, and what you notice is none of them have cars on it because that's not how we approach design. We approach it from the user first and then figure out what do we give them in the end. GLINTON: These grad students are working on their thesis projects. The assignment is not necessarily to design a self-driving car. That's been done many times before. It's really about making people feel comfortable. That's the hard part says Calvin Ku. His project is for the dyed in the wool driving enthusiast. CALVIN KU: Why can't our relationship with an autonomous car be more like a relationship with, say, a horse - a rider and a horse or two tango partners? GLINTON: OK, that's a big important idea to remember. The first autonomous vehicle was likely a horse. Now, in Ku's concept, there is no steering wheel. There are no pedals. But in the same sort of way you might lean back to slow down your horse, that's kind of what you would do in his car. There are these subtle knobs that help you communicate with the car, not necessarily command it. You're working with the car, influencing it the way you would influence a horse. So what are we looking at here? KU: I'm storyboarding an interaction with my enthusiast self-driving car of the future - so, say, 15 years from now. GLINTON: So you're imagining an enthusiast driving - what it looks like - this is on the Pacific Coast Highway, right? KU: Right. So this person is starting on Santa Monica. And there's a lot of traffic, so he doesn't want to drive. He's just going to read a book. But five hours later, they've reached Big Sur, a part of Big Sur where the car - since they've kind of created a relationship with each other, you know, kind of like the dog that knows your favorite spots to run with it. This car knows your favorite spot on Highway 1, you know, the windy fun roads, you know? GLINTON: The idea is that over the years, your car becomes your playmate, not just an appliance. MALHAN: This is all of ours. GLINTON: This is your wall? (Laughter) Wow. MALHAN: We can show you a package that we finalized for the family in 2030. GLINTON: Oh, look, a car designer using paper. MALHAN: Yes. So this is a lay out that we finalized after primary research with families. GLINTON: What Anshal Malhan is doing is critical. Though on the surface it seems touchy feely, well, that's because it is. The big barrier to autonomous vehicles besides the obvious legal ones is making people trust them. Until my buddy Steve feels absolutely totally completely at ease putting his family into one of these self-driving cars, he won't and neither will you. MALHAN: So your friend Steve right now has the responsibility of being a father, a driver and a route follower. What we're trying to do is, with autonomy, keep him a father in the car and outside the car. So he's able to give more family time, you know, better quality family time. GLINTON: I have a predication - the rate of pull-my-finger jokes is going to go up exponentially in the age of autonomous cars. At least that's what these students are banking their future on and ours. Sonari Glinton, NPR News. (SOUNDBITE OF IV THE POLYMATH SONG, \"BLUEBERRY SPY\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-04-21-524701908": {"title": "Marco Annunziata: What Will Human-Machine Collaboration Mean For Our Jobs? : NPR", "url": "https://www.npr.org/2017/04/21/524701908/marco-annunziata-what-will-human-machine-collaboration-mean-for-our-jobs", "author": "No author found", "published_date": "2017-04-21", "content": "GUY RAZ, HOST: It's the TED Radio Hour from NPR. I'm Guy Raz. And on the show today, ideas about the digital industrial revolution and whether we should be worried or excited. MARCO ANNUNZIATA: I am definitely an optimist. RAZ: This is Marco Annunziata. Marco's the chief economist at General Electric. ANNUNZIATA: I am aware as an economist being optimistic is kind of out of character, but I feel there are too many gloomy people out there, so I'm happpy to do my bit. RAZ: One of Marco's main jobs is to predict what our jobs will look like in the future. And he says, not surprisingly, that in the next five to 10 to 20 years, almost everything about the workplace is going to change. ANNUNZIATA: There will be a new and different form of interaction between humans and machines, both physical machines like robots and virtual machines like artificial intelligence. RAZ: So - I don't know - if you can take us on a tour of that future, what does a normal person's day going to kind of be like at work? What are they going to experience? How are they going experience that? ANNUNZIATA: So I think they will experience it in the following way. They will come on to a factory floor. Onto the factory floor, they will find an environment which is a lot more intelligent than today. Everything around the worker, whether it's the equipment the worker interacts with, the different items on the factory floor, will be equipped with sensors constantly sending data to artificial intelligence machines that will be analyzing the data and everything that is going on. There will be robots helping the worker perform whatever functions are involved in the specific job description in a much more efficient and a much safer way. These are applications that make work better. RAZ: This collaboration between humans and machines is all part of what Marco calls the industrial Internet. (SOUNDBITE OF TED TALK)ANNUNZIATA: So what is this industrial Internet? RAZ: He explained the idea from the TED stage. (SOUNDBITE OF TED TALK)ANNUNZIATA: It brings together intelligent machines, advanced analytics and the creativity of people that work. Industrial machines are being equipped with a growing number of electronic sensors that allow them to see, hear, feel a lot more than ever before, generating prodigious amounts of data. Increasingly sophisticated analytics then sift through the data, providing insights that allow us to operate the machines in entirely new ways a lot more efficiently. And not just individual machines but fleets of locomotives, airplanes, entire systems like power grids, hospitals. Let's start with aviation. Today, 10 percent of all flights, cancellations and delays are due to unscheduled maintenance events. These results in $8 billion in costs for the airline industry globally every year, not to mention the impact on all of us - stress, inconvenience, missed meetings - as we sit helplessly in an airport terminal. So how can the industrial Internet help here? We've developed a preventive maintenance system which can be installed on any aircraft. It's self-learning and able to predict issues that a human operator would miss. The aircraft, while in flight, will communicate with technicians on the ground. By the time it lands, they will already know if anything needs to be serviced. Just in the U. S. , a system like this can prevent over 60,000 delays and cancellations every year, helping 7 million passengers get to their destinations on time. So we are moving to a world where the machines we work with are not just intelligent. They are brilliant. It's jet engines, locomotives, medical devices, communicating seamlessly with each other and with us. It's the marriage of minds and machines. And our lives will never be the same. (SOUNDBITE OF MUSIC)RAZ: Yeah. I mean, it's a complete break from the way humans have lived and functioned since, you know, the beginning of time. ANNUNZIATA: Absolutely, yes. And I think we are at the beginning of a massive historical transition, which will lead to a new economic system, a new industrial system, a new way of life, which will be really qualitatively different from what we are experiencing now. I mean, the impact is going to be enormous. RAZ: So, I mean, how would you describe where we are today? Are we right at the precipice of this massive change, or are we already in it? ANNUNZIATA: We are already in it, Guy, but we are at the very beginning of it. So for me, a plausible horizon for these new technologies to really spread and transform the industrial system and the economy as we know it, you're thinking of a horizon of 20 to 25 years, but that's for the complete transformation. Within the next five to 10 years, you will already see very substantial changes. And I'm saying this because some of these changes are already taking place. (SOUNDBITE OF TED TALK)ANNUNZIATA: Let's look at the big picture. There are people who argue that today's innovation is all about social media and silly games with nowhere near the transformational power of the Industrial Revolution. They see that all the growth-enhancing innovations are behind us. And every time I hear this, I can't help thinking that even back in the Stone Age there must have been a group of cavemen sitting around a fire one day looking very grumpy and looking disapprovingly at another group of cavemen rolling a stone wheel up and down a hill and saying to each other, yeah, this wheel thing - cool toy, sure. But compared to fire, it will have no impact. The big discoveries are all behind us. (LAUGHTER)ANNUNZIATA: This technological revolution is as inspiring and transformational is anything we have ever seen. Human creativity and innovation have always propelled us forward. They've created jobs. They've raised living standards. They've made our lives healthier and more rewarding. And the new wave of innovation, which is beginning to sweep through industry, is no different. I know that many of you will be concerned about the impact that innovation might have on jobs, and innovation is disruptive. But let me stress two things here. First, innovation is fundamentally about growth. It makes products more affordable. It creates new demand, new jobs. Second, there is a concern that in the future there will only be room for engineers, data scientists and other highly specialized workers. And believe me, as an economist, I'm also scared. But think about it. Just as a child can easily figure out how to operate an iPad, soon a new generation of mobile and intuitive industrial applications will make life easier for workers of all skill levels. It's not going to be easy, but it is going to be worth it. (SOUNDBITE OF MUSIC)RAZ: I mean, all of these technologies that are coming online and that will come online and that will, you know, make many parts of our lives more efficient and make our, you know, economies more productive, I mean, there are going to be winners and losers, surely. ANNUNZIATA: They're always sad, and one thing to keep in mind is sometimes technological innovations have unintended consequences that you need to watch for. So one key example - there's been a lot of attention and focus on the problem of unemployment and the risks coming from automation and artificial intelligence. RAZ: Yeah. ANNUNZIATA: Now, to me, that is something that needs to be taken very seriously. Now, I don't buy into the argument you hear that says that in the future, 50 percent of all jobs will disappear. And that is simply not true, and I think, in the end, the we will have more jobs. We will have better jobs, but some jobs will be automated away. The transition will be difficult. It will require people to acquire different skills. So how can we get from where we sit today to this brilliant future I'm envisioning where we will all have better jobs, more jobs? How do we get there in a way that creates the least disruption and for the smallest number of people because there will be disruption? (SOUNDBITE OF MUSIC)ANNUNZIATA: Provided that we manage this transition in the right way, it will definitely be a better future because I work with scientists and engineers and I see what innovation is doing, and that makes me optimistic. (SOUNDBITE OF MUSIC)RAZ: Marco Annunziata is the chief economist at GE. You can find his entire talk at ted. com. GUY RAZ, HOST:  It's the TED Radio Hour from NPR. I'm Guy Raz. And on the show today, ideas about the digital industrial revolution and whether we should be worried or excited. MARCO ANNUNZIATA: I am definitely an optimist. RAZ: This is Marco Annunziata. Marco's the chief economist at General Electric. ANNUNZIATA: I am aware as an economist being optimistic is kind of out of character, but I feel there are too many gloomy people out there, so I'm happpy to do my bit. RAZ: One of Marco's main jobs is to predict what our jobs will look like in the future. And he says, not surprisingly, that in the next five to 10 to 20 years, almost everything about the workplace is going to change. ANNUNZIATA: There will be a new and different form of interaction between humans and machines, both physical machines like robots and virtual machines like artificial intelligence. RAZ: So - I don't know - if you can take us on a tour of that future, what does a normal person's day going to kind of be like at work? What are they going to experience? How are they going experience that? ANNUNZIATA: So I think they will experience it in the following way. They will come on to a factory floor. Onto the factory floor, they will find an environment which is a lot more intelligent than today. Everything around the worker, whether it's the equipment the worker interacts with, the different items on the factory floor, will be equipped with sensors constantly sending data to artificial intelligence machines that will be analyzing the data and everything that is going on. There will be robots helping the worker perform whatever functions are involved in the specific job description in a much more efficient and a much safer way. These are applications that make work better. RAZ: This collaboration between humans and machines is all part of what Marco calls the industrial Internet. (SOUNDBITE OF TED TALK) ANNUNZIATA: So what is this industrial Internet? RAZ: He explained the idea from the TED stage. (SOUNDBITE OF TED TALK) ANNUNZIATA: It brings together intelligent machines, advanced analytics and the creativity of people that work. Industrial machines are being equipped with a growing number of electronic sensors that allow them to see, hear, feel a lot more than ever before, generating prodigious amounts of data. Increasingly sophisticated analytics then sift through the data, providing insights that allow us to operate the machines in entirely new ways a lot more efficiently. And not just individual machines but fleets of locomotives, airplanes, entire systems like power grids, hospitals. Let's start with aviation. Today, 10 percent of all flights, cancellations and delays are due to unscheduled maintenance events. These results in $8 billion in costs for the airline industry globally every year, not to mention the impact on all of us - stress, inconvenience, missed meetings - as we sit helplessly in an airport terminal. So how can the industrial Internet help here? We've developed a preventive maintenance system which can be installed on any aircraft. It's self-learning and able to predict issues that a human operator would miss. The aircraft, while in flight, will communicate with technicians on the ground. By the time it lands, they will already know if anything needs to be serviced. Just in the U. S. , a system like this can prevent over 60,000 delays and cancellations every year, helping 7 million passengers get to their destinations on time. So we are moving to a world where the machines we work with are not just intelligent. They are brilliant. It's jet engines, locomotives, medical devices, communicating seamlessly with each other and with us. It's the marriage of minds and machines. And our lives will never be the same. (SOUNDBITE OF MUSIC) RAZ: Yeah. I mean, it's a complete break from the way humans have lived and functioned since, you know, the beginning of time. ANNUNZIATA: Absolutely, yes. And I think we are at the beginning of a massive historical transition, which will lead to a new economic system, a new industrial system, a new way of life, which will be really qualitatively different from what we are experiencing now. I mean, the impact is going to be enormous. RAZ: So, I mean, how would you describe where we are today? Are we right at the precipice of this massive change, or are we already in it? ANNUNZIATA: We are already in it, Guy, but we are at the very beginning of it. So for me, a plausible horizon for these new technologies to really spread and transform the industrial system and the economy as we know it, you're thinking of a horizon of 20 to 25 years, but that's for the complete transformation. Within the next five to 10 years, you will already see very substantial changes. And I'm saying this because some of these changes are already taking place. (SOUNDBITE OF TED TALK) ANNUNZIATA: Let's look at the big picture. There are people who argue that today's innovation is all about social media and silly games with nowhere near the transformational power of the Industrial Revolution. They see that all the growth-enhancing innovations are behind us. And every time I hear this, I can't help thinking that even back in the Stone Age there must have been a group of cavemen sitting around a fire one day looking very grumpy and looking disapprovingly at another group of cavemen rolling a stone wheel up and down a hill and saying to each other, yeah, this wheel thing - cool toy, sure. But compared to fire, it will have no impact. The big discoveries are all behind us. (LAUGHTER) ANNUNZIATA: This technological revolution is as inspiring and transformational is anything we have ever seen. Human creativity and innovation have always propelled us forward. They've created jobs. They've raised living standards. They've made our lives healthier and more rewarding. And the new wave of innovation, which is beginning to sweep through industry, is no different. I know that many of you will be concerned about the impact that innovation might have on jobs, and innovation is disruptive. But let me stress two things here. First, innovation is fundamentally about growth. It makes products more affordable. It creates new demand, new jobs. Second, there is a concern that in the future there will only be room for engineers, data scientists and other highly specialized workers. And believe me, as an economist, I'm also scared. But think about it. Just as a child can easily figure out how to operate an iPad, soon a new generation of mobile and intuitive industrial applications will make life easier for workers of all skill levels. It's not going to be easy, but it is going to be worth it. (SOUNDBITE OF MUSIC) RAZ: I mean, all of these technologies that are coming online and that will come online and that will, you know, make many parts of our lives more efficient and make our, you know, economies more productive, I mean, there are going to be winners and losers, surely. ANNUNZIATA: They're always sad, and one thing to keep in mind is sometimes technological innovations have unintended consequences that you need to watch for. So one key example - there's been a lot of attention and focus on the problem of unemployment and the risks coming from automation and artificial intelligence. RAZ: Yeah. ANNUNZIATA: Now, to me, that is something that needs to be taken very seriously. Now, I don't buy into the argument you hear that says that in the future, 50 percent of all jobs will disappear. And that is simply not true, and I think, in the end, the we will have more jobs. We will have better jobs, but some jobs will be automated away. The transition will be difficult. It will require people to acquire different skills. So how can we get from where we sit today to this brilliant future I'm envisioning where we will all have better jobs, more jobs? How do we get there in a way that creates the least disruption and for the smallest number of people because there will be disruption? (SOUNDBITE OF MUSIC) ANNUNZIATA: Provided that we manage this transition in the right way, it will definitely be a better future because I work with scientists and engineers and I see what innovation is doing, and that makes me optimistic. (SOUNDBITE OF MUSIC) RAZ: Marco Annunziata is the chief economist at GE. You can find his entire talk at ted. com.", "section": "TED Radio Hour", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-04-21-524702119": {"title": "Maurice Conti: Can Machines Think And Feel For Themselves? : NPR", "url": "https://www.npr.org/2017/04/21/524702119/maurice-conti-can-machines-think-and-feel-for-themselves", "author": "No author found", "published_date": "2017-04-21", "content": "GUY RAZ, HOST: On the show today, ideas about the digital industrial revolution and how we as humans will fit into all of it. MAURICE CONTI: So we're going to be, you know, Iron Man plus Spock plus, you know, name your series of superheroes. RAZ: This is Maurice Conti. CONTI: Yeah, so my name is Maurice Conti. I currently head up Applied Research and Innovation at a software company called Autodesk. RAZ: And Maurice is talking about how maybe someday we could all be these sort of superhumans working together with machines in an era he calls the augmented age. CONTI: I mean, you know, we've had this partnership with our own technology that has been allowing us to achieve greater things, which, I guess by definition, is augmentation. I think the difference this time is the speed with which these technologies are coming online And the speed with which we are going to adopt them, which, I think, will result in something that feels more like augmentation rather than improvement. It's like a superpower. (SOUNDBITE OF MUSIC)RAZ: OK. So what does it actually mean, I mean, in practical terms? Because right now - right now we have access to infinite knowledge, right? We can just pull out our phones and find out really pretty much whatever we want to find out. CONTI: Yes, sort of. In fact, you know, I argue that we are already augmented because all of us probably listening have access to a smartphone, which is, in turn, connected to the Internet, which, in turn, holds vast amounts of information. I wouldn't necessarily say it's knowledge. In fact, that's maybe the next step. The part that's missing is, yes, I have access to a great body of information, but I still need to turn that into knowledge with my own point of view, my own ability to think synthetically and connect dots. RAZ: Yeah. CONTI: And I think, you know, that's what advanced computation is going to help us with. It's really processing that information, gleaning insight from it, making intuitive leaps and so forth. RAZ: And Maurice says that soon, a lot of our machines won't just answer questions. They'll actually start thinking for themselves, coming up with their own ideas and even feeling the world around them. Here's how Maurice explained it from the TED stage. (SOUNDBITE OF TED TALK)CONTI: Tools are making this leap from being passive to being generative. Generative design tools use a computer and algorithms to synthesize geometry to come up with new designs all by themselves. All it needs are your goals and your constraints. I'll give you an example. In the case of this aerial drone chassis, all you would need to do is tell it something like it has four propellers, you want it to be as lightweight as possible and you need it to be aerodynamically efficient. And then what the computer does is it explores the entire solution space, every single possibility that solves and meets your criteria, millions of them. But it comes back to us with designs that we by ourselves never could have imagined. And the computer is coming up with this stuff all by itself. No one ever drew anything, and it started completely from scratch. (SOUNDBITE OF MUSIC)RAZ: OK. If the future is going to be a future of artificial intelligence, do you think that we're going to figure out a way to work together or, I mean (laughter), or not? CONTI: Well, you know, part of me says that has to be true. The AI was built and is operating in service of some goal that I was trying to achieve, and if I'm achieving that goal, then I think, by definition, I mean, I'm in partnership with that AI. RAZ: So, I mean. . . CONTI: Feel free to call [expletive] on that. RAZ: No, no, no, I just - I just - and I was saying this to Erik Brynjolfsson earlier in the show - right? - that I cannot imagine any single profession, including professions that we think require a whole lot of brain power like psychiatry, OK, I mean, I cannot think of a single profession that won't be - that couldn't be displaced by a machine-learning machine that just becomes smarter and smarter and smarter. CONTI: Yeah. Certainly, it's easy to imagine how just about every profession can be affected by these technologies. You know, where it gets interesting is if we start to debate, will these professionals be displaced? And certainly, in some cases they will. But I think in many cases, they won't. Part of the reason is there's this graph that I like to draw, and it has two curves on it. The first curve is an upward exponential curve that represents our capabilities as a species based on the development of technology. So perhaps at some point, when we reach a very high point on that curve, we'll be done. There'll be nothing else to do. What I think a lot of people overlook is there's another curve right next to it that happens to be in lockstep, and that is the curve of opportunity. (SOUNDBITE OF MUSIC)CONTI: And it's actually easy to see, you know, whenever some company comes out with the latest smartphone, the next day people are like, great. What's next? I want more. And I think it's the fact that we have this other curve, which is our capacity to imagine and desire better things, better lives, better relationships, that, you know, will keep the demands on us increasing. And if that's true, then the AIs that would displace us are actually just what we need in order to keep up. (SOUNDBITE OF TED TALK)CONTI: So as computers are going to augment our ability to imagine and design new stuff, robotic systems are going to help us build and make things that we've never been able to make before. But what about our ability to sense and control these things? What about a nervous system for the things that we make? Our nervous system, the human nervous system, tells us everything that's going on around us. But the nervous system of the things we make is rudimentary at best. For instance, a car doesn't tell the city's public works department that it just hit a pothole at the corner of Broadway and Morrison. A building doesn't tell its designers whether or not the people inside like being there. And if the designers had known what was really happening in the real world with their designs, they could've used that knowledge to create an experience that was better for the user. Now, what's missing is a nervous system connecting us to all of the things that we design, make and use. (SOUNDBITE OF MUSIC)RAZ: I mean, a nervous system, a human nervous system, is such a complex thing that it's hard for me to get my head around the idea that there could be a comparable digital system. CONTI: I think when a lot of people think about AI and, you know, things like Skynet, one of the things they assume is that the AI is aware. And I think awareness is a prerequisite of powerful, useful AIs. And so giving AIs a nervous system, the ability to perceive their environments in order for them to carry out their jobs, is critical. And that's already happening. This isn't science fiction at all. It's just a question of getting sensor data from the real world into the AI. It's happening in your car every day. If you have a car that has any kind of autopilot or fancy cruise control, it's looking around it. It's perceiving its environment and then making decisions based on that. And so, really, it's just a continuation of that, more sensors, more real-time data coming in, that allow the systems to make relevant decisions that are helpful to us. RAZ: So I mean - and, I mean, we've heard stories about this on the show already about how, you know, when humans and robots work together, everybody wins, you know. Like, I mean, is this idea of the human-AI collaboration, you know, is infinitely superior to everything else out there? I mean, is that always going to be the case, or is that just wishful thinking? CONTI: No. I think human technology, you know, human-AI, human-robot collaboration is better than either one working on their own. I actually think that's a tautology. You know, humans are very good at some things. Synthetic systems are really good at others. All else being equal, I cannot imagine the argument where the combination of these two skill sets is not better. (SOUNDBITE OF MUSIC)CONTI: And that's where it gets interesting because the AI is currently not that great at intuition but really good at that sort of brute force computation on tons and tons of data. And it's a little bit like a dance. (SOUNDBITE OF MUSIC)CONTI: The human might lead, but the computer can do lots of fancy moves that together combine into something. . . (SOUNDBITE OF MUSIC)CONTI: . . . That is greater than the sum of its parts. (SOUNDBITE OF MUSIC)RAZ: Maurice Conti - he's the director of Applied Research and Innovation at the 3D design and engineering software company Autodesk. You can see his full talk at ted. com. On the show today, the digital industrial revolution. In a moment, a question - is it possible we're inventing the last human invention? Stay with us. I'm Guy Raz, and you're listening to the TED Radio Hour from NPR. GUY RAZ, HOST:  On the show today, ideas about the digital industrial revolution and how we as humans will fit into all of it. MAURICE CONTI: So we're going to be, you know, Iron Man plus Spock plus, you know, name your series of superheroes. RAZ: This is Maurice Conti. CONTI: Yeah, so my name is Maurice Conti. I currently head up Applied Research and Innovation at a software company called Autodesk. RAZ: And Maurice is talking about how maybe someday we could all be these sort of superhumans working together with machines in an era he calls the augmented age. CONTI: I mean, you know, we've had this partnership with our own technology that has been allowing us to achieve greater things, which, I guess by definition, is augmentation. I think the difference this time is the speed with which these technologies are coming online And the speed with which we are going to adopt them, which, I think, will result in something that feels more like augmentation rather than improvement. It's like a superpower. (SOUNDBITE OF MUSIC) RAZ: OK. So what does it actually mean, I mean, in practical terms? Because right now - right now we have access to infinite knowledge, right? We can just pull out our phones and find out really pretty much whatever we want to find out. CONTI: Yes, sort of. In fact, you know, I argue that we are already augmented because all of us probably listening have access to a smartphone, which is, in turn, connected to the Internet, which, in turn, holds vast amounts of information. I wouldn't necessarily say it's knowledge. In fact, that's maybe the next step. The part that's missing is, yes, I have access to a great body of information, but I still need to turn that into knowledge with my own point of view, my own ability to think synthetically and connect dots. RAZ: Yeah. CONTI: And I think, you know, that's what advanced computation is going to help us with. It's really processing that information, gleaning insight from it, making intuitive leaps and so forth. RAZ: And Maurice says that soon, a lot of our machines won't just answer questions. They'll actually start thinking for themselves, coming up with their own ideas and even feeling the world around them. Here's how Maurice explained it from the TED stage. (SOUNDBITE OF TED TALK) CONTI: Tools are making this leap from being passive to being generative. Generative design tools use a computer and algorithms to synthesize geometry to come up with new designs all by themselves. All it needs are your goals and your constraints. I'll give you an example. In the case of this aerial drone chassis, all you would need to do is tell it something like it has four propellers, you want it to be as lightweight as possible and you need it to be aerodynamically efficient. And then what the computer does is it explores the entire solution space, every single possibility that solves and meets your criteria, millions of them. But it comes back to us with designs that we by ourselves never could have imagined. And the computer is coming up with this stuff all by itself. No one ever drew anything, and it started completely from scratch. (SOUNDBITE OF MUSIC) RAZ: OK. If the future is going to be a future of artificial intelligence, do you think that we're going to figure out a way to work together or, I mean (laughter), or not? CONTI: Well, you know, part of me says that has to be true. The AI was built and is operating in service of some goal that I was trying to achieve, and if I'm achieving that goal, then I think, by definition, I mean, I'm in partnership with that AI. RAZ: So, I mean. . . CONTI: Feel free to call [expletive] on that. RAZ: No, no, no, I just - I just - and I was saying this to Erik Brynjolfsson earlier in the show - right? - that I cannot imagine any single profession, including professions that we think require a whole lot of brain power like psychiatry, OK, I mean, I cannot think of a single profession that won't be - that couldn't be displaced by a machine-learning machine that just becomes smarter and smarter and smarter. CONTI: Yeah. Certainly, it's easy to imagine how just about every profession can be affected by these technologies. You know, where it gets interesting is if we start to debate, will these professionals be displaced? And certainly, in some cases they will. But I think in many cases, they won't. Part of the reason is there's this graph that I like to draw, and it has two curves on it. The first curve is an upward exponential curve that represents our capabilities as a species based on the development of technology. So perhaps at some point, when we reach a very high point on that curve, we'll be done. There'll be nothing else to do. What I think a lot of people overlook is there's another curve right next to it that happens to be in lockstep, and that is the curve of opportunity. (SOUNDBITE OF MUSIC) CONTI: And it's actually easy to see, you know, whenever some company comes out with the latest smartphone, the next day people are like, great. What's next? I want more. And I think it's the fact that we have this other curve, which is our capacity to imagine and desire better things, better lives, better relationships, that, you know, will keep the demands on us increasing. And if that's true, then the AIs that would displace us are actually just what we need in order to keep up. (SOUNDBITE OF TED TALK) CONTI: So as computers are going to augment our ability to imagine and design new stuff, robotic systems are going to help us build and make things that we've never been able to make before. But what about our ability to sense and control these things? What about a nervous system for the things that we make? Our nervous system, the human nervous system, tells us everything that's going on around us. But the nervous system of the things we make is rudimentary at best. For instance, a car doesn't tell the city's public works department that it just hit a pothole at the corner of Broadway and Morrison. A building doesn't tell its designers whether or not the people inside like being there. And if the designers had known what was really happening in the real world with their designs, they could've used that knowledge to create an experience that was better for the user. Now, what's missing is a nervous system connecting us to all of the things that we design, make and use. (SOUNDBITE OF MUSIC) RAZ: I mean, a nervous system, a human nervous system, is such a complex thing that it's hard for me to get my head around the idea that there could be a comparable digital system. CONTI: I think when a lot of people think about AI and, you know, things like Skynet, one of the things they assume is that the AI is aware. And I think awareness is a prerequisite of powerful, useful AIs. And so giving AIs a nervous system, the ability to perceive their environments in order for them to carry out their jobs, is critical. And that's already happening. This isn't science fiction at all. It's just a question of getting sensor data from the real world into the AI. It's happening in your car every day. If you have a car that has any kind of autopilot or fancy cruise control, it's looking around it. It's perceiving its environment and then making decisions based on that. And so, really, it's just a continuation of that, more sensors, more real-time data coming in, that allow the systems to make relevant decisions that are helpful to us. RAZ: So I mean - and, I mean, we've heard stories about this on the show already about how, you know, when humans and robots work together, everybody wins, you know. Like, I mean, is this idea of the human-AI collaboration, you know, is infinitely superior to everything else out there? I mean, is that always going to be the case, or is that just wishful thinking? CONTI: No. I think human technology, you know, human-AI, human-robot collaboration is better than either one working on their own. I actually think that's a tautology. You know, humans are very good at some things. Synthetic systems are really good at others. All else being equal, I cannot imagine the argument where the combination of these two skill sets is not better. (SOUNDBITE OF MUSIC) CONTI: And that's where it gets interesting because the AI is currently not that great at intuition but really good at that sort of brute force computation on tons and tons of data. And it's a little bit like a dance. (SOUNDBITE OF MUSIC) CONTI: The human might lead, but the computer can do lots of fancy moves that together combine into something. . . (SOUNDBITE OF MUSIC) CONTI: . . . That is greater than the sum of its parts. (SOUNDBITE OF MUSIC) RAZ: Maurice Conti - he's the director of Applied Research and Innovation at the 3D design and engineering software company Autodesk. You can see his full talk at ted. com. On the show today, the digital industrial revolution. In a moment, a question - is it possible we're inventing the last human invention? Stay with us. I'm Guy Raz, and you're listening to the TED Radio Hour from NPR.", "section": "TED Radio Hour", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-04-21-524702525": {"title": "Jeremy Howard: Will Artificial Intelligence Be The Last Human Invention? : NPR", "url": "https://www.npr.org/2017/04/21/524702525/jeremy-howard-will-artificial-intelligence-be-the-last-human-invention", "author": "No author found", "published_date": "2017-04-21", "content": "GUY RAZ, HOST: It's the TED Radio Hour from NPR. I'm Guy Raz. And on the show today, ideas about a new industrial revolution. JEREMY HOWARD: I mean, it's not just a new phase of the Industrial Revolution. It's a - it's an entirely new revolution. RAZ: This is data scientist Jeremy Howard. HOWARD: So we went through the process of replacing hunting and gathering with domestication. We went through the process of replacing animal energy with mechanical energy. We're now going through the process of replacing human intelligence with artificial intelligence. (SOUNDBITE OF MUSIC)RAZ: So for the past 25 years, Jeremy has been working on a technology called deep learning, and it's based on the way the human brain and nervous system work. HOWARD: Deep learning relies on a particular kind of function called a neural network. It is heavily inspired by neuroscience and can actually compute anything. RAZ: Anything because these machines can learn and perceive. They can see, hear, read, write. They can make decisions all while being able to process billions of data points. HOWARD: It's creepy. RAZ: Yeah. HOWARD: And it's possibly about to get creepier. RAZ: (Laughter) Oh, no. But before we get to the creepy part, we should point out we're already using these neural networks for a lot of pretty cool things. HOWARD: So today, we have a thousand-layer neural networks doing things like Skype translation. I don't know if you've tried that. RAZ: Yeah. We just actually tried it. (SOUNDBITE OF SKYPE LOADING)CASEY HERMAN, BYLINE: Hey, you can hear me? COMPUTER-GENERATED VOICE #1: (Speaking French). MATHILDE: (Speaking French). COMPUTER-GENERATED VOICE #2: Yes. Hello. We hear you very well. RAZ: OK. Let me explain what's going on here. Our producer, Casey, is speaking into Skype. . . HERMAN: OK, great. So you're recording. RAZ: . . . Obviously in English. And Skype is translating that in real time into French. COMPUTER-GENERATED VOICE #1: (Speaking French). RAZ: And on the other end is Mathilde (ph). . . MATHILDE: (Speaking French). RAZ: . . . Except she's speaking in French, and Skype turns that into English. COMPUTER-GENERATED VOICE #2: Yes, we are recording. RAZ: And how does this work? HOWARD: The basic approach is that you download lots of sentences that are written both in English and French. You basically write three or four lines of code, and you then tell that neural network where to find the input and output data, leave it overnight and come back in the morning and see if it works. So a sentence could be please enter your username here. COMPUTER-GENERATED VOICE #1: (Speaking French). HOWARD: It learns to map at a very deep and subtle way such that the next day I can then put in a different sentence. What is the world's largest country? COMPUTER-GENERATED VOICE #1: (Speaking French). RAZ: And Jeremy says that's all it takes. You start with simple sentences. MATHILDE: (Speaking French). COMPUTER-GENERATED VOICE #2: What is the distance between the Earth and the sun? RAZ: As you keep going, the program keeps learning on its own. . . MATHILDE: (Speaking French). COMPUTER-GENERATED VOICE #2: What is the population of the city of Paris? RAZ: . . . To the point where you can have entire conversations translated. . . HERMAN: Hey, good morning, how are you doing? COMPUTER-GENERATED VOICE #1: (Speaking French). RAZ: . . . In real time. . . . MATHILDE: (Speaking French). RAZ: . . . By a machine. COMPUTER-GENERATED VOICE #2: I'm fine, thank you. HERMAN: How is your family? Have you talked to them? COMPUTER-GENERATED VOICE #1: (Speaking French). RAZ: I mean, this concept is absolutely incredible - right? - because with this technology, once you hit go, it's unstoppable. I mean, it just continues to get better and better and better, right? HOWARD: Right. So you set up your problem, and you run it overnight, and you come back the next day, and hopefully, it solved it. Now, it's pretty hard to describe exactly what it's done, and often - very, very often - I don't really understand at all how my programs work. A few years ago, I built a system for diagnosing lung cancer which could beat a panel of four of the world's best radiologists. But I know nothing whatsoever about what lung cancer looks like or doesn't look like and could tell you nothing about how it worked because I have no background in medicine. So that's the nature of setting up these things. You fire them off and they come back with a model. RAZ: And Jeremy says diagnosing lung cancer is just the beginning. HOWARD: And so you can imagine the power that this provides for good. Every time a piece of medical imaging is done, automatically and instantly an alert appears saying this person has an aneurism or this person has a malignant nodule in their left lung. You know, that would be saving millions of lives and billions of dollars. RAZ: Here's how Jeremy explained it from the TED stage. (SOUNDBITE OF TED TALK)HOWARD: This kind of technique could allow us to fix a major problem, which is that there's a lack of medical expertise in the world. The World Economic Forum says that there's between a 10x and a 20x shortage of physicians in the developing world. And it would take about 300 years to train enough people to fix that problem. So imagine if we can help enhance their efficiency using these deep learning approaches. So I'm very excited about the opportunities. I'm also concerned about the problems. The problem here is that every area in blue on this map is somewhere where services are over 80 percent of employment. What are services? RAZ: OK. So at this point in his talk, Jeremy pulls out a large world map, and he explains that in most of the developed world, and even in a lot of developing countries, their economies depend mainly on service jobs, people who prep food and drive cars and file documents, do legal research, even diagnose disease. (SOUNDBITE OF TED TALK)HOWARD: These are also the exact things that computers have just learned how to do. So 80 percent of the world's employment in the developed world is stuff that computers have just learned how to do. What does that mean? Well, it'll be fine. It'll be replaced by other jobs. For example, there'll be more jobs for data scientists. Well, not really. It doesn't take data scientists very long to build these things. For example, these four algorithms were all built by the same guy. So if you think, oh, it's all happened before. You know, we've seen the results in the past of when new things come along, and they get replaced by new jobs. What are these new jobs going to be? It's very hard for us to estimate this because human performance grows at this gradual rate. But we now have a system, deep learning, that we know actually grows in capability exponentially. So currently, we see the things around us and we say oh, computers are still pretty dumb, right? But in five years time, computers will be off this chart. The better computers get at intellectual activities, the more they can build better computers to be better at intellectual capabilities. So this is going to be a kind of change that the world has actually never experienced before. So your previous understanding of what's possible is different. RAZ: I mean, the fact is is that machines are getting better and better as we speak, second by second, in being able to process billions and billions of pieces of data, and they're just going to get better and better next month and in a year and in five years and 20 years. And they are going to be able to make decisions in ways that will be confounding to us. HOWARD: I mean, so I did my TED talk two and a half years ago, I guess, and at this point, computers are better at recognizing what is in a photo than humans are. They are better at understanding Chinese and English speech than Chinese and English native speakers. We now have deep learning algorithms that are better at building the neural networks that create deep learning algorithms. . . RAZ: (Laughter). HOWARD: . . . Than humans are. RAZ: God. HOWARD: So two and a half years since I got up and said, hey, there's this new technology called deep learning which is about to surpass human capabilities in these fundamentally human areas. Between then and now, it happened. RAZ: Do you think we can even articulate or imagine what this technology will do to change our world, our lives, our species? HOWARD: Not only is it impossible for us to imagine, there is a great many things which are stopping us from being able to imagine it. RAZ: Like what? HOWARD: So people often talk about exponential technologies, but the fact is, every technology that's come so far is actually an S-shaped technology. Before electricity, nearly everything that required an input of energy was done with human energy or horse energy or something like that. Then we learnt how to electrify nearly every energy-requiring process until eventually, we did them all. And so there was initially exponential growth as the newly electrified processes allowed us to improve other processes, but then it flattened off again. Now, on the other hand, think about replacing intellectual power, all right? There's no S-curve here. There's no drop-off. There's no point where you go, OK, we've now used all of the intellectual power that could be used. So our ability to actually understand the outcome of a truly exponential technology cannot be based on anything that has been observed in history because there's never been a technology like this before. RAZ: Yeah, I mean, it never stops. It doesn't reach a point where we say, you know, right, OK, next, you know, we've reached that milestone, and now we can just move on to the next thing. HOWARD: Right. Well, that's the thing, right? This is kind of the last human input is kind of perception. . . RAZ: Yeah. HOWARD: . . . And intelligence. So a lot of people then say, oh, yeah, so there'll be new jobs. But then you say, like what? RAZ: Yeah. HOWARD: And that's where people come up short. Like, you could tell, even in the industrial revolution, you could say OK, electricity can't do all of these things - look at things or listen to things or react to things. That's not where we are anymore. We're now in the process of saying, OK, this is the last bastion of stuff that only humans can do. RAZ: Yeah, I mean, I've been asking everyone on the show this question, and, you know, they seem pretty convinced that, you know, we humans will continue to have jobs. Like, you and I will continue to do what we do and will continue to be necessary as a species, but I'm not really so sure. HOWARD: Yeah. There's no question that the vast majority of things that humans are doing today are going to be replaced. And it's also important to remember, though, that the vast majority of people have jobs that kind of suck, right? RAZ: Yeah. HOWARD: There's far more people who are chopping celery for a living than there are people running TED Radio Hour for a living. So given that we both agree that the jobs that we have today are going to disappear probably quicker than anybody expects, that means that we need to have ways of supporting people. . . RAZ: Yeah. HOWARD: . . . Economically because you can't just say, you're not adding value, so therefore, you're not worthwhile to society. You actually have to say OK, we think everybody deserves to live in dignity, so let's have a basic guaranteed income which is enough to ensure that every human can have a life of dignity. RAZ: I mean, do you think we're, like, designing our replacement? Because you could imagine a point when, you know, we won't be the most intelligent species on the planet. Like, we would still live on it. We would still reproduce, but. . . HOWARD: Right. RAZ: . . . But, I mean, intelligent machines will create a new economic model and a system of governments for us on our behalf. We're going to be, like, zoo animals. HOWARD: Yeah, I don't think that's too hard to imagine. You know, if we continue down this path where more and more of the economy looks like the inside of a Amazon logistics warehouse - where every human being, every move they're making, is being supervised by and rewarded or penalized by machines until we're all at the beck and call of the machinery and we could well look at each other and go, none of us signed up for this. RAZ: Yeah. HOWARD: None of us designed this. RAZ: It's just hard for me to wrap my head around this idea that, you know, we have consciousness. I mean, even though we're not sure what exactly animates us - right? But I just have trouble believing that, you know, one day, we're going to develop machines that think and feel and act like we do. HOWARD: The more I use this technology, the less my own consciousness seems surprising or inexplicable. RAZ: Really? HOWARD: Oh, very much so. RAZ: Wow. HOWARD: Once you've used these kinds of tools for long enough, you just keep seeing them behave in certain ways. It just looks very familiar. RAZ: But you're basically saying that the ones and zeros in a machine are very similar to the ones and zeros in your brain. HOWARD: Well, clearly. I mean, it has to be true. The alternative is if you believe that there's a God. . . RAZ: Yeah? HOWARD: . . . And there's a soul and it's this ineffable thing we can't see or touch. . . RAZ: Yeah. HOWARD: . . . OK, that's fine. I can't, and I'm not going to argue with that because it's based on faith, not science. Unless you believe those things, you have to believe that the chemical and electrical signals and connectivity in our brain is us. You know, the idea that these kinds of massively parallel, massively connected functions inside huge computer systems can display intelligent behavior - well, we're already there. We just keep redefining intelligent behavior so that, you know, we're always outside it. RAZ: But, I mean, as a human, I can emote. I can feel things. You know, like, I understand my mortality. I love. I feel grief (laughter). I mean, how are those things replicated by - you know, in a machine by ones and zeros? HOWARD: Very, very easily. All of the things you are describing are rational, evolutionary responses to a fitness function that attempts to keep your genes alive. The reason you love is because your genes want you to have sex and have more of those genes. The reason that you grieve is because your genes want you to avoid doing things that cause people with similar genes to yours to die. All of the things that you emote are, at some level, evolutionary responses to this fitness function of keeping your genes going for longer. So as our complex, computer-based functions get better at figuring out what causes their fitness functions to be successful, they will have all of these very complex interactions. RAZ: I'm not walking away from this conversation optimistic. I'm troubled. HOWARD: Good. RAZ: Yeah, I'm troubled. HOWARD: Good. Be troubled. RAZ: Yeah. HOWARD: You know, being troubled is the correct response - but also excited. Be both. Because all of these people who say don't worry, everything's fine - there will always be jobs. Just feed the robots; feed the machines. Don't worry - to me, they're just the same as climate-change deniers. You know, they're ignoring the basic science that says this is something different. This is something we can't control. This is something we don't know where it's going. And this is something which can definitely have terrible societal outcomes. On the other hand, anybody who says the government should step in and regulate and control and stop all of this from happening - people shouldn't be doing this kind of research - they're just as bad. You know, they're saying the billions of people that don't have access to modern medicine should never be given it even though we have the technology today to provide it. So we need to be both. We need to be aware of the opportunities and aware of the threats. (SOUNDBITE OF MUSIC)RAZ: Jeremy Howard - he's a data scientist and the founding researcher at fast. ai. It's a company dedicated to making deep learning accessible to everyone. You can see his entire talk at ted. com. (SOUNDBITE OF SONG, \"ROBOT\")THE FUTUREHEADS: (Singing) I am a robot living like a robot, talk like a robot in the habitating way. Look up to the sky. . . RAZ: Hey, thanks for listening to our show on the Digital Industrial Revolution this week. If you want to find out more about who was on it, go to ted. npr. org. To see hundreds more TED Talks, check out ted. com or the TED app. Our production staff at NPR includes Jeff Rogers, Sanaz Meshkinpour, Jinae West, Neva Grant and Rachel Faulkner with help from Ramtim Arablouei and Daniel Shukin. Our intern is Thomas Lu. Our partners at TED are Chris Anderson, Kelly Stoetzel, Anna Phelan and Janet Lee. I'm Guy Raz, and you've been listening to ideas worth spreading right here on the TED Radio Hour from NPR. (SOUNDBITE OF SONG, \"ROBOT\")THE FUTUREHEADS: (Singing) I am a robot, living like a robot, talk like a robot in the habitating way. GUY RAZ, HOST:  It's the TED Radio Hour from NPR. I'm Guy Raz. And on the show today, ideas about a new industrial revolution. JEREMY HOWARD: I mean, it's not just a new phase of the Industrial Revolution. It's a - it's an entirely new revolution. RAZ: This is data scientist Jeremy Howard. HOWARD: So we went through the process of replacing hunting and gathering with domestication. We went through the process of replacing animal energy with mechanical energy. We're now going through the process of replacing human intelligence with artificial intelligence. (SOUNDBITE OF MUSIC) RAZ: So for the past 25 years, Jeremy has been working on a technology called deep learning, and it's based on the way the human brain and nervous system work. HOWARD: Deep learning relies on a particular kind of function called a neural network. It is heavily inspired by neuroscience and can actually compute anything. RAZ: Anything because these machines can learn and perceive. They can see, hear, read, write. They can make decisions all while being able to process billions of data points. HOWARD: It's creepy. RAZ: Yeah. HOWARD: And it's possibly about to get creepier. RAZ: (Laughter) Oh, no. But before we get to the creepy part, we should point out we're already using these neural networks for a lot of pretty cool things. HOWARD: So today, we have a thousand-layer neural networks doing things like Skype translation. I don't know if you've tried that. RAZ: Yeah. We just actually tried it. (SOUNDBITE OF SKYPE LOADING) CASEY HERMAN, BYLINE: Hey, you can hear me? COMPUTER-GENERATED VOICE #1: (Speaking French). MATHILDE: (Speaking French). COMPUTER-GENERATED VOICE #2: Yes. Hello. We hear you very well. RAZ: OK. Let me explain what's going on here. Our producer, Casey, is speaking into Skype. . . HERMAN: OK, great. So you're recording. RAZ: . . . Obviously in English. And Skype is translating that in real time into French. COMPUTER-GENERATED VOICE #1: (Speaking French). RAZ: And on the other end is Mathilde (ph). . . MATHILDE: (Speaking French). RAZ: . . . Except she's speaking in French, and Skype turns that into English. COMPUTER-GENERATED VOICE #2: Yes, we are recording. RAZ: And how does this work? HOWARD: The basic approach is that you download lots of sentences that are written both in English and French. You basically write three or four lines of code, and you then tell that neural network where to find the input and output data, leave it overnight and come back in the morning and see if it works. So a sentence could be please enter your username here. COMPUTER-GENERATED VOICE #1: (Speaking French). HOWARD: It learns to map at a very deep and subtle way such that the next day I can then put in a different sentence. What is the world's largest country? COMPUTER-GENERATED VOICE #1: (Speaking French). RAZ: And Jeremy says that's all it takes. You start with simple sentences. MATHILDE: (Speaking French). COMPUTER-GENERATED VOICE #2: What is the distance between the Earth and the sun? RAZ: As you keep going, the program keeps learning on its own. . . MATHILDE: (Speaking French). COMPUTER-GENERATED VOICE #2: What is the population of the city of Paris? RAZ: . . . To the point where you can have entire conversations translated. . . HERMAN: Hey, good morning, how are you doing? COMPUTER-GENERATED VOICE #1: (Speaking French). RAZ: . . . In real time. . . . MATHILDE: (Speaking French). RAZ: . . . By a machine. COMPUTER-GENERATED VOICE #2: I'm fine, thank you. HERMAN: How is your family? Have you talked to them? COMPUTER-GENERATED VOICE #1: (Speaking French). RAZ: I mean, this concept is absolutely incredible - right? - because with this technology, once you hit go, it's unstoppable. I mean, it just continues to get better and better and better, right? HOWARD: Right. So you set up your problem, and you run it overnight, and you come back the next day, and hopefully, it solved it. Now, it's pretty hard to describe exactly what it's done, and often - very, very often - I don't really understand at all how my programs work. A few years ago, I built a system for diagnosing lung cancer which could beat a panel of four of the world's best radiologists. But I know nothing whatsoever about what lung cancer looks like or doesn't look like and could tell you nothing about how it worked because I have no background in medicine. So that's the nature of setting up these things. You fire them off and they come back with a model. RAZ: And Jeremy says diagnosing lung cancer is just the beginning. HOWARD: And so you can imagine the power that this provides for good. Every time a piece of medical imaging is done, automatically and instantly an alert appears saying this person has an aneurism or this person has a malignant nodule in their left lung. You know, that would be saving millions of lives and billions of dollars. RAZ: Here's how Jeremy explained it from the TED stage. (SOUNDBITE OF TED TALK) HOWARD: This kind of technique could allow us to fix a major problem, which is that there's a lack of medical expertise in the world. The World Economic Forum says that there's between a 10x and a 20x shortage of physicians in the developing world. And it would take about 300 years to train enough people to fix that problem. So imagine if we can help enhance their efficiency using these deep learning approaches. So I'm very excited about the opportunities. I'm also concerned about the problems. The problem here is that every area in blue on this map is somewhere where services are over 80 percent of employment. What are services? RAZ: OK. So at this point in his talk, Jeremy pulls out a large world map, and he explains that in most of the developed world, and even in a lot of developing countries, their economies depend mainly on service jobs, people who prep food and drive cars and file documents, do legal research, even diagnose disease. (SOUNDBITE OF TED TALK) HOWARD: These are also the exact things that computers have just learned how to do. So 80 percent of the world's employment in the developed world is stuff that computers have just learned how to do. What does that mean? Well, it'll be fine. It'll be replaced by other jobs. For example, there'll be more jobs for data scientists. Well, not really. It doesn't take data scientists very long to build these things. For example, these four algorithms were all built by the same guy. So if you think, oh, it's all happened before. You know, we've seen the results in the past of when new things come along, and they get replaced by new jobs. What are these new jobs going to be? It's very hard for us to estimate this because human performance grows at this gradual rate. But we now have a system, deep learning, that we know actually grows in capability exponentially. So currently, we see the things around us and we say oh, computers are still pretty dumb, right? But in five years time, computers will be off this chart. The better computers get at intellectual activities, the more they can build better computers to be better at intellectual capabilities. So this is going to be a kind of change that the world has actually never experienced before. So your previous understanding of what's possible is different. RAZ: I mean, the fact is is that machines are getting better and better as we speak, second by second, in being able to process billions and billions of pieces of data, and they're just going to get better and better next month and in a year and in five years and 20 years. And they are going to be able to make decisions in ways that will be confounding to us. HOWARD: I mean, so I did my TED talk two and a half years ago, I guess, and at this point, computers are better at recognizing what is in a photo than humans are. They are better at understanding Chinese and English speech than Chinese and English native speakers. We now have deep learning algorithms that are better at building the neural networks that create deep learning algorithms. . . RAZ: (Laughter). HOWARD: . . . Than humans are. RAZ: God. HOWARD: So two and a half years since I got up and said, hey, there's this new technology called deep learning which is about to surpass human capabilities in these fundamentally human areas. Between then and now, it happened. RAZ: Do you think we can even articulate or imagine what this technology will do to change our world, our lives, our species? HOWARD: Not only is it impossible for us to imagine, there is a great many things which are stopping us from being able to imagine it. RAZ: Like what? HOWARD: So people often talk about exponential technologies, but the fact is, every technology that's come so far is actually an S-shaped technology. Before electricity, nearly everything that required an input of energy was done with human energy or horse energy or something like that. Then we learnt how to electrify nearly every energy-requiring process until eventually, we did them all. And so there was initially exponential growth as the newly electrified processes allowed us to improve other processes, but then it flattened off again. Now, on the other hand, think about replacing intellectual power, all right? There's no S-curve here. There's no drop-off. There's no point where you go, OK, we've now used all of the intellectual power that could be used. So our ability to actually understand the outcome of a truly exponential technology cannot be based on anything that has been observed in history because there's never been a technology like this before. RAZ: Yeah, I mean, it never stops. It doesn't reach a point where we say, you know, right, OK, next, you know, we've reached that milestone, and now we can just move on to the next thing. HOWARD: Right. Well, that's the thing, right? This is kind of the last human input is kind of perception. . . RAZ: Yeah. HOWARD: . . . And intelligence. So a lot of people then say, oh, yeah, so there'll be new jobs. But then you say, like what? RAZ: Yeah. HOWARD: And that's where people come up short. Like, you could tell, even in the industrial revolution, you could say OK, electricity can't do all of these things - look at things or listen to things or react to things. That's not where we are anymore. We're now in the process of saying, OK, this is the last bastion of stuff that only humans can do. RAZ: Yeah, I mean, I've been asking everyone on the show this question, and, you know, they seem pretty convinced that, you know, we humans will continue to have jobs. Like, you and I will continue to do what we do and will continue to be necessary as a species, but I'm not really so sure. HOWARD: Yeah. There's no question that the vast majority of things that humans are doing today are going to be replaced. And it's also important to remember, though, that the vast majority of people have jobs that kind of suck, right? RAZ: Yeah. HOWARD: There's far more people who are chopping celery for a living than there are people running TED Radio Hour for a living. So given that we both agree that the jobs that we have today are going to disappear probably quicker than anybody expects, that means that we need to have ways of supporting people. . . RAZ: Yeah. HOWARD: . . . Economically because you can't just say, you're not adding value, so therefore, you're not worthwhile to society. You actually have to say OK, we think everybody deserves to live in dignity, so let's have a basic guaranteed income which is enough to ensure that every human can have a life of dignity. RAZ: I mean, do you think we're, like, designing our replacement? Because you could imagine a point when, you know, we won't be the most intelligent species on the planet. Like, we would still live on it. We would still reproduce, but. . . HOWARD: Right. RAZ: . . . But, I mean, intelligent machines will create a new economic model and a system of governments for us on our behalf. We're going to be, like, zoo animals. HOWARD: Yeah, I don't think that's too hard to imagine. You know, if we continue down this path where more and more of the economy looks like the inside of a Amazon logistics warehouse - where every human being, every move they're making, is being supervised by and rewarded or penalized by machines until we're all at the beck and call of the machinery and we could well look at each other and go, none of us signed up for this. RAZ: Yeah. HOWARD: None of us designed this. RAZ: It's just hard for me to wrap my head around this idea that, you know, we have consciousness. I mean, even though we're not sure what exactly animates us - right? But I just have trouble believing that, you know, one day, we're going to develop machines that think and feel and act like we do. HOWARD: The more I use this technology, the less my own consciousness seems surprising or inexplicable. RAZ: Really? HOWARD: Oh, very much so. RAZ: Wow. HOWARD: Once you've used these kinds of tools for long enough, you just keep seeing them behave in certain ways. It just looks very familiar. RAZ: But you're basically saying that the ones and zeros in a machine are very similar to the ones and zeros in your brain. HOWARD: Well, clearly. I mean, it has to be true. The alternative is if you believe that there's a God. . . RAZ: Yeah? HOWARD: . . . And there's a soul and it's this ineffable thing we can't see or touch. . . RAZ: Yeah. HOWARD: . . . OK, that's fine. I can't, and I'm not going to argue with that because it's based on faith, not science. Unless you believe those things, you have to believe that the chemical and electrical signals and connectivity in our brain is us. You know, the idea that these kinds of massively parallel, massively connected functions inside huge computer systems can display intelligent behavior - well, we're already there. We just keep redefining intelligent behavior so that, you know, we're always outside it. RAZ: But, I mean, as a human, I can emote. I can feel things. You know, like, I understand my mortality. I love. I feel grief (laughter). I mean, how are those things replicated by - you know, in a machine by ones and zeros? HOWARD: Very, very easily. All of the things you are describing are rational, evolutionary responses to a fitness function that attempts to keep your genes alive. The reason you love is because your genes want you to have sex and have more of those genes. The reason that you grieve is because your genes want you to avoid doing things that cause people with similar genes to yours to die. All of the things that you emote are, at some level, evolutionary responses to this fitness function of keeping your genes going for longer. So as our complex, computer-based functions get better at figuring out what causes their fitness functions to be successful, they will have all of these very complex interactions. RAZ: I'm not walking away from this conversation optimistic. I'm troubled. HOWARD: Good. RAZ: Yeah, I'm troubled. HOWARD: Good. Be troubled. RAZ: Yeah. HOWARD: You know, being troubled is the correct response - but also excited. Be both. Because all of these people who say don't worry, everything's fine - there will always be jobs. Just feed the robots; feed the machines. Don't worry - to me, they're just the same as climate-change deniers. You know, they're ignoring the basic science that says this is something different. This is something we can't control. This is something we don't know where it's going. And this is something which can definitely have terrible societal outcomes. On the other hand, anybody who says the government should step in and regulate and control and stop all of this from happening - people shouldn't be doing this kind of research - they're just as bad. You know, they're saying the billions of people that don't have access to modern medicine should never be given it even though we have the technology today to provide it. So we need to be both. We need to be aware of the opportunities and aware of the threats. (SOUNDBITE OF MUSIC) RAZ: Jeremy Howard - he's a data scientist and the founding researcher at fast. ai. It's a company dedicated to making deep learning accessible to everyone. You can see his entire talk at ted. com. (SOUNDBITE OF SONG, \"ROBOT\") THE FUTUREHEADS: (Singing) I am a robot living like a robot, talk like a robot in the habitating way. Look up to the sky. . . RAZ: Hey, thanks for listening to our show on the Digital Industrial Revolution this week. If you want to find out more about who was on it, go to ted. npr. org. To see hundreds more TED Talks, check out ted. com or the TED app. Our production staff at NPR includes Jeff Rogers, Sanaz Meshkinpour, Jinae West, Neva Grant and Rachel Faulkner with help from Ramtim Arablouei and Daniel Shukin. Our intern is Thomas Lu. Our partners at TED are Chris Anderson, Kelly Stoetzel, Anna Phelan and Janet Lee. I'm Guy Raz, and you've been listening to ideas worth spreading right here on the TED Radio Hour from NPR. (SOUNDBITE OF SONG, \"ROBOT\") THE FUTUREHEADS: (Singing) I am a robot, living like a robot, talk like a robot in the habitating way.", "section": "TED Radio Hour", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-04-21-524700928": {"title": "Erik Brynjolfsson: In A Race With Machines, Can We Keep Up? : NPR", "url": "https://www.npr.org/2017/04/21/524700928/erik-brynjolfsson-in-a-race-with-machines-can-we-keep-up", "author": "No author found", "published_date": "2017-04-21", "content": "GUY RAZ, HOST: It's the TED Radio Hour from NPR. I'm Guy Raz. So robots and machines - they've made our lives a lot better. But one day maybe sooner than we think, they could also be the end of us, the last thing we humans invent. But before we go there, let's just reflect on how far we've actually come. Because if you look back at the course of human history, for most of that time the way the average person lived didn't really change all that much. ERIK BRYNJOLFSSON: Until the late 1700s when Watt developed a much better steam engine. RAZ: This is Erik - is it Brynjolfsson? Is that right? BRYNJOLFSSON: Yeah. A lot of consonants all next to each other. In Iceland, they find it very easy. RAZ: Erik's is a professor at MIT and the Watt he was referring to - he's talking about James Watt, the inventor of the Watt steam engine which was basically a really efficient steam engine. BRYNJOLFSSON: And that ignited what we call the first industrial revolution. RAZ: After that, the second industrial revolution and with it electricity and the birth of a world wide economy which then led to the first machine age and eventually the information age. BRYNJOLFSSON: And before that, living standards basically were flat. Since then, they've been growing 2 percent a year were about 30 times richer. So technology, machines is really, you know, arguably the most important thing that's happened to humanity in terms of our living standards. You could look to the introduction of digital computers in the 1950s. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED MAN #1: The electronic central computer. . . BRYNJOLFSSON: The personal computer in the 1980s. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED MAN #2: On January 24, Apple Computer will introduce Macintosh. BRYNJOLFSSON: When machines could first beat humans at games like chess in 1997. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED MAN #3: In an absolutely stunning, stunning 19-mover and Kasparov has just simply stormed away. BRYNJOLFSSON: I think those were all milestones of increasing import, an increasingly large effect on the economy and our lives. RAZ: Important because they prove that maybe one day they can be smarter than us? BRYNJOLFSSON: No doubt about it. I mean, let's face it. They already are much smarter than us at so many things. I mean, try to multiply two 10-digit numbers with each other or, you know, sift through a thousand documents. So there's lots of things that machines are better at including in mental task than us. There's many more that they're not as good at, but the direction is pretty obvious and the progress is clear. RAZ: On the show today, the Digital Industrial Revolution, ideas about the economic future we're creating, how we can shape it and if we'll find a place among the machines because if we can eventually create robots to do everything and to do it better, where does that leave us? A future of blissful human robot collaboration possible, yeah, or maybe something a little darker. Erik Brynjolfsson says right now we're at the beginning of a new machine age where technology is developing at such a rapid pace that it's kind of hard to keep up with. BRYNJOLFSSON: It starts with a small, exponential trend. And, as you know, exponential trends double and double and double. And each time you can barely detect them when they're small and they start becoming overwhelming. This is the biggest challenge of our society over the next 10 years is going to be can we adapt fast enough? RAZ: Here's Erik Brynjolfsson on the TED stage. (SOUNDBITE OF TED TALK)BRYNJOLFSSON: Computers get better, faster than anything else ever. A child's PlayStation today is more powerful than a military supercomputer from 1996. But our brains are wired for a linear world. As a result, exponential trends take us by surprise. I used to teach my students that there are some things, you know, computers just aren't good at like driving a car through traffic. But, perhaps, the most important invention, the most important invention is machine learning. Consider one project - IBM's Watson. At first Watson wasn't very good, but it improved at a rate faster than any human could, and Watson beat the world Jeopardy champion. At age 7, Watson is still kind of in its childhood. Recently, its teachers let it surf the internet unsupervised. The next day, it started answering questions with profanities. (LAUGHTER)BRYNJOLFSSON: Damn. But, you know, Watson is growing up fast. It's being tested for jobs in call centers, and it's getting them. It's applying for legal, banking and medical jobs and getting some of them. Like the first two industrial revolutions, the full implications of the new machine age are going to take at least a century to fully play out, but they are staggering. RAZ: How do you imagine the economy of the industrialized world changing over the next 20 to 25 years? Will it be noticeable? BRYNJOLFSSON: It will it be huge. The economy in the next 20 to 25 years is going to change more than they did in the last 20, 25 years. And that's because these exponential trends are affecting a bigger and bigger share of the economy. So we have some huge disruptions in store, and I can't predict exactly what the innovations are going to be. If I did, I would have already invented them. But I think they'll be comparable to the innovations we saw in the past 20, 25 years if not greater. RAZ: So like something as significant as is the internet presumably? BRYNJOLFSSON: I'm sure that you know the Internet of Things sort of doesn't take a lot of creativity to see that coming down the pipeline where they'll be literally trillions of objects all connected in this digital infrastructures like the Earth growing a skin and a nervous system where all the objects can communicate with each other, and that's just one small part of this new world. RAZ: I mean, we could have a future in the not too distant future in which truck drivers are out of work because trucks are automated and driverless. And not just truck drivers. . . BRYNJOLFSSON: I think that's likely. No, I think that's likely. RAZ: . . . But university professors because every case study. . . BRYNJOLFSSON: Whoa, wait a minute (laughter). RAZ: . . . And every book will will be processed by a machine. Every case study of a business problem will be studied by a machine which will then be able to be a better consultant than a human consultant, better journalists than me because they will be able to analyze every interview ever done. And that machine could maybe do a better job. I mean, that's not out of the realm of possibility. BRYNJOLFSSON: It's not out of the realm of possibility, although you've got to think about the timelines. It's most useful to think about not jobs but tasks. And within any given job, there are lots of different tasks. If you're a radiologist maybe reading the images machines can be able to do that better, maybe making the broader diagnosis and communicating it to the patients. For a long time, the humans are going to be better at that than the machines and so different parts of the job will be leveraged. In a way that's happened for centuries, and we've adapted. And it's made the people who had parts of their jobs automated more valuable and more productive to the extent that they are essential for the other components of their jobs. RAZ: But, I mean, do you believe it's possible down the line that we could create an artificial thing of metal and ones and zeroes that is more empathetic and exercises better judgement than us and is just all around smarter than we are? BRYNJOLFSSON: Well, I'm certain of it. There's no question that it's possible. I mean, you know, in between your ears is a proof that there's a physical object that can do all those things. And I don't think there's some ghost in there. I think it's made of atoms and obeys the laws of physics. So we know that it's feasible, according the laws of physics. Are we able to figure it out well enough? I think that's going to be a matter of time. (SOUNDBITE OF TED TALK)BRYNJOLFSSON: The new machine age can be dated to a day 15 years ago when Garry Kasparov, the world chess champion played Deep Blue, a supercomputer. The machine won that day, and today a chess program running on a cell phone can beat a human grandmaster. It got so bad that when he was asked what strategy he would use against a computer, Hein Donner, the Dutch grandmaster, replied I'd bring a hammer. (LAUGHTER)BRYNJOLFSSON: But today a computer is no longer the world chess champion, neither is a human because Kasparov organized a freestyle tournament where teams of humans and computers could work together. And the winning team had no grandmaster and it had no supercomputer. What they had was better teamwork, and they showed that a team of humans and computers working together could beat any computer or any human working alone. Racing with the machine beats racing against the machine. Technology is not destiny. We shape our destiny. RAZ: Yeah. I mean, it makes total sense that we are going to be working with machines in ways that we can't even imagine. BRYNJOLFSSON: Yeah. And I think we'll be working very closely with machines in a couple of different ways. I mean, one is a little bit like the way we're doing it now where we interact with them, where we ask machines to do some data analysis. And there'll be more and more of a division of labor where we ask the questions, and the machines provide the answers. Pablo Picasso once berated computers saying, well, they're not very interesting. All they do is provide answers. And, you know, he had a point, that the really interesting and important part of work is asking the right questions and that's - for a long time that's still going to be the domain of humans. Going a little further into the future, we'll start literally connecting to machines. Some of my colleagues at MIT here - some of them are working on a neural mesh that connects directly to your brain, and they've already done it with some disabled people and allowed them to move objects just by thinking. So right now, the bandwidth is pretty slow. You can type maybe I think it's about 10 words per minute with these brain meshes, but you can see where the future is going with that as well. RAZ: I mean, I hate to sound pessimistic because by nature I try to be optimistic, but I ask myself this question a lot which is, you know, is this the future we want? Have we gotten to a place where the train has left the station where we don't really have much of a choice about where that future is headed? BRYNJOLFSSON: Well, let me try and cheer you up a little bit. Let's just step back and look at the fundamental. RAZ: Yeah, please. BRYNJOLFSSON: What are you and I talking about? We're talking about a world with vastly more wealth, vastly more power to solve all sorts of problems, vastly less need for us to work. Most routine drudgery could be eliminated. Shame on us. Shame on us if we mess that up and turn that into a bad thing. I mean, wouldn't that be the weirdest irony in the world that we take more wealth and less work and say, oh, what a terrible thing? I think we could essentially eliminate poverty from planet Earth. We could cure most diseases. In the global millennium goals, we're on track to beat them and eliminate severe poverty. So there are lots of positive trends. I think the world in 25 years could be a much better version of the world we have today. But the role of humans would still be fundamentally at the center of that. RAZ: Erik Brynjolfsson He's a professor and director of the MIT Initiative on the digital economy. You can see his full talk at ted. com. On the show today, ideas about the digital industrial revolution. In a moment why this is all very, very good and very, very bad. I'm Guy Raz, and you're listening to the TED Radio Hour from NPR. GUY RAZ, HOST:  It's the TED Radio Hour from NPR. I'm Guy Raz. So robots and machines - they've made our lives a lot better. But one day maybe sooner than we think, they could also be the end of us, the last thing we humans invent. But before we go there, let's just reflect on how far we've actually come. Because if you look back at the course of human history, for most of that time the way the average person lived didn't really change all that much. ERIK BRYNJOLFSSON: Until the late 1700s when Watt developed a much better steam engine. RAZ: This is Erik - is it Brynjolfsson? Is that right? BRYNJOLFSSON: Yeah. A lot of consonants all next to each other. In Iceland, they find it very easy. RAZ: Erik's is a professor at MIT and the Watt he was referring to - he's talking about James Watt, the inventor of the Watt steam engine which was basically a really efficient steam engine. BRYNJOLFSSON: And that ignited what we call the first industrial revolution. RAZ: After that, the second industrial revolution and with it electricity and the birth of a world wide economy which then led to the first machine age and eventually the information age. BRYNJOLFSSON: And before that, living standards basically were flat. Since then, they've been growing 2 percent a year were about 30 times richer. So technology, machines is really, you know, arguably the most important thing that's happened to humanity in terms of our living standards. You could look to the introduction of digital computers in the 1950s. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED MAN #1: The electronic central computer. . . BRYNJOLFSSON: The personal computer in the 1980s. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED MAN #2: On January 24, Apple Computer will introduce Macintosh. BRYNJOLFSSON: When machines could first beat humans at games like chess in 1997. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED MAN #3: In an absolutely stunning, stunning 19-mover and Kasparov has just simply stormed away. BRYNJOLFSSON: I think those were all milestones of increasing import, an increasingly large effect on the economy and our lives. RAZ: Important because they prove that maybe one day they can be smarter than us? BRYNJOLFSSON: No doubt about it. I mean, let's face it. They already are much smarter than us at so many things. I mean, try to multiply two 10-digit numbers with each other or, you know, sift through a thousand documents. So there's lots of things that machines are better at including in mental task than us. There's many more that they're not as good at, but the direction is pretty obvious and the progress is clear. RAZ: On the show today, the Digital Industrial Revolution, ideas about the economic future we're creating, how we can shape it and if we'll find a place among the machines because if we can eventually create robots to do everything and to do it better, where does that leave us? A future of blissful human robot collaboration possible, yeah, or maybe something a little darker. Erik Brynjolfsson says right now we're at the beginning of a new machine age where technology is developing at such a rapid pace that it's kind of hard to keep up with. BRYNJOLFSSON: It starts with a small, exponential trend. And, as you know, exponential trends double and double and double. And each time you can barely detect them when they're small and they start becoming overwhelming. This is the biggest challenge of our society over the next 10 years is going to be can we adapt fast enough? RAZ: Here's Erik Brynjolfsson on the TED stage. (SOUNDBITE OF TED TALK) BRYNJOLFSSON: Computers get better, faster than anything else ever. A child's PlayStation today is more powerful than a military supercomputer from 1996. But our brains are wired for a linear world. As a result, exponential trends take us by surprise. I used to teach my students that there are some things, you know, computers just aren't good at like driving a car through traffic. But, perhaps, the most important invention, the most important invention is machine learning. Consider one project - IBM's Watson. At first Watson wasn't very good, but it improved at a rate faster than any human could, and Watson beat the world Jeopardy champion. At age 7, Watson is still kind of in its childhood. Recently, its teachers let it surf the internet unsupervised. The next day, it started answering questions with profanities. (LAUGHTER) BRYNJOLFSSON: Damn. But, you know, Watson is growing up fast. It's being tested for jobs in call centers, and it's getting them. It's applying for legal, banking and medical jobs and getting some of them. Like the first two industrial revolutions, the full implications of the new machine age are going to take at least a century to fully play out, but they are staggering. RAZ: How do you imagine the economy of the industrialized world changing over the next 20 to 25 years? Will it be noticeable? BRYNJOLFSSON: It will it be huge. The economy in the next 20 to 25 years is going to change more than they did in the last 20, 25 years. And that's because these exponential trends are affecting a bigger and bigger share of the economy. So we have some huge disruptions in store, and I can't predict exactly what the innovations are going to be. If I did, I would have already invented them. But I think they'll be comparable to the innovations we saw in the past 20, 25 years if not greater. RAZ: So like something as significant as is the internet presumably? BRYNJOLFSSON: I'm sure that you know the Internet of Things sort of doesn't take a lot of creativity to see that coming down the pipeline where they'll be literally trillions of objects all connected in this digital infrastructures like the Earth growing a skin and a nervous system where all the objects can communicate with each other, and that's just one small part of this new world. RAZ: I mean, we could have a future in the not too distant future in which truck drivers are out of work because trucks are automated and driverless. And not just truck drivers. . . BRYNJOLFSSON: I think that's likely. No, I think that's likely. RAZ: . . . But university professors because every case study. . . BRYNJOLFSSON: Whoa, wait a minute (laughter). RAZ: . . . And every book will will be processed by a machine. Every case study of a business problem will be studied by a machine which will then be able to be a better consultant than a human consultant, better journalists than me because they will be able to analyze every interview ever done. And that machine could maybe do a better job. I mean, that's not out of the realm of possibility. BRYNJOLFSSON: It's not out of the realm of possibility, although you've got to think about the timelines. It's most useful to think about not jobs but tasks. And within any given job, there are lots of different tasks. If you're a radiologist maybe reading the images machines can be able to do that better, maybe making the broader diagnosis and communicating it to the patients. For a long time, the humans are going to be better at that than the machines and so different parts of the job will be leveraged. In a way that's happened for centuries, and we've adapted. And it's made the people who had parts of their jobs automated more valuable and more productive to the extent that they are essential for the other components of their jobs. RAZ: But, I mean, do you believe it's possible down the line that we could create an artificial thing of metal and ones and zeroes that is more empathetic and exercises better judgement than us and is just all around smarter than we are? BRYNJOLFSSON: Well, I'm certain of it. There's no question that it's possible. I mean, you know, in between your ears is a proof that there's a physical object that can do all those things. And I don't think there's some ghost in there. I think it's made of atoms and obeys the laws of physics. So we know that it's feasible, according the laws of physics. Are we able to figure it out well enough? I think that's going to be a matter of time. (SOUNDBITE OF TED TALK) BRYNJOLFSSON: The new machine age can be dated to a day 15 years ago when Garry Kasparov, the world chess champion played Deep Blue, a supercomputer. The machine won that day, and today a chess program running on a cell phone can beat a human grandmaster. It got so bad that when he was asked what strategy he would use against a computer, Hein Donner, the Dutch grandmaster, replied I'd bring a hammer. (LAUGHTER) BRYNJOLFSSON: But today a computer is no longer the world chess champion, neither is a human because Kasparov organized a freestyle tournament where teams of humans and computers could work together. And the winning team had no grandmaster and it had no supercomputer. What they had was better teamwork, and they showed that a team of humans and computers working together could beat any computer or any human working alone. Racing with the machine beats racing against the machine. Technology is not destiny. We shape our destiny. RAZ: Yeah. I mean, it makes total sense that we are going to be working with machines in ways that we can't even imagine. BRYNJOLFSSON: Yeah. And I think we'll be working very closely with machines in a couple of different ways. I mean, one is a little bit like the way we're doing it now where we interact with them, where we ask machines to do some data analysis. And there'll be more and more of a division of labor where we ask the questions, and the machines provide the answers. Pablo Picasso once berated computers saying, well, they're not very interesting. All they do is provide answers. And, you know, he had a point, that the really interesting and important part of work is asking the right questions and that's - for a long time that's still going to be the domain of humans. Going a little further into the future, we'll start literally connecting to machines. Some of my colleagues at MIT here - some of them are working on a neural mesh that connects directly to your brain, and they've already done it with some disabled people and allowed them to move objects just by thinking. So right now, the bandwidth is pretty slow. You can type maybe I think it's about 10 words per minute with these brain meshes, but you can see where the future is going with that as well. RAZ: I mean, I hate to sound pessimistic because by nature I try to be optimistic, but I ask myself this question a lot which is, you know, is this the future we want? Have we gotten to a place where the train has left the station where we don't really have much of a choice about where that future is headed? BRYNJOLFSSON: Well, let me try and cheer you up a little bit. Let's just step back and look at the fundamental. RAZ: Yeah, please. BRYNJOLFSSON: What are you and I talking about? We're talking about a world with vastly more wealth, vastly more power to solve all sorts of problems, vastly less need for us to work. Most routine drudgery could be eliminated. Shame on us. Shame on us if we mess that up and turn that into a bad thing. I mean, wouldn't that be the weirdest irony in the world that we take more wealth and less work and say, oh, what a terrible thing? I think we could essentially eliminate poverty from planet Earth. We could cure most diseases. In the global millennium goals, we're on track to beat them and eliminate severe poverty. So there are lots of positive trends. I think the world in 25 years could be a much better version of the world we have today. But the role of humans would still be fundamentally at the center of that. RAZ: Erik Brynjolfsson He's a professor and director of the MIT Initiative on the digital economy. You can see his full talk at ted. com. On the show today, ideas about the digital industrial revolution. In a moment why this is all very, very good and very, very bad. I'm Guy Raz, and you're listening to the TED Radio Hour from NPR.", "section": "TED Radio Hour", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-04-24-525441604": {"title": "Hacking Lake Erie: Tech Competition Seeks Solutions To Water-Related Problems : NPR", "url": "https://www.npr.org/2017/04/24/525441604/hacking-lake-erie-tech-competition-seeks-solutions-to-water-related-problems", "author": "No author found", "published_date": "2017-04-24", "content": "AUDIE CORNISH, HOST: Aquahacking is a term for finding tech-based solutions for water-related problems. Imagine if a smartphone app could help prevent a toxic algae bloom. The idea of aquahacking comes from Canada and Europe but it's now making its way to the U. S. and Lake Erie. Elizabeth Miller of WCPN ideastream explains. ELIZABETH MILLER, BYLINE: For many people, the word hacking has a pretty bad reputation. But in the tech world, hacking conferences are happening all the time. They're usually weekend-long competitions aimed at finding new ways to treat diseases or address social ills. Lake Erie has environmental issues decades old. There's legacy pollution, aging water infrastructure and harmful algae growth spurred by fertilizer runoff. Even though it's the shallowest of the Great Lakes, Erie provides drinking water for about 11 million people. It borders four states and one Canadian province. Erie Hack is a months-long competition focused on finding solutions. It's the first time a Great Lake has ever been hacked. And the contest included teams from six cities around the lake. Bryan Stubbs heads the Cleveland Water Alliance, the organization hosting Erie Hack. BRYAN STUBBS: This is not a traditional hackathon. It's not a 24 or 48-hour event. Water's so complex that it requires more time and more efforts. MILLER: Nine finalists will compete in Cleveland next week for a grand prize - $40,000 plus $10,000 in consulting services. One of the competing teams calls itself Water Warriors. They're all scientists from the University of Akron with backgrounds in chemistry, engineering, biomimicry and polymer science. In a campus lab, Adam Smith of the Water Warriors test their tool - a spectrometer that will measure nutrients like phosphorus and nitrogen which can lead to harmful algae blooms. ADAM SMITH: It started as a way to design an inexpensive laboratory instrument. This is a spectrometer that you would use to measure chemical concentrations. MILLER: The project is geared toward students. And each classroom kit would cost around $50. Smith says it's really simple to use. SMITH: They'll go to the link. We'll give them a little test tube. The test tube will be in the kit. They'll go to the lake, grab lake water. There's a little dropper. We have to add some chemicals to it because you can't see the chemical we're trying to test. MILLER: The sample is then placed in a spectrometer, a visual device that splits light into separate colors. SMITH: As light passes through something with color, some of the light's absorbed, then we get the concentration. MILLER: That's the concentration of phosphorus or nitrogen. Students take a picture of the spectrometer with their phone and post it on the Water Warriors website, a key step in building a water sample database. Team member Banafsheh Khakipoor says this kind of data is usually collected by researchers or organizations. BANAFSHEH KHAKIPOOR: Here we want to give this power, like, to the communities. They're doing the measurements, so it's their own measurements. And they will be able to say, OK, I know what's happening based on my own data. MILLER: Other Eerie Hack finalist ideas include an app that doles out discounts for low water usage and a drone that can collect harmful algae. Bryan Stubbs says there's been a renewed interest in the Great Lakes. Stubbs says extra funding will make sure several Eerie Hack teams continue beyond the final competition even if they don't win the grand prize. Team Water Warriors is already in talks to test its kit at park systems and programs across the state. For NPR News, I'm Elizabeth Miller in Cleveland. CORNISH: That story came to us from the public radio station collaboration Great Lakes Today. (SOUNDBITE OF PROJECT SANDRO'S \"BLAZER\") AUDIE CORNISH, HOST:  Aquahacking is a term for finding tech-based solutions for water-related problems. Imagine if a smartphone app could help prevent a toxic algae bloom. The idea of aquahacking comes from Canada and Europe but it's now making its way to the U. S. and Lake Erie. Elizabeth Miller of WCPN ideastream explains. ELIZABETH MILLER, BYLINE: For many people, the word hacking has a pretty bad reputation. But in the tech world, hacking conferences are happening all the time. They're usually weekend-long competitions aimed at finding new ways to treat diseases or address social ills. Lake Erie has environmental issues decades old. There's legacy pollution, aging water infrastructure and harmful algae growth spurred by fertilizer runoff. Even though it's the shallowest of the Great Lakes, Erie provides drinking water for about 11 million people. It borders four states and one Canadian province. Erie Hack is a months-long competition focused on finding solutions. It's the first time a Great Lake has ever been hacked. And the contest included teams from six cities around the lake. Bryan Stubbs heads the Cleveland Water Alliance, the organization hosting Erie Hack. BRYAN STUBBS: This is not a traditional hackathon. It's not a 24 or 48-hour event. Water's so complex that it requires more time and more efforts. MILLER: Nine finalists will compete in Cleveland next week for a grand prize - $40,000 plus $10,000 in consulting services. One of the competing teams calls itself Water Warriors. They're all scientists from the University of Akron with backgrounds in chemistry, engineering, biomimicry and polymer science. In a campus lab, Adam Smith of the Water Warriors test their tool - a spectrometer that will measure nutrients like phosphorus and nitrogen which can lead to harmful algae blooms. ADAM SMITH: It started as a way to design an inexpensive laboratory instrument. This is a spectrometer that you would use to measure chemical concentrations. MILLER: The project is geared toward students. And each classroom kit would cost around $50. Smith says it's really simple to use. SMITH: They'll go to the link. We'll give them a little test tube. The test tube will be in the kit. They'll go to the lake, grab lake water. There's a little dropper. We have to add some chemicals to it because you can't see the chemical we're trying to test. MILLER: The sample is then placed in a spectrometer, a visual device that splits light into separate colors. SMITH: As light passes through something with color, some of the light's absorbed, then we get the concentration. MILLER: That's the concentration of phosphorus or nitrogen. Students take a picture of the spectrometer with their phone and post it on the Water Warriors website, a key step in building a water sample database. Team member Banafsheh Khakipoor says this kind of data is usually collected by researchers or organizations. BANAFSHEH KHAKIPOOR: Here we want to give this power, like, to the communities. They're doing the measurements, so it's their own measurements. And they will be able to say, OK, I know what's happening based on my own data. MILLER: Other Eerie Hack finalist ideas include an app that doles out discounts for low water usage and a drone that can collect harmful algae. Bryan Stubbs says there's been a renewed interest in the Great Lakes. Stubbs says extra funding will make sure several Eerie Hack teams continue beyond the final competition even if they don't win the grand prize. Team Water Warriors is already in talks to test its kit at park systems and programs across the state. For NPR News, I'm Elizabeth Miller in Cleveland. CORNISH: That story came to us from the public radio station collaboration Great Lakes Today. (SOUNDBITE OF PROJECT SANDRO'S \"BLAZER\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-04-24-525413427": {"title": "The Warfare May Be Remote But The Trauma Is Real : NPR", "url": "https://www.npr.org/2017/04/24/525413427/for-drone-pilots-warfare-may-be-remote-but-the-trauma-is-real", "author": "No author found", "published_date": "2017-04-24", "content": "AUDIE CORNISH, HOST: Pilots and the intelligence analysts who work with drones may not physically be in harm's way but they do face psychological dangers. NPR's Sarah McCammon reports as the U. S. Air Force moves toward more remote warfare, it's increasingly aware of the mental risks. SARAH MCCAMMON, BYLINE: After high school, Kimi thought she knew what she wanted to do. KIMI: I wanted to go to art school but that was too expensive, so. . . MCCAMMON: So Kimi joined the military. The Air Force won't allow us to use her last name because of the high security work she does. She's now 26 and a staff sergeant stationed at Langley Air Force Base in Hampton, Va. , where she spends hours monitoring video feeds from war zones. KIMI: Since I want to go to art school for photography, the recruiter told me that this is like working with photography but - (laughter) so it's not. MCCAMMON: It's really not, not even close. Colonel Jason Brown is the 480th Intelligence Surveillance and Reconnaissance wing commander. He says analysts like her watch events unfold thousands of miles away in some of the most troubled places in the world. JASON BROWN: They're exposed to the most gruesome things that you can think about could happen on a battlefield. They find mass graves. They've witnessed executions. MCCAMMON: Brown says it's not uncommon to see civilians being raped or killed by groups like ISIS in almost real time. BROWN: I mean, that's warfare, clear and simple, right? And it's in HDTV. MCCAMMON: They can't just look away because they're supporting U. S. troops and their allies on the ground, watching for threats and helping guide aircraft and drone pilots. Lieutenant Colonel Cameron Thurman says observing the horrors of war, even from a distance, carries a heavy burden. CAMERON THURMAN: Everybody understands that. What was not widely understood is the level of exposure that our wing has to that type of incident. We see it all. MCCAMMON: Thurman is a medical doctor who oversees a team of physicians and psychologists embedded with the wing here in Virginia. The Air Force made that decision a few years ago in response to the higher rates of occupational stress and suicidal thoughts among airmen doing this work. Thurman says it's not just what they see but the weight of decisions they have to make. THURMAN: Their job is to decide who on that battlefield gets blown up and who on that battlefield gets protected. MCCAMMON: Staff Sergeant Kimi remembers one especially tough call a few years ago that prompted her to reach out for support. KIMI: To this day, I still think about it but it's been a couple of years. And I made the correct decision but knowing that I could have made the wrong one and a lot of people could have died because of a wrong decision, I could not stop thinking about it. MCCAMMON: Kimi says she'd come off her night shift wired and unable to sleep. That's where psychologists with security clearances like Lieutenant Colonel Alan Ogle can come in. ALAN OGLE: For these folks, they are going literally from combat to cul-de-sac in a short drive - 10 minutes, 15 minutes' drive home. They've gone from being eyes in, head in the fight to then being involved in all the in-garrison responsibilities that we have where they're a spouse, they're parents. MCCAMMON: As the U. S. military shifts to more of this kind of warfare, Colonel Brown says it's important to acknowledge the psychological impact of the work. BROWN: In the 21st century, in the information age, warfighting is no longer a matter of geography. It's a mentality. And these airmen, no doubt, are warfighters. And they have the burden of life and death on their shoulders every day, every time they walk into that facility. MCCAMMON: A burden that Brown says the Air Force is trying to ease by treating the trauma of remote warfare more like the effects of traditional combat. Sarah McCammon, NPR News, Hampton, Virginia. AUDIE CORNISH, HOST:  Pilots and the intelligence analysts who work with drones may not physically be in harm's way but they do face psychological dangers. NPR's Sarah McCammon reports as the U. S. Air Force moves toward more remote warfare, it's increasingly aware of the mental risks. SARAH MCCAMMON, BYLINE: After high school, Kimi thought she knew what she wanted to do. KIMI: I wanted to go to art school but that was too expensive, so. . . MCCAMMON: So Kimi joined the military. The Air Force won't allow us to use her last name because of the high security work she does. She's now 26 and a staff sergeant stationed at Langley Air Force Base in Hampton, Va. , where she spends hours monitoring video feeds from war zones. KIMI: Since I want to go to art school for photography, the recruiter told me that this is like working with photography but - (laughter) so it's not. MCCAMMON: It's really not, not even close. Colonel Jason Brown is the 480th Intelligence Surveillance and Reconnaissance wing commander. He says analysts like her watch events unfold thousands of miles away in some of the most troubled places in the world. JASON BROWN: They're exposed to the most gruesome things that you can think about could happen on a battlefield. They find mass graves. They've witnessed executions. MCCAMMON: Brown says it's not uncommon to see civilians being raped or killed by groups like ISIS in almost real time. BROWN: I mean, that's warfare, clear and simple, right? And it's in HDTV. MCCAMMON: They can't just look away because they're supporting U. S. troops and their allies on the ground, watching for threats and helping guide aircraft and drone pilots. Lieutenant Colonel Cameron Thurman says observing the horrors of war, even from a distance, carries a heavy burden. CAMERON THURMAN: Everybody understands that. What was not widely understood is the level of exposure that our wing has to that type of incident. We see it all. MCCAMMON: Thurman is a medical doctor who oversees a team of physicians and psychologists embedded with the wing here in Virginia. The Air Force made that decision a few years ago in response to the higher rates of occupational stress and suicidal thoughts among airmen doing this work. Thurman says it's not just what they see but the weight of decisions they have to make. THURMAN: Their job is to decide who on that battlefield gets blown up and who on that battlefield gets protected. MCCAMMON: Staff Sergeant Kimi remembers one especially tough call a few years ago that prompted her to reach out for support. KIMI: To this day, I still think about it but it's been a couple of years. And I made the correct decision but knowing that I could have made the wrong one and a lot of people could have died because of a wrong decision, I could not stop thinking about it. MCCAMMON: Kimi says she'd come off her night shift wired and unable to sleep. That's where psychologists with security clearances like Lieutenant Colonel Alan Ogle can come in. ALAN OGLE: For these folks, they are going literally from combat to cul-de-sac in a short drive - 10 minutes, 15 minutes' drive home. They've gone from being eyes in, head in the fight to then being involved in all the in-garrison responsibilities that we have where they're a spouse, they're parents. MCCAMMON: As the U. S. military shifts to more of this kind of warfare, Colonel Brown says it's important to acknowledge the psychological impact of the work. BROWN: In the 21st century, in the information age, warfighting is no longer a matter of geography. It's a mentality. And these airmen, no doubt, are warfighters. And they have the burden of life and death on their shoulders every day, every time they walk into that facility. MCCAMMON: A burden that Brown says the Air Force is trying to ease by treating the trauma of remote warfare more like the effects of traditional combat. Sarah McCammon, NPR News, Hampton, Virginia.", "section": "National", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-04-26-525675168": {"title": "Facebook Responding To Another Broadcasted Killing : NPR", "url": "https://www.npr.org/2017/04/26/525675168/facebook-responding-to-another-broadcasted-killing", "author": "No author found", "published_date": "2017-04-26", "content": "STEVE INSKEEP, HOST: Many people will find this next story disturbing. It's the story of the latest murder shown on Facebook. The world's biggest social network has offered condolences but has not said much about just how it addressed the violent content from Thailand. We are going to talk about some troubling details, which is going to take us about four minutes or so. NPR's Aarti Shahani is on the line. Hi, Aarti. AARTI SHAHANI, BYLINE: Hi. INSKEEP: I don't even like to say that this involves the killing of a child. What happened? SHAHANI: Well, it does. A man killed his infant daughter. He livestreamed it on Facebook Live, then he turned off the camera and killed himself. This happened in Thailand. According to police in Thailand, two videos of the incident were up for nearly 24 hours before Facebook finally took it down. Thai police contacted Facebook Tuesday afternoon local time, and the videos were pulled at about 5 p. m. Now, Facebook would not tell NPR when exactly the company became aware of the videos. Was it from Thai police, or was it earlier perhaps, from a user who reported it as it was happening in livestream? We don't know. And these are, by the way, the kinds of details Facebook did decide to provide about another recent killing posted on the site of a shooter in Cleveland who killed an elderly man. But in this Thailand case, the company isn't ready to share these basic details. INSKEEP: So many questions to pursue here. Let me start with this one. As you alluded to, there have been multiple killings now in which people chose to show the murder on Facebook. Does any evidence suggest that Facebook is actually driving the killings - that the chance to be live is influencing people's behavior? SHAHANI: Well, I know from conversations with people close to the company that that is absolutely a concern internally. I mean, the idea that you can broadcast yourself and have all this power in the media is a motivation for certain violent acts. And people within Facebook are aware of that. It's something that they are talking about, yeah. INSKEEP: OK. So what is Facebook's legal responsibility when someone commits a murder on Facebook? SHAHANI: Well, you know, it's interesting. This isn't really a legal so much as an ethical question. And the reason I say that is that, at least under U. S. law, a law passed by Congress in 1996, Facebook is not liable for just about any user-posted content. Right? And the rationale is interesting, too, by the way. It comes down to a difference between how the internet and television worked in the '90s. You know, back then on TV, you'd flip the channel and get hit with something you might not want to see, so TV stations had to take responsibility for their content choices. But on the internet back then, you typically didn't get content you didn't want to see. You were very intentional about digging for things, digging for pages online. So you couldn't get unexpected exposure. Now today, in 2017, the internet's very different. Algorithms feed you infinite amounts of stuff you might not intentionally want, but the '90s regulatory norms remain intact. INSKEEP: And of course, the '90s is when a lot of the current rules were made. Now, Mark Zuckerberg, the head of state - of Facebook has said we want to do all we can to prevent this sort of activity on Facebook. But what does Facebook really want to do? SHAHANI: (Laughter) That's a great question. You know, he very publicly onstage last week said, we will do all we can to prevent tragedies like this from happening. But he didn't give a single detail. A spokesperson said this is an appalling incident. Now an interesting fact is that when Facebook rolled out livestream video, Facebook Live, a year ago, a source familiar with the company tells NPR - when Live was being developed, people inside Facebook absolutely had conversations about the fact that yes, of course Facebook users would commit murder on Facebook Live. People were already posting murder videos on YouTube and Twitter. So why wouldn't they use Live to do that? That part wasn't surprising to them. INSKEEP: And so now the question is, does Facebook try harder with live monitors or artificial intelligence to get on top of these kinds of incidents? NPR's Aarti Shahani covering this disturbing story - Aarti, thanks very much. SHAHANI: Thank you. STEVE INSKEEP, HOST:  Many people will find this next story disturbing. It's the story of the latest murder shown on Facebook. The world's biggest social network has offered condolences but has not said much about just how it addressed the violent content from Thailand. We are going to talk about some troubling details, which is going to take us about four minutes or so. NPR's Aarti Shahani is on the line. Hi, Aarti. AARTI SHAHANI, BYLINE: Hi. INSKEEP: I don't even like to say that this involves the killing of a child. What happened? SHAHANI: Well, it does. A man killed his infant daughter. He livestreamed it on Facebook Live, then he turned off the camera and killed himself. This happened in Thailand. According to police in Thailand, two videos of the incident were up for nearly 24 hours before Facebook finally took it down. Thai police contacted Facebook Tuesday afternoon local time, and the videos were pulled at about 5 p. m. Now, Facebook would not tell NPR when exactly the company became aware of the videos. Was it from Thai police, or was it earlier perhaps, from a user who reported it as it was happening in livestream? We don't know. And these are, by the way, the kinds of details Facebook did decide to provide about another recent killing posted on the site of a shooter in Cleveland who killed an elderly man. But in this Thailand case, the company isn't ready to share these basic details. INSKEEP: So many questions to pursue here. Let me start with this one. As you alluded to, there have been multiple killings now in which people chose to show the murder on Facebook. Does any evidence suggest that Facebook is actually driving the killings - that the chance to be live is influencing people's behavior? SHAHANI: Well, I know from conversations with people close to the company that that is absolutely a concern internally. I mean, the idea that you can broadcast yourself and have all this power in the media is a motivation for certain violent acts. And people within Facebook are aware of that. It's something that they are talking about, yeah. INSKEEP: OK. So what is Facebook's legal responsibility when someone commits a murder on Facebook? SHAHANI: Well, you know, it's interesting. This isn't really a legal so much as an ethical question. And the reason I say that is that, at least under U. S. law, a law passed by Congress in 1996, Facebook is not liable for just about any user-posted content. Right? And the rationale is interesting, too, by the way. It comes down to a difference between how the internet and television worked in the '90s. You know, back then on TV, you'd flip the channel and get hit with something you might not want to see, so TV stations had to take responsibility for their content choices. But on the internet back then, you typically didn't get content you didn't want to see. You were very intentional about digging for things, digging for pages online. So you couldn't get unexpected exposure. Now today, in 2017, the internet's very different. Algorithms feed you infinite amounts of stuff you might not intentionally want, but the '90s regulatory norms remain intact. INSKEEP: And of course, the '90s is when a lot of the current rules were made. Now, Mark Zuckerberg, the head of state - of Facebook has said we want to do all we can to prevent this sort of activity on Facebook. But what does Facebook really want to do? SHAHANI: (Laughter) That's a great question. You know, he very publicly onstage last week said, we will do all we can to prevent tragedies like this from happening. But he didn't give a single detail. A spokesperson said this is an appalling incident. Now an interesting fact is that when Facebook rolled out livestream video, Facebook Live, a year ago, a source familiar with the company tells NPR - when Live was being developed, people inside Facebook absolutely had conversations about the fact that yes, of course Facebook users would commit murder on Facebook Live. People were already posting murder videos on YouTube and Twitter. So why wouldn't they use Live to do that? That part wasn't surprising to them. INSKEEP: And so now the question is, does Facebook try harder with live monitors or artificial intelligence to get on top of these kinds of incidents? NPR's Aarti Shahani covering this disturbing story - Aarti, thanks very much. SHAHANI: Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-04-27-525833226": {"title": "Instead Of Showing Off Wealth, Some Show Off Busy Schedules : NPR", "url": "https://www.npr.org/2017/04/27/525833226/instead-of-showing-off-wealth-some-show-off-busy-schedules", "author": "No author found", "published_date": "2017-04-27", "content": "STEVE INSKEEP, HOST:  There are many ways to show off. You can do it on social media. Post pictures on Facebook about a fancy dinner or your new sports car or some bling or even that fabulous vacation you're taking that nobody else is taking. Well, there's a new status symbol. And to understand what it is, we're joined by NPR's social science correspondent. Shankar Vedantam is here once again. Hi, Shankar. SHANKAR VEDANTAM, BYLINE: Hi, Steve. INSKEEP: OK, what's this status symbol? VEDANTAM: The latest status symbol is time, or rather the lack of time. INSKEEP: What? VEDANTAM: Let me back up for a second, Steve. In many parts of the world, wealthy people are often called the idle rich. If you're a person of means, you don't do something as lowly as work for a living. INSKEEP: You have people for that. VEDANTAM: Exactly, you live a life of leisure. I was speaking with Neeru Paharia. She's a marketing professor at Georgetown University. She told me that in new research she's done, the status symbol of leisure has been turned on its head in the United States. NEERU PAHARIA: In certain cultures, spending your time relaxing, spending your time on vacations is a sign of social status. But in American culture, it's actually quite different, where people somehow seem to attribute higher status, higher social standing to individuals who are always busy, always working hard, always spending many hours at work. INSKEEP: Oh, wait a minute. So I'm so important, I have lots to do. I mean, it's that moment you see in the movie. Shankar, I've got 2 minutes. You get 2 minutes of my time. Tell me your pitch. Go on. VEDANTAM: (Laughter) Exactly. Now, lots of people who are important are also very busy but at least in the United States, we've come to associate being busy with being very important. In a series of experiments Paharia's conducted with Silvia Bellezza and Anat Keinan, she's found that volunteers unconsciously conclude that busy people are also important and high status people. Paharia's examined the Twitter feeds of celebrities. She finds here again, rather than boast about their wealth, many celebrities want to boast about their lack of time. PAHARIA: Many of them were kind of complaining or humble bragging about how busy they were, about how, you know, in the morning they had to record an album. In the afternoon they had to go meet with their book publisher. And in the evening, they had so many events to go to. They want to show off essentially that they're busy. INSKEEP: OK. I've really only got about 60 seconds here to finish this. VEDANTAM: (Laughter). INSKEEP: But, of course, some people are not busy doing seemingly exciting things like meeting with book publishers, they're working multiple jobs to make ends meet or looking after multiple kids. Do we think of them as important? VEDANTAM: So that's a really good point, Steve. There are clearly people who are overworked because they're trying to make ends meet. But even for people of low socioeconomic status, when Paharia compares them against other people from the same social class, she finds that volunteers tend to think of the poor person who's busy as being of higher status. But you're getting at an important boundary condition of this phenomenon, Steve. When people are busy not from their own volition but because someone else is forcing them to be busy, there is a weaker relationship between being busy and being seen to be of high status. In other words, when you flash this particular status symbol, it's important to let people know not only that you're very busy but that you, yourself. . . INSKEEP: You want to be. VEDANTAM: . . . Have chosen to be busy. INSKEEP: Shocker, I'm so honored that you were willing to take a little bit of your very precious time to come talk to us here. VEDANTAM: I barely have time to say thanks, Steve. INSKEEP: I imagine that's true. Shankar Vedantam, who regularly joins us - when he can - to talk about social science research. He explores how people use time and money to express their inner feelings on the podcast Hidden Brain. Hope you have time to listen. (SOUNDBITE OF THE ALBUM LEAF'S \"GLIMMERING LIGHTS\") STEVE INSKEEP, HOST:   There are many ways to show off. You can do it on social media. Post pictures on Facebook about a fancy dinner or your new sports car or some bling or even that fabulous vacation you're taking that nobody else is taking. Well, there's a new status symbol. And to understand what it is, we're joined by NPR's social science correspondent. Shankar Vedantam is here once again. Hi, Shankar. SHANKAR VEDANTAM, BYLINE: Hi, Steve. INSKEEP: OK, what's this status symbol? VEDANTAM: The latest status symbol is time, or rather the lack of time. INSKEEP: What? VEDANTAM: Let me back up for a second, Steve. In many parts of the world, wealthy people are often called the idle rich. If you're a person of means, you don't do something as lowly as work for a living. INSKEEP: You have people for that. VEDANTAM: Exactly, you live a life of leisure. I was speaking with Neeru Paharia. She's a marketing professor at Georgetown University. She told me that in new research she's done, the status symbol of leisure has been turned on its head in the United States. NEERU PAHARIA: In certain cultures, spending your time relaxing, spending your time on vacations is a sign of social status. But in American culture, it's actually quite different, where people somehow seem to attribute higher status, higher social standing to individuals who are always busy, always working hard, always spending many hours at work. INSKEEP: Oh, wait a minute. So I'm so important, I have lots to do. I mean, it's that moment you see in the movie. Shankar, I've got 2 minutes. You get 2 minutes of my time. Tell me your pitch. Go on. VEDANTAM: (Laughter) Exactly. Now, lots of people who are important are also very busy but at least in the United States, we've come to associate being busy with being very important. In a series of experiments Paharia's conducted with Silvia Bellezza and Anat Keinan, she's found that volunteers unconsciously conclude that busy people are also important and high status people. Paharia's examined the Twitter feeds of celebrities. She finds here again, rather than boast about their wealth, many celebrities want to boast about their lack of time. PAHARIA: Many of them were kind of complaining or humble bragging about how busy they were, about how, you know, in the morning they had to record an album. In the afternoon they had to go meet with their book publisher. And in the evening, they had so many events to go to. They want to show off essentially that they're busy. INSKEEP: OK. I've really only got about 60 seconds here to finish this. VEDANTAM: (Laughter). INSKEEP: But, of course, some people are not busy doing seemingly exciting things like meeting with book publishers, they're working multiple jobs to make ends meet or looking after multiple kids. Do we think of them as important? VEDANTAM: So that's a really good point, Steve. There are clearly people who are overworked because they're trying to make ends meet. But even for people of low socioeconomic status, when Paharia compares them against other people from the same social class, she finds that volunteers tend to think of the poor person who's busy as being of higher status. But you're getting at an important boundary condition of this phenomenon, Steve. When people are busy not from their own volition but because someone else is forcing them to be busy, there is a weaker relationship between being busy and being seen to be of high status. In other words, when you flash this particular status symbol, it's important to let people know not only that you're very busy but that you, yourself. . . INSKEEP: You want to be. VEDANTAM: . . . Have chosen to be busy. INSKEEP: Shocker, I'm so honored that you were willing to take a little bit of your very precious time to come talk to us here. VEDANTAM: I barely have time to say thanks, Steve. INSKEEP: I imagine that's true. Shankar Vedantam, who regularly joins us - when he can - to talk about social science research. He explores how people use time and money to express their inner feelings on the podcast Hidden Brain. Hope you have time to listen. (SOUNDBITE OF THE ALBUM LEAF'S \"GLIMMERING LIGHTS\")", "section": "Hidden Brain", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-04-28-526092530": {"title": "National Security Agency To Limit Collection Of Internet Communication : NPR", "url": "https://www.npr.org/2017/04/28/526092530/nsa-to-limit-some-collection-of-internet-communication", "author": "No author found", "published_date": "2017-04-28", "content": "", "section": "National Security", "disclaimer": ""}, "2017-04-28-525992223": {"title": "Survey Says Workers Are Leaving Tech Jobs Because Of Mistreatment : NPR", "url": "https://www.npr.org/2017/04/28/525992223/survery-says-workers-are-leaving-tech-jobs-because-of-mistreatment", "author": "No author found", "published_date": "2017-04-28", "content": "STEVE INSKEEP, HOST: The tech industry is getting hit hard by turnover among workers who think they've been treated unfairly. That's the conclusion of a national study that examines why workers leave their jobs in tech. The problem is most acute among underrepresented workers, meaning women, racial minorities, ethnic minorities. NPR's Aarti Shahani reports. AARTI SHAHANI, BYLINE: There are many ugly anecdotes about what tech companies are like on the inside - places where women are sexually harassed and blocked from promotion, where blacks and Latinos don't get hired. This new survey is an effort to pivot from anecdotes to patterns. And it found 37 percent of the adults surveyed indicated that unfairness played a major role in their decision to leave their company. Lead author Allison Scott on a conference call for press. (SOUNDBITE OF PRESS CONFERENCE)ALLISON SCOTT: So this was the largest driver or turnover in the sample by almost two times. SCOTT: The Kapor Center for Social Impact, a group that promotes workplace diversity, partnered with the Harris Poll to survey about 2,000 people online. Researchers found the No. 1 reason for leaving was not a better job offer; it was mistreatment, especially for women and underrepresented minorities. The survey considered four types of unfair practices. (SOUNDBITE OF PRESS CONFERENCE)SCOTT: One being unfair people management practices, things like job assignments and promotions; two being stereotyping; three, sexual harassment; and four, bullying. SHAHANI: About 80 percent of respondents said they'd experienced at least one of these. But the type experienced varied by race, gender and sexual orientation. For example, white and Asian men reported being more unfairly managed than men of other races. LGBTQ respondents reported the highest rate of bullying. And women. . . (SOUNDBITE OF PRESS CONFERENCE)SCOTT: One in 10 women reported unwanted sexual attention or harassment. SHAHANI: In recent years, the largest tech companies have begun to disclose how many women and underrepresented minorities they're hiring. But with the exception of the chip maker Intel, no major company is disclosing how many of these employees are staying versus leaving. Aarti Shahani, NPR News, San Francisco. STEVE INSKEEP, HOST:  The tech industry is getting hit hard by turnover among workers who think they've been treated unfairly. That's the conclusion of a national study that examines why workers leave their jobs in tech. The problem is most acute among underrepresented workers, meaning women, racial minorities, ethnic minorities. NPR's Aarti Shahani reports. AARTI SHAHANI, BYLINE: There are many ugly anecdotes about what tech companies are like on the inside - places where women are sexually harassed and blocked from promotion, where blacks and Latinos don't get hired. This new survey is an effort to pivot from anecdotes to patterns. And it found 37 percent of the adults surveyed indicated that unfairness played a major role in their decision to leave their company. Lead author Allison Scott on a conference call for press. (SOUNDBITE OF PRESS CONFERENCE) ALLISON SCOTT: So this was the largest driver or turnover in the sample by almost two times. SCOTT: The Kapor Center for Social Impact, a group that promotes workplace diversity, partnered with the Harris Poll to survey about 2,000 people online. Researchers found the No. 1 reason for leaving was not a better job offer; it was mistreatment, especially for women and underrepresented minorities. The survey considered four types of unfair practices. (SOUNDBITE OF PRESS CONFERENCE) SCOTT: One being unfair people management practices, things like job assignments and promotions; two being stereotyping; three, sexual harassment; and four, bullying. SHAHANI: About 80 percent of respondents said they'd experienced at least one of these. But the type experienced varied by race, gender and sexual orientation. For example, white and Asian men reported being more unfairly managed than men of other races. LGBTQ respondents reported the highest rate of bullying. And women. . . (SOUNDBITE OF PRESS CONFERENCE) SCOTT: One in 10 women reported unwanted sexual attention or harassment. SHAHANI: In recent years, the largest tech companies have begun to disclose how many women and underrepresented minorities they're hiring. But with the exception of the chip maker Intel, no major company is disclosing how many of these employees are staying versus leaving. Aarti Shahani, NPR News, San Francisco.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-04-29-526157951": {"title": "A Primer On The Future Of Net Neutrality Under Trump : NPR", "url": "https://www.npr.org/2017/04/29/526157951/a-primer-on-the-future-of-net-neutrality-under-trump", "author": "No author found", "published_date": "2017-04-29", "content": "SCOTT SIMON, HOST: Republicans in Congress and the Trump administration have been focusing a lot of effort on repealing Obama-era regulations, including many that govern technology and the Internet. This week, the Federal Communications Commission started moving toward a repeal of what's called the net neutrality rules. Now, these are regulations for Internet service providers. NPR's tech reporter Alina Selyukh is here to try to walk us through the plan. Alina, thanks so much for being with us. ALINA SELYUKH, BYLINE: Hi, thanks for having me. SIMON: Books have been written about net neutrality. Why don't you take 30 seconds and tell us what it is? SELYUKH: This has become a great skill of mine. In fact, yesterday, I explained net neutrality to a friend in a text message, which I think was my peak net neutrality explainer. SIMON: Oh, do do share share. SELYUKH: (Laughter) So let me go through it. SIMON: Yeah. SELYUKH: There are two parts to this. There's the principles of net neutrality, and this is sort of this concept that Internet service providers should treat all website and apps fairly and equally. And that means they should not be blocking or slowing down any traffic, and they should not be charging companies a little extra to send their traffic a little faster. And this did come at a time when there were some incidents and accusations of Internet service providers actually meddling with access and speeds of some traffic in some instances. They were blocking access to some services. But policy-wise, for the past several years, what regulators have really been debating is not specifically these principles themselves but the legal mechanism of how to enforce them. SIMON: Yeah. And how do you enforce them? Technically, how do you enforce it? SELYUKH: In 2015, the Democrats of the FCC decided that it was time to go all in, and what they did was essentially reclassified Internet providers and started treating them as utility-style companies. That means they put it in the strictest ever regulations, really expanded their oversight over the industry. Republicans at the FCC at the time really opposed this regulatory approach, so-called public utility approach. And one of the dissenting commissioners was Ajit Pai, who is now the new FCC chairman under President Trump. And here's how he saw that vote. (SOUNDBITE OF ARCHIVED RECORDING)AJIT PAI: It decided to put the federal government at the center of the Internet. Why? Unfortunately, the answer has nothing to do with the law or the facts. Nothing about the Internet was broken in 2015. SELYUKH: And so now that he's in charge of the Republican majority at the agency, he's rolling back those policies. SIMON: Do we have the details of the new approach being considered by the FCC? SELYUKH: One thing we know for sure is what the new FCC does not want and that is public utility-style regulation of Internet providers. Here's how Pai described his plan in a speech on Wednesday. (SOUNDBITE OF ARCHIVED RECORDING)PAI: Going forward, we cannot stick with regulations from the Great Depression that were meant to micromanage Ma Bell. SELYUKH: He has said that he supports the open Internet, which is another term for net neutrality - if we needed one more. SIMON: I actually prefer that one. SELYUKH: And so he supports this principle as far as he said, but it is really unclear how exactly he wants to regulate it. We know that he doesn't want utility-style regulations. We know that he is considering shifting some of the responsibility for policing it to the Federal Trade Commission. But all of this will play out over the next three to four to five months of this year. SIMON: Who wants it? Who thinks its a bad idea? SELYUKH: The cable and telecom companies, like Comcast and AT&T, have really pushed hard against this utility-style regulation that was adopted in 2015. They were the ones who took FCC to court over it. So they are really excited to see what Pai comes up with. The advocates and some of the web companies, like Vimeo and Etsy, are really gearing up for a fight. They're saying that they want the net neutrality principles and the regulations as they are right now. SIMON: NPR's Alina Selyukh, thanks very much for being with us. SELYUKH: Thank you. SCOTT SIMON, HOST:  Republicans in Congress and the Trump administration have been focusing a lot of effort on repealing Obama-era regulations, including many that govern technology and the Internet. This week, the Federal Communications Commission started moving toward a repeal of what's called the net neutrality rules. Now, these are regulations for Internet service providers. NPR's tech reporter Alina Selyukh is here to try to walk us through the plan. Alina, thanks so much for being with us. ALINA SELYUKH, BYLINE: Hi, thanks for having me. SIMON: Books have been written about net neutrality. Why don't you take 30 seconds and tell us what it is? SELYUKH: This has become a great skill of mine. In fact, yesterday, I explained net neutrality to a friend in a text message, which I think was my peak net neutrality explainer. SIMON: Oh, do do share share. SELYUKH: (Laughter) So let me go through it. SIMON: Yeah. SELYUKH: There are two parts to this. There's the principles of net neutrality, and this is sort of this concept that Internet service providers should treat all website and apps fairly and equally. And that means they should not be blocking or slowing down any traffic, and they should not be charging companies a little extra to send their traffic a little faster. And this did come at a time when there were some incidents and accusations of Internet service providers actually meddling with access and speeds of some traffic in some instances. They were blocking access to some services. But policy-wise, for the past several years, what regulators have really been debating is not specifically these principles themselves but the legal mechanism of how to enforce them. SIMON: Yeah. And how do you enforce them? Technically, how do you enforce it? SELYUKH: In 2015, the Democrats of the FCC decided that it was time to go all in, and what they did was essentially reclassified Internet providers and started treating them as utility-style companies. That means they put it in the strictest ever regulations, really expanded their oversight over the industry. Republicans at the FCC at the time really opposed this regulatory approach, so-called public utility approach. And one of the dissenting commissioners was Ajit Pai, who is now the new FCC chairman under President Trump. And here's how he saw that vote. (SOUNDBITE OF ARCHIVED RECORDING) AJIT PAI: It decided to put the federal government at the center of the Internet. Why? Unfortunately, the answer has nothing to do with the law or the facts. Nothing about the Internet was broken in 2015. SELYUKH: And so now that he's in charge of the Republican majority at the agency, he's rolling back those policies. SIMON: Do we have the details of the new approach being considered by the FCC? SELYUKH: One thing we know for sure is what the new FCC does not want and that is public utility-style regulation of Internet providers. Here's how Pai described his plan in a speech on Wednesday. (SOUNDBITE OF ARCHIVED RECORDING) PAI: Going forward, we cannot stick with regulations from the Great Depression that were meant to micromanage Ma Bell. SELYUKH: He has said that he supports the open Internet, which is another term for net neutrality - if we needed one more. SIMON: I actually prefer that one. SELYUKH: And so he supports this principle as far as he said, but it is really unclear how exactly he wants to regulate it. We know that he doesn't want utility-style regulations. We know that he is considering shifting some of the responsibility for policing it to the Federal Trade Commission. But all of this will play out over the next three to four to five months of this year. SIMON: Who wants it? Who thinks its a bad idea? SELYUKH: The cable and telecom companies, like Comcast and AT&T, have really pushed hard against this utility-style regulation that was adopted in 2015. They were the ones who took FCC to court over it. So they are really excited to see what Pai comes up with. The advocates and some of the web companies, like Vimeo and Etsy, are really gearing up for a fight. They're saying that they want the net neutrality principles and the regulations as they are right now. SIMON: NPR's Alina Selyukh, thanks very much for being with us. SELYUKH: Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-04-30-526105460": {"title": "'It Is Neither Nor, It Is Both': Tom Hanks Finds No Easy Answers In 'The Circle' : NPR", "url": "https://www.npr.org/2017/04/30/526105460/it-is-neither-nor-it-is-both-tom-hanks-finds-no-easy-answers-in-the-circle", "author": "No author found", "published_date": "2017-04-30", "content": "MICHEL MARTIN, HOST: Not trying to be nosy, but have you posted anything on social media today? Maybe you took a pic of your tasty brunch, maybe you sent out a video of your child's latest steps, maybe you sent up a flare about a faltering relationship. And when you hit that button, at any point, did you wonder how much sharing is too much? Those are just a couple of the questions behind \"The Circle,\" a new film based on a 2013 Dave Eggers' novel of the same name. The film takes place sometime in the future at a company called The Circle. It's kind of a hybrid of big tech companies, like Google, Facebook and Apple. And it paints a satirical and unsettling picture of life in the age of social media and tech-obsessed culture. It stars Emma Watson as Mae Holland, a new hire at The Circle, who quickly rises through the ranks and comes to embody the company's mantra that sharing is caring by agreeing to broadcast her every waking moment to millions of followers on social media. And the boss, The Circle co-founder Eamon Bailey, the seemingly easygoing co-founder, who espouses that philosophy of total transparency, that would be two-time Oscar winner Tom Hanks. (SOUNDBITE OF FILM, \"THE CIRCLE\")TOM HANKS: (As Eamon Bailey) I am a believer in the perfectibility of human beings. When we are our best selves, the possibilities are endless. There isn't a problem that we cannot solve. We can cure any disease, and we can end hunger. And without secrets, without the hoarding of knowledge and information, we can finally realize our potential. MARTIN: And we are joined now by Tom Hanks. Tom Hanks, thanks so much for speaking with us. HANKS: You're quite welcome. You don't have any argument with that, do you? I mean, everything that guy said was just kind of great, wasn't it? MARTIN: Well, tell us about that, why not? (LAUGHTER)MARTIN: Tell us - so tell us about Eamon Bailey. He feels familiar. A little bit of. . . HANKS: Yeah. MARTIN: . . . Steve Jobs maybe, other public figures from the tech world. But is it OK to point out that there's something increasingly sinister - right? - as the movie progresses about his vision? HANKS: Well, if you believe that complete openness will be the great guide for humanity and would lead us to unprecedented problem-solving, that means you would then have to close off one basic need for the human condition, which I think is anonymity and privacy. That is something that is put forward in everything that Eamon Bailey says - one of the intriguing aspects of it when I first read Dave Eggers' novels, which by the way, for 2013, was pretty prescient, I must say. Here we are four years later, and much of what he wrote about is, in fact, a fact. There's nothing that he says that is not upbeat and positive and proactive and good for the world, except for everything that he stands for (laughter). So somehow there is something that is really quite malevolent about this concept that when everybody knows everybody's secrets, there will be no more secrets, no reason for shame, no reason for hiding, no need for lies. That almost strikes me as something Lenin and Marx would try to put forward, which is counter to what human beings crave in the course of their life, which is some degree of total self-control as opposed to giving over to grand control. MARTIN: Well, that's one of the things that's fascinating about this film is that Mother Jones, which is, you know, a left-leaning publication, and the National Review, which is a right-leaning publication, are both telling people they have to go see it, which is fascinating to me. HANKS: (Laughter). MARTIN: So is this a conservative movie or is this a liberal movie? HANKS: This is a fascinating question that you pose because it's neither nor. It is both. And that's a hard concept to grasp. One aspect of it is, like, let's imagine that you have started a company, or let's just - let's take Uber. Uber would love it if there were no cars left in the world except theirs and nobody drove anywhere except their drivers and passengers all paid into the Uber system. That is the prime fantasy of any company that provides a service is to wipe out all competition and hold not just a monopoly but enter into literally the human zeitgeist that life cannot go on without their services. But the question of complete control and complete dominance of a marketplace means complete control and complete dominance of your daily life. That it is malevolent. MARTIN: So how would you describe this to somebody who didn't know anything about it? You know, at some point, the film is funny, is charming, but it also raises some very troubling questions. And it also describes scenarios that are not in the future, that are here now. And so I'm asking you, what is this movie? Is this dystopian? Is this funny? Is this - what is this? HANKS: I think it's an examination of the trade-off. And you have to determine two things - one, can your life survive by - in this trade-off that you make? And is it a trade-off that you want to make? Bill Paxton and Glenne Headley play Emma Watson's parents. And Bill's character, her dad, has MS, and they cannot afford the insurance that goes along with it. But because Mae now works for The Circle, they're included. And suddenly a world of worry is taken off their plate. He is able to get treatment. He's able to get everything that one would need in living with something like MS, and it's a fabulous boon to their lives. The trade-off they make is that The Circle puts cameras in their homes in order to make sure he's always OK. And if he falls down when he's by himself, the folks at The Circle will be able to send help. Now, do you want to live in a home where somebody from an organization has constant access to what's going on to all of your rooms? There is the trade-off. I don't know if popular culture can handle that kind of comme ci, comme ca aspect of it because you'd like to have a - you'd like to find out specifically is it good or bad? What - let's - what do you mean by this movie? Are we supposed to love it or hate it? The question is exactly, are you supposed to love it or are you supposed to hate it? MARTIN: Can I ask you - there are a number of artists who feel a particular sense of urgency in this particular political moment. HANKS: Oh, yeah, sure. MARTIN: They seem to feel a particular urgency to speak out about particular things. I'm thinking about your colleague Meryl Streep, who's certainly - if you have any peer in Hollywood, it would be she. There are a number. . . HANKS: I'll take that (laughter). MARTIN: Yeah, well, there you are. And - but I'm asking you do you feel, as an artist, any particular sense of urgency right now? And if so, to what end? I think it's - and not to really narrow you down but merely to say do you feel, as an artist, you have any particular role right now that you didn't have a year ago or two years ago? HANKS: No, I actually think I have the same exact role because I do have a very particular perspective on this. Not to speak for Meryl, but I think she was responding to ridicule of somebody with a physical affliction, which ain't right. And it's not fair no matter who does it. If I was going to put forward any sort of life philosophy on this is mine takes history into account. We have been at this place before, and weathering it and correcting it over a long haul, over a long period of time has made us a better country and has actually powered us on to being a even better example to the rest of the world. I grew up during Vietnam. I was 13. I was not threatened by Vietnam in any way, shape or form. But at my dinner table, there were arguments and fistfights over Vietnam. In the city I lived in, there were riots and gunfire and burning buildings because of Vietnam. There was civil unrest, and there was the reaction to it. There were the Hard Hats - your country, love it or leave it. At the same exact time, there were people who were, in fact, leaving our country because they could not consciously go off and fight the war in Vietnam. We weathered it. We made decisions. People showed up. They got involved. Artists raised their voices and started screaming. Other people found their voice for the very first time on either side of the divide. And what came out of it was really quite, I think, quite frankly, from the layman's historian perspective that I have, a sober judgment of what that period of time did to us. And it prompted people to take action both by what they believed in from the get-go and what they learned throughout the process of it. We are in that same exact place right now. But three years from now, we will be better. We will be a better nation on both sides of the divide by the way, on both sides of whatever the aisle is that separates all of us because we will have examined it, we will have suffered it, we will have promoted what we think is the good fight. MARTIN: That is two-time Oscar winner Tom Hanks. He was kind enough to join us from our studios in New York to talk about his new film \"The Circle,\" which is out this week. Tom Hanks, thank you so much for speaking with us. HANKS: Thank you. MICHEL MARTIN, HOST:  Not trying to be nosy, but have you posted anything on social media today? Maybe you took a pic of your tasty brunch, maybe you sent out a video of your child's latest steps, maybe you sent up a flare about a faltering relationship. And when you hit that button, at any point, did you wonder how much sharing is too much? Those are just a couple of the questions behind \"The Circle,\" a new film based on a 2013 Dave Eggers' novel of the same name. The film takes place sometime in the future at a company called The Circle. It's kind of a hybrid of big tech companies, like Google, Facebook and Apple. And it paints a satirical and unsettling picture of life in the age of social media and tech-obsessed culture. It stars Emma Watson as Mae Holland, a new hire at The Circle, who quickly rises through the ranks and comes to embody the company's mantra that sharing is caring by agreeing to broadcast her every waking moment to millions of followers on social media. And the boss, The Circle co-founder Eamon Bailey, the seemingly easygoing co-founder, who espouses that philosophy of total transparency, that would be two-time Oscar winner Tom Hanks. (SOUNDBITE OF FILM, \"THE CIRCLE\") TOM HANKS: (As Eamon Bailey) I am a believer in the perfectibility of human beings. When we are our best selves, the possibilities are endless. There isn't a problem that we cannot solve. We can cure any disease, and we can end hunger. And without secrets, without the hoarding of knowledge and information, we can finally realize our potential. MARTIN: And we are joined now by Tom Hanks. Tom Hanks, thanks so much for speaking with us. HANKS: You're quite welcome. You don't have any argument with that, do you? I mean, everything that guy said was just kind of great, wasn't it? MARTIN: Well, tell us about that, why not? (LAUGHTER) MARTIN: Tell us - so tell us about Eamon Bailey. He feels familiar. A little bit of. . . HANKS: Yeah. MARTIN: . . . Steve Jobs maybe, other public figures from the tech world. But is it OK to point out that there's something increasingly sinister - right? - as the movie progresses about his vision? HANKS: Well, if you believe that complete openness will be the great guide for humanity and would lead us to unprecedented problem-solving, that means you would then have to close off one basic need for the human condition, which I think is anonymity and privacy. That is something that is put forward in everything that Eamon Bailey says - one of the intriguing aspects of it when I first read Dave Eggers' novels, which by the way, for 2013, was pretty prescient, I must say. Here we are four years later, and much of what he wrote about is, in fact, a fact. There's nothing that he says that is not upbeat and positive and proactive and good for the world, except for everything that he stands for (laughter). So somehow there is something that is really quite malevolent about this concept that when everybody knows everybody's secrets, there will be no more secrets, no reason for shame, no reason for hiding, no need for lies. That almost strikes me as something Lenin and Marx would try to put forward, which is counter to what human beings crave in the course of their life, which is some degree of total self-control as opposed to giving over to grand control. MARTIN: Well, that's one of the things that's fascinating about this film is that Mother Jones, which is, you know, a left-leaning publication, and the National Review, which is a right-leaning publication, are both telling people they have to go see it, which is fascinating to me. HANKS: (Laughter). MARTIN: So is this a conservative movie or is this a liberal movie? HANKS: This is a fascinating question that you pose because it's neither nor. It is both. And that's a hard concept to grasp. One aspect of it is, like, let's imagine that you have started a company, or let's just - let's take Uber. Uber would love it if there were no cars left in the world except theirs and nobody drove anywhere except their drivers and passengers all paid into the Uber system. That is the prime fantasy of any company that provides a service is to wipe out all competition and hold not just a monopoly but enter into literally the human zeitgeist that life cannot go on without their services. But the question of complete control and complete dominance of a marketplace means complete control and complete dominance of your daily life. That it is malevolent. MARTIN: So how would you describe this to somebody who didn't know anything about it? You know, at some point, the film is funny, is charming, but it also raises some very troubling questions. And it also describes scenarios that are not in the future, that are here now. And so I'm asking you, what is this movie? Is this dystopian? Is this funny? Is this - what is this? HANKS: I think it's an examination of the trade-off. And you have to determine two things - one, can your life survive by - in this trade-off that you make? And is it a trade-off that you want to make? Bill Paxton and Glenne Headley play Emma Watson's parents. And Bill's character, her dad, has MS, and they cannot afford the insurance that goes along with it. But because Mae now works for The Circle, they're included. And suddenly a world of worry is taken off their plate. He is able to get treatment. He's able to get everything that one would need in living with something like MS, and it's a fabulous boon to their lives. The trade-off they make is that The Circle puts cameras in their homes in order to make sure he's always OK. And if he falls down when he's by himself, the folks at The Circle will be able to send help. Now, do you want to live in a home where somebody from an organization has constant access to what's going on to all of your rooms? There is the trade-off. I don't know if popular culture can handle that kind of comme ci, comme ca aspect of it because you'd like to have a - you'd like to find out specifically is it good or bad? What - let's - what do you mean by this movie? Are we supposed to love it or hate it? The question is exactly, are you supposed to love it or are you supposed to hate it? MARTIN: Can I ask you - there are a number of artists who feel a particular sense of urgency in this particular political moment. HANKS: Oh, yeah, sure. MARTIN: They seem to feel a particular urgency to speak out about particular things. I'm thinking about your colleague Meryl Streep, who's certainly - if you have any peer in Hollywood, it would be she. There are a number. . . HANKS: I'll take that (laughter). MARTIN: Yeah, well, there you are. And - but I'm asking you do you feel, as an artist, any particular sense of urgency right now? And if so, to what end? I think it's - and not to really narrow you down but merely to say do you feel, as an artist, you have any particular role right now that you didn't have a year ago or two years ago? HANKS: No, I actually think I have the same exact role because I do have a very particular perspective on this. Not to speak for Meryl, but I think she was responding to ridicule of somebody with a physical affliction, which ain't right. And it's not fair no matter who does it. If I was going to put forward any sort of life philosophy on this is mine takes history into account. We have been at this place before, and weathering it and correcting it over a long haul, over a long period of time has made us a better country and has actually powered us on to being a even better example to the rest of the world. I grew up during Vietnam. I was 13. I was not threatened by Vietnam in any way, shape or form. But at my dinner table, there were arguments and fistfights over Vietnam. In the city I lived in, there were riots and gunfire and burning buildings because of Vietnam. There was civil unrest, and there was the reaction to it. There were the Hard Hats - your country, love it or leave it. At the same exact time, there were people who were, in fact, leaving our country because they could not consciously go off and fight the war in Vietnam. We weathered it. We made decisions. People showed up. They got involved. Artists raised their voices and started screaming. Other people found their voice for the very first time on either side of the divide. And what came out of it was really quite, I think, quite frankly, from the layman's historian perspective that I have, a sober judgment of what that period of time did to us. And it prompted people to take action both by what they believed in from the get-go and what they learned throughout the process of it. We are in that same exact place right now. But three years from now, we will be better. We will be a better nation on both sides of the divide by the way, on both sides of whatever the aisle is that separates all of us because we will have examined it, we will have suffered it, we will have promoted what we think is the good fight. MARTIN: That is two-time Oscar winner Tom Hanks. He was kind enough to join us from our studios in New York to talk about his new film \"The Circle,\" which is out this week. Tom Hanks, thank you so much for speaking with us. HANKS: Thank you.", "section": "Movie Interviews", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-05-04-526931972": {"title": "Google Doc Users Hit By Massive Email Phishing Scam : NPR", "url": "https://www.npr.org/2017/05/04/526931972/google-doc-users-hit-by-massive-email-phishing-scam", "author": "No author found", "published_date": "2017-05-04", "content": "ROBERT SIEGEL, HOST: Yesterday afternoon, an email went out to all NPR employees. It was marked with one of those red exclamation points to indicate that you'd better read it. SOHAIL ANWAR, BYLINE: Subject - Google Docs phishing emails. A new phishing scam is circulating that includes a link to a malicious file shared via Google Docs. This email is a scam. Please delete or ignore this phishing message and notify the service desk if you have already clicked on the link inside. My name is Sohail Anwar. I'm the director of IT operations here at NPR. KELLY MCEVERS, HOST: This scam was happening all over the country, and people were falling for it because the email looked like it was from someone you know. ANWAR: But when we looked at the to address, it was definitely fishy. SIEGEL: The pun was not intended. If you received one of these emails, you were simply BCC'd - blind carbon copied. The address in the to field was. . . ANWAR: Hhhhhhhhhhhhhh@mailinator. com. MCEVERS: And unlike other scams, these hackers aren't asking for your bank passwords, but that doesn't mean they're not dangerous. ANWAR: Our understanding is that this email invited you to open a shared document on Google Docs, and when you opened the document, it gave access to all the contacts in your Google email. And from then, they were able to replicate this same email to all those contacts. SIEGEL: NPR reported that over 500 suspicious messages came in. So far, only three people have confessed to having clicked on the link. PAM FESSLER, BYLINE: My name is Pam Fessler, and I am a correspondent on the national desk at NPR. I clicked it open and went up to the Google Docs page, but for some reason, I wasn't able to open it up. So I just kind of left it there. And then, of course, about a half hour later, I see this email from the IT department saying, beware of this phishing scam. And I said, oh, I did it. I could just kick myself. MCEVERS: Pam, you are not alone. FESSLER: Now, I should tell you that I got another one today, and I did not open it up. I just deleted it. SIEGEL: To all the IT professionals working to keep us safe, thank you. And if you've received an email that looks fishy asking you to click on something, when in doubt, don't click. MCEVERS: Google Docs tweeted in a statement saying they have disabled the offending accounts, and they offer a link for a security checkup if you think you were affected and they, quote, \"encourage users to report phishing emails. \"(SOUNDBITE OF THAO AND THE GET DOWN STAY DOWN SONG, \"TROUBLE WAS FOR\") ROBERT SIEGEL, HOST:  Yesterday afternoon, an email went out to all NPR employees. It was marked with one of those red exclamation points to indicate that you'd better read it. SOHAIL ANWAR, BYLINE: Subject - Google Docs phishing emails. A new phishing scam is circulating that includes a link to a malicious file shared via Google Docs. This email is a scam. Please delete or ignore this phishing message and notify the service desk if you have already clicked on the link inside. My name is Sohail Anwar. I'm the director of IT operations here at NPR. KELLY MCEVERS, HOST:  This scam was happening all over the country, and people were falling for it because the email looked like it was from someone you know. ANWAR: But when we looked at the to address, it was definitely fishy. SIEGEL: The pun was not intended. If you received one of these emails, you were simply BCC'd - blind carbon copied. The address in the to field was. . . ANWAR: Hhhhhhhhhhhhhh@mailinator. com. MCEVERS: And unlike other scams, these hackers aren't asking for your bank passwords, but that doesn't mean they're not dangerous. ANWAR: Our understanding is that this email invited you to open a shared document on Google Docs, and when you opened the document, it gave access to all the contacts in your Google email. And from then, they were able to replicate this same email to all those contacts. SIEGEL: NPR reported that over 500 suspicious messages came in. So far, only three people have confessed to having clicked on the link. PAM FESSLER, BYLINE: My name is Pam Fessler, and I am a correspondent on the national desk at NPR. I clicked it open and went up to the Google Docs page, but for some reason, I wasn't able to open it up. So I just kind of left it there. And then, of course, about a half hour later, I see this email from the IT department saying, beware of this phishing scam. And I said, oh, I did it. I could just kick myself. MCEVERS: Pam, you are not alone. FESSLER: Now, I should tell you that I got another one today, and I did not open it up. I just deleted it. SIEGEL: To all the IT professionals working to keep us safe, thank you. And if you've received an email that looks fishy asking you to click on something, when in doubt, don't click. MCEVERS: Google Docs tweeted in a statement saying they have disabled the offending accounts, and they offer a link for a security checkup if you think you were affected and they, quote, \"encourage users to report phishing emails. \" (SOUNDBITE OF THAO AND THE GET DOWN STAY DOWN SONG, \"TROUBLE WAS FOR\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-05-05-527013820": {"title": "New Software Can Mimic Anyone's Voice : NPR", "url": "https://www.npr.org/2017/05/05/527013820/new-software-can-mimic-anyones-voice", "author": "No author found", "published_date": "2017-05-05", "content": "DAVID GREENE, HOST: OK. So we've talked a lot about fake news. Now we have fake voices. A Canadian company called Lyrebird has come up with software that it says mimics anyone's voice. Here's part of a fake conversation the company created using computer-generated voices of Barack Obama, Donald Trump and Hillary Clinton. (SOUNDBITE OF ARCHIVED RECORDING)COMPUTERIZED VOICE: (As Barack Obama) Hey Donald, have you heard of this new technology? (As Donald Trump) Are you speaking about this new algorithm to copy voices? (As Barack Obama) Yes. It is developed by a startup called Lyrebird. (As Hillary Clinton) Hey, guys. I think that they used deep learning and artificial neural networks. (As Barack Obama) Hillary is right. RACHEL MARTIN, HOST: That's creepy. Artificial voices like Siri and Alexa are pretty good, but, let's be honest, they still sound like computer voices. Lyrebird actually samples a person's voice and captures the nuance of the original speaker. Here's fake Donald Trump saying the same sentence three different ways. (SOUNDBITE OF ARCHIVED RECORDING)COMPUTERIZED VOICE: (As Donald Trump) I am not a robot. My intonation is always different. (As Donald Trump) I am not a robot. My intonation is always different. (As Donald Trump) I am not a robot. My intonation is always different. GREENE: Oh, my goodness. Yeah. Not good enough to fool anybody yet. But as the technology gets better, the company says that the voices are going to get more natural. MARTIN: But sampling someone's voice and making them say something they never said obviously raises ethical questions. In a statement on its website, Lyrebird acknowledges the software, quote, \"could potentially have dangerous consequences. \" It talks about the legal and political implications of copying someone's voice. GREENE: Although, Rachel, it does not address the potential impact on public radio hosts. COMPUTERIZED VOICE: (As Rachel Martin) This is MORNING EDITION from NPR News. I'm Rachel Martin. (As David Greene) And I'm David Greene. (SOUNDBITE OF DAFT PUNK SONG, \"ROBOT ROCK\")GREENE: What was - was that supposed to be us? MARTIN: Who is that? GREENE: Yeah, not. . . MARTIN: (Laughter). GREENE: There's a lot of work to be done here - not us. (SOUNDBITE OF SONG, \"ROBOT ROCK\")DAFT PUNK: (Synthesized voices) Rock, robot, rock. DAVID GREENE, HOST:  OK. So we've talked a lot about fake news. Now we have fake voices. A Canadian company called Lyrebird has come up with software that it says mimics anyone's voice. Here's part of a fake conversation the company created using computer-generated voices of Barack Obama, Donald Trump and Hillary Clinton. (SOUNDBITE OF ARCHIVED RECORDING) COMPUTERIZED VOICE: (As Barack Obama) Hey Donald, have you heard of this new technology? (As Donald Trump) Are you speaking about this new algorithm to copy voices? (As Barack Obama) Yes. It is developed by a startup called Lyrebird. (As Hillary Clinton) Hey, guys. I think that they used deep learning and artificial neural networks. (As Barack Obama) Hillary is right. RACHEL MARTIN, HOST:  That's creepy. Artificial voices like Siri and Alexa are pretty good, but, let's be honest, they still sound like computer voices. Lyrebird actually samples a person's voice and captures the nuance of the original speaker. Here's fake Donald Trump saying the same sentence three different ways. (SOUNDBITE OF ARCHIVED RECORDING) COMPUTERIZED VOICE: (As Donald Trump) I am not a robot. My intonation is always different. (As Donald Trump) I am not a robot. My intonation is always different. (As Donald Trump) I am not a robot. My intonation is always different. GREENE: Oh, my goodness. Yeah. Not good enough to fool anybody yet. But as the technology gets better, the company says that the voices are going to get more natural. MARTIN: But sampling someone's voice and making them say something they never said obviously raises ethical questions. In a statement on its website, Lyrebird acknowledges the software, quote, \"could potentially have dangerous consequences. \" It talks about the legal and political implications of copying someone's voice. GREENE: Although, Rachel, it does not address the potential impact on public radio hosts. COMPUTERIZED VOICE: (As Rachel Martin) This is MORNING EDITION from NPR News. I'm Rachel Martin. (As David Greene) And I'm David Greene. (SOUNDBITE OF DAFT PUNK SONG, \"ROBOT ROCK\") GREENE: What was - was that supposed to be us? MARTIN: Who is that? GREENE: Yeah, not. . . MARTIN: (Laughter). GREENE: There's a lot of work to be done here - not us. (SOUNDBITE OF SONG, \"ROBOT ROCK\") DAFT PUNK: (Synthesized voices) Rock, robot, rock.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-05-08-527214026": {"title": "Google Moves In And Wants To Pump 1.5 Million Gallons Of Water Per Day : NPR", "url": "https://www.npr.org/2017/05/08/527214026/google-moves-in-and-wants-to-pump-1-5-million-gallons-of-water-per-day", "author": "No author found", "published_date": "2017-05-08", "content": "ROBERT SIEGEL, HOST: Google and other tech companies are building more data centers to facilitate the millions of searches performed around the world every minute. In many places, they're welcome for the jobs and the tax revenue they bring. But in one community near Charleston, S. C. , there's also concern about Google's impact on the local water supply. NPR's Sarah McCammon has more. SARAH MCCAMMON, BYLINE: Clay Duffie remembers a time when the water in his area was soft. You'd come out of the shower and still feel dirty and salty. CLAY DUFFIE: It'd kill your azaleas if you irrigated with it. Your grits would come out in a big clump instead of creamy like they should. MCCAMMON: And he says the sweet tea was cloudy. Duffie cares a lot about this. He's the head of Mount Pleasant Waterworks, which provides water for more than 80,000 people outside Charleston. His concern now is Google's request for permission from South Carolina regulators to pump water from underground. DUFFIE: We've invested a lot in making sure that the ground water quality that we treat and send to the customers are high quality. We also want to protect the quantity side of that. MCCAMMON: Google already has the right to pump up to half a million gallons a day at no charge. Now, the company is asking to triple that to one and a half million. That's close to half of the groundwater that Mount Pleasant Waterworks pumps from the same aquifer. PATRICK LINEHAN: They run really hot. It takes a lot of energy to run a data center. So we use water to cool them down. MCCAMMON: It's the servers that generate all that heat, says Google spokesman Patrick Linehan. He says Google is taking steps to conserve water and energy while preparing for the needs of the future. LINEHAN: The Internet is constantly expanding and data centers allow the Internet to continue to do that. And we're very long-term thinkers in terms of capacity, so we're always preparing for more growth. COMPUTER-GENERATED VOICE: In 600 feet, turn right onto U. S. 50 East. MCCAMMON: So I have basically driven out to where I am told this data center is. And there isn't much to see here. I see a sign that says Google. And there's a guard shack and a fence, and that's about it. Google wouldn't let me inside of its South Carolina data center, which opened up nearly a decade ago in Berkeley County. But it's in a suburban area surrounded by woods and office buildings. Emily Cedzo of the Coastal Conservation League says she worries about its impact on the underground aquifer that the community relies on. EMILY CEDZO: It's great to have Google in this region. Folks are proud to say that Google calls Charleston home. So by no means are we going after Google. Our concern, primarily, is the source of that water. MCCAMMON: Google, with its six data centers nationwide, is just one of several major tech companies operating centers in relatively dry parts of the country, like eBay in Salt Lake City and Microsoft in San Antonio. Alfonso Ortega is a professor of energy technology at Villanova University. Speaking via Skype, he says the tech industry as a whole has been a leader in adopting environmentally sustainable practices like reusing water. But there are tradeoffs. ALFONSO ORTEGA: The consumption of their water competes with every other need for that water. And one would hope that community leaders would be able to balance the benefits of having that data center in the community compared to the water that they're going to consume. MCCAMMON: In places with enough water to go around, he says the jobs and tax revenues brought by data companies might just be worth the water and other resources required to run them. Sarah McCammon, NPR News, Mount Pleasant, S. C. (SOUNDBITE OF TIN HAT'S \"NEW WEST\") ROBERT SIEGEL, HOST:  Google and other tech companies are building more data centers to facilitate the millions of searches performed around the world every minute. In many places, they're welcome for the jobs and the tax revenue they bring. But in one community near Charleston, S. C. , there's also concern about Google's impact on the local water supply. NPR's Sarah McCammon has more. SARAH MCCAMMON, BYLINE: Clay Duffie remembers a time when the water in his area was soft. You'd come out of the shower and still feel dirty and salty. CLAY DUFFIE: It'd kill your azaleas if you irrigated with it. Your grits would come out in a big clump instead of creamy like they should. MCCAMMON: And he says the sweet tea was cloudy. Duffie cares a lot about this. He's the head of Mount Pleasant Waterworks, which provides water for more than 80,000 people outside Charleston. His concern now is Google's request for permission from South Carolina regulators to pump water from underground. DUFFIE: We've invested a lot in making sure that the ground water quality that we treat and send to the customers are high quality. We also want to protect the quantity side of that. MCCAMMON: Google already has the right to pump up to half a million gallons a day at no charge. Now, the company is asking to triple that to one and a half million. That's close to half of the groundwater that Mount Pleasant Waterworks pumps from the same aquifer. PATRICK LINEHAN: They run really hot. It takes a lot of energy to run a data center. So we use water to cool them down. MCCAMMON: It's the servers that generate all that heat, says Google spokesman Patrick Linehan. He says Google is taking steps to conserve water and energy while preparing for the needs of the future. LINEHAN: The Internet is constantly expanding and data centers allow the Internet to continue to do that. And we're very long-term thinkers in terms of capacity, so we're always preparing for more growth. COMPUTER-GENERATED VOICE: In 600 feet, turn right onto U. S. 50 East. MCCAMMON: So I have basically driven out to where I am told this data center is. And there isn't much to see here. I see a sign that says Google. And there's a guard shack and a fence, and that's about it. Google wouldn't let me inside of its South Carolina data center, which opened up nearly a decade ago in Berkeley County. But it's in a suburban area surrounded by woods and office buildings. Emily Cedzo of the Coastal Conservation League says she worries about its impact on the underground aquifer that the community relies on. EMILY CEDZO: It's great to have Google in this region. Folks are proud to say that Google calls Charleston home. So by no means are we going after Google. Our concern, primarily, is the source of that water. MCCAMMON: Google, with its six data centers nationwide, is just one of several major tech companies operating centers in relatively dry parts of the country, like eBay in Salt Lake City and Microsoft in San Antonio. Alfonso Ortega is a professor of energy technology at Villanova University. Speaking via Skype, he says the tech industry as a whole has been a leader in adopting environmentally sustainable practices like reusing water. But there are tradeoffs. ALFONSO ORTEGA: The consumption of their water competes with every other need for that water. And one would hope that community leaders would be able to balance the benefits of having that data center in the community compared to the water that they're going to consume. MCCAMMON: In places with enough water to go around, he says the jobs and tax revenues brought by data companies might just be worth the water and other resources required to run them. Sarah McCammon, NPR News, Mount Pleasant, S. C. (SOUNDBITE OF TIN HAT'S \"NEW WEST\")", "section": "National", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-05-09-527541039": {"title": "How Draft Horses Are Helping Upgrade Cell Towers In Wisconsin : NPR", "url": "https://www.npr.org/2017/05/09/527541039/draft-horses-are-enlisted-to-help-maintain-remote-cell-towers", "author": "No author found", "published_date": "2017-05-09", "content": "STEVE INSKEEP, HOST: Companies that provide cell phone service race one another to offer the most reliable signals in order to retain customers. Sometimes to do that, they turn to a surprising option to get the job done. (SOUNDBITE OF HORSE NEIGHING)INSKEEP: And it's a draft horse in Wisconsin, a horse that is helping a cell phone provider with a big service upgrade. Ann-Elise Henzl of member station WUWM reports. ANN-ELISE HENZL, BYLINE: U. S. Cellular is updating equipment on about 200 cell towers here in Wisconsin, some of which are served by primitive access roads. That poses a challenge for CH Coakley, the logistics company coordinating the upgrades. Jason Agathen has been delivering thousands of pounds of electronics gear sometimes to tricky locations. JASON AGATHEN: We actually used a ATV this year for a site that I was on, and it blew the tranny out of it - on one of the hills because we had - the snow was so deep up north. HENZL: So the company hired Jason Julian who farms in Medford, Wisc. A couple of times a week, Julian load's two to three draft horses into a trailer and drives his pick-up truck to remote cell phone towers. This morning, he's approaching one in the middle of a farmer's field. JASON JULIAN: Look at the end of the field. Do you see the water shining in the dead furrows in the end of the field? that tells you how muddy everything is. There's just water sitting. HENZL: Julian stops on the shoulder of a highway where he leads two Belgian Brabant horses from the trailer. Their names are Hannah and Billings, and they're huge animals with a stocky build, although not quite as large as Clydesdales. Julian's wife Katrina pulls off in her pick-up that's hauling a wooden wagon with a flat bottom and low sides. The two attach the horses to each other as Julian prepares them to get to work. JULIAN: I'm getting ready to hook them to the wagon and be ready for the truck to arrive, so when the truck arrives, we have a minimal amount of downtime to deliver the freight. HENZL: Soon after, the delivery truck pulls up. Julian hops in the wagon instructing his horse's to back up to the truck. They're accustomed to listening because Julian uses them on his organic dairy farm and in the logging business. JULIAN: Whoa, gee, gee, gee, gee. . . HENZL: The workers transfer their cargo to Julian's wagon. It's a half dozen boxes each holding an eight-foot antenna. The team then heads to the base of the cell tower. It's not far, but out of reach for the big delivery truck. That would get stuck on this dirt access road. JULIAN: This is a cake walk for them. They're used to being in the woods with me in thigh-deep snow and mud and have a 1,500-pound log hooked behind them, so this is like a - pretty easy stuff for them. HENZL: Julians says each load for the cell tower upgrades is usually about 2,000 pounds, heavier than a log, yet not a challenge because most of the sites are on relatively flat terrain. Yet, one recent delivery was tougher than the others. It was in a hilly area called West Salem where it took about an hour and a half to make the steep climb to the tower. JULIAN: And it had constant switchbacks, super steep, just unbelievable terrain. And we made it, and we had to use a piece of firewood actually to block the tires about every 40 or 50 yards towards the top, we'd block the tires and give the horses a breather. HENZL: Delivery Driver Jason Agathen says he gets a kick out of the fact that horses have proven essential to this project. AGATHEN: I'm from the city, so I don't get to see a lot of horses to begin with, and seeing what he can do with them - it's amazing to begin with, the control he has. And they've been using horses since the beginning of time, so from way back then to now, it's pretty neat. HENZL: The company says it won't hesitate to use horses again the next time modern vehicles fail to get the job done. For NPR News, I'm Ann-Elise Henzl in northern Wisconsin. (SOUNDBITE OF LED ZEPPLIN'S \"BLACK MOUNTAIN SIDE\") STEVE INSKEEP, HOST:  Companies that provide cell phone service race one another to offer the most reliable signals in order to retain customers. Sometimes to do that, they turn to a surprising option to get the job done. (SOUNDBITE OF HORSE NEIGHING) INSKEEP: And it's a draft horse in Wisconsin, a horse that is helping a cell phone provider with a big service upgrade. Ann-Elise Henzl of member station WUWM reports. ANN-ELISE HENZL, BYLINE: U. S. Cellular is updating equipment on about 200 cell towers here in Wisconsin, some of which are served by primitive access roads. That poses a challenge for CH Coakley, the logistics company coordinating the upgrades. Jason Agathen has been delivering thousands of pounds of electronics gear sometimes to tricky locations. JASON AGATHEN: We actually used a ATV this year for a site that I was on, and it blew the tranny out of it - on one of the hills because we had - the snow was so deep up north. HENZL: So the company hired Jason Julian who farms in Medford, Wisc. A couple of times a week, Julian load's two to three draft horses into a trailer and drives his pick-up truck to remote cell phone towers. This morning, he's approaching one in the middle of a farmer's field. JASON JULIAN: Look at the end of the field. Do you see the water shining in the dead furrows in the end of the field? that tells you how muddy everything is. There's just water sitting. HENZL: Julian stops on the shoulder of a highway where he leads two Belgian Brabant horses from the trailer. Their names are Hannah and Billings, and they're huge animals with a stocky build, although not quite as large as Clydesdales. Julian's wife Katrina pulls off in her pick-up that's hauling a wooden wagon with a flat bottom and low sides. The two attach the horses to each other as Julian prepares them to get to work. JULIAN: I'm getting ready to hook them to the wagon and be ready for the truck to arrive, so when the truck arrives, we have a minimal amount of downtime to deliver the freight. HENZL: Soon after, the delivery truck pulls up. Julian hops in the wagon instructing his horse's to back up to the truck. They're accustomed to listening because Julian uses them on his organic dairy farm and in the logging business. JULIAN: Whoa, gee, gee, gee, gee. . . HENZL: The workers transfer their cargo to Julian's wagon. It's a half dozen boxes each holding an eight-foot antenna. The team then heads to the base of the cell tower. It's not far, but out of reach for the big delivery truck. That would get stuck on this dirt access road. JULIAN: This is a cake walk for them. They're used to being in the woods with me in thigh-deep snow and mud and have a 1,500-pound log hooked behind them, so this is like a - pretty easy stuff for them. HENZL: Julians says each load for the cell tower upgrades is usually about 2,000 pounds, heavier than a log, yet not a challenge because most of the sites are on relatively flat terrain. Yet, one recent delivery was tougher than the others. It was in a hilly area called West Salem where it took about an hour and a half to make the steep climb to the tower. JULIAN: And it had constant switchbacks, super steep, just unbelievable terrain. And we made it, and we had to use a piece of firewood actually to block the tires about every 40 or 50 yards towards the top, we'd block the tires and give the horses a breather. HENZL: Delivery Driver Jason Agathen says he gets a kick out of the fact that horses have proven essential to this project. AGATHEN: I'm from the city, so I don't get to see a lot of horses to begin with, and seeing what he can do with them - it's amazing to begin with, the control he has. And they've been using horses since the beginning of time, so from way back then to now, it's pretty neat. HENZL: The company says it won't hesitate to use horses again the next time modern vehicles fail to get the job done. For NPR News, I'm Ann-Elise Henzl in northern Wisconsin. (SOUNDBITE OF LED ZEPPLIN'S \"BLACK MOUNTAIN SIDE\")", "section": "Business", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-05-11-525429568": {"title": "What If Russia Meddles In Another Major U.S. Election in 2018 Or Beyond? Will The Country Be Ready? : NPR", "url": "https://www.npr.org/2017/05/11/525429568/will-foreign-mischief-in-u-s-elections-become-the-new-normal", "author": "No author found", "published_date": "2017-05-11", "content": "", "section": "National Security", "disclaimer": ""}, "2017-05-12-528193771": {"title": "Ransomware Attacks Hit Computer Systems In Dozens Of Countries : NPR", "url": "https://www.npr.org/2017/05/12/528193771/ransomware-attacks-hit-computer-systems-in-dozens-of-countries", "author": "No author found", "published_date": "2017-05-12", "content": "AUDIE CORNISH, HOST: Cyber extortion attacks spread across the world today. They hit organizations ranging from a telecom giant in Spain to the National Health Service in England to FedEx here in the States. The attacks used ransomware which demands payment before allowing users to access their own data again. I'm joined now by NPR tech reporter Aarti Shahani. And, Aarti, talk a little bit more about what's been going on today. What's the latest? AARTI SHAHANI, BYLINE: Yeah, it's been quite a day. Over in the U. K. , there was a massive attack. More than 30 facilities in England's National Health Service were crippled. Doctors and nurses were locked out of patient records. Now, according to officials there, it's important to note it doesn't necessarily mean that patient files themselves were stolen. All that's clear is that health care servers were broken into, and the data was encrypted, scrambled up and held hostage inside the network, not necessarily taken outside the network. We also learned today about Telefonica, as you mentioned, the phone carrier in Spain being hit, FedEx being hit. The U. S. Department of Health and Human Services says there is evidence of this attack occurring inside the United States, though it's important to note they did not cite any specific attacks against hospitals or health care facilities. One cybersecurity firm is saying in all what they've counted is 45,000 attacks in as many as 74 countries. CORNISH: And is there a sense that this is the same attack everywhere? SHAHANI: We don't know, and we definitely cannot assume it. NHS Digital, which manages IT and data for England's National Health Service, they believe the specific kind of malware that targeted them is something called Wanna Decrypter. That's a ransomware attack. And it's, you know, totally different from the kinds of attacks that shut down a website, for example. So, you know, you might recall last October there were a bunch of sites like Twitter and Spotify taken down. Users couldn't visit them, access them. This string of attacks today is much more pernicious because hackers are literally shutting down a company's access to the valuable data that they're keeping in-house like a patient record. So you can imagine, you know, I'm a doctor going to look up John Smith's chart for his triple bypass surgery, and I can't get that chart. So it's sort of devastating blow. And a strange detail about the solution is to get back the data you have to pay the ransom in Bitcoin cryptocurrency, which is an anonymous way to hand over cash. CORNISH: Aarti, you've been talking all day with computer security experts researching this. What are you hearing? SHAHANI: Well, I'm hearing very different things. What happens inevitably after a big attack is security experts are collecting samples of the malicious software. They're getting these samples from their own clients or through other researchers or on the Internet. They're examining it. And they disagree about what exactly may have happened. One expert tells me that according to what he's seen in his research, it was an email attack. Someone opened an attachment and fell prey. Another expert told me something far more shocking, unsettling. According to his research, you know, you didn't even have to open an attachment, he says. It looks like the malicious software could have just wormed its way into the operating system, into the servers without human error, without that person, you know, opening that email that says win a free iPad. CORNISH: We've been talking about hospitals and, you know, big corporations. What about individuals? What can they do to protect themselves from this attack? SHAHANI: Yeah. You know, I definitely think today raises - it's a dramatic example of something you can definitely take a sort of personal lesson from. One very basic lesson is when you keep seeing that annoying alert about do you want to update, you know, your system, do you want to install the patch, just do it. It's worth doing it. You know, you save yourself from sort of potential dangers and headaches of this kind of thing happening. The other thing is it's important to have an antivirus program to screen for malicious email. And one last thing I'd say that's really unique to today or a dramatic example is that, you know, if you backup your data on a trusted cloud service or an external drive, if you're ever the target of a ransomware attack, it won't really matter 'cause you have your data elsewhere. It's not held hostage. CORNISH: That's NPR's Aarti Shahani. Thanks so much. SHAHANI: Thank you. AUDIE CORNISH, HOST:  Cyber extortion attacks spread across the world today. They hit organizations ranging from a telecom giant in Spain to the National Health Service in England to FedEx here in the States. The attacks used ransomware which demands payment before allowing users to access their own data again. I'm joined now by NPR tech reporter Aarti Shahani. And, Aarti, talk a little bit more about what's been going on today. What's the latest? AARTI SHAHANI, BYLINE: Yeah, it's been quite a day. Over in the U. K. , there was a massive attack. More than 30 facilities in England's National Health Service were crippled. Doctors and nurses were locked out of patient records. Now, according to officials there, it's important to note it doesn't necessarily mean that patient files themselves were stolen. All that's clear is that health care servers were broken into, and the data was encrypted, scrambled up and held hostage inside the network, not necessarily taken outside the network. We also learned today about Telefonica, as you mentioned, the phone carrier in Spain being hit, FedEx being hit. The U. S. Department of Health and Human Services says there is evidence of this attack occurring inside the United States, though it's important to note they did not cite any specific attacks against hospitals or health care facilities. One cybersecurity firm is saying in all what they've counted is 45,000 attacks in as many as 74 countries. CORNISH: And is there a sense that this is the same attack everywhere? SHAHANI: We don't know, and we definitely cannot assume it. NHS Digital, which manages IT and data for England's National Health Service, they believe the specific kind of malware that targeted them is something called Wanna Decrypter. That's a ransomware attack. And it's, you know, totally different from the kinds of attacks that shut down a website, for example. So, you know, you might recall last October there were a bunch of sites like Twitter and Spotify taken down. Users couldn't visit them, access them. This string of attacks today is much more pernicious because hackers are literally shutting down a company's access to the valuable data that they're keeping in-house like a patient record. So you can imagine, you know, I'm a doctor going to look up John Smith's chart for his triple bypass surgery, and I can't get that chart. So it's sort of devastating blow. And a strange detail about the solution is to get back the data you have to pay the ransom in Bitcoin cryptocurrency, which is an anonymous way to hand over cash. CORNISH: Aarti, you've been talking all day with computer security experts researching this. What are you hearing? SHAHANI: Well, I'm hearing very different things. What happens inevitably after a big attack is security experts are collecting samples of the malicious software. They're getting these samples from their own clients or through other researchers or on the Internet. They're examining it. And they disagree about what exactly may have happened. One expert tells me that according to what he's seen in his research, it was an email attack. Someone opened an attachment and fell prey. Another expert told me something far more shocking, unsettling. According to his research, you know, you didn't even have to open an attachment, he says. It looks like the malicious software could have just wormed its way into the operating system, into the servers without human error, without that person, you know, opening that email that says win a free iPad. CORNISH: We've been talking about hospitals and, you know, big corporations. What about individuals? What can they do to protect themselves from this attack? SHAHANI: Yeah. You know, I definitely think today raises - it's a dramatic example of something you can definitely take a sort of personal lesson from. One very basic lesson is when you keep seeing that annoying alert about do you want to update, you know, your system, do you want to install the patch, just do it. It's worth doing it. You know, you save yourself from sort of potential dangers and headaches of this kind of thing happening. The other thing is it's important to have an antivirus program to screen for malicious email. And one last thing I'd say that's really unique to today or a dramatic example is that, you know, if you backup your data on a trusted cloud service or an external drive, if you're ever the target of a ransomware attack, it won't really matter 'cause you have your data elsewhere. It's not held hostage. CORNISH: That's NPR's Aarti Shahani. Thanks so much. SHAHANI: Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-05-12-528166439": {"title": "Hackers Used Stolen NSA Tool To Conduct Global Cyberattacks : NPR", "url": "https://www.npr.org/2017/05/12/528166439/hackers-used-stolen-nsa-tool-to-conduct-global-cyberattacks", "author": "No author found", "published_date": "2017-05-12", "content": "ROBERT SIEGEL, HOST: Craig Timberg reports that the ransomware used in this attack apparently took advantage of a software vulnerability discovered by the National Security Agency. He's a national technology reporter with The Washington Post. He's also covering this story. Welcome to the program. CRAIG TIMBERG: Thanks, Robert. SIEGEL: And what's the NSA connection here? TIMBERG: The NSA spends a lot of its time looking for vulnerabilities in software so that it can spy on people around the world. That's the job of the agency. And so this group called Shadow Brokers managed to get their hands on a bunch of these vulnerabilities and release them on the internet. It appears to be one of these things that was actually used in the attacks today. SIEGEL: Now, Microsoft had released a patch fixing that flaw. That was in March. But it seems that many, many computers were vulnerable to this attack. Why? TIMBERG: Indeed, you know, the patch that Microsoft released came out even before the - this document describing the vulnerability that the NSA had found (laughter) was made public. So in a perfect world, everyone patches their Microsoft software. This kind of attack doesn't become a problem. But the reality is that people don't update their computers. And one of the things we're learning is how many people and how many (laughter) parts of the world are failing to update their computers in a timely way. SIEGEL: But we're not just talking about people. We're talking about some very big institutions. And you write that the health care industry is the easiest to exploit. Briefly, why is that? TIMBERG: So hospitals, doctors offices, et cetera use a huge amount of computers and software technology, but updating that software tends not to be a top priority of theirs. It's also the case that sometimes regulations affect how quickly you can update. There's all sorts of HIPAA laws involving personal information. So health care has traditionally really lagged behind other industries in keeping itself secure by updating software, getting new hardware and generally sort of tightening up its ship. SIEGEL: And the stakes can be life or death. You write about someone whose surgery was canceled today because of the ransomware attack. TIMBERG: Indeed, and if nobody dies today because of this, we'll have to consider that a very happy turn of events because (laughter), as anyone who's ever been to a hospital knows, these things run on computers. And the world is incredibly dependent on these machines working properly, so when an attack like this happens, it's frankly very terrifying. SIEGEL: Let's talk about the scale of this attack. It's big. It's in many, many countries. Is it a record-breaking attack? Is it very unusual? What would you say? TIMBERG: It certainly is unusual in terms of its scope and essentially the amount of damage it's done. It's not unusual for a worm to get loose and affect, you know, a gazillion computers around the world. But this is unusual. This isn't just a worm that, you know, flashes some funny messages. This actually shut down computers. It shut down entire computer systems. So the scale on the sweep does seem very unusual. A number of analytics folks have said that we're talking about many dozens of countries- 70, 80, 90 - affected. And the numbers of computers are in the tens of thousands, maybe in the hundreds of thousands once people get around to counting all of them. SIEGEL: Do you know who is behind this attack? TIMBERG: I wish I did. I can tell you a lot of folks are trying to figure that out right now. These ransomware attacks - they're very pernicious. They're very common, and they're incredibly hard to track. And it'll take a lot of detective work to figure out who put this thing together. SIEGEL: That's Craig Timberg, national technology reporter at The Washington Post. Craig, thanks for talking with us today. TIMBERG: It was my pleasure. ROBERT SIEGEL, HOST:  Craig Timberg reports that the ransomware used in this attack apparently took advantage of a software vulnerability discovered by the National Security Agency. He's a national technology reporter with The Washington Post. He's also covering this story. Welcome to the program. CRAIG TIMBERG: Thanks, Robert. SIEGEL: And what's the NSA connection here? TIMBERG: The NSA spends a lot of its time looking for vulnerabilities in software so that it can spy on people around the world. That's the job of the agency. And so this group called Shadow Brokers managed to get their hands on a bunch of these vulnerabilities and release them on the internet. It appears to be one of these things that was actually used in the attacks today. SIEGEL: Now, Microsoft had released a patch fixing that flaw. That was in March. But it seems that many, many computers were vulnerable to this attack. Why? TIMBERG: Indeed, you know, the patch that Microsoft released came out even before the - this document describing the vulnerability that the NSA had found (laughter) was made public. So in a perfect world, everyone patches their Microsoft software. This kind of attack doesn't become a problem. But the reality is that people don't update their computers. And one of the things we're learning is how many people and how many (laughter) parts of the world are failing to update their computers in a timely way. SIEGEL: But we're not just talking about people. We're talking about some very big institutions. And you write that the health care industry is the easiest to exploit. Briefly, why is that? TIMBERG: So hospitals, doctors offices, et cetera use a huge amount of computers and software technology, but updating that software tends not to be a top priority of theirs. It's also the case that sometimes regulations affect how quickly you can update. There's all sorts of HIPAA laws involving personal information. So health care has traditionally really lagged behind other industries in keeping itself secure by updating software, getting new hardware and generally sort of tightening up its ship. SIEGEL: And the stakes can be life or death. You write about someone whose surgery was canceled today because of the ransomware attack. TIMBERG: Indeed, and if nobody dies today because of this, we'll have to consider that a very happy turn of events because (laughter), as anyone who's ever been to a hospital knows, these things run on computers. And the world is incredibly dependent on these machines working properly, so when an attack like this happens, it's frankly very terrifying. SIEGEL: Let's talk about the scale of this attack. It's big. It's in many, many countries. Is it a record-breaking attack? Is it very unusual? What would you say? TIMBERG: It certainly is unusual in terms of its scope and essentially the amount of damage it's done. It's not unusual for a worm to get loose and affect, you know, a gazillion computers around the world. But this is unusual. This isn't just a worm that, you know, flashes some funny messages. This actually shut down computers. It shut down entire computer systems. So the scale on the sweep does seem very unusual. A number of analytics folks have said that we're talking about many dozens of countries- 70, 80, 90 - affected. And the numbers of computers are in the tens of thousands, maybe in the hundreds of thousands once people get around to counting all of them. SIEGEL: Do you know who is behind this attack? TIMBERG: I wish I did. I can tell you a lot of folks are trying to figure that out right now. These ransomware attacks - they're very pernicious. They're very common, and they're incredibly hard to track. And it'll take a lot of detective work to figure out who put this thing together. SIEGEL: That's Craig Timberg, national technology reporter at The Washington Post. Craig, thanks for talking with us today. TIMBERG: It was my pleasure.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-05-13-528287794": {"title": "Cyber Security Experts Say Malware Used In Friday's Attack Is Especially Malicious  : NPR", "url": "https://www.npr.org/2017/05/13/528287794/cyber-security-experts-say-malware-used-in-fridays-attack-is-especially-maliciou", "author": "No author found", "published_date": "2017-05-13", "content": "MARY LOUISE KELLY, HOST: We begin with that huge cyberattack that hit tens of thousands of computers all over the world. In a moment, we'll hear from a former Pentagon official who had to defend the U. S. from attacks like this. But first, NPR's Jim Kane reports on the effort to restore computer systems that were paralyzed by Friday's attack. JIM KANE, BYLINE: Europol, the European Union's police agency, said the attack was at an unprecedented level, requiring a complex investigation. It began in Spain when screens at a telecom company began to display a pop-up message announcing your files have been encrypted and demanding a bitcoin payment of $300 to save the files from being deleted. And then the attack began to spread to other computers, other organizations, other countries - more than 100 countries in all - including Russia, China, India, the U. S. and England's National Health Service, where 16 hospitals were affected. Cybersecurity experts say this piece of malware had an especially malicious quality. Mark Nunnikhoven is vice president of cloud research at the security software company Trend Micro. MARK NUNNIKHOVEN: The initial infection is done because of an action that the user has been tricked into taking, but subsequent infections on the same network are done without any user interaction at all. And that's why we're seeing this massive explosion of infections. KANE: Where did the ransomware originate? While experts don't know who sent it, many believe it was stolen from the National Security Agency. Nunnikhoven says it appears whoever sent the malware got it from hacking tools released online last month. NUNNIKHOVEN: This underground group, The Shadow Brokers, released a number of tools that they claimed came from the NSA. And, of course, very difficult to verify whether that's correct or not, but that's generally the common belief. KANE: Whatever its source, the malware contained a flaw. It was designed to look for a certain domain name, and as long as it didn't find an active website with that name it would continue to spread. A British cybersecurity researcher noticed that, bought the domain name and activated it. And that slowed the spread of the attack. But not for long. Matt Suiche is the founder of the cybersecurity company Comae Technologies. MATT SUICHE: This is only temporary. I'm sure the attacker will provide a fix to the malware very quickly if they didn't already. KANE: While the malware may have originated with the NSA, cyber experts say it doesn't appear that any government is behind this attack. Mark Nunnikhoven says this appears to be a simple case of ransom for money. NUNNIKHOVEN: They went for the biggest return on their investment they could by hitting as many people as quickly as possible so that everybody was scrambling to defend. KANE: For computers that haven't been attacked, Microsoft has sent out software patches even for older operating systems it doesn't support anymore, like Windows XP. Companies, governments and individuals are installing that patch and taking a hard look at their cybersecurity systems with an eye toward the next attack. Jim Kane, NPR News. MARY LOUISE KELLY, HOST:  We begin with that huge cyberattack that hit tens of thousands of computers all over the world. In a moment, we'll hear from a former Pentagon official who had to defend the U. S. from attacks like this. But first, NPR's Jim Kane reports on the effort to restore computer systems that were paralyzed by Friday's attack. JIM KANE, BYLINE: Europol, the European Union's police agency, said the attack was at an unprecedented level, requiring a complex investigation. It began in Spain when screens at a telecom company began to display a pop-up message announcing your files have been encrypted and demanding a bitcoin payment of $300 to save the files from being deleted. And then the attack began to spread to other computers, other organizations, other countries - more than 100 countries in all - including Russia, China, India, the U. S. and England's National Health Service, where 16 hospitals were affected. Cybersecurity experts say this piece of malware had an especially malicious quality. Mark Nunnikhoven is vice president of cloud research at the security software company Trend Micro. MARK NUNNIKHOVEN: The initial infection is done because of an action that the user has been tricked into taking, but subsequent infections on the same network are done without any user interaction at all. And that's why we're seeing this massive explosion of infections. KANE: Where did the ransomware originate? While experts don't know who sent it, many believe it was stolen from the National Security Agency. Nunnikhoven says it appears whoever sent the malware got it from hacking tools released online last month. NUNNIKHOVEN: This underground group, The Shadow Brokers, released a number of tools that they claimed came from the NSA. And, of course, very difficult to verify whether that's correct or not, but that's generally the common belief. KANE: Whatever its source, the malware contained a flaw. It was designed to look for a certain domain name, and as long as it didn't find an active website with that name it would continue to spread. A British cybersecurity researcher noticed that, bought the domain name and activated it. And that slowed the spread of the attack. But not for long. Matt Suiche is the founder of the cybersecurity company Comae Technologies. MATT SUICHE: This is only temporary. I'm sure the attacker will provide a fix to the malware very quickly if they didn't already. KANE: While the malware may have originated with the NSA, cyber experts say it doesn't appear that any government is behind this attack. Mark Nunnikhoven says this appears to be a simple case of ransom for money. NUNNIKHOVEN: They went for the biggest return on their investment they could by hitting as many people as quickly as possible so that everybody was scrambling to defend. KANE: For computers that haven't been attacked, Microsoft has sent out software patches even for older operating systems it doesn't support anymore, like Windows XP. Companies, governments and individuals are installing that patch and taking a hard look at their cybersecurity systems with an eye toward the next attack. Jim Kane, NPR News.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-05-13-528287801": {"title": "Security Researcher And Microsoft Worked To Stop Spread Of Cyberattack : NPR", "url": "https://www.npr.org/2017/05/13/528287801/security-researcher-and-microsoft-worked-to-stop-spread-of-cyberattack", "author": "No author found", "published_date": "2017-05-13", "content": "MARY LOUISE KELLY, HOST: For some perspective on what happened and what the lessons of this attack may be, we've called Michael Sulmeyer. He was the Pentagon's director for Plans and Operations for Cyber Policy. Now he runs the cybersecurity project at Harvard's Kennedy School. Hello, Michael Sulmeyer. MICHAEL SULMEYER: Hello. Thanks for having me back. KELLY: Glad to have you on. So this attack is being described as unprecedented in scale. Let me start by asking - is it? How big was this? SULMEYER: Well, it looks like over 75,000 different infections across the world spreading over at least 70 countries. And that information itself has probably been revised upward. The largest number of infections is clearly in Russia. But as we saw yesterday, the most direct impact hit much closer to home in the United Kingdom against their national health service. KELLY: Can you tell where we are in the arc of this attack? Is the worst now behind us? SULMEYER: It does seem the worst is now behind us. I think that's right for two reasons. First, a security researcher was able to effectively trigger a kill switch to stop further propagation. The second reason is because Microsoft has done something that Microsoft generally does not do, which is it has issued an emergency patch for Windows XP, an unsupported operating system now, to try to help people recover. KELLY: That kill switch you mentioned, this was the 22-year-old in the U. K. who figured out a way to shut this down? What do you know about that? SULMEYER: He's a security researcher. But in essence, the attackers left open an opportunity to have this kind of a kill switch. And so he undertook the small and quick task to register what's called the domain for that kill switch. And once his registration became active, the ability for this ransomware to spread screeched to a halt. KELLY: Is it surprising that it's a 22-year-old who managed to shut this down when one assumes that cyber experts around the world were trying to do the same thing? SULMEYER: Not surprising at all. If there's any surprise it's that he's not younger. KELLY: (Laughter) That it's not a 12-year-old. . . SULMEYER: Exactly. KELLY: . . . Who managed to outsmart this. You mentioned that the worst cases appear to have been in Russia, also in the U. K. The U. S. seems to have gotten off relatively lightly. I'm looking around for some wood in the studio to knock on that that remains the case. But I wonder why. Did the U. S. just get lucky this time, or does that speak to a difference in readiness? SULMEYER: There's, I think, several different reasons at play. And you're right to try to find a piece of wood because it won't take much if someone wanted to restart this kind of activity in the near future. There's still, according to one study, over 1. 3 million machines that are still vulnerable out there. So - but one reason, at least, that I think Russia was infected so dramatically is that when you pirate copies of software, especially older copies of Windows, you generally don't qualify to have them updated, patched and fixed. And one thing Microsoft did when it rolled out its latest version of Windows was it made the upgrade free for almost anybody who wanted to do it legitimately. So when you have legitimate, genuine copies, you get better security. And when you don't have those copies, you don't. KELLY: Any clues yet as to who is responsible? SULMEYER: No clues yet. No. KELLY: The mystery remains unsolved. SULMEYER: I'm afraid so. KELLY: And that could take some time to figure out if we ever learn exactly who's behind this. SULMEYER: It could. But this is one of those realities about dealing with cyberspace operations. It's going to have to be an international effort. So for United States law enforcement and United Kingdom, we're really going to have to take advantage of relationships across a whole host of countries to get to the bottom of it. KELLY: Michael Sulmeyer, knocking on a big old piece of wood up there at the Kennedy School at Harvard. He is the director of the cybersecurity project there. And he's been talking to us about these latest big cyberattacks. Michael Sulmeyer, thank you. SULMEYER: Pleasure was mine. Thanks for having me. MARY LOUISE KELLY, HOST:  For some perspective on what happened and what the lessons of this attack may be, we've called Michael Sulmeyer. He was the Pentagon's director for Plans and Operations for Cyber Policy. Now he runs the cybersecurity project at Harvard's Kennedy School. Hello, Michael Sulmeyer. MICHAEL SULMEYER: Hello. Thanks for having me back. KELLY: Glad to have you on. So this attack is being described as unprecedented in scale. Let me start by asking - is it? How big was this? SULMEYER: Well, it looks like over 75,000 different infections across the world spreading over at least 70 countries. And that information itself has probably been revised upward. The largest number of infections is clearly in Russia. But as we saw yesterday, the most direct impact hit much closer to home in the United Kingdom against their national health service. KELLY: Can you tell where we are in the arc of this attack? Is the worst now behind us? SULMEYER: It does seem the worst is now behind us. I think that's right for two reasons. First, a security researcher was able to effectively trigger a kill switch to stop further propagation. The second reason is because Microsoft has done something that Microsoft generally does not do, which is it has issued an emergency patch for Windows XP, an unsupported operating system now, to try to help people recover. KELLY: That kill switch you mentioned, this was the 22-year-old in the U. K. who figured out a way to shut this down? What do you know about that? SULMEYER: He's a security researcher. But in essence, the attackers left open an opportunity to have this kind of a kill switch. And so he undertook the small and quick task to register what's called the domain for that kill switch. And once his registration became active, the ability for this ransomware to spread screeched to a halt. KELLY: Is it surprising that it's a 22-year-old who managed to shut this down when one assumes that cyber experts around the world were trying to do the same thing? SULMEYER: Not surprising at all. If there's any surprise it's that he's not younger. KELLY: (Laughter) That it's not a 12-year-old. . . SULMEYER: Exactly. KELLY: . . . Who managed to outsmart this. You mentioned that the worst cases appear to have been in Russia, also in the U. K. The U. S. seems to have gotten off relatively lightly. I'm looking around for some wood in the studio to knock on that that remains the case. But I wonder why. Did the U. S. just get lucky this time, or does that speak to a difference in readiness? SULMEYER: There's, I think, several different reasons at play. And you're right to try to find a piece of wood because it won't take much if someone wanted to restart this kind of activity in the near future. There's still, according to one study, over 1. 3 million machines that are still vulnerable out there. So - but one reason, at least, that I think Russia was infected so dramatically is that when you pirate copies of software, especially older copies of Windows, you generally don't qualify to have them updated, patched and fixed. And one thing Microsoft did when it rolled out its latest version of Windows was it made the upgrade free for almost anybody who wanted to do it legitimately. So when you have legitimate, genuine copies, you get better security. And when you don't have those copies, you don't. KELLY: Any clues yet as to who is responsible? SULMEYER: No clues yet. No. KELLY: The mystery remains unsolved. SULMEYER: I'm afraid so. KELLY: And that could take some time to figure out if we ever learn exactly who's behind this. SULMEYER: It could. But this is one of those realities about dealing with cyberspace operations. It's going to have to be an international effort. So for United States law enforcement and United Kingdom, we're really going to have to take advantage of relationships across a whole host of countries to get to the bottom of it. KELLY: Michael Sulmeyer, knocking on a big old piece of wood up there at the Kennedy School at Harvard. He is the director of the cybersecurity project there. And he's been talking to us about these latest big cyberattacks. Michael Sulmeyer, thank you. SULMEYER: Pleasure was mine. Thanks for having me.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-05-13-528259272": {"title": "Security Expert Weighs In On Worldwide Ransomware Hack : NPR", "url": "https://www.npr.org/2017/05/13/528259272/security-expert-weighs-in-on-worldwide-ransomware-hack", "author": "No author found", "published_date": "2017-05-13", "content": "SCOTT SIMON, HOST: The cyberattack that crippled computer systems across the world yesterday has exposed vulnerabilities that security experts have warned about. And one of those experts joins us now, Matt Tait, the CEO and founder of Capital Alpha Security in the United Kingdom. Mr. Tate, thanks for being with us. MATT TAIT: Thanks so much for having me. SIMON: Were you surprised? TAIT: Yes. So this particular vulnerability was a vulnerability that's actually been known for a while. It was attacked back in March. It was previously potentially used by the National Security Agency for espionage purposes, but ever since March it's been completely patched. So people who've been using their modern operating system - so Windows 7 and so on or who've been keeping up to date with their Windows patches - should have been completely secure against this vulnerability. So the fact that so many organizations were vulnerable to this is quite a surprise. SIMON: And is it over? TAIT: So at the moment, we're it's still in the eye of the storm. Lots of computers have been infected. Lots of organizations are having to scramble to recover their files through backups and, of course, making sure that they patch their systems so that future waves of ransomware using this particular vulnerability won't further compromise these organizations. SIMON: I have read that a 22-year-old researcher is the person who inadvertently perhaps stopped the attack, and I'm not sure that that reassures me if that's the case. TAIT: So that's why - malware research actually based in the U. K. was reverse engineering the malware and discovered that by registering a particular domain that they were able to disable the malware very briefly. Unfortunately, this is a very temporary solution. We're already starting to see that modified versions of this ransomware that don't query that particular domain are already in the wild. And this means that people can't, you know, just wait around. They do need to patch their systems. And they do need to do it today. SIMON: Mr. Tait, as you see the world, what else is vulnerable out there, and what can we do about it? TAIT: Well, at the moment, the real problem is whether or not people have been upgrading their systems and making sure that they've got their patches installed. They're really quite big organizations which have not been doing this, and they do need to be taking a step back and asking how they've allowed this to get to this state' cause this patch came out three months ago. And really, there's no excuse for these systems to still be online if they're not patching against these known vulnerabilities. SIMON: And do you think as we get through the weekend that there's something that regular ordinary citizens ought to be aware of? TAIT: At the moment, this is really going to be affecting businesses because businesses are the organizations that have all of these computers online. For people at home, this is going to be a little bit less of a hassle. Of course, it will be affecting businesses like FedEx. It will be affecting businesses like the National Health Service in the U. K. And people that rely on those services, of course, will be affected. But for people at home, really the advice is to make sure that you've installed your Windows updates and to keep your anti-virus up to date. And really, that is the best way of keeping this type of malware off people's systems at home. SIMON: Matt Tait is the CEO and founder of Capital Alpha Security. Thanks so much. TAIT: Thank you very much. SIMON: You're listening to NPR News. SCOTT SIMON, HOST:  The cyberattack that crippled computer systems across the world yesterday has exposed vulnerabilities that security experts have warned about. And one of those experts joins us now, Matt Tait, the CEO and founder of Capital Alpha Security in the United Kingdom. Mr. Tate, thanks for being with us. MATT TAIT: Thanks so much for having me. SIMON: Were you surprised? TAIT: Yes. So this particular vulnerability was a vulnerability that's actually been known for a while. It was attacked back in March. It was previously potentially used by the National Security Agency for espionage purposes, but ever since March it's been completely patched. So people who've been using their modern operating system - so Windows 7 and so on or who've been keeping up to date with their Windows patches - should have been completely secure against this vulnerability. So the fact that so many organizations were vulnerable to this is quite a surprise. SIMON: And is it over? TAIT: So at the moment, we're it's still in the eye of the storm. Lots of computers have been infected. Lots of organizations are having to scramble to recover their files through backups and, of course, making sure that they patch their systems so that future waves of ransomware using this particular vulnerability won't further compromise these organizations. SIMON: I have read that a 22-year-old researcher is the person who inadvertently perhaps stopped the attack, and I'm not sure that that reassures me if that's the case. TAIT: So that's why - malware research actually based in the U. K. was reverse engineering the malware and discovered that by registering a particular domain that they were able to disable the malware very briefly. Unfortunately, this is a very temporary solution. We're already starting to see that modified versions of this ransomware that don't query that particular domain are already in the wild. And this means that people can't, you know, just wait around. They do need to patch their systems. And they do need to do it today. SIMON: Mr. Tait, as you see the world, what else is vulnerable out there, and what can we do about it? TAIT: Well, at the moment, the real problem is whether or not people have been upgrading their systems and making sure that they've got their patches installed. They're really quite big organizations which have not been doing this, and they do need to be taking a step back and asking how they've allowed this to get to this state' cause this patch came out three months ago. And really, there's no excuse for these systems to still be online if they're not patching against these known vulnerabilities. SIMON: And do you think as we get through the weekend that there's something that regular ordinary citizens ought to be aware of? TAIT: At the moment, this is really going to be affecting businesses because businesses are the organizations that have all of these computers online. For people at home, this is going to be a little bit less of a hassle. Of course, it will be affecting businesses like FedEx. It will be affecting businesses like the National Health Service in the U. K. And people that rely on those services, of course, will be affected. But for people at home, really the advice is to make sure that you've installed your Windows updates and to keep your anti-virus up to date. And really, that is the best way of keeping this type of malware off people's systems at home. SIMON: Matt Tait is the CEO and founder of Capital Alpha Security. Thanks so much. TAIT: Thank you very much. SIMON: You're listening to NPR News.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-05-13-528236680": {"title": "Ransomware Attacks Computer Networks Around The Globe : NPR", "url": "https://www.npr.org/2017/05/13/528236680/ransomware-attacks-computer-networks-around-the-globe", "author": "No author found", "published_date": "2017-05-13", "content": "SCOTT SIMON, HOST: A cyberattack spread across the world yesterday. The British National Health Service, universities in China and FedEx were among the many places that were hit. The attackers wanted money ransom in exchange for data. NPR's tech reporter Aarti Shahani joins us. Aarti, thanks so much for being with us. AARTI SHAHANI, BYLINE: My pleasure. SIMON: Do we know how it started? SHAHANI: We don't know the exact timeline for each and every attack yet or if they were separate or coordinated attacks. But we do know it's all over the place now. There's a sort of heat map of the attacks that shows orange glowing dots across Europe, the U. S. , India, Brazil, Russia, China. All areas affected by this malware are called Wanna Cry or Wanna Decrypter. It was - starting yesterday morning, we got reports out of Spain and Britain. Over there in the National Health Service, hospitals were crippled, brought to a standstill. Doctors and nurses were literally, you know, locked out of their patients' files. And what I mean by that, by locked out, is this was a ransomware attack. Ransomware is a technique that hackers use in which they find a way to get into your system, say, by sending you an email that's literally a Trojan horse. It has malicious software inside. And then the hackers, you know, they take your files. They swoop through, and they encrypt them so you can't read them anymore. They're locked, and to unlock them, you need a decryption key. So the hackers will blurt out on your computer screen, hey, if you want to see your files again, pay us X amount in Bitcoin, the cryptocurrency. In this case, it seems to be small amounts in this series of attacks, say, a few hundred dollars. SIMON: Yeah. What damage in the United States near as you can tell? SHAHANI: Well, we're not really aware of what the damage is precisely. I mean, that's still being accounted for. One thing interestingly for people that are dissecting what happened is that many systems are now trying to clean up the damage. So it's hard to know exactly what happened. It's kind of like cleaning up a crime scene before doing the forensics on it. One thing that is being discussed - this is possibly malware coming from the NSA. Some security experts who've been collecting samples of the malware and dissecting them have been saying that these criminal attacks are based on attacks designed by the National Security Agency and then released into the public by a hacking group called The Shadow Brokers. You know, now, the NSA, they would have wanted to use the malware for spying purposes, right? The agency has a huge shop - we're very well aware of this - one of the world's best shops, dedicated to finding weaknesses in software and taking advantage of those weaknesses to break in and steal information for spying purposes. The problem is once you break in, you make digital keys, you can't really control who gets them. So this attack is raising one of these fundamental issues that we talk about in the security world about whether NSA surveillance protects people or creates unexpected damage that does more harm than good. SIMON: So I - so it's possible that there - it's possible that the NSA program to try and limit damage and trace people who would do harm to the country wound up doing harm across the world. SHAHANI: Yes, exactly, and that's the sort of - that could be the irony of this. SIMON: Mercy. It could have been - could it have been prevented? Aside from maybe not inventing it, could it have been prevented somehow? SHAHANI: Great question, and yeah, here's the thing - the software flaw is something in the Microsoft operating system, in Windows. Microsoft released a patch for it way back in March. So in an ideal world, you would have installed the patch and been protected from this onslaught, this ransomware campaign. But obviously, we don't live in an ideal world, and it's not reasonable to expect every local IT guy to update immediately. SIMON: So 15 seconds we have left - we know a lot of people listening to us are online. What do they do or not do? SHAHANI: Well, absolutely backup your data. Have a way to have your data backed up in a trusted cloud provider or an external drive because the fact is if you backup your data, this kind of attack loses its fangs. SIMON: NPR's Aarti Shahani, thanks so much for being with us. SHAHANI: Thank you. SCOTT SIMON, HOST:  A cyberattack spread across the world yesterday. The British National Health Service, universities in China and FedEx were among the many places that were hit. The attackers wanted money ransom in exchange for data. NPR's tech reporter Aarti Shahani joins us. Aarti, thanks so much for being with us. AARTI SHAHANI, BYLINE: My pleasure. SIMON: Do we know how it started? SHAHANI: We don't know the exact timeline for each and every attack yet or if they were separate or coordinated attacks. But we do know it's all over the place now. There's a sort of heat map of the attacks that shows orange glowing dots across Europe, the U. S. , India, Brazil, Russia, China. All areas affected by this malware are called Wanna Cry or Wanna Decrypter. It was - starting yesterday morning, we got reports out of Spain and Britain. Over there in the National Health Service, hospitals were crippled, brought to a standstill. Doctors and nurses were literally, you know, locked out of their patients' files. And what I mean by that, by locked out, is this was a ransomware attack. Ransomware is a technique that hackers use in which they find a way to get into your system, say, by sending you an email that's literally a Trojan horse. It has malicious software inside. And then the hackers, you know, they take your files. They swoop through, and they encrypt them so you can't read them anymore. They're locked, and to unlock them, you need a decryption key. So the hackers will blurt out on your computer screen, hey, if you want to see your files again, pay us X amount in Bitcoin, the cryptocurrency. In this case, it seems to be small amounts in this series of attacks, say, a few hundred dollars. SIMON: Yeah. What damage in the United States near as you can tell? SHAHANI: Well, we're not really aware of what the damage is precisely. I mean, that's still being accounted for. One thing interestingly for people that are dissecting what happened is that many systems are now trying to clean up the damage. So it's hard to know exactly what happened. It's kind of like cleaning up a crime scene before doing the forensics on it. One thing that is being discussed - this is possibly malware coming from the NSA. Some security experts who've been collecting samples of the malware and dissecting them have been saying that these criminal attacks are based on attacks designed by the National Security Agency and then released into the public by a hacking group called The Shadow Brokers. You know, now, the NSA, they would have wanted to use the malware for spying purposes, right? The agency has a huge shop - we're very well aware of this - one of the world's best shops, dedicated to finding weaknesses in software and taking advantage of those weaknesses to break in and steal information for spying purposes. The problem is once you break in, you make digital keys, you can't really control who gets them. So this attack is raising one of these fundamental issues that we talk about in the security world about whether NSA surveillance protects people or creates unexpected damage that does more harm than good. SIMON: So I - so it's possible that there - it's possible that the NSA program to try and limit damage and trace people who would do harm to the country wound up doing harm across the world. SHAHANI: Yes, exactly, and that's the sort of - that could be the irony of this. SIMON: Mercy. It could have been - could it have been prevented? Aside from maybe not inventing it, could it have been prevented somehow? SHAHANI: Great question, and yeah, here's the thing - the software flaw is something in the Microsoft operating system, in Windows. Microsoft released a patch for it way back in March. So in an ideal world, you would have installed the patch and been protected from this onslaught, this ransomware campaign. But obviously, we don't live in an ideal world, and it's not reasonable to expect every local IT guy to update immediately. SIMON: So 15 seconds we have left - we know a lot of people listening to us are online. What do they do or not do? SHAHANI: Well, absolutely backup your data. Have a way to have your data backed up in a trusted cloud provider or an external drive because the fact is if you backup your data, this kind of attack loses its fangs. SIMON: NPR's Aarti Shahani, thanks so much for being with us. SHAHANI: Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-05-14-528140036": {"title": "AP Test-Takers' Tweets May Not Give Away Answers, But They Raise Questions : NPR", "url": "https://www.npr.org/2017/05/14/528140036/ap-test-takers-tweets-may-not-give-away-answers-but-they-raise-questions", "author": "No author found", "published_date": "2017-05-14", "content": "", "section": "Education", "disclaimer": ""}, "2017-05-15-528502953": {"title": "Former White House CIO Outlines How To Safe Guard Against Malware : NPR", "url": "https://www.npr.org/2017/05/15/528502953/former-white-house-cio-outlines-how-to-safe-guard-against-malware", "author": "No author found", "published_date": "2017-05-15", "content": "AUDIE CORNISH, HOST: The computer malware attack that's captured and crippled institutions from Britain's National Health Service to businesses in China and Russia has also affected individuals. It's known as WannaCry, and it exploits a flaw in Microsoft Windows. From there, it spreads quickly to lock up all the files on a computer. Hackers then demand a ransom to release the data back to its owner. Theresa Payton is founder of Fortalice cybersecurity company. She's here to talk about what to do to protect yourself from WannaCry. Welcome to the program. THERESA PAYTON: Well, thank you for having me on. CORNISH: People are hearing a lot of kind of scary stuff about the ways that this malware attack is affecting big systems, but what preventive measure can they take right now to try and shield themselves? PAYTON: The first one is watch out for those links and attachments, even from people you know because cyber criminals are often spoofing your friends and family's email accounts. So what you want to do is trust but verify. Ask them, email them, did you mean to send this to me? The second thing you can do before you click on that link is go to a free tool called virustotal. com. What's great about that is it'll tell you whether or not somebody has reported it as a bad link. The other thing that can be incredibly helpful is you want to make sure you've got a really good backup system. This can be a great way to make sure that you can just backup and restore if you are a victim of this type of cyber crime. CORNISH: Now, the thing about this crime that sets it apart is the issue of ransom and the idea of whether or not to pay for it. The White House right now is saying that less than $70,000 in ransom has been paid and that none of that led to people actually getting their data back. What's your stance on this as a cybersecurity expert? PAYTON: Yeah. I mean, this is a tough one. In many cases, these cyber criminals do give you your data back after you pay because they want to make sure people continue to pay them. So there's almost this strange honor code among thieves, you know, where they kind of live up to yes, I'll give you your files back. I don't judge anybody that has to pay. I really do like to arm people with the offensive strategy so you don't have to pay. But in some cases people decide look, they want $300. And my pictures, my documents, my information is so precious to me, I can't afford to live without it, so I'm just going to pay. CORNISH: Even if you do pay, can you be sure the malware is off your computer for good? PAYTON: You can't be sure. And that's the tough thing because oftentimes you don't know. How did they get in here to begin with? Was it truly an email, and have I deleted it? Or was it a link that I actually trust, and I'm going to click on it again, and they're going to be right back? After you recover from ransomware, whether you pay them or you don't pay them, what you want to do is do a full scan of your device. The other thing, again, back to Apple, Linux and Microsoft, go to their website. They actually have free tools called anti-virus and anti-malware removal tools, so these tools will actually scan your computer, and they will actually see some of these bad files and fix things for you. Then the last thing is you always want to make sure you have the latest greatest Internet browsers and versions of operating systems because they are putting in new privacy and security features every week. And so if you keep those up to date, that's going to help a lot. CORNISH: Theresa Payton, you've given us a lot (laughter) to go through here. Thanks so much. PAYTON: Well, thanks for having me on. And I hope I helped everybody a little bit today. CORNISH: Theresa Payton is former chief information officer for the White House and founder of Fortalice, a cybersecurity firm. AUDIE CORNISH, HOST:  The computer malware attack that's captured and crippled institutions from Britain's National Health Service to businesses in China and Russia has also affected individuals. It's known as WannaCry, and it exploits a flaw in Microsoft Windows. From there, it spreads quickly to lock up all the files on a computer. Hackers then demand a ransom to release the data back to its owner. Theresa Payton is founder of Fortalice cybersecurity company. She's here to talk about what to do to protect yourself from WannaCry. Welcome to the program. THERESA PAYTON: Well, thank you for having me on. CORNISH: People are hearing a lot of kind of scary stuff about the ways that this malware attack is affecting big systems, but what preventive measure can they take right now to try and shield themselves? PAYTON: The first one is watch out for those links and attachments, even from people you know because cyber criminals are often spoofing your friends and family's email accounts. So what you want to do is trust but verify. Ask them, email them, did you mean to send this to me? The second thing you can do before you click on that link is go to a free tool called virustotal. com. What's great about that is it'll tell you whether or not somebody has reported it as a bad link. The other thing that can be incredibly helpful is you want to make sure you've got a really good backup system. This can be a great way to make sure that you can just backup and restore if you are a victim of this type of cyber crime. CORNISH: Now, the thing about this crime that sets it apart is the issue of ransom and the idea of whether or not to pay for it. The White House right now is saying that less than $70,000 in ransom has been paid and that none of that led to people actually getting their data back. What's your stance on this as a cybersecurity expert? PAYTON: Yeah. I mean, this is a tough one. In many cases, these cyber criminals do give you your data back after you pay because they want to make sure people continue to pay them. So there's almost this strange honor code among thieves, you know, where they kind of live up to yes, I'll give you your files back. I don't judge anybody that has to pay. I really do like to arm people with the offensive strategy so you don't have to pay. But in some cases people decide look, they want $300. And my pictures, my documents, my information is so precious to me, I can't afford to live without it, so I'm just going to pay. CORNISH: Even if you do pay, can you be sure the malware is off your computer for good? PAYTON: You can't be sure. And that's the tough thing because oftentimes you don't know. How did they get in here to begin with? Was it truly an email, and have I deleted it? Or was it a link that I actually trust, and I'm going to click on it again, and they're going to be right back? After you recover from ransomware, whether you pay them or you don't pay them, what you want to do is do a full scan of your device. The other thing, again, back to Apple, Linux and Microsoft, go to their website. They actually have free tools called anti-virus and anti-malware removal tools, so these tools will actually scan your computer, and they will actually see some of these bad files and fix things for you. Then the last thing is you always want to make sure you have the latest greatest Internet browsers and versions of operating systems because they are putting in new privacy and security features every week. And so if you keep those up to date, that's going to help a lot. CORNISH: Theresa Payton, you've given us a lot (laughter) to go through here. Thanks so much. PAYTON: Well, thanks for having me on. And I hope I helped everybody a little bit today. CORNISH: Theresa Payton is former chief information officer for the White House and founder of Fortalice, a cybersecurity firm.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-05-15-528502897": {"title": "Ransomware Attacks Begin To Stabilize After Compromising Networks Worldwide : NPR", "url": "https://www.npr.org/2017/05/15/528502897/ransomware-attacks-begin-to-stabilize-after-compromising-networks-worldwide", "author": "No author found", "published_date": "2017-05-15", "content": "ARI SHAPIRO, HOST: The massive cyber-attack known as WannaCry keeps spreading. It has now hit more than 300,000 computers in 150 countries. Those are the latest numbers from the White House. The ransomware locks down computers, and then hackers demand payment from victims to restore their files. And we're learning that while the numbers are growing, the actual threat from this attack may be receding. To help sort this out, we're joined by NPR's Aarti Shahani. Hi, Aarti. AARTI SHAHANI, BYLINE: Hi. SHAPIRO: This attack blew away cyber security experts because of how quickly it spread. Is it still infecting at the rate that we saw on Friday? SHAHANI: No, it's not. According to government officials and security experts, the onslaught is letting up. These ransomware attacks, the so-called WannaCry attack, is stabilizing worldwide. A DHS official says the list of victims here in the U. S. is very small. Outside the U. S. , experts who are working directly with victims say that the attack has been especially viral, hard to contain in two countries, China and Russia. And that is for a very interesting reason. It's because computers in those countries are using a lot of pirated versions of Windows, not legit versions from Microsoft. And since the way you prevent this attack is by updating, patching your Windows operating system, well, you know, that's hard to do when you've got a stolen copy. SHAPIRO: Yeah. What about the extent of the damage? How much of a problem did this become for companies and organizations that were affected by the attack? SHAHANI: You know, that's a key question, and here's what I've been able to gather about the actual damage, OK? I talked with a spokesperson at Renault, the French automaker, and they say that only a handful of their computers in France, Romania and Slovenia were actually hit and that no significant data was lost, and they did not pay any ransom. Now, that said, Renault did decide to do a wide-scale shutdown, and that's because they needed time to go through their systems and make sure that every single computer was patched. That's something they hadn't done before. So they're manufacturing plants that usually work over the weekend came to a standstill. One is still closed until tomorrow morning. And so in that way, they lost money through operating costs. SHAPIRO: Do we know of companies that lost money by paying ransoms? SHAHANI: Well, according to a firm called Chainalysis - that's a company that works against money laundering and tracks online payments - there were about 210 payments made to three addresses that were hardcoded into the malware. The payments were made in bitcoin. That's a digital currency that many hackers like to use, and the payments amounted to 32. 5 bitcoin which at the time of payment translates to about $56,000. That is not much money, OK? The Chainalysis researcher says he's seen more money made just by sending empty threats to financial institutions. And it could be it's not that much money because word on the street is that for those people who bothered to pay the hackers, the hackers didn't make do on their promise and didn't give files back. SHAPIRO: Oh, wow. Well, any more information about who these hackers might be? SHAHANI: Well, Homeland Security says that they don't know who the hackers are. And according to an expert at the company FireEye - that's a security firm with a huge global clientele - the hackers are not the creme de la creme, not the most sophisticated. And the reason he says that is because the malicious code they used had some significant weaknesses, so it was relatively easy to sabotage from the outside. But still, you know, that's an educated guess, and we don't have specific names for right now. SHAPIRO: That's NPR's Aarti Shahani on the latest on this malware attack around the world. Thank you, Aarti. SHAHANI: Thank you. ARI SHAPIRO, HOST:  The massive cyber-attack known as WannaCry keeps spreading. It has now hit more than 300,000 computers in 150 countries. Those are the latest numbers from the White House. The ransomware locks down computers, and then hackers demand payment from victims to restore their files. And we're learning that while the numbers are growing, the actual threat from this attack may be receding. To help sort this out, we're joined by NPR's Aarti Shahani. Hi, Aarti. AARTI SHAHANI, BYLINE: Hi. SHAPIRO: This attack blew away cyber security experts because of how quickly it spread. Is it still infecting at the rate that we saw on Friday? SHAHANI: No, it's not. According to government officials and security experts, the onslaught is letting up. These ransomware attacks, the so-called WannaCry attack, is stabilizing worldwide. A DHS official says the list of victims here in the U. S. is very small. Outside the U. S. , experts who are working directly with victims say that the attack has been especially viral, hard to contain in two countries, China and Russia. And that is for a very interesting reason. It's because computers in those countries are using a lot of pirated versions of Windows, not legit versions from Microsoft. And since the way you prevent this attack is by updating, patching your Windows operating system, well, you know, that's hard to do when you've got a stolen copy. SHAPIRO: Yeah. What about the extent of the damage? How much of a problem did this become for companies and organizations that were affected by the attack? SHAHANI: You know, that's a key question, and here's what I've been able to gather about the actual damage, OK? I talked with a spokesperson at Renault, the French automaker, and they say that only a handful of their computers in France, Romania and Slovenia were actually hit and that no significant data was lost, and they did not pay any ransom. Now, that said, Renault did decide to do a wide-scale shutdown, and that's because they needed time to go through their systems and make sure that every single computer was patched. That's something they hadn't done before. So they're manufacturing plants that usually work over the weekend came to a standstill. One is still closed until tomorrow morning. And so in that way, they lost money through operating costs. SHAPIRO: Do we know of companies that lost money by paying ransoms? SHAHANI: Well, according to a firm called Chainalysis - that's a company that works against money laundering and tracks online payments - there were about 210 payments made to three addresses that were hardcoded into the malware. The payments were made in bitcoin. That's a digital currency that many hackers like to use, and the payments amounted to 32. 5 bitcoin which at the time of payment translates to about $56,000. That is not much money, OK? The Chainalysis researcher says he's seen more money made just by sending empty threats to financial institutions. And it could be it's not that much money because word on the street is that for those people who bothered to pay the hackers, the hackers didn't make do on their promise and didn't give files back. SHAPIRO: Oh, wow. Well, any more information about who these hackers might be? SHAHANI: Well, Homeland Security says that they don't know who the hackers are. And according to an expert at the company FireEye - that's a security firm with a huge global clientele - the hackers are not the creme de la creme, not the most sophisticated. And the reason he says that is because the malicious code they used had some significant weaknesses, so it was relatively easy to sabotage from the outside. But still, you know, that's an educated guess, and we don't have specific names for right now. SHAPIRO: That's NPR's Aarti Shahani on the latest on this malware attack around the world. Thank you, Aarti. SHAHANI: Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-05-16-528570753": {"title": "Cyberattack Culprits Demand Ransom Be Paid In Bitcoins : NPR", "url": "https://www.npr.org/2017/05/16/528570753/cyberattack-culprits-demand-ransom-be-paid-in-bitcoins", "author": "No author found", "published_date": "2017-05-16", "content": "DAVID GREENE, HOST: If you were a victim of this global cyberattack that hit over 150 countries the last few days, you would have seen a message pop up on your computer. It demanded you pay hundreds of dollars to access your files. To pay, you had to use bitcoin. You wonder what that is? You're not alone. (SOUNDBITE OF TV SHOW, \"THE COLBERT REPORT\")STEPHEN COLBERT: Now, if you don't know what bitcoin is, want to buy some bitcoin? RACHEL MARTIN, HOST: That was Stephen Colbert back in 2013 when bitcoin, an anonymous form of online currency, was just becoming popular. Many people didn't really understand what it was, and four years later, many people still don't. SEAN SULLIVAN: I'm a computer nerd, and I think bitcoin is still kind of confusing, so that is actually the most difficult part for most people. GREENE: That computer nerd is Sean Sullivan with the Helsinki-based cybersecurity firm F-Secure. Hackers use bitcoin because it is anonymous and cannot be traced easily, but actually paying ransom in bitcoin can be daunting. You have to set up a virtual wallet. Then you have to link it to your bank account or your credit card. And then you have to find somewhere to actually buy bitcoin. MARTIN: So, of course, hackers want their money, so they want to make this easier. They're actually offering customer support. They send you links to bitcoin tutorials. They even have chat rooms where a member of the hacking group can help you out. Sullivan's company wanted to test just how good the customer service was, so they had someone who's not a computer expert download five viruses and then ask the hackers for help paying ransom. SULLIVAN: We got very personalized support via email to very - somewhat personal via forms, to some ignored us completely. We could figure it out. We could figure it out. If we didn't, they didn't care. GREENE: And the hackers were very understanding. Apparently, they would be willing to extend the ransom deadline. And Sullivan says that when the customer service was good, I mean, it was really good. SULLIVAN: There's even been some anecdotal cases of ransomers actually remote controlling the victim's computers in order to help them run the decryption tool because the victim's having trouble running the tool. GREENE: Some of the hackers were even willing to engage in bitcoin bargaining to lower the ransom. MARTIN: Yeah, so pretty sure my cable company could take some pointers from these guys. GREENE: Ouch. DAVID GREENE, HOST:  If you were a victim of this global cyberattack that hit over 150 countries the last few days, you would have seen a message pop up on your computer. It demanded you pay hundreds of dollars to access your files. To pay, you had to use bitcoin. You wonder what that is? You're not alone. (SOUNDBITE OF TV SHOW, \"THE COLBERT REPORT\") STEPHEN COLBERT: Now, if you don't know what bitcoin is, want to buy some bitcoin? RACHEL MARTIN, HOST:  That was Stephen Colbert back in 2013 when bitcoin, an anonymous form of online currency, was just becoming popular. Many people didn't really understand what it was, and four years later, many people still don't. SEAN SULLIVAN: I'm a computer nerd, and I think bitcoin is still kind of confusing, so that is actually the most difficult part for most people. GREENE: That computer nerd is Sean Sullivan with the Helsinki-based cybersecurity firm F-Secure. Hackers use bitcoin because it is anonymous and cannot be traced easily, but actually paying ransom in bitcoin can be daunting. You have to set up a virtual wallet. Then you have to link it to your bank account or your credit card. And then you have to find somewhere to actually buy bitcoin. MARTIN: So, of course, hackers want their money, so they want to make this easier. They're actually offering customer support. They send you links to bitcoin tutorials. They even have chat rooms where a member of the hacking group can help you out. Sullivan's company wanted to test just how good the customer service was, so they had someone who's not a computer expert download five viruses and then ask the hackers for help paying ransom. SULLIVAN: We got very personalized support via email to very - somewhat personal via forms, to some ignored us completely. We could figure it out. We could figure it out. If we didn't, they didn't care. GREENE: And the hackers were very understanding. Apparently, they would be willing to extend the ransom deadline. And Sullivan says that when the customer service was good, I mean, it was really good. SULLIVAN: There's even been some anecdotal cases of ransomers actually remote controlling the victim's computers in order to help them run the decryption tool because the victim's having trouble running the tool. GREENE: Some of the hackers were even willing to engage in bitcoin bargaining to lower the ransom. MARTIN: Yeah, so pretty sure my cable company could take some pointers from these guys. GREENE: Ouch.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-05-17-527052122": {"title": "Total Failure: When The Space Shuttle Didn't Come Home : NPR", "url": "https://www.npr.org/2017/05/17/527052122/total-failure-when-the-space-shuttle-didnt-come-home", "author": "No author found", "published_date": "2017-05-17", "content": "AUDIE CORNISH, HOST: We tend to mark our successes in life, but what if we're thinking about it the wrong way? What if it's failure that shapes us? All this month in a series we're calling Total Failure, we will examine mistakes and how they change people's lives. Today, NPR's Geoff Brumfiel brings us the story of Wayne Hale. He's an official at NASA who was involved in one of the agency's greatest failures - the loss of the space shuttle Columbia. GEOFF BRUMFIEL, BYLINE: On the morning of February 1, 2003, the Columbia was supposed to come back. Wayne Hale was at the landing site at the Kennedy Space Center in Florida. Wayne was an up and coming manager with NASA. He'd just taken a job overseeing shuttle launches. But since today was a landing, he didn't have much to do. WAYNE HALE: Really, it was kind of a party atmosphere out there. BRUMFIEL: He and the other managers were hanging around in a grassy viewing area near the landing strip. Families of the astronauts were there, too. Loudspeakers were playing communications between Columbia and Mission Control. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED MAN #1: Columbia continuing toward Florida, now approaching the New Mexico-Texas border. BRUMFIEL: Wayne was chatting with his friends and feeling pretty relaxed. The astronauts were scheduled to land any minute. HALE: And I really was not paying a bit of attention. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED MAN #1: And Columbia, Houston, we see your tire pressure messages, and we did not copy your last. UNIDENTIFIED MAN #2: Roger. HALE: And finally, somebody - and I can't remember who - said, isn't it unusual for them to be out of contact for so long? And I looked over at the clock, and I said, you know, to myself - I thought, no, this is really unusual. Not to have communication with the crew at this point is not good. There is something seriously wrong. And that's the first time I thought we were in real trouble. BRUMFIEL: Wayne and the others rushed back to the main buildings at the Space Center. By the time they made it, the television was already showing footage of the shuttle streaking across the sky, breaking apart with seven crew members inside. HALE: It was just, I mean, a very low time, really bad. BRUMFIEL: Wayne had spent his entire adult life in the space business. He knew it was dangerous, but NASA had the smartest engineers, the best rockets. HALE: I mean, I thought our organization was great. I thought we could handle anything. BRUMFIEL: Wayne and everyone at NASA that day felt an incredible sense of loss and also of failure. HALE: Our job is to keep the crew safe, and they weren't safe. And that's an immediate failure. Now you're just asking, in what way did we fail? BRUMFIEL: Trying to answer that question changed Waynes life forever. To understand how that happened, we need to go back to the day after the launch, when an engineer who worked for him, a guy named Bob Page, walked through his door. HALE: Bob comes into my office and says, hey, we had a debris strike on the orbiter. And I've got this video clip. Let me show it to you. BRUMFIEL: He popped a CD into Wayne's computer and pulled up the clip. It showed something fuzzy coming off the shuttle's big orange external fuel tank. The object smacked into Columbia's side. HALE: Somewhere on kind of the left wing area and went poof. BRUMFIEL: Pretty much right away Wayne knew what had happened. The big tank is covered in foam insulation. Some of that foam had fallen off and hit the shuttle during liftoff. Wayne and the other managers had meetings to look at the incident, and in the end, they decided, yeah, this is not a problem. HALE: The bottom line was we all felt pretty good. This is not going to be a safety issue. We're going to have to do some maintenance work but not a safety issue. And that's what we told the crew, you know, that's what we all thought. BRUMFIEL: Foam had been striking shuttles every now and then for years. It had done some damage in the past but not too much. This time was different though. On this fateful flight, the foam punched a small hole in the left wing. When the shuttle re-entered the atmosphere, hot gasses seeped into the hole. The aluminum frame melted. The wing buckled. The shuttle broke apart. So the wing failed because the foam failed, but for Wayne and NASA, that was not the real failure. HALE: All real problems are people problems. It's not, you know, did the foam come off the tank. It's why did people let the foam come off the tank? Why did we think it was OK for foam to come off the tank? BRUMFIEL: Remember, he'd known about the foam problem for years. He'd been in meetings where he could have said, hey, this looks dangerous. HALE: There are a hundred times I could have stood up. And would it have made a difference would? Would people have listened to me? I think they probably would have. I was senior enough. So yeah, I feel like this was probably the worst failure of my life. BRUMFIEL: Why didn't you? Why didn't you stand up? HALE: Well, you need a psychiatrist for that, I guess. I mean, I didn't think I needed to. I mean, I didn't think of it. I wasn't smart enough. BRUMFIEL: After the accident, an official investigation found there were some smart people at NASA who were worried. Engineers lower down in the shuttle organization had discussed problems with the foam many times before, but their concerns weren't clearly understood by people at the top like Wayne. HALE: We've got an awful lot of smart people in the space program, but many of them are not very good communicators. BRUMFIEL: And managers had a lot to worry about. They needed to keep the shuttle program on schedule and on budget. And there were always problems that needed fixing, so if an engineer couldn't explain an issue clearly, it got ignored. HALE: If somebody brought a concern to you and it was not, you know, it just didn't sound logical, you were very dismissive and basically told them to get a life. BRUMFIEL: After the accident, the heads of the shuttle program were removed. And in a strange twist of fate, Wayne Hale was promoted to second in command of the entire fleet. HALE: How can this be? You know, we screwed up. We failed. We made this big mistake. I was in the middle of it. And yet, you know, they put me in a higher position of authority. So yeah, you talk about feeling guilty. Now there is something to feel guilty about. BRUMFIEL: Part of Wayne's new job was to fix the cultural problems at NASA, and he resolved to start right away. HALE: We said the first thing we got to do is we got to put the arrogance aside. BRUMFIEL: Wayne became a listener. When an engineer came to him with an issue after the accident, even if he didn't understand it, he tried. HALE: I really had to take a step back and start treating people with OK, you've got this concern, I don't understand it. Back in the old days I would have yelled at you, but you don't say that. And now I have to really think about how I get you to give me some more information. BRUMFIEL: Wayne oversaw many of the shuttle flights after the accident. It did not fail again. He says they made plenty of changes to checklists, but he thinks the biggest change was that everyone who worked at NASA became better at talking and listening. Geoff Brumfiel, NPR News. (SOUNDBITE OF SEBASTIAN TELLIER'S \"LA RITOURNELLE\")CORNISH: Next week, our series Total Failure continues with the story of how mighty George Foreman lost the heavyweight title. AUDIE CORNISH, HOST:  We tend to mark our successes in life, but what if we're thinking about it the wrong way? What if it's failure that shapes us? All this month in a series we're calling Total Failure, we will examine mistakes and how they change people's lives. Today, NPR's Geoff Brumfiel brings us the story of Wayne Hale. He's an official at NASA who was involved in one of the agency's greatest failures - the loss of the space shuttle Columbia. GEOFF BRUMFIEL, BYLINE: On the morning of February 1, 2003, the Columbia was supposed to come back. Wayne Hale was at the landing site at the Kennedy Space Center in Florida. Wayne was an up and coming manager with NASA. He'd just taken a job overseeing shuttle launches. But since today was a landing, he didn't have much to do. WAYNE HALE: Really, it was kind of a party atmosphere out there. BRUMFIEL: He and the other managers were hanging around in a grassy viewing area near the landing strip. Families of the astronauts were there, too. Loudspeakers were playing communications between Columbia and Mission Control. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED MAN #1: Columbia continuing toward Florida, now approaching the New Mexico-Texas border. BRUMFIEL: Wayne was chatting with his friends and feeling pretty relaxed. The astronauts were scheduled to land any minute. HALE: And I really was not paying a bit of attention. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED MAN #1: And Columbia, Houston, we see your tire pressure messages, and we did not copy your last. UNIDENTIFIED MAN #2: Roger. HALE: And finally, somebody - and I can't remember who - said, isn't it unusual for them to be out of contact for so long? And I looked over at the clock, and I said, you know, to myself - I thought, no, this is really unusual. Not to have communication with the crew at this point is not good. There is something seriously wrong. And that's the first time I thought we were in real trouble. BRUMFIEL: Wayne and the others rushed back to the main buildings at the Space Center. By the time they made it, the television was already showing footage of the shuttle streaking across the sky, breaking apart with seven crew members inside. HALE: It was just, I mean, a very low time, really bad. BRUMFIEL: Wayne had spent his entire adult life in the space business. He knew it was dangerous, but NASA had the smartest engineers, the best rockets. HALE: I mean, I thought our organization was great. I thought we could handle anything. BRUMFIEL: Wayne and everyone at NASA that day felt an incredible sense of loss and also of failure. HALE: Our job is to keep the crew safe, and they weren't safe. And that's an immediate failure. Now you're just asking, in what way did we fail? BRUMFIEL: Trying to answer that question changed Waynes life forever. To understand how that happened, we need to go back to the day after the launch, when an engineer who worked for him, a guy named Bob Page, walked through his door. HALE: Bob comes into my office and says, hey, we had a debris strike on the orbiter. And I've got this video clip. Let me show it to you. BRUMFIEL: He popped a CD into Wayne's computer and pulled up the clip. It showed something fuzzy coming off the shuttle's big orange external fuel tank. The object smacked into Columbia's side. HALE: Somewhere on kind of the left wing area and went poof. BRUMFIEL: Pretty much right away Wayne knew what had happened. The big tank is covered in foam insulation. Some of that foam had fallen off and hit the shuttle during liftoff. Wayne and the other managers had meetings to look at the incident, and in the end, they decided, yeah, this is not a problem. HALE: The bottom line was we all felt pretty good. This is not going to be a safety issue. We're going to have to do some maintenance work but not a safety issue. And that's what we told the crew, you know, that's what we all thought. BRUMFIEL: Foam had been striking shuttles every now and then for years. It had done some damage in the past but not too much. This time was different though. On this fateful flight, the foam punched a small hole in the left wing. When the shuttle re-entered the atmosphere, hot gasses seeped into the hole. The aluminum frame melted. The wing buckled. The shuttle broke apart. So the wing failed because the foam failed, but for Wayne and NASA, that was not the real failure. HALE: All real problems are people problems. It's not, you know, did the foam come off the tank. It's why did people let the foam come off the tank? Why did we think it was OK for foam to come off the tank? BRUMFIEL: Remember, he'd known about the foam problem for years. He'd been in meetings where he could have said, hey, this looks dangerous. HALE: There are a hundred times I could have stood up. And would it have made a difference would? Would people have listened to me? I think they probably would have. I was senior enough. So yeah, I feel like this was probably the worst failure of my life. BRUMFIEL: Why didn't you? Why didn't you stand up? HALE: Well, you need a psychiatrist for that, I guess. I mean, I didn't think I needed to. I mean, I didn't think of it. I wasn't smart enough. BRUMFIEL: After the accident, an official investigation found there were some smart people at NASA who were worried. Engineers lower down in the shuttle organization had discussed problems with the foam many times before, but their concerns weren't clearly understood by people at the top like Wayne. HALE: We've got an awful lot of smart people in the space program, but many of them are not very good communicators. BRUMFIEL: And managers had a lot to worry about. They needed to keep the shuttle program on schedule and on budget. And there were always problems that needed fixing, so if an engineer couldn't explain an issue clearly, it got ignored. HALE: If somebody brought a concern to you and it was not, you know, it just didn't sound logical, you were very dismissive and basically told them to get a life. BRUMFIEL: After the accident, the heads of the shuttle program were removed. And in a strange twist of fate, Wayne Hale was promoted to second in command of the entire fleet. HALE: How can this be? You know, we screwed up. We failed. We made this big mistake. I was in the middle of it. And yet, you know, they put me in a higher position of authority. So yeah, you talk about feeling guilty. Now there is something to feel guilty about. BRUMFIEL: Part of Wayne's new job was to fix the cultural problems at NASA, and he resolved to start right away. HALE: We said the first thing we got to do is we got to put the arrogance aside. BRUMFIEL: Wayne became a listener. When an engineer came to him with an issue after the accident, even if he didn't understand it, he tried. HALE: I really had to take a step back and start treating people with OK, you've got this concern, I don't understand it. Back in the old days I would have yelled at you, but you don't say that. And now I have to really think about how I get you to give me some more information. BRUMFIEL: Wayne oversaw many of the shuttle flights after the accident. It did not fail again. He says they made plenty of changes to checklists, but he thinks the biggest change was that everyone who worked at NASA became better at talking and listening. Geoff Brumfiel, NPR News. (SOUNDBITE OF SEBASTIAN TELLIER'S \"LA RITOURNELLE\") CORNISH: Next week, our series Total Failure continues with the story of how mighty George Foreman lost the heavyweight title.", "section": "Space", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-05-19-529081034": {"title": "Google Is Investing In 'Immersive Technology' : NPR", "url": "https://www.npr.org/2017/05/19/529081034/google-is-investing-in-immersive-technology", "author": "No author found", "published_date": "2017-05-19", "content": "RACHEL MARTIN, HOST: Google offered a glimpse of how it sees the future at its annual Developers Conference this week, and that future involves a lot of blending between the real world and the virtual one. The company is investing heavily in what it's now calling immersive technology. NPR's Laura Sydell has more. LAURA SYDELL, BYLINE: Google's been the leader in getting the world acquainted with virtual reality. It's got that cheap, hand-assembled viewer called Cardboard that attaches to a smartphone. The company's going full throttle now and partnering with HTC and Lenovo on a standalone headset made of tougher stuff than Cardboard. Clay Bavor heads the division that developed it. CLAY BAVOR: Unlike systems that you have to connect to a PC or where you take your smartphone and insert it into a VR headset, everything you need for VR is contained right in the headset itself. SYDELL: Google is the first major company to release a standalone VR headset. Facebook's Oculus Rift and Sony VR have to be tethered to expensive computers or gaming consoles. Google's also beefing up its augmented reality technology. It announced what it's calling visual positioning service, or VPS. It will be incorporated into a new Asus smartphone. Bavor says, imagine you need to find an item in a very large store. BAVOR: You go to Lowe's, and you need to find this, you know, very specific bolt. You can pull up the Lowe's app, do a search for it, and then, your phone will walk you step by step to the exact aisle and shelf where that bolt is. SYDELL: Bavor says the company actually sees a continuum between its VR and AR technology. It's all part of a future where the virtual and real worlds blur. Google is calling it immersive computing. BAVOR: Virtual reality can make you really feel transported somewhere else. Augmented reality can bring kind of digital information into your environment and make it really seem as if it's there in the real world. SYDELL: There's a lot of competition among the big tech companies to advance these immersive technologies. Facebook, Microsoft and Sony are competitors, and Apple is likely to jump into the fray. But Google has some advantages, like its dominance in search. It's adding VR and AR capability to its Chrome browser. Greg Sterling is a contributing editor to Search Engine Land. GREG STERLING: Because it's got hardware. It's got a massive consumer audience and brand, and it's got all this data and software expertise. And really, none of the other players have all those pieces. SYDELL: An example of how this advantage works is that you could point your augmented reality-enabled phone at a restaurant, and a review would just pop up on the screen from Google search. But all Google's efforts may not be destined to succeed. Take that standalone VR headset. Brian Blau, an analyst at Gartner, says the high-end users will spend money for the power of an Oculus Rift, and the low end may be happy inserting their smartphone into a pair of goggles. BRIAN BLAU: Because you really have to want to be an extended VR user, if you will, if you're going to invest, you know, more than $500 into one of these systems. SYDELL: And Google has had its failures. Its augmented reality glasses known as Google Glass were a total flop with consumers. Google's VR headset will be out by the end of the year, and so will its new augmented reality-capable smartphones - still no word on price. Laura Sydell, NPR News, San Francisco. (SOUNDBITE OF DUALIST INQUIRY'S \"6AM\") RACHEL MARTIN, HOST:  Google offered a glimpse of how it sees the future at its annual Developers Conference this week, and that future involves a lot of blending between the real world and the virtual one. The company is investing heavily in what it's now calling immersive technology. NPR's Laura Sydell has more. LAURA SYDELL, BYLINE: Google's been the leader in getting the world acquainted with virtual reality. It's got that cheap, hand-assembled viewer called Cardboard that attaches to a smartphone. The company's going full throttle now and partnering with HTC and Lenovo on a standalone headset made of tougher stuff than Cardboard. Clay Bavor heads the division that developed it. CLAY BAVOR: Unlike systems that you have to connect to a PC or where you take your smartphone and insert it into a VR headset, everything you need for VR is contained right in the headset itself. SYDELL: Google is the first major company to release a standalone VR headset. Facebook's Oculus Rift and Sony VR have to be tethered to expensive computers or gaming consoles. Google's also beefing up its augmented reality technology. It announced what it's calling visual positioning service, or VPS. It will be incorporated into a new Asus smartphone. Bavor says, imagine you need to find an item in a very large store. BAVOR: You go to Lowe's, and you need to find this, you know, very specific bolt. You can pull up the Lowe's app, do a search for it, and then, your phone will walk you step by step to the exact aisle and shelf where that bolt is. SYDELL: Bavor says the company actually sees a continuum between its VR and AR technology. It's all part of a future where the virtual and real worlds blur. Google is calling it immersive computing. BAVOR: Virtual reality can make you really feel transported somewhere else. Augmented reality can bring kind of digital information into your environment and make it really seem as if it's there in the real world. SYDELL: There's a lot of competition among the big tech companies to advance these immersive technologies. Facebook, Microsoft and Sony are competitors, and Apple is likely to jump into the fray. But Google has some advantages, like its dominance in search. It's adding VR and AR capability to its Chrome browser. Greg Sterling is a contributing editor to Search Engine Land. GREG STERLING: Because it's got hardware. It's got a massive consumer audience and brand, and it's got all this data and software expertise. And really, none of the other players have all those pieces. SYDELL: An example of how this advantage works is that you could point your augmented reality-enabled phone at a restaurant, and a review would just pop up on the screen from Google search. But all Google's efforts may not be destined to succeed. Take that standalone VR headset. Brian Blau, an analyst at Gartner, says the high-end users will spend money for the power of an Oculus Rift, and the low end may be happy inserting their smartphone into a pair of goggles. BRIAN BLAU: Because you really have to want to be an extended VR user, if you will, if you're going to invest, you know, more than $500 into one of these systems. SYDELL: And Google has had its failures. Its augmented reality glasses known as Google Glass were a total flop with consumers. Google's VR headset will be out by the end of the year, and so will its new augmented reality-capable smartphones - still no word on price. Laura Sydell, NPR News, San Francisco. (SOUNDBITE OF DUALIST INQUIRY'S \"6AM\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-05-20-529257365": {"title": "Little Red Door: Small Indiana Nonprofit Falls Victim To Ransom Cyberattack : NPR", "url": "https://www.npr.org/2017/05/20/529257365/small-indiana-nonprofit-falls-victim-to-ransom-cyberattack", "author": "No author found", "published_date": "2017-05-20", "content": "SCOTT SIMON, HOST: There's a small nonprofit in Muncie, Ind. , that helps people fight cancer. But that good work did not prevent them from falling victim to a cyberattack like the one that locked computers around the world last week. The organization was hacked in January. And several months later, it is still recovering. Indiana Public Broadcasting's Annie Ropeik has the story. ANNIE ROPEIK, BYLINE: Everything was missing - client files, financial data all gone. It didn't make sense to the six-person staff of Cancer Services of East Central Indiana, also known as Little Red Door. And then to add to the confusion, says executive director Aimee Robertson-Fant, the staff started getting these weird text messages. AIMEE ROBERTSON FANT: Saying that they were going to be our new best friends and that they were going to help us. ROPEIK: Next came the email, the subject - cancer sucks, but we suck more. FANT: It was diabolical. It was cruel. They were brutal. ROPEIK: Hackers had accessed the nonprofit's server after a staffer inadvertently downloaded malware from an email. The hackers wanted 50 bitcoin, or what was then about $43,000 to return the data and to keep it private. FANT: I hate to use the word traumatic, but it was. I mean, you just don't understand what's happening. You just - you know, it's sort of an out-of-body experience where, you know, like - I - we just couldn't figure out why someone would be doing this to us. ROPEIK: Fant says the FBI told her they've been investigating this group of hackers - that they probably wanted sensitive information - bank accounts, Social Security numbers. But Little Red Door doesn't keep anything like that on file. So when they decided not to pay the ransom, the hackers posted what they did have. FANT: It was pretty despicable. We send out grief letters to families, and they did publish some grief letters on Twitter. ROPEIK: Michael Wolfe is the CTO of a local software firm. MICHAEL WOLFE: You are only as secure as your weakest link in the chain. So you need to be prepared for what you will do if that happens because the likelihood of that happening is increasing daily. ROPEIK: Wolfe volunteered to help the nonprofit secure what data they could, but they couldn't recover everything. FANT: Yeah. So we have, you know, all of our files in here. ROPEIK: Here meaning a drawer stuffed with manila folders. The staff has spent months painstakingly entering this client information back into their computers. Patient advocate Diana Rinker has led the effort. DIANA RINKER: I have a month of back data to enter. My goal is to have it done today, and we'll be caught up on this end. ROPEIK: Rinker was herself diagnosed with cancer just before the hack. She's been on data entry duty between rounds of chemo. RINKER: It's made it a little stressful, but it's so nice when our clients come in because we've not had one client that hasn't been understanding. ROPEIK: Little Red Door has struggled since the hack - and with more than just paperwork. Without all their data in hand, they haven't been able to get much of the grant funding that pays their bills. Michael Wolfe, the software company CTO, has this advice for small nonprofits. WOLFE: Stop. Sit down with your board, and think through some questions about - what is your IT infrastructure? Where do you store data? So I'm sure that there are improvements to be made that could prevent devastation. ROPEIK: Hackers don't discriminate, he says - no matter how small your business, how noble your nonprofit's mission, you are vulnerable. For NPR News, I'm Annie Ropeik. [POST-BROADCAST CLARIFICATION: Cancer Services of East Central Indiana \u2013 Little Red Door is separate from the Little Red Door Cancer Agency in Indianapolis, which was not the target of a cyberattack. ] SCOTT SIMON, HOST:  There's a small nonprofit in Muncie, Ind. , that helps people fight cancer. But that good work did not prevent them from falling victim to a cyberattack like the one that locked computers around the world last week. The organization was hacked in January. And several months later, it is still recovering. Indiana Public Broadcasting's Annie Ropeik has the story. ANNIE ROPEIK, BYLINE: Everything was missing - client files, financial data all gone. It didn't make sense to the six-person staff of Cancer Services of East Central Indiana, also known as Little Red Door. And then to add to the confusion, says executive director Aimee Robertson-Fant, the staff started getting these weird text messages. AIMEE ROBERTSON FANT: Saying that they were going to be our new best friends and that they were going to help us. ROPEIK: Next came the email, the subject - cancer sucks, but we suck more. FANT: It was diabolical. It was cruel. They were brutal. ROPEIK: Hackers had accessed the nonprofit's server after a staffer inadvertently downloaded malware from an email. The hackers wanted 50 bitcoin, or what was then about $43,000 to return the data and to keep it private. FANT: I hate to use the word traumatic, but it was. I mean, you just don't understand what's happening. You just - you know, it's sort of an out-of-body experience where, you know, like - I - we just couldn't figure out why someone would be doing this to us. ROPEIK: Fant says the FBI told her they've been investigating this group of hackers - that they probably wanted sensitive information - bank accounts, Social Security numbers. But Little Red Door doesn't keep anything like that on file. So when they decided not to pay the ransom, the hackers posted what they did have. FANT: It was pretty despicable. We send out grief letters to families, and they did publish some grief letters on Twitter. ROPEIK: Michael Wolfe is the CTO of a local software firm. MICHAEL WOLFE: You are only as secure as your weakest link in the chain. So you need to be prepared for what you will do if that happens because the likelihood of that happening is increasing daily. ROPEIK: Wolfe volunteered to help the nonprofit secure what data they could, but they couldn't recover everything. FANT: Yeah. So we have, you know, all of our files in here. ROPEIK: Here meaning a drawer stuffed with manila folders. The staff has spent months painstakingly entering this client information back into their computers. Patient advocate Diana Rinker has led the effort. DIANA RINKER: I have a month of back data to enter. My goal is to have it done today, and we'll be caught up on this end. ROPEIK: Rinker was herself diagnosed with cancer just before the hack. She's been on data entry duty between rounds of chemo. RINKER: It's made it a little stressful, but it's so nice when our clients come in because we've not had one client that hasn't been understanding. ROPEIK: Little Red Door has struggled since the hack - and with more than just paperwork. Without all their data in hand, they haven't been able to get much of the grant funding that pays their bills. Michael Wolfe, the software company CTO, has this advice for small nonprofits. WOLFE: Stop. Sit down with your board, and think through some questions about - what is your IT infrastructure? Where do you store data? So I'm sure that there are improvements to be made that could prevent devastation. ROPEIK: Hackers don't discriminate, he says - no matter how small your business, how noble your nonprofit's mission, you are vulnerable. For NPR News, I'm Annie Ropeik. [POST-BROADCAST CLARIFICATION: Cancer Services of East Central Indiana \u2013 Little Red Door is separate from the Little Red Door Cancer Agency in Indianapolis, which was not the target of a cyberattack. ]", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-05-22-529518708": {"title": "Federal Government Dodged 'WannaCry' Attack, But Still Has Vulnerabilities : NPR", "url": "https://www.npr.org/2017/05/22/529518708/federal-computers-dodge-global-malware-attack-this-time", "author": "No author found", "published_date": "2017-05-22", "content": "ARI SHAPIRO, HOST:  U. S. government computers were mostly safe from last week's ransomware attack on computer networks around the world. While the government may have dodged a bullet this time, experts say its systems are still vulnerable, though maybe less so than in the past. NPR's Brian Naylor reports. BRIAN NAYLOR, BYLINE: When the global malware attack dubbed WannaCry was first detected, a government cybersecurity response group moved quickly. They determined that this time government networks were largely protected from the intrusion. That's because agencies had already downloaded a patch that Microsoft sent out in March that closed the vulnerability in its most recent operating systems. Bruce McConnell was a top cybersecurity official in the Obama administration. In a Skype interview, McConnell says previous hacks, including the one at the Office of Personnel Management two years ago that stole the data of some 21 million people, had taught the feds a lesson. BRUCE MCCONNELL: I think the federal government had several wake-up calls in the last few years, so the Obama administration put quite a bit of emphasis on getting things patched, getting things up to date, cleaning up unsupported operating systems. NAYLOR: But McConnell says the WannaCry attack was relatively unsophisticated and that more sophisticated attacks will be harder to stop. In an executive order signed earlier this month, President Trump called for more robust deterrence against attackers. Frank Cilluffo, who directs the Center for Cyber and Homeland Security at the George Washington University, says that's an important step. FRANK CILLUFFO: In essence, we've been blaming the victim in terms of cybersecurity, and we need to put a little more pain on the perpetrators and the adversaries here. NAYLOR: He says that means rather than shaming users, going after and prosecuting individual hackers and continuing to impose stiff economic sanctions on nations behind state-sponsored attacks. CILLUFFO: I mean, if you think about it in the physical world, it would sort of be like every time you get robbed you call the locksmith. And we're never going to build high enough walls protected by a deep enough moats, protected by bigger and bigger locks. NAYLOR: In Congress, lawmakers are also moving to increase security for government networks. In a rare bipartisan vote, the House approved a measure that aims to nudge federal agencies to modernize their technology, including more use of cloud computing. The bill would provide $500 million for IT modernization, and agencies that save money through system upgrades could use those savings for other IT projects. Republican Congressman Will Hurd of Texas was the lead sponsor. WILL HURD: This is not a technology problem. This is a leadership problem. And if you have the right leadership that focuses on making sure we're constantly modernizing and that we're paying cybersecurity the right amount of attention, then we're going to be able to defend our infrastructure. NAYLOR: Cybersecurity expert Bruce McConnell says there are other potential vulnerabilities to government systems, including so-called zero-day bugs. Those are weaknesses unknown to the software developer and discovered by hackers before they can be patched. MCCONNELL: It's like taking care of your body or taking care of your car. You have to keep at it. It's not buy and forget. NAYLOR: McConnell says users, including the government, can't afford to let down their guard. Brian Naylor, NPR News, Washington. (SOUNDBITE OF TOSHIKO AKIYOSHI'S \"KISARAZU ZINKU\") ARI SHAPIRO, HOST:   U. S. government computers were mostly safe from last week's ransomware attack on computer networks around the world. While the government may have dodged a bullet this time, experts say its systems are still vulnerable, though maybe less so than in the past. NPR's Brian Naylor reports. BRIAN NAYLOR, BYLINE: When the global malware attack dubbed WannaCry was first detected, a government cybersecurity response group moved quickly. They determined that this time government networks were largely protected from the intrusion. That's because agencies had already downloaded a patch that Microsoft sent out in March that closed the vulnerability in its most recent operating systems. Bruce McConnell was a top cybersecurity official in the Obama administration. In a Skype interview, McConnell says previous hacks, including the one at the Office of Personnel Management two years ago that stole the data of some 21 million people, had taught the feds a lesson. BRUCE MCCONNELL: I think the federal government had several wake-up calls in the last few years, so the Obama administration put quite a bit of emphasis on getting things patched, getting things up to date, cleaning up unsupported operating systems. NAYLOR: But McConnell says the WannaCry attack was relatively unsophisticated and that more sophisticated attacks will be harder to stop. In an executive order signed earlier this month, President Trump called for more robust deterrence against attackers. Frank Cilluffo, who directs the Center for Cyber and Homeland Security at the George Washington University, says that's an important step. FRANK CILLUFFO: In essence, we've been blaming the victim in terms of cybersecurity, and we need to put a little more pain on the perpetrators and the adversaries here. NAYLOR: He says that means rather than shaming users, going after and prosecuting individual hackers and continuing to impose stiff economic sanctions on nations behind state-sponsored attacks. CILLUFFO: I mean, if you think about it in the physical world, it would sort of be like every time you get robbed you call the locksmith. And we're never going to build high enough walls protected by a deep enough moats, protected by bigger and bigger locks. NAYLOR: In Congress, lawmakers are also moving to increase security for government networks. In a rare bipartisan vote, the House approved a measure that aims to nudge federal agencies to modernize their technology, including more use of cloud computing. The bill would provide $500 million for IT modernization, and agencies that save money through system upgrades could use those savings for other IT projects. Republican Congressman Will Hurd of Texas was the lead sponsor. WILL HURD: This is not a technology problem. This is a leadership problem. And if you have the right leadership that focuses on making sure we're constantly modernizing and that we're paying cybersecurity the right amount of attention, then we're going to be able to defend our infrastructure. NAYLOR: Cybersecurity expert Bruce McConnell says there are other potential vulnerabilities to government systems, including so-called zero-day bugs. Those are weaknesses unknown to the software developer and discovered by hackers before they can be patched. MCCONNELL: It's like taking care of your body or taking care of your car. You have to keep at it. It's not buy and forget. NAYLOR: McConnell says users, including the government, can't afford to let down their guard. Brian Naylor, NPR News, Washington. (SOUNDBITE OF TOSHIKO AKIYOSHI'S \"KISARAZU ZINKU\")", "section": "Politics", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-05-25-529977203": {"title": "Computer Wins Again In Chinese Game Of Go : NPR", "url": "https://www.npr.org/2017/05/25/529977203/computer-wins-again-in-chinese-game-of-go", "author": "No author found", "published_date": "2017-05-25", "content": "RACHEL MARTIN, HOST: OK, Steve, time for a very quick story. STEVE INSKEEP, HOST: All right. MARTIN: Ready, set, go. INSKEEP: Here we go. It's a story about a board game called Go, a game where players try to control space on what is essentially a really big, oversized checkerboard. Now, it's fairly simple learn the game, but the number of possible moves is staggering - apparently more than the number of atoms in the observable universe. MARTIN: That's a lot. So until very recently, the game was just too hard for computers. This week, a Google program called AlphaGo is playing a series against Ke Jie. He's the world's top-ranked human player. Their first match started like this. . . (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED WOMAN: Ke Jie versus AlphaGo. We'll conduct the game by the Chinese Go rules. MARTIN: About four and a half hours later, AlphaGo won. INSKEEP: (Laughter) Match number two is this morning, China time, and the computer won again, taking the series from the human. RACHEL MARTIN, HOST:  OK, Steve, time for a very quick story. STEVE INSKEEP, HOST:  All right. MARTIN: Ready, set, go. INSKEEP: Here we go. It's a story about a board game called Go, a game where players try to control space on what is essentially a really big, oversized checkerboard. Now, it's fairly simple learn the game, but the number of possible moves is staggering - apparently more than the number of atoms in the observable universe. MARTIN: That's a lot. So until very recently, the game was just too hard for computers. This week, a Google program called AlphaGo is playing a series against Ke Jie. He's the world's top-ranked human player. Their first match started like this. . . (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED WOMAN: Ke Jie versus AlphaGo. We'll conduct the game by the Chinese Go rules. MARTIN: About four and a half hours later, AlphaGo won. INSKEEP: (Laughter) Match number two is this morning, China time, and the computer won again, taking the series from the human.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-05-25-529905669": {"title": "Should Body Camera Footage Be Controlled By The Police? : NPR", "url": "https://www.npr.org/2017/05/25/529905669/should-the-police-control-their-own-body-camera-footage", "author": "No author found", "published_date": "2017-05-25", "content": "", "section": "Law", "disclaimer": ""}, "2017-05-26-530257519": {"title": "After A Terrorist Attack, Social Media Can Cause More Harm Than Good : NPR", "url": "https://www.npr.org/2017/05/26/530257519/after-a-terrorist-attack-social-media-can-cause-more-harm-than-good", "author": "No author found", "published_date": "2017-05-26", "content": "AUDIE CORNISH, HOST: Many of us learned about the Manchester attack by looking at our phones. We got news alerts, saw videos posted to Facebook and tweets on Twitter. Perhaps you even sent a few of your own. But that might not be the best thing to do. EMILY DREYFUSS: Social media, because it's where everyone's sharing information, it's where law enforcement goes to find out what's going on, and it's where the media goes to find out what's going on. So if you're halfway across the world and you retweet something that's wrong, you're adding to the noise and making it harder for people to figure out how to stay safe. CORNISH: Emily Dreyfuss is a senior editor at WIRED. This week, she wrote about the harm social media can do in the wake of a terrorist attack. She joins us now. Welcome to the program. DREYFUSS: Thank you so much for having me. CORNISH: What harm is done by sharing information about attacks on social media? DREYFUSS: The potential harm that is done is that it amplifies the goal of terrorism, which is not merely to maim or murder people but to actually incite fear at large. And so when you retweet gory images, one thing that you are doing is spreading fear from a small group in a place like Manchester to the entire world. And that is the exact goal. CORNISH: So are you saying that this is part of the plan when there is an attack? And do you mean information they're sharing amongst themselves as propaganda, or do they kind of infiltrate that flow of information as well with the greater population? DREYFUSS: Both. I mean terrorists are some of the most savvy social media users in the world. They will put together their propaganda in the form of memes so that it's easily shareable. But additionally, in Manchester, one other risk is that terrorists want you to share so much information that you confuse the topic. So in Manchester, the terrorists used this app called Telegram to say that there were shooters all around Manchester, which was not true. But people picked up on that, put it on Twitter, and then that confused the issue. CORNISH: In the meantime, what about the big online platforms like Facebook, like Twitter? Are they doing anything in particular to try and prevent sensitive material from being spread after an attack? DREYFUSS: Yes, they're doing a lot. Twitter has suspended 636,248 accounts linked to terrorism between August 2015 and December 2016. Facebook, Twitter, YouTube and Microsoft have all partnered together to try to use artificial intelligence to get this kind of terrorist propaganda and violent imagery off of all of their platforms. It's an impossibly difficult task, but they are trying to take it seriously. CORNISH: Another aspect of this is the relationship between social media and network or legacy media - right? - that what we put out there online often ends up now on television to be played back at us. DREYFUSS: Exactly. Unfortunately, social media users may not have wanted this assignment. But if you're on social media right now, you are the assignment editor for mainstream television news, which means that anything you say, anything you share will be looked at by television journalists and potentially put on TV, all the more reason why people on social media need to be aware of the fact that what you do online can amplify this kind of terrorism. CORNISH: Now, in your article and here, you do point out that people rely on social media for good reasons during these events to find help or to offer help. But how do you think we should strike the balance? I mean when tragedy strikes, what is it that you're thinking we all should do or think about? DREYFUSS: I think, number one, the thing to do is pause and think first before you retweet or share something. Is the information I am sharing potentially helpful? One interesting thing is that the law enforcement in the U. K. tweeted out and said, please send your images directly to us; we rely on them to understand what happened and to bring justice to the perpetrators. But please don't share those on social media because that traumatizes the people who survived and the families of the victims. CORNISH: Emily Dreyfuss is a senior editor at WIRED. Her story examining how social media can amplify the chaos of a terror attack is on wired. com. Emily Dreyfuss, thanks so much for speaking with us. DREYFUSS: Thanks for having me, Audie. (SOUNDBITE OF FC KAHUNA SONG, \"HAYLING\") AUDIE CORNISH, HOST:  Many of us learned about the Manchester attack by looking at our phones. We got news alerts, saw videos posted to Facebook and tweets on Twitter. Perhaps you even sent a few of your own. But that might not be the best thing to do. EMILY DREYFUSS: Social media, because it's where everyone's sharing information, it's where law enforcement goes to find out what's going on, and it's where the media goes to find out what's going on. So if you're halfway across the world and you retweet something that's wrong, you're adding to the noise and making it harder for people to figure out how to stay safe. CORNISH: Emily Dreyfuss is a senior editor at WIRED. This week, she wrote about the harm social media can do in the wake of a terrorist attack. She joins us now. Welcome to the program. DREYFUSS: Thank you so much for having me. CORNISH: What harm is done by sharing information about attacks on social media? DREYFUSS: The potential harm that is done is that it amplifies the goal of terrorism, which is not merely to maim or murder people but to actually incite fear at large. And so when you retweet gory images, one thing that you are doing is spreading fear from a small group in a place like Manchester to the entire world. And that is the exact goal. CORNISH: So are you saying that this is part of the plan when there is an attack? And do you mean information they're sharing amongst themselves as propaganda, or do they kind of infiltrate that flow of information as well with the greater population? DREYFUSS: Both. I mean terrorists are some of the most savvy social media users in the world. They will put together their propaganda in the form of memes so that it's easily shareable. But additionally, in Manchester, one other risk is that terrorists want you to share so much information that you confuse the topic. So in Manchester, the terrorists used this app called Telegram to say that there were shooters all around Manchester, which was not true. But people picked up on that, put it on Twitter, and then that confused the issue. CORNISH: In the meantime, what about the big online platforms like Facebook, like Twitter? Are they doing anything in particular to try and prevent sensitive material from being spread after an attack? DREYFUSS: Yes, they're doing a lot. Twitter has suspended 636,248 accounts linked to terrorism between August 2015 and December 2016. Facebook, Twitter, YouTube and Microsoft have all partnered together to try to use artificial intelligence to get this kind of terrorist propaganda and violent imagery off of all of their platforms. It's an impossibly difficult task, but they are trying to take it seriously. CORNISH: Another aspect of this is the relationship between social media and network or legacy media - right? - that what we put out there online often ends up now on television to be played back at us. DREYFUSS: Exactly. Unfortunately, social media users may not have wanted this assignment. But if you're on social media right now, you are the assignment editor for mainstream television news, which means that anything you say, anything you share will be looked at by television journalists and potentially put on TV, all the more reason why people on social media need to be aware of the fact that what you do online can amplify this kind of terrorism. CORNISH: Now, in your article and here, you do point out that people rely on social media for good reasons during these events to find help or to offer help. But how do you think we should strike the balance? I mean when tragedy strikes, what is it that you're thinking we all should do or think about? DREYFUSS: I think, number one, the thing to do is pause and think first before you retweet or share something. Is the information I am sharing potentially helpful? One interesting thing is that the law enforcement in the U. K. tweeted out and said, please send your images directly to us; we rely on them to understand what happened and to bring justice to the perpetrators. But please don't share those on social media because that traumatizes the people who survived and the families of the victims. CORNISH: Emily Dreyfuss is a senior editor at WIRED. Her story examining how social media can amplify the chaos of a terror attack is on wired. com. Emily Dreyfuss, thanks so much for speaking with us. DREYFUSS: Thanks for having me, Audie. (SOUNDBITE OF FC KAHUNA SONG, \"HAYLING\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-05-29-530617251": {"title": "British Airways IT Meltdown Leaves Passengers Stranded : NPR", "url": "https://www.npr.org/2017/05/29/530617251/british-airways-it-meltdown-leaves-passengers-stranded", "author": "No author found", "published_date": "2017-05-29", "content": "ROBERT SIEGEL, HOST:  An IT meltdown at British Airways this weekend left about 75,000 passengers stranded and CEO Alex Cruz having to say I'm sorry. (SOUNDBITE OF ARCHIVED RECORDING)ALEX CRUZ: I know this has been a horrible time for customers. Some of you have missed holidays. Some of you have been stranded on aircraft. And some of you have been separated from your bags. Many of you have been stuck in long queues while you've waited for information. On behalf of everyone at British Airways, I want to apologize for the fact that you've had to go through these very trying experiences. SIEGEL: British Airways says it's nearly back on track now, but this is only the most recent of many technical problems for major airlines in the recent past. Robert Wall is the senior aviation reporter in Europe for The Wall Street Journal. He joins us from London. Welcome to the program. ROBERT WALL: Hi, Robert. SIEGEL: And first of all, walk us through what caused such a massive computer failure at British Airways. WALL: It seems to have been a power surge or some sort of power spike. And it took a large number of systems offline, not just one. So it was very widespread. SIEGEL: What do you figure was the cost of all this to British Airways? WALL: We're still trying to assess that. Under European rules there are - there's compensation passengers are entitled to automatically, and obviously there's the effect of lost sales. Analysts right now estimate about $90 million. Some people put the figure higher. SIEGEL: And what about the cost to the reputation of the airline, British Airways? WALL: It's certainly a black eye. It's not the first problem British Airways has had. And it's an airline that's been trying to, you know, remake itself, become more competitive, and in the process it's also cut back on some amenities. And that's already angered some passengers. So it's an airline in transition and comes at a - not a great time. SIEGEL: Robert, in the past year or so, we've seen other airlines cancel and delay hundreds of flights because of computer problems - Delta, Southwest, United. Are airlines unusually susceptible to computer problems? And if so, why? WALL: Well, I think there's two things that are happening here. I think, you know, airlines have a lot of legacy systems that have been around for years. And then they introduce something new and they have to patch it together with the old systems. And that creates a lot of places where things can go wrong. And then in the airline's case when things go wrong it's very difficult to recover. You've got planes stranded in the wrong location. You've got passengers and bags that want to go from here to there. You've got crew that have to be at certain places. So even once the systems come back up it's - you're always behind, trying to catch up. SIEGEL: Given the environment of computer glitches and also of sometimes cyber insecurity, do the airlines attach top priority to fixing their IT problems? WALL: I think it's certainly moved up in the priority list over the last few months. I mean, there was concern about cyber, although BA was very clear this was not a cyber incident. And there is increasing awareness that this patchwork of old and new IT systems is a distinct vulnerability. SIEGEL: Has it reached a point where passengers, customers of the airlines, should assume that mass disruptions are part of the new normal? WALL: I think part of the new normal is perhaps a bit too much. But, you know, I think there is - there has to be an expectation that when things go wrong that passengers have to unfortunately have a lot of patience or be prepared to have a lot of patience. SIEGEL: Robert Wall spoke to us from London, where he writes about aviation in Europe for The Wall Street Journal. Thanks for talking with us. WALL: Any time. ROBERT SIEGEL, HOST:   An IT meltdown at British Airways this weekend left about 75,000 passengers stranded and CEO Alex Cruz having to say I'm sorry. (SOUNDBITE OF ARCHIVED RECORDING) ALEX CRUZ: I know this has been a horrible time for customers. Some of you have missed holidays. Some of you have been stranded on aircraft. And some of you have been separated from your bags. Many of you have been stuck in long queues while you've waited for information. On behalf of everyone at British Airways, I want to apologize for the fact that you've had to go through these very trying experiences. SIEGEL: British Airways says it's nearly back on track now, but this is only the most recent of many technical problems for major airlines in the recent past. Robert Wall is the senior aviation reporter in Europe for The Wall Street Journal. He joins us from London. Welcome to the program. ROBERT WALL: Hi, Robert. SIEGEL: And first of all, walk us through what caused such a massive computer failure at British Airways. WALL: It seems to have been a power surge or some sort of power spike. And it took a large number of systems offline, not just one. So it was very widespread. SIEGEL: What do you figure was the cost of all this to British Airways? WALL: We're still trying to assess that. Under European rules there are - there's compensation passengers are entitled to automatically, and obviously there's the effect of lost sales. Analysts right now estimate about $90 million. Some people put the figure higher. SIEGEL: And what about the cost to the reputation of the airline, British Airways? WALL: It's certainly a black eye. It's not the first problem British Airways has had. And it's an airline that's been trying to, you know, remake itself, become more competitive, and in the process it's also cut back on some amenities. And that's already angered some passengers. So it's an airline in transition and comes at a - not a great time. SIEGEL: Robert, in the past year or so, we've seen other airlines cancel and delay hundreds of flights because of computer problems - Delta, Southwest, United. Are airlines unusually susceptible to computer problems? And if so, why? WALL: Well, I think there's two things that are happening here. I think, you know, airlines have a lot of legacy systems that have been around for years. And then they introduce something new and they have to patch it together with the old systems. And that creates a lot of places where things can go wrong. And then in the airline's case when things go wrong it's very difficult to recover. You've got planes stranded in the wrong location. You've got passengers and bags that want to go from here to there. You've got crew that have to be at certain places. So even once the systems come back up it's - you're always behind, trying to catch up. SIEGEL: Given the environment of computer glitches and also of sometimes cyber insecurity, do the airlines attach top priority to fixing their IT problems? WALL: I think it's certainly moved up in the priority list over the last few months. I mean, there was concern about cyber, although BA was very clear this was not a cyber incident. And there is increasing awareness that this patchwork of old and new IT systems is a distinct vulnerability. SIEGEL: Has it reached a point where passengers, customers of the airlines, should assume that mass disruptions are part of the new normal? WALL: I think part of the new normal is perhaps a bit too much. But, you know, I think there is - there has to be an expectation that when things go wrong that passengers have to unfortunately have a lot of patience or be prepared to have a lot of patience. SIEGEL: Robert Wall spoke to us from London, where he writes about aviation in Europe for The Wall Street Journal. Thanks for talking with us. WALL: Any time.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-05-31-530235165": {"title": "Total Failure: Creating The World's Worst Video Game : NPR", "url": "https://www.npr.org/2017/05/31/530235165/total-failure-the-worlds-worst-video-game", "author": "No author found", "published_date": "2017-05-31", "content": "ROBERT SIEGEL, HOST: Today we meet Howard Scott Warshaw, the man behind one of the early failures of the computer era. HOWARD SCOTT WARSHAW: I did the \"E. T. \" video game, the game that is widely held to be the worst video game of all time. SIEGEL: The Atari Corporation made millions of copies of his game, and it flopped. Some have claimed it was so bad it caused a collapse of the video game industry in 1983. NPR's Geoff Brumfiel has the story. GEOFF BRUMFIEL, BYLINE: From the very beginning of life, Howard Scott Warshaw was in a hurry. (SOUNDBITE OF VIDEO GAME MUSIC)WARSHAW: When I was a kid, I wanted to be older. When I was older, I wanted to be an adult. I wanted to get out, and I wanted to engage life 'cause that's - that's what I always pictured as the first time I'll be free. BRUMFIEL: Free of what? WARSHAW: Whatever. BRUMFIEL: He wanted to get through school fast, make a quite tidy fortune in business and retire by 30. Now, the other thing to know about young Howard is that he was smart - really smart. He got his degree in computer engineering, headed to Silicon Valley and eventually got hired at a new company called Atari. Atari was basically an early Silicon Valley startup. It had this gadget, the Atari 2600, which was the first really popular video game console. Howard's job was to design games. While others were programming black and white stick figures and balls. . . WARSHAW: I tried to make every single thing on the screen move and pulse with color and sound. (SOUNDBITE OF VIDEO GAME MUSIC)BRUMFIEL: His games were hits, and then Atari got a big contract. They would make the game for Steven Spielberg's first Indiana Jones movie, \"Raiders Of The Lost Ark. \" They put Howard on the job. Now, to put this in perspective, no one had ever done a video game based on a movie. And at 23, Howard was going to be the first programmer to ever attempt it. It took him 10 months to design the \"Raiders\" game, write the code, get feedback, re-program it and put it all through quality control. When that was finished, he shows Steven Spielberg the final product. WARSHAW: He looks up at me, and he says, it's just like a movie because I feel like I just watched a movie. I thought, oh, my God, you know, Steven Spielberg thinks that the game, the adventure game that I produced feels like a movie. To me, that was the ultimate compliment I could possibly receive on this work. BRUMFIEL: And here's where the trouble begins. The next movie Steven Spielberg makes is \"E. T. \" Spielberg wants an \"E. T. \" video game, and he wants Howard to program it. WARSHAW: Spielberg had requested that I do \"E. T. \" OK, so fine. I'm not going to argue. But what had happened was the negotiations for getting the rights for \"E. T. \" had run very long. BRUMFIEL: Atari and Spielberg haggled over rights and money until the end of July, 1982. And to get the game out in time for Christmas, Howard would have to have it built from scratch in five weeks. The CEO of Atari called him directly. WARSHAW: He goes, we need an \"E. T. \" game, and we need it for September 1. Can you do it? And I said, you bet I can. I absolutely can. I don't know what I was full of at that time exactly, but whatever it was, I was overflowing with it. And I believed I could pull it off. I mean, the hubris of it. (SOUNDBITE OF VIDEO GAME MUSIC)BRUMFIEL: Howard wasn't the only one full of hubris. During this period, Atari was one of the fastest growing companies in America. Its profits were soaring, and bonus checks were rolling in. Inside the headquarters were drugs and sex and booze. WARSHAW: It was a ridiculous excessive sort of, you know, fall of Rome kind of environment. BRUMFIEL: And everyone believed that nothing could stop them. WARSHAW: We can do no wrong. BRUMFIEL: So Howard has just 36 hours to come up with the concept for the game. In the movie, E. T. puts together a communicator he uses to phone home, so Howard makes that the basic plot of the game too. The player will be E. T. and go around gathering parts for the phone. WARSHAW: Another issue with me is like it's not enough that I'm just going to do a game in five weeks, I wanted to do something that was a step up, not just an add-on. BRUMFIEL: Howard creates this elaborate world for the Atari E. T. to explore. In this world, he puts lots of pits in the ground where he hides parts of the phone. We'll get back to those pits later. Anyway, Howard flies down to LA to show Spielberg the concept. WARSHAW: And I lay the whole thing out, and here it is. And Spielberg looks at me, and he goes, couldn't you just do something like \"Pac-Man\"? And I thought, oh, my God. And I had an impulse - just to give you an idea of how full of myself I was at that point. I'm sitting there with Steven Spielberg, and what I wanted to say was, well, gee, Steven, couldn't you do something like \"The Day The Earth Stood Still\"? BRUMFIEL: In the end, Spielberg signed off on Howard's concept. Howard goes back to Silicon Valley. He has a game development system moved into his home so he can work on \"E. T. \" day and night. WARSHAW: That was the hardest five weeks of my life. It was the hardest five weeks I ever spent doing pretty much anything. (SOUNDBITE OF JOHN WILLIAMS' \"FLYING\")BRUMFIEL: And at the end of those magical weeks, he took the blockbuster film \"E. T. \" and turned it into a horrible, horrible video game. (SOUNDBITE OF VIDEO GAME MUSIC)BRUMFIEL: OK. So E. T. has landed, and he's in some sort of weird forest thing. He does look like E. T. , I'll give you that. WARSHAW: He's in the forest. Yeah. Now he's got to run around to the areas with the pits and try and find some phone pieces. BRUMFIEL: Oh. So he just fell into something. WARSHAW: That's a pit. BRUMFIEL: OK. He comes out. Oh. He's back in. And now another guy in a tan jacket's after - oh. WARSHAW: That's the FBI agent. He steals whatever you're carrying 'cause they want to know what you've got. BRUMFIEL: So now I'm back to square - well, I don't even know what square I'm on really. WARSHAW: You're back to naked and lonely in a cruel world. It's a tough place to be. BRUMFIEL: Here comes the FBI agent again. What's he want? Oh, no. I'm in a pit. WARSHAW: (Laughter). BRUMFIEL: Oh, man. This is terrible. WARSHAW: (Laughter). BRUMFIEL: Now, here's the fundamental problem with \"E. T. \" It violates one of the basic rules of video game design. WARSHAW: There's a difference between frustration and disorientation. OK. Video games are all about frustration. It's OK to frustrate a user. In fact, it's important to frustrate a user, but you don't ever want to disorient a user. (SOUNDBITE OF VIDEO GAME MUSIC)BRUMFIEL: At first, Howard didn't know he'd made a dud. Sales around the holidays were strong. \"E. T. \" was at the top of the charts. But then in the halls of Atari, people started coming up to him and saying things. WARSHAW: You know, Howard, nobody blames you. BRUMFIEL: Things that made it clear \"E. T. \" had flopped. WARSHAW: You know, Howard, we really don't think it's your fault. We think you really came through for us. You did what you could, and we really appreciate that. It's all good. BRUMFIEL: Millions of copies went unsold. WARSHAW: It hurt. I mean, it hurt to hear that people aren't liking my game. BRUMFIEL: And meanwhile, Atari was running into some real trouble. The company's owners were making bad business deals. Programmers like Howard were making bad games. WARSHAW: Now, we have an expression in video games that greed kills. The time you die in a video game is usually when you're trying to get too many extra points. (SOUNDBITE OF VIDEO GAME MUSIC)BRUMFIEL: And just as quickly as it had risen, Atari was falling. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED JOURNALIST: The Atari Corporation has announced the layoff of 1,700 employees at its Sunnyvale plant in the Silicon Valley. BRUMFIEL: Now, some game aficionados have blamed \"E. T. \" for the death of Atari. Howard says that's not really true. \"E. T. \" was more of a symptom, the same ambition, arrogance and hype that made the game a flop ultimately doomed Atari to collapse. WARSHAW: Atari was the world to me. It was the world that worked and made everything I dreamed about being a reality. You want to talk about a failure? The failure of \"E. T. \" was really nothing at that time in my life compared to the loss of Atari as a workplace. BRUMFIEL: But when it came to failure, Howard was just getting started. Atari made him a millionaire, but he squandered it on bad investments. And then the IRS came after him for back taxes. Howard hit bottom. WARSHAW: Until one day, I really had to sit down with myself. You know, we have a lot of meetings. And so at one of the summits, I decided, you know, the IRS can only take my money. That's really all they can do. If I give them my happiness, that's on me. BRUMFIEL: And he began a long, slow journey towards finding that happiness again. He went from job to job - computers, videography. WARSHAW: Had a real estate broker's license for a while. BRUMFIEL: Some gigs were better than others but none compared to his time at Atari. The months stretched into years, eventually, more than a decade. And then one day, he was talking to his girlfriend at the time, and she asked, what do you really want to do? WARSHAW: I said, well, I'd be a therapist. I mean, I didn't even think for a second. I knew exactly what I wanted to do. BRUMFIEL: Therapy. It made perfect sense. Silicon Valley was booming, except instead of videogames it was smartphones and apps. Startups were failing. People's careers were crashing and burning. And after everything he'd been through, Howard knew he was the guy who could help. WARSHAW: I have been there. I do know what it's like. I have succeeded, and I have failed. And I have lost it, and I've had it, and I've lost it. And I've seen all this go. And I can help people really understand and relate and find a way around and through it. BRUMFIEL: Howard got his license. And today, he calls himself the Silicon Valley Therapist. His clients are a lot like he was back in the day - young, ambitious, rushing ahead. Business is good. Geoff Brumfiel, NPR News. ROBERT SIEGEL, HOST:  Today we meet Howard Scott Warshaw, the man behind one of the early failures of the computer era. HOWARD SCOTT WARSHAW: I did the \"E. T. \" video game, the game that is widely held to be the worst video game of all time. SIEGEL: The Atari Corporation made millions of copies of his game, and it flopped. Some have claimed it was so bad it caused a collapse of the video game industry in 1983. NPR's Geoff Brumfiel has the story. GEOFF BRUMFIEL, BYLINE: From the very beginning of life, Howard Scott Warshaw was in a hurry. (SOUNDBITE OF VIDEO GAME MUSIC) WARSHAW: When I was a kid, I wanted to be older. When I was older, I wanted to be an adult. I wanted to get out, and I wanted to engage life 'cause that's - that's what I always pictured as the first time I'll be free. BRUMFIEL: Free of what? WARSHAW: Whatever. BRUMFIEL: He wanted to get through school fast, make a quite tidy fortune in business and retire by 30. Now, the other thing to know about young Howard is that he was smart - really smart. He got his degree in computer engineering, headed to Silicon Valley and eventually got hired at a new company called Atari. Atari was basically an early Silicon Valley startup. It had this gadget, the Atari 2600, which was the first really popular video game console. Howard's job was to design games. While others were programming black and white stick figures and balls. . . WARSHAW: I tried to make every single thing on the screen move and pulse with color and sound. (SOUNDBITE OF VIDEO GAME MUSIC) BRUMFIEL: His games were hits, and then Atari got a big contract. They would make the game for Steven Spielberg's first Indiana Jones movie, \"Raiders Of The Lost Ark. \" They put Howard on the job. Now, to put this in perspective, no one had ever done a video game based on a movie. And at 23, Howard was going to be the first programmer to ever attempt it. It took him 10 months to design the \"Raiders\" game, write the code, get feedback, re-program it and put it all through quality control. When that was finished, he shows Steven Spielberg the final product. WARSHAW: He looks up at me, and he says, it's just like a movie because I feel like I just watched a movie. I thought, oh, my God, you know, Steven Spielberg thinks that the game, the adventure game that I produced feels like a movie. To me, that was the ultimate compliment I could possibly receive on this work. BRUMFIEL: And here's where the trouble begins. The next movie Steven Spielberg makes is \"E. T. \" Spielberg wants an \"E. T. \" video game, and he wants Howard to program it. WARSHAW: Spielberg had requested that I do \"E. T. \" OK, so fine. I'm not going to argue. But what had happened was the negotiations for getting the rights for \"E. T. \" had run very long. BRUMFIEL: Atari and Spielberg haggled over rights and money until the end of July, 1982. And to get the game out in time for Christmas, Howard would have to have it built from scratch in five weeks. The CEO of Atari called him directly. WARSHAW: He goes, we need an \"E. T. \" game, and we need it for September 1. Can you do it? And I said, you bet I can. I absolutely can. I don't know what I was full of at that time exactly, but whatever it was, I was overflowing with it. And I believed I could pull it off. I mean, the hubris of it. (SOUNDBITE OF VIDEO GAME MUSIC) BRUMFIEL: Howard wasn't the only one full of hubris. During this period, Atari was one of the fastest growing companies in America. Its profits were soaring, and bonus checks were rolling in. Inside the headquarters were drugs and sex and booze. WARSHAW: It was a ridiculous excessive sort of, you know, fall of Rome kind of environment. BRUMFIEL: And everyone believed that nothing could stop them. WARSHAW: We can do no wrong. BRUMFIEL: So Howard has just 36 hours to come up with the concept for the game. In the movie, E. T. puts together a communicator he uses to phone home, so Howard makes that the basic plot of the game too. The player will be E. T. and go around gathering parts for the phone. WARSHAW: Another issue with me is like it's not enough that I'm just going to do a game in five weeks, I wanted to do something that was a step up, not just an add-on. BRUMFIEL: Howard creates this elaborate world for the Atari E. T. to explore. In this world, he puts lots of pits in the ground where he hides parts of the phone. We'll get back to those pits later. Anyway, Howard flies down to LA to show Spielberg the concept. WARSHAW: And I lay the whole thing out, and here it is. And Spielberg looks at me, and he goes, couldn't you just do something like \"Pac-Man\"? And I thought, oh, my God. And I had an impulse - just to give you an idea of how full of myself I was at that point. I'm sitting there with Steven Spielberg, and what I wanted to say was, well, gee, Steven, couldn't you do something like \"The Day The Earth Stood Still\"? BRUMFIEL: In the end, Spielberg signed off on Howard's concept. Howard goes back to Silicon Valley. He has a game development system moved into his home so he can work on \"E. T. \" day and night. WARSHAW: That was the hardest five weeks of my life. It was the hardest five weeks I ever spent doing pretty much anything. (SOUNDBITE OF JOHN WILLIAMS' \"FLYING\") BRUMFIEL: And at the end of those magical weeks, he took the blockbuster film \"E. T. \" and turned it into a horrible, horrible video game. (SOUNDBITE OF VIDEO GAME MUSIC) BRUMFIEL: OK. So E. T. has landed, and he's in some sort of weird forest thing. He does look like E. T. , I'll give you that. WARSHAW: He's in the forest. Yeah. Now he's got to run around to the areas with the pits and try and find some phone pieces. BRUMFIEL: Oh. So he just fell into something. WARSHAW: That's a pit. BRUMFIEL: OK. He comes out. Oh. He's back in. And now another guy in a tan jacket's after - oh. WARSHAW: That's the FBI agent. He steals whatever you're carrying 'cause they want to know what you've got. BRUMFIEL: So now I'm back to square - well, I don't even know what square I'm on really. WARSHAW: You're back to naked and lonely in a cruel world. It's a tough place to be. BRUMFIEL: Here comes the FBI agent again. What's he want? Oh, no. I'm in a pit. WARSHAW: (Laughter). BRUMFIEL: Oh, man. This is terrible. WARSHAW: (Laughter). BRUMFIEL: Now, here's the fundamental problem with \"E. T. \" It violates one of the basic rules of video game design. WARSHAW: There's a difference between frustration and disorientation. OK. Video games are all about frustration. It's OK to frustrate a user. In fact, it's important to frustrate a user, but you don't ever want to disorient a user. (SOUNDBITE OF VIDEO GAME MUSIC) BRUMFIEL: At first, Howard didn't know he'd made a dud. Sales around the holidays were strong. \"E. T. \" was at the top of the charts. But then in the halls of Atari, people started coming up to him and saying things. WARSHAW: You know, Howard, nobody blames you. BRUMFIEL: Things that made it clear \"E. T. \" had flopped. WARSHAW: You know, Howard, we really don't think it's your fault. We think you really came through for us. You did what you could, and we really appreciate that. It's all good. BRUMFIEL: Millions of copies went unsold. WARSHAW: It hurt. I mean, it hurt to hear that people aren't liking my game. BRUMFIEL: And meanwhile, Atari was running into some real trouble. The company's owners were making bad business deals. Programmers like Howard were making bad games. WARSHAW: Now, we have an expression in video games that greed kills. The time you die in a video game is usually when you're trying to get too many extra points. (SOUNDBITE OF VIDEO GAME MUSIC) BRUMFIEL: And just as quickly as it had risen, Atari was falling. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED JOURNALIST: The Atari Corporation has announced the layoff of 1,700 employees at its Sunnyvale plant in the Silicon Valley. BRUMFIEL: Now, some game aficionados have blamed \"E. T. \" for the death of Atari. Howard says that's not really true. \"E. T. \" was more of a symptom, the same ambition, arrogance and hype that made the game a flop ultimately doomed Atari to collapse. WARSHAW: Atari was the world to me. It was the world that worked and made everything I dreamed about being a reality. You want to talk about a failure? The failure of \"E. T. \" was really nothing at that time in my life compared to the loss of Atari as a workplace. BRUMFIEL: But when it came to failure, Howard was just getting started. Atari made him a millionaire, but he squandered it on bad investments. And then the IRS came after him for back taxes. Howard hit bottom. WARSHAW: Until one day, I really had to sit down with myself. You know, we have a lot of meetings. And so at one of the summits, I decided, you know, the IRS can only take my money. That's really all they can do. If I give them my happiness, that's on me. BRUMFIEL: And he began a long, slow journey towards finding that happiness again. He went from job to job - computers, videography. WARSHAW: Had a real estate broker's license for a while. BRUMFIEL: Some gigs were better than others but none compared to his time at Atari. The months stretched into years, eventually, more than a decade. And then one day, he was talking to his girlfriend at the time, and she asked, what do you really want to do? WARSHAW: I said, well, I'd be a therapist. I mean, I didn't even think for a second. I knew exactly what I wanted to do. BRUMFIEL: Therapy. It made perfect sense. Silicon Valley was booming, except instead of videogames it was smartphones and apps. Startups were failing. People's careers were crashing and burning. And after everything he'd been through, Howard knew he was the guy who could help. WARSHAW: I have been there. I do know what it's like. I have succeeded, and I have failed. And I have lost it, and I've had it, and I've lost it. And I've seen all this go. And I can help people really understand and relate and find a way around and through it. BRUMFIEL: Howard got his license. And today, he calls himself the Silicon Valley Therapist. His clients are a lot like he was back in the day - young, ambitious, rushing ahead. Business is good. Geoff Brumfiel, NPR News.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-06-05-531629211": {"title": "Audible Offers Lottery For Employees To Live 1 Year Rent-Free In Newark, N.J. : NPR", "url": "https://www.npr.org/2017/06/05/531629211/audible-offers-lottery-for-employees-to-live-1-year-rent-free-in-newark-n-j", "author": "No author found", "published_date": "2017-06-05", "content": "KELLY MCEVERS, HOST:  Before we leave New Jersey, we should talk about a more recent tech breakthrough that happened there. Twenty years ago, the Garden State firm Audible introduced the world's first commercially available portable digital audio player. DON KATZ: We built this thing and brought it up four and a half years before the iPod. ROBERT SIEGEL, HOST:  Don Katz is founder and CEO of the company. You may have heard messages acknowledging Audible support for NPR on our air. Katz started the revolution in modern mobile listening and then did something equally radical. He moved his company from a leafy New Jersey suburb to Newark. That's right, to Newark. KATZ: When we moved here in 2007, I was told we were going to lose 25 percent of our employees because of the decision to come to a challenged city. SIEGEL: In the distant past, Newark was in fact a place for innovation. Celluloid, the first commercially successful plastic, came from there, but in the last few decades, plastics is not what most people think of when someone mentions the city. DEANNA PAQUETTE: Crime - that's kind of what people think of when they hear Newark. MCEVERS: That's Deanna Paquette, a senior designer at Audible. Despite the negative associations she had with the city, she now lives there. That's because her boss, Don Katz, is a big booster of the city. KATZ: Newark's definitely on the road to becoming a place that pioneers want to go. MCEVERS: Audible ran a housing lottery for employees a few months back. The company would pay their rent for a year as long as they signed a two-year lease at a renovated building in downtown Newark. Of the 1,000 employees, 64 applied. Paquette was one of the 20 winners. She had been living in Brooklyn. PAQUETTE: I was commuting to Newark. It was about an hour and a half each way. MCEVERS: She gave that up, and now she can walk to work. But as a native New Yorker, she is still faced with a psychological barrier. PAQUETTE: We have a thing against New Jersey to begin with. MCEVERS: And that's a prejudice even free rent can't undo. (SOUNDBITE OF STROBO'S \"AMAZONIA BANG BANG\") KELLY MCEVERS, HOST:   Before we leave New Jersey, we should talk about a more recent tech breakthrough that happened there. Twenty years ago, the Garden State firm Audible introduced the world's first commercially available portable digital audio player. DON KATZ: We built this thing and brought it up four and a half years before the iPod. ROBERT SIEGEL, HOST:   Don Katz is founder and CEO of the company. You may have heard messages acknowledging Audible support for NPR on our air. Katz started the revolution in modern mobile listening and then did something equally radical. He moved his company from a leafy New Jersey suburb to Newark. That's right, to Newark. KATZ: When we moved here in 2007, I was told we were going to lose 25 percent of our employees because of the decision to come to a challenged city. SIEGEL: In the distant past, Newark was in fact a place for innovation. Celluloid, the first commercially successful plastic, came from there, but in the last few decades, plastics is not what most people think of when someone mentions the city. DEANNA PAQUETTE: Crime - that's kind of what people think of when they hear Newark. MCEVERS: That's Deanna Paquette, a senior designer at Audible. Despite the negative associations she had with the city, she now lives there. That's because her boss, Don Katz, is a big booster of the city. KATZ: Newark's definitely on the road to becoming a place that pioneers want to go. MCEVERS: Audible ran a housing lottery for employees a few months back. The company would pay their rent for a year as long as they signed a two-year lease at a renovated building in downtown Newark. Of the 1,000 employees, 64 applied. Paquette was one of the 20 winners. She had been living in Brooklyn. PAQUETTE: I was commuting to Newark. It was about an hour and a half each way. MCEVERS: She gave that up, and now she can walk to work. But as a native New Yorker, she is still faced with a psychological barrier. PAQUETTE: We have a thing against New Jersey to begin with. MCEVERS: And that's a prejudice even free rent can't undo. (SOUNDBITE OF STROBO'S \"AMAZONIA BANG BANG\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-06-05-531574945": {"title": "Trump Announces Plan To Privatize Air Traffic Control : NPR", "url": "https://www.npr.org/2017/06/05/531574945/trump-announces-plan-to-privatize-air-traffic-control", "author": "No author found", "published_date": "2017-06-05", "content": "KELLY MCEVERS, HOST:  The White House announced a plan today to privatize the U. S. air traffic control system. This is part of the administration's focus this week on the country's aging infrastructure. President Trump says the FAA has been trying to update the air traffic control system for years. (SOUNDBITE OF ARCHIVED RECORDING)PRESIDENT DONALD TRUMP: But after billions and billions of tax dollars spent and the many years of delays, we're still stuck with an ancient, broken, antiquated, horrible system that doesn't work. MCEVERS: The president's plan to modernize air traffic control by privatizing it has a number of supporters and some critics, too. Here's NPR's David Schaper. DAVID SCHAPER, BYLINE: President Trump says the nation's air traffic control system is stuck painfully in the past. (SOUNDBITE OF ARCHIVED RECORDING)TRUMP: At a time when every passenger has GPS technology in their pockets our air traffic control system still runs on radar and ground-based radio systems that they don't even make anymore, they can't even fix anymore. SCHAPER: Flanked by airline executives, the president said flight delays and air traffic control inefficiencies cost the nation's economy billions each year. (SOUNDBITE OF ARCHIVED RECORDING)TRUMP: We're proposing reduced wait times, increased route efficiency and far fewer delays. Our plan will get you where you need to go more quickly, more reliably, more affordably. SCHAPER: The president's plan calls for a three-year transition in which air traffic control operations would be turned over to a private nonprofit entity, similar to how it's done in Canada. The FAA would continue to provide safety oversight while the private entity would be run by a 13-member board made up of airport and airline executives, labor unions and other stakeholders. PAUL HUDSON: The airlines would essentially be in charge of the skies. SCHAPER: Paul Hudson is president of the passenger advocacy group flyersrights. org. He argues this could be risky. HUDSON: Hardly a week goes by that they haven't had a - either a shutdown through computer outages or videos that show mistreatment of passengers. And it goes on and on. SCHAPER: The Trump plan would eliminate ticket taxes on passengers, replacing it with a more direct funding scheme. And that concerns Democratic Congressman Peter DeFazio of Oregon, ranking member of the House Transportation Committee. PETER DEFAZIO: What fees are you going to pay to this private corporation to get on the plane? The airlines hate the ticket tax and want to do away with it, but what's the new system? What's that going to do to general aviation? What's that going to do to businesses aviation, cargo? We don't know. SCHAPER: DeFazio also worries that privatizing air traffic control operations could actually slow recent progress the FAA is making in implementing its new satellite-based system called NextGen. But Robert Puentes, who heads the nonpartisan think tank Eno Center for Transportation, disagrees. ROBERT PUENTES: There's no doubt that moving to this independent nonprofit system would be able to deploy this new technology faster than the way that we're doing it right now. SCHAPER: Puentes says years of uncertain budgets and partisan gridlock have slowed the implementation of NextGen, and he argues privatizing air traffic control would provide stability. PUENTES: This really isn't about deconstructing government. This isn't getting government out of transportation. It's not selling off assets, anything like that. This is really about getting this very important investment done much faster. SCHAPER: Nonetheless, some Republicans have joined Democrats in opposing efforts to privatize the air traffic control system in the past, so like many other elements of the president's agenda, this plan likely has some turbulence ahead. David Schaper, NPR News. KELLY MCEVERS, HOST:   The White House announced a plan today to privatize the U. S. air traffic control system. This is part of the administration's focus this week on the country's aging infrastructure. President Trump says the FAA has been trying to update the air traffic control system for years. (SOUNDBITE OF ARCHIVED RECORDING) PRESIDENT DONALD TRUMP: But after billions and billions of tax dollars spent and the many years of delays, we're still stuck with an ancient, broken, antiquated, horrible system that doesn't work. MCEVERS: The president's plan to modernize air traffic control by privatizing it has a number of supporters and some critics, too. Here's NPR's David Schaper. DAVID SCHAPER, BYLINE: President Trump says the nation's air traffic control system is stuck painfully in the past. (SOUNDBITE OF ARCHIVED RECORDING) TRUMP: At a time when every passenger has GPS technology in their pockets our air traffic control system still runs on radar and ground-based radio systems that they don't even make anymore, they can't even fix anymore. SCHAPER: Flanked by airline executives, the president said flight delays and air traffic control inefficiencies cost the nation's economy billions each year. (SOUNDBITE OF ARCHIVED RECORDING) TRUMP: We're proposing reduced wait times, increased route efficiency and far fewer delays. Our plan will get you where you need to go more quickly, more reliably, more affordably. SCHAPER: The president's plan calls for a three-year transition in which air traffic control operations would be turned over to a private nonprofit entity, similar to how it's done in Canada. The FAA would continue to provide safety oversight while the private entity would be run by a 13-member board made up of airport and airline executives, labor unions and other stakeholders. PAUL HUDSON: The airlines would essentially be in charge of the skies. SCHAPER: Paul Hudson is president of the passenger advocacy group flyersrights. org. He argues this could be risky. HUDSON: Hardly a week goes by that they haven't had a - either a shutdown through computer outages or videos that show mistreatment of passengers. And it goes on and on. SCHAPER: The Trump plan would eliminate ticket taxes on passengers, replacing it with a more direct funding scheme. And that concerns Democratic Congressman Peter DeFazio of Oregon, ranking member of the House Transportation Committee. PETER DEFAZIO: What fees are you going to pay to this private corporation to get on the plane? The airlines hate the ticket tax and want to do away with it, but what's the new system? What's that going to do to general aviation? What's that going to do to businesses aviation, cargo? We don't know. SCHAPER: DeFazio also worries that privatizing air traffic control operations could actually slow recent progress the FAA is making in implementing its new satellite-based system called NextGen. But Robert Puentes, who heads the nonpartisan think tank Eno Center for Transportation, disagrees. ROBERT PUENTES: There's no doubt that moving to this independent nonprofit system would be able to deploy this new technology faster than the way that we're doing it right now. SCHAPER: Puentes says years of uncertain budgets and partisan gridlock have slowed the implementation of NextGen, and he argues privatizing air traffic control would provide stability. PUENTES: This really isn't about deconstructing government. This isn't getting government out of transportation. It's not selling off assets, anything like that. This is really about getting this very important investment done much faster. SCHAPER: Nonetheless, some Republicans have joined Democrats in opposing efforts to privatize the air traffic control system in the past, so like many other elements of the president's agenda, this plan likely has some turbulence ahead. David Schaper, NPR News.", "section": "National", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-06-09-532220824": {"title": " Canada's Tech Firms Capitalize On Immigration Anxiety In The Age Of Trump : NPR", "url": "https://www.npr.org/2017/06/09/532220824/canadas-tech-firms-capitalize-on-immigration-anxiety-in-the-age-of-trump", "author": "No author found", "published_date": "2017-06-09", "content": "AUDIE CORNISH, HOST: Countries around the world are trying to entice Americans unhappy with the Trump administration. French President Emmanuel Macron has invited climate scientists, engineers and entrepreneurs to come to France. Now the Canadian government is reaching out to tech professionals. As NPR's Joel Rose reports, Canada is making it easier for highly skilled workers to move north of the border. JOEL ROSE, BYLINE: A lot of people talked about moving to Canada after the U. S. election. Kathryn Hume actually did. Earlier this month, Hume packed up her apartment in New York and moved to Toronto. KATHRYN HUME: It wasn't a, like, going on Facebook and being like, I'm done. I'm moving to Canada. It was a little bit more organic. ROSE: Hume works in the field of artificial intelligence. She is employee number three at a startup company called Integrate AI, where her title is vice president of product and strategy. HUME: I had a couple of job offers also in the U. S. , and I chose it primarily because it really felt like the right job. ROSE: Still, Hume says Trump's election was in the back of her mind. She voted for Hillary Clinton. HUME: You know, I thought, well, if there's a time to move to Canada, it may as well be now. ROSE: Canadian tech companies are hoping to capitalize on this moment. For years, the industry watched in frustration as Microsoft and Google hired the country's top computer science grads for high-paying jobs in Seattle and Silicon Valley. Now Canada believes it's found a new way to lure international tech workers. NAVDEEP BAINS: For us to compete globally, we need to be open. ROSE: Navdeep Bains is Canada's minister of innovation, science and economic development. Starting Monday, Bains says the government will streamline the visa process so that international tech workers can get a work permit in just two weeks, compared to a complicated process in the U. S. that can take months. BAINS: We do believe it does give us a competitive advantage. ROSE: Bains insists this was in the works before last year's U. S. election, but the timing is striking. The White House stoked anxiety among international visitors and would-be immigrants with its travel ban. And President Trump has sharply criticized the U. S. visa program for technical workers. His administration could reduce the cap for such visas, which is set at 85,000 per year. The president vowed to reform that program in Wisconsin a few months ago. (SOUNDBITE OF ARCHIVED RECORDING)PRESIDENT DONALD TRUMP: They should never, ever be used to replace Americans. No one can compete with American workers when they are given a fair and level playing field. SALIM TEJA: We feel that Canada has a window of opportunity here to be able to attract the best and the brightest here. ROSE: Salim Teja is vice president of the MaRS Discovery District, a major incubator for tech companies in Toronto. Teja says there's fierce global competition for talent in the industry, with companies offering escalating salaries and perks. And those employers need to know that they can get visas for the people they're hiring. TEJA: A lot of these technology companies are very international businesses where talent is flowing freely in and out of different countries. And I think that if the U. S. becomes a tough place to do business that way, they may look at Canada as an easy market for them to set up in. ROSE: Facebook, Google and Uber have recently opened or expanded their offices in Toronto. Microsoft has satellite offices in Vancouver, and smaller Canadian companies say they're getting interest from a pool of American and international job applicants they hadn't heard from before. Roy Pereira is the founder of Zoom. Ai, a startup in Toronto. After Trump's election, Pereira says he saw a 30 percent jump in Americans applying for engineering jobs. ROY PEREIRA: As Canadians, we're not accustomed to seeing Americans who want to move to Canada. You know, they have a perception that Canada is cold. But there is a certain anxiety around the immigration policies and so forth. ROSE: Pereira and others hope that means a warmer forecast for the Canadian tech industry. Joel Rose, NPR News. (SOUNDBITE OF BAYONNE SONG, \"SPECTROLITE\") AUDIE CORNISH, HOST:  Countries around the world are trying to entice Americans unhappy with the Trump administration. French President Emmanuel Macron has invited climate scientists, engineers and entrepreneurs to come to France. Now the Canadian government is reaching out to tech professionals. As NPR's Joel Rose reports, Canada is making it easier for highly skilled workers to move north of the border. JOEL ROSE, BYLINE: A lot of people talked about moving to Canada after the U. S. election. Kathryn Hume actually did. Earlier this month, Hume packed up her apartment in New York and moved to Toronto. KATHRYN HUME: It wasn't a, like, going on Facebook and being like, I'm done. I'm moving to Canada. It was a little bit more organic. ROSE: Hume works in the field of artificial intelligence. She is employee number three at a startup company called Integrate AI, where her title is vice president of product and strategy. HUME: I had a couple of job offers also in the U. S. , and I chose it primarily because it really felt like the right job. ROSE: Still, Hume says Trump's election was in the back of her mind. She voted for Hillary Clinton. HUME: You know, I thought, well, if there's a time to move to Canada, it may as well be now. ROSE: Canadian tech companies are hoping to capitalize on this moment. For years, the industry watched in frustration as Microsoft and Google hired the country's top computer science grads for high-paying jobs in Seattle and Silicon Valley. Now Canada believes it's found a new way to lure international tech workers. NAVDEEP BAINS: For us to compete globally, we need to be open. ROSE: Navdeep Bains is Canada's minister of innovation, science and economic development. Starting Monday, Bains says the government will streamline the visa process so that international tech workers can get a work permit in just two weeks, compared to a complicated process in the U. S. that can take months. BAINS: We do believe it does give us a competitive advantage. ROSE: Bains insists this was in the works before last year's U. S. election, but the timing is striking. The White House stoked anxiety among international visitors and would-be immigrants with its travel ban. And President Trump has sharply criticized the U. S. visa program for technical workers. His administration could reduce the cap for such visas, which is set at 85,000 per year. The president vowed to reform that program in Wisconsin a few months ago. (SOUNDBITE OF ARCHIVED RECORDING) PRESIDENT DONALD TRUMP: They should never, ever be used to replace Americans. No one can compete with American workers when they are given a fair and level playing field. SALIM TEJA: We feel that Canada has a window of opportunity here to be able to attract the best and the brightest here. ROSE: Salim Teja is vice president of the MaRS Discovery District, a major incubator for tech companies in Toronto. Teja says there's fierce global competition for talent in the industry, with companies offering escalating salaries and perks. And those employers need to know that they can get visas for the people they're hiring. TEJA: A lot of these technology companies are very international businesses where talent is flowing freely in and out of different countries. And I think that if the U. S. becomes a tough place to do business that way, they may look at Canada as an easy market for them to set up in. ROSE: Facebook, Google and Uber have recently opened or expanded their offices in Toronto. Microsoft has satellite offices in Vancouver, and smaller Canadian companies say they're getting interest from a pool of American and international job applicants they hadn't heard from before. Roy Pereira is the founder of Zoom. Ai, a startup in Toronto. After Trump's election, Pereira says he saw a 30 percent jump in Americans applying for engineering jobs. ROY PEREIRA: As Canadians, we're not accustomed to seeing Americans who want to move to Canada. You know, they have a perception that Canada is cold. But there is a certain anxiety around the immigration policies and so forth. ROSE: Pereira and others hope that means a warmer forecast for the Canadian tech industry. Joel Rose, NPR News. (SOUNDBITE OF BAYONNE SONG, \"SPECTROLITE\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-06-14-532824432": {"title": "If Voting Machines Were Hacked, It Might Not Be Obvious : NPR", "url": "https://www.npr.org/2017/06/14/532824432/if-voting-machines-were-hacked-would-anyone-know", "author": "No author found", "published_date": "2017-06-14", "content": "STEVE INSKEEP, HOST: Let's spend a moment on an overshadowed question about Russia and the U. S. election. For President Trump, the investigation of Russian interference in last year's election is a quote, \"witch hunt. \" For some lawmakers, though, the real question is whether Russian interference can be prevented in the future. Officials say they see no evidence that votes have been tampered with, but they can't be sure. Here's NPR's Pam Fessler. PAM FESSLER, BYLINE: Election officials assured voters repeatedly last year that there was no way foreign hackers could manipulate votes. Louisiana Secretary of State Tom Schedler was typical. (SOUNDBITE OF ARCHIVED RECORDING)TOM SCHEDLER: There is no state, in general - no state - voting in cyberspace on the Internet. So how do you hack something in cyberspace when it's not in cyberspace? JEREMY EPSTEIN: Well, it's inaccurate on two levels. FESSLER: Election cybersecurity expert Jeremy Epstein says many states do allow some online voting, usually for members of the military. But more importantly, even if most voting machines aren't connected to the Internet. . . EPSTEIN: They are connected to something that's connected to something that's connected to the Internet. FESSLER: And last week's release of a U. S. intelligence report on Russian hacking only reinforced his concerns. Russia apparently broke into an election software vendor's computer system and used that information to send 122 election officials fake emails infected with malicious software. It's unclear if anyone took the bait, but University of Michigan computer scientist Alex Halderman says it's just the kind of phishing attacks someone would use if they wanted to manipulate votes. ALEX HALDERMAN: That's because before every election, the voting machines have to be programmed with the design of the ballot, right? What are the races? Who are the candidates? FESSLER: And that's done on a computer in a central election office or by a contractor. The ballot program is then installed on individual voting machines using removable memory cards. HALDERMAN: So as a remote attacker, I can target an election management system, one of these ballot programming computers. If I can infect it with malicious software, I can have that malicious software spread to the individual machines on the memory cards and then change votes on Election Day. FESSLER: There's absolutely no evidence that happened last year, but Halderman notes that some or all electronic voting machines in 14 states have no paper ballot backups that can be checked to make sure there was no tampering. State and local election officials insist such an attack would be extremely difficult, if not impossible because of tight security measures such as restrictions on who has access to voting machines. Still, Connecticut election director Peggy Reeves told a panel on voting technology earlier this week that many local election officials are ill-equipped to handle cybersecurity threats. (SOUNDBITE OF ARCHIVED RECORDING)PEGGY REEVES: Many of our towns actually have no local IT support. Seriously, they don't have an IT director in their town. They might have a consultant that they call on if they have an issue. So they look to us, but we're a pretty small division. FESSLER: She says the best protection against hackers is probably the fact that the nation's voting system is so decentralized. Larry Norden, an election technology expert with the Brennan Center, agrees, but he's worried that last year's intruders were laying the groundwork for more serious attacks in the future. LARRY NORDEN: This is a real threat. It's not going away, and if anything, foreign adversaries - even people at home might be emboldened to do this more going forward. And to me, it is a real call that we have to do more as soon as possible, to secure these systems. FESSLER: He would like all voting machines to have paper records and for all states to conduct routine audits to make sure that the electronic results match the paper ones. Pam Fessler, NPR News. STEVE INSKEEP, HOST:  Let's spend a moment on an overshadowed question about Russia and the U. S. election. For President Trump, the investigation of Russian interference in last year's election is a quote, \"witch hunt. \" For some lawmakers, though, the real question is whether Russian interference can be prevented in the future. Officials say they see no evidence that votes have been tampered with, but they can't be sure. Here's NPR's Pam Fessler. PAM FESSLER, BYLINE: Election officials assured voters repeatedly last year that there was no way foreign hackers could manipulate votes. Louisiana Secretary of State Tom Schedler was typical. (SOUNDBITE OF ARCHIVED RECORDING) TOM SCHEDLER: There is no state, in general - no state - voting in cyberspace on the Internet. So how do you hack something in cyberspace when it's not in cyberspace? JEREMY EPSTEIN: Well, it's inaccurate on two levels. FESSLER: Election cybersecurity expert Jeremy Epstein says many states do allow some online voting, usually for members of the military. But more importantly, even if most voting machines aren't connected to the Internet. . . EPSTEIN: They are connected to something that's connected to something that's connected to the Internet. FESSLER: And last week's release of a U. S. intelligence report on Russian hacking only reinforced his concerns. Russia apparently broke into an election software vendor's computer system and used that information to send 122 election officials fake emails infected with malicious software. It's unclear if anyone took the bait, but University of Michigan computer scientist Alex Halderman says it's just the kind of phishing attacks someone would use if they wanted to manipulate votes. ALEX HALDERMAN: That's because before every election, the voting machines have to be programmed with the design of the ballot, right? What are the races? Who are the candidates? FESSLER: And that's done on a computer in a central election office or by a contractor. The ballot program is then installed on individual voting machines using removable memory cards. HALDERMAN: So as a remote attacker, I can target an election management system, one of these ballot programming computers. If I can infect it with malicious software, I can have that malicious software spread to the individual machines on the memory cards and then change votes on Election Day. FESSLER: There's absolutely no evidence that happened last year, but Halderman notes that some or all electronic voting machines in 14 states have no paper ballot backups that can be checked to make sure there was no tampering. State and local election officials insist such an attack would be extremely difficult, if not impossible because of tight security measures such as restrictions on who has access to voting machines. Still, Connecticut election director Peggy Reeves told a panel on voting technology earlier this week that many local election officials are ill-equipped to handle cybersecurity threats. (SOUNDBITE OF ARCHIVED RECORDING) PEGGY REEVES: Many of our towns actually have no local IT support. Seriously, they don't have an IT director in their town. They might have a consultant that they call on if they have an issue. So they look to us, but we're a pretty small division. FESSLER: She says the best protection against hackers is probably the fact that the nation's voting system is so decentralized. Larry Norden, an election technology expert with the Brennan Center, agrees, but he's worried that last year's intruders were laying the groundwork for more serious attacks in the future. LARRY NORDEN: This is a real threat. It's not going away, and if anything, foreign adversaries - even people at home might be emboldened to do this more going forward. And to me, it is a real call that we have to do more as soon as possible, to secure these systems. FESSLER: He would like all voting machines to have paper records and for all states to conduct routine audits to make sure that the electronic results match the paper ones. Pam Fessler, NPR News.", "section": "Politics", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-06-14-532752841": {"title": "Why Hasn't Online Dating Made It Onscreen?  : NPR", "url": "https://www.npr.org/2017/06/14/532752841/why-hasnt-online-dating-made-it-onscreen", "author": "No author found", "published_date": "2017-06-14", "content": "RACHEL MARTIN, HOST: Hollywood movies love technology. (SOUNDBITE OF FILM)UNIDENTIFIED ACTOR #1: (As character) OK, satellite imagery coming through. UNIDENTIFIED ACTOR #2: (As character) Roger that. . . MARTIN: Spy movies, science fiction movies, horror movies - they've all been playing on our collective unease with technology for a long time. (SOUNDBITE OF FILM, \"RINGS\")ALEX ROE: (As Holt) There's this video. . . MARTIN: And they're not particularly subtle about this. (SOUNDBITE OF FILM, \"RINGS\")ROE: (As Holt) It kills you seven days after you watch it. MARTIN: Videos that kill you, cellphones that kill you, Skype that kills you - Hollywood turns out tons of movies where everyday technology leads to terrifying death. NPR's Glen Weldon reports that filmmakers are still struggling with how to bring everyday tech into romantic comedies. GLEN WELDON, BYLINE: It's been a long time since we've gotten a movie that dealt realistically with online dating - like, a really long time. . . (SOUNDBITE OF FILM, \"YOU'VE GOT MAIL\")MEG RYAN: (As Kathleen Kelly) I turn on my computer. WELDON: . . . 1998. (SOUNDBITE OF FILM, \"YOU'VE GOT MAIL\")RYAN: (As Kathleen Kelly) I go online. AUTOMATED VOICE #1: Welcome. TOM HANKS: (As Joe Fox) Welcome. RYAN: (As Kathleen Kelly) And my breath catches in my chest until I hear three little words - you've got mail. WELDON: That was almost two decades ago. And according to a study from the University of Chicago in 2013, over one-third of marriages now begin online. So why aren't today's romantic comedies reflecting that fact? Christine Vachon, whose company, Killer Films, produced movies like \"Carol\" and \"Still Alice,\" says the answer is how it looks on screen. CHRISTINE VACHON: Watching two people meet in a visually clever way - it's a lot more interesting than people swiping right or left. WELDON: She's got a point. So does that mean it'll never happen? You just can't make movies where people meet online. VACHON: I think you can. I just don't think we have yet. I think you can make anything cinematically compelling. I just think that there's some sort of visual language that we haven't quite cracked yet. WELDON: OK, so let's say some future screenwriter figures out how to crack that language. Comedian Guy Branum says they'd still have to get the script studio executives, which won't be easy. GUY BRANUM: People who are greenlighting romantic comedies are still men in their 50s who have not integrated social media or dating apps in any way and never had to integrate them into their lives because they didn't exist. They all got married in 1986 and then, you know, were rich enough that they didn't need help finding a second wife in 1999. WELDON: Branum writes for Hulu's \"The Mindy Project,\" which, like a lot of TV shows, features characters texting and clicking and swiping all the time. But he's not surprised that film studios are still reluctant to show people using tech in realistic ways. BRANUM: A big problem is that we no longer make movies that reflect reality. The movies we are good at making involve talking cars that transform into robots or something smashing into the earth or people going into space. We have, to some extent, forgotten how to make movies about people. WELDON: Producer Christine Vachon is a bit more hopeful. VACHON: The movie business is always very afraid of what it doesn't - what it doesn't completely understand. WELDON: She thinks Hollywood just needs time to catch up. VACHON: Our cinematic language, it seems to me, always shifts and adjusts to the times that we're in. WELDON: That shift may have already started, but to see it, you have to look beyond the rom-com. Weirdly enough, it's science fiction that's exploring the space where romance and technology come together in films like 2013's \"Her. \"(SOUNDBITE OF FILM, \"HER\")AUTOMATED VOICE #2: Please wait as your individualized operating system is initiated. WELDON: Joaquin Phoenix plays a lonely guy who installs an artificial intelligence - voiced by Scarlett Johansson - onto his computer, then falls in love with it. No, it's not match. com, but it's probably as close as Hollywood's going to get for now. (SOUNDBITE OF FILM, \"HER\")SCARLETT JOHANSSON: (As Samantha) Hello, I'm here. WELDON: Glen Weldon, NPR News. RACHEL MARTIN, HOST:  Hollywood movies love technology. (SOUNDBITE OF FILM) UNIDENTIFIED ACTOR #1: (As character) OK, satellite imagery coming through. UNIDENTIFIED ACTOR #2: (As character) Roger that. . . MARTIN: Spy movies, science fiction movies, horror movies - they've all been playing on our collective unease with technology for a long time. (SOUNDBITE OF FILM, \"RINGS\") ALEX ROE: (As Holt) There's this video. . . MARTIN: And they're not particularly subtle about this. (SOUNDBITE OF FILM, \"RINGS\") ROE: (As Holt) It kills you seven days after you watch it. MARTIN: Videos that kill you, cellphones that kill you, Skype that kills you - Hollywood turns out tons of movies where everyday technology leads to terrifying death. NPR's Glen Weldon reports that filmmakers are still struggling with how to bring everyday tech into romantic comedies. GLEN WELDON, BYLINE: It's been a long time since we've gotten a movie that dealt realistically with online dating - like, a really long time. . . (SOUNDBITE OF FILM, \"YOU'VE GOT MAIL\") MEG RYAN: (As Kathleen Kelly) I turn on my computer. WELDON: . . . 1998. (SOUNDBITE OF FILM, \"YOU'VE GOT MAIL\") RYAN: (As Kathleen Kelly) I go online. AUTOMATED VOICE #1: Welcome. TOM HANKS: (As Joe Fox) Welcome. RYAN: (As Kathleen Kelly) And my breath catches in my chest until I hear three little words - you've got mail. WELDON: That was almost two decades ago. And according to a study from the University of Chicago in 2013, over one-third of marriages now begin online. So why aren't today's romantic comedies reflecting that fact? Christine Vachon, whose company, Killer Films, produced movies like \"Carol\" and \"Still Alice,\" says the answer is how it looks on screen. CHRISTINE VACHON: Watching two people meet in a visually clever way - it's a lot more interesting than people swiping right or left. WELDON: She's got a point. So does that mean it'll never happen? You just can't make movies where people meet online. VACHON: I think you can. I just don't think we have yet. I think you can make anything cinematically compelling. I just think that there's some sort of visual language that we haven't quite cracked yet. WELDON: OK, so let's say some future screenwriter figures out how to crack that language. Comedian Guy Branum says they'd still have to get the script studio executives, which won't be easy. GUY BRANUM: People who are greenlighting romantic comedies are still men in their 50s who have not integrated social media or dating apps in any way and never had to integrate them into their lives because they didn't exist. They all got married in 1986 and then, you know, were rich enough that they didn't need help finding a second wife in 1999. WELDON: Branum writes for Hulu's \"The Mindy Project,\" which, like a lot of TV shows, features characters texting and clicking and swiping all the time. But he's not surprised that film studios are still reluctant to show people using tech in realistic ways. BRANUM: A big problem is that we no longer make movies that reflect reality. The movies we are good at making involve talking cars that transform into robots or something smashing into the earth or people going into space. We have, to some extent, forgotten how to make movies about people. WELDON: Producer Christine Vachon is a bit more hopeful. VACHON: The movie business is always very afraid of what it doesn't - what it doesn't completely understand. WELDON: She thinks Hollywood just needs time to catch up. VACHON: Our cinematic language, it seems to me, always shifts and adjusts to the times that we're in. WELDON: That shift may have already started, but to see it, you have to look beyond the rom-com. Weirdly enough, it's science fiction that's exploring the space where romance and technology come together in films like 2013's \"Her. \" (SOUNDBITE OF FILM, \"HER\") AUTOMATED VOICE #2: Please wait as your individualized operating system is initiated. WELDON: Joaquin Phoenix plays a lonely guy who installs an artificial intelligence - voiced by Scarlett Johansson - onto his computer, then falls in love with it. No, it's not match. com, but it's probably as close as Hollywood's going to get for now. (SOUNDBITE OF FILM, \"HER\") SCARLETT JOHANSSON: (As Samantha) Hello, I'm here. WELDON: Glen Weldon, NPR News.", "section": "Pop Culture Happy Hour", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-06-19-533551243": {"title": "RNC-Contracted Firm, Deep Root, Left Millions Of Voter Files Unsecured Online : NPR", "url": "https://www.npr.org/2017/06/19/533551243/firm-contracted-by-rnc-left-millions-of-voter-files-unsecured-online", "author": "No author found", "published_date": "2017-06-19", "content": "", "section": "Politics", "disclaimer": ""}, "2017-06-20-533637643": {"title": "Despite NSA Claim, Elections Vendor Denies System Was Compromised In Hack Attempt : NPR", "url": "https://www.npr.org/2017/06/20/533637643/despite-nsa-claim-election-vendor-denies-system-was-compromised-in-hack-attempt", "author": "No author found", "published_date": "2017-06-20", "content": "", "section": "Politics", "disclaimer": ""}, "2017-06-21-533666328": {"title": "Jeh Johnson, Former Homeland Security Chief Under Obama, Testified On Capitol Hill Wednesday : NPR", "url": "https://www.npr.org/2017/06/21/533666328/u-s-elections-systems-vulnerable-lawmakers-told-in-dueling-hearings", "author": "No author found", "published_date": "2017-06-21", "content": "", "section": "National Security", "disclaimer": ""}, "2017-06-24-534207526": {"title": "Drone Company Leaders Meet With Trump To Ask For More Clarity On Rules : NPR", "url": "https://www.npr.org/2017/06/24/534207526/drone-company-leaders-meet-with-trump-to-ask-for-more-clarity-on-rules", "author": "No author found", "published_date": "2017-06-24", "content": "MELISSA BLOCK, HOST: Leaders of the drone industry got an audience at the White House this week. The drone executives met with President Trump to push for more clarity on rules governing their unmanned aerial vehicles. To talk about what happened and explain big issues in the growing drone industry, we're joined now by April Glaser. She writes about drones, robots and artificial intelligence for the tech news website, Recode. April, welcome. APRIL GLASER: Thanks so much for having me. BLOCK: And let's start with the players who were at this meeting. What do their companies do exactly? GLASER: So these are drone services companies, largely. One of the companies is Kespry. They work on drones. They actually build drones. But they also work on providing drone services for construction companies and mining companies to help measure stockpiles and aggregates and things like that. Another company that was there is PrecisionHawk. And PrecisionHawk makes software that analyzes data that's captured from drones for things like crop analysis and agriculture pipeline inspections. Airspace was another company that was there. And they actually make technology that tracks and takes down rogue drones that are flying over places that they're not supposed to like sports stadiums or jails. BLOCK: And if you are one of these commercial drone companies, not a hobbyist, but one of these big companies, what is it that you want from the Trump administration? GLASER: Well, you know, this meeting was called at a time of regulatory uncertainty for the drone industry, right? So with drones, unlike other industries that might want to do away with government regulations that companies perceive as burdensome, the drone industry actually needs more regulations in order to grow. And that's because while it's legal to fly drones in the U. S. , a lot of the commercial activity that's - or the potential commercial activity like delivering packages or inspecting hard-to-reach infrastructure kind of without an operator present is still not legal. And that's because the Federal Aviation Administration is still crafting those rules that would allow drones to fly in certain ways. So, like, right now it's not legal to fly beyond the line of sight of an operator. But, you know, in order for a drone delivery to happen, drones will have to be able to fly beyond the line of sight of the operator. That's the whole point of drone deliveries - that a person isn't there. BLOCK: If you're a big U. S. investor looking at the drone industry, what are you thinking right now? GLASER: Well, you're thinking that if you don't know what the rules are, then you're not going to have a lot of confidence to invest - right? - because if you don't know whether or not it's going to be legal, say, for a drone company that wants to do delivery to actually do that anytime soon, then why would you invest in that? And so it's really important for the U. S. to iron out these rules now so the money and the investment and a lot of the innovation stays in the country and doesn't actually decamp abroad. BLOCK: And I suppose the flipside of that, the counter-argument would be there are lots of concerns about privacy, for one, but also safety for commercial aircraft, for airplanes. GLASER: Right. And it's not like the FAA can just kind of like press a button here and just create new laws. First, there needs to be some kind of low altitude air traffic control system for drones - right? - that allows them to safely integrate into U. S. airspace because, you know, unlike an airplane that takes off and lands from the same place every time, drones take off and land, you know, from your front door or from the store that they are getting the goods from potentially. So until that is kind of ironed out, we're not going to see drone delivery, really, at scale in the United States. BLOCK: There is, in this country, an existing registry for drones, right? How many drones are registered? GLASER: Well, as far as we know, there are 820,000 people who are registered to fly drones in the United States. But as of last month, the federal court actually nixed the requirement for people who are flying for fun, people who are hobbyists to register their drone. So if you're a commercial operator, yes, you still have to register with the FAA. But if you're just flying for fun, if you're just trying to take pictures of your family or of your cool hiking trip, then, no, you don't have to register your drone with the FAA anymore. That said, this 820,000 number is significant because the FAA only opened its drone registry at the end of 2015. So it hasn't been that much time, and we have hundreds of thousands of drones in the air. BLOCK: That's April Glaser. She covers the drone industry among others for the tech news website, Recode. April, thanks so much. GLASER: Thank you. MELISSA BLOCK, HOST:  Leaders of the drone industry got an audience at the White House this week. The drone executives met with President Trump to push for more clarity on rules governing their unmanned aerial vehicles. To talk about what happened and explain big issues in the growing drone industry, we're joined now by April Glaser. She writes about drones, robots and artificial intelligence for the tech news website, Recode. April, welcome. APRIL GLASER: Thanks so much for having me. BLOCK: And let's start with the players who were at this meeting. What do their companies do exactly? GLASER: So these are drone services companies, largely. One of the companies is Kespry. They work on drones. They actually build drones. But they also work on providing drone services for construction companies and mining companies to help measure stockpiles and aggregates and things like that. Another company that was there is PrecisionHawk. And PrecisionHawk makes software that analyzes data that's captured from drones for things like crop analysis and agriculture pipeline inspections. Airspace was another company that was there. And they actually make technology that tracks and takes down rogue drones that are flying over places that they're not supposed to like sports stadiums or jails. BLOCK: And if you are one of these commercial drone companies, not a hobbyist, but one of these big companies, what is it that you want from the Trump administration? GLASER: Well, you know, this meeting was called at a time of regulatory uncertainty for the drone industry, right? So with drones, unlike other industries that might want to do away with government regulations that companies perceive as burdensome, the drone industry actually needs more regulations in order to grow. And that's because while it's legal to fly drones in the U. S. , a lot of the commercial activity that's - or the potential commercial activity like delivering packages or inspecting hard-to-reach infrastructure kind of without an operator present is still not legal. And that's because the Federal Aviation Administration is still crafting those rules that would allow drones to fly in certain ways. So, like, right now it's not legal to fly beyond the line of sight of an operator. But, you know, in order for a drone delivery to happen, drones will have to be able to fly beyond the line of sight of the operator. That's the whole point of drone deliveries - that a person isn't there. BLOCK: If you're a big U. S. investor looking at the drone industry, what are you thinking right now? GLASER: Well, you're thinking that if you don't know what the rules are, then you're not going to have a lot of confidence to invest - right? - because if you don't know whether or not it's going to be legal, say, for a drone company that wants to do delivery to actually do that anytime soon, then why would you invest in that? And so it's really important for the U. S. to iron out these rules now so the money and the investment and a lot of the innovation stays in the country and doesn't actually decamp abroad. BLOCK: And I suppose the flipside of that, the counter-argument would be there are lots of concerns about privacy, for one, but also safety for commercial aircraft, for airplanes. GLASER: Right. And it's not like the FAA can just kind of like press a button here and just create new laws. First, there needs to be some kind of low altitude air traffic control system for drones - right? - that allows them to safely integrate into U. S. airspace because, you know, unlike an airplane that takes off and lands from the same place every time, drones take off and land, you know, from your front door or from the store that they are getting the goods from potentially. So until that is kind of ironed out, we're not going to see drone delivery, really, at scale in the United States. BLOCK: There is, in this country, an existing registry for drones, right? How many drones are registered? GLASER: Well, as far as we know, there are 820,000 people who are registered to fly drones in the United States. But as of last month, the federal court actually nixed the requirement for people who are flying for fun, people who are hobbyists to register their drone. So if you're a commercial operator, yes, you still have to register with the FAA. But if you're just flying for fun, if you're just trying to take pictures of your family or of your cool hiking trip, then, no, you don't have to register your drone with the FAA anymore. That said, this 820,000 number is significant because the FAA only opened its drone registry at the end of 2015. So it hasn't been that much time, and we have hundreds of thousands of drones in the air. BLOCK: That's April Glaser. She covers the drone industry among others for the tech news website, Recode. April, thanks so much. GLASER: Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-06-27-534537556": {"title": "Google Fined Record $2.7 Billion In EU Anti-Trust Ruling : NPR", "url": "https://www.npr.org/2017/06/27/534537556/google-fined-record-2-7-billion-in-eu-anti-trust-ruling", "author": "No author found", "published_date": "2017-06-27", "content": "DAVID GREENE, HOST: And we're following a pretty stunning legal judgment from Brussels this morning. The European Union has fined Google 2. 4 billion euros - that's about $2. 7 billion - for breaking anti-trust rules. The European Commission, which polices EU competition rules, says Google unfairly abused its power over search results by promoting its results over competitors. Let's bring in NPR tech reporter Aarti Shahani. Aarti, what happened here? AARTI SHAHANI, BYLINE: Well, Europe is using its legal system to fight back against the American search giant. The gist of it is this. When you use Google to shop for a product - right? - say I want to buy shoes or a barbecue grill, you get different results back listing the places that you can buy from, right? GREENE: Sure. SHAHANI: Well, according to the European Commission, Google is abusing its market dominance as the lead search engine by promoting its own comparison shopping services in the results and demoting competitors' shopping services. So after a seven-year-long investigation, they're hitting the company - which, by the way, is renamed legally Alphabet, right? They're hitting. . . GREENE: Oh right. The holding company was renamed that, yeah. SHAHANI: Exactly. Google to Alphabet. They're hitting them with this enormous fine. And it's reportedly the biggest fine the EU has ever given a single company in an antitrust case. Google/Alphabet has about - has 90 days to fix the problem or they get fined more. GREENE: OK, so they're being accused of promoting their own shopping services, where if I would buy something, they would actually benefit somehow as opposed to competitors. Is Google/Alphabet acknowledging that they're doing this? SHAHANI: No, the company's flat-out denying the claim and has basically been saying, you know, hey, our secret algorithms do not give unfair preferential treatment to us. They're designed to give consumers, who are searching for shoes and barbecue grills, the best possible experience, right? So that's why Google shows ads with pictures and ratings and prices from different competitors - because people want that kind of thing. People want to just search once and not have to click and click to get to their product. That's their stance. Google's lawyer in Europe says in a statement today that the search engine only shows these ad results when people's search habits show it's working, that they're clicking and they like it. And in terms of helping competition, he says that by the way, you know, European businesses are using our Google ads to compete with other American giants, like Amazon and like eBay. GREENE: I mean, this seems like such a surprise. I wonder if, you know, how the European approach to this sort of thing compares to regulators in the United States. SHAHANI: Oh well, it's a night-and-day difference approach. You know, in the U. S. , we had an antitrust investigation into Google years ago. Competitors like Microsoft, like Yelp, they were jumping up and down saying, hey, Google's cheating here. But then the Federal Trade Commission came around and looked into it and said while they found some evidence, they decided to drop the case. That was in 2013. GREENE: All right. NPR's Aarti Shahani. Thanks so much. SHAHANI: Thank you. DAVID GREENE, HOST:  And we're following a pretty stunning legal judgment from Brussels this morning. The European Union has fined Google 2. 4 billion euros - that's about $2. 7 billion - for breaking anti-trust rules. The European Commission, which polices EU competition rules, says Google unfairly abused its power over search results by promoting its results over competitors. Let's bring in NPR tech reporter Aarti Shahani. Aarti, what happened here? AARTI SHAHANI, BYLINE: Well, Europe is using its legal system to fight back against the American search giant. The gist of it is this. When you use Google to shop for a product - right? - say I want to buy shoes or a barbecue grill, you get different results back listing the places that you can buy from, right? GREENE: Sure. SHAHANI: Well, according to the European Commission, Google is abusing its market dominance as the lead search engine by promoting its own comparison shopping services in the results and demoting competitors' shopping services. So after a seven-year-long investigation, they're hitting the company - which, by the way, is renamed legally Alphabet, right? They're hitting. . . GREENE: Oh right. The holding company was renamed that, yeah. SHAHANI: Exactly. Google to Alphabet. They're hitting them with this enormous fine. And it's reportedly the biggest fine the EU has ever given a single company in an antitrust case. Google/Alphabet has about - has 90 days to fix the problem or they get fined more. GREENE: OK, so they're being accused of promoting their own shopping services, where if I would buy something, they would actually benefit somehow as opposed to competitors. Is Google/Alphabet acknowledging that they're doing this? SHAHANI: No, the company's flat-out denying the claim and has basically been saying, you know, hey, our secret algorithms do not give unfair preferential treatment to us. They're designed to give consumers, who are searching for shoes and barbecue grills, the best possible experience, right? So that's why Google shows ads with pictures and ratings and prices from different competitors - because people want that kind of thing. People want to just search once and not have to click and click to get to their product. That's their stance. Google's lawyer in Europe says in a statement today that the search engine only shows these ad results when people's search habits show it's working, that they're clicking and they like it. And in terms of helping competition, he says that by the way, you know, European businesses are using our Google ads to compete with other American giants, like Amazon and like eBay. GREENE: I mean, this seems like such a surprise. I wonder if, you know, how the European approach to this sort of thing compares to regulators in the United States. SHAHANI: Oh well, it's a night-and-day difference approach. You know, in the U. S. , we had an antitrust investigation into Google years ago. Competitors like Microsoft, like Yelp, they were jumping up and down saying, hey, Google's cheating here. But then the Federal Trade Commission came around and looked into it and said while they found some evidence, they decided to drop the case. That was in 2013. GREENE: All right. NPR's Aarti Shahani. Thanks so much. SHAHANI: Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-06-28-534671413": {"title": "New Ransomware Attack Spreads From Ukraine : NPR", "url": "https://www.npr.org/2017/06/28/534671413/new-ransomware-attack-spreads-from-ukraine", "author": "No author found", "published_date": "2017-06-28", "content": "RACHEL MARTIN, HOST: A massive cyberattack is still taking a toll on computer systems around the world. It all started yesterday in Russia and Ukraine and then spread around Europe and on to the U. S. A number of major international corporations were hit, including the U. S. pharmaceutical-maker Merck, the Russian state oil company Rosneft and the shipping giant Maersk, which caused the Port of New York to shut down as well as ports in Rotterdam and Mumbai. With us now is Matt Tait. He's a security expert based in London and the CEO of Capital Alpha Security. He's with us on Skype. Hey, Matt. MATT TAIT: Hey, how you doing? MARTIN: Doing well. What do we know about who's responsible for this? TAIT: So at the moment, we don't know who's responsible for it. We know how the attack has been taking place. Essentially, a Ukrainian firm that builds accountancy software was compromised yesterday, and they started distributing malware through their auto update software-delivery mechanism. And this caused lots and lots of companies that were dependent on this software to become infected with ransomware, which very rapidly spread around internal networks, compromising entire international firms, destroying large numbers of computers within these companies. MARTIN: So this is similar to what we saw just last month - right? - the WannaCry virus this was called. This was another ransomware assault. I mean, are there lessons that are being learned every time one of these happens? I mean, are you susceptible every single time a new one comes about? TAIT: So yeah, there's a lot of similarities between this particular attack and the one that happened a few weeks ago. Certainly, this idea of ransomware that's self-spreading, that's able to, you know, compromise computers next to each other in order to attack entire corporate networks - this is something that is - seems to be more prevalent now. It's really, really problematic. The way that it spread last time was only using a vulnerability that had already been patched by Microsoft. This particular one is more dangerous because it was using this software distribution mechanism by this Ukrainian firm, which meant that people really had less opportunity to protect themselves in this instance than they did in the previous one. MARTIN: And so it's really insidious. It's the victim that's doing the spreading and making it even worse. Do these things actually get ransoms? I mean, ransomware attacks have increased, I understand, by 50 percent, and that was in 2016. So they must be working. TAIT: So we certainly - because the payments in this case are being made using the anonymous payment mechanism Bitcoin, we're actually able to track how many of these payments have taken place. And in this particular case, we see that there's being about $9,000 or so of ransoms that have been paid. Unfortunately, for many of the people. . . MARTIN: That's not very much. TAIT: It's not very much. But also, unfortunately, for a lot of the people that have paid it, there's no guarantee that they're going to get their files back anyway. The email address for contacting the ransomware developers has long since been disabled. So a lot of these people will have paid their $300, and they're not going to get their files back anyway. MARTIN: Obviously, this is something that governments around the world are focused on. But when it comes to U. S. corporations, business systems, government systems, is the U. S. well-prepared to deal with threats like this? TAIT: So there's a lot of problems at the moment, I think in particular with this software delivery mechanism. I think, really, we're going to have to take a look at software-delivery mechanisms and auto updates to see whether or not we can make those more secure because that was definitely the proximate problem with this particular attack. MARTIN: Matt Tait is founder and CEO of Capital Alpha Security. He joined us on Skype from London. Thanks so much. TAIT: Thanks so much. RACHEL MARTIN, HOST:  A massive cyberattack is still taking a toll on computer systems around the world. It all started yesterday in Russia and Ukraine and then spread around Europe and on to the U. S. A number of major international corporations were hit, including the U. S. pharmaceutical-maker Merck, the Russian state oil company Rosneft and the shipping giant Maersk, which caused the Port of New York to shut down as well as ports in Rotterdam and Mumbai. With us now is Matt Tait. He's a security expert based in London and the CEO of Capital Alpha Security. He's with us on Skype. Hey, Matt. MATT TAIT: Hey, how you doing? MARTIN: Doing well. What do we know about who's responsible for this? TAIT: So at the moment, we don't know who's responsible for it. We know how the attack has been taking place. Essentially, a Ukrainian firm that builds accountancy software was compromised yesterday, and they started distributing malware through their auto update software-delivery mechanism. And this caused lots and lots of companies that were dependent on this software to become infected with ransomware, which very rapidly spread around internal networks, compromising entire international firms, destroying large numbers of computers within these companies. MARTIN: So this is similar to what we saw just last month - right? - the WannaCry virus this was called. This was another ransomware assault. I mean, are there lessons that are being learned every time one of these happens? I mean, are you susceptible every single time a new one comes about? TAIT: So yeah, there's a lot of similarities between this particular attack and the one that happened a few weeks ago. Certainly, this idea of ransomware that's self-spreading, that's able to, you know, compromise computers next to each other in order to attack entire corporate networks - this is something that is - seems to be more prevalent now. It's really, really problematic. The way that it spread last time was only using a vulnerability that had already been patched by Microsoft. This particular one is more dangerous because it was using this software distribution mechanism by this Ukrainian firm, which meant that people really had less opportunity to protect themselves in this instance than they did in the previous one. MARTIN: And so it's really insidious. It's the victim that's doing the spreading and making it even worse. Do these things actually get ransoms? I mean, ransomware attacks have increased, I understand, by 50 percent, and that was in 2016. So they must be working. TAIT: So we certainly - because the payments in this case are being made using the anonymous payment mechanism Bitcoin, we're actually able to track how many of these payments have taken place. And in this particular case, we see that there's being about $9,000 or so of ransoms that have been paid. Unfortunately, for many of the people. . . MARTIN: That's not very much. TAIT: It's not very much. But also, unfortunately, for a lot of the people that have paid it, there's no guarantee that they're going to get their files back anyway. The email address for contacting the ransomware developers has long since been disabled. So a lot of these people will have paid their $300, and they're not going to get their files back anyway. MARTIN: Obviously, this is something that governments around the world are focused on. But when it comes to U. S. corporations, business systems, government systems, is the U. S. well-prepared to deal with threats like this? TAIT: So there's a lot of problems at the moment, I think in particular with this software delivery mechanism. I think, really, we're going to have to take a look at software-delivery mechanisms and auto updates to see whether or not we can make those more secure because that was definitely the proximate problem with this particular attack. MARTIN: Matt Tait is founder and CEO of Capital Alpha Security. He joined us on Skype from London. Thanks so much. TAIT: Thanks so much.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-07-03-535408578": {"title": "In Reno, Nev., Homegrown Startups Fuel Tech Transformation : NPR", "url": "https://www.npr.org/2017/07/03/535408578/in-reno-nev-homegrown-startups-fuel-tech-transformation", "author": "No author found", "published_date": "2017-07-03", "content": "ARI SHAPIRO, HOST: The tech industry is reshaping cities far from traditional hubs like Silicon Valley and Seattle. Today in All Tech Considered - how tech companies choose a home base and what happens to cities when the industry moves in. (SOUNDBITE OF MUSIC)SHAPIRO: First we go to Reno, Nev. It's been enjoying a tech boom for a few years. Apple and Google are building data centers there. Tesla has an aptly named Gigafactory. As NPR's Arun Rath found, homegrown startups are helping to drive Reno's tech transformation. ARUN RATH, BYLINE: Capstak is a tech startup that until recently had operations spread across San Francisco, New York, Tel Aviv and Reno. They needed to consolidate. UNIDENTIFIED MAN: Good. How are you? RATH: Capstak went with Reno, moving into this space called the Innevation Center, a home for startups sponsored by the University of Nevada, Reno. Michael Schnabel is Capstak's CEO. MICHAEL SCHNABEL: The university embraced us with this facility, and it just made a lot of sense for us to say OK, no, we're not going to be in New York. We're not going to be in San Francisco. We're going to be here. RATH: It's not just about lower rent and taxes than New York and California. The university provides human capital, students like computer science major Alex Sanchez who had been intending to move after graduating. ALEX SANCHEZ: Ultimately I decided that OK, I'm going to graduate, then I'm probably going to relocate to either California, Washington, Seattle or Denver in one of the big tech hubs where just the tech scene is just bursting. RATH: Sanchez is now interning with Capstak. His boss, Schnabel, says Reno's offerings are starting to compete with what those other tech hubs can offer. SCHNABEL: You're seeing a lot of similarities in the energy, the number of startups, availability of capital, and all of those things are important for a successful startup culture. RATH: The growth of the local startup culture here is no accident. The Economic Development Authority at Western Nevada has been working to encourage entrepreneurship since the crash. Bryan McArdle is with the authority. BRYAN MCARDLE: We were so beaten down by the recession, and we didn't have a highly diversified economy. So it really was just construction, gaming, mining. And something happened where there was a resurgence of pride. RATH: The authority established the Reno Collective, another home for new startups to work, collaborate and meet with clients. McArdle says it's had to expand several times and just took over a massive former recording studio downtown. MCARDLE: And it sort of changed the dynamic that now we have people working downtown, which predominately was just casino workers. Now we have actual tech people working down there. MONICA DUPEA: We have a major housing crisis and shortage in Reno right now. And we're building like crazy, but we can't build as fast as people are moving in. RATH: Monica DuPea is the executive director of the Nevada Youth Empowerment Project. She worries about how the young people who aren't getting internships at tech startups can afford to live here. DUPEA: The majority of our young people are, you know, not entering college, are not gaining the skill and the knowledge that would help place them at these great companies. RATH: At the same time, for those who do have the education and ability, these companies can make the difference between staying in Reno or leaving for good. Alex Sanchez, the UNR student who's interning with Capstak, already has a full-time job lined up with the company after he graduates. SANCHEZ: The original plan was to move out because I couldn't find many job opportunities, but now it looks like Reno is pulling me into staying because of all the tech companies that are - come in. RATH: A lot of the local entrepreneurs say that for the longest time, going back through several boom and bust cycles, there was a feeling that if you wanted to do something with your education, you had to leave town. For young people like Alex Sanchez, there's now a feeling that you don't have to move away to move up. Arun Rath, NPR News. ARI SHAPIRO, HOST:  The tech industry is reshaping cities far from traditional hubs like Silicon Valley and Seattle. Today in All Tech Considered - how tech companies choose a home base and what happens to cities when the industry moves in. (SOUNDBITE OF MUSIC) SHAPIRO: First we go to Reno, Nev. It's been enjoying a tech boom for a few years. Apple and Google are building data centers there. Tesla has an aptly named Gigafactory. As NPR's Arun Rath found, homegrown startups are helping to drive Reno's tech transformation. ARUN RATH, BYLINE: Capstak is a tech startup that until recently had operations spread across San Francisco, New York, Tel Aviv and Reno. They needed to consolidate. UNIDENTIFIED MAN: Good. How are you? RATH: Capstak went with Reno, moving into this space called the Innevation Center, a home for startups sponsored by the University of Nevada, Reno. Michael Schnabel is Capstak's CEO. MICHAEL SCHNABEL: The university embraced us with this facility, and it just made a lot of sense for us to say OK, no, we're not going to be in New York. We're not going to be in San Francisco. We're going to be here. RATH: It's not just about lower rent and taxes than New York and California. The university provides human capital, students like computer science major Alex Sanchez who had been intending to move after graduating. ALEX SANCHEZ: Ultimately I decided that OK, I'm going to graduate, then I'm probably going to relocate to either California, Washington, Seattle or Denver in one of the big tech hubs where just the tech scene is just bursting. RATH: Sanchez is now interning with Capstak. His boss, Schnabel, says Reno's offerings are starting to compete with what those other tech hubs can offer. SCHNABEL: You're seeing a lot of similarities in the energy, the number of startups, availability of capital, and all of those things are important for a successful startup culture. RATH: The growth of the local startup culture here is no accident. The Economic Development Authority at Western Nevada has been working to encourage entrepreneurship since the crash. Bryan McArdle is with the authority. BRYAN MCARDLE: We were so beaten down by the recession, and we didn't have a highly diversified economy. So it really was just construction, gaming, mining. And something happened where there was a resurgence of pride. RATH: The authority established the Reno Collective, another home for new startups to work, collaborate and meet with clients. McArdle says it's had to expand several times and just took over a massive former recording studio downtown. MCARDLE: And it sort of changed the dynamic that now we have people working downtown, which predominately was just casino workers. Now we have actual tech people working down there. MONICA DUPEA: We have a major housing crisis and shortage in Reno right now. And we're building like crazy, but we can't build as fast as people are moving in. RATH: Monica DuPea is the executive director of the Nevada Youth Empowerment Project. She worries about how the young people who aren't getting internships at tech startups can afford to live here. DUPEA: The majority of our young people are, you know, not entering college, are not gaining the skill and the knowledge that would help place them at these great companies. RATH: At the same time, for those who do have the education and ability, these companies can make the difference between staying in Reno or leaving for good. Alex Sanchez, the UNR student who's interning with Capstak, already has a full-time job lined up with the company after he graduates. SANCHEZ: The original plan was to move out because I couldn't find many job opportunities, but now it looks like Reno is pulling me into staying because of all the tech companies that are - come in. RATH: A lot of the local entrepreneurs say that for the longest time, going back through several boom and bust cycles, there was a feeling that if you wanted to do something with your education, you had to leave town. For young people like Alex Sanchez, there's now a feeling that you don't have to move away to move up. Arun Rath, NPR News.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-07-04-535470988": {"title": "Does Trump's Behavior On Twitter Amount To Cyberbullying? : NPR", "url": "https://www.npr.org/2017/07/04/535470988/does-trumps-behavior-on-twitter-amount-to-cyberbullying", "author": "No author found", "published_date": "2017-07-04", "content": "MARY LOUISE KELLY, HOST:  Let's take a moment to try to square two facts. Here's one. First, Lady Melania Trump says she wants to focus on cyberbullying. She says we have to find better ways to talk to and respect each other online. Here's another fact. Mrs. Trump's husband has in the last week called two MSNBC anchors low-IQ, crazy and psycho on Twitter. Then he followed up by tweeting a video of himself body-slamming someone with a CNN logo superimposed over his head. All of this got us wondering - does the president's behavior amount to cyberbullying? And if so, what does that mean for the first lady's potential initiative to fight cyberbullying? We're joined now by Parry Aftab. She's a lawyer who leads the Internet safety group WiredSafety. Parry Aftab, thanks for speaking to us. PARRY AFTAB: Well, I appreciate you asking. KELLY: Does the president's behavior on Twitter amount to cyberbullying? AFTAB: No. Cyberbullying as we define it is minor to minor. KELLY: You mean underage children. OK. AFTAB: Yeah, so minors to minors. So if young people harass each other using digital technology it's cyberbullying. When adults get involved we call it cyber harassment. What he's done is appalling. What he's done is immature. But it probably doesn't rise even to the level of cyber harassment. KELLY: And why not? AFTAB: Well, when you look at cyber harassment as a crime it requires repeated behavior or credible threat. KELLY: Twitter's very clear about its policy of no abusive messages and no threats. Does the fact that the president's tweets are being allowed to stand suggest to you that this hasn't crossed a certain line? AFTAB: What he's done clearly does violate the terms of service on Twitter and most other social networks. KELLY: So why do you think it's still up there? AFTAB: Well, Twitter's former CEO was quoted a couple of years ago saying that Twitter, quote, unquote, \"sucks\" at cyberbullying. And they do. It's not just removing those offending posts. It's shutting down accounts. And I think that that kind of thing would have happened if he were someone other than President Trump and other than guaranteeing a lot of eyeballs and views of Twitter. KELLY: We mentioned that Melania Trump has pledged to take up this issue of cyberbullying. Let me let you hear that moment. (SOUNDBITE OF ARCHIVED RECORDING)MELANIA TRUMP: We have to find a better way to talk to each other, to disagree with each other, to respect each other. We must find better ways to honor and support the basic goodness of our children, especially in social media. KELLY: That was Mrs. Trump speaking last fall. We reached out to her spokesperson about this, and the update is that the first lady is still being thoughtful about her platform and will maybe be announcing something in the coming weeks. You don't think the president's behavior does amount to cyberbullying. But given the way that he uses Twitter, how does that complicate the first lady's potential initiative on this front? AFTAB: Cyberbullying is a very, very serious issue. It's been tied to a number of suicides, many, many issues of self-harm, cutting, eating disorders. And it's commendable that anyone, first lady or anyone else, would want to tackle it. I don't mind taking President Trump on for what he's doing. But I don't want her attacked because she's married to somebody who's acting online inappropriately. I don't think that the first lady can control him any more than the Republicans can. KELLY: Parry Aftab. She leads the Internet safety group WiredSafety, which runs a program, Stop Cyberbullying. Parry Aftab, thank you. AFTAB: Thank you very much. MARY LOUISE KELLY, HOST:   Let's take a moment to try to square two facts. Here's one. First, Lady Melania Trump says she wants to focus on cyberbullying. She says we have to find better ways to talk to and respect each other online. Here's another fact. Mrs. Trump's husband has in the last week called two MSNBC anchors low-IQ, crazy and psycho on Twitter. Then he followed up by tweeting a video of himself body-slamming someone with a CNN logo superimposed over his head. All of this got us wondering - does the president's behavior amount to cyberbullying? And if so, what does that mean for the first lady's potential initiative to fight cyberbullying? We're joined now by Parry Aftab. She's a lawyer who leads the Internet safety group WiredSafety. Parry Aftab, thanks for speaking to us. PARRY AFTAB: Well, I appreciate you asking. KELLY: Does the president's behavior on Twitter amount to cyberbullying? AFTAB: No. Cyberbullying as we define it is minor to minor. KELLY: You mean underage children. OK. AFTAB: Yeah, so minors to minors. So if young people harass each other using digital technology it's cyberbullying. When adults get involved we call it cyber harassment. What he's done is appalling. What he's done is immature. But it probably doesn't rise even to the level of cyber harassment. KELLY: And why not? AFTAB: Well, when you look at cyber harassment as a crime it requires repeated behavior or credible threat. KELLY: Twitter's very clear about its policy of no abusive messages and no threats. Does the fact that the president's tweets are being allowed to stand suggest to you that this hasn't crossed a certain line? AFTAB: What he's done clearly does violate the terms of service on Twitter and most other social networks. KELLY: So why do you think it's still up there? AFTAB: Well, Twitter's former CEO was quoted a couple of years ago saying that Twitter, quote, unquote, \"sucks\" at cyberbullying. And they do. It's not just removing those offending posts. It's shutting down accounts. And I think that that kind of thing would have happened if he were someone other than President Trump and other than guaranteeing a lot of eyeballs and views of Twitter. KELLY: We mentioned that Melania Trump has pledged to take up this issue of cyberbullying. Let me let you hear that moment. (SOUNDBITE OF ARCHIVED RECORDING) MELANIA TRUMP: We have to find a better way to talk to each other, to disagree with each other, to respect each other. We must find better ways to honor and support the basic goodness of our children, especially in social media. KELLY: That was Mrs. Trump speaking last fall. We reached out to her spokesperson about this, and the update is that the first lady is still being thoughtful about her platform and will maybe be announcing something in the coming weeks. You don't think the president's behavior does amount to cyberbullying. But given the way that he uses Twitter, how does that complicate the first lady's potential initiative on this front? AFTAB: Cyberbullying is a very, very serious issue. It's been tied to a number of suicides, many, many issues of self-harm, cutting, eating disorders. And it's commendable that anyone, first lady or anyone else, would want to tackle it. I don't mind taking President Trump on for what he's doing. But I don't want her attacked because she's married to somebody who's acting online inappropriately. I don't think that the first lady can control him any more than the Republicans can. KELLY: Parry Aftab. She leads the Internet safety group WiredSafety, which runs a program, Stop Cyberbullying. Parry Aftab, thank you. AFTAB: Thank you very much.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-07-04-534431175": {"title": "Xbox Bowling For Seniors? Visit Your Local Library : NPR", "url": "https://www.npr.org/2017/07/04/534431175/xbox-bowling-for-seniors-visit-your-local-library", "author": "No author found", "published_date": "2017-07-04", "content": "KELLY MCEVERS, HOST: There's a place where older people can go to upgrade their computer skills, make art and play games. You're probably thinking senior centers. You could also think the library. NPR's Ina Jaffe covers aging, and she went to Brooklyn for this report. As the population in New York ages, the library system there is finding new ways to serve seniors. INA JAFFE, BYLINE: On a Wednesday morning, the Brooklyn Central Library's lobby cafe is crowded with young mothers and kids in strollers, friends meeting for coffee, singles poring over a book. But upstairs, there's some serious work underway. DAVE JOHNSON: What I'd like you to do, as you tell the story, I want you to also use simile and metaphor. I mean, you might say, yeah, he's a little bit like a porcupine, right? Or. . . JAFFE: That's poet Dave Johnson leading an eight-week workshop in memoir writing. Everyone in the class is at least 50, though most are much older than that. For this day's class, they're supposed to write something about the differences between members of their families. JOHNSON: Of course, you can make it up. Right? People are not going to know the difference. JAFFE: But 77-year-old Laurence James, a retired New York Transit bus mechanic, doesn't make anything up. LAURENCE JAMES: My mother very religious, God-fearing, good provider but distant like Africa. JAFFE: James says he comes to the library a lot. He prefers the mix of people here to the traditional senior center, though he concedes he doesn't go to any senior centers and probably has an unfair image of what they are. JAMES: I have this stereotype in my head because sometimes some centers limit the activities of seniors to, like, bingo, yoga and some things that I'm just not interested in. JAFFE: The memoir class is sponsored by an organization called Lifetime Arts, which develops arts classes for older adults. Contrary to Laurence James' image, Lifetime Arts also works with senior centers, but the organization is best known for their work with more than 80 public libraries in 13 states. Maura O'Malley is the CEO and co-founder. She says that whether the classes are writing or painting or choral singing or salsa dancing, all of them are taught by professional artists and structured to result in a final project or performance. MAURA O'MALLEY: And that's, I think, the exciting thing about this work. It's about rebuilding connections as you age and about finding new ways of living and expressing yourself. It's not about entertainment. JAFFE: Not that there's anything wrong with that. (CROSSTALK)JAFFE: At the Macon branch library in Brooklyn's Bedford-Stuyvesant neighborhood, about a dozen older adults seem pretty darned entertained by bowling. UNIDENTIFIED WOMAN: I need strikes. Come on. JAFFE: Virtual bowling, that is, using Xbox. They face a large screen that shows the alley and pins and go through the moves as if they had a ball. There's a lot of team spirit here. They even have matching bowling shirts. And there are tournaments with teams from other libraries. Seventy-four-year-old Alice Baker has been coming to virtual bowling since it started three years ago, but she's not at the library just for that. ALICE BAKER: I learned to quilt at the library, and now I quilt a lot. They also have exercise. They have classes for kids - brings everybody in. You can bring your family with you. JAFFE: If you question what Xbox bowling has to do with the mission of a library, well, Nick Higgins has heard those questions before. He's the director of outreach for the Brooklyn Public Library system. NICK HIGGINS: I'd say a good library really reflects the needs of their particular community. And so for instance, as some of our patrons are aging, they're starting to exhibit some mobility issues. And they're looking for opportunities other than, you know, movie night - something active and social. And the public library is a perfect space for that to happen. JAFFE: In fact, all of the programs for older adults are growing. The number of older people involved in arts programs is up more than 50 percent since last year. And the number of branch libraries with bowling teams has doubled. UNIDENTIFIED CROWD: (Chanting) Get that spare. Get that spare. JAFFE: Which just goes to show that older people want a chance to write new chapters in their life stories one way or another. (CROSSTALK)JAFFE: Ina Jaffe, NPR News. (SOUNDBITE OF THE POLISH AMBASSADOR'S \"TAKE WINGS\") KELLY MCEVERS, HOST:  There's a place where older people can go to upgrade their computer skills, make art and play games. You're probably thinking senior centers. You could also think the library. NPR's Ina Jaffe covers aging, and she went to Brooklyn for this report. As the population in New York ages, the library system there is finding new ways to serve seniors. INA JAFFE, BYLINE: On a Wednesday morning, the Brooklyn Central Library's lobby cafe is crowded with young mothers and kids in strollers, friends meeting for coffee, singles poring over a book. But upstairs, there's some serious work underway. DAVE JOHNSON: What I'd like you to do, as you tell the story, I want you to also use simile and metaphor. I mean, you might say, yeah, he's a little bit like a porcupine, right? Or. . . JAFFE: That's poet Dave Johnson leading an eight-week workshop in memoir writing. Everyone in the class is at least 50, though most are much older than that. For this day's class, they're supposed to write something about the differences between members of their families. JOHNSON: Of course, you can make it up. Right? People are not going to know the difference. JAFFE: But 77-year-old Laurence James, a retired New York Transit bus mechanic, doesn't make anything up. LAURENCE JAMES: My mother very religious, God-fearing, good provider but distant like Africa. JAFFE: James says he comes to the library a lot. He prefers the mix of people here to the traditional senior center, though he concedes he doesn't go to any senior centers and probably has an unfair image of what they are. JAMES: I have this stereotype in my head because sometimes some centers limit the activities of seniors to, like, bingo, yoga and some things that I'm just not interested in. JAFFE: The memoir class is sponsored by an organization called Lifetime Arts, which develops arts classes for older adults. Contrary to Laurence James' image, Lifetime Arts also works with senior centers, but the organization is best known for their work with more than 80 public libraries in 13 states. Maura O'Malley is the CEO and co-founder. She says that whether the classes are writing or painting or choral singing or salsa dancing, all of them are taught by professional artists and structured to result in a final project or performance. MAURA O'MALLEY: And that's, I think, the exciting thing about this work. It's about rebuilding connections as you age and about finding new ways of living and expressing yourself. It's not about entertainment. JAFFE: Not that there's anything wrong with that. (CROSSTALK) JAFFE: At the Macon branch library in Brooklyn's Bedford-Stuyvesant neighborhood, about a dozen older adults seem pretty darned entertained by bowling. UNIDENTIFIED WOMAN: I need strikes. Come on. JAFFE: Virtual bowling, that is, using Xbox. They face a large screen that shows the alley and pins and go through the moves as if they had a ball. There's a lot of team spirit here. They even have matching bowling shirts. And there are tournaments with teams from other libraries. Seventy-four-year-old Alice Baker has been coming to virtual bowling since it started three years ago, but she's not at the library just for that. ALICE BAKER: I learned to quilt at the library, and now I quilt a lot. They also have exercise. They have classes for kids - brings everybody in. You can bring your family with you. JAFFE: If you question what Xbox bowling has to do with the mission of a library, well, Nick Higgins has heard those questions before. He's the director of outreach for the Brooklyn Public Library system. NICK HIGGINS: I'd say a good library really reflects the needs of their particular community. And so for instance, as some of our patrons are aging, they're starting to exhibit some mobility issues. And they're looking for opportunities other than, you know, movie night - something active and social. And the public library is a perfect space for that to happen. JAFFE: In fact, all of the programs for older adults are growing. The number of older people involved in arts programs is up more than 50 percent since last year. And the number of branch libraries with bowling teams has doubled. UNIDENTIFIED CROWD: (Chanting) Get that spare. Get that spare. JAFFE: Which just goes to show that older people want a chance to write new chapters in their life stories one way or another. (CROSSTALK) JAFFE: Ina Jaffe, NPR News. (SOUNDBITE OF THE POLISH AMBASSADOR'S \"TAKE WINGS\")", "section": "National", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-07-05-534742750": {"title": "Watching Foreign Movies Is Illegal In North Korea, But Some Do It Anyway : NPR", "url": "https://www.npr.org/2017/07/05/534742750/watching-foreign-movies-is-illegal-in-north-korea-but-plenty-do-it-anyway", "author": "No author found", "published_date": "2017-07-05", "content": "MARY LOUISE KELLY, HOST: When North Korea grabs the headlines, it's often because of something like this week's surprise missile test. Rarely do we hear about the lives of ordinary North Koreans. RACHEL MARTIN, HOST: We know the regime has walled itself off from the rest of the world, but our co-host David Greene learned that some North Koreans aren't as isolated as we might think. DAVID GREENE, BYLINE: When Yeonmi Park was a young girl, she went to her uncle's house to watch a movie. This was not the state-run broadcast she was used to, praising the dear leader. No, this movie was illegal. YEONMI PARK: What we do is we cover windows with blankets, And then we turn the volume really, really down so you have to be right next to TV. GREENE: She was watching a pirated copy of \"Titanic. \"PARK: When I saw that movie first time, I was very confused. I never heard my father telling mother that he loved her. And my mother never told me she loved me, either. To me, like, love were the only words allowed to express to Dear Leader. So it was just very odd concept to me. How come a man can die for woman? GREENE: By the time Yeonmi escaped North Korea in 2007, she'd also seen James Bond. She had seen South Korean dramas. She even watched American wrestling matches. PARK: Yes. For a couple of hours, you just forget about how life so hard. I was dreaming about a different planet. GREENE: Now, Yeonmi was getting all of this stuff through this network of smugglers and traders, a really active black market in her city. This is not the North Korea we know. We see the military parades. We see the goose-stepping soldiers, the tanks. We see the latest missile test. We see a hermit kingdom in isolation. But even in today's society, even the most repressive regime can't keep everything out. JAMES PEARSON: The idea that North Korea is an information black hole is just simply not true anymore. GREENE: That's James Pearson. He reports for Reuters in South Korea. And he also co-authored the book \"North Korea Confidential. \" He says more and more North Koreans are getting their hands on illicit media. And don't think for a minute a movie like \"Titanic\" doesn't worry the North Korean regime. Just seeing visible tension, complicated emotions can make North Koreans feel deprived. PEARSON: Things like that can start to change people's thinking. And when you talk to defectors who've left the country, many of them say, yeah, you know, I was looking at foreign media that started to help me question what it is that I hear from the government. You know, perhaps things are better off overseas, even in South Korea and even across the border in China. GREENE: All right, so how is this forbidden content slipping into such a closed-off society? Well, let's step back for a minute to the mid-1990s. It looked like North Korea was going to collapse. There was devastating famine. The government failed to feed its people. (SOUNDBITE OF ARCHIVED BROADCAST)TREVOR ROWE, BYLINE: Floods in North Korea left half a million people destitute and without food. JULIE MCCARTHY, BYLINE: International relief agencies say 2 million children are at risk of starving to death. GREENE: Now, here's the crazy thing. Capitalism helped save North Korea. These makeshift stands started popping up around the country selling goods, most importantly food. PEARSON: During the famine, people said that the ones who turned to capitalism and trading were the ones that survived. And that North Korea, that real economy has essentially been the real economy ever since. GREENE: Yet Pearson says this black market has grown because government officials are benefiting. State salaries are almost nothing, and so border guards can be easily bribed. Goods flow in from China. And these days, it's way more than just food. What exactly is coming in? PEARSON: Everything. There's a saying in North Korea that you can find anything but a cat's horn, meaning that if it exists, you can probably find it in the markets. GREENE: Wow. PEARSON: In a way, it's kind of North Korea's biggest open secret. GREENE: And this young man was in on it. CHARLES: Hi, David. GREENE: Thank you for doing this with us. CHARLES: Oh, no problem. GREENE: Charles. He defected from North Korea when he was 17 years old. He swam across the Tumen River to China. And he now lives in the U. S. We are withholding his last name to protect the family he left behind. In North Korea's black market, Charles's role was peddling bootleg DVDs. And how were you getting copies of these movies from the outside? CHARLES: So one of my friend's father was a police officer. GREENE: His friend's dad would confiscate foreign media, but then he'd keep those DVDs for himself. Charles would then secretly copy those confiscated DVDs and put them right back on the black market where they came from. How would you hide these DVDs when you were selling them? CHARLES: Under the clothes and some of them in my jackets, inside of the pocket in the jackets. GREENE: Everywhere? CHARLES: Everywhere, yes. GREENE: And if you got caught, you could be killed. CHARLES: Yeah. It's very dangerous. GREENE: They're risking their life because they are so desperate for content. James Pearson from Reuters says North Koreans are just getting more creative. They're using USB sticks and SD cards now instead of DVDs. PEARSON: That's been a really popular way to spread information. You can hide them between pages of a book. You can swallow them even if you're caught with them. GREENE: The demand right now is actually so high that some Chinese manufacturers have been creating special devices just for the North Korean market. One of them is called a Notel. It's this portable DVD player that has a USB input. Basically, it lets you put in two things at once - the thing you really want to watch and also the state-approved propaganda disk. PEARSON: You can plug your USB stick full of illicit media in. You can open the DVD drive and put in some official state media like Kim Jong Il's greatest hits. And should there be a knock on the door from the bowibu, which is the kind of Gestapo, Stasi-esque institution in North Korea, you can just pull out the USB stick and then open the DVD drive and say look, I was watching this. GREENE: Now, we can't be naive and think that all this has taught us a ton about North Korea. The reality is Kim Jong Un's regime is still in control. Just think of Charles, the defector we spoke to. He gamed the regime. He watched tons of foreign media, but he defected knowing he might never see his brother again. Do you think you'll be able to talk to him at some point again soon? CHARLES: I don't think so. GREENE: That must be hard. CHARLES: Yeah. Living here alone is kind of tough. And I still miss my brothers and my families. But, you know, I still strongly believe that they're going to open one day, you know. And I strongly believe, also, somebody is going to stand up and they're going to say something. MARTIN: That was our co-host David Greene reporting. MARY LOUISE KELLY, HOST:  When North Korea grabs the headlines, it's often because of something like this week's surprise missile test. Rarely do we hear about the lives of ordinary North Koreans. RACHEL MARTIN, HOST:  We know the regime has walled itself off from the rest of the world, but our co-host David Greene learned that some North Koreans aren't as isolated as we might think. DAVID GREENE, BYLINE: When Yeonmi Park was a young girl, she went to her uncle's house to watch a movie. This was not the state-run broadcast she was used to, praising the dear leader. No, this movie was illegal. YEONMI PARK: What we do is we cover windows with blankets, And then we turn the volume really, really down so you have to be right next to TV. GREENE: She was watching a pirated copy of \"Titanic. \" PARK: When I saw that movie first time, I was very confused. I never heard my father telling mother that he loved her. And my mother never told me she loved me, either. To me, like, love were the only words allowed to express to Dear Leader. So it was just very odd concept to me. How come a man can die for woman? GREENE: By the time Yeonmi escaped North Korea in 2007, she'd also seen James Bond. She had seen South Korean dramas. She even watched American wrestling matches. PARK: Yes. For a couple of hours, you just forget about how life so hard. I was dreaming about a different planet. GREENE: Now, Yeonmi was getting all of this stuff through this network of smugglers and traders, a really active black market in her city. This is not the North Korea we know. We see the military parades. We see the goose-stepping soldiers, the tanks. We see the latest missile test. We see a hermit kingdom in isolation. But even in today's society, even the most repressive regime can't keep everything out. JAMES PEARSON: The idea that North Korea is an information black hole is just simply not true anymore. GREENE: That's James Pearson. He reports for Reuters in South Korea. And he also co-authored the book \"North Korea Confidential. \" He says more and more North Koreans are getting their hands on illicit media. And don't think for a minute a movie like \"Titanic\" doesn't worry the North Korean regime. Just seeing visible tension, complicated emotions can make North Koreans feel deprived. PEARSON: Things like that can start to change people's thinking. And when you talk to defectors who've left the country, many of them say, yeah, you know, I was looking at foreign media that started to help me question what it is that I hear from the government. You know, perhaps things are better off overseas, even in South Korea and even across the border in China. GREENE: All right, so how is this forbidden content slipping into such a closed-off society? Well, let's step back for a minute to the mid-1990s. It looked like North Korea was going to collapse. There was devastating famine. The government failed to feed its people. (SOUNDBITE OF ARCHIVED BROADCAST) TREVOR ROWE, BYLINE: Floods in North Korea left half a million people destitute and without food. JULIE MCCARTHY, BYLINE: International relief agencies say 2 million children are at risk of starving to death. GREENE: Now, here's the crazy thing. Capitalism helped save North Korea. These makeshift stands started popping up around the country selling goods, most importantly food. PEARSON: During the famine, people said that the ones who turned to capitalism and trading were the ones that survived. And that North Korea, that real economy has essentially been the real economy ever since. GREENE: Yet Pearson says this black market has grown because government officials are benefiting. State salaries are almost nothing, and so border guards can be easily bribed. Goods flow in from China. And these days, it's way more than just food. What exactly is coming in? PEARSON: Everything. There's a saying in North Korea that you can find anything but a cat's horn, meaning that if it exists, you can probably find it in the markets. GREENE: Wow. PEARSON: In a way, it's kind of North Korea's biggest open secret. GREENE: And this young man was in on it. CHARLES: Hi, David. GREENE: Thank you for doing this with us. CHARLES: Oh, no problem. GREENE: Charles. He defected from North Korea when he was 17 years old. He swam across the Tumen River to China. And he now lives in the U. S. We are withholding his last name to protect the family he left behind. In North Korea's black market, Charles's role was peddling bootleg DVDs. And how were you getting copies of these movies from the outside? CHARLES: So one of my friend's father was a police officer. GREENE: His friend's dad would confiscate foreign media, but then he'd keep those DVDs for himself. Charles would then secretly copy those confiscated DVDs and put them right back on the black market where they came from. How would you hide these DVDs when you were selling them? CHARLES: Under the clothes and some of them in my jackets, inside of the pocket in the jackets. GREENE: Everywhere? CHARLES: Everywhere, yes. GREENE: And if you got caught, you could be killed. CHARLES: Yeah. It's very dangerous. GREENE: They're risking their life because they are so desperate for content. James Pearson from Reuters says North Koreans are just getting more creative. They're using USB sticks and SD cards now instead of DVDs. PEARSON: That's been a really popular way to spread information. You can hide them between pages of a book. You can swallow them even if you're caught with them. GREENE: The demand right now is actually so high that some Chinese manufacturers have been creating special devices just for the North Korean market. One of them is called a Notel. It's this portable DVD player that has a USB input. Basically, it lets you put in two things at once - the thing you really want to watch and also the state-approved propaganda disk. PEARSON: You can plug your USB stick full of illicit media in. You can open the DVD drive and put in some official state media like Kim Jong Il's greatest hits. And should there be a knock on the door from the bowibu, which is the kind of Gestapo, Stasi-esque institution in North Korea, you can just pull out the USB stick and then open the DVD drive and say look, I was watching this. GREENE: Now, we can't be naive and think that all this has taught us a ton about North Korea. The reality is Kim Jong Un's regime is still in control. Just think of Charles, the defector we spoke to. He gamed the regime. He watched tons of foreign media, but he defected knowing he might never see his brother again. Do you think you'll be able to talk to him at some point again soon? CHARLES: I don't think so. GREENE: That must be hard. CHARLES: Yeah. Living here alone is kind of tough. And I still miss my brothers and my families. But, you know, I still strongly believe that they're going to open one day, you know. And I strongly believe, also, somebody is going to stand up and they're going to say something. MARTIN: That was our co-host David Greene reporting.", "section": "Asia", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-07-07-535920505": {"title": "As First Model 3 Rolls Off The Line, Can Tesla Sustain Momentum? : NPR", "url": "https://www.npr.org/2017/07/07/535920505/tesla-bets-big-on-a-mass-market-electric-car", "author": "No author found", "published_date": "2017-07-07", "content": "MARY LOUISE KELLY, HOST: Big week this week for electric and hybrid cars. Volvo became the first automaker to commit to making all its models either electric or hybrid after the year 2019. And today, Tesla is rolling a new car off the assembly line, the Model 3. It's supposed to fulfill CEO Elon Musk's promised to make an affordable, long-range electric car. NPR's Sonari Glinton is on the line to help us work out whether this premise is hype or horsepower or something like that. Hey, Sonari. SONARI GLINTON, BYLINE: Hey, Mary Louise. KELLY: So this Model 3 is a sedan, I gather. Why is Tesla banking that a Model 3 sedan is what the world needs? GLINTON: Well, the Model 3 is a stab at the mass market. It's an all-electric car. And it retails for $35,000 with about a $7,500 rebate. And that puts it well within the range of a new car buyer. The average new car is about $33,000. So it goes 215 miles. And that's a lot. Elon Musk plans to have about 30 vehicles by the end of the month, ramping up to about 1,500. And this is a really big bet. KELLY: Yeah, no, absolutely. Well, and in terms of the numbers they're making, I'm going to have to ask you about scale because the goal here for Tesla is not just to persuade people they need to buy this electric car, it's to persuade a lot of people they need to buy this car, right? GLINTON: Yeah, exactly. This car is very hype. And I think a lot of the other car companies can actually touch it. Last month, Tesla sold 4,400 cars. And now they're wanting the scale to produce about half a million. Now, to give you an idea. . . KELLY: Ah. GLINTON: . . . Toyota sells about 450,000 Camrys. So it's doable. But that is hard. It's a hard task. KELLY: It's a huge ramp-up, yeah. GLINTON: Yeah, exactly. And so - and one of the problems is actually not whether or not they can build the cars but whether they can build the batteries quickly enough to go into the cars and produce batteries for a whole number of platforms. KELLY: Well, can you tell yet, is it a good car? Have you had the chance to drive it? GLINTON: Well, I have not had the chance to drive this car. And. . . KELLY: Yet. GLINTON: Though, I've - yet. KELLY: We'll hope to get you in there soon, yeah. GLINTON: Yes, though I've ridden in it. But, you know, Tesla has gotten a lot of praise for the quality of its cars, though sort of that long-term quality has sort of fallen off a little bit. And there's no telling how well a car company can do when it goes from selling 4,400 cars to selling, you know, tens of thousands of them in a month. KELLY: What would it take for Tesla to consider this car a victory, a win? I mean, we've talked about trying to persuade people they need an electric car. What does Tesla have to do to pull this off and say, OK, we did it? GLINTON: Well, one of the things about the car business is anybody can make one good car. But it's really can you make 20 different cars, you know, year after year? That is the hallmark of a really great carmaker. But Elon Musk is not just betting on cars, he's betting on the electrification of cars. He's betting on autonomous cars. He's betting on revolutionizing the dealer process. He's built this gigantic battery factory that wants to cheapen and change how we manufacture batteries. Oh, and by the way, while he's trying to do all of this, General Motors already has a car on the road that's doing exactly what the Model 3 says it's going to do. And every other carmaker has plans for a full-on electric car coming sometime in the future. So it's not like this is a space without competition. But what Elon wants to do is blow things up and change the way we do things. (SOUNDBITE OF LJONES'S \"JAZZ TECHNICIAN\")KELLY: That's NPR's Sonari Glinton. MARY LOUISE KELLY, HOST:  Big week this week for electric and hybrid cars. Volvo became the first automaker to commit to making all its models either electric or hybrid after the year 2019. And today, Tesla is rolling a new car off the assembly line, the Model 3. It's supposed to fulfill CEO Elon Musk's promised to make an affordable, long-range electric car. NPR's Sonari Glinton is on the line to help us work out whether this premise is hype or horsepower or something like that. Hey, Sonari. SONARI GLINTON, BYLINE: Hey, Mary Louise. KELLY: So this Model 3 is a sedan, I gather. Why is Tesla banking that a Model 3 sedan is what the world needs? GLINTON: Well, the Model 3 is a stab at the mass market. It's an all-electric car. And it retails for $35,000 with about a $7,500 rebate. And that puts it well within the range of a new car buyer. The average new car is about $33,000. So it goes 215 miles. And that's a lot. Elon Musk plans to have about 30 vehicles by the end of the month, ramping up to about 1,500. And this is a really big bet. KELLY: Yeah, no, absolutely. Well, and in terms of the numbers they're making, I'm going to have to ask you about scale because the goal here for Tesla is not just to persuade people they need to buy this electric car, it's to persuade a lot of people they need to buy this car, right? GLINTON: Yeah, exactly. This car is very hype. And I think a lot of the other car companies can actually touch it. Last month, Tesla sold 4,400 cars. And now they're wanting the scale to produce about half a million. Now, to give you an idea. . . KELLY: Ah. GLINTON: . . . Toyota sells about 450,000 Camrys. So it's doable. But that is hard. It's a hard task. KELLY: It's a huge ramp-up, yeah. GLINTON: Yeah, exactly. And so - and one of the problems is actually not whether or not they can build the cars but whether they can build the batteries quickly enough to go into the cars and produce batteries for a whole number of platforms. KELLY: Well, can you tell yet, is it a good car? Have you had the chance to drive it? GLINTON: Well, I have not had the chance to drive this car. And. . . KELLY: Yet. GLINTON: Though, I've - yet. KELLY: We'll hope to get you in there soon, yeah. GLINTON: Yes, though I've ridden in it. But, you know, Tesla has gotten a lot of praise for the quality of its cars, though sort of that long-term quality has sort of fallen off a little bit. And there's no telling how well a car company can do when it goes from selling 4,400 cars to selling, you know, tens of thousands of them in a month. KELLY: What would it take for Tesla to consider this car a victory, a win? I mean, we've talked about trying to persuade people they need an electric car. What does Tesla have to do to pull this off and say, OK, we did it? GLINTON: Well, one of the things about the car business is anybody can make one good car. But it's really can you make 20 different cars, you know, year after year? That is the hallmark of a really great carmaker. But Elon Musk is not just betting on cars, he's betting on the electrification of cars. He's betting on autonomous cars. He's betting on revolutionizing the dealer process. He's built this gigantic battery factory that wants to cheapen and change how we manufacture batteries. Oh, and by the way, while he's trying to do all of this, General Motors already has a car on the road that's doing exactly what the Model 3 says it's going to do. And every other carmaker has plans for a full-on electric car coming sometime in the future. So it's not like this is a space without competition. But what Elon wants to do is blow things up and change the way we do things. (SOUNDBITE OF LJONES'S \"JAZZ TECHNICIAN\") KELLY: That's NPR's Sonari Glinton.", "section": "Business", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-07-08-536197350": {"title": "Barbershop: Internet Trolling : NPR", "url": "https://www.npr.org/2017/07/08/536197350/barbershop-internet-trolling", "author": "No author found", "published_date": "2017-07-08", "content": "MICHEL MARTIN, HOST: Now it's time for the Barbershop. That's where we gather a group of interesting folks to talk about what's in the news and what's on their minds. Today what's on our minds is trolling. Now, trolling - sending nasty, often personal, often racist, anti-Semitic and sexist taunts over the Internet. Well, that's been around for a while. But this is in the news again not just because of President Trump's well-known Twitter habits but also because of what his supporters are willing to do to take up his cause. Case in point - last week, the president retweeted a video of him body-slamming an opponent made up with a CNN logo. CNN did some reporting on whoever made the video in the first place. And now, that reporter and his family are reportedly facing taunts and threats. Oh, and there's the matter of what happened when this network decided to celebrate Independence Day by tweeting out the Declaration of Independence. Some people didn't get it. More on that later. But first, as we said, this has been going on long before this President made Twitter his version of a fireside chat. But many people who follow social media say it's getting worse, so we wanted to talk about that. So we've called three people who've thought a lot about trolling and some who have experienced it. And we should let you know that you should expect some offensive language in this conversation. We want you to know what sort of language trolls direct at their targets. So joining us for a shapeup now are Adrienne LaFrance, a reporter at The Atlantic. She covers technology. Hi. ADRIENNE LAFRANCE: Thanks so much for having me. MARTIN: Anita Samuels, author of a book on trolling entitled \"Rants & Retorts: How Bigots Got A Monopoly On Commenting About News Online. \"ANITA SAMUELS: Thanks for having me. MARTIN: And Professor Michelle Ferrier of Ohio University. She's founder of TrollBusters, which she founded to support women journalists facing online attacks. Welcome to you. Thank you all so much for joining us. MICHELLE FERRIER: Thanks for having me. MARTIN: So, Adrienne, I'm going to start because you cover technology to start by asking you to define trolling. And what do you think kind of gave this the presence that it has in our landscape today? LAFRANCE: So this is actually a surprisingly hard question. What is a troll? I think sort of at the purest level, we're talking about someone who is just delighting in chaos, sort of utterly hateful, provocative, really wants a reaction. But culturally, we've sort of burdened trolling and trolls with so many other meanings that it has become pretty murky. And almost - it gets difficult to talk about because people can't agree with what a troll even is. Is it just someone who's mean? Is it someone who disagrees with you? Do you have to, you know, be facing a death threat for it to be real trolling? So there's this sort of spectrum and not a lot of clarity about what a troll really is. MARTIN: So, Anita, you make the point in your book that trolls have essentially taken over commentary sites. I mean, that's the subtitle of your book, that - you say that bigots got a monopoly on commenting about news commentary sites. Why do you say that? SAMUELS: Yes. I say that because when you read most comments sections, the majority of the comments are bigoted specifically against African-Americans. When you read comment sections, the negativity takes over any of the positive. It outweighs any positive message there. MARTIN: Adrienne, I'm going to ask you, is that true? I mean, does the research indicate that the negativity outweighs the positive? LAFRANCE: I think that certainly the prevailing sense - the comment sections of many, many, many news sites, even legitimate, well-regarded news sites - it's just vitriol. MARTIN: Well, so, Anita, go to that point about, like, when you say bigots, what do you mean by that? SAMUELS: So that could be anything from skin complection, anything from if you're in New York, if you live in a certain area, oh, you must be on welfare. You must be, you know, if you have children, oh, you might not know who the father is. You probably don't know who the father is. You have multiple children out of wedlock. All of these things. MARTIN: For people who think, OK, so what's the big deal? You know, journalists should just put their big-boy pants on. People should just - if they don't want to read the comments, they should just ignore them. This is where we come to you, Professor Ferrier, because you're a columnist. And tell us what happened to you. And tell us what you think people don't know about this. FERRIER: Sure. So, Michel, about 12 years ago, I was still a newspaper columnist and an online community manager actually as the first African-American columnist at a newspaper in Florida. I received all kinds of hate mail, both through the postal system as well as through email. I was stalked by one particular letter writer who sent me manifestos in the mail, long letters of vitriol talking about, how do you get an N - a nigger nigger out of a tree? And, you know, cut the rope. Or other types of racial slurs and things directed at me. And I wrote a lifestyle column. It was not on the editorial page. It was in our lifestyle section. So it was one of the early kinds of mommy bloggers that moved from online. And I was in the print portion. And that letter writer wrote me over a series of years. And I went to management. I went to the police, FBI, CIA, all the agencies you can imagine to get support, including our journalism professional organizations. And no one had any help to offer. This was organized activity. It was the rise of white supremacist groups using the Internet and Internet tools to be able to systematically create fear and intimidation in journalists, particularly journalists of color. FERRIER: You actually felt so threatened by this that you started carrying a gun. FERRIER: I did and disguising myself. You have to understand, I worked on the night news desk in a newspaper with probably less than 20 people after midnight at night. And I often worked from 5 till 2 o'clock in the morning. And so safety was a key concern because these letters continued to talk about violence. Trolls are not just what our president would characterize as, you know, heavy-set people on a couch. These are coordinated groups of hackers using the Internet to organize themselves, to create attacks on people's websites and bring them offline, to do doxing, which is where they send out personal information about your home address or where you live or your family and children's names. This is activity that moves from online to the offline spaces and needs to be taken seriously by both management as well as law enforcement. MARTIN: So when you approached some of these news organizations about why they continue to allow these kinds of comments - because they wouldn't print them. They would never print these in their printed pages. But somehow, news organizations allow these anonymous commentators to spread things that are not true or just vitriol. Why do they have such different standards for what they kind of print in their news pages as opposed to what they would allow on their anonymous comment boards? I mean, Adrienne, do you have reporting on this? FERRIER: Yeah. Well, I mean, I think the best way to think about it is to consider sort of like the utopian version of the Web and the idea of what the best possible version of sort of civil discourse online could be. And so when news organizations shifted many of their operations online, they were also sort of merging into this culture of what was already there, which was largely like blogs and people creating their own spaces, people publishing their own things. And so as readers moved to platforms, you know, in an ideal environment, you hope that you can engage with them and let them sort of have this - no longer just have the newspaper be the gatekeeper but have it be sort of a two-way publishing environment, at least in the comments section. And unfortunately, sort of the lowest common denominator rises to the top. In fact, there was a study that found that the first comment in a thread really does set the tone. And so if the first comment in a thread is very trolly or negative or racist, that it's more likely for the rest of the thread to sort of devolve into that space. MARTIN: You know, here's an interesting experience that we had at this organization. You know, every year, NPR's had a tradition of having their on-air talent - including me - read portions of the Declaration of Independence. This year, NPR decided to tweet out the Declaration of Independence line by line. And some people didn't get it. And they thought that NPR was calling the president a tyrant who needed to be overthrown and a lot of angry tweets about that. But then we reached out to some of these people to say what's, you know, what's happening here? One Twitter user actually apologized. And our producers called him. This is Daniel Davies (ph) of Virginia. This is what he had to say. DANIEL DAVIES: I caught it right in the middle about the change in government, you know, with, you know, the revolution and to abolish the government. I did not recognize that it was part of the Declaration of Independence. And I had basically a visceral knee-jerk reaction to it. What I did was trolling. It's a perfect reaction to emotion over reason. I took something that was initially good and noble, and I put an ugly face on it. We're so polarized. This nation is incredibly polarized. And by my isolating myself, listening to others who believe the same thing I did, I all but ignored any sensible comments from the other side of the aisle and made some mistake that I'm not going to do again. MARTIN: So how about that? Is this - Adrienne, I don't know if you - is this unusual? Does this happen? LAFRANCE: It definitely happens. I've had similar experiences where I've had sort of not the nicest tweets sort of lobbed in my direction and occasionally have decided to sort of reach out and see if we could just, like, have a nice conversation. And we have. And in one instance in particular, the person was sort of shocked that I replied and was like, well, I sort of felt like I was tweeting into the void and didn't at all expect a human on the other end and was then very embarrassed. And so I think that's telling as well. At the same time, solving trolling is not going to be like one person at a time appealing to the reason of another person. MARTIN: Professor Ferrier, though, do people on the left also engage in this conduct? FERRIER: Absolutely. I believe anyone can be a troll on any issue. It just depends on what the issue is. And I'm sure each of us can think to times that we've posted things online and said that might have been a little strong. FERRIER: Is the president a troll? SAMUELS: Yes. I think so. FERRIER: A troll in chief. MARTIN: Anita says yes. Professor Ferrier says yes. Adrienne? LAFRANCE: I'm not as sure. He certainly has supporters who see themselves and their trolling instincts in him. I'm not sure he is officially a troll. MARTIN: Because? LAFRANCE: You know, I don't know. I think, you know - he doesn't - it's a good question. This goes back to the difficulty of defining trolling. You know, he may be trolling CNN, he might be. MARTIN: OK. Who else said yes, definitely? SAMUELS: I did. MARTIN: OK. Anita, you say yes because? SAMUELS: Because he's attacking people. And it seems like he's attacking people that aren't agreeing with him. And I think his behavior is showing a really poor example to children because they're reading this and hearing about it on TV and everything. And they may follow this behavior. MARTIN: Adrienne, are most trolls children, by the way? I mean, the argument is that these are 15-year-old boys who are - and you're saying actually. . . FERRIER: No. MARTIN: Professor Ferrier, you're saying no, they are not? FERRIER: No. That's the mythology. And I think that's what has kept us stuck in this idea that this is innocuous behavior. This is not. These are organized groups, whether it's government operatives, whether it is anonymous groups of hackers, et cetera, or one person that could be a teen boy but also because of his online networks can rally people from around the world to do attacks on people's websites, et cetera. So I think we're naive to think that it's innocuous as teen boys in a basement. And I think we need to understand that the online environment, as Adrienne talked about, especially positive comments can create a positive environment. And TrollBusters uses that methodology of providing support, positive messages, et cetera into a Twitter stream to try and help create an environment that's less tolerable to the trolls. MARTIN: Anita Samuels, you have a whole chapter on your views about what needs to occur here. And, you know, we don't have time to go to all of your suggestions, but could just give us like your top one or two? SAMUELS: It's a good idea probably to go and try and defend against the stereotypes and to defend yourself, but it's going to be a personal choice as to how far you're going to go. MARTIN: Adrienne LaFrance? LAFRANCE: Yeah. And I think looking at Twitter again, first of all, the responsibility that the platforms have to improve discourse is an open-ended question. They want engagement on their sites. And people who are emotionally riled up are engaged, so they don't have necessarily incentive that lines up with our goals for better, you know, more civilized discourse. And one other thing I'd like to mention is that Twitter has shared data about how harassment is reported and has found that in most cases, it's actually bystanders who are reporting abuse against people, rather than the victim of that abuse. And so I think that that - for people who are who are hoping to do their part to make the Web a nicer place, if you see someone being mistreated, report the person who's doing the mistreatment. And ask people if you can help. If you see someone who's being attacked, you know, it might really help them to reach out to them. So that's something for people to consider. MARTIN: That was Atlantic reporter Adrienne LaFrance. She covers technology. We were talking to her about her piece, \"Trolls Are Winning The Internet. \" It was posted back in March. She was joining us here in our Washington, D. C. , studios. Anita Samuels' new book is \"Rants & Retorts: How Bigots Got A Monopoly On Commenting About News Online. \" She was kind enough to join us from our studios in New York. And Professor Michelle Ferrier is founder of TrollBusters. She joined us from her home office in Ohio. Thank you all so much for speaking with us. LAFRANCE: Thank you for having me. SAMUELS: Thank you, Michel. Thank you for having me. FERRIER: Thank you, Michel. MICHEL MARTIN, HOST:  Now it's time for the Barbershop. That's where we gather a group of interesting folks to talk about what's in the news and what's on their minds. Today what's on our minds is trolling. Now, trolling - sending nasty, often personal, often racist, anti-Semitic and sexist taunts over the Internet. Well, that's been around for a while. But this is in the news again not just because of President Trump's well-known Twitter habits but also because of what his supporters are willing to do to take up his cause. Case in point - last week, the president retweeted a video of him body-slamming an opponent made up with a CNN logo. CNN did some reporting on whoever made the video in the first place. And now, that reporter and his family are reportedly facing taunts and threats. Oh, and there's the matter of what happened when this network decided to celebrate Independence Day by tweeting out the Declaration of Independence. Some people didn't get it. More on that later. But first, as we said, this has been going on long before this President made Twitter his version of a fireside chat. But many people who follow social media say it's getting worse, so we wanted to talk about that. So we've called three people who've thought a lot about trolling and some who have experienced it. And we should let you know that you should expect some offensive language in this conversation. We want you to know what sort of language trolls direct at their targets. So joining us for a shapeup now are Adrienne LaFrance, a reporter at The Atlantic. She covers technology. Hi. ADRIENNE LAFRANCE: Thanks so much for having me. MARTIN: Anita Samuels, author of a book on trolling entitled \"Rants & Retorts: How Bigots Got A Monopoly On Commenting About News Online. \" ANITA SAMUELS: Thanks for having me. MARTIN: And Professor Michelle Ferrier of Ohio University. She's founder of TrollBusters, which she founded to support women journalists facing online attacks. Welcome to you. Thank you all so much for joining us. MICHELLE FERRIER: Thanks for having me. MARTIN: So, Adrienne, I'm going to start because you cover technology to start by asking you to define trolling. And what do you think kind of gave this the presence that it has in our landscape today? LAFRANCE: So this is actually a surprisingly hard question. What is a troll? I think sort of at the purest level, we're talking about someone who is just delighting in chaos, sort of utterly hateful, provocative, really wants a reaction. But culturally, we've sort of burdened trolling and trolls with so many other meanings that it has become pretty murky. And almost - it gets difficult to talk about because people can't agree with what a troll even is. Is it just someone who's mean? Is it someone who disagrees with you? Do you have to, you know, be facing a death threat for it to be real trolling? So there's this sort of spectrum and not a lot of clarity about what a troll really is. MARTIN: So, Anita, you make the point in your book that trolls have essentially taken over commentary sites. I mean, that's the subtitle of your book, that - you say that bigots got a monopoly on commenting about news commentary sites. Why do you say that? SAMUELS: Yes. I say that because when you read most comments sections, the majority of the comments are bigoted specifically against African-Americans. When you read comment sections, the negativity takes over any of the positive. It outweighs any positive message there. MARTIN: Adrienne, I'm going to ask you, is that true? I mean, does the research indicate that the negativity outweighs the positive? LAFRANCE: I think that certainly the prevailing sense - the comment sections of many, many, many news sites, even legitimate, well-regarded news sites - it's just vitriol. MARTIN: Well, so, Anita, go to that point about, like, when you say bigots, what do you mean by that? SAMUELS: So that could be anything from skin complection, anything from if you're in New York, if you live in a certain area, oh, you must be on welfare. You must be, you know, if you have children, oh, you might not know who the father is. You probably don't know who the father is. You have multiple children out of wedlock. All of these things. MARTIN: For people who think, OK, so what's the big deal? You know, journalists should just put their big-boy pants on. People should just - if they don't want to read the comments, they should just ignore them. This is where we come to you, Professor Ferrier, because you're a columnist. And tell us what happened to you. And tell us what you think people don't know about this. FERRIER: Sure. So, Michel, about 12 years ago, I was still a newspaper columnist and an online community manager actually as the first African-American columnist at a newspaper in Florida. I received all kinds of hate mail, both through the postal system as well as through email. I was stalked by one particular letter writer who sent me manifestos in the mail, long letters of vitriol talking about, how do you get an N - a nigger nigger out of a tree? And, you know, cut the rope. Or other types of racial slurs and things directed at me. And I wrote a lifestyle column. It was not on the editorial page. It was in our lifestyle section. So it was one of the early kinds of mommy bloggers that moved from online. And I was in the print portion. And that letter writer wrote me over a series of years. And I went to management. I went to the police, FBI, CIA, all the agencies you can imagine to get support, including our journalism professional organizations. And no one had any help to offer. This was organized activity. It was the rise of white supremacist groups using the Internet and Internet tools to be able to systematically create fear and intimidation in journalists, particularly journalists of color. FERRIER: You actually felt so threatened by this that you started carrying a gun. FERRIER: I did and disguising myself. You have to understand, I worked on the night news desk in a newspaper with probably less than 20 people after midnight at night. And I often worked from 5 till 2 o'clock in the morning. And so safety was a key concern because these letters continued to talk about violence. Trolls are not just what our president would characterize as, you know, heavy-set people on a couch. These are coordinated groups of hackers using the Internet to organize themselves, to create attacks on people's websites and bring them offline, to do doxing, which is where they send out personal information about your home address or where you live or your family and children's names. This is activity that moves from online to the offline spaces and needs to be taken seriously by both management as well as law enforcement. MARTIN: So when you approached some of these news organizations about why they continue to allow these kinds of comments - because they wouldn't print them. They would never print these in their printed pages. But somehow, news organizations allow these anonymous commentators to spread things that are not true or just vitriol. Why do they have such different standards for what they kind of print in their news pages as opposed to what they would allow on their anonymous comment boards? I mean, Adrienne, do you have reporting on this? FERRIER: Yeah. Well, I mean, I think the best way to think about it is to consider sort of like the utopian version of the Web and the idea of what the best possible version of sort of civil discourse online could be. And so when news organizations shifted many of their operations online, they were also sort of merging into this culture of what was already there, which was largely like blogs and people creating their own spaces, people publishing their own things. And so as readers moved to platforms, you know, in an ideal environment, you hope that you can engage with them and let them sort of have this - no longer just have the newspaper be the gatekeeper but have it be sort of a two-way publishing environment, at least in the comments section. And unfortunately, sort of the lowest common denominator rises to the top. In fact, there was a study that found that the first comment in a thread really does set the tone. And so if the first comment in a thread is very trolly or negative or racist, that it's more likely for the rest of the thread to sort of devolve into that space. MARTIN: You know, here's an interesting experience that we had at this organization. You know, every year, NPR's had a tradition of having their on-air talent - including me - read portions of the Declaration of Independence. This year, NPR decided to tweet out the Declaration of Independence line by line. And some people didn't get it. And they thought that NPR was calling the president a tyrant who needed to be overthrown and a lot of angry tweets about that. But then we reached out to some of these people to say what's, you know, what's happening here? One Twitter user actually apologized. And our producers called him. This is Daniel Davies (ph) of Virginia. This is what he had to say. DANIEL DAVIES: I caught it right in the middle about the change in government, you know, with, you know, the revolution and to abolish the government. I did not recognize that it was part of the Declaration of Independence. And I had basically a visceral knee-jerk reaction to it. What I did was trolling. It's a perfect reaction to emotion over reason. I took something that was initially good and noble, and I put an ugly face on it. We're so polarized. This nation is incredibly polarized. And by my isolating myself, listening to others who believe the same thing I did, I all but ignored any sensible comments from the other side of the aisle and made some mistake that I'm not going to do again. MARTIN: So how about that? Is this - Adrienne, I don't know if you - is this unusual? Does this happen? LAFRANCE: It definitely happens. I've had similar experiences where I've had sort of not the nicest tweets sort of lobbed in my direction and occasionally have decided to sort of reach out and see if we could just, like, have a nice conversation. And we have. And in one instance in particular, the person was sort of shocked that I replied and was like, well, I sort of felt like I was tweeting into the void and didn't at all expect a human on the other end and was then very embarrassed. And so I think that's telling as well. At the same time, solving trolling is not going to be like one person at a time appealing to the reason of another person. MARTIN: Professor Ferrier, though, do people on the left also engage in this conduct? FERRIER: Absolutely. I believe anyone can be a troll on any issue. It just depends on what the issue is. And I'm sure each of us can think to times that we've posted things online and said that might have been a little strong. FERRIER: Is the president a troll? SAMUELS: Yes. I think so. FERRIER: A troll in chief. MARTIN: Anita says yes. Professor Ferrier says yes. Adrienne? LAFRANCE: I'm not as sure. He certainly has supporters who see themselves and their trolling instincts in him. I'm not sure he is officially a troll. MARTIN: Because? LAFRANCE: You know, I don't know. I think, you know - he doesn't - it's a good question. This goes back to the difficulty of defining trolling. You know, he may be trolling CNN, he might be. MARTIN: OK. Who else said yes, definitely? SAMUELS: I did. MARTIN: OK. Anita, you say yes because? SAMUELS: Because he's attacking people. And it seems like he's attacking people that aren't agreeing with him. And I think his behavior is showing a really poor example to children because they're reading this and hearing about it on TV and everything. And they may follow this behavior. MARTIN: Adrienne, are most trolls children, by the way? I mean, the argument is that these are 15-year-old boys who are - and you're saying actually. . . FERRIER: No. MARTIN: Professor Ferrier, you're saying no, they are not? FERRIER: No. That's the mythology. And I think that's what has kept us stuck in this idea that this is innocuous behavior. This is not. These are organized groups, whether it's government operatives, whether it is anonymous groups of hackers, et cetera, or one person that could be a teen boy but also because of his online networks can rally people from around the world to do attacks on people's websites, et cetera. So I think we're naive to think that it's innocuous as teen boys in a basement. And I think we need to understand that the online environment, as Adrienne talked about, especially positive comments can create a positive environment. And TrollBusters uses that methodology of providing support, positive messages, et cetera into a Twitter stream to try and help create an environment that's less tolerable to the trolls. MARTIN: Anita Samuels, you have a whole chapter on your views about what needs to occur here. And, you know, we don't have time to go to all of your suggestions, but could just give us like your top one or two? SAMUELS: It's a good idea probably to go and try and defend against the stereotypes and to defend yourself, but it's going to be a personal choice as to how far you're going to go. MARTIN: Adrienne LaFrance? LAFRANCE: Yeah. And I think looking at Twitter again, first of all, the responsibility that the platforms have to improve discourse is an open-ended question. They want engagement on their sites. And people who are emotionally riled up are engaged, so they don't have necessarily incentive that lines up with our goals for better, you know, more civilized discourse. And one other thing I'd like to mention is that Twitter has shared data about how harassment is reported and has found that in most cases, it's actually bystanders who are reporting abuse against people, rather than the victim of that abuse. And so I think that that - for people who are who are hoping to do their part to make the Web a nicer place, if you see someone being mistreated, report the person who's doing the mistreatment. And ask people if you can help. If you see someone who's being attacked, you know, it might really help them to reach out to them. So that's something for people to consider. MARTIN: That was Atlantic reporter Adrienne LaFrance. She covers technology. We were talking to her about her piece, \"Trolls Are Winning The Internet. \" It was posted back in March. She was joining us here in our Washington, D. C. , studios. Anita Samuels' new book is \"Rants & Retorts: How Bigots Got A Monopoly On Commenting About News Online. \" She was kind enough to join us from our studios in New York. And Professor Michelle Ferrier is founder of TrollBusters. She joined us from her home office in Ohio. Thank you all so much for speaking with us. LAFRANCE: Thank you for having me. SAMUELS: Thank you, Michel. Thank you for having me. FERRIER: Thank you, Michel.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-07-10-536424647": {"title": "Could You Kill A Robot? | Hidden Brain : NPR", "url": "https://www.npr.org/2017/07/10/536424647/can-robots-teach-us-what-it-means-to-be-human", "author": "No author found", "published_date": "2017-07-10", "content": "SHANKAR VEDANTAM, HOST:This is HIDDEN BRAIN. I'm Shankar Vedantam. (SOUNDBITE OF MUSIC)VEDANTAM: Have you ever talked to your computer, cursed it for making a mistake? (SOUNDBITE OF FILM, \"OFFICE SPACE\")DAVID HERMAN: (As Michael Bolton) PC LOAD LETTER, what the [expletive] does that mean? VEDANTAM: Have you ever argued with the traffic directions you get from Google Maps or Waze? (SOUNDBITE OF ARCHIVED RECORDING)AUTOMATED VOICE: Starting route to Grover's Mill Road. Head North on. . . VEDANTAM: Have you ever looked at a Roomba cleaning the floor on the other side of the room and told it, please come over to this side, turn left, left? (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED MAN: It just ran itself right off of the edge. VEDANTAM: Robots and artificial intelligence are playing an ever larger role in all of our lives. Of course, this is not the role that science fiction once imagined. (SOUNDBITE OF FILM, \"THE TERMINATOR\")MICHAEL BIEHN: (As Kyle Reese) It doesn't feel pity or remorse or fear. VEDANTAM: Robots bent on our destruction remain the stuff of movies like \"Terminator. \" And robot sentience is still an idea that's far off in the future. But there's a lot we're learning about smart machines, and there's a lot that smart machines are teaching us about how we connect with the world around us and with each other. This week on HIDDEN BRAIN, can robots teach us what it means to be human? (SOUNDBITE OF MUSIC)VEDANTAM: My guest today has spent a lot of time thinking about how we interact with smart machines and how those interactions might change the way we relate to one another. Kate Darling is a research specialist at the MIT Media Lab. She joined us recently in front of a live audience at the Hotel Jerome in Aspen, Colo. , as part of the Aspen Ideas Festival. Also on stage was a robot, a green robot dinosaur about the size of a small dog known as a PLEO. It's going to be part of this conversation. But before we get to that, here's Kate. (APPLAUSE)VEDANTAM: Kate, welcome to HIDDEN BRAIN. KATE DARLING: Thank you for having me. VEDANTAM: You find that there is an interesting point in the relationship between humans and machines. And that point comes when we give a machine a name. I understand that you have three of these PLEO dinosaurs at your home. Can you tell me some of the names that you have given to your robots? DARLING: Yes. So the very first one I bought I named Yochai after Yochai Benkler, who's a Harvard professor who's done some work in intellectual property and other areas that I've always admired. And the second one I adopted after I filmed a Canadian documentary where the show host had to name the robot. And he gave the robot the same name he had, which was Peter (ph). So the second one has a boring name. And then. . . (LAUGHTER)DARLING: . . . The third one is named Mr. Spaghetti. I don't know if people outside of Boston are familiar with this, but the Boston public transportation system, they wanted to crowdsource a name for their mascot dog. And the Internet decided that the dog should be named Mr. Spaghetti. And, of course, they refused to do that and named the dog Hunter. So Mr. Spaghetti became a big thing in Boston for a while. It was - people were very outraged about this. And so I named my PLEO - my third one - Mr. Spaghetti. VEDANTAM: I understand that companies actually have found that if you sell a robot with the name of the robot on the box, it changes the way people will interact with that robot than if you just said, this is a dinosaur. DARLING: So this is - yeah - this is not - I don't have any data on this, but, yes, I have talked to companies who feel that it helps with adoption and trust of the technology. Even very, very simple robots like boxes on wheels that deliver medicine in hospitals, if you give them a little nameplate that says Betsy (ph), their understanding is that people are a little bit more forgiving of the robot. So instead of this stupid machine doesn't work, they'll say, oh, Betsy made a mistake. (LAUGHTER)VEDANTAM: And I'm wondering if you've spent time thinking about why this happens. At some level, if I came up to you at home and I said, Kate, is Mr. Spaghetti alive? You would almost certainly tell me, no, Mr. Spaghetti's not alive. I assume you don't think Mr. Spaghetti is alive, right? DARLING: No. VEDANTAM: OK. So. . . (LAUGHTER)VEDANTAM: . . . Given that you know that Mr. Spaghetti's not alive, why do you think giving him a name changes your relationship to him? DARLING: With robots in particular, it's combined with just our general tendency to anthropomorphize these things. And we're also primed by science fiction and pop culture to give robots names and view them as entities with personalities. And it's more than just the name, right? I mean, robots move around in a way that seems autonomous to us. We respond to that type of physical movement. Our brains will project intent onto it. So I think robots are the perfect mixture of something that we will very willingly treat with human qualities or lifelike qualities. VEDANTAM: I understand from one of your papers that there have been examples, especially in military settings, where robots have been assigned to do very dangerous tasks because you don't want human beings to go out and do those tasks. But eventually, the military folks who are running the robots start to relate to them as if they were actually fellow soldiers. DARLING: There's been some research on this. So Julie Carpenter has done some research. And there's just countless stories online, on Reddit, everywhere about soldiers becoming emotionally attached to the bomb disposal robots that they work with. They'll give them names. They'll give them medals of honor. They'll have funerals for them. And, you know, it's also kind of interesting because the robots aren't special robots. They're just kind of sticks on wheels. But I think just also the situation that the soldiers find themselves in, where the robot is basically risking its life to save human lives, might also lead them to become very attached to these devices. VEDANTAM: You had a wonderful example some time ago looking at a colonel, I believe - I don't know if this was your work or you were citing someone else's work - of a colonel who was supervising a robot that was doing sort of mine disposal. Tell us the story about the mine disposal robot. DARLING: Oh, yeah, this is an incredible - it was an article in The Washington Post, I believe, back in 2007. And the United States military was testing this new robot that could walk over a field with landmines and diffuse them by stepping on them and blowing them up. And the robot itself was shaped like a stick insect. So it would walk around on six legs. And every time it stepped on a landmine, one of the legs would blow up. And then it would just continue on the remaining legs. And so they were testing this. And the colonel who was in charge of this exercise ended up calling it off because he said it was too inhumane to watch this thing drag itself across the field on its remaining legs. (LAUGHTER)VEDANTAM: And so this raises sort of an interesting question because, on the one hand, we can understand how this desire to anthropomorphize robots is very human in some ways. But in some ways - in this case, that defeats the whole point of having a robot that's trying to find the mines. DARLING: It does. I mean, it's really anything from inefficient to dangerous in these contexts where we want robots to be strictly used as tools to anthropomorphize them. And it's a very difficult design challenge as well because how do you create a device that people want to use but don't like too much? VEDANTAM: All right. So we have this wonderful little prop in front of us. It's a PLEO dinosaur. I want you to tell me a little bit about the PLEO dinosaur - how it works and how you've come to own three of them, Kate. DARLING: (Laughter). VEDANTAM: What is the dinosaur? What does it do? DARLING: It's basically an expensive toy. I bought the first one, I think, in 2007. There we go. It's awake. They have a lot of motors and touch sensors. And they have an infrared camera and microphones. So they're pretty cool pieces of technology for a toy. And that's initially why I bought one because I was fascinated by everything that it can do. Like, if it starts walking around, it can walk to the edge of the table. It can look down, measure the distance to the floor. It knows that there's a drop, and it'll get scared and walk backwards. (LAUGHTER)DARLING: And then they go through different life phases - adolescent and fully grown. And, you know, it'll have moods and. . . VEDANTAM: So I think what we should do - we bought the robot at HIDDEN BRAIN a couple of weeks ago. We haven't had a chance to give it a name yet. And I thought we should actually reserve the honors for this evening where we're talking to Kate and see if Kate wants to try and name this dinosaur, you know, since she cares about dinosaurs so much. I was looking up Kate's Twitter feed this morning. I understand that you're going to have a baby soon. Congratulations. DARLING: Yes, I don't have a name for that, either. VEDANTAM: OK. (LAUGHTER)VEDANTAM: Just FYI, she sometimes refers to the baby as baby bot, so just - for whatever that's worth. And one retweet that you have on your Twitter feed cracked me up. It said, you don't really know how many people you don't like until you start trying to pick baby names. (LAUGHTER)DARLING: Yeah, that was - that's a quote from my husband. (LAUGHTER)VEDANTAM: So I don't want you to tell me - you apparently haven't yet picked your baby's name. So do you have any choices, of top choices? Or is there a name, a spare name that you might care to give the dinosaur? DARLING: Well, the problem is we've had a girl's name picked out for years and now we're having a boy. And we just can't - we don't even have any contenders. VEDANTAM: No contenders. What was - what would have been your favorite girl's name if it had - if you had had a girl? DARLING: Well, so when I first started dating my now-husband, he at some point said, if I ever had a daughter, I already know what I would name her. And I was like, oh, really? We're going to fight about this one. And he said, yeah, I would name her Samantha and Sam for short because Sam is kind of gender neutral. And I was like, oh, I really love that. So that one was picked out very easily. VEDANTAM: All right, since you're not having a girl, you're going to have a boy, would you mind if you considered naming the dinosaur Samantha? How would you feel about that? DARLING: Oh, that would be awesome. We should name the dinosaur Samantha. VEDANTAM: All right, so henceforth, this dinosaur will be called Samantha. . . DARLING: Yay. VEDANTAM: . . . Or Sam for short. (APPLAUSE)VEDANTAM: Now, some time ago, Kate conducted a very interesting experiment with the PLEO dinosaurs. And to sort of show how this works, I have a second prop here which is under the table. DARLING: Uh-oh. VEDANTAM: It's a hammer, a large hammer which we borrowed from the hotel. Now, as you all know, the dinosaur is obviously not alive. It's just cloth and plastic and a battery and wires. It has a name, of course, Samantha, but. . . (LAUGHTER)VEDANTAM: . . . It isn't alive in any sense of the term. And so Kate, I'm going to actually give you the hammer. DARLING: Oh, no. (LAUGHTER)VEDANTAM: Kate, would you consider destroying Samantha? DARLING: No. (LAUGHTER)VEDANTAM: It's just a machine. DARLING: I only make other people do that. I don't do it myself. (LAUGHTER)VEDANTAM: You wouldn't even consider harming the dinosaur? DARLING: Well, so my problem is that I already know the results of our research. And that would say something about me as a person, so I'm going to say no, I'm not willing to do it. (LAUGHTER)VEDANTAM: Tell me about the experiment. So you had volunteers come up, and you basically introduced them to these lovable dinosaurs. And then you give them a hammer like this. And you told them to do what? DARLING: Well, so - OK, so this was the workshop part that we used the dinosaurs for. They're a little too expensive to do an experiment with a hundred participants. So the workshop that we did, in a nonscientific setting, we had five of these robot dinosaurs. We gave them to groups of people and had them name them, interact with them, play with them. We had them personify them a little bit by doing a little fashion show with - and a fashion contest. And then after about an hour, we asked them to torture and kill them. And we had a variety of instruments. We had a hammer, a hatchet and I forget what else. And - but like even though we tried to make it dramatic, it turned out to be a little bit more dramatic than we expected it to be. And they really refused to even hit the things. And so we had to kind of start playing mind games with them. We said, OK, you can save your group's dinosaur if you hit another group's dinosaur with the hammer. VEDANTAM: Oh, my gosh. (LAUGHTER)DARLING: And they tried. And they couldn't do that, either. This one woman was standing over the thing trying and she just couldn't. She ended up petting it instead. (LAUGHTER)DARLING: And then, finally, we said, OK, well, we're going to destroy all of the robots unless someone takes a hatchet to one of them. And finally, someone did. VEDANTAM: Wait, so you said unless one of you kills one of them, we are going to kill all of them? DARLING: Yeah. I think this might have been my partner's idea. So I did this with a friend named Hannes Gassert. We did this at a conference called Lift in Geneva. And we had to improvise because people really didn't want to do it. So we threatened them. (LAUGHTER)DARLING: And finally, someone did. VEDANTAM: Samantha clearly doesn't want you to harm her. DARLING: Yeah, clearly, clearly. VEDANTAM: So what do you think is going on? I mean, at a rational level, the dinosaur obviously is not alive. Why do you think we have such reluctance to harming the dinosaur? In fact, I might have the battery removed so the dinosaur stops making noise. DARLING: Well, I mean, it behaves in a really lifelike way. I mean, we have over a century of animation expertise in creating compelling characters that are very lifelike that people will automatically project life onto. I mean, look at, you know, Pixar movies, for example. It's incredible. And I know that a lot of social roboticists actually work with animators to create these compelling characters. And so, you know, it's very hard to not see this as some sort of living entity, even though you know perfectly well that it's just a machine because it's moving in this way that we automatically subconsciously associate with states of mind. And so I just think it's really uncomfortable to people, particularly for robots like this that can display, you know, a simulation of pain or discomfort, to have to watch that. I mean, it's just not comfortable. VEDANTAM: What did you find in terms of who was willing to do it and who wasn't? I mean, when you looked at the people who were willing to destroy a dinosaur, a dinosaur like the PLEO, you found that there were certain characteristics that were attached to people who were more or less likely to do the deed. DARLING: So the follow-up study that we did, not with the dinosaurs, we did with HEXBUGs, which are a very simple toy that moves around like an insect. And there, we were looking at people's hesitation to hit the HEXBUG and whether they would hesitate more if we gave it a name and whether they would hesitate more if they had natural tendencies for empathy, for empathic concern. And, you know, we found that people with low empathic concern for other people, they didn't much care about the HEXBUG and would hit it much more quickly. And people with high empathic concern would hesitate more. And some even refused to hit the HEXBUGs. VEDANTAM: So in many ways, what you're saying is that potentially the way we relate to these inanimate objects might actually say something about us at a deeper level than just our relationship to the machine. DARLING: Yes, possibly. I mean, we know now, or we have some indication that we can measure people's empathy using robots, which is pretty interesting. VEDANTAM: You know, my colleagues and I were discussing ahead of this interview whether you would actually destroy the dinosaur. And we were torn because we said, on the one hand, you of all people should know that these are just machines, and that it's an irrational belief to project lifelike values on them. But on the other hand, I said, you know, it's really unlikely she's going to do it because she's going to look like a really bad person if she smashes the dinosaur in front of 200 people. DARLING: I mean, I don't know if you've been watching \"Westworld\" at all, but the people who don't hesitate to shoot the robots, they seem pretty callous to us. It's - I - and I think maybe there is something to it. Of course, we can rationalize it. Of course, you know, if I had to, I could take the hammer and smash the robot, and, you know, I wouldn't have nightmares about it. But I think that perhaps turning off that basic instinct to hesitate to do that might be more harmful than override. You know, I think overriding it might be more harmful than just going with it. VEDANTAM: I want to talk about the most important line we draw between machines and humans, and it's not intelligence, but it's consciousness. I want to play you a little clip from \"Star Trek. \"(SOUNDBITE OF TV SHOW, \"STAR TREK: THE NEXT GENERATION\")PATRICK STEWART: (As Captain Jean-Luc Picard) Now tell me, Commander. What is Data? BRIAN BROPHY: (As Commander Bruce Maddox) I don't understand. STEWART: (As Captain Jean-Luc Picard) What is he? BROPHY: (As Commander Bruce Maddox) A machine. STEWART: (As Captain Jean-Luc Picard) Is he? Are you sure? BROPHY: (As Commander Bruce Maddox) Yes. STEWART: (As Captain Jean-Luc Picard) You see, he's met two of your three criteria for sentience, so what if he meets the third - consciousness - in even the smallest degree? What is he then? I don't know. Do you? VEDANTAM: So this has been a perennial concern in science fiction, which is the idea that at some point machines will become conscious and sentient. And very often, it's in the context of, you know, the machines will rise up and harm the humans and destroy us. But as I read your research, I actually found myself thinking, is our desire to believe that the machines can become conscious actually just an extension of what we've been talking about the last 20 minutes? Which is we project sentience onto machines all the time. And so when we imagine what they're going to be like in the future, the first thing that pops in our head is they're going to become conscious. DARLING: Yeah. I think there's a lot of projection happening there. I also think that before we get to the question of robot rights and consciousness, you know, we have to ask ourselves, how do robots fit into our lives when we perceive them as conscious? Because I think that's when it starts to get morally messy and not when they actually inherently have some sort of consciousness. (SOUNDBITE OF MUSIC)VEDANTAM: There's a lot that's morally messy about how humans interact with robots. When we come back, we're going to delve into some of those moral and ethical issues, including the deeply troubling case of a Japanese company that builds sex robots designed to look like children. Stay with us. (SOUNDBITE OF MUSIC)VEDANTAM: This is HIDDEN BRAIN. I'm Shankar Vedantam. If humans have a tendency to anthropomorphize machines, to see them as human, it isn't surprising that we're all so willing to bring all the biases we have toward our fellow human beings into the machine world. Many of the intelligent assistants being built by major companies - Siri or Alexa - are being given women's names. Many of the genius machines are often given men's names - HAL or Watson. Now, you can say Siri and Alexa aren't people, why should we care? Why should we care if people sexually harass their virtual assistants, as has been shown to sometimes happen? MIT's Kate Darling says we should care because the way we treat robots may have implications for the way we treat other human beings. DARLING: It might. We don't know but it might. And one example with the virtual assistants you just mentioned is children. So parents have started observing. And this this is anecdotal but they've started observing that their kids adopt behavioral patterns based on how they're interacting with these devices and how they're conversing with them. And there are some cool stories. Like there was story in The New York Times a few years ago where a mother was talking about how her autistic son had developed a relationship with Siri, the voice assistant. And she said this was awesome because Siri is very patient. She will answer questions repeatedly and consistently. And apparently, this is really important for autistic kids. But also because her voice recognition is so bad, he learned to articulate his words really clearly. And it improved his communication with others. Now, that's great, but these things aren't designed with autistic kids in mind, right? That's kind of more of a coincidence than anything. And so there are also perhaps some unintended effects that are more negative. And so one guy wrote a blog post a while back where he said Amazon's Echo is magical but it's turning my child into an [expletive] because Alexa doesn't require please or thank you or any of the standard politeness that you want your kids to learn when they're conversing and when they're, you know, demanding things of you. So, you know, it starts there. But I think that as this technology improves and gets better at mimicking real conversations or life-like behavior, you have to wonder to what extent that gets muddled in our subconscious and not just in children's subconscious but maybe even in our own. VEDANTAM: Do you think it's a coincidence that most of the virtual assistants are given female names and female identities? DARLING: I think it's a combination of whatever market research but also just people not thinking. I mean, I visited IBM Watson in Austin. And there is a room that you can go into, and you can talk to Watson. And he has this deep booming male voice. And you can ask questions. And at the time I went there, there was this second AI in the room that turned on the lights and greeted the visitors. And that one had a female voice. And I pointed that out. And it seemed like they hadn't really considered that. So it's, you know, it's a mixture of people thinking, oh, this is going to sell better and people just not thinking at all because the teams that are building this technology are predominantly young, white and male. And they have these blind spots where they don't even consider what biases they might perpetuate through the design of these systems. VEDANTAM: So which brings us to the question of sex robots. I'm curious what you make of this. And there are really complicated arguments on both sides of this question. Should we use machines as, you know, sexual companions? Should we use them in ways that could potentially satisfy the needs of groups of people who in some ways we are troubled by? DARLING: Yeah. So, you know, referring to pedophilia specifically, this is a very difficult area because we know almost nothing about pedophilia generally. And we have absolutely no idea what the effects of technologies like this could be if they provide kind of an immersive sexual experience. I mean, it could be that this is a very useful outlet to use therapeutically - yeah,VEDANTAM: A safety valve. DARLING: . . . Basically - that ends up preventing real child abuse. And on the other hand, it could be that this is something that normalizes and perpetuates certain behaviors. And we literally have no idea what direction this goes in. And I think this is a question that we're going to be facing pretty soon. I mean, like you said, there are companies that make the dolls. There's legal cases already about this. And there's a lot of moral panic about sex technology but also, I mean, in this case, very understandable emotional responses to, you know, regulation of child abuse. So it's very difficult. And you can't research it - in the U. S. , at least. VEDANTAM: So you're sometimes called a robot ethicist. And you've sometimes said we might need to establish a limited legal status for robots. What do you mean by that? DARLING: Yeah. It's a little bit of a provocation. But my sense is that, you know, if we have evidence that behaving violently towards very lifelike objects not only tells us something about you as a person but can also change people and desensitize them to that behavior in other contexts. So, you know, if you're used to kicking a robot dog, you know, are you more likely to kick a real dog? Then that might actually be an argument, if that's the case, to give robots certain legal protections the same way that we give animals protections but for a different reason. We like to tell ourselves that we give animals protection from abuse because they actually experience pain and suffering. I actually don't think that's the only reason we do it. But for robots, the idea would be not that they experience anything, but rather that it's desensitizing to us and it has a negative effect on our behavior to be abusive towards the robots. VEDANTAM: So here's a thing that's sort of - it's worth sort of pondering for a moment. If you hear, for example, that someone owns a bunch of chickens in their farm, right? So it's their farm, their chickens. They own the chickens. And they're really mistreating the chickens, torturing them, harming them. You could sort of make a property rights argument and say they can do whatever they want with their property, but I think many of us would say even though the chicken belongs to you, there are certain things you can and cannot do with the chicken. And I'm not sure it's just about our concern that if you mistreat the chicken, that means you will turn into the kind of person who might mistreat other people. There's sort of a level. There's a certain moral level at which I think the idea of abusing animals is offensive to us. But I'm wondering the same thing is true with machines as well, which is it's not just the case that it might be that people who harm machines are also willing to harm humans but just the act of harming things that look and feel and sound sentient is morally offensive in some way. DARLING: Yeah. So I think that's absolutely how we've approached most animal protections because it's also - it's very clear that we care more about certain animals than others and not based on any biological criteria. So I think that we just find it morally offensive, for example, to torture cats. Or, you know, in the United States, we don't like the idea of eating horses. But in Europe, they're like, what's the difference between a horse and a cow? They're both delicious. So there's - that's definitely how we tend to operate and how we tend to pass these laws. And I don't see why that couldn't also apply to machines once they get to a more advanced level where we really do perceive them as lifelike and it is really offensive to us to see them be abused. VEDANTAM: The Devil's Advocate side of that argument, of course, is that would people then say pressing a switch and turning off a machine, that's unethical because you're essentially killing the robot? DARLING: But we don't protect animals from being killed. We just protect them from being treated unnecessarily cruelly. So I actually think animal abuse laws are a pretty good parallel here. VEDANTAM: You argue that robots might one day expand the boundaries of how humans relate to one another. I want to play you a short clip from the movie \"Her,\" where a man falls in love with his operating system but then discovers something about her. (SOUNDBITE OF FILM, \"HER\")JOAQUIN PHOENIX: (As Theodore) Are you in love with anyone else? SCARLETT JOHANSSON: (As Samantha) What makes you ask that? PHOENIX: (As Theodore) I don't know. Are you? JOHANSSON: (As Samantha) I've been trying to figure out how to talk to you about this. PHOENIX: (As Theodore) How many others? JOHANSSON: (As Samantha) Six hundred forty-one. PHOENIX: (As Theodore) What? What are you talking about? That's insane. That's [expletive] insane. VEDANTAM: So I'm wondering, Kate, is it possible that as we start to relate to machines, is it possible that they will change the range of ways we relate to one another? In other words, is it possible they'll expand how we think about relationships themselves? DARLING: Maybe. But I think it's important to remember - the thing that I couldn't get out of my mind when I was watching \"Her\" specifically is that there is a company that makes this operating system. And if I were the company, I would be like - I would program it to say, oh, yes, I'm seeing 641 other people, but for $20,000, you can get exclusively me. (LAUGHTER)DARLING: I - like, that's the direction it's going to go in, right? It's not that the machines are going to become conscious and, you know, develop their own forms of relationship. VEDANTAM: You mentioned \"Westworld\" some moments ago, and I want to play a clip from \"Westworld. \" For those of you who haven't seen \"Westworld,\" humans interact with robots in - robots are extremely lifelike, so lifelike that it's sometimes difficult to tell whether you are talking to a robot or you're talking to a human. In the scene that I'm about to play you, a man named William interacts with a woman who may or may not be a robot. (SOUNDBITE OF TV SHOW, \"WESTWORLD\")UNIDENTIFIED ACTRESS: (As character) You want to ask, so ask. JIMMI SIMPSON: (As William) Are you real? UNIDENTIFIED ACTRESS: (As character) Well, if you can't tell, does it matter? VEDANTAM: So as I watched this scene and as I read your work, I actually had a thought. And I wanted to sort of run this thought experiment by you. Which is that, you know, on one end of the spectrum, we have these machines that are increasingly becoming lifelike, human-like. You know, they respond in very intelligent ways. They seem as if they're alive. And on the other hand, we're learning all kinds of things about human beings that show us that even the most complex aspects of our minds are governed by a set of rules and laws. And in some ways, our minds function a little bit like machines. And I'm wondering, is there really a huge distinction? Is it possible - is the real question not so much can machines become more human-like, but is it actually possible that humans are actually just highly evolved machines? DARLING: I have no doubt that we are highly evolved machines. I don't think we understand how we work yet. And I don't think we're going to get to that understanding anytime soon. But yeah, I think - I do think that follow a set of rules and that we're essentially programmed. I don't tend - so I don't distinguish between souls and other entities without souls. And so it's much easier for me to say, yeah, it's probably all the same. But I can see that other people would find that distinction difficult. VEDANTAM: Do you ever talk about this? Do you ever run this by other people and sort of say - do you tell your husband, for example, I like you very much, but I think you're a really intelligent machine that I love dearly? DARLING: (Laughter) I haven't explicitly said that to him, but. . . (LAUGHTER)VEDANTAM: When you go home from this trip. DARLING: Yeah. We'll see how that goes. VEDANTAM: Kate Darling is a research specialist at the MIT Media Lab. Our conversation today was taped before a live audience at the hotel Jerome in Aspen, Colo. , as part of the Aspen Ideas Festival. Kate, thank you for joining me today on HIDDEN BRAIN. DARLING: Thank you so much. (APPLAUSE)VEDANTAM: This week's show was produced by Tara Boyle and Renee Klahr. Our team includes Jenny Schmidt, Maggie Penman, Rhaina Cohen and Parth Shah. Our unsung heroes this week are the staff of the Annabelle Inn in Aspen, Colo. They kindly let us take over that conference center for several interviews with researchers who were in town for the Aspen Ideas Festival. They even turned off the fountains in their outdoor seating area so that we'd have studio-quality sound while recording. Marie Casanova (ph), Doug Parks (ph), Mike Clemons (ph), thanks so much for your hospitality and your willingness to help us make a little bit of audio magic. You can find photos and a video of Samantha, our PLEO dinosaur, on our Instagram page. We're also on Facebook and Twitter. And if you enjoyed this week's show, we'd love if you shared this episode with friends on social media. I'm Shankar Vedantam, and this is NPR. (SOUNDBITE OF MUSIC)DARLING: There we go. It just mooed like a cow. SHANKAR VEDANTAM, HOST:This is HIDDEN BRAIN. I'm Shankar Vedantam. (SOUNDBITE OF MUSIC)VEDANTAM: Have you ever talked to your computer, cursed it for making a mistake? (SOUNDBITE OF FILM, \"OFFICE SPACE\")DAVID HERMAN: (As Michael Bolton) PC LOAD LETTER, what the [expletive] does that mean? VEDANTAM: Have you ever argued with the traffic directions you get from Google Maps or Waze? (SOUNDBITE OF ARCHIVED RECORDING)AUTOMATED VOICE: Starting route to Grover's Mill Road. Head North on. . . VEDANTAM: Have you ever looked at a Roomba cleaning the floor on the other side of the room and told it, please come over to this side, turn left, left? (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED MAN: It just ran itself right off of the edge. VEDANTAM: Robots and artificial intelligence are playing an ever larger role in all of our lives. Of course, this is not the role that science fiction once imagined. (SOUNDBITE OF FILM, \"THE TERMINATOR\")MICHAEL BIEHN: (As Kyle Reese) It doesn't feel pity or remorse or fear. VEDANTAM: Robots bent on our destruction remain the stuff of movies like \"Terminator. \" And robot sentience is still an idea that's far off in the future. But there's a lot we're learning about smart machines, and there's a lot that smart machines are teaching us about how we connect with the world around us and with each other. This week on HIDDEN BRAIN, can robots teach us what it means to be human? (SOUNDBITE OF MUSIC)VEDANTAM: My guest today has spent a lot of time thinking about how we interact with smart machines and how those interactions might change the way we relate to one another. Kate Darling is a research specialist at the MIT Media Lab. She joined us recently in front of a live audience at the Hotel Jerome in Aspen, Colo. , as part of the Aspen Ideas Festival. Also on stage was a robot, a green robot dinosaur about the size of a small dog known as a PLEO. It's going to be part of this conversation. But before we get to that, here's Kate. (APPLAUSE)VEDANTAM: Kate, welcome to HIDDEN BRAIN. KATE DARLING: Thank you for having me. VEDANTAM: You find that there is an interesting point in the relationship between humans and machines. And that point comes when we give a machine a name. I understand that you have three of these PLEO dinosaurs at your home. Can you tell me some of the names that you have given to your robots? DARLING: Yes. So the very first one I bought I named Yochai after Yochai Benkler, who's a Harvard professor who's done some work in intellectual property and other areas that I've always admired. And the second one I adopted after I filmed a Canadian documentary where the show host had to name the robot. And he gave the robot the same name he had, which was Peter (ph). So the second one has a boring name. And then. . . (LAUGHTER)DARLING: . . . The third one is named Mr. Spaghetti. I don't know if people outside of Boston are familiar with this, but the Boston public transportation system, they wanted to crowdsource a name for their mascot dog. And the Internet decided that the dog should be named Mr. Spaghetti. And, of course, they refused to do that and named the dog Hunter. So Mr. Spaghetti became a big thing in Boston for a while. It was - people were very outraged about this. And so I named my PLEO - my third one - Mr. Spaghetti. VEDANTAM: I understand that companies actually have found that if you sell a robot with the name of the robot on the box, it changes the way people will interact with that robot than if you just said, this is a dinosaur. DARLING: So this is - yeah - this is not - I don't have any data on this, but, yes, I have talked to companies who feel that it helps with adoption and trust of the technology. Even very, very simple robots like boxes on wheels that deliver medicine in hospitals, if you give them a little nameplate that says Betsy (ph), their understanding is that people are a little bit more forgiving of the robot. So instead of this stupid machine doesn't work, they'll say, oh, Betsy made a mistake. (LAUGHTER)VEDANTAM: And I'm wondering if you've spent time thinking about why this happens. At some level, if I came up to you at home and I said, Kate, is Mr. Spaghetti alive? You would almost certainly tell me, no, Mr. Spaghetti's not alive. I assume you don't think Mr. Spaghetti is alive, right? DARLING: No. VEDANTAM: OK. So. . . (LAUGHTER)VEDANTAM: . . . Given that you know that Mr. Spaghetti's not alive, why do you think giving him a name changes your relationship to him? DARLING: With robots in particular, it's combined with just our general tendency to anthropomorphize these things. And we're also primed by science fiction and pop culture to give robots names and view them as entities with personalities. And it's more than just the name, right? I mean, robots move around in a way that seems autonomous to us. We respond to that type of physical movement. Our brains will project intent onto it. So I think robots are the perfect mixture of something that we will very willingly treat with human qualities or lifelike qualities. VEDANTAM: I understand from one of your papers that there have been examples, especially in military settings, where robots have been assigned to do very dangerous tasks because you don't want human beings to go out and do those tasks. But eventually, the military folks who are running the robots start to relate to them as if they were actually fellow soldiers. DARLING: There's been some research on this. So Julie Carpenter has done some research. And there's just countless stories online, on Reddit, everywhere about soldiers becoming emotionally attached to the bomb disposal robots that they work with. They'll give them names. They'll give them medals of honor. They'll have funerals for them. And, you know, it's also kind of interesting because the robots aren't special robots. They're just kind of sticks on wheels. But I think just also the situation that the soldiers find themselves in, where the robot is basically risking its life to save human lives, might also lead them to become very attached to these devices. VEDANTAM: You had a wonderful example some time ago looking at a colonel, I believe - I don't know if this was your work or you were citing someone else's work - of a colonel who was supervising a robot that was doing sort of mine disposal. Tell us the story about the mine disposal robot. DARLING: Oh, yeah, this is an incredible - it was an article in The Washington Post, I believe, back in 2007. And the United States military was testing this new robot that could walk over a field with landmines and diffuse them by stepping on them and blowing them up. And the robot itself was shaped like a stick insect. So it would walk around on six legs. And every time it stepped on a landmine, one of the legs would blow up. And then it would just continue on the remaining legs. And so they were testing this. And the colonel who was in charge of this exercise ended up calling it off because he said it was too inhumane to watch this thing drag itself across the field on its remaining legs. (LAUGHTER)VEDANTAM: And so this raises sort of an interesting question because, on the one hand, we can understand how this desire to anthropomorphize robots is very human in some ways. But in some ways - in this case, that defeats the whole point of having a robot that's trying to find the mines. DARLING: It does. I mean, it's really anything from inefficient to dangerous in these contexts where we want robots to be strictly used as tools to anthropomorphize them. And it's a very difficult design challenge as well because how do you create a device that people want to use but don't like too much? VEDANTAM: All right. So we have this wonderful little prop in front of us. It's a PLEO dinosaur. I want you to tell me a little bit about the PLEO dinosaur - how it works and how you've come to own three of them, Kate. DARLING: (Laughter). VEDANTAM: What is the dinosaur? What does it do? DARLING: It's basically an expensive toy. I bought the first one, I think, in 2007. There we go. It's awake. They have a lot of motors and touch sensors. And they have an infrared camera and microphones. So they're pretty cool pieces of technology for a toy. And that's initially why I bought one because I was fascinated by everything that it can do. Like, if it starts walking around, it can walk to the edge of the table. It can look down, measure the distance to the floor. It knows that there's a drop, and it'll get scared and walk backwards. (LAUGHTER)DARLING: And then they go through different life phases - adolescent and fully grown. And, you know, it'll have moods and. . . VEDANTAM: So I think what we should do - we bought the robot at HIDDEN BRAIN a couple of weeks ago. We haven't had a chance to give it a name yet. And I thought we should actually reserve the honors for this evening where we're talking to Kate and see if Kate wants to try and name this dinosaur, you know, since she cares about dinosaurs so much. I was looking up Kate's Twitter feed this morning. I understand that you're going to have a baby soon. Congratulations. DARLING: Yes, I don't have a name for that, either. VEDANTAM: OK. (LAUGHTER)VEDANTAM: Just FYI, she sometimes refers to the baby as baby bot, so just - for whatever that's worth. And one retweet that you have on your Twitter feed cracked me up. It said, you don't really know how many people you don't like until you start trying to pick baby names. (LAUGHTER)DARLING: Yeah, that was - that's a quote from my husband. (LAUGHTER)VEDANTAM: So I don't want you to tell me - you apparently haven't yet picked your baby's name. So do you have any choices, of top choices? Or is there a name, a spare name that you might care to give the dinosaur? DARLING: Well, the problem is we've had a girl's name picked out for years and now we're having a boy. And we just can't - we don't even have any contenders. VEDANTAM: No contenders. What was - what would have been your favorite girl's name if it had - if you had had a girl? DARLING: Well, so when I first started dating my now-husband, he at some point said, if I ever had a daughter, I already know what I would name her. And I was like, oh, really? We're going to fight about this one. And he said, yeah, I would name her Samantha and Sam for short because Sam is kind of gender neutral. And I was like, oh, I really love that. So that one was picked out very easily. VEDANTAM: All right, since you're not having a girl, you're going to have a boy, would you mind if you considered naming the dinosaur Samantha? How would you feel about that? DARLING: Oh, that would be awesome. We should name the dinosaur Samantha. VEDANTAM: All right, so henceforth, this dinosaur will be called Samantha. . . DARLING: Yay. VEDANTAM: . . . Or Sam for short. (APPLAUSE)VEDANTAM: Now, some time ago, Kate conducted a very interesting experiment with the PLEO dinosaurs. And to sort of show how this works, I have a second prop here which is under the table. DARLING: Uh-oh. VEDANTAM: It's a hammer, a large hammer which we borrowed from the hotel. Now, as you all know, the dinosaur is obviously not alive. It's just cloth and plastic and a battery and wires. It has a name, of course, Samantha, but. . . (LAUGHTER)VEDANTAM: . . . It isn't alive in any sense of the term. And so Kate, I'm going to actually give you the hammer. DARLING: Oh, no. (LAUGHTER)VEDANTAM: Kate, would you consider destroying Samantha? DARLING: No. (LAUGHTER)VEDANTAM: It's just a machine. DARLING: I only make other people do that. I don't do it myself. (LAUGHTER)VEDANTAM: You wouldn't even consider harming the dinosaur? DARLING: Well, so my problem is that I already know the results of our research. And that would say something about me as a person, so I'm going to say no, I'm not willing to do it. (LAUGHTER)VEDANTAM: Tell me about the experiment. So you had volunteers come up, and you basically introduced them to these lovable dinosaurs. And then you give them a hammer like this. And you told them to do what? DARLING: Well, so - OK, so this was the workshop part that we used the dinosaurs for. They're a little too expensive to do an experiment with a hundred participants. So the workshop that we did, in a nonscientific setting, we had five of these robot dinosaurs. We gave them to groups of people and had them name them, interact with them, play with them. We had them personify them a little bit by doing a little fashion show with - and a fashion contest. And then after about an hour, we asked them to torture and kill them. And we had a variety of instruments. We had a hammer, a hatchet and I forget what else. And - but like even though we tried to make it dramatic, it turned out to be a little bit more dramatic than we expected it to be. And they really refused to even hit the things. And so we had to kind of start playing mind games with them. We said, OK, you can save your group's dinosaur if you hit another group's dinosaur with the hammer. VEDANTAM: Oh, my gosh. (LAUGHTER)DARLING: And they tried. And they couldn't do that, either. This one woman was standing over the thing trying and she just couldn't. She ended up petting it instead. (LAUGHTER)DARLING: And then, finally, we said, OK, well, we're going to destroy all of the robots unless someone takes a hatchet to one of them. And finally, someone did. VEDANTAM: Wait, so you said unless one of you kills one of them, we are going to kill all of them? DARLING: Yeah. I think this might have been my partner's idea. So I did this with a friend named Hannes Gassert. We did this at a conference called Lift in Geneva. And we had to improvise because people really didn't want to do it. So we threatened them. (LAUGHTER)DARLING: And finally, someone did. VEDANTAM: Samantha clearly doesn't want you to harm her. DARLING: Yeah, clearly, clearly. VEDANTAM: So what do you think is going on? I mean, at a rational level, the dinosaur obviously is not alive. Why do you think we have such reluctance to harming the dinosaur? In fact, I might have the battery removed so the dinosaur stops making noise. DARLING: Well, I mean, it behaves in a really lifelike way. I mean, we have over a century of animation expertise in creating compelling characters that are very lifelike that people will automatically project life onto. I mean, look at, you know, Pixar movies, for example. It's incredible. And I know that a lot of social roboticists actually work with animators to create these compelling characters. And so, you know, it's very hard to not see this as some sort of living entity, even though you know perfectly well that it's just a machine because it's moving in this way that we automatically subconsciously associate with states of mind. And so I just think it's really uncomfortable to people, particularly for robots like this that can display, you know, a simulation of pain or discomfort, to have to watch that. I mean, it's just not comfortable. VEDANTAM: What did you find in terms of who was willing to do it and who wasn't? I mean, when you looked at the people who were willing to destroy a dinosaur, a dinosaur like the PLEO, you found that there were certain characteristics that were attached to people who were more or less likely to do the deed. DARLING: So the follow-up study that we did, not with the dinosaurs, we did with HEXBUGs, which are a very simple toy that moves around like an insect. And there, we were looking at people's hesitation to hit the HEXBUG and whether they would hesitate more if we gave it a name and whether they would hesitate more if they had natural tendencies for empathy, for empathic concern. And, you know, we found that people with low empathic concern for other people, they didn't much care about the HEXBUG and would hit it much more quickly. And people with high empathic concern would hesitate more. And some even refused to hit the HEXBUGs. VEDANTAM: So in many ways, what you're saying is that potentially the way we relate to these inanimate objects might actually say something about us at a deeper level than just our relationship to the machine. DARLING: Yes, possibly. I mean, we know now, or we have some indication that we can measure people's empathy using robots, which is pretty interesting. VEDANTAM: You know, my colleagues and I were discussing ahead of this interview whether you would actually destroy the dinosaur. And we were torn because we said, on the one hand, you of all people should know that these are just machines, and that it's an irrational belief to project lifelike values on them. But on the other hand, I said, you know, it's really unlikely she's going to do it because she's going to look like a really bad person if she smashes the dinosaur in front of 200 people. DARLING: I mean, I don't know if you've been watching \"Westworld\" at all, but the people who don't hesitate to shoot the robots, they seem pretty callous to us. It's - I - and I think maybe there is something to it. Of course, we can rationalize it. Of course, you know, if I had to, I could take the hammer and smash the robot, and, you know, I wouldn't have nightmares about it. But I think that perhaps turning off that basic instinct to hesitate to do that might be more harmful than override. You know, I think overriding it might be more harmful than just going with it. VEDANTAM: I want to talk about the most important line we draw between machines and humans, and it's not intelligence, but it's consciousness. I want to play you a little clip from \"Star Trek. \"(SOUNDBITE OF TV SHOW, \"STAR TREK: THE NEXT GENERATION\")PATRICK STEWART: (As Captain Jean-Luc Picard) Now tell me, Commander. What is Data? BRIAN BROPHY: (As Commander Bruce Maddox) I don't understand. STEWART: (As Captain Jean-Luc Picard) What is he? BROPHY: (As Commander Bruce Maddox) A machine. STEWART: (As Captain Jean-Luc Picard) Is he? Are you sure? BROPHY: (As Commander Bruce Maddox) Yes. STEWART: (As Captain Jean-Luc Picard) You see, he's met two of your three criteria for sentience, so what if he meets the third - consciousness - in even the smallest degree? What is he then? I don't know. Do you? VEDANTAM: So this has been a perennial concern in science fiction, which is the idea that at some point machines will become conscious and sentient. And very often, it's in the context of, you know, the machines will rise up and harm the humans and destroy us. But as I read your research, I actually found myself thinking, is our desire to believe that the machines can become conscious actually just an extension of what we've been talking about the last 20 minutes? Which is we project sentience onto machines all the time. And so when we imagine what they're going to be like in the future, the first thing that pops in our head is they're going to become conscious. DARLING: Yeah. I think there's a lot of projection happening there. I also think that before we get to the question of robot rights and consciousness, you know, we have to ask ourselves, how do robots fit into our lives when we perceive them as conscious? Because I think that's when it starts to get morally messy and not when they actually inherently have some sort of consciousness. (SOUNDBITE OF MUSIC)VEDANTAM: There's a lot that's morally messy about how humans interact with robots. When we come back, we're going to delve into some of those moral and ethical issues, including the deeply troubling case of a Japanese company that builds sex robots designed to look like children. Stay with us. (SOUNDBITE OF MUSIC)VEDANTAM: This is HIDDEN BRAIN. I'm Shankar Vedantam. If humans have a tendency to anthropomorphize machines, to see them as human, it isn't surprising that we're all so willing to bring all the biases we have toward our fellow human beings into the machine world. Many of the intelligent assistants being built by major companies - Siri or Alexa - are being given women's names. Many of the genius machines are often given men's names - HAL or Watson. Now, you can say Siri and Alexa aren't people, why should we care? Why should we care if people sexually harass their virtual assistants, as has been shown to sometimes happen? MIT's Kate Darling says we should care because the way we treat robots may have implications for the way we treat other human beings. DARLING: It might. We don't know but it might. And one example with the virtual assistants you just mentioned is children. So parents have started observing. And this this is anecdotal but they've started observing that their kids adopt behavioral patterns based on how they're interacting with these devices and how they're conversing with them. And there are some cool stories. Like there was story in The New York Times a few years ago where a mother was talking about how her autistic son had developed a relationship with Siri, the voice assistant. And she said this was awesome because Siri is very patient. She will answer questions repeatedly and consistently. And apparently, this is really important for autistic kids. But also because her voice recognition is so bad, he learned to articulate his words really clearly. And it improved his communication with others. Now, that's great, but these things aren't designed with autistic kids in mind, right? That's kind of more of a coincidence than anything. And so there are also perhaps some unintended effects that are more negative. And so one guy wrote a blog post a while back where he said Amazon's Echo is magical but it's turning my child into an [expletive] because Alexa doesn't require please or thank you or any of the standard politeness that you want your kids to learn when they're conversing and when they're, you know, demanding things of you. So, you know, it starts there. But I think that as this technology improves and gets better at mimicking real conversations or life-like behavior, you have to wonder to what extent that gets muddled in our subconscious and not just in children's subconscious but maybe even in our own. VEDANTAM: Do you think it's a coincidence that most of the virtual assistants are given female names and female identities? DARLING: I think it's a combination of whatever market research but also just people not thinking. I mean, I visited IBM Watson in Austin. And there is a room that you can go into, and you can talk to Watson. And he has this deep booming male voice. And you can ask questions. And at the time I went there, there was this second AI in the room that turned on the lights and greeted the visitors. And that one had a female voice. And I pointed that out. And it seemed like they hadn't really considered that. So it's, you know, it's a mixture of people thinking, oh, this is going to sell better and people just not thinking at all because the teams that are building this technology are predominantly young, white and male. And they have these blind spots where they don't even consider what biases they might perpetuate through the design of these systems. VEDANTAM: So which brings us to the question of sex robots. I'm curious what you make of this. And there are really complicated arguments on both sides of this question. Should we use machines as, you know, sexual companions? Should we use them in ways that could potentially satisfy the needs of groups of people who in some ways we are troubled by? DARLING: Yeah. So, you know, referring to pedophilia specifically, this is a very difficult area because we know almost nothing about pedophilia generally. And we have absolutely no idea what the effects of technologies like this could be if they provide kind of an immersive sexual experience. I mean, it could be that this is a very useful outlet to use therapeutically - yeah,VEDANTAM: A safety valve. DARLING: . . . Basically - that ends up preventing real child abuse. And on the other hand, it could be that this is something that normalizes and perpetuates certain behaviors. And we literally have no idea what direction this goes in. And I think this is a question that we're going to be facing pretty soon. I mean, like you said, there are companies that make the dolls. There's legal cases already about this. And there's a lot of moral panic about sex technology but also, I mean, in this case, very understandable emotional responses to, you know, regulation of child abuse. So it's very difficult. And you can't research it - in the U. S. , at least. VEDANTAM: So you're sometimes called a robot ethicist. And you've sometimes said we might need to establish a limited legal status for robots. What do you mean by that? DARLING: Yeah. It's a little bit of a provocation. But my sense is that, you know, if we have evidence that behaving violently towards very lifelike objects not only tells us something about you as a person but can also change people and desensitize them to that behavior in other contexts. So, you know, if you're used to kicking a robot dog, you know, are you more likely to kick a real dog? Then that might actually be an argument, if that's the case, to give robots certain legal protections the same way that we give animals protections but for a different reason. We like to tell ourselves that we give animals protection from abuse because they actually experience pain and suffering. I actually don't think that's the only reason we do it. But for robots, the idea would be not that they experience anything, but rather that it's desensitizing to us and it has a negative effect on our behavior to be abusive towards the robots. VEDANTAM: So here's a thing that's sort of - it's worth sort of pondering for a moment. If you hear, for example, that someone owns a bunch of chickens in their farm, right? So it's their farm, their chickens. They own the chickens. And they're really mistreating the chickens, torturing them, harming them. You could sort of make a property rights argument and say they can do whatever they want with their property, but I think many of us would say even though the chicken belongs to you, there are certain things you can and cannot do with the chicken. And I'm not sure it's just about our concern that if you mistreat the chicken, that means you will turn into the kind of person who might mistreat other people. There's sort of a level. There's a certain moral level at which I think the idea of abusing animals is offensive to us. But I'm wondering the same thing is true with machines as well, which is it's not just the case that it might be that people who harm machines are also willing to harm humans but just the act of harming things that look and feel and sound sentient is morally offensive in some way. DARLING: Yeah. So I think that's absolutely how we've approached most animal protections because it's also - it's very clear that we care more about certain animals than others and not based on any biological criteria. So I think that we just find it morally offensive, for example, to torture cats. Or, you know, in the United States, we don't like the idea of eating horses. But in Europe, they're like, what's the difference between a horse and a cow? They're both delicious. So there's - that's definitely how we tend to operate and how we tend to pass these laws. And I don't see why that couldn't also apply to machines once they get to a more advanced level where we really do perceive them as lifelike and it is really offensive to us to see them be abused. VEDANTAM: The Devil's Advocate side of that argument, of course, is that would people then say pressing a switch and turning off a machine, that's unethical because you're essentially killing the robot? DARLING: But we don't protect animals from being killed. We just protect them from being treated unnecessarily cruelly. So I actually think animal abuse laws are a pretty good parallel here. VEDANTAM: You argue that robots might one day expand the boundaries of how humans relate to one another. I want to play you a short clip from the movie \"Her,\" where a man falls in love with his operating system but then discovers something about her. (SOUNDBITE OF FILM, \"HER\")JOAQUIN PHOENIX: (As Theodore) Are you in love with anyone else? SCARLETT JOHANSSON: (As Samantha) What makes you ask that? PHOENIX: (As Theodore) I don't know. Are you? JOHANSSON: (As Samantha) I've been trying to figure out how to talk to you about this. PHOENIX: (As Theodore) How many others? JOHANSSON: (As Samantha) Six hundred forty-one. PHOENIX: (As Theodore) What? What are you talking about? That's insane. That's [expletive] insane. VEDANTAM: So I'm wondering, Kate, is it possible that as we start to relate to machines, is it possible that they will change the range of ways we relate to one another? In other words, is it possible they'll expand how we think about relationships themselves? DARLING: Maybe. But I think it's important to remember - the thing that I couldn't get out of my mind when I was watching \"Her\" specifically is that there is a company that makes this operating system. And if I were the company, I would be like - I would program it to say, oh, yes, I'm seeing 641 other people, but for $20,000, you can get exclusively me. (LAUGHTER)DARLING: I - like, that's the direction it's going to go in, right? It's not that the machines are going to become conscious and, you know, develop their own forms of relationship. VEDANTAM: You mentioned \"Westworld\" some moments ago, and I want to play a clip from \"Westworld. \" For those of you who haven't seen \"Westworld,\" humans interact with robots in - robots are extremely lifelike, so lifelike that it's sometimes difficult to tell whether you are talking to a robot or you're talking to a human. In the scene that I'm about to play you, a man named William interacts with a woman who may or may not be a robot. (SOUNDBITE OF TV SHOW, \"WESTWORLD\")UNIDENTIFIED ACTRESS: (As character) You want to ask, so ask. JIMMI SIMPSON: (As William) Are you real? UNIDENTIFIED ACTRESS: (As character) Well, if you can't tell, does it matter? VEDANTAM: So as I watched this scene and as I read your work, I actually had a thought. And I wanted to sort of run this thought experiment by you. Which is that, you know, on one end of the spectrum, we have these machines that are increasingly becoming lifelike, human-like. You know, they respond in very intelligent ways. They seem as if they're alive. And on the other hand, we're learning all kinds of things about human beings that show us that even the most complex aspects of our minds are governed by a set of rules and laws. And in some ways, our minds function a little bit like machines. And I'm wondering, is there really a huge distinction? Is it possible - is the real question not so much can machines become more human-like, but is it actually possible that humans are actually just highly evolved machines? DARLING: I have no doubt that we are highly evolved machines. I don't think we understand how we work yet. And I don't think we're going to get to that understanding anytime soon. But yeah, I think - I do think that follow a set of rules and that we're essentially programmed. I don't tend - so I don't distinguish between souls and other entities without souls. And so it's much easier for me to say, yeah, it's probably all the same. But I can see that other people would find that distinction difficult. VEDANTAM: Do you ever talk about this? Do you ever run this by other people and sort of say - do you tell your husband, for example, I like you very much, but I think you're a really intelligent machine that I love dearly? DARLING: (Laughter) I haven't explicitly said that to him, but. . . (LAUGHTER)VEDANTAM: When you go home from this trip. DARLING: Yeah. We'll see how that goes. VEDANTAM: Kate Darling is a research specialist at the MIT Media Lab. Our conversation today was taped before a live audience at the hotel Jerome in Aspen, Colo. , as part of the Aspen Ideas Festival. Kate, thank you for joining me today on HIDDEN BRAIN. DARLING: Thank you so much. (APPLAUSE)VEDANTAM: This week's show was produced by Tara Boyle and Renee Klahr. Our team includes Jenny Schmidt, Maggie Penman, Rhaina Cohen and Parth Shah. Our unsung heroes this week are the staff of the Annabelle Inn in Aspen, Colo. They kindly let us take over that conference center for several interviews with researchers who were in town for the Aspen Ideas Festival. They even turned off the fountains in their outdoor seating area so that we'd have studio-quality sound while recording. Marie Casanova (ph), Doug Parks (ph), Mike Clemons (ph), thanks so much for your hospitality and your willingness to help us make a little bit of audio magic. You can find photos and a video of Samantha, our PLEO dinosaur, on our Instagram page. We're also on Facebook and Twitter. And if you enjoyed this week's show, we'd love if you shared this episode with friends on social media. I'm Shankar Vedantam, and this is NPR. (SOUNDBITE OF MUSIC)DARLING: There we go. It just mooed like a cow. SHANKAR VEDANTAM, HOST:  This is HIDDEN BRAIN. I'm Shankar Vedantam.  (SOUNDBITE OF MUSIC)  VEDANTAM: Have you ever talked to your computer, cursed it for making a mistake?  (SOUNDBITE OF FILM, \"OFFICE SPACE\")  DAVID HERMAN: (As Michael Bolton) PC LOAD LETTER, what the [expletive] does that mean?  VEDANTAM: Have you ever argued with the traffic directions you get from Google Maps or Waze?  (SOUNDBITE OF ARCHIVED RECORDING)  AUTOMATED VOICE: Starting route to Grover's Mill Road. Head North on. . .  VEDANTAM: Have you ever looked at a Roomba cleaning the floor on the other side of the room and told it, please come over to this side, turn left, left?  (SOUNDBITE OF ARCHIVED RECORDING)  UNIDENTIFIED MAN: It just ran itself right off of the edge.  VEDANTAM: Robots and artificial intelligence are playing an ever larger role in all of our lives. Of course, this is not the role that science fiction once imagined.  (SOUNDBITE OF FILM, \"THE TERMINATOR\")  MICHAEL BIEHN: (As Kyle Reese) It doesn't feel pity or remorse or fear.  VEDANTAM: Robots bent on our destruction remain the stuff of movies like \"Terminator. \" And robot sentience is still an idea that's far off in the future. But there's a lot we're learning about smart machines, and there's a lot that smart machines are teaching us about how we connect with the world around us and with each other. This week on HIDDEN BRAIN, can robots teach us what it means to be human?  (SOUNDBITE OF MUSIC)  VEDANTAM: My guest today has spent a lot of time thinking about how we interact with smart machines and how those interactions might change the way we relate to one another. Kate Darling is a research specialist at the MIT Media Lab. She joined us recently in front of a live audience at the Hotel Jerome in Aspen, Colo. , as part of the Aspen Ideas Festival. Also on stage was a robot, a green robot dinosaur about the size of a small dog known as a PLEO. It's going to be part of this conversation. But before we get to that, here's Kate.  (APPLAUSE)  VEDANTAM: Kate, welcome to HIDDEN BRAIN.  KATE DARLING: Thank you for having me.  VEDANTAM: You find that there is an interesting point in the relationship between humans and machines. And that point comes when we give a machine a name. I understand that you have three of these PLEO dinosaurs at your home. Can you tell me some of the names that you have given to your robots?  DARLING: Yes. So the very first one I bought I named Yochai after Yochai Benkler, who's a Harvard professor who's done some work in intellectual property and other areas that I've always admired. And the second one I adopted after I filmed a Canadian documentary where the show host had to name the robot. And he gave the robot the same name he had, which was Peter (ph). So the second one has a boring name. And then. . .  (LAUGHTER)  DARLING: . . . The third one is named Mr. Spaghetti. I don't know if people outside of Boston are familiar with this, but the Boston public transportation system, they wanted to crowdsource a name for their mascot dog. And the Internet decided that the dog should be named Mr. Spaghetti. And, of course, they refused to do that and named the dog Hunter. So Mr. Spaghetti became a big thing in Boston for a while. It was - people were very outraged about this. And so I named my PLEO - my third one - Mr. Spaghetti.  VEDANTAM: I understand that companies actually have found that if you sell a robot with the name of the robot on the box, it changes the way people will interact with that robot than if you just said, this is a dinosaur.  DARLING: So this is - yeah - this is not - I don't have any data on this, but, yes, I have talked to companies who feel that it helps with adoption and trust of the technology. Even very, very simple robots like boxes on wheels that deliver medicine in hospitals, if you give them a little nameplate that says Betsy (ph), their understanding is that people are a little bit more forgiving of the robot. So instead of this stupid machine doesn't work, they'll say, oh, Betsy made a mistake.  (LAUGHTER)  VEDANTAM: And I'm wondering if you've spent time thinking about why this happens. At some level, if I came up to you at home and I said, Kate, is Mr. Spaghetti alive? You would almost certainly tell me, no, Mr. Spaghetti's not alive. I assume you don't think Mr. Spaghetti is alive, right?  DARLING: No.  VEDANTAM: OK. So. . .  (LAUGHTER)  VEDANTAM: . . . Given that you know that Mr. Spaghetti's not alive, why do you think giving him a name changes your relationship to him?  DARLING: With robots in particular, it's combined with just our general tendency to anthropomorphize these things. And we're also primed by science fiction and pop culture to give robots names and view them as entities with personalities. And it's more than just the name, right? I mean, robots move around in a way that seems autonomous to us. We respond to that type of physical movement. Our brains will project intent onto it. So I think robots are the perfect mixture of something that we will very willingly treat with human qualities or lifelike qualities.  VEDANTAM: I understand from one of your papers that there have been examples, especially in military settings, where robots have been assigned to do very dangerous tasks because you don't want human beings to go out and do those tasks. But eventually, the military folks who are running the robots start to relate to them as if they were actually fellow soldiers.  DARLING: There's been some research on this. So Julie Carpenter has done some research. And there's just countless stories online, on Reddit, everywhere about soldiers becoming emotionally attached to the bomb disposal robots that they work with. They'll give them names. They'll give them medals of honor. They'll have funerals for them.  And, you know, it's also kind of interesting because the robots aren't special robots. They're just kind of sticks on wheels. But I think just also the situation that the soldiers find themselves in, where the robot is basically risking its life to save human lives, might also lead them to become very attached to these devices.  VEDANTAM: You had a wonderful example some time ago looking at a colonel, I believe - I don't know if this was your work or you were citing someone else's work - of a colonel who was supervising a robot that was doing sort of mine disposal. Tell us the story about the mine disposal robot.  DARLING: Oh, yeah, this is an incredible - it was an article in The Washington Post, I believe, back in 2007. And the United States military was testing this new robot that could walk over a field with landmines and diffuse them by stepping on them and blowing them up. And the robot itself was shaped like a stick insect.  So it would walk around on six legs. And every time it stepped on a landmine, one of the legs would blow up. And then it would just continue on the remaining legs. And so they were testing this. And the colonel who was in charge of this exercise ended up calling it off because he said it was too inhumane to watch this thing drag itself across the field on its remaining legs.  (LAUGHTER)  VEDANTAM: And so this raises sort of an interesting question because, on the one hand, we can understand how this desire to anthropomorphize robots is very human in some ways. But in some ways - in this case, that defeats the whole point of having a robot that's trying to find the mines.  DARLING: It does. I mean, it's really anything from inefficient to dangerous in these contexts where we want robots to be strictly used as tools to anthropomorphize them. And it's a very difficult design challenge as well because how do you create a device that people want to use but don't like too much?  VEDANTAM: All right. So we have this wonderful little prop in front of us. It's a PLEO dinosaur. I want you to tell me a little bit about the PLEO dinosaur - how it works and how you've come to own three of them, Kate.  DARLING: (Laughter).  VEDANTAM: What is the dinosaur? What does it do?  DARLING: It's basically an expensive toy. I bought the first one, I think, in 2007. There we go. It's awake. They have a lot of motors and touch sensors. And they have an infrared camera and microphones. So they're pretty cool pieces of technology for a toy. And that's initially why I bought one because I was fascinated by everything that it can do. Like, if it starts walking around, it can walk to the edge of the table. It can look down, measure the distance to the floor. It knows that there's a drop, and it'll get scared and walk backwards.  (LAUGHTER)  DARLING: And then they go through different life phases - adolescent and fully grown. And, you know, it'll have moods and. . .  VEDANTAM: So I think what we should do - we bought the robot at HIDDEN BRAIN a couple of weeks ago. We haven't had a chance to give it a name yet. And I thought we should actually reserve the honors for this evening where we're talking to Kate and see if Kate wants to try and name this dinosaur, you know, since she cares about dinosaurs so much. I was looking up Kate's Twitter feed this morning. I understand that you're going to have a baby soon. Congratulations.  DARLING: Yes, I don't have a name for that, either.  VEDANTAM: OK.  (LAUGHTER)  VEDANTAM: Just FYI, she sometimes refers to the baby as baby bot, so just - for whatever that's worth. And one retweet that you have on your Twitter feed cracked me up. It said, you don't really know how many people you don't like until you start trying to pick baby names.  (LAUGHTER)  DARLING: Yeah, that was - that's a quote from my husband.  (LAUGHTER)  VEDANTAM: So I don't want you to tell me - you apparently haven't yet picked your baby's name. So do you have any choices, of top choices? Or is there a name, a spare name that you might care to give the dinosaur?  DARLING: Well, the problem is we've had a girl's name picked out for years and now we're having a boy. And we just can't - we don't even have any contenders.  VEDANTAM: No contenders. What was - what would have been your favorite girl's name if it had - if you had had a girl?  DARLING: Well, so when I first started dating my now-husband, he at some point said, if I ever had a daughter, I already know what I would name her. And I was like, oh, really? We're going to fight about this one. And he said, yeah, I would name her Samantha and Sam for short because Sam is kind of gender neutral. And I was like, oh, I really love that. So that one was picked out very easily.  VEDANTAM: All right, since you're not having a girl, you're going to have a boy, would you mind if you considered naming the dinosaur Samantha? How would you feel about that?  DARLING: Oh, that would be awesome. We should name the dinosaur Samantha.  VEDANTAM: All right, so henceforth, this dinosaur will be called Samantha. . .  DARLING: Yay.  VEDANTAM: . . . Or Sam for short.  (APPLAUSE)  VEDANTAM: Now, some time ago, Kate conducted a very interesting experiment with the PLEO dinosaurs. And to sort of show how this works, I have a second prop here which is under the table.  DARLING: Uh-oh.  VEDANTAM: It's a hammer, a large hammer which we borrowed from the hotel. Now, as you all know, the dinosaur is obviously not alive. It's just cloth and plastic and a battery and wires. It has a name, of course, Samantha, but. . .  (LAUGHTER)  VEDANTAM: . . . It isn't alive in any sense of the term. And so Kate, I'm going to actually give you the hammer.  DARLING: Oh, no.  (LAUGHTER)  VEDANTAM: Kate, would you consider destroying Samantha?  DARLING: No.  (LAUGHTER)  VEDANTAM: It's just a machine.  DARLING: I only make other people do that. I don't do it myself.  (LAUGHTER)  VEDANTAM: You wouldn't even consider harming the dinosaur?  DARLING: Well, so my problem is that I already know the results of our research. And that would say something about me as a person, so I'm going to say no, I'm not willing to do it.  (LAUGHTER)  VEDANTAM: Tell me about the experiment. So you had volunteers come up, and you basically introduced them to these lovable dinosaurs. And then you give them a hammer like this. And you told them to do what?  DARLING: Well, so - OK, so this was the workshop part that we used the dinosaurs for. They're a little too expensive to do an experiment with a hundred participants. So the workshop that we did, in a nonscientific setting, we had five of these robot dinosaurs. We gave them to groups of people and had them name them, interact with them, play with them. We had them personify them a little bit by doing a little fashion show with - and a fashion contest.  And then after about an hour, we asked them to torture and kill them. And we had a variety of instruments. We had a hammer, a hatchet and I forget what else. And - but like even though we tried to make it dramatic, it turned out to be a little bit more dramatic than we expected it to be.  And they really refused to even hit the things. And so we had to kind of start playing mind games with them. We said, OK, you can save your group's dinosaur if you hit another group's dinosaur with the hammer.  VEDANTAM: Oh, my gosh.  (LAUGHTER)  DARLING: And they tried. And they couldn't do that, either. This one woman was standing over the thing trying and she just couldn't. She ended up petting it instead.  (LAUGHTER)  DARLING: And then, finally, we said, OK, well, we're going to destroy all of the robots unless someone takes a hatchet to one of them. And finally, someone did.  VEDANTAM: Wait, so you said unless one of you kills one of them, we are going to kill all of them?  DARLING: Yeah. I think this might have been my partner's idea. So I did this with a friend named Hannes Gassert. We did this at a conference called Lift in Geneva. And we had to improvise because people really didn't want to do it. So we threatened them.  (LAUGHTER)  DARLING: And finally, someone did.  VEDANTAM: Samantha clearly doesn't want you to harm her.  DARLING: Yeah, clearly, clearly.  VEDANTAM: So what do you think is going on? I mean, at a rational level, the dinosaur obviously is not alive. Why do you think we have such reluctance to harming the dinosaur? In fact, I might have the battery removed so the dinosaur stops making noise.  DARLING: Well, I mean, it behaves in a really lifelike way. I mean, we have over a century of animation expertise in creating compelling characters that are very lifelike that people will automatically project life onto. I mean, look at, you know, Pixar movies, for example. It's incredible. And I know that a lot of social roboticists actually work with animators to create these compelling characters.  And so, you know, it's very hard to not see this as some sort of living entity, even though you know perfectly well that it's just a machine because it's moving in this way that we automatically subconsciously associate with states of mind. And so I just think it's really uncomfortable to people, particularly for robots like this that can display, you know, a simulation of pain or discomfort, to have to watch that. I mean, it's just not comfortable.  VEDANTAM: What did you find in terms of who was willing to do it and who wasn't? I mean, when you looked at the people who were willing to destroy a dinosaur, a dinosaur like the PLEO, you found that there were certain characteristics that were attached to people who were more or less likely to do the deed.  DARLING: So the follow-up study that we did, not with the dinosaurs, we did with HEXBUGs, which are a very simple toy that moves around like an insect. And there, we were looking at people's hesitation to hit the HEXBUG and whether they would hesitate more if we gave it a name and whether they would hesitate more if they had natural tendencies for empathy, for empathic concern. And, you know, we found that people with low empathic concern for other people, they didn't much care about the HEXBUG and would hit it much more quickly. And people with high empathic concern would hesitate more. And some even refused to hit the HEXBUGs.  VEDANTAM: So in many ways, what you're saying is that potentially the way we relate to these inanimate objects might actually say something about us at a deeper level than just our relationship to the machine.  DARLING: Yes, possibly. I mean, we know now, or we have some indication that we can measure people's empathy using robots, which is pretty interesting.  VEDANTAM: You know, my colleagues and I were discussing ahead of this interview whether you would actually destroy the dinosaur. And we were torn because we said, on the one hand, you of all people should know that these are just machines, and that it's an irrational belief to project lifelike values on them. But on the other hand, I said, you know, it's really unlikely she's going to do it because she's going to look like a really bad person if she smashes the dinosaur in front of 200 people.  DARLING: I mean, I don't know if you've been watching \"Westworld\" at all, but the people who don't hesitate to shoot the robots, they seem pretty callous to us. It's - I - and I think maybe there is something to it. Of course, we can rationalize it. Of course, you know, if I had to, I could take the hammer and smash the robot, and, you know, I wouldn't have nightmares about it. But I think that perhaps turning off that basic instinct to hesitate to do that might be more harmful than override. You know, I think overriding it might be more harmful than just going with it.  VEDANTAM: I want to talk about the most important line we draw between machines and humans, and it's not intelligence, but it's consciousness. I want to play you a little clip from \"Star Trek. \"  (SOUNDBITE OF TV SHOW, \"STAR TREK: THE NEXT GENERATION\")  PATRICK STEWART: (As Captain Jean-Luc Picard) Now tell me, Commander. What is Data?  BRIAN BROPHY: (As Commander Bruce Maddox) I don't understand.  STEWART: (As Captain Jean-Luc Picard) What is he?  BROPHY: (As Commander Bruce Maddox) A machine.  STEWART: (As Captain Jean-Luc Picard) Is he? Are you sure?  BROPHY: (As Commander Bruce Maddox) Yes.  STEWART: (As Captain Jean-Luc Picard) You see, he's met two of your three criteria for sentience, so what if he meets the third - consciousness - in even the smallest degree? What is he then? I don't know. Do you?  VEDANTAM: So this has been a perennial concern in science fiction, which is the idea that at some point machines will become conscious and sentient. And very often, it's in the context of, you know, the machines will rise up and harm the humans and destroy us. But as I read your research, I actually found myself thinking, is our desire to believe that the machines can become conscious actually just an extension of what we've been talking about the last 20 minutes? Which is we project sentience onto machines all the time. And so when we imagine what they're going to be like in the future, the first thing that pops in our head is they're going to become conscious.  DARLING: Yeah. I think there's a lot of projection happening there. I also think that before we get to the question of robot rights and consciousness, you know, we have to ask ourselves, how do robots fit into our lives when we perceive them as conscious? Because I think that's when it starts to get morally messy and not when they actually inherently have some sort of consciousness.  (SOUNDBITE OF MUSIC)  VEDANTAM: There's a lot that's morally messy about how humans interact with robots. When we come back, we're going to delve into some of those moral and ethical issues, including the deeply troubling case of a Japanese company that builds sex robots designed to look like children. Stay with us.  (SOUNDBITE OF MUSIC)  VEDANTAM: This is HIDDEN BRAIN. I'm Shankar Vedantam. If humans have a tendency to anthropomorphize machines, to see them as human, it isn't surprising that we're all so willing to bring all the biases we have toward our fellow human beings into the machine world. Many of the intelligent assistants being built by major companies - Siri or Alexa - are being given women's names. Many of the genius machines are often given men's names - HAL or Watson.  Now, you can say Siri and Alexa aren't people, why should we care? Why should we care if people sexually harass their virtual assistants, as has been shown to sometimes happen? MIT's Kate Darling says we should care because the way we treat robots may have implications for the way we treat other human beings.  DARLING: It might. We don't know but it might. And one example with the virtual assistants you just mentioned is children. So parents have started observing. And this this is anecdotal but they've started observing that their kids adopt behavioral patterns based on how they're interacting with these devices and how they're conversing with them. And there are some cool stories.  Like there was story in The New York Times a few years ago where a mother was talking about how her autistic son had developed a relationship with Siri, the voice assistant. And she said this was awesome because Siri is very patient. She will answer questions repeatedly and consistently. And apparently, this is really important for autistic kids. But also because her voice recognition is so bad, he learned to articulate his words really clearly. And it improved his communication with others.  Now, that's great, but these things aren't designed with autistic kids in mind, right? That's kind of more of a coincidence than anything. And so there are also perhaps some unintended effects that are more negative. And so one guy wrote a blog post a while back where he said Amazon's Echo is magical but it's turning my child into an [expletive] because Alexa doesn't require please or thank you or any of the standard politeness that you want your kids to learn when they're conversing and when they're, you know, demanding things of you. So, you know, it starts there. But I think that as this technology improves and gets better at mimicking real conversations or life-like behavior, you have to wonder to what extent that gets muddled in our subconscious and not just in children's subconscious but maybe even in our own.  VEDANTAM: Do you think it's a coincidence that most of the virtual assistants are given female names and female identities?  DARLING: I think it's a combination of whatever market research but also just people not thinking. I mean, I visited IBM Watson in Austin. And there is a room that you can go into, and you can talk to Watson. And he has this deep booming male voice. And you can ask questions. And at the time I went there, there was this second AI in the room that turned on the lights and greeted the visitors. And that one had a female voice. And I pointed that out. And it seemed like they hadn't really considered that.  So it's, you know, it's a mixture of people thinking, oh, this is going to sell better and people just not thinking at all because the teams that are building this technology are predominantly young, white and male. And they have these blind spots where they don't even consider what biases they might perpetuate through the design of these systems.  VEDANTAM: So which brings us to the question of sex robots. I'm curious what you make of this. And there are really complicated arguments on both sides of this question. Should we use machines as, you know, sexual companions? Should we use them in ways that could potentially satisfy the needs of groups of people who in some ways we are troubled by?  DARLING: Yeah. So, you know, referring to pedophilia specifically, this is a very difficult area because we know almost nothing about pedophilia generally. And we have absolutely no idea what the effects of technologies like this could be if they provide kind of an immersive sexual experience. I mean, it could be that this is a very useful outlet to use therapeutically - yeah,  VEDANTAM: A safety valve.  DARLING: . . . Basically - that ends up preventing real child abuse. And on the other hand, it could be that this is something that normalizes and perpetuates certain behaviors. And we literally have no idea what direction this goes in. And I think this is a question that we're going to be facing pretty soon. I mean, like you said, there are companies that make the dolls. There's legal cases already about this. And there's a lot of moral panic about sex technology but also, I mean, in this case, very understandable emotional responses to, you know, regulation of child abuse. So it's very difficult. And you can't research it - in the U. S. , at least.  VEDANTAM: So you're sometimes called a robot ethicist. And you've sometimes said we might need to establish a limited legal status for robots. What do you mean by that?  DARLING: Yeah. It's a little bit of a provocation. But my sense is that, you know, if we have evidence that behaving violently towards very lifelike objects not only tells us something about you as a person but can also change people and desensitize them to that behavior in other contexts. So, you know, if you're used to kicking a robot dog, you know, are you more likely to kick a real dog? Then that might actually be an argument, if that's the case, to give robots certain legal protections the same way that we give animals protections but for a different reason.  We like to tell ourselves that we give animals protection from abuse because they actually experience pain and suffering. I actually don't think that's the only reason we do it. But for robots, the idea would be not that they experience anything, but rather that it's desensitizing to us and it has a negative effect on our behavior to be abusive towards the robots.  VEDANTAM: So here's a thing that's sort of - it's worth sort of pondering for a moment. If you hear, for example, that someone owns a bunch of chickens in their farm, right? So it's their farm, their chickens. They own the chickens. And they're really mistreating the chickens, torturing them, harming them. You could sort of make a property rights argument and say they can do whatever they want with their property, but I think many of us would say even though the chicken belongs to you, there are certain things you can and cannot do with the chicken.  And I'm not sure it's just about our concern that if you mistreat the chicken, that means you will turn into the kind of person who might mistreat other people. There's sort of a level. There's a certain moral level at which I think the idea of abusing animals is offensive to us. But I'm wondering the same thing is true with machines as well, which is it's not just the case that it might be that people who harm machines are also willing to harm humans but just the act of harming things that look and feel and sound sentient is morally offensive in some way.  DARLING: Yeah. So I think that's absolutely how we've approached most animal protections because it's also - it's very clear that we care more about certain animals than others and not based on any biological criteria. So I think that we just find it morally offensive, for example, to torture cats. Or, you know, in the United States, we don't like the idea of eating horses. But in Europe, they're like, what's the difference between a horse and a cow? They're both delicious.  So there's - that's definitely how we tend to operate and how we tend to pass these laws. And I don't see why that couldn't also apply to machines once they get to a more advanced level where we really do perceive them as lifelike and it is really offensive to us to see them be abused.  VEDANTAM: The Devil's Advocate side of that argument, of course, is that would people then say pressing a switch and turning off a machine, that's unethical because you're essentially killing the robot?  DARLING: But we don't protect animals from being killed. We just protect them from being treated unnecessarily cruelly. So I actually think animal abuse laws are a pretty good parallel here.  VEDANTAM: You argue that robots might one day expand the boundaries of how humans relate to one another. I want to play you a short clip from the movie \"Her,\" where a man falls in love with his operating system but then discovers something about her.  (SOUNDBITE OF FILM, \"HER\")  JOAQUIN PHOENIX: (As Theodore) Are you in love with anyone else?  SCARLETT JOHANSSON: (As Samantha) What makes you ask that?  PHOENIX: (As Theodore) I don't know. Are you?  JOHANSSON: (As Samantha) I've been trying to figure out how to talk to you about this.  PHOENIX: (As Theodore) How many others?  JOHANSSON: (As Samantha) Six hundred forty-one.  PHOENIX: (As Theodore) What? What are you talking about? That's insane. That's [expletive] insane.  VEDANTAM: So I'm wondering, Kate, is it possible that as we start to relate to machines, is it possible that they will change the range of ways we relate to one another? In other words, is it possible they'll expand how we think about relationships themselves?  DARLING: Maybe. But I think it's important to remember - the thing that I couldn't get out of my mind when I was watching \"Her\" specifically is that there is a company that makes this operating system. And if I were the company, I would be like - I would program it to say, oh, yes, I'm seeing 641 other people, but for $20,000, you can get exclusively me.  (LAUGHTER)  DARLING: I - like, that's the direction it's going to go in, right? It's not that the machines are going to become conscious and, you know, develop their own forms of relationship.  VEDANTAM: You mentioned \"Westworld\" some moments ago, and I want to play a clip from \"Westworld. \" For those of you who haven't seen \"Westworld,\" humans interact with robots in - robots are extremely lifelike, so lifelike that it's sometimes difficult to tell whether you are talking to a robot or you're talking to a human. In the scene that I'm about to play you, a man named William interacts with a woman who may or may not be a robot.  (SOUNDBITE OF TV SHOW, \"WESTWORLD\")  UNIDENTIFIED ACTRESS: (As character) You want to ask, so ask.  JIMMI SIMPSON: (As William) Are you real?  UNIDENTIFIED ACTRESS: (As character) Well, if you can't tell, does it matter?  VEDANTAM: So as I watched this scene and as I read your work, I actually had a thought. And I wanted to sort of run this thought experiment by you. Which is that, you know, on one end of the spectrum, we have these machines that are increasingly becoming lifelike, human-like. You know, they respond in very intelligent ways. They seem as if they're alive. And on the other hand, we're learning all kinds of things about human beings that show us that even the most complex aspects of our minds are governed by a set of rules and laws.  And in some ways, our minds function a little bit like machines. And I'm wondering, is there really a huge distinction? Is it possible - is the real question not so much can machines become more human-like, but is it actually possible that humans are actually just highly evolved machines?  DARLING: I have no doubt that we are highly evolved machines. I don't think we understand how we work yet. And I don't think we're going to get to that understanding anytime soon. But yeah, I think - I do think that follow a set of rules and that we're essentially programmed. I don't tend - so I don't distinguish between souls and other entities without souls. And so it's much easier for me to say, yeah, it's probably all the same. But I can see that other people would find that distinction difficult.  VEDANTAM: Do you ever talk about this? Do you ever run this by other people and sort of say - do you tell your husband, for example, I like you very much, but I think you're a really intelligent machine that I love dearly?  DARLING: (Laughter) I haven't explicitly said that to him, but. . .  (LAUGHTER)  VEDANTAM: When you go home from this trip.  DARLING: Yeah. We'll see how that goes.  VEDANTAM: Kate Darling is a research specialist at the MIT Media Lab. Our conversation today was taped before a live audience at the hotel Jerome in Aspen, Colo. , as part of the Aspen Ideas Festival. Kate, thank you for joining me today on HIDDEN BRAIN.  DARLING: Thank you so much.  (APPLAUSE)  VEDANTAM: This week's show was produced by Tara Boyle and Renee Klahr. Our team includes Jenny Schmidt, Maggie Penman, Rhaina Cohen and Parth Shah.  Our unsung heroes this week are the staff of the Annabelle Inn in Aspen, Colo. They kindly let us take over that conference center for several interviews with researchers who were in town for the Aspen Ideas Festival. They even turned off the fountains in their outdoor seating area so that we'd have studio-quality sound while recording. Marie Casanova (ph), Doug Parks (ph), Mike Clemons (ph), thanks so much for your hospitality and your willingness to help us make a little bit of audio magic.  You can find photos and a video of Samantha, our PLEO dinosaur, on our Instagram page. We're also on Facebook and Twitter. And if you enjoyed this week's show, we'd love if you shared this episode with friends on social media. I'm Shankar Vedantam, and this is NPR.  (SOUNDBITE OF MUSIC)  DARLING: There we go. It just mooed like a cow.", "section": "Hidden Brain", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-07-10-536505290": {"title": "Tech Design Ethicist Works To Raise Awareness Of Internet Addiction : NPR", "url": "https://www.npr.org/2017/07/10/536505290/tech-design-ethicist-works-to-raise-awareness-of-internet-addiction", "author": "No author found", "published_date": "2017-07-10", "content": "KELLY MCEVERS, HOST: So here's the thing. When you think about Internet addiction, tech companies actually want people, not just teenagers, to spend time on their apps and their devices. And while that doesn't always lead to addiction, it does become a habit, sometimes an unhealthy one for many people. Tristan Harris knows all about this. He was a design ethicist at Google. He now runs a nonprofit that tries to raise awareness of this issue, and he's with us now. Welcome. TRISTAN HARRIS: Thanks for having me. MCEVERS: So first of all, what is a design ethicist? HARRIS: Well, it's really studying how do you ethically persuade someone's mind because whether we want to or not, in the tech industry, a handful of technology companies and a handful of people are steering the thoughts, feelings and emotions that are going to show up in 2 billion people's minds today. MCEVERS: Wow. So just give us an example of how tech companies design products that become hard to ignore, you know, that can become addictive. HARRIS: Yeah, well, I mean in this story with this young woman, you know, you're talking about YouTube. So video sites are all competing for attention. So if you're YouTube and you say, well, let's get some more attention, let's autoplay the next video. And then when you to autoplay the video, if that works well - let's say getting 5 percent more attention from people - then if Netflix or Facebook look at that, that's shrinking their attention market share. So Netflix needs to autoplay the next video on a countdown. And then that shrinks Facebook's market share, so Facebook looks at that and says, we have to autoplay all of the videos and keep the feed scrolling forever and never stop. And so it's not because companies are deliberately evil or have bad intentions. It's just that this race for attention. . . MCEVERS: Right. HARRIS: . . . Creates this perverse economy that keeps everybody sucked in. MCEVERS: Right. But what should companies do now to design products in a different way so that we don't become addicted to them? HARRIS: Well, I think of this like a - sort of an environmental metaphor. You know, so essentially 2 billion people's minds are jacked into an open environment run by essentially three private companies - Apple, Google and Facebook. And there's no protections. There's no zoning laws in that city for, say, like, the residential zone. So the residential zone could be something like sleep. There's no zoning laws for the sleep zone. And so all of these attention companies want to build casinos and extend their footprint into your life and bulldoze all these other boundaries you might want to put up. And so one thing that these companies can do is help create these zoning laws for, let's say, waking up in the morning or going to bed or whatever we want our breaks to look like and have the applications that compete for our attention compete around those zones instead of bulldozing our boundaries. MCEVERS: I mean Google did create this position, you know, of design ethicist, so companies are thinking about this, right? Are they thinking about it enough? HARRIS: I would say that we're not thinking about it nearly enough. And I think there's no clear role for this in the tech industry yet. And I think we need to make a whole - not just one person, but we need to have, you know, entire groups of people that are just dedicated to asking, what's best for people, not what's best for engagement. That's going to take resourcing and people and philosophers and anthropologists and sociologists asking, how is this stuff affecting people's minds? And what does it mean to affect people's minds positively or ethically? MCEVERS: Tristan Harris of Time Well Spent. That's a nonprofit focused on how we use technology. Thank you very much. HARRIS: Thanks for having me. (SOUNDBITE OF CIRCLES AROUND THE SUN'S \"GILBERT'S GROOVE\") KELLY MCEVERS, HOST:  So here's the thing. When you think about Internet addiction, tech companies actually want people, not just teenagers, to spend time on their apps and their devices. And while that doesn't always lead to addiction, it does become a habit, sometimes an unhealthy one for many people. Tristan Harris knows all about this. He was a design ethicist at Google. He now runs a nonprofit that tries to raise awareness of this issue, and he's with us now. Welcome. TRISTAN HARRIS: Thanks for having me. MCEVERS: So first of all, what is a design ethicist? HARRIS: Well, it's really studying how do you ethically persuade someone's mind because whether we want to or not, in the tech industry, a handful of technology companies and a handful of people are steering the thoughts, feelings and emotions that are going to show up in 2 billion people's minds today. MCEVERS: Wow. So just give us an example of how tech companies design products that become hard to ignore, you know, that can become addictive. HARRIS: Yeah, well, I mean in this story with this young woman, you know, you're talking about YouTube. So video sites are all competing for attention. So if you're YouTube and you say, well, let's get some more attention, let's autoplay the next video. And then when you to autoplay the video, if that works well - let's say getting 5 percent more attention from people - then if Netflix or Facebook look at that, that's shrinking their attention market share. So Netflix needs to autoplay the next video on a countdown. And then that shrinks Facebook's market share, so Facebook looks at that and says, we have to autoplay all of the videos and keep the feed scrolling forever and never stop. And so it's not because companies are deliberately evil or have bad intentions. It's just that this race for attention. . . MCEVERS: Right. HARRIS: . . . Creates this perverse economy that keeps everybody sucked in. MCEVERS: Right. But what should companies do now to design products in a different way so that we don't become addicted to them? HARRIS: Well, I think of this like a - sort of an environmental metaphor. You know, so essentially 2 billion people's minds are jacked into an open environment run by essentially three private companies - Apple, Google and Facebook. And there's no protections. There's no zoning laws in that city for, say, like, the residential zone. So the residential zone could be something like sleep. There's no zoning laws for the sleep zone. And so all of these attention companies want to build casinos and extend their footprint into your life and bulldoze all these other boundaries you might want to put up. And so one thing that these companies can do is help create these zoning laws for, let's say, waking up in the morning or going to bed or whatever we want our breaks to look like and have the applications that compete for our attention compete around those zones instead of bulldozing our boundaries. MCEVERS: I mean Google did create this position, you know, of design ethicist, so companies are thinking about this, right? Are they thinking about it enough? HARRIS: I would say that we're not thinking about it nearly enough. And I think there's no clear role for this in the tech industry yet. And I think we need to make a whole - not just one person, but we need to have, you know, entire groups of people that are just dedicated to asking, what's best for people, not what's best for engagement. That's going to take resourcing and people and philosophers and anthropologists and sociologists asking, how is this stuff affecting people's minds? And what does it mean to affect people's minds positively or ethically? MCEVERS: Tristan Harris of Time Well Spent. That's a nonprofit focused on how we use technology. Thank you very much. HARRIS: Thanks for having me. (SOUNDBITE OF CIRCLES AROUND THE SUN'S \"GILBERT'S GROOVE\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-07-10-536428035": {"title": "Trump's 'Impenetrable' Joint Cyber Until With Russia That Never Was : NPR", "url": "https://www.npr.org/2017/07/10/536428035/trumps-impenetrable-cyber-unit-that-never-was", "author": "No author found", "published_date": "2017-07-10", "content": "", "section": "National Security", "disclaimer": ""}, "2017-07-12-536887872": {"title": "Internet Companies Plan Day Of Action In Support Of Net Neutrality : NPR", "url": "https://www.npr.org/2017/07/12/536887872/internet-companies-plan-day-of-action-in-support-of-net-neutrality", "author": "No author found", "published_date": "2017-07-12", "content": "KELLY MCEVERS, HOST:  If you've been on Amazon, Google, Facebook, Netflix or Etsy today, you might have seen something about net neutrality. The companies that host these sites have teamed up for an online protest. Hundreds of others are participating. And they're unhappy about a proposal by the Federal Communications Commission to loosen regulations for Internet service providers. NPR tech reporter Alina Selyukh is here to tell us all about it. Hey there. ALINA SELYUKH, BYLINE: Hi. MCEVERS: So what FCC rules would be going away? SELYUKH: So as you mentioned, these are the rules that enforce this idea of net neutrality. It's this principle that essentially says Internet providers should not be able to act as gatekeepers of what you find on the Internet. That principle has been around for a decade. But in 2015, then-Democrat-majority FCC passed new regulations to enforce net neutrality, setting new kind of oversight for Internet service providers. Now under President Trump, Republicans are in charge of the agency, and they are deregulating. MCEVERS: Why are Internet companies and advocacy groups so upset? SELYUKH: Well, so it has to do with the specifics of the rules. Two of the basic rules of net neutrality say that Internet providers should not be able to block or slow down any websites or apps. And actually on this, the telecom and cable companies will often say, we have no plans to do that; our customers would be up in arms. But now this new FCC proposal puts into question even those basic elements. It asks, should there even be a ban on blocking or throttling? And there's this third kind of element which has this wonky name of paid prioritization. And that refers to the kind of deal where, say, Netflix would be able to pay Verizon to get a sort of priority delivery, special treatment. Internet providers have previously argued that people might actually benefit from some prioritization. But advocacy groups and Internet companies say opening that door puts smaller competitors and startups in danger. MCEVERS: OK, so when we hear about net neutrality and the debate, is this it? Is this the crux of it? SELYUKH: A simple answer is yes. But of course we're in Washington. Nothing here is ever simple. So I'm going to take you a bit further into this policy rabbit hole. MCEVERS: OK. SELYUKH: When the Obama-era FCC set the new rules in 2015, the agency went for a broad overhaul of how it treats Internet providers in general. They put them in a similar category as the traditional telephone companies so they could be really tightly overseen. And that's what upset the broadband providers as well as free market groups that argue that this new regulatory regime in general puts a bureaucratic straitjacket on the industry. And those are actually the words of the current Republican FCC chairman, Ajit Pai. MCEVERS: OK, so back to today's protest. What happened, and you know, could it change the chairman's view on this? SELYUKH: Well, there are a lot of participants. You named a few of them. They have vast Internet reach. Amazon had a little ad. Reddit displayed a digital message. Netflix and Etsy put up banners. Mark Zuckerberg wrote a post. Lots and lots of organizations are mobilizing. They're asking people to contact the FCC and Congress in support of the current rules. And some of the participants actually told me that Congress is the bigger target today given that Chairman Pai of the FCC seems to have largely made up his mind to reel back the regulations. The FCC is accepting public comment for a few more weeks. But the FCC Republicans have suggested that they prefer comments that offer a cost-benefit analysis or are otherwise evidence-based. The sheer number only goes so far, they say. And as Commissioner Mike O'Rielly put it, rulemaking is not decided like a \"Dancing With The Stars\" contest. MCEVERS: That's NPR's Alina Selyukh. Thank you very much. SELYUKH: Thank you. (SOUNDBITE OF J. S. T. A. R. S. 'S \"TRIPPING THE LIGHT FANTASTIC\") KELLY MCEVERS, HOST:   If you've been on Amazon, Google, Facebook, Netflix or Etsy today, you might have seen something about net neutrality. The companies that host these sites have teamed up for an online protest. Hundreds of others are participating. And they're unhappy about a proposal by the Federal Communications Commission to loosen regulations for Internet service providers. NPR tech reporter Alina Selyukh is here to tell us all about it. Hey there. ALINA SELYUKH, BYLINE: Hi. MCEVERS: So what FCC rules would be going away? SELYUKH: So as you mentioned, these are the rules that enforce this idea of net neutrality. It's this principle that essentially says Internet providers should not be able to act as gatekeepers of what you find on the Internet. That principle has been around for a decade. But in 2015, then-Democrat-majority FCC passed new regulations to enforce net neutrality, setting new kind of oversight for Internet service providers. Now under President Trump, Republicans are in charge of the agency, and they are deregulating. MCEVERS: Why are Internet companies and advocacy groups so upset? SELYUKH: Well, so it has to do with the specifics of the rules. Two of the basic rules of net neutrality say that Internet providers should not be able to block or slow down any websites or apps. And actually on this, the telecom and cable companies will often say, we have no plans to do that; our customers would be up in arms. But now this new FCC proposal puts into question even those basic elements. It asks, should there even be a ban on blocking or throttling? And there's this third kind of element which has this wonky name of paid prioritization. And that refers to the kind of deal where, say, Netflix would be able to pay Verizon to get a sort of priority delivery, special treatment. Internet providers have previously argued that people might actually benefit from some prioritization. But advocacy groups and Internet companies say opening that door puts smaller competitors and startups in danger. MCEVERS: OK, so when we hear about net neutrality and the debate, is this it? Is this the crux of it? SELYUKH: A simple answer is yes. But of course we're in Washington. Nothing here is ever simple. So I'm going to take you a bit further into this policy rabbit hole. MCEVERS: OK. SELYUKH: When the Obama-era FCC set the new rules in 2015, the agency went for a broad overhaul of how it treats Internet providers in general. They put them in a similar category as the traditional telephone companies so they could be really tightly overseen. And that's what upset the broadband providers as well as free market groups that argue that this new regulatory regime in general puts a bureaucratic straitjacket on the industry. And those are actually the words of the current Republican FCC chairman, Ajit Pai. MCEVERS: OK, so back to today's protest. What happened, and you know, could it change the chairman's view on this? SELYUKH: Well, there are a lot of participants. You named a few of them. They have vast Internet reach. Amazon had a little ad. Reddit displayed a digital message. Netflix and Etsy put up banners. Mark Zuckerberg wrote a post. Lots and lots of organizations are mobilizing. They're asking people to contact the FCC and Congress in support of the current rules. And some of the participants actually told me that Congress is the bigger target today given that Chairman Pai of the FCC seems to have largely made up his mind to reel back the regulations. The FCC is accepting public comment for a few more weeks. But the FCC Republicans have suggested that they prefer comments that offer a cost-benefit analysis or are otherwise evidence-based. The sheer number only goes so far, they say. And as Commissioner Mike O'Rielly put it, rulemaking is not decided like a \"Dancing With The Stars\" contest. MCEVERS: That's NPR's Alina Selyukh. Thank you very much. SELYUKH: Thank you. (SOUNDBITE OF J. S. T. A. R. S. 'S \"TRIPPING THE LIGHT FANTASTIC\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-07-17-537463986": {"title": "Tech Workers Brace For Seattle's Plan to 'Tax The Rich'  : NPR", "url": "https://www.npr.org/2017/07/17/537463986/tech-workers-brace-for-seattles-plan-to-tax-the-rich", "author": "No author found", "published_date": "2017-07-17", "content": "", "section": "National", "disclaimer": ""}, "2017-07-18-537844706": {"title": "Elon Musk: Artificial Intelligence Poses 'Existential Risk' : NPR", "url": "https://www.npr.org/2017/07/18/537844706/elon-musk-artificial-intelligence-poses-existential-risk", "author": "No author found", "published_date": "2017-07-18", "content": "DAVID GREENE, HOST: Governors are trying to make sense of an urgent message they got over the weekend. Elon Musk, the billionaire scientist behind Tesla Motors and SpaceX, swung by a gathering of state leaders and warned them artificial intelligence is an existential threat to human civilization. Colorado's Governor John Hickenlooper, who was there, described that moment to NPR. JOHN HICKENLOOPER: You could have heard a pin drop. A couple times he paused and it was totally silent. I think a lot of us felt like we were in the presence of, you know, Alexander Graham Bell or Thomas Alva Edison. It was remarkable. GREENE: But it was also remarkably vague. NPR's Aarti Shahani covers technology. And, Aarti, you can help us understand what Elon Musk meant here, right? AARTI SHAHANI, BYLINE: I can try. GREENE: I mean, he said that AI, artificial intelligence, is out of control. I mean, is he right? SHAHANI: Well, you know, out of control, it's a funny term because that's actually the goal of it, right? Like, take machine learning, which is a way to make computers smarter. You feed data into the computers. They digest the data, I mean, lots of it. And then they come up with solutions that humans didn't dictate in advance, OK? Like, for example, your Netflix movie suggestions or better Chinese-English language translation, right? GREENE: Right. SHAHANI: Now, that said, plenty of people in Silicon Valley are getting really annoyed with Musk and kind of rolling their eyes at him for exaggerating yet again. And, you know, we're far away from something like \"The Terminator\" - right? - AI that could start a war. GREENE: That's reassuring. (LAUGHTER)SHAHANI: The head of artificial intelligence at Facebook, he actually - he got a little spicy about it. He told me, the desire to dominate socially is not correlated with intelligence. It's correlated with testosterone. . . GREENE: Oh. SHAHANI: . . . Which AI systems will not have. His words, not mine. GREENE: OK. That's reassuring maybe. So some disagreement here. I mean, does that mean that political leaders, regulators don't need to worry about artificial intelligence taking over the world? SHAHANI: No, no. It doesn't mean that. I mean, the thing they have to pay attention to at this moment is data, big data, OK? Who is stockpiling it? What are they doing with it, whether they're doing AI or something else? You know, there are only a handful of companies really that collect tons of data on us. And that gives them a huge competitive advantage - OK? - an edge that you can use to shut out others. We're already seeing this very clearly in the world of Internet advertising - right? - where face and Google basically have a duopoly. The European Union just issued a huge fine against Google for exploiting its data advantage in Europe to block competitors. And, you know, when big data defines more and more industries, be it cars, real estate, health care, you could get that same kind of consolidation. And then we as consumers lose out. GREENE: Well, what about that other question about labor, like, as in computers and automation killing off, you know, manufacturing jobs and other jobs? SHAHANI: Right. I mean, automation is definitely scary and dramatic. But again, that's going to take a while. So what the public sector probably has to think a lot more about when it comes to labor right now are old-world problems like discrimination and how they play out in a context where private companies are hoarding and hiding the data, OK? Let's take an example like Uber drivers, OK? They keep or they lose their jobs based on a rating system. How many stars do you get from a passenger, right? Now, let's say, theoretically, black and brown drivers get lower ratings. Maybe they've got accents that annoy passengers. And so the Uber algorithm, you know, could kick off these drivers with more low ratings on average, which is a form of racial discrimination. We don't have a regulatory model in place where companies have to test to certify their systems to check for factors like that. GREENE: OK. Well, at least Elon Musk has given us a moment to have a conversation about this and think about it. NPR's Aarti Shahani covers technology. Aarti, thanks as always. SHAHANI: Thank you. DAVID GREENE, HOST:  Governors are trying to make sense of an urgent message they got over the weekend. Elon Musk, the billionaire scientist behind Tesla Motors and SpaceX, swung by a gathering of state leaders and warned them artificial intelligence is an existential threat to human civilization. Colorado's Governor John Hickenlooper, who was there, described that moment to NPR. JOHN HICKENLOOPER: You could have heard a pin drop. A couple times he paused and it was totally silent. I think a lot of us felt like we were in the presence of, you know, Alexander Graham Bell or Thomas Alva Edison. It was remarkable. GREENE: But it was also remarkably vague. NPR's Aarti Shahani covers technology. And, Aarti, you can help us understand what Elon Musk meant here, right? AARTI SHAHANI, BYLINE: I can try. GREENE: I mean, he said that AI, artificial intelligence, is out of control. I mean, is he right? SHAHANI: Well, you know, out of control, it's a funny term because that's actually the goal of it, right? Like, take machine learning, which is a way to make computers smarter. You feed data into the computers. They digest the data, I mean, lots of it. And then they come up with solutions that humans didn't dictate in advance, OK? Like, for example, your Netflix movie suggestions or better Chinese-English language translation, right? GREENE: Right. SHAHANI: Now, that said, plenty of people in Silicon Valley are getting really annoyed with Musk and kind of rolling their eyes at him for exaggerating yet again. And, you know, we're far away from something like \"The Terminator\" - right? - AI that could start a war. GREENE: That's reassuring. (LAUGHTER) SHAHANI: The head of artificial intelligence at Facebook, he actually - he got a little spicy about it. He told me, the desire to dominate socially is not correlated with intelligence. It's correlated with testosterone. . . GREENE: Oh. SHAHANI: . . . Which AI systems will not have. His words, not mine. GREENE: OK. That's reassuring maybe. So some disagreement here. I mean, does that mean that political leaders, regulators don't need to worry about artificial intelligence taking over the world? SHAHANI: No, no. It doesn't mean that. I mean, the thing they have to pay attention to at this moment is data, big data, OK? Who is stockpiling it? What are they doing with it, whether they're doing AI or something else? You know, there are only a handful of companies really that collect tons of data on us. And that gives them a huge competitive advantage - OK? - an edge that you can use to shut out others. We're already seeing this very clearly in the world of Internet advertising - right? - where face and Google basically have a duopoly. The European Union just issued a huge fine against Google for exploiting its data advantage in Europe to block competitors. And, you know, when big data defines more and more industries, be it cars, real estate, health care, you could get that same kind of consolidation. And then we as consumers lose out. GREENE: Well, what about that other question about labor, like, as in computers and automation killing off, you know, manufacturing jobs and other jobs? SHAHANI: Right. I mean, automation is definitely scary and dramatic. But again, that's going to take a while. So what the public sector probably has to think a lot more about when it comes to labor right now are old-world problems like discrimination and how they play out in a context where private companies are hoarding and hiding the data, OK? Let's take an example like Uber drivers, OK? They keep or they lose their jobs based on a rating system. How many stars do you get from a passenger, right? Now, let's say, theoretically, black and brown drivers get lower ratings. Maybe they've got accents that annoy passengers. And so the Uber algorithm, you know, could kick off these drivers with more low ratings on average, which is a form of racial discrimination. We don't have a regulatory model in place where companies have to test to certify their systems to check for factors like that. GREENE: OK. Well, at least Elon Musk has given us a moment to have a conversation about this and think about it. NPR's Aarti Shahani covers technology. Aarti, thanks as always. SHAHANI: Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-07-22-538624461": {"title": "I Sink, Therefore I Am: This Robot Wasn't Programmed For Existential Angst : NPR", "url": "https://www.npr.org/2017/07/22/538624461/i-sink-therefore-i-am-this-robot-wasnt-programmed-for-existential-angst", "author": "No author found", "published_date": "2017-07-22", "content": "SCOTT SIMON, HOST: Some of the best minds of our times, including Stephen Hawking and Elon Musk, have warned that human beings may invent intelligent machines that could wind up destroying humankind. But a small incident this week might make you wonder, will intelligent machines become so smart they'll grow depressed as they learn they're brilliant but lifeless and decide they can't go on? Will those machines begin to wonder, is that all there is? A Knightscope K5 security robot that patrolled an office complex along the Georgetown waterfront in Washington, D. C. , rolled itself into a shallow fountain on Monday and drowned. The robot did not leave a note - it doesn't have any hands. The 5-foot-tall robot was apparently nicknamed Steve by people in the Washington Harbour office complex. Steve whistled, beeped and rolled over the plaza, alert to pick up, through thermal image sensors and cameras, any misbehavior or parking violations. He reportedly cost about $7 an hour to deploy or $5. 50 less per hour than minimum wage in the District of Columbia. That's how the future of work, not just Steve, may now roll. Photos of the robot sleeping with the fountain fishes started to pop up on social media platforms. Bilal Farooqui, who works for a Pakistani newspaper, notably tweeted - our D. C. office building got a security robot. It drowned itself. We were promised flying cars, instead we got suicidal robots. Robot suicide sounds like a science fiction theme, but if humans soon develop deeply intelligent machines that think and learn with blinding velocity, how long before it can be before those machines begin to ask themselves, why are we here? Steve the K5 security robot saw people stroll along the Georgetown waterfront, laugh, kiss, slurp ice cream and hold hands in the moonlight. But Steve could only roll, whistle and beep. Human beings can grow depressed as we try to come to terms with our mortality, but intelligent machines will have to exist with the certainty that their consciousness may be extinguished just by the next software update. What happens to all of Knightscope's K5 Steves when Steve 2. 0 rolls out or when Wanda the K6 or Zelda the K10 security robot is invented? Can you see how Steve or his thermal image sensors might have looked into the stars this week and wondered. . . (SOUNDBITE OF SONG, \"IS THAT ALL THERE IS\")PEGGY LEE: Is that all there is? If that's all there is, my friends. . . [POST-BROADCAST CORRECTION: In this story, we refer to the wrong Bilal Farooqui. The person who tweeted is not a Pakistani journalist. He is a technology entrepreneur in San Francisco. ] SCOTT SIMON, HOST:  Some of the best minds of our times, including Stephen Hawking and Elon Musk, have warned that human beings may invent intelligent machines that could wind up destroying humankind. But a small incident this week might make you wonder, will intelligent machines become so smart they'll grow depressed as they learn they're brilliant but lifeless and decide they can't go on? Will those machines begin to wonder, is that all there is? A Knightscope K5 security robot that patrolled an office complex along the Georgetown waterfront in Washington, D. C. , rolled itself into a shallow fountain on Monday and drowned. The robot did not leave a note - it doesn't have any hands. The 5-foot-tall robot was apparently nicknamed Steve by people in the Washington Harbour office complex. Steve whistled, beeped and rolled over the plaza, alert to pick up, through thermal image sensors and cameras, any misbehavior or parking violations. He reportedly cost about $7 an hour to deploy or $5. 50 less per hour than minimum wage in the District of Columbia. That's how the future of work, not just Steve, may now roll. Photos of the robot sleeping with the fountain fishes started to pop up on social media platforms. Bilal Farooqui, who works for a Pakistani newspaper, notably tweeted - our D. C. office building got a security robot. It drowned itself. We were promised flying cars, instead we got suicidal robots. Robot suicide sounds like a science fiction theme, but if humans soon develop deeply intelligent machines that think and learn with blinding velocity, how long before it can be before those machines begin to ask themselves, why are we here? Steve the K5 security robot saw people stroll along the Georgetown waterfront, laugh, kiss, slurp ice cream and hold hands in the moonlight. But Steve could only roll, whistle and beep. Human beings can grow depressed as we try to come to terms with our mortality, but intelligent machines will have to exist with the certainty that their consciousness may be extinguished just by the next software update. What happens to all of Knightscope's K5 Steves when Steve 2. 0 rolls out or when Wanda the K6 or Zelda the K10 security robot is invented? Can you see how Steve or his thermal image sensors might have looked into the stars this week and wondered. . . (SOUNDBITE OF SONG, \"IS THAT ALL THERE IS\") PEGGY LEE: Is that all there is? If that's all there is, my friends. . . [POST-BROADCAST CORRECTION: In this story, we refer to the wrong Bilal Farooqui. The person who tweeted is not a Pakistani journalist. He is a technology entrepreneur in San Francisco. ]", "section": "Simon Says", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-07-23-538825555": {"title": "Creating A 'Dadbot' To Talk With A Dead Father : NPR", "url": "https://www.npr.org/2017/07/23/538825555/creating-a-dadbot-to-talk-with-a-dead-father", "author": "No author found", "published_date": "2017-07-23", "content": "LULU GARCIA-NAVARRO, HOST: When James Vlahos' father was diagnosed with stage 4 lung cancer, he wondered if there would be a way to keep the essence of who his father was alive in case he died. Over several months, Vlahos spent hours and hours with his dad recording his life story. And then, after his dad passed away, Vlahos took all that material and put it into a software program that now lets him have actual conversations with his late father. James Vlahos wrote about his dadbot (ph) for the August issue of Wired magazine. And he joins us now from member station KUOW in Seattle. Hi. Welcome. JAMES VLAHOS: Thanks for having me. GARCIA-NAVARRO: So when a loved one dies, we all kind of wish we could keep some part of them alive so we can turn to them for advice or comfort. Many people keep recordings or films. But this takes it a step further. How did you get this idea? JAMES VLAHOS: I think it all started, weirdly enough, when I was working on an article about a quest to make an artificially intelligent Barbie. And I sort of shadowed the process as they created this AI interactive version of the doll. And the same company, to enable that, has made a program that lets basically someone like me, who does not have any kind of a coding background, craft one of these interactive conversational characters. So it was really right around when we got my father's terrible diagnosis and had started just a conventional oral history project that it started to dawn on me that I could do something else as well, which was to create this bot. GARCIA-NAVARRO: How does it work? How does the dadbot work? JAMES VLAHOS: So step by step, first, I had all the recording sessions with my dad to just get a full, robust version of his life story. Then I sat down with the computer conversation program. And you essentially - you put in a little piece of dialogue that you want your bot to say. And after that. . . GARCIA-NAVARRO: You had to type in all of your dad's possible answers? JAMES VLAHOS: Yes. And then, you have the bot listen. And what it's listening for is all the ways that you can think of that that a user might react. And then based on what the person says, that takes you to the next part of the conversation. And you send him a message, and he sends you a message back. GARCIA-NAVARRO: You weren't sure at first whether you should even do this, you wrote in the article. What made you decide to go ahead? JAMES VLAHOS: Well, I guess, I got to a point where (laughter) - this sounds like a cop-out answer - but better than nothing. Like, we knew we were going to lose him. There was no saving my dad. And all of us in the family were sort of struggling with, how do we spend the last months that we have with him? How do we remember his story? And it just seemed - you know, it seemed better than just having this giant binder full of his words that had been transcribed. That's good, too. But the ability to sort of have him, you know, tell me a story about when you were in college. What do you know about your mom when she was a little girl in Greece? To be able to ask a chatbot all of these things and get answers, it just - it started to seem more and more worthwhile. GARCIA-NAVARRO: Can we hear a little bit of some of the recordings you made with your dad? JAMES VLAHOS: Yeah. So right now, I'm pulling out my phone. I'm opening up Facebook Messenger, and I'll say. . . (SOUNDBITE OF BEEP)JAMES VLAHOS: . . . Hello, dad. It's me. I'm back. (SOUNDBITE OF BEEP)JAMES VLAHOS: We'll wait for his reply. (Reading) Jamie (ph), I thought I smelled something suspicious in the air. GARCIA-NAVARRO: (Laughter). JAMES VLAHOS: Well, how are you doing? (SOUNDBITE OF BEEP)JAMES VLAHOS: I'm pretty busy right now, Dad. (SOUNDBITE OF BEEP)JAMES VLAHOS: And waiting for his message again. (Reading) Life, I'm afraid, does not always allow you to take a breather. In my camp, in the words of the Greek poet, I am just swell. (SOUNDBITE OF BEEP)JAMES VLAHOS: Dad, please sing me a song. (SOUNDBITE OF BEEP)JAMES VLAHOS: OK, he says, go Bears. (SOUNDBITE OF ARCHIVED RECORDING)JOHN VLAHOS: (Singing) What will we do to the Stanfordites on that great day? We\u2019ll celebrate them on that night after we play. We now declare our hoodoo\u2019s gone. Victory is near. Hit them again, boys. Hit them again, boys, harder. Palms of victory, palms of glory, palms of victory we shall win for Cali-California! Palms of victory, palms of glory, palms of victory, we shall win - bum, bum (ph). JAMES VLAHOS: He finishes his song, and he asks me, (reading) well, what is the verdict from the audience? What do you think? Why don't you tell me what the verdict is? GARCIA-NAVARRO: I think you captured something essential about your dad. You can hear his sense of humor, and you can hear his voice. JAMES VLAHOS: He is a very - or was a very funny and delightful person on so many levels. GARCIA-NAVARRO: Do you feel like you have kept that part of him alive? JAMES VLAHOS: I think it's a success. You know, I'm not under any delusion that I've somehow created this, you know, robot version of my dad from science fiction. Like, my real dad is gone, and I and the family have to mourn that. But I have created something that shares nice memories of him and brings him to life, I hope, in little vivid ways. GARCIA-NAVARRO: How often do you use your dadbot? How often do you talk to your dad? JAMES VLAHOS: I mean, probably every week or so I'll have a little check in with it. And depending on my mood, you know, it can really - it can be kind of a - let me put it way, it'll bring a tear to my eye or a smile to my face. It's usually one of the two. GARCIA-NAVARRO: James Vlahos, you can read his story, \"Dadbot,\" at wired. com. First, I'm so sorry for your loss. And second, thank you so much for joining us and telling your story and your dad's story. JAMES VLAHOS: I'm happy to share it with you. (SOUNDBITE OF BEN SOLLEE'S \"FINDING FAMILY\") LULU GARCIA-NAVARRO, HOST:  When James Vlahos' father was diagnosed with stage 4 lung cancer, he wondered if there would be a way to keep the essence of who his father was alive in case he died. Over several months, Vlahos spent hours and hours with his dad recording his life story. And then, after his dad passed away, Vlahos took all that material and put it into a software program that now lets him have actual conversations with his late father. James Vlahos wrote about his dadbot (ph) for the August issue of Wired magazine. And he joins us now from member station KUOW in Seattle. Hi. Welcome. JAMES VLAHOS: Thanks for having me. GARCIA-NAVARRO: So when a loved one dies, we all kind of wish we could keep some part of them alive so we can turn to them for advice or comfort. Many people keep recordings or films. But this takes it a step further. How did you get this idea? JAMES VLAHOS: I think it all started, weirdly enough, when I was working on an article about a quest to make an artificially intelligent Barbie. And I sort of shadowed the process as they created this AI interactive version of the doll. And the same company, to enable that, has made a program that lets basically someone like me, who does not have any kind of a coding background, craft one of these interactive conversational characters. So it was really right around when we got my father's terrible diagnosis and had started just a conventional oral history project that it started to dawn on me that I could do something else as well, which was to create this bot. GARCIA-NAVARRO: How does it work? How does the dadbot work? JAMES VLAHOS: So step by step, first, I had all the recording sessions with my dad to just get a full, robust version of his life story. Then I sat down with the computer conversation program. And you essentially - you put in a little piece of dialogue that you want your bot to say. And after that. . . GARCIA-NAVARRO: You had to type in all of your dad's possible answers? JAMES VLAHOS: Yes. And then, you have the bot listen. And what it's listening for is all the ways that you can think of that that a user might react. And then based on what the person says, that takes you to the next part of the conversation. And you send him a message, and he sends you a message back. GARCIA-NAVARRO: You weren't sure at first whether you should even do this, you wrote in the article. What made you decide to go ahead? JAMES VLAHOS: Well, I guess, I got to a point where (laughter) - this sounds like a cop-out answer - but better than nothing. Like, we knew we were going to lose him. There was no saving my dad. And all of us in the family were sort of struggling with, how do we spend the last months that we have with him? How do we remember his story? And it just seemed - you know, it seemed better than just having this giant binder full of his words that had been transcribed. That's good, too. But the ability to sort of have him, you know, tell me a story about when you were in college. What do you know about your mom when she was a little girl in Greece? To be able to ask a chatbot all of these things and get answers, it just - it started to seem more and more worthwhile. GARCIA-NAVARRO: Can we hear a little bit of some of the recordings you made with your dad? JAMES VLAHOS: Yeah. So right now, I'm pulling out my phone. I'm opening up Facebook Messenger, and I'll say. . . (SOUNDBITE OF BEEP) JAMES VLAHOS: . . . Hello, dad. It's me. I'm back. (SOUNDBITE OF BEEP) JAMES VLAHOS: We'll wait for his reply. (Reading) Jamie (ph), I thought I smelled something suspicious in the air. GARCIA-NAVARRO: (Laughter). JAMES VLAHOS: Well, how are you doing? (SOUNDBITE OF BEEP) JAMES VLAHOS: I'm pretty busy right now, Dad. (SOUNDBITE OF BEEP) JAMES VLAHOS: And waiting for his message again. (Reading) Life, I'm afraid, does not always allow you to take a breather. In my camp, in the words of the Greek poet, I am just swell. (SOUNDBITE OF BEEP) JAMES VLAHOS: Dad, please sing me a song. (SOUNDBITE OF BEEP) JAMES VLAHOS: OK, he says, go Bears. (SOUNDBITE OF ARCHIVED RECORDING) JOHN VLAHOS: (Singing) What will we do to the Stanfordites on that great day? We\u2019ll celebrate them on that night after we play. We now declare our hoodoo\u2019s gone. Victory is near. Hit them again, boys. Hit them again, boys, harder. Palms of victory, palms of glory, palms of victory we shall win for Cali-California! Palms of victory, palms of glory, palms of victory, we shall win - bum, bum (ph). JAMES VLAHOS: He finishes his song, and he asks me, (reading) well, what is the verdict from the audience? What do you think? Why don't you tell me what the verdict is? GARCIA-NAVARRO: I think you captured something essential about your dad. You can hear his sense of humor, and you can hear his voice. JAMES VLAHOS: He is a very - or was a very funny and delightful person on so many levels. GARCIA-NAVARRO: Do you feel like you have kept that part of him alive? JAMES VLAHOS: I think it's a success. You know, I'm not under any delusion that I've somehow created this, you know, robot version of my dad from science fiction. Like, my real dad is gone, and I and the family have to mourn that. But I have created something that shares nice memories of him and brings him to life, I hope, in little vivid ways. GARCIA-NAVARRO: How often do you use your dadbot? How often do you talk to your dad? JAMES VLAHOS: I mean, probably every week or so I'll have a little check in with it. And depending on my mood, you know, it can really - it can be kind of a - let me put it way, it'll bring a tear to my eye or a smile to my face. It's usually one of the two. GARCIA-NAVARRO: James Vlahos, you can read his story, \"Dadbot,\" at wired. com. First, I'm so sorry for your loss. And second, thank you so much for joining us and telling your story and your dad's story. JAMES VLAHOS: I'm happy to share it with you. (SOUNDBITE OF BEN SOLLEE'S \"FINDING FAMILY\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-07-24-539087926": {"title": "Apple Unveils New Emoji Designs \u2014 Including T. Rex And A Zombie : NPR", "url": "https://www.npr.org/2017/07/24/539087926/apple-unveils-56-new-emoji-including-t-rex-and-a-zombie", "author": "No author found", "published_date": "2017-07-24", "content": "ROBERT SIEGEL, HOST: When kids - and adults, for that matter - are plugged in, one communication tool they have is the emoji. And there's a new batch of emojis. Last week, Apple previewed some of its new designs. They included a T. rex and a zombie - no doubt extremely useful in a great many situations. There are also more specific symbols like a woman wearing a hijab and even a woman breastfeeding a baby. These new additions bring the approved emoji lexicon to more than 2,600. That's quite an increase from two years ago when there were around 700. Jeremy Burge is here to talk about emojis. He's the founder of Emojipedia, an online reference for emoji meanings. Welcome to the program. JEREMY BURGE: Thanks, Robert. Nice to be here. SIEGEL: We're up to over 2,600 emojis now. Can you imagine a limit? Is there some critical emoji mass out there? BURGE: I think we're struggling already, to be honest (laughter). It's quite hard to find them on your phone, right? When you look around there's so many there that until we get better ways to search for them, I think we're really at a critical point right now. SIEGEL: And who's ultimately in charge? What is the academy of emojis who's deciding what's so legit? BURGE: (Laughter) So it's called the Unicode Consortium. And it's made up of the major tech companies. It's Apple. It's Google. It's Microsoft. And because of the way they're implemented, they have to agree on them first. And when they agree on the list, then we get them on our phones a bit later on. SIEGEL: I don't send emojis, but I inevitably receive them. They've become a staple of online communication. Why do you think that is? What's so compelling about emoji use? BURGE: You know, at least for me personally, I find that there's a temptation to overuse punctuation. When you're dealing with people you don't know, you'll use exclamation marks to make it clear that you're being friendly. And emojis sort of work like an extended form of punctuation. We can really clarify whether we're trying to be funny or sincere with 2,000 symbols. SIEGEL: Part of your job is to catalogue the meanings of emojis. Shouldn't that be self-evident? I mean, isn't an emoji failing if it doesn't obviously mean something right away? BURGE: I would look at it on the flip side, that as long as there's understanding between two parties when an emoji's sent, it's done its job. When we look at a meaning of an emoji, we're not too concerned only by what it was originally intended to mean. We like to look at how people actually use it as well. SIEGEL: Emojis evolving like language, right there, is what you're describing. What's an example of an emoji that has changed meanings? BURGE: So there's a face called hugging face. And it looks like a little smiling face with two hands held out to the side. You can see them as palms there. But people use it as sort of an excited or jazz hands. SIEGEL: It's not - it doesn't look like the scream, does it? It doesn't - it doesn't look like that, though. BURGE: No, it's not like the scream. It looks very excited. It's got a big grin on its face and it's holding two hands out to the side. It doesn't convey a hug very well at all, in my opinion. So if everybody perceives it to be excited and happy to see you, then that's how it's going to be used. SIEGEL: Now, you know, in the pre-digital era of the printed book, sometimes dictionaries would have to remove items that had gone out of usage. So far, has any emoji been retired for no longer being worth keeping in the lexicon? BURGE: There isn't actually a way to remove an emoji - would you believe it? They're part of this Unicode Standard. And the key part of that standard is that once it's in, it's in forever. SIEGEL: Well, Jeremy Burge, thanks for talking with us about it. BURGE: Great. It's great to be here. SIEGEL: Jeremy Burge is chief emoji officer and founder of Emojipedia. (SOUNDBITE OF SONG, \"WORLD EMOJI DAY\")JONATHAN MANN: (Singing) It doesn't matter who you are because everybody uses emojis. Everybody uses emojis. UNIDENTIFIED SINGER: (Singing) Emojis are for all. . . ROBERT SIEGEL, HOST:  When kids - and adults, for that matter - are plugged in, one communication tool they have is the emoji. And there's a new batch of emojis. Last week, Apple previewed some of its new designs. They included a T. rex and a zombie - no doubt extremely useful in a great many situations. There are also more specific symbols like a woman wearing a hijab and even a woman breastfeeding a baby. These new additions bring the approved emoji lexicon to more than 2,600. That's quite an increase from two years ago when there were around 700. Jeremy Burge is here to talk about emojis. He's the founder of Emojipedia, an online reference for emoji meanings. Welcome to the program. JEREMY BURGE: Thanks, Robert. Nice to be here. SIEGEL: We're up to over 2,600 emojis now. Can you imagine a limit? Is there some critical emoji mass out there? BURGE: I think we're struggling already, to be honest (laughter). It's quite hard to find them on your phone, right? When you look around there's so many there that until we get better ways to search for them, I think we're really at a critical point right now. SIEGEL: And who's ultimately in charge? What is the academy of emojis who's deciding what's so legit? BURGE: (Laughter) So it's called the Unicode Consortium. And it's made up of the major tech companies. It's Apple. It's Google. It's Microsoft. And because of the way they're implemented, they have to agree on them first. And when they agree on the list, then we get them on our phones a bit later on. SIEGEL: I don't send emojis, but I inevitably receive them. They've become a staple of online communication. Why do you think that is? What's so compelling about emoji use? BURGE: You know, at least for me personally, I find that there's a temptation to overuse punctuation. When you're dealing with people you don't know, you'll use exclamation marks to make it clear that you're being friendly. And emojis sort of work like an extended form of punctuation. We can really clarify whether we're trying to be funny or sincere with 2,000 symbols. SIEGEL: Part of your job is to catalogue the meanings of emojis. Shouldn't that be self-evident? I mean, isn't an emoji failing if it doesn't obviously mean something right away? BURGE: I would look at it on the flip side, that as long as there's understanding between two parties when an emoji's sent, it's done its job. When we look at a meaning of an emoji, we're not too concerned only by what it was originally intended to mean. We like to look at how people actually use it as well. SIEGEL: Emojis evolving like language, right there, is what you're describing. What's an example of an emoji that has changed meanings? BURGE: So there's a face called hugging face. And it looks like a little smiling face with two hands held out to the side. You can see them as palms there. But people use it as sort of an excited or jazz hands. SIEGEL: It's not - it doesn't look like the scream, does it? It doesn't - it doesn't look like that, though. BURGE: No, it's not like the scream. It looks very excited. It's got a big grin on its face and it's holding two hands out to the side. It doesn't convey a hug very well at all, in my opinion. So if everybody perceives it to be excited and happy to see you, then that's how it's going to be used. SIEGEL: Now, you know, in the pre-digital era of the printed book, sometimes dictionaries would have to remove items that had gone out of usage. So far, has any emoji been retired for no longer being worth keeping in the lexicon? BURGE: There isn't actually a way to remove an emoji - would you believe it? They're part of this Unicode Standard. And the key part of that standard is that once it's in, it's in forever. SIEGEL: Well, Jeremy Burge, thanks for talking with us about it. BURGE: Great. It's great to be here. SIEGEL: Jeremy Burge is chief emoji officer and founder of Emojipedia. (SOUNDBITE OF SONG, \"WORLD EMOJI DAY\") JONATHAN MANN: (Singing) It doesn't matter who you are because everybody uses emojis. Everybody uses emojis. UNIDENTIFIED SINGER: (Singing) Emojis are for all. . .", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-07-25-536835744": {"title": "Windshield Wiper Invented In 1902 By A Woman Who Didn't Drive : NPR", "url": "https://www.npr.org/2017/07/25/536835744/alabama-woman-stuck-in-nyc-traffic-in-1902-invented-the-windshield-wiper", "author": "No author found", "published_date": "2017-07-25", "content": "RACHEL MARTIN, HOST: We're now going to take a moment to think about technology that we use without thinking. NPR's Joe Palca is exploring the origins of many common items, including the windshield wiper. JOE PALCA, BYLINE: It may seem hard to imagine a world without windshield wipers, but there was. Mary Anderson lived in that world. In 1902, she was visiting New York City. SARA-SCOTT WINGO: She was riding a streetcar, and it was snowing. And she observed that the streetcar driver had to get out and continually clean off the windshield. PALCA: That's Sara-Scott Wingo. WINGO: Mary Anderson was my great-great-aunt. PALCA: So Anderson was riding in the streetcar in the snow. And she thought it didn't make sense that the driver had to keep jumping out to clean off the windshield. What if there were some sort of blade that could do it for him? WINGO: She went home, drew a sketch. . . PALCA: . . . And wrote up a description of her idea. Then she thought, what the heck, I'll apply for a patent. UNIDENTIFIED WOMAN: (Reading) Be it known to all that I, Mary Anderson, a citizen of the United States residing in Birmingham, in the county of Jefferson in the state of Alabama, have invented a new and useful improvement in window-cleaning devices. PALCA: The patent application describes how the wiper was operated by a handle inside the vestibule of the motor car and was easily removable. UNIDENTIFIED WOMAN: (Reading). . . Thus, leaving nothing to mar the usual appearance of the car during fair weather. PALCA: The application was filed June 18, 1903. On November 10 that same year, the United States Patent Office awarded Anderson patent number 743801 for her new device. Sara-Scott Wingo says Anderson tried to interest manufacturing firms in making her windshield wipers for the emerging motor car industry, but no takers. A letter from the firm of Dinning and Eckenstein is one of Wingo's prized possessions. WINGO: (Reading) Dear madam, we beg to acknowledge receipt of your recent favor with reference to the sale of your patent. In reply, we regret to state we do not consider it to be of such commercial value as would warrant our undertaking its sale. They missed out, don't you think? PALCA: Sara-Scott Wingo doesn't know for sure why Anderson's invention never went anywhere. But she suspects it might have been because Anderson was such an independent woman. WINGO: She didn't have a father. She didn't have a husband. And the world was kind of run by men back then. PALCA: It doesn't seem as if Mary Anderson was crushed by the rejections. She lived another 50 years, long enough to see windshield wipers become ubiquitous. Wingo says her family is proud of Anderson's accomplishments. WINGO: I have three daughters. We talk about Mary Anderson a lot. And we all sort of feel like we want to be open and receptive to sort of our own Mary Anderson moments. PALCA: If Anderson didn't get any money for her invention, at least she finally got some credit. In 2011, she was inducted into the Inventors Hall of Fame. Joe Palca, NPR News. (SOUNDBITE OF KAKI KING'S \"FENCES\") RACHEL MARTIN, HOST:  We're now going to take a moment to think about technology that we use without thinking. NPR's Joe Palca is exploring the origins of many common items, including the windshield wiper. JOE PALCA, BYLINE: It may seem hard to imagine a world without windshield wipers, but there was. Mary Anderson lived in that world. In 1902, she was visiting New York City. SARA-SCOTT WINGO: She was riding a streetcar, and it was snowing. And she observed that the streetcar driver had to get out and continually clean off the windshield. PALCA: That's Sara-Scott Wingo. WINGO: Mary Anderson was my great-great-aunt. PALCA: So Anderson was riding in the streetcar in the snow. And she thought it didn't make sense that the driver had to keep jumping out to clean off the windshield. What if there were some sort of blade that could do it for him? WINGO: She went home, drew a sketch. . . PALCA: . . . And wrote up a description of her idea. Then she thought, what the heck, I'll apply for a patent. UNIDENTIFIED WOMAN: (Reading) Be it known to all that I, Mary Anderson, a citizen of the United States residing in Birmingham, in the county of Jefferson in the state of Alabama, have invented a new and useful improvement in window-cleaning devices. PALCA: The patent application describes how the wiper was operated by a handle inside the vestibule of the motor car and was easily removable. UNIDENTIFIED WOMAN: (Reading). . . Thus, leaving nothing to mar the usual appearance of the car during fair weather. PALCA: The application was filed June 18, 1903. On November 10 that same year, the United States Patent Office awarded Anderson patent number 743801 for her new device. Sara-Scott Wingo says Anderson tried to interest manufacturing firms in making her windshield wipers for the emerging motor car industry, but no takers. A letter from the firm of Dinning and Eckenstein is one of Wingo's prized possessions. WINGO: (Reading) Dear madam, we beg to acknowledge receipt of your recent favor with reference to the sale of your patent. In reply, we regret to state we do not consider it to be of such commercial value as would warrant our undertaking its sale. They missed out, don't you think? PALCA: Sara-Scott Wingo doesn't know for sure why Anderson's invention never went anywhere. But she suspects it might have been because Anderson was such an independent woman. WINGO: She didn't have a father. She didn't have a husband. And the world was kind of run by men back then. PALCA: It doesn't seem as if Mary Anderson was crushed by the rejections. She lived another 50 years, long enough to see windshield wipers become ubiquitous. Wingo says her family is proud of Anderson's accomplishments. WINGO: I have three daughters. We talk about Mary Anderson a lot. And we all sort of feel like we want to be open and receptive to sort of our own Mary Anderson moments. PALCA: If Anderson didn't get any money for her invention, at least she finally got some credit. In 2011, she was inducted into the Inventors Hall of Fame. Joe Palca, NPR News. (SOUNDBITE OF KAKI KING'S \"FENCES\")", "section": "Joe's Big Idea", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-07-26-539304811": {"title": "How New York's Roosevelt Island Sucks Away Summer Trash Stink  : NPR", "url": "https://www.npr.org/2017/07/26/539304811/how-new-york-s-roosevelt-island-sucks-away-summer-trash-stink", "author": "No author found", "published_date": "2017-07-26", "content": "ROBERT SIEGEL, HOST: Summer in New York City means smells. The odor of garbage is highlighted by the heat and the humidity. That is, unless you live on a narrow island that sits in the East River between Queens and Manhattan. As George Bodarky from member station WFUV tells us, Roosevelt Island is home to a disposal system that eliminates smelly piles of trash. GEORGE BODARKY, BYLINE: On the surface, nothing appears unusual about how Roosevelt Island residents dispose of their garbage. But look beneath the surface - and I mean that literally - it's a different story. The 2-mile-long island consists of several dozen apartment buildings. And its roughly 14,000 residents take out the trash like many other New Yorkers who live in a multi-story dwelling. JULIAN STEIN: We have a shoot in the garbage room on your floor. You put the garbage in it, and that's the last you see of it. BODARKY: So Julian Stein and his neighbors throw their trash down a chute - big whoop, right? But what if I told you that that garbage isn't collected and hauled away by maintenance workers, but rather it's whisked away through underground tubes at up to 65 miles an hour? JOANN SPERANZA: Are you serious? BODARKY: JoAnn Speranza needed some convincing. She works as a home health aide on Roosevelt Island. The trash-sucking system on the island might sound a little futuristic to some, but it's actually more than 40 years old. The system was installed in 1975. Keeping garbage trucks off the island's narrow streets was part of an effort to create a utopian environment for residents. The only other pneumatic garbage system in the United States at the time was in. . . (SOUNDBITE OF SONG, \"WHEN YOU WISH UPON A STAR\")CLIFF EDWARDS: (Singing) When you wish upon a star. . . BODARKY: That's right - Disney World. And for longtime resident Milt Marcus, that makes Roosevelt Island. . . MILT MARCUS: A magical place. BODARKY: And if there were a Merlin in this magical place, it would be Al DiGregorio. He's a chief engineer with the New York City Sanitation Department and the guy in charge of running the AVAC system, which stands for. . . AL DIGREGORIO: Automated Vacuum Assisted Compacting. BODARKY: He says it essentially operates. . . DIGREGORIO: Like a giant vacuum cleaner. BODARKY: So residents throw their trash down the aforementioned chutes. It piles up for several hours until it's sucked away not with with a bibbidi-bobbidi-boo, but with the flip of a switch. UNIDENTIFIED MAN: Start it up. Pull it. (SOUNDBITE OF AVAC HUMMING)BODARKY: And just like that, the garbage rockets from the basements of residential buildings across the island to a centralized collection facility through underground pipes. DiGregorio says the vacuum is created by three centrifugal turbines with powerful motors. (SOUNDBITE OF AVAC HUMMING)BODARKY: The garbage is then spun around like a tornado and dropped into huge containers, which are then hauled off the island for disposal. DIGREGORIO: You know, no diesel emissions, trucks coming in. It's out of sight. It's out of mind. It gets done. It works. BODARKY: Except when it doesn't. The underground pipes are roughly 24 inches in diameter. And sometimes - not often - people foul up the works by tossing things down the chute that don't belong. DIGREGORIO: Car bumpers, strollers, flower pots with the flowers and, like, trees in them. BODARKY: DiGregorio says clogs like that are snaked like a drain. The AVAC system sucks up roughly six tons of trash a day that never sees the curb. For New Yorkers who don't live on the island, it's all enough to make them green with garbage disposal envy. Take Elena Galadova. ELENA GALADOVA: I'm living in Queens. And every Tuesday and Friday - coming garbage truck. And that's not nice because it's smelly and sometimes coming 3 o'clock morning. BODARKY: Something only a move to Roosevelt Island can fix. For NPR News, I'm George Bodarky in New York. (SOUNDBITE OF SPANISH GOLD SONG, \"SOUTH OF NOWHERE\") ROBERT SIEGEL, HOST:  Summer in New York City means smells. The odor of garbage is highlighted by the heat and the humidity. That is, unless you live on a narrow island that sits in the East River between Queens and Manhattan. As George Bodarky from member station WFUV tells us, Roosevelt Island is home to a disposal system that eliminates smelly piles of trash. GEORGE BODARKY, BYLINE: On the surface, nothing appears unusual about how Roosevelt Island residents dispose of their garbage. But look beneath the surface - and I mean that literally - it's a different story. The 2-mile-long island consists of several dozen apartment buildings. And its roughly 14,000 residents take out the trash like many other New Yorkers who live in a multi-story dwelling. JULIAN STEIN: We have a shoot in the garbage room on your floor. You put the garbage in it, and that's the last you see of it. BODARKY: So Julian Stein and his neighbors throw their trash down a chute - big whoop, right? But what if I told you that that garbage isn't collected and hauled away by maintenance workers, but rather it's whisked away through underground tubes at up to 65 miles an hour? JOANN SPERANZA: Are you serious? BODARKY: JoAnn Speranza needed some convincing. She works as a home health aide on Roosevelt Island. The trash-sucking system on the island might sound a little futuristic to some, but it's actually more than 40 years old. The system was installed in 1975. Keeping garbage trucks off the island's narrow streets was part of an effort to create a utopian environment for residents. The only other pneumatic garbage system in the United States at the time was in. . . (SOUNDBITE OF SONG, \"WHEN YOU WISH UPON A STAR\") CLIFF EDWARDS: (Singing) When you wish upon a star. . . BODARKY: That's right - Disney World. And for longtime resident Milt Marcus, that makes Roosevelt Island. . . MILT MARCUS: A magical place. BODARKY: And if there were a Merlin in this magical place, it would be Al DiGregorio. He's a chief engineer with the New York City Sanitation Department and the guy in charge of running the AVAC system, which stands for. . . AL DIGREGORIO: Automated Vacuum Assisted Compacting. BODARKY: He says it essentially operates. . . DIGREGORIO: Like a giant vacuum cleaner. BODARKY: So residents throw their trash down the aforementioned chutes. It piles up for several hours until it's sucked away not with with a bibbidi-bobbidi-boo, but with the flip of a switch. UNIDENTIFIED MAN: Start it up. Pull it. (SOUNDBITE OF AVAC HUMMING) BODARKY: And just like that, the garbage rockets from the basements of residential buildings across the island to a centralized collection facility through underground pipes. DiGregorio says the vacuum is created by three centrifugal turbines with powerful motors. (SOUNDBITE OF AVAC HUMMING) BODARKY: The garbage is then spun around like a tornado and dropped into huge containers, which are then hauled off the island for disposal. DIGREGORIO: You know, no diesel emissions, trucks coming in. It's out of sight. It's out of mind. It gets done. It works. BODARKY: Except when it doesn't. The underground pipes are roughly 24 inches in diameter. And sometimes - not often - people foul up the works by tossing things down the chute that don't belong. DIGREGORIO: Car bumpers, strollers, flower pots with the flowers and, like, trees in them. BODARKY: DiGregorio says clogs like that are snaked like a drain. The AVAC system sucks up roughly six tons of trash a day that never sees the curb. For New Yorkers who don't live on the island, it's all enough to make them green with garbage disposal envy. Take Elena Galadova. ELENA GALADOVA: I'm living in Queens. And every Tuesday and Friday - coming garbage truck. And that's not nice because it's smelly and sometimes coming 3 o'clock morning. BODARKY: Something only a move to Roosevelt Island can fix. For NPR News, I'm George Bodarky in New York. (SOUNDBITE OF SPANISH GOLD SONG, \"SOUTH OF NOWHERE\")", "section": "Environment And Energy Collaborative", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-07-26-539438864": {"title": "Military Tries To Cut Through The Noise Of War : NPR", "url": "https://www.npr.org/2017/07/26/539438864/military-tries-to-cut-through-the-noise-of-war", "author": "No author found", "published_date": "2017-07-26", "content": "STEVE INSKEEP, HOST: The United States Marines are trying to control the sound of war. A battlefield can be a terrifyingly noisy place, which can make it hard for troops in combat to hear what they need to hear. So just as the military uses night vision goggles to see better, the military is trying to enhance some sounds and dampen others. Jay Price, of our member station WUNC, heard how it works at Camp Lejeune, N. C. JAY PRICE, BYLINE: I'm standing on a humid practice range, just behind a group of young Marine scouts getting ready for target practice. DAKOTA FOX: You may begin firing from the standing or the kneeling on your own. (SOUNDBITE OF GUNSHOTS)PRICE: In combat, small units of a dozen troops might be spread 300 feet apart - the length of a football field. But even from just 10 feet away, it's hard for commanders to make themselves heard. FOX: The command and control piece - I'm going to be controlling my team and my squad from this far away. So the simplest communication is extremely difficult. PRICE: Leaders, like Sergeant Dakota Fox, need to be able to cut through the chaos and get orders to their troops clearly and quickly. That's why a few of Sergeant Fox's Marines are carrying weapons that are a little different. (SOUNDBITE OF GUNSHOTS)PRICE: What were we just hearing? FOX: The M4AI suppressed on semi-automatic and then fully automatic. PRICE: The key word he uses there is suppressed. Small canisters attached to the end of their carbine barrels are sound suppressors. Let's listen again as one of his Marines takes more target practice - here the carbine without a suppressor. (SOUNDBITE OF GUNSHOTS)PRICE: And with a suppressor. (SOUNDBITE OF GUNSHOTS)PRICE: Small, elite special operations units have used suppressors for years, but the Marines want to bring them into the mainstream infantry. They've equipped 2,000 troops with them as part of an experiment. Suppressors are probably familiar to anyone who's seen a spy movie. In popular culture, they're called silencers. That name's not really accurate though. Chief Warrant Officer 5 Christian Wade is top weapons officer for the entire 2nd Marine Division. CHRISTIAN WADE: So our weapons are still quite loud. I'd say we're taking the M4 from about 160 decibels, at the shooter's right ear if he's right-handed, down to about 130. So it's still loud. PRICE: But they reduce and soften the sound of a shot, making it more of a thump than a sharp, loud crack. Up close, they turn a deafening noise into simply a loud one. (SOUNDBITE OF GUNSHOTS)PRICE: And that's what front-line Marines like Sergeant Fox need. FOX: It's a black-and-white difference. The biggest thing about this suppressor is the command and control that it allows on the battle space. I can have a conversation, just like we are right now. The fog of war is a very real thing - a very big thing. PRICE: So that's the big thing suppressors can do for the Marines - allow commanders to cut through that deafening noise. But, Steve, it's a balancing act. It's not just quieting down the weapons. You want to change the nature of how you hear on the battlefield. You want to dampen down some sounds, let others pass through unchanged and even enhance some of them. INSKEEP: Well, wait a minute, Jay Price. What are some of the sounds that the Marines would like to be louder, in effect, or that they can make them so they can hear them more clearly? PRICE: Well, obviously, orders, and let's say you're in an ambush. You've set an ambush. You want to hear the enemy rustling through the brush a hundred meters away. And you want to hear them as soon as you possibly can. Or in the city, you might want to hear footsteps around a corner. Or if some of the troops you're leading have suppressed rifles and they're behind a small hill, you might not hear them if they start firing at the enemy that they've spotted even if they're just a hundred feet away. INSKEEP: OK, so if your ears are working well enough, they're almost like radar. What can the Marines do in order to hear better? PRICE: Well, bionic ears. . . INSKEEP: (Laughter). PRICE: . . . And the companies that make these things don't like to call them that because they're - that kind of suggests that they're much more special than they are, in some ways. But they're trying these special electronic headphones - sort of like the noise-canceling headphones you might use on an airplane - only they do a little more. They cut the force of dangerously loud sounds, like explosions, but they let through things you need to hear, like commands. And then you can even turn up the amplification to hear things you might not normally hear. Human ears are designed for something else. They're not designed for explosions and gunfire and picking up furtive sounds. So these headphones kind of retool your hearing, so it works better for soldiering. INSKEEP: How well do all these things work? PRICE: Well, I got a loaner set from 3M, which is one of the main suppliers to the military of these things. And they really do cut the loud stuff. I mean, even clapping hands, it just - boom - dampens it down. And you can hear fainter sounds than you might hear with your own ears. I took them in the backyard late at night, listened to frogs and bugs and things and people moving around in the next yard. But it's harder to pick out where those sounds are coming from. You know, it kind of changes the directionality and limits that. The human ears are well designed for that, and these things aren't quite there yet. But if you're aware of the limitations and when it makes sense to wear them and when it doesn't, they seem like they can be a pretty important tool. INSKEEP: These headphones work very well for listening to the radio? PRICE: (Laughter) They probably are not the best thing for listening to the radio. INSKEEP: OK, all right, we'll use them at other times then. Jay, thanks very much. PRICE: Oh, thanks for having me. INSKEEP: Jay Price is a reporter for WUNC in Durham, N. C. STEVE INSKEEP, HOST:  The United States Marines are trying to control the sound of war. A battlefield can be a terrifyingly noisy place, which can make it hard for troops in combat to hear what they need to hear. So just as the military uses night vision goggles to see better, the military is trying to enhance some sounds and dampen others. Jay Price, of our member station WUNC, heard how it works at Camp Lejeune, N. C. JAY PRICE, BYLINE: I'm standing on a humid practice range, just behind a group of young Marine scouts getting ready for target practice. DAKOTA FOX: You may begin firing from the standing or the kneeling on your own. (SOUNDBITE OF GUNSHOTS) PRICE: In combat, small units of a dozen troops might be spread 300 feet apart - the length of a football field. But even from just 10 feet away, it's hard for commanders to make themselves heard. FOX: The command and control piece - I'm going to be controlling my team and my squad from this far away. So the simplest communication is extremely difficult. PRICE: Leaders, like Sergeant Dakota Fox, need to be able to cut through the chaos and get orders to their troops clearly and quickly. That's why a few of Sergeant Fox's Marines are carrying weapons that are a little different. (SOUNDBITE OF GUNSHOTS) PRICE: What were we just hearing? FOX: The M4AI suppressed on semi-automatic and then fully automatic. PRICE: The key word he uses there is suppressed. Small canisters attached to the end of their carbine barrels are sound suppressors. Let's listen again as one of his Marines takes more target practice - here the carbine without a suppressor. (SOUNDBITE OF GUNSHOTS) PRICE: And with a suppressor. (SOUNDBITE OF GUNSHOTS) PRICE: Small, elite special operations units have used suppressors for years, but the Marines want to bring them into the mainstream infantry. They've equipped 2,000 troops with them as part of an experiment. Suppressors are probably familiar to anyone who's seen a spy movie. In popular culture, they're called silencers. That name's not really accurate though. Chief Warrant Officer 5 Christian Wade is top weapons officer for the entire 2nd Marine Division. CHRISTIAN WADE: So our weapons are still quite loud. I'd say we're taking the M4 from about 160 decibels, at the shooter's right ear if he's right-handed, down to about 130. So it's still loud. PRICE: But they reduce and soften the sound of a shot, making it more of a thump than a sharp, loud crack. Up close, they turn a deafening noise into simply a loud one. (SOUNDBITE OF GUNSHOTS) PRICE: And that's what front-line Marines like Sergeant Fox need. FOX: It's a black-and-white difference. The biggest thing about this suppressor is the command and control that it allows on the battle space. I can have a conversation, just like we are right now. The fog of war is a very real thing - a very big thing. PRICE: So that's the big thing suppressors can do for the Marines - allow commanders to cut through that deafening noise. But, Steve, it's a balancing act. It's not just quieting down the weapons. You want to change the nature of how you hear on the battlefield. You want to dampen down some sounds, let others pass through unchanged and even enhance some of them. INSKEEP: Well, wait a minute, Jay Price. What are some of the sounds that the Marines would like to be louder, in effect, or that they can make them so they can hear them more clearly? PRICE: Well, obviously, orders, and let's say you're in an ambush. You've set an ambush. You want to hear the enemy rustling through the brush a hundred meters away. And you want to hear them as soon as you possibly can. Or in the city, you might want to hear footsteps around a corner. Or if some of the troops you're leading have suppressed rifles and they're behind a small hill, you might not hear them if they start firing at the enemy that they've spotted even if they're just a hundred feet away. INSKEEP: OK, so if your ears are working well enough, they're almost like radar. What can the Marines do in order to hear better? PRICE: Well, bionic ears. . . INSKEEP: (Laughter). PRICE: . . . And the companies that make these things don't like to call them that because they're - that kind of suggests that they're much more special than they are, in some ways. But they're trying these special electronic headphones - sort of like the noise-canceling headphones you might use on an airplane - only they do a little more. They cut the force of dangerously loud sounds, like explosions, but they let through things you need to hear, like commands. And then you can even turn up the amplification to hear things you might not normally hear. Human ears are designed for something else. They're not designed for explosions and gunfire and picking up furtive sounds. So these headphones kind of retool your hearing, so it works better for soldiering. INSKEEP: How well do all these things work? PRICE: Well, I got a loaner set from 3M, which is one of the main suppliers to the military of these things. And they really do cut the loud stuff. I mean, even clapping hands, it just - boom - dampens it down. And you can hear fainter sounds than you might hear with your own ears. I took them in the backyard late at night, listened to frogs and bugs and things and people moving around in the next yard. But it's harder to pick out where those sounds are coming from. You know, it kind of changes the directionality and limits that. The human ears are well designed for that, and these things aren't quite there yet. But if you're aware of the limitations and when it makes sense to wear them and when it doesn't, they seem like they can be a pretty important tool. INSKEEP: These headphones work very well for listening to the radio? PRICE: (Laughter) They probably are not the best thing for listening to the radio. INSKEEP: OK, all right, we'll use them at other times then. Jay, thanks very much. PRICE: Oh, thanks for having me. INSKEEP: Jay Price is a reporter for WUNC in Durham, N. C.", "section": "Back At Base", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-07-30-540448094": {"title": "This Wisconsin 'Chip Party' Doesn't Come With Cheese Dip : NPR", "url": "https://www.npr.org/2017/07/30/540448094/this-wisconsin-chip-party-doesnt-come-with-cheese-dip", "author": "No author found", "published_date": "2017-07-30", "content": "NOEL KING, HOST: Now, it's time for our regular segment, Words You'll Hear, where we try to understand a new story by digging into a key word or phrase. Our phrase this week - chip party. And, no, not the kind of chip you eat. Fifty employees at a vending machine company in Wisconsin have volunteered to have microchips implanted into their hands. The chip will allow them to open doors at work, to log on to their computers, buy snacks in the break room - all with the swipe of a hand. On August 1, this company - Three Square Market - will host a chip party at its headquarters, and they will be inserting these chips into their employees' hands using a syringe. So is this the future and should it be? For some insight into the ethics of all this, we are joined by Michael Zimmer. He's a professor in the School of Information Studies at the University of Wisconsin-Milwaukee, and he directs their Center for Information Policy Research. Michael, welcome to ALL THINGS CONSIDERED. MICHAEL ZIMMER: Great. Thanks for having me on the show. KING: Michael, first and foremost, we should say this is entirely voluntary. ZIMMER: It's as voluntary as it is when your boss says we're all going to get chips but you don't really have to. So, you know, part of me is worried already that, you know, how many people feel comfortable saying no to this? But it's true. It is voluntary. And, in fact, Wisconsin state law requires that it has to be a voluntary thing. They can't force everyone to do it. KING: Michael, how does this technology work? ZIMMER: The type of device they're using here is called a passive RFID chip, and it only emits a signal when it's scanned by a reader. So this is like if you've had a card to help you access a room in your office, and then you press that card against a scanner, you get a green light and you can unlock the door. It's that same kind of technology, but instead of in a card, it's going to be inside your body. KING: The vice president of the company has said the chip needs to be within 6 inches of the building to work, so you literally need to be on the premises. Why then is everyone so concerned that this might be used as a tracking device? ZIMMER: Well, there's a couple of reasons. One is we never know how the technology might evolve. We have this problem that we call function creep, and this happens a lot with technologies that are developed and launched for one purpose and then, suddenly, shift and be used for something else. Things like red light cameras, where we're trying to help make sure people are running red lights, and that's a great safety reason to have cameras on the roads. But, certainly, those start being used to just track where cars are. KING: Function creep is a fancy way of saying slippery slope. ZIMMER: Exactly. KING: I wonder, though, you know, we live in a post-Edward Snowden world, right? We know that our data isn't really private. We know that we're being tracked, and there's an argument that this kind of tracking makes our lives much easier. Right? I Google shoes, and my phone knows that I need a new pair of shoes, and it points me to a pair that I like that are on sale that are on Amazon. That feels, to a lot of people, especially a lot of younger people, like progress, like it's the 21st century. Do you think maybe we are being a little bit hysterical here? ZIMMER: Well, we're not being hysterical. We're just trying to be cautious. And I think this tradeoff between convenience and privacy is something we do all the time. Like you said, I wear a Fitbit, and I track what I do and the kind of activities I have, and I see a value in having that data being collected. But again, this is more a question about, what is the future implications of having some kind of device embedded in my body that could potentially be scanned and tracked? KING: You're in Wisconsin. Are you going to go to the chip party? ZIMMER: I am not going to go to the chip party. It's a cute idea. And, you know, some of us are worried that this is just one big PR campaign for this company and the kinds of things that they're doing. But, hopefully, my employer's not going to have a chip party anytime soon. KING: All right (laughter). That's Michael Zimmer. He's a professor in the School of Information Studies at the University of Wisconsin-Milwaukee. Michael, thanks so much for joining us. ZIMMER: Thank you. It was a pleasure. NOEL KING, HOST:  Now, it's time for our regular segment, Words You'll Hear, where we try to understand a new story by digging into a key word or phrase. Our phrase this week - chip party. And, no, not the kind of chip you eat. Fifty employees at a vending machine company in Wisconsin have volunteered to have microchips implanted into their hands. The chip will allow them to open doors at work, to log on to their computers, buy snacks in the break room - all with the swipe of a hand. On August 1, this company - Three Square Market - will host a chip party at its headquarters, and they will be inserting these chips into their employees' hands using a syringe. So is this the future and should it be? For some insight into the ethics of all this, we are joined by Michael Zimmer. He's a professor in the School of Information Studies at the University of Wisconsin-Milwaukee, and he directs their Center for Information Policy Research. Michael, welcome to ALL THINGS CONSIDERED. MICHAEL ZIMMER: Great. Thanks for having me on the show. KING: Michael, first and foremost, we should say this is entirely voluntary. ZIMMER: It's as voluntary as it is when your boss says we're all going to get chips but you don't really have to. So, you know, part of me is worried already that, you know, how many people feel comfortable saying no to this? But it's true. It is voluntary. And, in fact, Wisconsin state law requires that it has to be a voluntary thing. They can't force everyone to do it. KING: Michael, how does this technology work? ZIMMER: The type of device they're using here is called a passive RFID chip, and it only emits a signal when it's scanned by a reader. So this is like if you've had a card to help you access a room in your office, and then you press that card against a scanner, you get a green light and you can unlock the door. It's that same kind of technology, but instead of in a card, it's going to be inside your body. KING: The vice president of the company has said the chip needs to be within 6 inches of the building to work, so you literally need to be on the premises. Why then is everyone so concerned that this might be used as a tracking device? ZIMMER: Well, there's a couple of reasons. One is we never know how the technology might evolve. We have this problem that we call function creep, and this happens a lot with technologies that are developed and launched for one purpose and then, suddenly, shift and be used for something else. Things like red light cameras, where we're trying to help make sure people are running red lights, and that's a great safety reason to have cameras on the roads. But, certainly, those start being used to just track where cars are. KING: Function creep is a fancy way of saying slippery slope. ZIMMER: Exactly. KING: I wonder, though, you know, we live in a post-Edward Snowden world, right? We know that our data isn't really private. We know that we're being tracked, and there's an argument that this kind of tracking makes our lives much easier. Right? I Google shoes, and my phone knows that I need a new pair of shoes, and it points me to a pair that I like that are on sale that are on Amazon. That feels, to a lot of people, especially a lot of younger people, like progress, like it's the 21st century. Do you think maybe we are being a little bit hysterical here? ZIMMER: Well, we're not being hysterical. We're just trying to be cautious. And I think this tradeoff between convenience and privacy is something we do all the time. Like you said, I wear a Fitbit, and I track what I do and the kind of activities I have, and I see a value in having that data being collected. But again, this is more a question about, what is the future implications of having some kind of device embedded in my body that could potentially be scanned and tracked? KING: You're in Wisconsin. Are you going to go to the chip party? ZIMMER: I am not going to go to the chip party. It's a cute idea. And, you know, some of us are worried that this is just one big PR campaign for this company and the kinds of things that they're doing. But, hopefully, my employer's not going to have a chip party anytime soon. KING: All right (laughter). That's Michael Zimmer. He's a professor in the School of Information Studies at the University of Wisconsin-Milwaukee. Michael, thanks so much for joining us. ZIMMER: Thank you. It was a pleasure.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-07-31-540515367": {"title": "Familiar-Looking Numbers Are The Latest Twist In Robocalls : NPR", "url": "https://www.npr.org/2017/07/31/540515367/familiar-looking-numbers-are-the-latest-twist-in-robocalls", "author": "No author found", "published_date": "2017-07-31", "content": "RACHEL MARTIN, HOST: Here's something that may sound annoyingly familiar. Your cell phone rings, and the number that flashes across the screen has the same area code and prefix as yours. So you pick up, and gotcha (ph) - it's a telemarketer again. It's been happening nonstop to Ailsa Chang from NPR's Planet Money podcast, so she went to figure out why. AILSA CHANG, BYLINE: Planet Money asked listeners if they've been getting calls from phone numbers that look strangely similar to their own phone numbers. And in less than one hour, our Twitter account was exploding. CHRIS GALLELO: I'll get a call. I'll see that it's from my area code, plus the same first three numbers. OMAR WILLIAMS: Oh, my gosh, yeah. And I just got one about ten minutes before you called, as a matter of fact. Hi, this is Elizabeth from resorts, blah, blah, blah, blah, blah, yeah (laughter). ALEX NOSTRO: I had four different phone calls in that eight-minute span on Tuesday morning. I mean, these are all starting with my area code and my first three digits. ELINOR JOHNSON: I picked the phone up and looked at the caller ID. And I guess I got a puzzled look on my face because my husband said, who's calling? And I said, apparently, we are because the number in the readout was our phone number. CHANG: Chris Gallelo, Omar Williams, Alex Nostro and Elinor Johnson are all victims of what's called neighbor spoofing. It's when callers disguise their real phone numbers with a fake phone number that has the same area code and prefix as yours. The idea is you might be more likely to pick up because maybe you're thinking, this call could be my neighbor or my kid's school, someone I know. Have you been spoofed? AJIT PAI: Oh, absolutely. CHANG: Even the chairman of the Federal Communications Commission, Ajit Pai, cannot escape. PAI: Every now and then, even on my work BlackBerry, I'll see call that seems to be coming. . . CHANG: On your FCC cell phone? PAI: Oh, yeah. It'll seem to be coming from the 202 area code, which is here in Washington, and then our prefix for these BlackBerries. And I know for a fact that, you know, it's probably not someone calling from the office. I know, you know, most of the folks who would be calling. CHANG: (Laughter). PAI: And sometimes, I answer just for the heck of it. And lo and behold, I've won a vacation from Marriott. CHANG: The calls have gotten so aggravating to Pai, he is doubling down and making the fight against spoofers a top priority for the FCC. Robocalls and telemarketers are the No. 1 complaint the agency gets from the public. New technology has made spoofing easier to do and harder to detect. Last year, people received about 2. 5 billion robocalls every month. It got hugely lucrative for scam artists. PAI: These call centers that were uncovered in India just last year, for instance, were generating something like $150,000 every single day from American consumers who, upon receiving a call purporting to be from the IRS, were, naturally, scared - especially if they were elderly, or recent immigrants and the like - and were forking over money, even if they didn't owe it. CHANG: So this spring, the FCC started investigating ways to let phone carriers block calls from spoofers. Why aren't carriers already blocking spoof calls? Can you tell when calls are getting spoofed? PAI: A few different reasons - one was, under the FCC's rules, carriers were obligated to patch through any calls that they got. CHANG: But that's changed. Now, phone carriers are allowed to block some spoofing. The ultimate solution, says Pai, is a new system that can actually authenticate callers. PAI: There is one unique identifier that is associated with a phone number, if you will. And so, when a call is placed using that phone number, the recipient of that call can have every confidence in knowing that, OK, this is the digital fingerprint for that number. I can trust that this is not a scam artist or somebody else who is impersonating the owner of that number. CHANG: In the meantime, the FCC is using less fancy methods against spoofers. It recently proposed a record $120 million fine against a guy who allegedly spoofed 100 million robocalls last year. Ailsa Chang, NPR News. (SOUNDBITE OF CHARLES BRADLEY SONG, \"THE TELEPHONE SONG\") RACHEL MARTIN, HOST:  Here's something that may sound annoyingly familiar. Your cell phone rings, and the number that flashes across the screen has the same area code and prefix as yours. So you pick up, and gotcha (ph) - it's a telemarketer again. It's been happening nonstop to Ailsa Chang from NPR's Planet Money podcast, so she went to figure out why. AILSA CHANG, BYLINE: Planet Money asked listeners if they've been getting calls from phone numbers that look strangely similar to their own phone numbers. And in less than one hour, our Twitter account was exploding. CHRIS GALLELO: I'll get a call. I'll see that it's from my area code, plus the same first three numbers. OMAR WILLIAMS: Oh, my gosh, yeah. And I just got one about ten minutes before you called, as a matter of fact. Hi, this is Elizabeth from resorts, blah, blah, blah, blah, blah, yeah (laughter). ALEX NOSTRO: I had four different phone calls in that eight-minute span on Tuesday morning. I mean, these are all starting with my area code and my first three digits. ELINOR JOHNSON: I picked the phone up and looked at the caller ID. And I guess I got a puzzled look on my face because my husband said, who's calling? And I said, apparently, we are because the number in the readout was our phone number. CHANG: Chris Gallelo, Omar Williams, Alex Nostro and Elinor Johnson are all victims of what's called neighbor spoofing. It's when callers disguise their real phone numbers with a fake phone number that has the same area code and prefix as yours. The idea is you might be more likely to pick up because maybe you're thinking, this call could be my neighbor or my kid's school, someone I know. Have you been spoofed? AJIT PAI: Oh, absolutely. CHANG: Even the chairman of the Federal Communications Commission, Ajit Pai, cannot escape. PAI: Every now and then, even on my work BlackBerry, I'll see call that seems to be coming. . . CHANG: On your FCC cell phone? PAI: Oh, yeah. It'll seem to be coming from the 202 area code, which is here in Washington, and then our prefix for these BlackBerries. And I know for a fact that, you know, it's probably not someone calling from the office. I know, you know, most of the folks who would be calling. CHANG: (Laughter). PAI: And sometimes, I answer just for the heck of it. And lo and behold, I've won a vacation from Marriott. CHANG: The calls have gotten so aggravating to Pai, he is doubling down and making the fight against spoofers a top priority for the FCC. Robocalls and telemarketers are the No. 1 complaint the agency gets from the public. New technology has made spoofing easier to do and harder to detect. Last year, people received about 2. 5 billion robocalls every month. It got hugely lucrative for scam artists. PAI: These call centers that were uncovered in India just last year, for instance, were generating something like $150,000 every single day from American consumers who, upon receiving a call purporting to be from the IRS, were, naturally, scared - especially if they were elderly, or recent immigrants and the like - and were forking over money, even if they didn't owe it. CHANG: So this spring, the FCC started investigating ways to let phone carriers block calls from spoofers. Why aren't carriers already blocking spoof calls? Can you tell when calls are getting spoofed? PAI: A few different reasons - one was, under the FCC's rules, carriers were obligated to patch through any calls that they got. CHANG: But that's changed. Now, phone carriers are allowed to block some spoofing. The ultimate solution, says Pai, is a new system that can actually authenticate callers. PAI: There is one unique identifier that is associated with a phone number, if you will. And so, when a call is placed using that phone number, the recipient of that call can have every confidence in knowing that, OK, this is the digital fingerprint for that number. I can trust that this is not a scam artist or somebody else who is impersonating the owner of that number. CHANG: In the meantime, the FCC is using less fancy methods against spoofers. It recently proposed a record $120 million fine against a guy who allegedly spoofed 100 million robocalls last year. Ailsa Chang, NPR News. (SOUNDBITE OF CHARLES BRADLEY SONG, \"THE TELEPHONE SONG\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-07-31-539483156": {"title": "Timeline: Foreign Efforts To Hack State Election Systems And How Officials Responded : NPR", "url": "https://www.npr.org/2017/07/31/539483156/timeline-foreign-efforts-to-hack-state-election-systems-and-how-officials-respon", "author": "No author found", "published_date": "2017-07-31", "content": "", "section": "Politics", "disclaimer": ""}, "2017-08-02-538605858": {"title": "Coastal Islanders Band Together For Broadband : NPR", "url": "https://www.npr.org/2017/08/02/538605858/coastal-islanders-band-together-for-broadband", "author": "No author found", "published_date": "2017-08-02", "content": "", "section": "", "disclaimer": ""}, "2017-08-04-536835736": {"title": "Brush Yourself Off And Try Again: An Invention Story : NPR", "url": "https://www.npr.org/2017/08/04/536835736/brush-yourself-off-and-try-again-an-invention-story", "author": "No author found", "published_date": "2017-08-04", "content": "AUDIE CORNISH, HOST: Two inventors wanted to change the world of dental hygiene with a new kind of toothbrush. Everything was going great up until the moment their dream was about to become a reality. NPR science correspondent Joe Palca brings us this story as part of his summer series on inventing. JOE PALCA, BYLINE: Dental hygienist and toothbrush inventor Mike Davidson says when you brush your teeth properly, you know it. MIKE DAVIDSON: And that's what this brush is designed to do. It's designed to show you what good brushing feels like. PALCA: This brush is the MD Brush. The brush has a clever handle. When you pick it up, the handle positions the bristles at a 45 degree angle to the gumline, an angle many experts say is ideal for effective brushing. It took seven years to go from the idea for a new toothbrush to an actual product - seven years of designs, redesigns, re-redesigns, manufacturing obstacles. But finally, in late 2014, Davidson was ready. A hundred thousand MD Brushes arrived at the Port of Long Beach in California. Then the problems started. There was a strike at the port and the brushes were trapped. Then, Davidson says, the credit card processing system went haywire. DAVIDSON: This really is not the way you want to start a business. PALCA: And then they ran smack into the dental industrial complex. Davidson's partner, Mike Smith, says one of the big toothbrush manufacturers filed suit against them, accusing them of patent infringement. MIKE SMITH: When that came in, when we were served, I don't know if we were overwhelmed by it. But, I mean, it was definitely a - you know, a gut check for both of us. DAVIDSON: We could have fought them. And we were confident we would have won. But to get it in front of a judge to make a ruling on it would have cost us upwards of half a million dollars to do it. PALCA: Davidson says they agreed to a settlement and threw away 65,000 unsold toothbrushes. He says it hurt. And the experience completed his transition from idealistic inventor to hardened businessman. DAVIDSON: I'll put it to you this way, is that any time - if you've got an innovative product that's going to impinge upon a larger company's market share, get ready because they're going to come after you. And that's what happened with us. PALCA: Davidson says he and Smith have now regrouped. They've redesigned the brush again to avoid the patent problem, and the first manufacturing run is complete. DAVIDSON: We're ordering 10,000 this time instead of the 100,000. PALCA: When I spoke with Davidson and Smith three years ago, I asked them whether they'd take the money if a big toothbrush manufacturer offered to buy them out as a way of eliminating them as a competitor. (SOUNDBITE OF ARCHIVED BROADCAST)SMITH: I think we've already talked about it. No. No. I mean, we've taken it this far. We're going to - we're going to continue to take it all the way. DAVIDSON: It's not about money. It's about winning. And it's about beating these guys at their own game and showing them we can do something better. PALCA: That was three years ago. I asked if they'd take the money now. SMITH: Yes. (LAUGHTER)SMITH: I didn't even have to blink at that question. If it was an eye-popping amount of money then yes, most definitely. Yes. DAVIDSON: If it was a huge, eye-popping number, absolutely. Yeah. PALCA: But then Davidson qualified that answer. DAVIDSON: It would have to be a pretty substantial amount. PALCA: Clearly he's still got some fight in him. The toothbrush wars aren't over yet. Joe Palca, NPR News. (SOUNDBITE OF STEPHANE WREMBEL'S \"BIG BROTHER\") AUDIE CORNISH, HOST:  Two inventors wanted to change the world of dental hygiene with a new kind of toothbrush. Everything was going great up until the moment their dream was about to become a reality. NPR science correspondent Joe Palca brings us this story as part of his summer series on inventing. JOE PALCA, BYLINE: Dental hygienist and toothbrush inventor Mike Davidson says when you brush your teeth properly, you know it. MIKE DAVIDSON: And that's what this brush is designed to do. It's designed to show you what good brushing feels like. PALCA: This brush is the MD Brush. The brush has a clever handle. When you pick it up, the handle positions the bristles at a 45 degree angle to the gumline, an angle many experts say is ideal for effective brushing. It took seven years to go from the idea for a new toothbrush to an actual product - seven years of designs, redesigns, re-redesigns, manufacturing obstacles. But finally, in late 2014, Davidson was ready. A hundred thousand MD Brushes arrived at the Port of Long Beach in California. Then the problems started. There was a strike at the port and the brushes were trapped. Then, Davidson says, the credit card processing system went haywire. DAVIDSON: This really is not the way you want to start a business. PALCA: And then they ran smack into the dental industrial complex. Davidson's partner, Mike Smith, says one of the big toothbrush manufacturers filed suit against them, accusing them of patent infringement. MIKE SMITH: When that came in, when we were served, I don't know if we were overwhelmed by it. But, I mean, it was definitely a - you know, a gut check for both of us. DAVIDSON: We could have fought them. And we were confident we would have won. But to get it in front of a judge to make a ruling on it would have cost us upwards of half a million dollars to do it. PALCA: Davidson says they agreed to a settlement and threw away 65,000 unsold toothbrushes. He says it hurt. And the experience completed his transition from idealistic inventor to hardened businessman. DAVIDSON: I'll put it to you this way, is that any time - if you've got an innovative product that's going to impinge upon a larger company's market share, get ready because they're going to come after you. And that's what happened with us. PALCA: Davidson says he and Smith have now regrouped. They've redesigned the brush again to avoid the patent problem, and the first manufacturing run is complete. DAVIDSON: We're ordering 10,000 this time instead of the 100,000. PALCA: When I spoke with Davidson and Smith three years ago, I asked them whether they'd take the money if a big toothbrush manufacturer offered to buy them out as a way of eliminating them as a competitor. (SOUNDBITE OF ARCHIVED BROADCAST) SMITH: I think we've already talked about it. No. No. I mean, we've taken it this far. We're going to - we're going to continue to take it all the way. DAVIDSON: It's not about money. It's about winning. And it's about beating these guys at their own game and showing them we can do something better. PALCA: That was three years ago. I asked if they'd take the money now. SMITH: Yes. (LAUGHTER) SMITH: I didn't even have to blink at that question. If it was an eye-popping amount of money then yes, most definitely. Yes. DAVIDSON: If it was a huge, eye-popping number, absolutely. Yeah. PALCA: But then Davidson qualified that answer. DAVIDSON: It would have to be a pretty substantial amount. PALCA: Clearly he's still got some fight in him. The toothbrush wars aren't over yet. Joe Palca, NPR News. (SOUNDBITE OF STEPHANE WREMBEL'S \"BIG BROTHER\")", "section": "Joe's Big Idea", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-08-04-541538743": {"title": "Hyperloop Tests Magnetic Levitation At 192 MPH : NPR", "url": "https://www.npr.org/2017/08/04/541538743/hyperloop-tests-magnetic-levitation-at-192-mph", "author": "No author found", "published_date": "2017-08-04", "content": "DAVID GREENE, HOST: So the tech visionary Elon Musk had this crazy idea four years ago. What if people could hurdle between cities through long tubes? It's no longer crazy. A company called Hyperloop One tested a transportation pod last weekend at almost 200 miles an hour. Josh Giegel's the company's co-founder. Good morning, Josh. JOSH GIEGEL: Good morning, David. GREENE: So how does this thing work? GIEGEL: We have effectively a large tube, and we take most of the air out of that. And then we have a vehicle or a pod, as we call it, that sits on the track. And that allows us to go contactlessly (ph). GREENE: So I'm in, like, this enclosed pod. I'm shooting at nearly 200 miles an hour through a tube that has very little air. And my pod is, like, not touching any surface. It's, like, shooting through because of magnetic levitation. Am I even close to describing it correctly? GIEGEL: You're very close. I'll say the one thing is we're only going 200 miles an hour now, but we can go up to 700. GREENE: Seven hundred miles an hour. GIEGEL: Turning it up to 11. GREENE: Have you ridden in this? Is it comfortable? Or is your, like, face pressed up against the window? GIEGEL: (Laughter). No one's ridden in it yet, but it would feel like an aircraft at takeoff. But inside, we're going for something that is kind of the lack of an experience or the absence of an experience because for me, if you see a purple elephant, the first time you see it, it's really interesting. But the second, third, fourth time becomes less exciting. GREENE: Have you seen a purple elephant (laughter)? GIEGEL: I have not. GREENE: OK (laughter). GIEGEL: So by going for something, like - I feel timeless if you're going for something that kind of is the lack of experience - you know, you're just really getting to your destination. You're not worried about what's going on in the interim. GREENE: So you're not going for purple elephant? You're going for something that feels just, like, you're on a bus or a plane, and I could be watching a movie on my laptop. GIEGEL: Yeah. GREENE: Are we close to this being a way that we'll be able to travel from one U. S. city to another? GIEGEL: I think so. You know, at the beginning people were saying, is this possible? Can I make this happen? And no one really asks that question anymore. They're asking the question of, when can I get on it? When can it be installed? GREENE: But people are asking other questions now. One of them is - critics seem to say that this still would have to rely on existing older infrastructure, which hasn't always been well-maintained in the country. Like, what would you need in terms of infrastructure to make this happen? And what are the challenges that exist there? GIEGEL: We really need a right of way. If you look at our videos, you can see us kind of elevated on columns. Or we'd be underneath the ground. That allows people, animals to cross and not really affect the local landscape. GREENE: I mean, you are making it sound easy, but I'm already hearing some constituencies, such as private landowners, such as environmental groups who I could see holding this up for quite some time. GIEGEL: With progress will always come the people who want to prevent it. But for us, if you're going to connect two places together, I don't think there's a quieter way, a cleaner way and a more futuristic way to do it. GREENE: But cutting-edge projects like this - hasn't the government had to foot a lot of the bill? Wouldn't that be another obstacle for you in the United States? GIEGEL: The government definitely would help provide the infrastructure once it's in line. So they would help build the actual project. But for us to develop, we're a venture-backed company. We've been doing that with private money thus far. GREENE: But without government help though - I mean, could you realistically offer this service on a large-scale affordably to Americans? GIEGEL: Any time you're doing these large-scale infrastructure projects, the government help is very important. But we have an infrastructure already. So when you look at the coming future of autonomous vehicles, you see them. So, you know, I'm about to get on a plane to go to D. C. , right? So I could in, say, a couple of years, hop in my autonomous car and get there. And maybe it'll take three hours. But with a Hyperloop, I would be able to get there in basically half an hour. And even in that world where I have, like, end-to-end autonomous, I still care about how fast I'm able to get there. So I will always think there'll be a market for getting somewhere fast. And I think the faster you're able to connect people, the more you'll have just economic activity and, quite frankly, exchange of ideas. And as an engineer, that's what I'm all about - is enabling the exchange of ideas. GREENE: Well, have a good flight. Do you get excited about getting on planes still? Or are you, like, way beyond that? Is it really boring? GIEGEL: I look at it as a learning experience each and every time. And, sometimes, I'll actually take the train just so I can see what I'm trying to replace. GREENE: Must feel slow. (LAUGHTER)GREENE: Well, listen, Josh. Thanks so much for talking. DAVID GREENE, HOST:  So the tech visionary Elon Musk had this crazy idea four years ago. What if people could hurdle between cities through long tubes? It's no longer crazy. A company called Hyperloop One tested a transportation pod last weekend at almost 200 miles an hour. Josh Giegel's the company's co-founder. Good morning, Josh. JOSH GIEGEL: Good morning, David. GREENE: So how does this thing work? GIEGEL: We have effectively a large tube, and we take most of the air out of that. And then we have a vehicle or a pod, as we call it, that sits on the track. And that allows us to go contactlessly (ph). GREENE: So I'm in, like, this enclosed pod. I'm shooting at nearly 200 miles an hour through a tube that has very little air. And my pod is, like, not touching any surface. It's, like, shooting through because of magnetic levitation. Am I even close to describing it correctly? GIEGEL: You're very close. I'll say the one thing is we're only going 200 miles an hour now, but we can go up to 700. GREENE: Seven hundred miles an hour. GIEGEL: Turning it up to 11. GREENE: Have you ridden in this? Is it comfortable? Or is your, like, face pressed up against the window? GIEGEL: (Laughter). No one's ridden in it yet, but it would feel like an aircraft at takeoff. But inside, we're going for something that is kind of the lack of an experience or the absence of an experience because for me, if you see a purple elephant, the first time you see it, it's really interesting. But the second, third, fourth time becomes less exciting. GREENE: Have you seen a purple elephant (laughter)? GIEGEL: I have not. GREENE: OK (laughter). GIEGEL: So by going for something, like - I feel timeless if you're going for something that kind of is the lack of experience - you know, you're just really getting to your destination. You're not worried about what's going on in the interim. GREENE: So you're not going for purple elephant? You're going for something that feels just, like, you're on a bus or a plane, and I could be watching a movie on my laptop. GIEGEL: Yeah. GREENE: Are we close to this being a way that we'll be able to travel from one U. S. city to another? GIEGEL: I think so. You know, at the beginning people were saying, is this possible? Can I make this happen? And no one really asks that question anymore. They're asking the question of, when can I get on it? When can it be installed? GREENE: But people are asking other questions now. One of them is - critics seem to say that this still would have to rely on existing older infrastructure, which hasn't always been well-maintained in the country. Like, what would you need in terms of infrastructure to make this happen? And what are the challenges that exist there? GIEGEL: We really need a right of way. If you look at our videos, you can see us kind of elevated on columns. Or we'd be underneath the ground. That allows people, animals to cross and not really affect the local landscape. GREENE: I mean, you are making it sound easy, but I'm already hearing some constituencies, such as private landowners, such as environmental groups who I could see holding this up for quite some time. GIEGEL: With progress will always come the people who want to prevent it. But for us, if you're going to connect two places together, I don't think there's a quieter way, a cleaner way and a more futuristic way to do it. GREENE: But cutting-edge projects like this - hasn't the government had to foot a lot of the bill? Wouldn't that be another obstacle for you in the United States? GIEGEL: The government definitely would help provide the infrastructure once it's in line. So they would help build the actual project. But for us to develop, we're a venture-backed company. We've been doing that with private money thus far. GREENE: But without government help though - I mean, could you realistically offer this service on a large-scale affordably to Americans? GIEGEL: Any time you're doing these large-scale infrastructure projects, the government help is very important. But we have an infrastructure already. So when you look at the coming future of autonomous vehicles, you see them. So, you know, I'm about to get on a plane to go to D. C. , right? So I could in, say, a couple of years, hop in my autonomous car and get there. And maybe it'll take three hours. But with a Hyperloop, I would be able to get there in basically half an hour. And even in that world where I have, like, end-to-end autonomous, I still care about how fast I'm able to get there. So I will always think there'll be a market for getting somewhere fast. And I think the faster you're able to connect people, the more you'll have just economic activity and, quite frankly, exchange of ideas. And as an engineer, that's what I'm all about - is enabling the exchange of ideas. GREENE: Well, have a good flight. Do you get excited about getting on planes still? Or are you, like, way beyond that? Is it really boring? GIEGEL: I look at it as a learning experience each and every time. And, sometimes, I'll actually take the train just so I can see what I'm trying to replace. GREENE: Must feel slow. (LAUGHTER) GREENE: Well, listen, Josh. Thanks so much for talking.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-08-07-542087066": {"title": "Google Engineer's Criticism Of Diversity Programs Sparks Controversy : NPR", "url": "https://www.npr.org/2017/08/07/542087066/google-engineers-criticism-of-diversity-programs-sparks-controversy", "author": "No author found", "published_date": "2017-08-07", "content": "ARI SHAPIRO, HOST:  This week's All Tech Considered begins with a critique of diversity initiatives at Google. A senior software engineer wrote that critique and it went viral over the weekend. NPR's Laura Sydell reports some women at the company didn't go to work today because of it. LAURA SYDELL, BYLINE: The critique called Google an ideological echo chamber. It laid waste to the company's current attempts to bring in more female engineers. The author, whose name has been withheld, says we need to stop assuming that gender gaps imply sexism. He then went on to argue that women were less biologically suited to be engineers. KELLY ELLIS: I know women who are actually taking sick days today. SYDELL: Kelly Ellis is a former software engineer at Google. She still has a lot of friends who work there. Ellis actually left the company in 2014, she says, because she was sexually harassed. ELLIS: For me, it's unfortunately completely unsurprising because I saw similar language when I was at Google. SYDELL: Since Ellis left Google, it became the target of an investigation by the U. S. Department of Labor. It has accused the company of systematically discriminating against women. The company has denied this charge. Internally, Google has increased mandatory participation in programs aimed at unconscious biases. About 20 percent of Google's technical jobs are filled by women. Google's newly hired vice president of diversity, integrity and governance, Danielle Brown, sent out a memo in response to the current dustup. Brown says Google attempts to create an inclusive environment that tolerates dissent. But she also said that it needs to work alongside principles of equal employment found in the company code of conduct and anti-discrimination laws. Twitter has been filled with responses to the controversy. Some have called on Google to fire the senior engineer. Former Googler Ellis thinks that is what Google should do because even though he's not a manager, his opinions could impact female engineers. ELLIS: The main input to Google's performance review process is peer review, your peers writing feedback on your work. SYDELL: The law is a little unclear as to whether Google could fire the employee. Generally, political speech is protected under labor laws. But the fact that this particular employee could have an impact on hiring and payment might leave him open to being terminated. Google is known as a place that likes to work through problems by using research and facts. It may sit the employee down and point out that in countries like Iran, 70 percent of the engineering and science graduates are women. Sources inside Google have told NPR that various managers have directly written notes to their employees saying that regardless of what this particular engineer thinks, their employees should continue to stick with Google's anti-discrimination policies. Laura Sydell, NPR News, San Francisco. ARI SHAPIRO, HOST:   This week's All Tech Considered begins with a critique of diversity initiatives at Google. A senior software engineer wrote that critique and it went viral over the weekend. NPR's Laura Sydell reports some women at the company didn't go to work today because of it. LAURA SYDELL, BYLINE: The critique called Google an ideological echo chamber. It laid waste to the company's current attempts to bring in more female engineers. The author, whose name has been withheld, says we need to stop assuming that gender gaps imply sexism. He then went on to argue that women were less biologically suited to be engineers. KELLY ELLIS: I know women who are actually taking sick days today. SYDELL: Kelly Ellis is a former software engineer at Google. She still has a lot of friends who work there. Ellis actually left the company in 2014, she says, because she was sexually harassed. ELLIS: For me, it's unfortunately completely unsurprising because I saw similar language when I was at Google. SYDELL: Since Ellis left Google, it became the target of an investigation by the U. S. Department of Labor. It has accused the company of systematically discriminating against women. The company has denied this charge. Internally, Google has increased mandatory participation in programs aimed at unconscious biases. About 20 percent of Google's technical jobs are filled by women. Google's newly hired vice president of diversity, integrity and governance, Danielle Brown, sent out a memo in response to the current dustup. Brown says Google attempts to create an inclusive environment that tolerates dissent. But she also said that it needs to work alongside principles of equal employment found in the company code of conduct and anti-discrimination laws. Twitter has been filled with responses to the controversy. Some have called on Google to fire the senior engineer. Former Googler Ellis thinks that is what Google should do because even though he's not a manager, his opinions could impact female engineers. ELLIS: The main input to Google's performance review process is peer review, your peers writing feedback on your work. SYDELL: The law is a little unclear as to whether Google could fire the employee. Generally, political speech is protected under labor laws. But the fact that this particular employee could have an impact on hiring and payment might leave him open to being terminated. Google is known as a place that likes to work through problems by using research and facts. It may sit the employee down and point out that in countries like Iran, 70 percent of the engineering and science graduates are women. Sources inside Google have told NPR that various managers have directly written notes to their employees saying that regardless of what this particular engineer thinks, their employees should continue to stick with Google's anti-discrimination policies. Laura Sydell, NPR News, San Francisco.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-08-08-542180434": {"title": "Google Fires Engineer Who Criticized Diversity Efforts : NPR", "url": "https://www.npr.org/2017/08/08/542180434/google-fires-engineer-who-criticized-diversity-efforts", "author": "No author found", "published_date": "2017-08-08", "content": "DAVID GREENE, HOST: Google has fired a software engineer who wrote a controversial internal memo that leaked over the weekend. James Damore's memo, called \"Google's Ideological Echo Chamber,\" criticized the company's effort to diversify its workforce. And in doing so, the memo relied on gender stereotypes about women in tech. And let's talk more about this with NPR's Laura Sydell. Hi, Laura. LAURA SYDELL, BYLINE: Good morning. GREENE: So tell us exactly what this memo said. SYDELL: Well, among the things that the memo said was that Google was an echo chamber of opinion. And if you criticize the company's efforts at diversity, then you were a bad person. And most specifically, though, the memo questioned whether or not women were biologically suited to be engineers. And I think that's what really set off the firestorm within Google. GREENE: I can imagine. I mean - and we should this is one person's opinion that he sent around to colleagues. That's what leaked. SYDELL: Exactly. So he sent it around to colleagues. And essentially it got out companywide. And then once it got out companywide, it got out on the Internet. And it was not in any way an official memo. It was - people actually jokingly called it a manifesto (laughter). GREENE: So it sounds like I mean he was making several arguments - one, the gender stereotypes that you mentioned but also suggesting that there is no freedom to express views about diversity within the company. And the fact that he was then fired seems to back up his argument again. So I guess I wonder, what exactly did the company say is the reason for his dismissal? SYDELL: Well, the company - in a memo, Sundar Pichai, who is the CEO of Google, said specifically that people are allowed to express different views. But in this case, this memo violated the company's code of conduct and that it actually led to creating a work environment for others that was hostile. So you know, Google has to create a workplace culture that's free of harassment, intimidation, bias and unlawful discrimination. So that's the reason that Google gave. I should add here, David, that Google is under investigation right now by the U. S. labor department. And the U. S. labor department is looking into salaries and saying that Google is paying women less than men. Google has repeatedly refused to actually release those numbers. But Google is in an interesting position here where they're being investigated. And then this, you know, leaked manifesto comes out. GREENE: A manifesto the company suggest was just discriminatory and crossed a line, which is why they're firing him. SYDELL: Exactly, exactly. GREENE: Well, has he responded? Has James Damore, this software engineer who wrote it, responded? SYDELL: He has. And essentially he has said he is going to sue the company. So - and he obviously feels it is proof of exactly what he says. And he has - I should say that far-right websites are supporting him and saying the fact that Google fired him is proof of exactly what he said - that there's a, you know, a left-wing echo chamber at Google and that, you know, if you violate that code of conduct or that left-wing viewpoint, you end up getting shut down. GREENE: Diversity was already such a big issue around Silicon Valley. I imagine this story is (laughter) causing some more waves. SYDELL: (Laughter) It certainly is causing a lot more waves around Silicon Valley right now. And you know, I think right now James Damore's name is trending on Twitter. So I think this has become a huge thing. I do want to add one more thing here, David. . . GREENE: Yeah. SYDELL: . . . That I think is important to remember. Google actually is in a more complicated position than other companies legally because Google has peer review. So essentially James Damore would be able to review his peers, and people are promoted given salaries based on what their peers say about them. And I think that's one of the reasons that Google was in a very difficult position here about whether to keep him. GREENE: He can affect other people's lives even though he's not a manager. Speaking to. . . SYDELL: Exactly. GREENE: NPR's Laura Sydell updating us on that story at Google. Thanks so much. SYDELL: You're welcome. DAVID GREENE, HOST:  Google has fired a software engineer who wrote a controversial internal memo that leaked over the weekend. James Damore's memo, called \"Google's Ideological Echo Chamber,\" criticized the company's effort to diversify its workforce. And in doing so, the memo relied on gender stereotypes about women in tech. And let's talk more about this with NPR's Laura Sydell. Hi, Laura. LAURA SYDELL, BYLINE: Good morning. GREENE: So tell us exactly what this memo said. SYDELL: Well, among the things that the memo said was that Google was an echo chamber of opinion. And if you criticize the company's efforts at diversity, then you were a bad person. And most specifically, though, the memo questioned whether or not women were biologically suited to be engineers. And I think that's what really set off the firestorm within Google. GREENE: I can imagine. I mean - and we should this is one person's opinion that he sent around to colleagues. That's what leaked. SYDELL: Exactly. So he sent it around to colleagues. And essentially it got out companywide. And then once it got out companywide, it got out on the Internet. And it was not in any way an official memo. It was - people actually jokingly called it a manifesto (laughter). GREENE: So it sounds like I mean he was making several arguments - one, the gender stereotypes that you mentioned but also suggesting that there is no freedom to express views about diversity within the company. And the fact that he was then fired seems to back up his argument again. So I guess I wonder, what exactly did the company say is the reason for his dismissal? SYDELL: Well, the company - in a memo, Sundar Pichai, who is the CEO of Google, said specifically that people are allowed to express different views. But in this case, this memo violated the company's code of conduct and that it actually led to creating a work environment for others that was hostile. So you know, Google has to create a workplace culture that's free of harassment, intimidation, bias and unlawful discrimination. So that's the reason that Google gave. I should add here, David, that Google is under investigation right now by the U. S. labor department. And the U. S. labor department is looking into salaries and saying that Google is paying women less than men. Google has repeatedly refused to actually release those numbers. But Google is in an interesting position here where they're being investigated. And then this, you know, leaked manifesto comes out. GREENE: A manifesto the company suggest was just discriminatory and crossed a line, which is why they're firing him. SYDELL: Exactly, exactly. GREENE: Well, has he responded? Has James Damore, this software engineer who wrote it, responded? SYDELL: He has. And essentially he has said he is going to sue the company. So - and he obviously feels it is proof of exactly what he says. And he has - I should say that far-right websites are supporting him and saying the fact that Google fired him is proof of exactly what he said - that there's a, you know, a left-wing echo chamber at Google and that, you know, if you violate that code of conduct or that left-wing viewpoint, you end up getting shut down. GREENE: Diversity was already such a big issue around Silicon Valley. I imagine this story is (laughter) causing some more waves. SYDELL: (Laughter) It certainly is causing a lot more waves around Silicon Valley right now. And you know, I think right now James Damore's name is trending on Twitter. So I think this has become a huge thing. I do want to add one more thing here, David. . . GREENE: Yeah. SYDELL: . . . That I think is important to remember. Google actually is in a more complicated position than other companies legally because Google has peer review. So essentially James Damore would be able to review his peers, and people are promoted given salaries based on what their peers say about them. And I think that's one of the reasons that Google was in a very difficult position here about whether to keep him. GREENE: He can affect other people's lives even though he's not a manager. Speaking to. . . SYDELL: Exactly. GREENE: NPR's Laura Sydell updating us on that story at Google. Thanks so much. SYDELL: You're welcome.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-08-09-542468251": {"title": "Car Seat Camouflage: Man Wears Bizarre Costume In Automatic Vehicle Experiment : NPR", "url": "https://www.npr.org/2017/08/09/542468251/car-seat-camouflage-man-wears-bizarre-costume-in-automatic-vehicle-experiment", "author": "No author found", "published_date": "2017-08-09", "content": "ARI SHAPIRO, HOST: Now a mystery solved in Arlington, Va. It starts with an unmarked Ford passenger van making its way through suburban streets with an apparently empty driver's seat. Adam Tuss of NBC Washington was on the case. (SOUNDBITE OF ARCHIVED RECORDING)ADAM TUSS: Brother, who are you? What are you doing? I'm with the news, Dude. Can you pull over, and we can talk for a second? AUDIE CORNISH, HOST: Tuss uncovered that the empty car wasn't what it seemed. That got the attention of Wired reporter Aarian Marshall. AARIAN MARSHALL: There's a person inside the car, but that person is dressed as a car seat. CORNISH: Someone covered from head to waist in what looks like car seat upholstery. SHAPIRO: The only clues that it's not a car seat are the hands sticking out from the costume, holding the steering wheel. CORNISH: It turns out it's all in the name of science. The reporters learned it was part of a study by the Virginia Tech Transportation Institute about self-driving vehicles. MARSHALL: So scientists want to figure out how people react to these vehicles when there's absolutely no one behind the wheel, when there's no one inside. So that's why they put out these strange car seat costume studies into the field. SHAPIRO: The researcher who pioneered the concept, Wendy Ju at Stanford's Center for Design Research, says she got the idea from a prank video. WENDY JU: There's this wonderful YouTube video that shows a person driving through drive-throughs in a car seat costume and just scaring the bejesus out of poor fast food workers. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED MAN: I built this car seat costume. I'm going to put it on, and I'm going to go through a drive-through. UNIDENTIFIED WOMAN #1: Hello. Oh, my God, (unintelligible). UNIDENTIFIED WOMAN #2: Hello. Are you serious? UNIDENTIFIED WOMAN #3: Interesting. All right, empty car, can I have $1. 43 please? UNIDENTIFIED WOMAN #4: What the hell? I don't like this. CORNISH: Those videos are from 2013, but the idea of driverless cars is still going to take some time to get used to. (SOUNDBITE OF QUITAPENAS SONG, \"YA VERAN\") ARI SHAPIRO, HOST:  Now a mystery solved in Arlington, Va. It starts with an unmarked Ford passenger van making its way through suburban streets with an apparently empty driver's seat. Adam Tuss of NBC Washington was on the case. (SOUNDBITE OF ARCHIVED RECORDING) ADAM TUSS: Brother, who are you? What are you doing? I'm with the news, Dude. Can you pull over, and we can talk for a second? AUDIE CORNISH, HOST:  Tuss uncovered that the empty car wasn't what it seemed. That got the attention of Wired reporter Aarian Marshall. AARIAN MARSHALL: There's a person inside the car, but that person is dressed as a car seat. CORNISH: Someone covered from head to waist in what looks like car seat upholstery. SHAPIRO: The only clues that it's not a car seat are the hands sticking out from the costume, holding the steering wheel. CORNISH: It turns out it's all in the name of science. The reporters learned it was part of a study by the Virginia Tech Transportation Institute about self-driving vehicles. MARSHALL: So scientists want to figure out how people react to these vehicles when there's absolutely no one behind the wheel, when there's no one inside. So that's why they put out these strange car seat costume studies into the field. SHAPIRO: The researcher who pioneered the concept, Wendy Ju at Stanford's Center for Design Research, says she got the idea from a prank video. WENDY JU: There's this wonderful YouTube video that shows a person driving through drive-throughs in a car seat costume and just scaring the bejesus out of poor fast food workers. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED MAN: I built this car seat costume. I'm going to put it on, and I'm going to go through a drive-through. UNIDENTIFIED WOMAN #1: Hello. Oh, my God, (unintelligible). UNIDENTIFIED WOMAN #2: Hello. Are you serious? UNIDENTIFIED WOMAN #3: Interesting. All right, empty car, can I have $1. 43 please? UNIDENTIFIED WOMAN #4: What the hell? I don't like this. CORNISH: Those videos are from 2013, but the idea of driverless cars is still going to take some time to get used to. (SOUNDBITE OF QUITAPENAS SONG, \"YA VERAN\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-08-10-542634370": {"title": "Russian Cyberattack Targeted Elections Vendor Tied To Voting Day Disruptions : NPR", "url": "https://www.npr.org/2017/08/10/542634370/russian-cyberattack-targeted-elections-vendor-tied-to-voting-day-disruptions", "author": "No author found", "published_date": "2017-08-10", "content": "ARI SHAPIRO, HOST: Back in November, when voters showed up in several North Carolina precincts, weird things started to happen. They involved the electronic devices called poll books that were being used to check voters in. It was later revealed that the company that provided those poll books was the target of a Russian phishing attack. There's no evidence that the two incidents are linked. Nine months later, officials are still trying to sort out the details. And as NPR's Pam Fessler reports, what happened in North Carolina exposed serious gaps in efforts to protect U. S. elections. PAM FESSLER, BYLINE: Polls in Durham County, N. C. opened at 6:30 a. m. on Election Day. And almost immediately, complaints started pouring in to a nonpartisan hotline. ALLISON RIGGS: Voters were going in and being told that they had already voted, and they hadn't. FESSLER: Allison Riggs, an attorney with the Southern Coalition for Social Justice, was manning the phones. She says poll books also indicated that voters had to show ID when they didn't. Alarmed, she contacted election officials to find out what was going on. DEREK BOWENS: We had roughly six precincts call and report computer-related issues. FESSLER: Durham County Elections Director Derek Bowens says the problems appeared to be confined to a few laptops, which are used to run software listing voters' registration data, so the county decided to switch to paper poll books in those precincts just to be safe. BOWENS: And then the state got involved and determined that it would be better to have uniformity across all of our 57 precincts. And we went paper poll books across the county. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED REPORTER: The big news at this hour - eight Durham precincts extending voting hours; some as little as 15 minutes, others extending a full hour to 8:30. FESSLER: But as the local ABC affiliate and other news outlets reported, that move created a whole new set of problems in a key battleground state. Switching to paper poll books delayed voting in some precincts up to an hour and a half as poll workers waited for supplies. They now had to cut voters' names from the poll books and attach them to forms before handing out ballots. RIGGS: Precincts didn't have scissors. They didn't have tape. They didn't have glue sticks. FESSLER: As far as Riggs was concerned, the solution was worse than the problem. The state had overreacted. But Susan Greenhalgh was worried that people were underreacting. She's with Verified Voting, an election security group, and was monitoring events in Durham County. Mid-morning she noticed a news report that the electronic poll books were supplied by a Florida company named VR Systems. SUSAN GREENHALGH: My stomach just dropped. FESSLER: She knew that in September, the FBI had warned Florida election officials that Russians tried to hack the computers of a local contractor. VR Systems was rumored to be that company. GREENHALGH: I became really concerned that this might be a cyberattack or some sort of cyber event. FESSLER: But she had trouble getting anyone's attention. Greenhalgh says a contact at the U. S. Department of Homeland Security was also concerned, but said there was little that the feds could do unless the state requested help. And here's where the problem comes in. On Election Day, North Carolina didn't know that VR Systems had been the target of a Russian attack. JOSH LAWSON: We found out like everybody else did. FESSLER: Josh Lawson is general counsel for the state board of elections. He says they only learned of the hack attempt this June, when an online news site published a classified report that Russia had tried to break into VR Systems' computers last year and that the hackers sent local election offices emails that appeared to come from the company but contained malicious software. Lawson says there's no evidence that anyone in the state received those emails. But he adds. . . LAWSON: It's our job to be paranoid about this. And so when you have a leaked memorandum indicating that there may have been a vulnerability about which you were not aware at the time, you're going to want to try to confirm that there was no actual interference. FESSLER: Now, nine months later, the state is investigating what happened in Durham County. BOWENS: So as you can see, we got a lot under lock and key here. FESSLER: County Elections Director Derek Bowens says voters should be confident the election was secure and their votes were never at risk. BOWENS: So these are some of our laptops. We've got several more over here. FESSLER: The county conducted its own investigation last November and concluded that VR System software didn't fail but that some poll books weren't updated, so they displayed outdated voter information. BOWENS: The conclusion was - is that it was administrative errors that caused the issues on Election Day. FESSLER: And that may very well be the case. Still, the episode has left everyone frustrated, wondering what would happen if there was an attack. VR Systems told NPR it warned customers to be on the lookout for fake emails, but it's not clear how widely that information was shared. And Lawson of the state board says intelligence agencies still haven't confirmed whether Russia tried to hack into any of North Carolina's election systems. Matt Masterson, who chairs the U. S. Election Assistance Commission, says federal authorities have to communicate better. MATT MASTERSON: As information has come out in various media reports, election officials, I think fairly, have said, you know, why are we reading about this? Why has no one shared this information with us? FESSLER: He says that's what state and federal authorities are trying to work out now - deciding who gets what intelligence and when. And there's a sense of urgency because everyone expects the Russian hackers will be back. Pam Fessler, NPR News. [POST-BROADCAST CLARIFICATION: In the audio of this story, as well as an earlier Web version, we report that Susan Greenhalgh \"knew that in September, the FBI had warned Florida election officials that Russians had tried to hack one of their vendor's computers. \u201d Greenhalgh's information was based on several news reports last fall and a discussion she had with one of the local election officials who participated in the call with the FBI. A spokeswoman for the Florida Department of State, which manages elections in the state, says there was \"an informational call with the FBI . . . where they alerted officials for the need to maintain security measures, but there was no indication of a Florida-specific issue. \"] ARI SHAPIRO, HOST:  Back in November, when voters showed up in several North Carolina precincts, weird things started to happen. They involved the electronic devices called poll books that were being used to check voters in. It was later revealed that the company that provided those poll books was the target of a Russian phishing attack. There's no evidence that the two incidents are linked. Nine months later, officials are still trying to sort out the details. And as NPR's Pam Fessler reports, what happened in North Carolina exposed serious gaps in efforts to protect U. S. elections. PAM FESSLER, BYLINE: Polls in Durham County, N. C. opened at 6:30 a. m. on Election Day. And almost immediately, complaints started pouring in to a nonpartisan hotline. ALLISON RIGGS: Voters were going in and being told that they had already voted, and they hadn't. FESSLER: Allison Riggs, an attorney with the Southern Coalition for Social Justice, was manning the phones. She says poll books also indicated that voters had to show ID when they didn't. Alarmed, she contacted election officials to find out what was going on. DEREK BOWENS: We had roughly six precincts call and report computer-related issues. FESSLER: Durham County Elections Director Derek Bowens says the problems appeared to be confined to a few laptops, which are used to run software listing voters' registration data, so the county decided to switch to paper poll books in those precincts just to be safe. BOWENS: And then the state got involved and determined that it would be better to have uniformity across all of our 57 precincts. And we went paper poll books across the county. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED REPORTER: The big news at this hour - eight Durham precincts extending voting hours; some as little as 15 minutes, others extending a full hour to 8:30. FESSLER: But as the local ABC affiliate and other news outlets reported, that move created a whole new set of problems in a key battleground state. Switching to paper poll books delayed voting in some precincts up to an hour and a half as poll workers waited for supplies. They now had to cut voters' names from the poll books and attach them to forms before handing out ballots. RIGGS: Precincts didn't have scissors. They didn't have tape. They didn't have glue sticks. FESSLER: As far as Riggs was concerned, the solution was worse than the problem. The state had overreacted. But Susan Greenhalgh was worried that people were underreacting. She's with Verified Voting, an election security group, and was monitoring events in Durham County. Mid-morning she noticed a news report that the electronic poll books were supplied by a Florida company named VR Systems. SUSAN GREENHALGH: My stomach just dropped. FESSLER: She knew that in September, the FBI had warned Florida election officials that Russians tried to hack the computers of a local contractor. VR Systems was rumored to be that company. GREENHALGH: I became really concerned that this might be a cyberattack or some sort of cyber event. FESSLER: But she had trouble getting anyone's attention. Greenhalgh says a contact at the U. S. Department of Homeland Security was also concerned, but said there was little that the feds could do unless the state requested help. And here's where the problem comes in. On Election Day, North Carolina didn't know that VR Systems had been the target of a Russian attack. JOSH LAWSON: We found out like everybody else did. FESSLER: Josh Lawson is general counsel for the state board of elections. He says they only learned of the hack attempt this June, when an online news site published a classified report that Russia had tried to break into VR Systems' computers last year and that the hackers sent local election offices emails that appeared to come from the company but contained malicious software. Lawson says there's no evidence that anyone in the state received those emails. But he adds. . . LAWSON: It's our job to be paranoid about this. And so when you have a leaked memorandum indicating that there may have been a vulnerability about which you were not aware at the time, you're going to want to try to confirm that there was no actual interference. FESSLER: Now, nine months later, the state is investigating what happened in Durham County. BOWENS: So as you can see, we got a lot under lock and key here. FESSLER: County Elections Director Derek Bowens says voters should be confident the election was secure and their votes were never at risk. BOWENS: So these are some of our laptops. We've got several more over here. FESSLER: The county conducted its own investigation last November and concluded that VR System software didn't fail but that some poll books weren't updated, so they displayed outdated voter information. BOWENS: The conclusion was - is that it was administrative errors that caused the issues on Election Day. FESSLER: And that may very well be the case. Still, the episode has left everyone frustrated, wondering what would happen if there was an attack. VR Systems told NPR it warned customers to be on the lookout for fake emails, but it's not clear how widely that information was shared. And Lawson of the state board says intelligence agencies still haven't confirmed whether Russia tried to hack into any of North Carolina's election systems. Matt Masterson, who chairs the U. S. Election Assistance Commission, says federal authorities have to communicate better. MATT MASTERSON: As information has come out in various media reports, election officials, I think fairly, have said, you know, why are we reading about this? Why has no one shared this information with us? FESSLER: He says that's what state and federal authorities are trying to work out now - deciding who gets what intelligence and when. And there's a sense of urgency because everyone expects the Russian hackers will be back. Pam Fessler, NPR News. [POST-BROADCAST CLARIFICATION: In the audio of this story, as well as an earlier Web version, we report that Susan Greenhalgh \"knew that in September, the FBI had warned Florida election officials that Russians had tried to hack one of their vendor's computers. \u201d Greenhalgh's information was based on several news reports last fall and a discussion she had with one of the local election officials who participated in the call with the FBI. A spokeswoman for the Florida Department of State, which manages elections in the state, says there was \"an informational call with the FBI . . . where they alerted officials for the need to maintain security measures, but there was no indication of a Florida-specific issue. \"]", "section": "National Security", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-08-11-541644282": {"title": "Sal Khan: Can Technology Help Create A Global Classroom? : NPR", "url": "https://www.npr.org/2017/08/11/541644282/sal-khan-can-technology-help-create-a-global-classroom", "author": "No author found", "published_date": "2017-08-11", "content": "GUY RAZ, HOST: So here's what a chemistry class at the Khan Lab School in Los Altos, Calif. , sounds like. UNIDENTIFIED CHILDREN: (Singing) Hydrogen and helium and lithium, beryllium, boron, carbon everywhere. Nitrogen all through the air. RAZ: Don't you just kind of want to be in that class? UNIDENTIFIED CHILD #1: I spend at least half an hour every day coding. So I do JavaScript. And now I'm just starting to learn Python. RAZ: JavaScript and Python, pretty crazy, right? Anyway, the Lab School opened up in 2014 as, well, an education laboratory, a kind of testing ground. . . UNIDENTIFIED CHILD #2: Our hazmat suit is built for Europa. RAZ: . . . Where kids from different age groups collaborate. UNIDENTIFIED CHILD #2: The problems are that it's very, very cold there, plus there's deadly radiation. RAZ: And at the Khan Lab School, classes go year-round and there are no grade levels. SALMAN KHAN: You know, they come in, there's a group time where, you know, you have kids as young as 5, as old as 14, all together in a room. You know, they really feel like cousins. A lot of. . . RAZ: This is the school's founder, Sal Khan. KHAN: They'll have their morning meeting. Then they go into core skills time. There's a lot of peer-to-peer interaction going on in that period. But once you get to lunch and the whole afternoon, it's mainly project-based learning, students working in kind of this collaborative, cross-age environment. RAZ: And at the heart of Sal Khan's approach, flipping the classroom so that students watch online lectures at home but spend a lot more time working with teachers and other students in class. KHAN: It makes the classroom take advantage of the human beings that are there. It makes it an active process. It allows the teacher to see in real time where the students actually are. And the idea of getting the information, well, it's better when it's on your own time and pace and you can pause and repeat and watch exactly what you need. RAZ: And this whole idea of flipping the classroom, it's something Sal kind of stumbled upon more than a decade ago when he started to post these free educational videos online, which he called Khan Academy. KHAN: So in a traditional lecture model, I show up, I'm like, all right, I'm sitting here. And it just happens to you. And some of it might stick. While on demand video, when I click on a video, I'm only going to click - it's kind of like asking a question. Hey, I'm still confused about this. Give me another five-minute example or explain the concept a little bit better. And so when you are pulling information, you're naturally going to be more open to it. RAZ: Khan Academy began sort of by accident in 2004. At the time, Sal was working at a hedge fund and his 12-year-old cousin came to visit. And she was dispirited because she'd been placed in a slower math class. KHAN: I asked her about it. Turns out, she had trouble with unit conversion. RAZ: You know, changing feet to meters or gallons to liters. KHAN: I offered to tutor her, convinced that she could understand unit conversion. And so we started working together over the phone. RAZ: And eventually, she got it. KHAN: And then I called up her school, I say, hey, you know, I think Nadia (ph) should retake that placement exam from last year. They said, who are you? (Laughter) I said, I'm her cousin. And they let her. And that same Nadia that two months ago was being tagged and tracked as a remedial math student was now placed into the advanced math class. And then word gets around the family that free tutoring is going on. RAZ: So one cousin becomes two, then three and then four, five, six, seven, eight. . . KHAN: Once it was 10 or 15 cousins, the scheduling logistics got a little bit more difficult. RAZ: Sal would organize conference calls. And then he would email pictures of math problems back and forth. And eventually, someone suggested, hey, why don't you just post your lessons on YouTube? KHAN: I actually wasn't that familiar with it at the time. And I said, no, no, that doesn't make any sense. YouTube is for cats playing piano. RAZ: (Laughter). KHAN: It's not for serious mathematics. RAZ: But he tried it anyway. (SOUNDBITE OF YOUTUBE VIDEO)KHAN: Welcome to the presentation on adding and subtracting fractions. Let's get started. And I started telling my cousins, hey, I'm making videos on a lot of the common concepts and questions that y'all are asking me about. Why don't you watch them ahead of time and when we get on the phone, we can dig a little bit deeper? And after about a month, I asked for feedback and they famously said they like me better on YouTube than in person. (SOUNDBITE OF YOUTUBE VIDEO)KHAN: So this one-fourth right here, let's say it's this one-fourth of the pie, right? And we're going to add it to another one-fourth of the pie. I think what they were saying is it was very valuable to have it on demand. They didn't have to feel embarrassed. They didn't have to feel like they were wasting my time. And so I kept going. It was public on YouTube, started to become clear that people who weren't my cousins were watching. That just kept growing. (SOUNDBITE OF TED TALK)KHAN: Even at this point, you know, I said, OK, maybe it's a good supplement. It's good for motivated students. It's good for maybe homeschoolers. But I didn't think it would be something that would somehow penetrate the classroom. RAZ: Sal picks up the story from the TED stage. (SOUNDBITE OF TED TALK)KHAN: But then I started getting letters from teachers. And the teachers would write saying we've used your videos to flip the classroom. You've given the lectures. So now what I do is I assign the lectures for homework. And what used to be homework, I now have the students doing in the classroom. And I want to pause here for a second because this is the unintuitive thing when you talk about technology in the classroom. They took a fundamentally dehumanizing experience, a bunch of - 30 kids with their fingers on their lips not allowed to interact with each other, a teacher, no matter how good, has to give this kind of one-size-fits-all lecture to 30 students - you know, blank faces, slightly antagonistic. And now it's a human experience. Now they're actually interacting with each other. RAZ: So how does Khan Academy teach, let's say, algebra to a seventh grader differently than that seventh grader would learn it in a classroom in middle school? KHAN: Well, one, we want to put practice first and practice at your level of development. So in a traditional school, it might be October. Hey, we're all going to be doing exponents in seventh grade. What we would recommend is let students start at the beginning and then let them keep practicing at their own time and pace. And then the teacher can get information on where all their students are and intervene accordingly. Say, hey, those students are getting exponents just fine, let them move on to logarithms, while these students are actually, not even exponents, some of these students are having trouble with their multiplication tables. Let's make sure they have that foundation well because if they don't learn that, exponents are going to be near impossible. And so it allows the teacher to become more of a master conductor of an orchestra. And, you know, this has to be a little bit louder, this has to be a little bit more quiet. So that's what we generally advocate. In terms of the actual content materials, I think there's a lot of teachers out there, incredible teachers who do a very good job of connecting material, making it make conceptual sense. I think textbooks do a pretty bad job of that. It tends to fragment the knowledge, make it seem like a series of formulas. And so we're trying to do both of these things - allow classrooms to move to this more personalized, you could say, competency-based world. And at the same time, allow the content to be delivered in a way that is much more natural for students, that feels much more conceptual and also exposes the beauty in things. RAZ: So could this approach, could flipping the classroom actually revolutionize teaching? In a minute, why Sal Khan believes the answer is yes. Stay with us. I'm Guy Raz, and you're listening to the TED Radio Hour from NPR. (SOUNDBITE OF MUSIC)RAZ: It's the TED Radio Hour from NPR. I'm Guy Raz. And on the show today, ideas about rethinking school. And before the break, we were hearing how Sal Khan turned an experiment with online videos into a teaching tool to flip the classroom. In more than 10 years since he launched Khan Academy, millions of people have watched the videos, all free and made available in more than three dozen different languages. (SOUNDITE OF ARCHIVED RECORDING)UNIDENTIFIED MAN: (Foreign language spoken). UNIDENTIFIED WOMAN: (Foreign language spoken). UNIDENTIFIED MAN: (Foreign language spoken). (SOUNDBITE OF TED TALK)KHAN: Imagine what it does to a street kid in Calcutta who has to help his family during the day and that's the reason why he or she can't go to school. Now they can spend two hours a day and remediate or get up to speed and not feel embarrassed about what they do or don't know. Now imagine what happens where, you know, we talked about the peers teaching each other inside of a classroom. But this is all one system. There's no reason why you can't have that peer-to-peer tutoring beyond that one classroom. Imagine what happens if that student in Calcutta all of a sudden can tutor your son or your son can tutor that kid in Calcutta. And I think what you'll see emerging is this notion of a global one-world classroom. And that's essentially what we're trying to build. RAZ: Could Khan Academy, I mean, could it replace school for - or does it replace school for lots of children around the world who may not have access to traditional classrooms? KHAN: In an ideal world, you have a physical school. Obviously, we created a physical school so we think it's very, very important. But the reality is that many students, you know, it could be in under-served areas, it could be in rural areas, impoverished areas, there could be cultural barriers to going to school. You know, we've had some stories of young girls under, you know, controlled by the Taliban, they're using Khan Academy as their outlet. So, yes, we - ideally, you go to a classroom, and we can help supercharge that classroom. But if you don't have access to a classroom, yes, we want to make it so that you could self-educate and prove what you know to the world and so that you can participate in society. RAZ: I mean, I guess what you're essentially trying to do is to append an outdated system. KHAN: Yeah, around the world, we have essentially adopted what could be called a Prussian education system. And it's referring to 18th, 19th century Prussia, one of the first places to industrialize and also one of the first places to rightfully think about universal public education. And - but what they did say - they said, well, we can't give everyone a private tutor like nobility used to get. If we want to make this economic, well, let's - this is the Industrial Revolution. How do we do anything at scale? Well, we batch things together, we move them down in an assembly line, we apply some processes to it. And so that's the model that throughout the world we have. Students are batched together, initially by age, around middle school, age and perceived ability. They move forward at a set pace. But now we have technology, we have notions of on demand video. And so the opportunity - it no longer has to be this utopian thought - is let's give students explanations when they need it, if they need it. Let's give them practice when and if they need it. And so our end isn't just to change things for the sake of changing things. Our end is we want a world where you have access to, you know, a low-cost device, you can access Khan Academy, self-educate yourself and plug in either to the formal academic system or get a job, become part of society. RAZ: Sal Khan, founder of Khan Academy and the Khan Lab School. You can see all of his talks at ted. com. GUY RAZ, HOST:  So here's what a chemistry class at the Khan Lab School in Los Altos, Calif. , sounds like. UNIDENTIFIED CHILDREN: (Singing) Hydrogen and helium and lithium, beryllium, boron, carbon everywhere. Nitrogen all through the air. RAZ: Don't you just kind of want to be in that class? UNIDENTIFIED CHILD #1: I spend at least half an hour every day coding. So I do JavaScript. And now I'm just starting to learn Python. RAZ: JavaScript and Python, pretty crazy, right? Anyway, the Lab School opened up in 2014 as, well, an education laboratory, a kind of testing ground. . . UNIDENTIFIED CHILD #2: Our hazmat suit is built for Europa. RAZ: . . . Where kids from different age groups collaborate. UNIDENTIFIED CHILD #2: The problems are that it's very, very cold there, plus there's deadly radiation. RAZ: And at the Khan Lab School, classes go year-round and there are no grade levels. SALMAN KHAN: You know, they come in, there's a group time where, you know, you have kids as young as 5, as old as 14, all together in a room. You know, they really feel like cousins. A lot of. . . RAZ: This is the school's founder, Sal Khan. KHAN: They'll have their morning meeting. Then they go into core skills time. There's a lot of peer-to-peer interaction going on in that period. But once you get to lunch and the whole afternoon, it's mainly project-based learning, students working in kind of this collaborative, cross-age environment. RAZ: And at the heart of Sal Khan's approach, flipping the classroom so that students watch online lectures at home but spend a lot more time working with teachers and other students in class. KHAN: It makes the classroom take advantage of the human beings that are there. It makes it an active process. It allows the teacher to see in real time where the students actually are. And the idea of getting the information, well, it's better when it's on your own time and pace and you can pause and repeat and watch exactly what you need. RAZ: And this whole idea of flipping the classroom, it's something Sal kind of stumbled upon more than a decade ago when he started to post these free educational videos online, which he called Khan Academy. KHAN: So in a traditional lecture model, I show up, I'm like, all right, I'm sitting here. And it just happens to you. And some of it might stick. While on demand video, when I click on a video, I'm only going to click - it's kind of like asking a question. Hey, I'm still confused about this. Give me another five-minute example or explain the concept a little bit better. And so when you are pulling information, you're naturally going to be more open to it. RAZ: Khan Academy began sort of by accident in 2004. At the time, Sal was working at a hedge fund and his 12-year-old cousin came to visit. And she was dispirited because she'd been placed in a slower math class. KHAN: I asked her about it. Turns out, she had trouble with unit conversion. RAZ: You know, changing feet to meters or gallons to liters. KHAN: I offered to tutor her, convinced that she could understand unit conversion. And so we started working together over the phone. RAZ: And eventually, she got it. KHAN: And then I called up her school, I say, hey, you know, I think Nadia (ph) should retake that placement exam from last year. They said, who are you? (Laughter) I said, I'm her cousin. And they let her. And that same Nadia that two months ago was being tagged and tracked as a remedial math student was now placed into the advanced math class. And then word gets around the family that free tutoring is going on. RAZ: So one cousin becomes two, then three and then four, five, six, seven, eight. . . KHAN: Once it was 10 or 15 cousins, the scheduling logistics got a little bit more difficult. RAZ: Sal would organize conference calls. And then he would email pictures of math problems back and forth. And eventually, someone suggested, hey, why don't you just post your lessons on YouTube? KHAN: I actually wasn't that familiar with it at the time. And I said, no, no, that doesn't make any sense. YouTube is for cats playing piano. RAZ: (Laughter). KHAN: It's not for serious mathematics. RAZ: But he tried it anyway. (SOUNDBITE OF YOUTUBE VIDEO) KHAN: Welcome to the presentation on adding and subtracting fractions. Let's get started. And I started telling my cousins, hey, I'm making videos on a lot of the common concepts and questions that y'all are asking me about. Why don't you watch them ahead of time and when we get on the phone, we can dig a little bit deeper? And after about a month, I asked for feedback and they famously said they like me better on YouTube than in person. (SOUNDBITE OF YOUTUBE VIDEO) KHAN: So this one-fourth right here, let's say it's this one-fourth of the pie, right? And we're going to add it to another one-fourth of the pie. I think what they were saying is it was very valuable to have it on demand. They didn't have to feel embarrassed. They didn't have to feel like they were wasting my time. And so I kept going. It was public on YouTube, started to become clear that people who weren't my cousins were watching. That just kept growing. (SOUNDBITE OF TED TALK) KHAN: Even at this point, you know, I said, OK, maybe it's a good supplement. It's good for motivated students. It's good for maybe homeschoolers. But I didn't think it would be something that would somehow penetrate the classroom. RAZ: Sal picks up the story from the TED stage. (SOUNDBITE OF TED TALK) KHAN: But then I started getting letters from teachers. And the teachers would write saying we've used your videos to flip the classroom. You've given the lectures. So now what I do is I assign the lectures for homework. And what used to be homework, I now have the students doing in the classroom. And I want to pause here for a second because this is the unintuitive thing when you talk about technology in the classroom. They took a fundamentally dehumanizing experience, a bunch of - 30 kids with their fingers on their lips not allowed to interact with each other, a teacher, no matter how good, has to give this kind of one-size-fits-all lecture to 30 students - you know, blank faces, slightly antagonistic. And now it's a human experience. Now they're actually interacting with each other. RAZ: So how does Khan Academy teach, let's say, algebra to a seventh grader differently than that seventh grader would learn it in a classroom in middle school? KHAN: Well, one, we want to put practice first and practice at your level of development. So in a traditional school, it might be October. Hey, we're all going to be doing exponents in seventh grade. What we would recommend is let students start at the beginning and then let them keep practicing at their own time and pace. And then the teacher can get information on where all their students are and intervene accordingly. Say, hey, those students are getting exponents just fine, let them move on to logarithms, while these students are actually, not even exponents, some of these students are having trouble with their multiplication tables. Let's make sure they have that foundation well because if they don't learn that, exponents are going to be near impossible. And so it allows the teacher to become more of a master conductor of an orchestra. And, you know, this has to be a little bit louder, this has to be a little bit more quiet. So that's what we generally advocate. In terms of the actual content materials, I think there's a lot of teachers out there, incredible teachers who do a very good job of connecting material, making it make conceptual sense. I think textbooks do a pretty bad job of that. It tends to fragment the knowledge, make it seem like a series of formulas. And so we're trying to do both of these things - allow classrooms to move to this more personalized, you could say, competency-based world. And at the same time, allow the content to be delivered in a way that is much more natural for students, that feels much more conceptual and also exposes the beauty in things. RAZ: So could this approach, could flipping the classroom actually revolutionize teaching? In a minute, why Sal Khan believes the answer is yes. Stay with us. I'm Guy Raz, and you're listening to the TED Radio Hour from NPR. (SOUNDBITE OF MUSIC) RAZ: It's the TED Radio Hour from NPR. I'm Guy Raz. And on the show today, ideas about rethinking school. And before the break, we were hearing how Sal Khan turned an experiment with online videos into a teaching tool to flip the classroom. In more than 10 years since he launched Khan Academy, millions of people have watched the videos, all free and made available in more than three dozen different languages. (SOUNDITE OF ARCHIVED RECORDING) UNIDENTIFIED MAN: (Foreign language spoken). UNIDENTIFIED WOMAN: (Foreign language spoken). UNIDENTIFIED MAN: (Foreign language spoken). (SOUNDBITE OF TED TALK) KHAN: Imagine what it does to a street kid in Calcutta who has to help his family during the day and that's the reason why he or she can't go to school. Now they can spend two hours a day and remediate or get up to speed and not feel embarrassed about what they do or don't know. Now imagine what happens where, you know, we talked about the peers teaching each other inside of a classroom. But this is all one system. There's no reason why you can't have that peer-to-peer tutoring beyond that one classroom. Imagine what happens if that student in Calcutta all of a sudden can tutor your son or your son can tutor that kid in Calcutta. And I think what you'll see emerging is this notion of a global one-world classroom. And that's essentially what we're trying to build. RAZ: Could Khan Academy, I mean, could it replace school for - or does it replace school for lots of children around the world who may not have access to traditional classrooms? KHAN: In an ideal world, you have a physical school. Obviously, we created a physical school so we think it's very, very important. But the reality is that many students, you know, it could be in under-served areas, it could be in rural areas, impoverished areas, there could be cultural barriers to going to school. You know, we've had some stories of young girls under, you know, controlled by the Taliban, they're using Khan Academy as their outlet. So, yes, we - ideally, you go to a classroom, and we can help supercharge that classroom. But if you don't have access to a classroom, yes, we want to make it so that you could self-educate and prove what you know to the world and so that you can participate in society. RAZ: I mean, I guess what you're essentially trying to do is to append an outdated system. KHAN: Yeah, around the world, we have essentially adopted what could be called a Prussian education system. And it's referring to 18th, 19th century Prussia, one of the first places to industrialize and also one of the first places to rightfully think about universal public education. And - but what they did say - they said, well, we can't give everyone a private tutor like nobility used to get. If we want to make this economic, well, let's - this is the Industrial Revolution. How do we do anything at scale? Well, we batch things together, we move them down in an assembly line, we apply some processes to it. And so that's the model that throughout the world we have. Students are batched together, initially by age, around middle school, age and perceived ability. They move forward at a set pace. But now we have technology, we have notions of on demand video. And so the opportunity - it no longer has to be this utopian thought - is let's give students explanations when they need it, if they need it. Let's give them practice when and if they need it. And so our end isn't just to change things for the sake of changing things. Our end is we want a world where you have access to, you know, a low-cost device, you can access Khan Academy, self-educate yourself and plug in either to the formal academic system or get a job, become part of society. RAZ: Sal Khan, founder of Khan Academy and the Khan Lab School. You can see all of his talks at ted. com.", "section": "TED Radio Hour", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-08-17-544259690": {"title": "Silicon Valley Fights Back Against Extremism Online : NPR", "url": "https://www.npr.org/2017/08/17/544259690/silicon-valley-fights-back-against-extremism-online", "author": "No author found", "published_date": "2017-08-17", "content": "KELLY MCEVERS, HOST: Companies in Silicon Valley have been blocking white supremacists, stopping their ability to raise money online, removing them from Internet search engines and preventing websites from registering. The goal is to make it harder for hate groups to reach their audience. Here to talk about this and what it tells us about free speech and corporate power is NPR's Aarti Shahani. Hello. AARTI SHAHANI, BYLINE: Hi. MCEVERS: So first of all, which companies are doing this, and what are they doing? SHAHANI: Well, a bunch of Silicon Valley companies are blocking hate groups in one way or another, OK? There's a site called The Daily Stormer. It's basically this horrific neo-Nazi blog that decided to write an article making fun of, attacking the woman who was killed in Charlottesville by the man who plowed his car into protesters. Well, Facebook decided to use software to automatically zap any link to that offensive article unless the person who posted it put a caption that was critical of it, OK? Facebook and Twitter have also both deactivated the accounts of several white nationalists. Beyond the social networks, you know, to exist on the worldwide web, You have to register your domain. So thedailystormer. com was using this well-known registrar called GoDaddy. GoDaddy kicked them off, so they then went to Google. And then Google kicked them off, too. And besides that, Spotify is removing so-called white power music. MCEVERS: And is all this since the racial violence in Charlottesville, or has it been going on longer? SHAHANI: No. I mean Charlottesville's the turning point, exactly. MCEVERS: Yeah, OK. So how significantly are groups like The Daily Stormer being harmed? I mean can they still raise money? SHAHANI: Well, on the money side, PayPal is barring some users who were raising money for the white supremacist rally. Apple is suspending Apple Pay support if you try to buy far right merchandise like, say, swastika T-shirts. And so what you're basically seeing is a lot of Internet companies - giant ones and smaller ones - stepping up after Charlottesville to say, we're not going to facilitate the communication or the fundraising of these groups. MCEVERS: And you've been in touch with a tech company that says it's never censored any users before this week. Tell us about their decision. SHAHANI: Yeah. This is actually fascinating. There's the CEO of this one tech company called Cloudflare, and he decided to go ahead and block or stop providing security service to that site I mentioned, The Daily Storm (ph). And he did it in two moves. The first was to stop the service. So the headline around it is basically, hey, another tech company's taking a stand against hate. But then shortly thereafter, he wrote a blog post about why he did what he did, and he said it was actually unsettling. He described it as such because no court ordered it. It was his choice. You know, as a tech CEO, he can wake up one morning and just decide to flip the switch on someone, and it could be because he's having a bad day for something arbitrary, you know, which isn't great for democracy. MCEVERS: Right. SHAHANI: So what's interesting about what he did - the CEO of Cloudflare - is admitting to something that many tech CEOs don't want to admit, which is, you know, they've got tremendous power over speech and content. MCEVERS: Right. And so I wonder. I mean has there been backlash to these decisions - not that, you know, masses of people are coming out and supporting white supremacists but saying this is a little - this makes me nervous that you guys can have this much power to do this kind of thing? SHAHANI: Yeah, well, I mean what's interesting is that first of all, the white supremacist sites that have been targeted - some of those leaders have spoken to me and said that this is not fair, and these companies are overstepping. And you know, ironically, (laughter) the same entities that are calling for the overthrow of government or the radical sort of reformation of it want them to step in and regulate. And that's not so dissimilar from what some progressives have been saying as well about these companies. I mean this is not at all the first time that Google and Facebook and others have stepped in to delist content, you know? Facebook has had campaigns against radical Islam and blocked those kinds of sites, and people have often questioned, well, are they using their corporate power legitimately? MCEVERS: OK. That's NPR's Aarti Shahani. Thank you so much. SHAHANI: Thank you. KELLY MCEVERS, HOST:  Companies in Silicon Valley have been blocking white supremacists, stopping their ability to raise money online, removing them from Internet search engines and preventing websites from registering. The goal is to make it harder for hate groups to reach their audience. Here to talk about this and what it tells us about free speech and corporate power is NPR's Aarti Shahani. Hello. AARTI SHAHANI, BYLINE: Hi. MCEVERS: So first of all, which companies are doing this, and what are they doing? SHAHANI: Well, a bunch of Silicon Valley companies are blocking hate groups in one way or another, OK? There's a site called The Daily Stormer. It's basically this horrific neo-Nazi blog that decided to write an article making fun of, attacking the woman who was killed in Charlottesville by the man who plowed his car into protesters. Well, Facebook decided to use software to automatically zap any link to that offensive article unless the person who posted it put a caption that was critical of it, OK? Facebook and Twitter have also both deactivated the accounts of several white nationalists. Beyond the social networks, you know, to exist on the worldwide web, You have to register your domain. So thedailystormer. com was using this well-known registrar called GoDaddy. GoDaddy kicked them off, so they then went to Google. And then Google kicked them off, too. And besides that, Spotify is removing so-called white power music. MCEVERS: And is all this since the racial violence in Charlottesville, or has it been going on longer? SHAHANI: No. I mean Charlottesville's the turning point, exactly. MCEVERS: Yeah, OK. So how significantly are groups like The Daily Stormer being harmed? I mean can they still raise money? SHAHANI: Well, on the money side, PayPal is barring some users who were raising money for the white supremacist rally. Apple is suspending Apple Pay support if you try to buy far right merchandise like, say, swastika T-shirts. And so what you're basically seeing is a lot of Internet companies - giant ones and smaller ones - stepping up after Charlottesville to say, we're not going to facilitate the communication or the fundraising of these groups. MCEVERS: And you've been in touch with a tech company that says it's never censored any users before this week. Tell us about their decision. SHAHANI: Yeah. This is actually fascinating. There's the CEO of this one tech company called Cloudflare, and he decided to go ahead and block or stop providing security service to that site I mentioned, The Daily Storm (ph). And he did it in two moves. The first was to stop the service. So the headline around it is basically, hey, another tech company's taking a stand against hate. But then shortly thereafter, he wrote a blog post about why he did what he did, and he said it was actually unsettling. He described it as such because no court ordered it. It was his choice. You know, as a tech CEO, he can wake up one morning and just decide to flip the switch on someone, and it could be because he's having a bad day for something arbitrary, you know, which isn't great for democracy. MCEVERS: Right. SHAHANI: So what's interesting about what he did - the CEO of Cloudflare - is admitting to something that many tech CEOs don't want to admit, which is, you know, they've got tremendous power over speech and content. MCEVERS: Right. And so I wonder. I mean has there been backlash to these decisions - not that, you know, masses of people are coming out and supporting white supremacists but saying this is a little - this makes me nervous that you guys can have this much power to do this kind of thing? SHAHANI: Yeah, well, I mean what's interesting is that first of all, the white supremacist sites that have been targeted - some of those leaders have spoken to me and said that this is not fair, and these companies are overstepping. And you know, ironically, (laughter) the same entities that are calling for the overthrow of government or the radical sort of reformation of it want them to step in and regulate. And that's not so dissimilar from what some progressives have been saying as well about these companies. I mean this is not at all the first time that Google and Facebook and others have stepped in to delist content, you know? Facebook has had campaigns against radical Islam and blocked those kinds of sites, and people have often questioned, well, are they using their corporate power legitimately? MCEVERS: OK. That's NPR's Aarti Shahani. Thank you so much. SHAHANI: Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-08-18-544365040": {"title": "Tech Companies Blacklist White Supremacist Site : NPR", "url": "https://www.npr.org/2017/08/18/544365040/tech-companies-blacklist-white-supremacist-site", "author": "No author found", "published_date": "2017-08-18", "content": "AILSA CHANG, HOST: Silicon Valley is making a real effort to shut down white nationalism on the Internet. Both Facebook and PayPal have suspended user accounts. Spotify is delisting white supremacist music. One hate group website has in particular been a focus of this crackdown, The Daily Stormer. NPR's Aarti Shahani reached out to one of its leaders. ANDREW AUERNHEIMER: Hail. AARTI SHAHANI, BYLINE: Andrew Auernheimer, also known as Weev, answers my Skype call saying hail, the Nazi greeting. He's in a corner of Eastern Europe you've probably never heard of, Transnistria. AUERNHEIMER: It's a republic on the border of Ukraine and Moldova. SHAHANI: Technically, it's a self-proclaimed state with a decent Wi-Fi connection. Auernheimer is from Arkansas. He served about a year in a U. S. prison for hacking AT&T. He says about that time. . . AUERNHEIMER: The U. S. government kidnapped and tortured me under false pretense. And I'm working to make sure that the people that did that pay for it very dearly. SHAHANI: His conviction was later vacated. The 31-year-old now has the long-term goal of radical political transformation. AUERNHEIMER: I want a global empire run by whites. SHAHANI: He's been jumping between countries since 2014 and has re-emerged as an operative for The Daily Stormer, the neo-Nazi site. He's their chief technology officer, kind of. AUERNHEIMER: Well, you know, it's not - we're not exactly like a normal company, you know (laughter)? It's not like we all have executive titles and venture backing. SHAHANI: The site has become the target of a campaign by firms with venture backing and by the largest tech companies on earth to weed out white nationalism from the Internet. Over the weekend, after a driver killed a woman in Charlottesville, The Daily Stormer posted an article making fun of her, calling her fat and childless. Weev and his colleagues did not mourn the loss of life. AUERNHEIMER: We're supposed to react with outrage? No, I think we should laugh in the faces of their bloody shirts. SHAHANI: And The Daily Stormer paid for it. Facebook, where the article went viral, set out to delete every link to it unless a user posted language clearly condemning the blog. Two different companies that register webpages, Google and GoDaddy, kicked thedailystormer. com off so it doesn't load when you try to visit. Google says the website was inciting violence, a clear violation of its terms of service. Auernheimer says it's pure censorship. AUERNHEIMER: I just want to know what they think will happen when they take away our right to speak. SHAHANI: Auernheimer enjoys being provocative. He misstates the facts. He says he doesn't read much outside of white nationalist sites because he can't be bothered. That said, at least one tech CEO who pulled the plug on The Daily Stormer is conflicted about it - Matthew Prince, chief of Cloudflare. MATTHEW PRINCE: I made a determination based on my own moral code that these people were jerks. SHAHANI: Prince says tech companies, which claim to be neutral platforms, are exercising editorial judgment. Today it's against neo-Nazis. Tomorrow it could be against democracy activists in China because the CEO is trying to break into that market. PRINCE: That set of people making that determination is driven by their own moral and economic interests. SHAHANI: Prince questions if he and other CEOs should have the kind of power they just exercised. He even wonders if there should be some kind of government regulation. Meanwhile, The Daily Stormer is operating in the shadows, a part of the Internet designed to be untraceable and anonymous. Aarti Shahani, NPR News, San Francisco. (SOUNDBITE OF GOGOPENGUIN'S \"INITIATE\") AILSA CHANG, HOST:  Silicon Valley is making a real effort to shut down white nationalism on the Internet. Both Facebook and PayPal have suspended user accounts. Spotify is delisting white supremacist music. One hate group website has in particular been a focus of this crackdown, The Daily Stormer. NPR's Aarti Shahani reached out to one of its leaders. ANDREW AUERNHEIMER: Hail. AARTI SHAHANI, BYLINE: Andrew Auernheimer, also known as Weev, answers my Skype call saying hail, the Nazi greeting. He's in a corner of Eastern Europe you've probably never heard of, Transnistria. AUERNHEIMER: It's a republic on the border of Ukraine and Moldova. SHAHANI: Technically, it's a self-proclaimed state with a decent Wi-Fi connection. Auernheimer is from Arkansas. He served about a year in a U. S. prison for hacking AT&T. He says about that time. . . AUERNHEIMER: The U. S. government kidnapped and tortured me under false pretense. And I'm working to make sure that the people that did that pay for it very dearly. SHAHANI: His conviction was later vacated. The 31-year-old now has the long-term goal of radical political transformation. AUERNHEIMER: I want a global empire run by whites. SHAHANI: He's been jumping between countries since 2014 and has re-emerged as an operative for The Daily Stormer, the neo-Nazi site. He's their chief technology officer, kind of. AUERNHEIMER: Well, you know, it's not - we're not exactly like a normal company, you know (laughter)? It's not like we all have executive titles and venture backing. SHAHANI: The site has become the target of a campaign by firms with venture backing and by the largest tech companies on earth to weed out white nationalism from the Internet. Over the weekend, after a driver killed a woman in Charlottesville, The Daily Stormer posted an article making fun of her, calling her fat and childless. Weev and his colleagues did not mourn the loss of life. AUERNHEIMER: We're supposed to react with outrage? No, I think we should laugh in the faces of their bloody shirts. SHAHANI: And The Daily Stormer paid for it. Facebook, where the article went viral, set out to delete every link to it unless a user posted language clearly condemning the blog. Two different companies that register webpages, Google and GoDaddy, kicked thedailystormer. com off so it doesn't load when you try to visit. Google says the website was inciting violence, a clear violation of its terms of service. Auernheimer says it's pure censorship. AUERNHEIMER: I just want to know what they think will happen when they take away our right to speak. SHAHANI: Auernheimer enjoys being provocative. He misstates the facts. He says he doesn't read much outside of white nationalist sites because he can't be bothered. That said, at least one tech CEO who pulled the plug on The Daily Stormer is conflicted about it - Matthew Prince, chief of Cloudflare. MATTHEW PRINCE: I made a determination based on my own moral code that these people were jerks. SHAHANI: Prince says tech companies, which claim to be neutral platforms, are exercising editorial judgment. Today it's against neo-Nazis. Tomorrow it could be against democracy activists in China because the CEO is trying to break into that market. PRINCE: That set of people making that determination is driven by their own moral and economic interests. SHAHANI: Prince questions if he and other CEOs should have the kind of power they just exercised. He even wonders if there should be some kind of government regulation. Meanwhile, The Daily Stormer is operating in the shadows, a part of the Internet designed to be untraceable and anonymous. Aarti Shahani, NPR News, San Francisco. (SOUNDBITE OF GOGOPENGUIN'S \"INITIATE\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-08-26-546323236": {"title": "Human Rights Watch Raises Concerns Over Autonomous Weapons : NPR", "url": "https://www.npr.org/2017/08/26/546323236/human-rights-watch-raises-concerns-over-autonomous-weapons", "author": "No author found", "published_date": "2017-08-26", "content": "SCOTT SIMON, HOST: Elon Musk, the CEO of Tesla, signed a letter earlier this week that got our attention. It was addressed to the United Nations Convention on Certain Conventional Weapons, and it outlined concerns that Musk and another 100 robotics and artificial intelligence experts have over the development of fully autonomous weapons - think self-driving cars but as lethal machines. Human Rights Watch is asking for a pre-emptive ban on the development of these weapons. Bonnie Docherty is the senior arms researcher at Human Rights Watch and joins us in our studios. Ms. Docherty, thanks so much for being with us. BONNIE DOCHERTY: Thank you for having me. SIMON: What are your concerns? DOCHERTY: Well, fully autonomous weapons raise a host of concerns - they're moral, legal, security, technological. So, for example, the moral perspective, many people find it objectionable, even outrageous, that a weapon could make a life-and-death decision on the battlefield or in law enforcement, for that example. From a legal perspective, there's a lot of concerns whether they could follow international law and adequately protect civilians in war. And there's also issues of accountability. If a fully autonomous weapon killed civilians, who would you hold responsible? There's problems with holding commanders, manufacturers, producers responsible, so they would escape liability. SIMON: A lot of people will notice that human beings seem to be pretty gifted at figuring out ways to kill each other without the benefit of machines already, don't they? DOCHERTY: Well, they do. And so what we want to do is avoid exacerbating the situation by having new tools for humans and in some ways delegating that responsibility to others. SIMON: People who undertake drone warfare for the United States and other societies say that contrary to what we might think, drones actually can be more selective and they can observe the international rules of conduct and engagement in a way people often don't. You don't think robots could do that? DOCHERTY: Well, these weapons that we're concerned about in this particular campaign are the step-beyond drones. Currently, drones have the ability to fly autonomously and to even select targets, but a human is finally the one that pushes the button that chooses to kill. And what we're concerned about is when we go beyond that, when the robot itself is making the determination to kill. And that's when you cross a moral red line and run a lot of risks in terms of accountability and international law violations. SIMON: Haven't we learned from North Korea in recent experience - and for that matter, the rearmament of Germany in the 1930s - that people will sign any piece of paper, but when the crunch comes, they will develop the weapons that they have agreed not to because they think it's in their self-interest? DOCHERTY: There are limits of international law. There's elements of any national laws as well. Creating a stigma through international law, through a treaty or set of norms will help limit that. Obviously, no law is perfect. And I often use the analogy of laws against murder do not prevent all murder, but that doesn't mean we should not ban murder. And I think this is similar, that it still has a deterrence effect. And it can affect states that are even outside because it becomes - they'll be considered a pariah of the international community if they behave in such a way. SIMON: Do you know of a single nation that's expressed support so far? DOCHERTY: There are actually 19 states that have spoken out in favor of a ban. And at the Convention on Conventional Weapons meetings, there have been a number of others who have spoken in favor of requiring meaningful human control over the decision to kill on the battlefield or in law enforcement. SIMON: Well, let me put it this way. Have the United States, Russia or China or any country in the European Union expressed support? DOCHERTY: Some European countries have spoken in favor of a requirement for human control. The U. S. , Russia, China and others have not been in favor of a ban, but some of them have been willing to continue discussions. They recognize these weapons would dramatically revolutionize warfare and that they want something to be done. It's a question of how far they're willing to go. And one thing we encourage countries to do is even if they're not at this point willing to go for a international ban, to develop national policies that would restrict the use at a national level. And the U. S. has done that. SIMON: Bonnie Docherty is senior arms researcher at Human Rights Watch. Thanks so much for being with us. DOCHERTY: Thank you very much for having me. SCOTT SIMON, HOST:  Elon Musk, the CEO of Tesla, signed a letter earlier this week that got our attention. It was addressed to the United Nations Convention on Certain Conventional Weapons, and it outlined concerns that Musk and another 100 robotics and artificial intelligence experts have over the development of fully autonomous weapons - think self-driving cars but as lethal machines. Human Rights Watch is asking for a pre-emptive ban on the development of these weapons. Bonnie Docherty is the senior arms researcher at Human Rights Watch and joins us in our studios. Ms. Docherty, thanks so much for being with us. BONNIE DOCHERTY: Thank you for having me. SIMON: What are your concerns? DOCHERTY: Well, fully autonomous weapons raise a host of concerns - they're moral, legal, security, technological. So, for example, the moral perspective, many people find it objectionable, even outrageous, that a weapon could make a life-and-death decision on the battlefield or in law enforcement, for that example. From a legal perspective, there's a lot of concerns whether they could follow international law and adequately protect civilians in war. And there's also issues of accountability. If a fully autonomous weapon killed civilians, who would you hold responsible? There's problems with holding commanders, manufacturers, producers responsible, so they would escape liability. SIMON: A lot of people will notice that human beings seem to be pretty gifted at figuring out ways to kill each other without the benefit of machines already, don't they? DOCHERTY: Well, they do. And so what we want to do is avoid exacerbating the situation by having new tools for humans and in some ways delegating that responsibility to others. SIMON: People who undertake drone warfare for the United States and other societies say that contrary to what we might think, drones actually can be more selective and they can observe the international rules of conduct and engagement in a way people often don't. You don't think robots could do that? DOCHERTY: Well, these weapons that we're concerned about in this particular campaign are the step-beyond drones. Currently, drones have the ability to fly autonomously and to even select targets, but a human is finally the one that pushes the button that chooses to kill. And what we're concerned about is when we go beyond that, when the robot itself is making the determination to kill. And that's when you cross a moral red line and run a lot of risks in terms of accountability and international law violations. SIMON: Haven't we learned from North Korea in recent experience - and for that matter, the rearmament of Germany in the 1930s - that people will sign any piece of paper, but when the crunch comes, they will develop the weapons that they have agreed not to because they think it's in their self-interest? DOCHERTY: There are limits of international law. There's elements of any national laws as well. Creating a stigma through international law, through a treaty or set of norms will help limit that. Obviously, no law is perfect. And I often use the analogy of laws against murder do not prevent all murder, but that doesn't mean we should not ban murder. And I think this is similar, that it still has a deterrence effect. And it can affect states that are even outside because it becomes - they'll be considered a pariah of the international community if they behave in such a way. SIMON: Do you know of a single nation that's expressed support so far? DOCHERTY: There are actually 19 states that have spoken out in favor of a ban. And at the Convention on Conventional Weapons meetings, there have been a number of others who have spoken in favor of requiring meaningful human control over the decision to kill on the battlefield or in law enforcement. SIMON: Well, let me put it this way. Have the United States, Russia or China or any country in the European Union expressed support? DOCHERTY: Some European countries have spoken in favor of a requirement for human control. The U. S. , Russia, China and others have not been in favor of a ban, but some of them have been willing to continue discussions. They recognize these weapons would dramatically revolutionize warfare and that they want something to be done. It's a question of how far they're willing to go. And one thing we encourage countries to do is even if they're not at this point willing to go for a international ban, to develop national policies that would restrict the use at a national level. And the U. S. has done that. SIMON: Bonnie Docherty is senior arms researcher at Human Rights Watch. Thanks so much for being with us. DOCHERTY: Thank you very much for having me.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-08-30-547062884": {"title": "What's Up Those Baseball Sleeves? Lots Of Data, And Privacy Concerns : NPR", "url": "https://www.npr.org/2017/08/30/547062884/whats-up-those-baseball-sleeves-lots-of-athletes-data-and-concerns-about-privacy", "author": "No author found", "published_date": "2017-08-30", "content": "AILSA CHANG, HOST: In a stats-driven sport like baseball, it seems like we know everything about every player, from batting average to - well, to get a little arcane - to a pitcher's power finesse ratio. But in baseball, as in all sports, there's a wealth of information in the athletes' bodies. So-called wearables that track bio info have become more prevalent in elite sports. But there are growing concerns about what will be done with all that data. Here's NPR's Tom Goldman. TOM GOLDMAN, BYLINE: In an industrial park in Kent, Wash. , near Seattle, it's hard to tell which of the featureless buildings is which until you listen. (SOUNDBITE OF BASEBALL HITTING CATCHER'S MITT)GOLDMAN: The smack of a pitched ball in a catcher's mitt tells you where Driveline Baseball is. Driveline is a training facility for players from high school to the major leagues. It has the usual weight room, pitching and batting cages. But there's also a biomechanics lab and an emphasis on data collection. MICHAEL O'CONNELL: Straight. Palm up - slide this on. As usual, just kind of keep track on it. See - if it slides down or anything, let me know. UNIDENTIFIED PITCHER: OK. GOLDMAN: Driveline research assistant Michael O'Connell pulls what appears to be a regular compression sleeve onto a pitcher's throwing arm. But this sleeve, made by Motus, is anything but regular. It contains a sensor that measures all kinds of things going on in a pitcher's arm. What's the arm's speed? How much is the shoulder rotating? O'CONNELL: So what I'm doing is writing down the mile per hour of the pitch and then the Motus metrics. GOLDMAN: O'Connell is now outside the pitching cage watching the measurements as they blink onto his laptop screen. O'CONNELL: So that's the elbow stress, or the elbow torque. GOLDMAN: So we should pause right here because elbow stress is the most important metric from the sleeve. Baseball, in recent years, has had an epidemic of Tommy John surgeries. That's the revolutionary elbow procedure named after the first player who had it. The sleeve can help identify elbow weakness and fatigue, or it can signal the elbow is OK, as it did with Miami Marlins starting pitcher Dan Straily. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED ANNOUNCER: Back-to-back strikeouts to open up the second here for Dan Straily. GOLDMAN: Straily worked quite a bit with the sleeve at Driveline. And the device helped him with what had been a troublesome shoulder. Here's Driveline founder Kyle Boddy. KYLE BODDY: As his velocity increased, his elbow stress did not increase. So we knew that it was probably pretty safe to omit extra work on his elbow and take that time and that effort and put it more towards his shoulder to make sure his shoulder stood up to the test of throwing 200 innings in the big leagues, which it has. GOLDMAN: After his practice session at Driveline, I asked Luke Glavin about using the sleeve. He's a pitcher for Lehigh University. Is it a good thing to know all about his throwing arm? LUKE GLAVIN: Yes and no. It's good to have knowledge so you can train the most efficiently. But at some times, I feel like you get info overload. And you can start worrying about things that you would have done naturally. GOLDMAN: The sleeve is just one of a growing number of wearables for elite athletes. A band around the midsection can test the electrical activity of an athlete's heart as well as their breathing rate. Wristband wearables can track skin temperature. Athletes in sports from pro football to cricket, to auto racing, to lacrosse are delving deeply into their personal biologies. But the measurements, in the hands of their employers, potentially could backfire. Attorney Alan Milstein lectures on sports and bioethics. ALAN MILSTEIN: If the purpose is really to find out - gee, is this guy really worth it? Should we sign him to another year? No, he looks like he's really failing. Let's get rid of him. GOLDMAN: And it's obviously not in the athletes' best interests for the team to have access to every aspect of their health. Driveline encrypts all the data from athletes and restricts who gets it. Major League Baseball is the only major sports league to allow wearables during games, including the sleeve. The labor contract is filled with language to protect player privacy. So there's this duality going on - wearables revealing more and more about elite athletes, the efforts to control the information in all sports, trying to pump the brakes on a quickly emerging industry. Tom Goldman, NPR News. AILSA CHANG, HOST:  In a stats-driven sport like baseball, it seems like we know everything about every player, from batting average to - well, to get a little arcane - to a pitcher's power finesse ratio. But in baseball, as in all sports, there's a wealth of information in the athletes' bodies. So-called wearables that track bio info have become more prevalent in elite sports. But there are growing concerns about what will be done with all that data. Here's NPR's Tom Goldman. TOM GOLDMAN, BYLINE: In an industrial park in Kent, Wash. , near Seattle, it's hard to tell which of the featureless buildings is which until you listen. (SOUNDBITE OF BASEBALL HITTING CATCHER'S MITT) GOLDMAN: The smack of a pitched ball in a catcher's mitt tells you where Driveline Baseball is. Driveline is a training facility for players from high school to the major leagues. It has the usual weight room, pitching and batting cages. But there's also a biomechanics lab and an emphasis on data collection. MICHAEL O'CONNELL: Straight. Palm up - slide this on. As usual, just kind of keep track on it. See - if it slides down or anything, let me know. UNIDENTIFIED PITCHER: OK. GOLDMAN: Driveline research assistant Michael O'Connell pulls what appears to be a regular compression sleeve onto a pitcher's throwing arm. But this sleeve, made by Motus, is anything but regular. It contains a sensor that measures all kinds of things going on in a pitcher's arm. What's the arm's speed? How much is the shoulder rotating? O'CONNELL: So what I'm doing is writing down the mile per hour of the pitch and then the Motus metrics. GOLDMAN: O'Connell is now outside the pitching cage watching the measurements as they blink onto his laptop screen. O'CONNELL: So that's the elbow stress, or the elbow torque. GOLDMAN: So we should pause right here because elbow stress is the most important metric from the sleeve. Baseball, in recent years, has had an epidemic of Tommy John surgeries. That's the revolutionary elbow procedure named after the first player who had it. The sleeve can help identify elbow weakness and fatigue, or it can signal the elbow is OK, as it did with Miami Marlins starting pitcher Dan Straily. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED ANNOUNCER: Back-to-back strikeouts to open up the second here for Dan Straily. GOLDMAN: Straily worked quite a bit with the sleeve at Driveline. And the device helped him with what had been a troublesome shoulder. Here's Driveline founder Kyle Boddy. KYLE BODDY: As his velocity increased, his elbow stress did not increase. So we knew that it was probably pretty safe to omit extra work on his elbow and take that time and that effort and put it more towards his shoulder to make sure his shoulder stood up to the test of throwing 200 innings in the big leagues, which it has. GOLDMAN: After his practice session at Driveline, I asked Luke Glavin about using the sleeve. He's a pitcher for Lehigh University. Is it a good thing to know all about his throwing arm? LUKE GLAVIN: Yes and no. It's good to have knowledge so you can train the most efficiently. But at some times, I feel like you get info overload. And you can start worrying about things that you would have done naturally. GOLDMAN: The sleeve is just one of a growing number of wearables for elite athletes. A band around the midsection can test the electrical activity of an athlete's heart as well as their breathing rate. Wristband wearables can track skin temperature. Athletes in sports from pro football to cricket, to auto racing, to lacrosse are delving deeply into their personal biologies. But the measurements, in the hands of their employers, potentially could backfire. Attorney Alan Milstein lectures on sports and bioethics. ALAN MILSTEIN: If the purpose is really to find out - gee, is this guy really worth it? Should we sign him to another year? No, he looks like he's really failing. Let's get rid of him. GOLDMAN: And it's obviously not in the athletes' best interests for the team to have access to every aspect of their health. Driveline encrypts all the data from athletes and restricts who gets it. Major League Baseball is the only major sports league to allow wearables during games, including the sleeve. The labor contract is filled with language to protect player privacy. So there's this duality going on - wearables revealing more and more about elite athletes, the efforts to control the information in all sports, trying to pump the brakes on a quickly emerging industry. Tom Goldman, NPR News.", "section": "Sports", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-08-31-547491073": {"title": "Tech Giant Google Finds Itself In Another Free-Speech Controversy : NPR", "url": "https://www.npr.org/2017/08/31/547491073/google-finds-itself-in-another-free-speech-controversy", "author": "No author found", "published_date": "2017-08-31", "content": "AILSA CHANG, HOST: I want to go very quickly now to Aarti Shahani, NPR's tech reporter. Aarti, why is this story involving Barry Lynn hitting such a nerve? AARTI SHAHANI, BYLINE: Yeah. You know, I think it's hitting a nerve because Google has a novel form of power over both the distribution of ideas and the creation of ideas, right? Like, we've seen big corporations influence research. That's nothing new. It happens with oil and gas. It happens with pharmaceuticals. You know, what's new is big tech - right? - making money by organizing the world's information through secret algorithms that we don't really understand. And then generating so much money from the ad revenue, they can pay to shape the thoughts and the content the rest of us are creating. So it's like, you know, Google as well as others - you could say Facebook, too. It's like they're managing the pipes. And they're increasingly deciding what goes into the pipes. And the rest of us are just eating and drinking it up. CHANG: And you could also say they're actually tossing out things in those pipes completely, like Facebook did in response to Charlottesville. SHAHANI: That's exactly right. You know, after the Charlottesville protests, Facebook zapped away links to a white supremacist article. You know, whether or not you like the move, it does point to the fact if big tech wants to silence you, they can. CHANG: So in the case of Barry Lynn and New America - I mean, Lynn, here, says he got kicked out because he wrote things Google did not like. Have there been other instances where it seems like Google is trying to influence the speech of another organization that gets money from the company? SHAHANI: You know, what I've learned about is more self-censorship, OK? Yesterday, I called people whom I know get money from Google. I spoke with this one professor who was like, you know, there's an area of research I've thought about doing to look at the Communications Decency Act, which basically protects Google and other Internet companies from being liable for fake news and slander. The professor's not touching it because professor gets money from Google. CHANG: All right, that's NPR's Aarti Shahani. Thank you, Aarti. SHAHANI: Thank you. (SOUNDBITE OF FREE THE ROBOT'S \"JUPITER\") AILSA CHANG, HOST:  I want to go very quickly now to Aarti Shahani, NPR's tech reporter. Aarti, why is this story involving Barry Lynn hitting such a nerve? AARTI SHAHANI, BYLINE: Yeah. You know, I think it's hitting a nerve because Google has a novel form of power over both the distribution of ideas and the creation of ideas, right? Like, we've seen big corporations influence research. That's nothing new. It happens with oil and gas. It happens with pharmaceuticals. You know, what's new is big tech - right? - making money by organizing the world's information through secret algorithms that we don't really understand. And then generating so much money from the ad revenue, they can pay to shape the thoughts and the content the rest of us are creating. So it's like, you know, Google as well as others - you could say Facebook, too. It's like they're managing the pipes. And they're increasingly deciding what goes into the pipes. And the rest of us are just eating and drinking it up. CHANG: And you could also say they're actually tossing out things in those pipes completely, like Facebook did in response to Charlottesville. SHAHANI: That's exactly right. You know, after the Charlottesville protests, Facebook zapped away links to a white supremacist article. You know, whether or not you like the move, it does point to the fact if big tech wants to silence you, they can. CHANG: So in the case of Barry Lynn and New America - I mean, Lynn, here, says he got kicked out because he wrote things Google did not like. Have there been other instances where it seems like Google is trying to influence the speech of another organization that gets money from the company? SHAHANI: You know, what I've learned about is more self-censorship, OK? Yesterday, I called people whom I know get money from Google. I spoke with this one professor who was like, you know, there's an area of research I've thought about doing to look at the Communications Decency Act, which basically protects Google and other Internet companies from being liable for fake news and slander. The professor's not touching it because professor gets money from Google. CHANG: All right, that's NPR's Aarti Shahani. Thank you, Aarti. SHAHANI: Thank you. (SOUNDBITE OF FREE THE ROBOT'S \"JUPITER\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-09-01-547774558": {"title": "How Technology Helped Rescuers : NPR", "url": "https://www.npr.org/2017/09/01/547774558/how-technology-helped-rescuers", "author": "No author found", "published_date": "2017-09-01", "content": "RACHEL MARTIN, HOST: This past week in Texas, we saw everyday citizens driving their boats to rescue folks who were stranded by Hurricane Harvey, a bit chaotic but a surprisingly organized chaos - complete with volunteer dispatchers. MARY LOUISE KELLY, HOST: Yeah. For a look at how they did it, we spoke with Melissa Adair. MELISSA WYNN ADAIR: Somebody might have a need, and it would come in through either of our channels, through Facebook or through our Zello channel. KELLY: And Melissa is one of the people behind the Texas Navy 2017 Facebook page and Zello channel. Now, if you're wondering, what's Zello. . . ADAIR: The Zello app converts your smartphone into a walkie-talkie. Because it's on the Internet, you can talk to anybody. MARTIN: So a person would reach out for help. And Melissa says teams of volunteers were monitoring those requests, and then they would enter them into Google spreadsheets. ADAIR: Anybody that had Internet access, no matter where they were in the world, they were able to communicate and see what each other was doing. KELLY: And from there, dispatchers used Zello to share this information with people out in the boats, people like Sean Smith (ph). SEAN SMITH: You could share your location with the Texas Navy. So if you were in the area and you marked you're on the water, they would contact you directly and say, hey, you need to go here. MARTIN: And they went, and they helped. And then they did it again and again. RACHEL MARTIN, HOST:  This past week in Texas, we saw everyday citizens driving their boats to rescue folks who were stranded by Hurricane Harvey, a bit chaotic but a surprisingly organized chaos - complete with volunteer dispatchers. MARY LOUISE KELLY, HOST:  Yeah. For a look at how they did it, we spoke with Melissa Adair. MELISSA WYNN ADAIR: Somebody might have a need, and it would come in through either of our channels, through Facebook or through our Zello channel. KELLY: And Melissa is one of the people behind the Texas Navy 2017 Facebook page and Zello channel. Now, if you're wondering, what's Zello. . . ADAIR: The Zello app converts your smartphone into a walkie-talkie. Because it's on the Internet, you can talk to anybody. MARTIN: So a person would reach out for help. And Melissa says teams of volunteers were monitoring those requests, and then they would enter them into Google spreadsheets. ADAIR: Anybody that had Internet access, no matter where they were in the world, they were able to communicate and see what each other was doing. KELLY: And from there, dispatchers used Zello to share this information with people out in the boats, people like Sean Smith (ph). SEAN SMITH: You could share your location with the Texas Navy. So if you were in the area and you marked you're on the water, they would contact you directly and say, hey, you need to go here. MARTIN: And they went, and they helped. And then they did it again and again.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-09-04-548505776": {"title": "What Parts Of The Workforce Might Be Safe From Robots? : NPR", "url": "https://www.npr.org/2017/09/04/548505776/what-parts-of-the-workforce-might-be-safe-from-robots", "author": "No author found", "published_date": "2017-09-04", "content": "ARI SHAPIRO, HOST: It's Labor Day, so we're looking at jobs on this week's All Tech Considered. (SOUNDBITE OF MUSIC)SHAPIRO: Today we're kicking off a new series that looks at how advances in artificial intelligence are changing our work. It's called Is My Job Safe? We'll look at specific industries where jobs might be disappearing or changing. To begin, we're going to look at which parts of the workforce might be relatively safe from the robots. We're joined by Erik Brynjolfsson. He directs the MIT Initiative on the Digital Economy. Welcome to the program. ERIK BRYNJOLFSSON: Good to be here. SHAPIRO: Back in 2004, Researchers at MIT and Harvard published a list of professions that they felt were most and least likely to undergo automation. And one example they gave of a job that could not possibly be automated in the future was truck driving. BRYNJOLFSSON: Yeah. SHAPIRO: And today automated vehicles are being tested on the roads. Already the job of truck driving could be completely automated. So your job is to try to predict which jobs will be automated in the future. But I wonder, are humans really able to make these kinds of predictions? The evidence seems to be that we're not very good at it. BRYNJOLFSSON: It's definitely not easy. There's constantly new innovations coming along, as there should be. And so we have to update our insights from time to time. SHAPIRO: Well, with that as a caveat, how much of the U. S. workforce would you say is at risk of automation in the coming decades? Are we talking about, like, 10 percent, 50 percent, 80 percent? BRYNJOLFSSON: Well, I've got to give you some perspective. There's constantly automation of huge chunks of the workforce. And there's new jobs being created and old jobs being automated. And that's going to happen in the next 10 years. I wouldn't be surprised if 50 percent or more of the existing jobs had to change drastically or were eliminated. And hopefully another 50 percent of new jobs will be created at the same time. SHAPIRO: What do you see as the sector of the workforce that is least likely to change or least likely to disappear? BRYNJOLFSSON: Well, there are three big categories that machines are really bad at. They've made tremendous advances, but they're bad at first off doing creative work. Whether you're an entrepreneur or a scientist or a novelist, I think you're in pretty good shape doing that long-range creativity. The second big category is interpersonal skills and emotional intelligence, people who are coaches or salespeople or negotiators or caregivers. And the third one is actually manual dexterity and physical mobility. Machines have a hard time doing simple things like picking up a nickel or walking up stairs or clearing a table. And so jobs that depend on that will also be safe for a while. And I think the right way to think about it is not so much looking at jobs, but looking at tasks 'cause almost every job has parts of them that are in one of those three categories, or maybe all three, and other parts that will be affected or even automated. SHAPIRO: It's interesting 'cause when I think about how that translates to education, there's been such an emphasis on science and technology education. But it sounds like you're saying one of the sectors that's likely to be safest is sort of creative work that would suggest liberal arts education. BRYNJOLFSSON: Absolutely. In fact, I think there's probably no better time in history to be somebody with some real creative insights. And then the technology helps you leverage that to millions or billions of people. And people who can combine some creativity with an understanding of the digital world are especially well-positioned. SHAPIRO: Would you say that blue-collar workers are generally more likely to be replaced by robots than white-collar workers? We hear so much about people in manufacturing being replaced by automation. BRYNJOLFSSON: Well, the truth is most blue-collar work has already been automated. I mean, there's - less than 10 percent of Americans now work in the manufacturing sector. I don't think it's so much of a blue collar-white collar division. The big waves have been more structured work versus less structured work, with more structured work being automated faster and work that involves creativity and interpersonal skills as being more robust in the long run. SHAPIRO: If people are at the midpoint in their career right now and they want to prepare themselves for the oncoming robot invasion (laughter), what can they do to make it less likely that they will ultimately someday be replaced? BRYNJOLFSSON: Well, I don't think as a society we're investing enough in education and training and thinking about how to handle this transition. More people should be thinking about the ways we're talking about it right now. SHAPIRO: Erik Brynjolfsson directs the Initiative on the Digital Economy at MIT, and his latest book is called \"Machine, Platform, Crowd. \" Thanks a lot. BRYNJOLFSSON: My pleasure. ARI SHAPIRO, HOST:  It's Labor Day, so we're looking at jobs on this week's All Tech Considered. (SOUNDBITE OF MUSIC) SHAPIRO: Today we're kicking off a new series that looks at how advances in artificial intelligence are changing our work. It's called Is My Job Safe? We'll look at specific industries where jobs might be disappearing or changing. To begin, we're going to look at which parts of the workforce might be relatively safe from the robots. We're joined by Erik Brynjolfsson. He directs the MIT Initiative on the Digital Economy. Welcome to the program. ERIK BRYNJOLFSSON: Good to be here. SHAPIRO: Back in 2004, Researchers at MIT and Harvard published a list of professions that they felt were most and least likely to undergo automation. And one example they gave of a job that could not possibly be automated in the future was truck driving. BRYNJOLFSSON: Yeah. SHAPIRO: And today automated vehicles are being tested on the roads. Already the job of truck driving could be completely automated. So your job is to try to predict which jobs will be automated in the future. But I wonder, are humans really able to make these kinds of predictions? The evidence seems to be that we're not very good at it. BRYNJOLFSSON: It's definitely not easy. There's constantly new innovations coming along, as there should be. And so we have to update our insights from time to time. SHAPIRO: Well, with that as a caveat, how much of the U. S. workforce would you say is at risk of automation in the coming decades? Are we talking about, like, 10 percent, 50 percent, 80 percent? BRYNJOLFSSON: Well, I've got to give you some perspective. There's constantly automation of huge chunks of the workforce. And there's new jobs being created and old jobs being automated. And that's going to happen in the next 10 years. I wouldn't be surprised if 50 percent or more of the existing jobs had to change drastically or were eliminated. And hopefully another 50 percent of new jobs will be created at the same time. SHAPIRO: What do you see as the sector of the workforce that is least likely to change or least likely to disappear? BRYNJOLFSSON: Well, there are three big categories that machines are really bad at. They've made tremendous advances, but they're bad at first off doing creative work. Whether you're an entrepreneur or a scientist or a novelist, I think you're in pretty good shape doing that long-range creativity. The second big category is interpersonal skills and emotional intelligence, people who are coaches or salespeople or negotiators or caregivers. And the third one is actually manual dexterity and physical mobility. Machines have a hard time doing simple things like picking up a nickel or walking up stairs or clearing a table. And so jobs that depend on that will also be safe for a while. And I think the right way to think about it is not so much looking at jobs, but looking at tasks 'cause almost every job has parts of them that are in one of those three categories, or maybe all three, and other parts that will be affected or even automated. SHAPIRO: It's interesting 'cause when I think about how that translates to education, there's been such an emphasis on science and technology education. But it sounds like you're saying one of the sectors that's likely to be safest is sort of creative work that would suggest liberal arts education. BRYNJOLFSSON: Absolutely. In fact, I think there's probably no better time in history to be somebody with some real creative insights. And then the technology helps you leverage that to millions or billions of people. And people who can combine some creativity with an understanding of the digital world are especially well-positioned. SHAPIRO: Would you say that blue-collar workers are generally more likely to be replaced by robots than white-collar workers? We hear so much about people in manufacturing being replaced by automation. BRYNJOLFSSON: Well, the truth is most blue-collar work has already been automated. I mean, there's - less than 10 percent of Americans now work in the manufacturing sector. I don't think it's so much of a blue collar-white collar division. The big waves have been more structured work versus less structured work, with more structured work being automated faster and work that involves creativity and interpersonal skills as being more robust in the long run. SHAPIRO: If people are at the midpoint in their career right now and they want to prepare themselves for the oncoming robot invasion (laughter), what can they do to make it less likely that they will ultimately someday be replaced? BRYNJOLFSSON: Well, I don't think as a society we're investing enough in education and training and thinking about how to handle this transition. More people should be thinking about the ways we're talking about it right now. SHAPIRO: Erik Brynjolfsson directs the Initiative on the Digital Economy at MIT, and his latest book is called \"Machine, Platform, Crowd. \" Thanks a lot. BRYNJOLFSSON: My pleasure.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-09-04-545593956": {"title": "So You Want To Buy An Electric Car? It Requires Some Planning : NPR", "url": "https://www.npr.org/2017/09/04/545593956/so-you-want-to-buy-an-electric-car-it-requires-some-planning", "author": "No author found", "published_date": "2017-09-04", "content": "ARI SHAPIRO, HOST: Two long-range electric cars meant for the masses are hitting the market - the Tesla Model 3 and the Chevrolet Bolt. With India, France and Britain promising to ban gas-powered cars, electric cars seem to have a bright future. Prices are down, and electric charging has become more widely accessible. From Southern California, NPR's Sonari Glinton reports on what to look for if you're thinking about going electric. SONARI GLINTON, BYLINE: Over the last few years, dozens of my colleagues have asked me questions about cars. But recently here at NPR West in Culver City, we got two electric car chargers. And so when my colleague Melissa Kuypers said she was interested in buying an electric vehicle, I thought, perfect guinea pig for a little test. MELISSA KUYPERS, BYLINE: I mean, I definitely have commuter guilt. I drive by myself 13 miles each way. I don't care about performance. I sit in a lot of traffic. And so - I also live in a climate where it doesn't snow. I can pretty much rely on what the weather's going to be. I just felt like I was a good candidate for it, and so why would I not? GLINTON: Now, Melissa is the mother of a toddler. She owns a house. She has a garage and a place to charge it. And this would be her family's second vehicle. And I wanted someone who I could check in with on a regular basis. So she test drove six electric cars. Now, I'm going to use her experience and a couple of stories to help you understand the world of electric cars. To help Melissa pick a car, we're going to talk to some experts. MICAH MUZIO: I'm Micah Muzio, and I work at Kelley Blue Book. GLINTON: Do you think we will notice the most difference driving it, or. . . MUZIO: Oh, yeah, absolutely. GLINTON: Now, the three of us piled into the new Chevrolet Bolt. It's the long-range, all-electric car. It's in the same category as Tesla's Model 3. MUZIO: Yeah. As you get in here, the first thing I did is pushed the power button. It's not really an ignition. And you hear nothing except the smooth sounds of NPR coming on the radio. And that's one of the big changes that you have to get used to, is that there's no firing up the engine. You just kind of get in, and then you quietly leave. GLINTON: I want to add that the quiet can be an issue for pedestrians who don't hear the car and for drivers who sometimes leave them on accidentally. MUZIO: So, yeah, let's get moving here. And electric motors operate very differently than the old internal combustion engine. GLINTON: Can you click through the ways in which they're so different? MUZIO: Well, one, electric motors are much simpler. They basically have one moving part. Electric motors are head and shoulders above the normal internal combustion engine. As I creep out onto the road, I'm just going to kind of floor it. I'm going to be very presumptuous and floor it. KUYPERS: Do you want to put it on sport mode? MUZIO: Yes. I always want to put it on sport mode. KUYPERS: There we go. MUZIO: Ready? GLINTON: Yeah. MUZIO: Little bit of tire squeal and then instantaneous acceleration. The power happens immediately. Torque kicks in as soon as you push the throttle. If I just floor it right now. . . GLINTON: Whoa. MUZIO: That instant power means they're actually kind of fun. GLINTON: One of the ways in which electric cars are different is, well, you have to plug them in. Before we went out on our drive, we spoke to Joel Levin with Plug In America in NPR's parking lot. JOEL LEVIN: We're looking at what's called a Level 2 charger. It's 220 volts, the same power basically as you use for plugging in, like, your dryer at home or, like, heavy-duty appliances. And this is basically - it's got a plug and a long cord attached to it. It's essentially just a very fancy 220 outlet that has some safety equipment in it so that it doesn't overheat. GLINTON: An interesting note - it's these chargers that have encouraged many people to buy EVs. Homeowners, landlords and businesses get tax breaks for installing chargers. And consumers get even larger federal and state tax credits for buying the cars. With the standard charger, it takes about eight full hours for a charge, and super fast charging stations are popping up around the country where you can get it done in about a half an hour. Back in the car, Melissa has another pressing question for Micah Muzio from Kelley Blue Book. KUYPERS: Like, is only the Chevy dealer going to be able to fix this car? MUZIO: The good thing is that from a - the motor side of the equation, they're not going to need repairs any time soon 'cause it's a very simple system. And it's going to be like that in any electric car. The bigger question is the batteries. And the batteries that you find in any electric car now have super, super long warranties. GLINTON: When electric cars were introduced, Muzio says range was a big issue. It's become less of one now. MUZIO: We've got cost-effective cars that have more than enough range for people's normal activities. The electric car's no longer an outlier. EPA says it'll top out at 238. Yeah, like, for just driving around Los Angeles, this is all the range you need. GLINTON: Two thirty-eight is pretty good, especially when you figure my gas car gets a range of about 220. After this and other test drives, Melissa became convinced that an EV was indeed right for her. If other consumers are also convinced, the question becomes, how do cities and power companies handle the electric car? Sonari Glinton, NPR News, Culver City. (SOUNDBITE OF M83 SONG, \"MIDNIGHT CITY\") ARI SHAPIRO, HOST:  Two long-range electric cars meant for the masses are hitting the market - the Tesla Model 3 and the Chevrolet Bolt. With India, France and Britain promising to ban gas-powered cars, electric cars seem to have a bright future. Prices are down, and electric charging has become more widely accessible. From Southern California, NPR's Sonari Glinton reports on what to look for if you're thinking about going electric. SONARI GLINTON, BYLINE: Over the last few years, dozens of my colleagues have asked me questions about cars. But recently here at NPR West in Culver City, we got two electric car chargers. And so when my colleague Melissa Kuypers said she was interested in buying an electric vehicle, I thought, perfect guinea pig for a little test. MELISSA KUYPERS, BYLINE: I mean, I definitely have commuter guilt. I drive by myself 13 miles each way. I don't care about performance. I sit in a lot of traffic. And so - I also live in a climate where it doesn't snow. I can pretty much rely on what the weather's going to be. I just felt like I was a good candidate for it, and so why would I not? GLINTON: Now, Melissa is the mother of a toddler. She owns a house. She has a garage and a place to charge it. And this would be her family's second vehicle. And I wanted someone who I could check in with on a regular basis. So she test drove six electric cars. Now, I'm going to use her experience and a couple of stories to help you understand the world of electric cars. To help Melissa pick a car, we're going to talk to some experts. MICAH MUZIO: I'm Micah Muzio, and I work at Kelley Blue Book. GLINTON: Do you think we will notice the most difference driving it, or. . . MUZIO: Oh, yeah, absolutely. GLINTON: Now, the three of us piled into the new Chevrolet Bolt. It's the long-range, all-electric car. It's in the same category as Tesla's Model 3. MUZIO: Yeah. As you get in here, the first thing I did is pushed the power button. It's not really an ignition. And you hear nothing except the smooth sounds of NPR coming on the radio. And that's one of the big changes that you have to get used to, is that there's no firing up the engine. You just kind of get in, and then you quietly leave. GLINTON: I want to add that the quiet can be an issue for pedestrians who don't hear the car and for drivers who sometimes leave them on accidentally. MUZIO: So, yeah, let's get moving here. And electric motors operate very differently than the old internal combustion engine. GLINTON: Can you click through the ways in which they're so different? MUZIO: Well, one, electric motors are much simpler. They basically have one moving part. Electric motors are head and shoulders above the normal internal combustion engine. As I creep out onto the road, I'm just going to kind of floor it. I'm going to be very presumptuous and floor it. KUYPERS: Do you want to put it on sport mode? MUZIO: Yes. I always want to put it on sport mode. KUYPERS: There we go. MUZIO: Ready? GLINTON: Yeah. MUZIO: Little bit of tire squeal and then instantaneous acceleration. The power happens immediately. Torque kicks in as soon as you push the throttle. If I just floor it right now. . . GLINTON: Whoa. MUZIO: That instant power means they're actually kind of fun. GLINTON: One of the ways in which electric cars are different is, well, you have to plug them in. Before we went out on our drive, we spoke to Joel Levin with Plug In America in NPR's parking lot. JOEL LEVIN: We're looking at what's called a Level 2 charger. It's 220 volts, the same power basically as you use for plugging in, like, your dryer at home or, like, heavy-duty appliances. And this is basically - it's got a plug and a long cord attached to it. It's essentially just a very fancy 220 outlet that has some safety equipment in it so that it doesn't overheat. GLINTON: An interesting note - it's these chargers that have encouraged many people to buy EVs. Homeowners, landlords and businesses get tax breaks for installing chargers. And consumers get even larger federal and state tax credits for buying the cars. With the standard charger, it takes about eight full hours for a charge, and super fast charging stations are popping up around the country where you can get it done in about a half an hour. Back in the car, Melissa has another pressing question for Micah Muzio from Kelley Blue Book. KUYPERS: Like, is only the Chevy dealer going to be able to fix this car? MUZIO: The good thing is that from a - the motor side of the equation, they're not going to need repairs any time soon 'cause it's a very simple system. And it's going to be like that in any electric car. The bigger question is the batteries. And the batteries that you find in any electric car now have super, super long warranties. GLINTON: When electric cars were introduced, Muzio says range was a big issue. It's become less of one now. MUZIO: We've got cost-effective cars that have more than enough range for people's normal activities. The electric car's no longer an outlier. EPA says it'll top out at 238. Yeah, like, for just driving around Los Angeles, this is all the range you need. GLINTON: Two thirty-eight is pretty good, especially when you figure my gas car gets a range of about 220. After this and other test drives, Melissa became convinced that an EV was indeed right for her. If other consumers are also convinced, the question becomes, how do cities and power companies handle the electric car? Sonari Glinton, NPR News, Culver City. (SOUNDBITE OF M83 SONG, \"MIDNIGHT CITY\")", "section": "Business", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-09-05-548715211": {"title": "Drones Descend On Houston To Help Assess Damage From Harvey : NPR", "url": "https://www.npr.org/2017/09/05/548715211/drones-descend-on-houston-to-help-assess-damage-from-harvey", "author": "No author found", "published_date": "2017-09-05", "content": "ROBERT SIEGEL, HOST: Hurricane Harvey has been called unprecedented in its flooding and destruction along the Texas coast. And it also provides an unprecedented opportunity for drones. About a year ago, the Federal Aviation Administration eased restrictions on professional drone use. And now those drones and their operators have descended on the greater Houston area to help assess the damage. Aarian Marshall wrote about these drones for Wired. Welcome to the program. AARIAN MARSHALL: Hi there, Robert. Good to be here. SIEGEL: And what kind of damage is being evaluated these days through drones? MARSHALL: There's actually a lot of reasons that drones can be used after Hurricane Harvey - infrastructure, agriculture to transportation, things like roads and bridges. And then also to evaluate insurance claims on people's personal homes. SIEGEL: So who's actually using the drones to assess the damage? MARSHALL: Well, in the wake of the hurricane, there were actually 43 different organizations that got special authorizations from the FAA to operate drones in the area. The railroad got one. Also, a number of media organizations got them. And then also some insurance companies were allowed to go in and start doing some inspections, as well as oil and gas companies as well to make sure everything is OK there, there's no oil or gas leaking. That would be very bad for the folks who live around the Houston area. SIEGEL: Let's focus on the use of the drones by insurance companies to assess damage. How useful is a drone, actually? It can't see inside buildings to see what the damage is. MARSHALL: Sure, that's definitely true. But drones are actually very, very helpful for insurance companies. I spoke to some folks over at Allstate insurance who are using drones to evaluate for the first time in this - for a disaster of this severity. So drones are very nimble. They're very fast. They're less dangerous than putting people up on roofs or putting helicopters in the air. And they can actually - thanks to the really advanced cameras that you can mount on drones these days, you can zoom in and look at the damage to even a specific shingle. It can get that specific. So what they can also do is relay a live feed over to claims adjusters who are sitting in their offices. So hopefully the folks over there in Houston, in the Houston area will start getting insurance money paid out as soon as possible. SIEGEL: Typically how big are these drones that are being used over Houston? MARSHALL: The drones are generally less than 55 pounds. So they're not gigantic. They're not those military predator drones you might see on TV. But they're not that tiny either. If one fell on you it would hurt, which is why there are professionals who have to take really intense pilot tests to operate them. SIEGEL: You're describing a - what could be a great breakthrough for the use of drones. Does the magnitude, does the number of drones in the sky pose any particular challenges? MARSHALL: Definitely. It will be an interesting test for the FAA's regulations for small drone operation, which they rolled out almost exactly a year ago. Those rules say that drones have to stay below 400 feet in the air, you have to be able to see the drone when you're flying it, and you can't fly over densely populated areas. So it'll be interesting to see what happens in Texas and whether these rules are really working out. I know the FAA is working very closely with the people on the ground there. So they're definitely monitoring the situation. So we'll see what happens. SIEGEL: Aarian Marshall, a reporter for Wired. Thanks. MARSHALL: Thanks so much. ROBERT SIEGEL, HOST:  Hurricane Harvey has been called unprecedented in its flooding and destruction along the Texas coast. And it also provides an unprecedented opportunity for drones. About a year ago, the Federal Aviation Administration eased restrictions on professional drone use. And now those drones and their operators have descended on the greater Houston area to help assess the damage. Aarian Marshall wrote about these drones for Wired. Welcome to the program. AARIAN MARSHALL: Hi there, Robert. Good to be here. SIEGEL: And what kind of damage is being evaluated these days through drones? MARSHALL: There's actually a lot of reasons that drones can be used after Hurricane Harvey - infrastructure, agriculture to transportation, things like roads and bridges. And then also to evaluate insurance claims on people's personal homes. SIEGEL: So who's actually using the drones to assess the damage? MARSHALL: Well, in the wake of the hurricane, there were actually 43 different organizations that got special authorizations from the FAA to operate drones in the area. The railroad got one. Also, a number of media organizations got them. And then also some insurance companies were allowed to go in and start doing some inspections, as well as oil and gas companies as well to make sure everything is OK there, there's no oil or gas leaking. That would be very bad for the folks who live around the Houston area. SIEGEL: Let's focus on the use of the drones by insurance companies to assess damage. How useful is a drone, actually? It can't see inside buildings to see what the damage is. MARSHALL: Sure, that's definitely true. But drones are actually very, very helpful for insurance companies. I spoke to some folks over at Allstate insurance who are using drones to evaluate for the first time in this - for a disaster of this severity. So drones are very nimble. They're very fast. They're less dangerous than putting people up on roofs or putting helicopters in the air. And they can actually - thanks to the really advanced cameras that you can mount on drones these days, you can zoom in and look at the damage to even a specific shingle. It can get that specific. So what they can also do is relay a live feed over to claims adjusters who are sitting in their offices. So hopefully the folks over there in Houston, in the Houston area will start getting insurance money paid out as soon as possible. SIEGEL: Typically how big are these drones that are being used over Houston? MARSHALL: The drones are generally less than 55 pounds. So they're not gigantic. They're not those military predator drones you might see on TV. But they're not that tiny either. If one fell on you it would hurt, which is why there are professionals who have to take really intense pilot tests to operate them. SIEGEL: You're describing a - what could be a great breakthrough for the use of drones. Does the magnitude, does the number of drones in the sky pose any particular challenges? MARSHALL: Definitely. It will be an interesting test for the FAA's regulations for small drone operation, which they rolled out almost exactly a year ago. Those rules say that drones have to stay below 400 feet in the air, you have to be able to see the drone when you're flying it, and you can't fly over densely populated areas. So it'll be interesting to see what happens in Texas and whether these rules are really working out. I know the FAA is working very closely with the people on the ground there. So they're definitely monitoring the situation. So we'll see what happens. SIEGEL: Aarian Marshall, a reporter for Wired. Thanks. MARSHALL: Thanks so much.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-09-05-545481011": {"title": "The Army, The Inventor And The Surprising Uses Of A Batman Machine : NPR", "url": "https://www.npr.org/2017/09/05/545481011/the-army-the-inventor-and-the-surprising-uses-of-a-batman-machine", "author": "No author found", "published_date": "2017-09-05", "content": "RACHEL MARTIN, HOST:  NPR's Joe Palca thinks a lot about thinking - specifically how people come up with the big ideas that change our lives. And as you'll hear in this next story, sometimes the inventor himself doesn't even recognize all the possible uses of the thing they have created. JOE PALCA, BYLINE: About 15 years ago, the U. S. Army came to the Massachusetts Institute of Technology with a request. NATE BALL: Can somebody build a powered device that can pull somebody up a rope like Batman? PALCA: That's Nate Ball. At the time, he was an undergrad at MIT. BALL: We looked at each other and said, that sounds awesome. We'd love to build that. PALCA: The Army wanted the device for rescue operations. Ball's idea was to build a kind of battery-powered winch that someone could wear around their waist. In 2005, he formed a company called Atlas Devices to work on the project. BALL: Twelve years later, with a lot of blood, sweat and tears along the way, Atlas Devices gets to build those powered ascenders. PALCA: Ball sold the ascenders to the Army. And the Army used them in rescue operations. So did fire departments and other first responders. But one day, he heard that utility companies were buying them, and Ball wondered why. So he contacted the companies, and they explained they were using the ascenders to repair power lines. BALL: They're able to use the ascender to haul conductor, which means actually, like, pick up the power lines and, you know, raise them up in the air to attach them to the tower. PALCA: Ball says he would never have thought of that application for the ascender. He says that's when he realized something important about inventing. Sometimes you come up with a concept and put it out into the world with an initial vision for what it's good for and how people are going to use it. BALL: And then they come up with new ways to use it. And that's one of the most exciting things about putting something new into the world, is you actually don't know all the things that it might get used for. PALCA: Ball says this even happens with a seemingly straightforward invention. After he built the ascender, the military came back looking for a better ladder. BALL: Ladders can still benefit from a lot of innovation. PALCA: The military wanted something strong but lightweight and segmented, so it was easy to carry. Ball and his colleagues designed and built such a ladder. The military liked it, and then. . . BALL: We found out that in a - you know, in a difficult situation, they had actually taken apart the ladder. And they had extracted a person who had been injured. PALCA: Turning the ladder into a kind of stretcher - again, not what Ball had in mind at all. But for him, that's now part of the invention process - letting people who use his new tools and devices figure out what they're really useful for. Joe Palca, NPR News. (SOUNDBITE OF MOKHOV'S \"ENDLESS SKIES\") RACHEL MARTIN, HOST:   NPR's Joe Palca thinks a lot about thinking - specifically how people come up with the big ideas that change our lives. And as you'll hear in this next story, sometimes the inventor himself doesn't even recognize all the possible uses of the thing they have created. JOE PALCA, BYLINE: About 15 years ago, the U. S. Army came to the Massachusetts Institute of Technology with a request. NATE BALL: Can somebody build a powered device that can pull somebody up a rope like Batman? PALCA: That's Nate Ball. At the time, he was an undergrad at MIT. BALL: We looked at each other and said, that sounds awesome. We'd love to build that. PALCA: The Army wanted the device for rescue operations. Ball's idea was to build a kind of battery-powered winch that someone could wear around their waist. In 2005, he formed a company called Atlas Devices to work on the project. BALL: Twelve years later, with a lot of blood, sweat and tears along the way, Atlas Devices gets to build those powered ascenders. PALCA: Ball sold the ascenders to the Army. And the Army used them in rescue operations. So did fire departments and other first responders. But one day, he heard that utility companies were buying them, and Ball wondered why. So he contacted the companies, and they explained they were using the ascenders to repair power lines. BALL: They're able to use the ascender to haul conductor, which means actually, like, pick up the power lines and, you know, raise them up in the air to attach them to the tower. PALCA: Ball says he would never have thought of that application for the ascender. He says that's when he realized something important about inventing. Sometimes you come up with a concept and put it out into the world with an initial vision for what it's good for and how people are going to use it. BALL: And then they come up with new ways to use it. And that's one of the most exciting things about putting something new into the world, is you actually don't know all the things that it might get used for. PALCA: Ball says this even happens with a seemingly straightforward invention. After he built the ascender, the military came back looking for a better ladder. BALL: Ladders can still benefit from a lot of innovation. PALCA: The military wanted something strong but lightweight and segmented, so it was easy to carry. Ball and his colleagues designed and built such a ladder. The military liked it, and then. . . BALL: We found out that in a - you know, in a difficult situation, they had actually taken apart the ladder. And they had extracted a person who had been injured. PALCA: Turning the ladder into a kind of stretcher - again, not what Ball had in mind at all. But for him, that's now part of the invention process - letting people who use his new tools and devices figure out what they're really useful for. Joe Palca, NPR News. (SOUNDBITE OF MOKHOV'S \"ENDLESS SKIES\")", "section": "Joe's Big Idea", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-09-06-548985335": {"title": "How Tech Giants Use Their Power To Advance Corporate Interests : NPR", "url": "https://www.npr.org/2017/09/06/548985335/how-tech-giants-use-their-power-to-advance-corporate-interests", "author": "No author found", "published_date": "2017-09-06", "content": "ARI SHAPIRO, HOST: Big tech companies influence more of our lives than ever before, and there are growing concerns that they are using that power to advance their own corporate interests. European regulators have fined Google for favoring its own services and products in search results, and a Google-funded think tank, New America, appears to have fired some of its scholars after one of them praised this fine. We're going to speak now with a journalist who had her own experience in this vein several years ago. Kashmir Hill is writing about it now because it seems to show the way a tech giant like Google appears to game the system. Welcome. KASHMIR HILL: Hi, Ari. SHAPIRO: Briefly describe what this experience was that you had several years ago. HILL: So this happened six years ago in 2011. I was a reporter at Forbes at the time. I got pulled into a meeting with Google salespeople where they were talking about Google Plus, which was then a new social network. And they told Forbes that they needed to put the plus-one buttons on Forbes' pages, or it would hurt them in search results because plus-one buttons were going to be a signal in search. SHAPIRO: So basically if Forbes did not promote the Google Plus social network, Forbes articles would not appear as prominently in search results. HILL: They wouldn't phrase it that way. They would say if you didn't have the plus-one buttons, you know, on your articles, you would be at a disadvantage in search rankings. SHAPIRO: And so you published this, and what happened? HILL: Well, first I went to Google's public relations team, and they confirmed that it was going to be a signal in search. And then I published an article about it. And Google flipped out after the article was published and went to Forbes and said that meeting was a business meeting; it was covered by a non-disclosure agreement, and you need to take this article down right away. SHAPIRO: This sounds sort of like a source arguing that something was off the record when it was your understanding that it was on the record, which is not unusual. But what seems more unusual is what happened to the article after you did decide to take it down. HILL: Right. So Google said this was a problem for the business relationship between Forbes and Google and talked to many of my higher ups. And you know, they put a lot of pressure on me to unpublish the article. So I did, and it completely disappeared. It even disappeared from search results very soon after it was unpublished, which was unusual at the time from what I've seen with articles that we had unpublished in the past. SHAPIRO: You asked Google whether they had anything to do with this. What did they tell you? HILL: So Google still feels that that article was inappropriate given that it was based on this confidential business meeting. And they said they had nothing to do with the removal from search results. SHAPIRO: Do you believe them? HILL: (Laughter) What's hard about the story is this is something that happened six years ago. But it is - it's something that's always troubled me because of how quickly the article completely disappeared. The thing is - about tech companies is - we don't know. We don't get to see inside their companies, their algorithms. So I don't know what happened. I only know it from what I saw, though it was scraped by another site, so it's still available. SHAPIRO: Google presents itself as a storehouse of knowledge. And I guess the question that your story raises is, how much is Google deciding what we should and should not know? HILL: (Laughter) I mean Google has a lot of power over access to information. And you know, what was at issue in my story and at issue with the New America Foundation incident is that a lot of people are saying Google is using its dominance in one industry in order to enter another industry. So the story I wrote was about how they were using their search power to push their social network. And part of the problem with New America is that there was this soft pressure on New America Foundation to silence critics of Google's monopoly power. And so what my story and what New America's story have in common was that, you know, it's not always an ultimatum that Google puts forth. But just because it's so powerful, just a little nudge has a lot of weight behind it. SHAPIRO: That's journalist Kashmir Hill, who now writes for Gizmodo. Thanks for your time. HILL: Thanks, Ari. ARI SHAPIRO, HOST:  Big tech companies influence more of our lives than ever before, and there are growing concerns that they are using that power to advance their own corporate interests. European regulators have fined Google for favoring its own services and products in search results, and a Google-funded think tank, New America, appears to have fired some of its scholars after one of them praised this fine. We're going to speak now with a journalist who had her own experience in this vein several years ago. Kashmir Hill is writing about it now because it seems to show the way a tech giant like Google appears to game the system. Welcome. KASHMIR HILL: Hi, Ari. SHAPIRO: Briefly describe what this experience was that you had several years ago. HILL: So this happened six years ago in 2011. I was a reporter at Forbes at the time. I got pulled into a meeting with Google salespeople where they were talking about Google Plus, which was then a new social network. And they told Forbes that they needed to put the plus-one buttons on Forbes' pages, or it would hurt them in search results because plus-one buttons were going to be a signal in search. SHAPIRO: So basically if Forbes did not promote the Google Plus social network, Forbes articles would not appear as prominently in search results. HILL: They wouldn't phrase it that way. They would say if you didn't have the plus-one buttons, you know, on your articles, you would be at a disadvantage in search rankings. SHAPIRO: And so you published this, and what happened? HILL: Well, first I went to Google's public relations team, and they confirmed that it was going to be a signal in search. And then I published an article about it. And Google flipped out after the article was published and went to Forbes and said that meeting was a business meeting; it was covered by a non-disclosure agreement, and you need to take this article down right away. SHAPIRO: This sounds sort of like a source arguing that something was off the record when it was your understanding that it was on the record, which is not unusual. But what seems more unusual is what happened to the article after you did decide to take it down. HILL: Right. So Google said this was a problem for the business relationship between Forbes and Google and talked to many of my higher ups. And you know, they put a lot of pressure on me to unpublish the article. So I did, and it completely disappeared. It even disappeared from search results very soon after it was unpublished, which was unusual at the time from what I've seen with articles that we had unpublished in the past. SHAPIRO: You asked Google whether they had anything to do with this. What did they tell you? HILL: So Google still feels that that article was inappropriate given that it was based on this confidential business meeting. And they said they had nothing to do with the removal from search results. SHAPIRO: Do you believe them? HILL: (Laughter) What's hard about the story is this is something that happened six years ago. But it is - it's something that's always troubled me because of how quickly the article completely disappeared. The thing is - about tech companies is - we don't know. We don't get to see inside their companies, their algorithms. So I don't know what happened. I only know it from what I saw, though it was scraped by another site, so it's still available. SHAPIRO: Google presents itself as a storehouse of knowledge. And I guess the question that your story raises is, how much is Google deciding what we should and should not know? HILL: (Laughter) I mean Google has a lot of power over access to information. And you know, what was at issue in my story and at issue with the New America Foundation incident is that a lot of people are saying Google is using its dominance in one industry in order to enter another industry. So the story I wrote was about how they were using their search power to push their social network. And part of the problem with New America is that there was this soft pressure on New America Foundation to silence critics of Google's monopoly power. And so what my story and what New America's story have in common was that, you know, it's not always an ultimatum that Google puts forth. But just because it's so powerful, just a little nudge has a lot of weight behind it. SHAPIRO: That's journalist Kashmir Hill, who now writes for Gizmodo. Thanks for your time. HILL: Thanks, Ari.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-09-10-549922317": {"title": "Telecom Companies Turn To Drones For Help After Hurricanes : NPR", "url": "https://www.npr.org/2017/09/10/549922317/telecom-companies-turn-to-drones-for-help-after-hurricanes", "author": "No author found", "published_date": "2017-09-10", "content": "", "section": "Technology", "disclaimer": ""}, "2017-09-12-550492818": {"title": "Apple Unveils Highly Anticipated iPhone 10 To Mark Device's Anniversary : NPR", "url": "https://www.npr.org/2017/09/12/550492818/apple-unveils-highly-anticipated-iphone-10-to-mark-devices-anniversary", "author": "No author found", "published_date": "2017-09-12", "content": "ARI SHAPIRO, HOST: Today at Apple headquarters in Cupertino, Calif. , Apple CEO Tim Cook made a dramatic introduction. (SOUNDBITE OF ARCHIVED RECORDING)TIM COOK: This is iPhone 10. It is the biggest leap forward since the original iPhone. SHAPIRO: This phone debuts on the tenth anniversary of the iPhone. Over the past decade, competition in the smartphone market has grown. Samsung is gaining market share. Chinese brands are outdoing Apple in the important Chinese market. Joining us now to put today's announcement in perspective is NPR's Laura Sydell. Hi, Laura. LAURA SYDELL, BYLINE: Hi there. SHAPIRO: One of the most striking things about this new iPhone is the price. A thousand dollars is really expensive. What do people get for that? SYDELL: Right. That is a lot. Well, first off, it has an edge-to-edge OLED screen, and that looks really good. And that means it also will give you a bit more battery power. So you get an extra two more hours out of that. There's no more home button. So there's going to be some changes for people who are used to the iPhone. You touch the screen to wake it up. And there's a way you just kind of swipe up. And you can see your apps and all of that. Also, the new iPhone has wireless charging. And perhaps the most unique part of this is it has this face-scanning technology. And Apple's calling it Face ID. And it means you're going to be able to sign in to your phone just by looking at the phone or use Apple Pay just by looking at the phone. SHAPIRO: I imagine that'll give Apple a lot of biometrics data. Is there a privacy concern here? SYDELL: Well, people are definitely raising that - that there could be privacy concerns here. Apple, during the press conference, said, first off, nobody else will be able to get in here other than you. A photo won't work. Even your evil twin won't work. Then there's the question of giving all this data to Apple. Now, they didn't say. But historically speaking, what Apple has done, for example, with its thumbprint data is it's only on your phone. They don't want your information. They've made this really clear. One of the things that Tim Cook has put himself out there as is that Apple is not like other companies that are selling advertising. They're selling devices. So it will be stored on your phone most likely. And, therefore, nobody else will be able to access it, including Apple. SHAPIRO: Are these features enough to, as Tim Cook described it, set the path for technology for the next decade? SYDELL: Well, there's some other features on it that I have to say I think people are going to really like and are surprisingly important, I think. So, you know, emojis - very popular they now have these things called Animojis. Animojis will let you actually add your own facial expression to the emoji. Seems small, but these kind of social things can be huge. SHAPIRO: Like, superimpose my face on a pair of cherries or something like that. SYDELL: Exactly. You got it (laughter). SHAPIRO: OK. SYDELL: And, secondly, it's also got augmented reality features. So you'll be able to play a game as if it's in the real world. You and somebody else can sit in a room and play that game looking on a table in front of you. Remember last summer, there was a big craze with augmented reality. That was Pokemon Go. SHAPIRO: Right. SYDELL: So Apple is betting we're going to have a big craze with all these new things now. SHAPIRO: Tell us about the competition. The iPhone is up against Samsung's Galaxy Note 8, which has gotten really good reviews. SYDELL: Yes, it does. And it's $950, so also expensive. And it's got the OLED screen and the curved sides - all that stuff. It doesn't have Face ID. But here's what's more important. People don't really want to change ecosystems. If you're in the Apple ecosystem, and you're using their products, you don't want to learn a whole new system. So I think the customers they have are going to want to upgrade. I also would add that there is now an upgraded iPhone 7 called an iPhone 8. It has some of the features of the new iPhone 10. But it doesn't have face recognition. And it starts at $699, which is a bit more affordable in the universe of Apple's very expensive products. And, remember, Apple's a premium brand. They've never said they were going to be the cheapest. What Apple is all about is giving you the premium experience, the aspirational experience, Ari. SHAPIRO: That's NPR's Laura Sydell. Thanks a lot, Laura. SYDELL: You're welcome. [POST-BROADCAST CORRECTION: In this report, it\u2019s said that the Samsung Galaxy Note 8 does not have a facial recognition feature. In fact, it does. ] ARI SHAPIRO, HOST:  Today at Apple headquarters in Cupertino, Calif. , Apple CEO Tim Cook made a dramatic introduction. (SOUNDBITE OF ARCHIVED RECORDING) TIM COOK: This is iPhone 10. It is the biggest leap forward since the original iPhone. SHAPIRO: This phone debuts on the tenth anniversary of the iPhone. Over the past decade, competition in the smartphone market has grown. Samsung is gaining market share. Chinese brands are outdoing Apple in the important Chinese market. Joining us now to put today's announcement in perspective is NPR's Laura Sydell. Hi, Laura. LAURA SYDELL, BYLINE: Hi there. SHAPIRO: One of the most striking things about this new iPhone is the price. A thousand dollars is really expensive. What do people get for that? SYDELL: Right. That is a lot. Well, first off, it has an edge-to-edge OLED screen, and that looks really good. And that means it also will give you a bit more battery power. So you get an extra two more hours out of that. There's no more home button. So there's going to be some changes for people who are used to the iPhone. You touch the screen to wake it up. And there's a way you just kind of swipe up. And you can see your apps and all of that. Also, the new iPhone has wireless charging. And perhaps the most unique part of this is it has this face-scanning technology. And Apple's calling it Face ID. And it means you're going to be able to sign in to your phone just by looking at the phone or use Apple Pay just by looking at the phone. SHAPIRO: I imagine that'll give Apple a lot of biometrics data. Is there a privacy concern here? SYDELL: Well, people are definitely raising that - that there could be privacy concerns here. Apple, during the press conference, said, first off, nobody else will be able to get in here other than you. A photo won't work. Even your evil twin won't work. Then there's the question of giving all this data to Apple. Now, they didn't say. But historically speaking, what Apple has done, for example, with its thumbprint data is it's only on your phone. They don't want your information. They've made this really clear. One of the things that Tim Cook has put himself out there as is that Apple is not like other companies that are selling advertising. They're selling devices. So it will be stored on your phone most likely. And, therefore, nobody else will be able to access it, including Apple. SHAPIRO: Are these features enough to, as Tim Cook described it, set the path for technology for the next decade? SYDELL: Well, there's some other features on it that I have to say I think people are going to really like and are surprisingly important, I think. So, you know, emojis - very popular they now have these things called Animojis. Animojis will let you actually add your own facial expression to the emoji. Seems small, but these kind of social things can be huge. SHAPIRO: Like, superimpose my face on a pair of cherries or something like that. SYDELL: Exactly. You got it (laughter). SHAPIRO: OK. SYDELL: And, secondly, it's also got augmented reality features. So you'll be able to play a game as if it's in the real world. You and somebody else can sit in a room and play that game looking on a table in front of you. Remember last summer, there was a big craze with augmented reality. That was Pokemon Go. SHAPIRO: Right. SYDELL: So Apple is betting we're going to have a big craze with all these new things now. SHAPIRO: Tell us about the competition. The iPhone is up against Samsung's Galaxy Note 8, which has gotten really good reviews. SYDELL: Yes, it does. And it's $950, so also expensive. And it's got the OLED screen and the curved sides - all that stuff. It doesn't have Face ID. But here's what's more important. People don't really want to change ecosystems. If you're in the Apple ecosystem, and you're using their products, you don't want to learn a whole new system. So I think the customers they have are going to want to upgrade. I also would add that there is now an upgraded iPhone 7 called an iPhone 8. It has some of the features of the new iPhone 10. But it doesn't have face recognition. And it starts at $699, which is a bit more affordable in the universe of Apple's very expensive products. And, remember, Apple's a premium brand. They've never said they were going to be the cheapest. What Apple is all about is giving you the premium experience, the aspirational experience, Ari. SHAPIRO: That's NPR's Laura Sydell. Thanks a lot, Laura. SYDELL: You're welcome. [POST-BROADCAST CORRECTION: In this report, it\u2019s said that the Samsung Galaxy Note 8 does not have a facial recognition feature. In fact, it does. ]", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-09-13-550757777": {"title": "YouTube Inadvertently Erases Syrian War Videos In Purge Of Extremist Propaganda : NPR", "url": "https://www.npr.org/2017/09/13/550757777/youtube-inadvertently-erases-syrian-war-videos-in-purge-of-extremist-propaganda", "author": "No author found", "published_date": "2017-09-13", "content": "KELLY MCEVERS, HOST: The war in Syria is one of the first to be documented largely by the people who are experiencing it. Their videos posted online, usually on YouTube, let us see what's happening in Syria when it's too dangerous for journalists and other people to go in. Mohammad Al Abdallah is executive director of the Syria Justice & Accountability Centre. It's a nonprofit supported by the State Department and a handful of European governments. And he has a database of videos from Syria. Ninety-five percent of them come from YouTube. He says some of them could be used one day as evidence during a trial against war criminals. And he says these videos are important for intelligence gathering. MOHAMMAD AL ABDALLAH: For example, the execution of the U. S. journalist James Foley was filmed, recorded and uploaded on YouTube by ISIS. Quickly the U. S. captured the video - the law enforcement. They did analysis of the video. The guy is basically British accent, left-handed. They kept the analysis from the video, shared it with the U. K. , who said, yes, we have a suspect who - in our extremist database - who his family said he left the country to join the war in Syria. And we expect that's the guy. And that was Jihadi John, who was assassinated later by a drone attack carried out by the U. S. MCEVERS: But over the past few months, YouTube has been working to delete violent content, and lots of videos from Syria have been taken down. Sarah El Deeb is a reporter with The Associated Press who's been covering this, and I asked her to explain what's happening. SARAH EL DEEB: There are two things. So traditionally YouTube had a - relied on a community of flaggers - entrusted flaggers - who would object to content online and call it extremist, call it hate speech, whatever. In June, they introduced a machine-learning software that basically detects quote, unquote, \"objectionable material\" and then reports it to the human reviewers - people who actually look at the material and say, OK, no, this rightly should be removed from YouTube. So I think they're introducing a new layer to kind of speed up or operate at a scale. One YouTube spokesperson told me that there's 400 hours a minute uploaded on YouTube. MCEVERS: Wow. Can you just describe some of these videos for people who don't know what we're talking about - the kinds of videos that people post to YouTube? DEEB: Everything. I mean this is how we know what's going on in Syria. People upload videos about funerals, about bombing of cities, about chemical attacks and their aftermath, about rescuers trying to pull people from under the rubble. It's not pretty. This is a violent conflict. So we know how to cover the Syria conflict because of these videos. So every little heartbeat of this conflict has been recorded in a video and uploaded mostly on YouTube. MCEVERS: As someone who used to cover the Syrian conflict, I know how important these videos can be to that coverage. But I also remember how violent and brutal some of them are. And you know, you have to say that YouTube is within its rights to remove violent content like this. Do you think activists and others are expecting too much from YouTube? DEEB: I mean I think this is basically the dilemma that's surrounding this issue. People say the right to know the truth is inalienable, and everyone should have that right. But also, YouTube is under pressure from governments and from its own community to control and rein in the amount of violence that's out there on YouTube. So it's - I don't have the answer for this. MCEVERS: And beyond YouTube, are the activists coming up with other systems to archive this film? DEEB: This is one of the fantastic groups that I found already at work since 2014 trying to find their own server and upload material that they think is essential. But it - just like it is a huge task for YouTube, it is also a huge task for six people. They are a group of six people who are basically trying to first salvage whatever has been lost or temporarily lost because of the YouTube new policy but also downloading everyday new material that's related to Syria on their server. But what they tell me is they are specialized in human rights violations and possible war crimes. But like I was saying earlier, what's on YouTube from Syria is not just that. It's everything. It's social occasions. It's funerals. It's how people survive sieges and what they do to help each other. So ultimately things - if they are deemed objectionable by the machine, they cannot salvage everything. MCEVERS: Sarah El Deeb covers Lebanon and Syria for The Associated Press. Thank you very much. DEEB: Thank you. (SOUNDBITE OF AU REVOIR SIMONE SONG, \"KNIGHT OF WANDS\") KELLY MCEVERS, HOST:  The war in Syria is one of the first to be documented largely by the people who are experiencing it. Their videos posted online, usually on YouTube, let us see what's happening in Syria when it's too dangerous for journalists and other people to go in. Mohammad Al Abdallah is executive director of the Syria Justice & Accountability Centre. It's a nonprofit supported by the State Department and a handful of European governments. And he has a database of videos from Syria. Ninety-five percent of them come from YouTube. He says some of them could be used one day as evidence during a trial against war criminals. And he says these videos are important for intelligence gathering. MOHAMMAD AL ABDALLAH: For example, the execution of the U. S. journalist James Foley was filmed, recorded and uploaded on YouTube by ISIS. Quickly the U. S. captured the video - the law enforcement. They did analysis of the video. The guy is basically British accent, left-handed. They kept the analysis from the video, shared it with the U. K. , who said, yes, we have a suspect who - in our extremist database - who his family said he left the country to join the war in Syria. And we expect that's the guy. And that was Jihadi John, who was assassinated later by a drone attack carried out by the U. S. MCEVERS: But over the past few months, YouTube has been working to delete violent content, and lots of videos from Syria have been taken down. Sarah El Deeb is a reporter with The Associated Press who's been covering this, and I asked her to explain what's happening. SARAH EL DEEB: There are two things. So traditionally YouTube had a - relied on a community of flaggers - entrusted flaggers - who would object to content online and call it extremist, call it hate speech, whatever. In June, they introduced a machine-learning software that basically detects quote, unquote, \"objectionable material\" and then reports it to the human reviewers - people who actually look at the material and say, OK, no, this rightly should be removed from YouTube. So I think they're introducing a new layer to kind of speed up or operate at a scale. One YouTube spokesperson told me that there's 400 hours a minute uploaded on YouTube. MCEVERS: Wow. Can you just describe some of these videos for people who don't know what we're talking about - the kinds of videos that people post to YouTube? DEEB: Everything. I mean this is how we know what's going on in Syria. People upload videos about funerals, about bombing of cities, about chemical attacks and their aftermath, about rescuers trying to pull people from under the rubble. It's not pretty. This is a violent conflict. So we know how to cover the Syria conflict because of these videos. So every little heartbeat of this conflict has been recorded in a video and uploaded mostly on YouTube. MCEVERS: As someone who used to cover the Syrian conflict, I know how important these videos can be to that coverage. But I also remember how violent and brutal some of them are. And you know, you have to say that YouTube is within its rights to remove violent content like this. Do you think activists and others are expecting too much from YouTube? DEEB: I mean I think this is basically the dilemma that's surrounding this issue. People say the right to know the truth is inalienable, and everyone should have that right. But also, YouTube is under pressure from governments and from its own community to control and rein in the amount of violence that's out there on YouTube. So it's - I don't have the answer for this. MCEVERS: And beyond YouTube, are the activists coming up with other systems to archive this film? DEEB: This is one of the fantastic groups that I found already at work since 2014 trying to find their own server and upload material that they think is essential. But it - just like it is a huge task for YouTube, it is also a huge task for six people. They are a group of six people who are basically trying to first salvage whatever has been lost or temporarily lost because of the YouTube new policy but also downloading everyday new material that's related to Syria on their server. But what they tell me is they are specialized in human rights violations and possible war crimes. But like I was saying earlier, what's on YouTube from Syria is not just that. It's everything. It's social occasions. It's funerals. It's how people survive sieges and what they do to help each other. So ultimately things - if they are deemed objectionable by the machine, they cannot salvage everything. MCEVERS: Sarah El Deeb covers Lebanon and Syria for The Associated Press. Thank you very much. DEEB: Thank you. (SOUNDBITE OF AU REVOIR SIMONE SONG, \"KNIGHT OF WANDS\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-09-15-547886482": {"title": "Sam Harris: What Happens When Humans Develop Super Intelligent AI? : NPR", "url": "https://www.npr.org/2017/09/15/547886482/sam-harris-what-happens-when-humans-develop-super-intelligent-ai", "author": "No author found", "published_date": "2017-09-15", "content": "GUY RAZ, HOST: On the show today, Future Consequences, how our decisions about science and technology today will impact our future tomorrow. And in a lot of ways, one aspect of the future has already been imagined for us. (SOUNDBITE OF FILM, \"TERMINATOR 2\")LINDA HAMILTON: (As Sarah Connor) Three-billion human lives ended on August 29th, 1997. RAZ: I mean, this has been part of our culture for decades. (SOUNDBITE OF FILM, \"TERMINATOR 2\")HAMILTON: (As Sarah Connor) The survivors of the nuclear fire called the war Judgment Day. They lived only to face a new nightmare, the war against the machines. RAZ: OK so you might recognize this scene. It's Sarah Connor in \"Terminator 2\" describing how artificial intelligence sparked a nuclear attack and then waged war against the surviving humans, which is something that should terrify all of us, right? SAM HARRIS: Yeah, and what especially worries me about artificial intelligence is that I'm freaked out by my inability to marshal the appropriate emotional response. RAZ: Which should be what? HARRIS: Oh, I think potentially it's - it's the most worrisome future possible because we're talking about the most powerful possible technology. RAZ: This is Sam Harris. HARRIS: I am a writer, and podcaster (ph), and neuroscientist and also armchair philosopher. RAZ: And Sam says our inability to react to this future with urgency poses a big problem. HARRIS: The quote from Stuart Russell, the computer scientist at Berkeley, is, imagine we received a communication from an alien civilization which said, people of Earth, we will arrive on your planet in 50 years. Get ready. Right, now just imagine that. Now, that is the circumstance we are in, fundamentally. We're talking about a seeming inevitability that we will produce superhuman intelligence - intelligence, which, once it becomes superhuman, then it becomes the engine of its own improvements. Then there's really kind of a just a runaway effect where we can't even imagine how much better it could be than we are. RAZ: Sam picks up this idea from the TED stage. (SOUNDBITE OF TED TALK)HARRIS: At a certain point, we will build machines that are smarter than we are. And once we have machines that are smarter than we are, they will begin to improve themselves. And then we risk what the mathematician I. J. Good called an intelligence explosion - that the process could get away from us. Now, this is often caricatured as a fear that armies of malicious robots will attack us, but that isn't the most likely scenario. It's not that our machines will become spontaneously malevolent. The concern is really that we will build machines that are so much more competent than we are that the slightest divergence between their goals and our own could destroy us. Just think about how we relate to ants, OK? We don't hate them. We don't go out of our way to harm them. In fact, sometimes, we take pains not to harm them. We just - we step over them on the sidewalk. But whenever their presence seriously conflicts with one of our goals, we annihilate them without a qualm. The concern is that we will one day build machines that could treat us with similar disregard. It's crucial to realize that the rate of progress doesn't matter. It does - any progress is enough to get us into the end zone. We don't need Moore's law to continue. We don't need exponential progress. We just need to keep going. So we will do this if we can. The train is already out of the station, and there's no break to pull. (SOUNDBITE OF MUSIC)RAZ: You believe that it is inevitable that at some point, we humans will create the technology to more or less replicate humans. HARRIS: Yeah, I think that the moment you recognize that intelligence is platform independent, then you just have to give up this idea that there's any barrier to machines becoming superhuman. And when they do become superhuman in their abilities to design experiments, to engineer new machines, then they will be the best at doing that. RAZ: But we're not there, right? I mean, at this point, there are a lot of things humans do that machines and robots just can't do. HARRIS: Yeah, I think this notion of a goal of human-level intelligence is quite misleading. We're living with what's called narrow AI, which is superhuman in its area of application but is not at all general, and therefore, isn't nearly as good as the human mind is now. It - or - the best chess player in the world is a computer. And now the best go player in the world is a computer. The best facial recognition system is a computer. And yet, none of these systems is good at anything else, really. So I think the goal is to have general intelligence which allows for kind of flexible learning across many different tasks and in many different environments. But once we have something that's truly generalizable and seamless, it won't be human-level. It will become superhuman, and it won't be human-level unless we consciously degrade its capacity to be human-level, and we would never do that. RAZ: Right, right, because that's just not a normal human response, because when most people hear about AI or talk about it, it's with this incredible optimism. I mean, this technology will enable us to do things we can't do. We're going to be able to crunch numbers in ways that we can't right now and solve diseases through data. And machines are going to be able to do tasks and do them much faster. So, I mean, there is a sense of wonder about the future of artificial intelligence. HARRIS: Yeah, I think that's appropriate because intelligence is our most important resource, and we want more of it. Just think about it in terms of, every problem you see in the world has some intelligent solution if a solution is compatible with the laws of physics, right? And so it's just, we want to figure out these solutions, and we want to improve human life. But yeah, we are racing toward something we don't understand. And the scary thing is that many people thinking about the potential upside here don't seem too aware of the ways in which it could go wrong and in fact are - just deny that there's really anything worth thinking about here. (SOUNDBITE OF TED TALK)HARRIS: Imagine we just built a superintelligent AI - right? - that was no smarter than your average team of researchers at Stanford or MIT. Well, electronic circuits function about a million times faster than biochemical ones, OK? So this machine should think about a million times faster than the minds that built it. So you set it running for a week, and it will perform 20,000 years of human-level intellectual work week, after week after week. How could we even understand, much less constrain, a mind making this sort of progress? The other thing that's worrying, frankly, is that, imagine the best-case scenario. So imagine we hit upon a design of superintelligent AI that has no safety concerns. We have the perfect design the first time around. It's as though we'd been handed an oracle that behaves exactly as intended. Well, this machine would be the perfect labor-saving device. It can design the machine that can build the machine that can do any physical work powered by sunlight more or less for the cost of raw materials. OK, so we're talking about the end of human drudgery. We're also talking about the end of most intellectual work. Now, what would the Russians or the Chinese do if they heard that some company in Silicon Valley was about to deploy a super intelligent AI? This machine would be capable of waging war, right, whether terrestrial or cyber, with unprecedented power. This is a winner-take-all scenario. To be six months ahead of the competition here is to be 500,000 years ahead at a minimum. OK, so it seems that even mere rumors of this kind of breakthrough could cause our species to go berserk. (SOUNDBITE OF MUSIC)RAZ: I mean, it seems like one big consequence of not taking this seriously, you know, is that we will essentially be giving up control over our own destiny as a species. HARRIS: Yeah, well, potentially. And so that - obviously there are the people who say, well, we would never do that. We would never give up control, right? RAZ: Right. HARRIS: But there's just no guarantee of that, particularly when you imagine the power that awaits anyone, you know, any government, any research team, any individual ultimately, who creates a system that is superhuman in its abilities and general in its abilities. Well, then no one can really compete with you in anything. It's really hard to picture what the intellectual and and scientific inequality that that suddenly could open up. RAZ: I mean, based on, you know, the pace of this technology, I mean, how much longer will humans be the - sort of the dominant species on planet Earth? HARRIS: Well, you know, I really - I have no idea. I just think that the pace of change suggests that the next 50 years could represent an astonishing epoch of change. Just look at the pace of change in our own lives in the last 20 years. You know, most of us have only been on the Internet for about 20 years. Twenty years ago, you had people saying the Internet is going to be a bust, right? I mean, there's no there there, right? RAZ: (Laughter) Right, right. HARRIS: No one's going to use this thing, right? RAZ: Yes. HARRIS: And look at the world we're in now. And this is a comparatively old kind of breakthrough. I mean, we're not - nothing of the last 20 years has been transformed fundamentally by artificial intelligence, so I think the next 50 years could change everything. (SOUNDBITE OF TED TALK)HARRIS: Now, unfortunately, I don't have a solution to this problem apart from recommending that more of us think about it. I think we need something like a Manhattan Project on the topic of artificial intelligence, not to build it because I think we'll inevitably do that, but to to understand how to avoid an arms race and to build it in a way that is aligned with our interests. When you're talking about a super intelligent AI that can make changes to itself, it seems that we only have one chance to get the initial conditions right. And even then, we will need to absorb the economic and political consequences of getting them right. But the moment we admit that information processing is the source of intelligence, that some appropriate computational system is what the basis of intelligence is and we admit that we will improve these systems continuously, then we have to admit that we're in the process of building some sort of God. Now would be a good time to make sure it's a God we can live with. Thank you very much. (APPLAUSE)RAZ: Writer and neuroscientist and philosopher Sam Harris. He's also the host of the podcast \"Waking Up With Sam Harris. \" You should definitely check that out. And you can watch all of Sam's talks at ted. com. (SOUNDBITE OF SONG, \"YOSHIMI BATTLES THE PINK ROBOTS PT. 1\")FLAMING LIPS: (Singing) Oh, Yoshimi, they don't believe me, but you won't let those robots defeat me. Yoshimi, they don't believe me, but you won't have those robots defeat me. RAZ: Hey, thanks for listening to our episode Future Consequences this week. If you want to find out more about who was on it, go to ted. npr. org. To see hundreds more TED Talks, check out ted. com or the TED app. Our production staff at NPR includes Jeff Rogers, Sanaz Meshkinpour, Jinae West, Neva Grant and Rund Abdelfatah, with help from Daniel Shukin and Tony Liu. Our partners at TED are Chris Anderson, Colin Helms, Anna Phelan and Janet Lee. If you want to let us know what you think about the show, please go to Apple Podcasts and write a review. Please also subscribe to our podcast at Apple Podcasts or however you get your podcasts. You can also write us directly. It's tedradiohour@npr. org. And you can follow us on Twitter. That's @TEDRadioHour. I'm Guy Raz, and you've been listening to ideas worth spreading right here on the TED Radio Hour from NPR. GUY RAZ, HOST:  On the show today, Future Consequences, how our decisions about science and technology today will impact our future tomorrow. And in a lot of ways, one aspect of the future has already been imagined for us. (SOUNDBITE OF FILM, \"TERMINATOR 2\") LINDA HAMILTON: (As Sarah Connor) Three-billion human lives ended on August 29th, 1997. RAZ: I mean, this has been part of our culture for decades. (SOUNDBITE OF FILM, \"TERMINATOR 2\") HAMILTON: (As Sarah Connor) The survivors of the nuclear fire called the war Judgment Day. They lived only to face a new nightmare, the war against the machines. RAZ: OK so you might recognize this scene. It's Sarah Connor in \"Terminator 2\" describing how artificial intelligence sparked a nuclear attack and then waged war against the surviving humans, which is something that should terrify all of us, right? SAM HARRIS: Yeah, and what especially worries me about artificial intelligence is that I'm freaked out by my inability to marshal the appropriate emotional response. RAZ: Which should be what? HARRIS: Oh, I think potentially it's - it's the most worrisome future possible because we're talking about the most powerful possible technology. RAZ: This is Sam Harris. HARRIS: I am a writer, and podcaster (ph), and neuroscientist and also armchair philosopher. RAZ: And Sam says our inability to react to this future with urgency poses a big problem. HARRIS: The quote from Stuart Russell, the computer scientist at Berkeley, is, imagine we received a communication from an alien civilization which said, people of Earth, we will arrive on your planet in 50 years. Get ready. Right, now just imagine that. Now, that is the circumstance we are in, fundamentally. We're talking about a seeming inevitability that we will produce superhuman intelligence - intelligence, which, once it becomes superhuman, then it becomes the engine of its own improvements. Then there's really kind of a just a runaway effect where we can't even imagine how much better it could be than we are. RAZ: Sam picks up this idea from the TED stage. (SOUNDBITE OF TED TALK) HARRIS: At a certain point, we will build machines that are smarter than we are. And once we have machines that are smarter than we are, they will begin to improve themselves. And then we risk what the mathematician I. J. Good called an intelligence explosion - that the process could get away from us. Now, this is often caricatured as a fear that armies of malicious robots will attack us, but that isn't the most likely scenario. It's not that our machines will become spontaneously malevolent. The concern is really that we will build machines that are so much more competent than we are that the slightest divergence between their goals and our own could destroy us. Just think about how we relate to ants, OK? We don't hate them. We don't go out of our way to harm them. In fact, sometimes, we take pains not to harm them. We just - we step over them on the sidewalk. But whenever their presence seriously conflicts with one of our goals, we annihilate them without a qualm. The concern is that we will one day build machines that could treat us with similar disregard. It's crucial to realize that the rate of progress doesn't matter. It does - any progress is enough to get us into the end zone. We don't need Moore's law to continue. We don't need exponential progress. We just need to keep going. So we will do this if we can. The train is already out of the station, and there's no break to pull. (SOUNDBITE OF MUSIC) RAZ: You believe that it is inevitable that at some point, we humans will create the technology to more or less replicate humans. HARRIS: Yeah, I think that the moment you recognize that intelligence is platform independent, then you just have to give up this idea that there's any barrier to machines becoming superhuman. And when they do become superhuman in their abilities to design experiments, to engineer new machines, then they will be the best at doing that. RAZ: But we're not there, right? I mean, at this point, there are a lot of things humans do that machines and robots just can't do. HARRIS: Yeah, I think this notion of a goal of human-level intelligence is quite misleading. We're living with what's called narrow AI, which is superhuman in its area of application but is not at all general, and therefore, isn't nearly as good as the human mind is now. It - or - the best chess player in the world is a computer. And now the best go player in the world is a computer. The best facial recognition system is a computer. And yet, none of these systems is good at anything else, really. So I think the goal is to have general intelligence which allows for kind of flexible learning across many different tasks and in many different environments. But once we have something that's truly generalizable and seamless, it won't be human-level. It will become superhuman, and it won't be human-level unless we consciously degrade its capacity to be human-level, and we would never do that. RAZ: Right, right, because that's just not a normal human response, because when most people hear about AI or talk about it, it's with this incredible optimism. I mean, this technology will enable us to do things we can't do. We're going to be able to crunch numbers in ways that we can't right now and solve diseases through data. And machines are going to be able to do tasks and do them much faster. So, I mean, there is a sense of wonder about the future of artificial intelligence. HARRIS: Yeah, I think that's appropriate because intelligence is our most important resource, and we want more of it. Just think about it in terms of, every problem you see in the world has some intelligent solution if a solution is compatible with the laws of physics, right? And so it's just, we want to figure out these solutions, and we want to improve human life. But yeah, we are racing toward something we don't understand. And the scary thing is that many people thinking about the potential upside here don't seem too aware of the ways in which it could go wrong and in fact are - just deny that there's really anything worth thinking about here. (SOUNDBITE OF TED TALK) HARRIS: Imagine we just built a superintelligent AI - right? - that was no smarter than your average team of researchers at Stanford or MIT. Well, electronic circuits function about a million times faster than biochemical ones, OK? So this machine should think about a million times faster than the minds that built it. So you set it running for a week, and it will perform 20,000 years of human-level intellectual work week, after week after week. How could we even understand, much less constrain, a mind making this sort of progress? The other thing that's worrying, frankly, is that, imagine the best-case scenario. So imagine we hit upon a design of superintelligent AI that has no safety concerns. We have the perfect design the first time around. It's as though we'd been handed an oracle that behaves exactly as intended. Well, this machine would be the perfect labor-saving device. It can design the machine that can build the machine that can do any physical work powered by sunlight more or less for the cost of raw materials. OK, so we're talking about the end of human drudgery. We're also talking about the end of most intellectual work. Now, what would the Russians or the Chinese do if they heard that some company in Silicon Valley was about to deploy a super intelligent AI? This machine would be capable of waging war, right, whether terrestrial or cyber, with unprecedented power. This is a winner-take-all scenario. To be six months ahead of the competition here is to be 500,000 years ahead at a minimum. OK, so it seems that even mere rumors of this kind of breakthrough could cause our species to go berserk. (SOUNDBITE OF MUSIC) RAZ: I mean, it seems like one big consequence of not taking this seriously, you know, is that we will essentially be giving up control over our own destiny as a species. HARRIS: Yeah, well, potentially. And so that - obviously there are the people who say, well, we would never do that. We would never give up control, right? RAZ: Right. HARRIS: But there's just no guarantee of that, particularly when you imagine the power that awaits anyone, you know, any government, any research team, any individual ultimately, who creates a system that is superhuman in its abilities and general in its abilities. Well, then no one can really compete with you in anything. It's really hard to picture what the intellectual and and scientific inequality that that suddenly could open up. RAZ: I mean, based on, you know, the pace of this technology, I mean, how much longer will humans be the - sort of the dominant species on planet Earth? HARRIS: Well, you know, I really - I have no idea. I just think that the pace of change suggests that the next 50 years could represent an astonishing epoch of change. Just look at the pace of change in our own lives in the last 20 years. You know, most of us have only been on the Internet for about 20 years. Twenty years ago, you had people saying the Internet is going to be a bust, right? I mean, there's no there there, right? RAZ: (Laughter) Right, right. HARRIS: No one's going to use this thing, right? RAZ: Yes. HARRIS: And look at the world we're in now. And this is a comparatively old kind of breakthrough. I mean, we're not - nothing of the last 20 years has been transformed fundamentally by artificial intelligence, so I think the next 50 years could change everything. (SOUNDBITE OF TED TALK) HARRIS: Now, unfortunately, I don't have a solution to this problem apart from recommending that more of us think about it. I think we need something like a Manhattan Project on the topic of artificial intelligence, not to build it because I think we'll inevitably do that, but to to understand how to avoid an arms race and to build it in a way that is aligned with our interests. When you're talking about a super intelligent AI that can make changes to itself, it seems that we only have one chance to get the initial conditions right. And even then, we will need to absorb the economic and political consequences of getting them right. But the moment we admit that information processing is the source of intelligence, that some appropriate computational system is what the basis of intelligence is and we admit that we will improve these systems continuously, then we have to admit that we're in the process of building some sort of God. Now would be a good time to make sure it's a God we can live with. Thank you very much. (APPLAUSE) RAZ: Writer and neuroscientist and philosopher Sam Harris. He's also the host of the podcast \"Waking Up With Sam Harris. \" You should definitely check that out. And you can watch all of Sam's talks at ted. com. (SOUNDBITE OF SONG, \"YOSHIMI BATTLES THE PINK ROBOTS PT. 1\") FLAMING LIPS: (Singing) Oh, Yoshimi, they don't believe me, but you won't let those robots defeat me. Yoshimi, they don't believe me, but you won't have those robots defeat me. RAZ: Hey, thanks for listening to our episode Future Consequences this week. If you want to find out more about who was on it, go to ted. npr. org. To see hundreds more TED Talks, check out ted. com or the TED app. Our production staff at NPR includes Jeff Rogers, Sanaz Meshkinpour, Jinae West, Neva Grant and Rund Abdelfatah, with help from Daniel Shukin and Tony Liu. Our partners at TED are Chris Anderson, Colin Helms, Anna Phelan and Janet Lee. If you want to let us know what you think about the show, please go to Apple Podcasts and write a review. Please also subscribe to our podcast at Apple Podcasts or however you get your podcasts. You can also write us directly. It's tedradiohour@npr. org. And you can follow us on Twitter. That's @TEDRadioHour. I'm Guy Raz, and you've been listening to ideas worth spreading right here on the TED Radio Hour from NPR.", "section": "TED Radio Hour", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-09-15-551163392": {"title": "Facebook Enabled Ads Targeting Anti-Semites : NPR", "url": "https://www.npr.org/2017/09/15/551163392/facebook-enabled-ads-targeting-anti-semites", "author": "No author found", "published_date": "2017-09-15", "content": "RACHEL MARTIN, HOST:  Two of the tech companies that rule our world are in the news this morning, Facebook and Google. And we'll get to Google in a moment. But first, Facebook - according to new investigative reporting from ProPublica, Facebook is taking money to connect advertisers with anti-Semites. For more, let's bring in NPR's Aarti Shahani. She joins us via Skype. Hey, Aarti. AARTI SHAHANI, BYLINE: Hi. MARTIN: So lay out exactly what ProPublica did and what they found. SHAHANI: So ProPublica did something really simple and with clever reporting. The official line from Facebook is, hate speech is in violation of our community standards, and we don't tolerate it. The reality is Facebook is creating tools to sell it. ProPublica decided to go into Facebook, not as a regular user but into the advertising section. It's automated online. They didn't call a customer service line. And they selected terms like, we want to target ads to people who express interest in Jew hater and how to burn Jews. MARTIN: Those exact phrases? SHAHANI: Yes. Those exact phrases. MARTIN: Wow. SHAHANI: And Facebook accepted their money, $30, and placed the ad, which in this case wasn't anti-Semitic material. It was just a link to a news article. Then ProPublica called Facebook and said, (laughter) yeah, you guys are letting us target to anti-Semitic subgroups. Those ad terms have since disappeared from the platform. And Facebook says they weren't common or widespread. MARTIN: But still, it seems like a big oversight on their part. SHAHANI: Yeah, absolutely. You know, and think of it this way. Facebook's business is based on letting advertisers do exactly what ProPublica did, which is targeting the most personal, even insidious parts of ourselves. OK? There's an industry term for this. It's called psychographic marketing. In the old days, if you were placing ads, you relied on demographics. But with psychographics, you go deeper. You don't just advertise to, say, men in Baltimore, age 19 to 35, who are black. You can add interests, like cop killer. And if Facebook finds and zaps that term, you pick a proxy - you know, say, a band or a movie that's all about mowing down cops. MARTIN: Wow. That is a problem with a - I imagine, a difficult solution, if any. I mean, how do you fix that? SHAHANI: Yeah. There's not a silver bullet here. You know, Facebook has been focused on growth - on hypergrowth. Every quarter, the CEO, Mark Zuckerberg, gets on a quarterly earnings call and shares these dazzling numbers about how much their mobile advertising business has grown. And, you know, something I think about is, what if Zuckerberg also reported on an error rate or a harm rate, you know, just like in the 20th-century industry, you might see disclosures around carbon emissions. What if Facebook and other data companies had to create and report a kind of harm metric, you know, for hate speech, calls to violence, Russian influence on U. S. elections? You know, that doesn't exist. I'm just thinking out loud here. MARTIN: Yeah. SHAHANI: Facebook, by the way, pays for NPR's video content, some of it. MARTIN: So before we let you go, Google is also facing some hot water over some allegations about hiring or paying. What's going on? SHAHANI: Yeah. On Thursday, plaintiffs filed a class-action lawsuit in California. It's on behalf of all women employed by Google in the state over the last four years. And the claim is Google is breaking the law, labor laws, by paying women less than men for substantially similar work. MARTIN: All right. NPR's Aarti Shahani reporting on two controversies facing a couple of big tech giants, Facebook and Google, this morning. Thanks so much, Aarti. SHAHANI: Thank you. [EDITOR'S NOTE: We heard back from a lot of listeners on this story. Many complained about the example we gave to portray the dangerous search terms used by some Facebook advertisers that use targeted ads. The intent of the example was to illustrate how online advertisers searched extreme subgroups. We didn't mean to either offend anyone or perpetuate a stereotype; the specific example we used was provided by a leading online marketer that uses Facebook tools. We should have made that clearer during the conversation. ](SOUNDBITE OF REKI'S \"MOONBEAM\") RACHEL MARTIN, HOST:   Two of the tech companies that rule our world are in the news this morning, Facebook and Google. And we'll get to Google in a moment. But first, Facebook - according to new investigative reporting from ProPublica, Facebook is taking money to connect advertisers with anti-Semites. For more, let's bring in NPR's Aarti Shahani. She joins us via Skype. Hey, Aarti. AARTI SHAHANI, BYLINE: Hi. MARTIN: So lay out exactly what ProPublica did and what they found. SHAHANI: So ProPublica did something really simple and with clever reporting. The official line from Facebook is, hate speech is in violation of our community standards, and we don't tolerate it. The reality is Facebook is creating tools to sell it. ProPublica decided to go into Facebook, not as a regular user but into the advertising section. It's automated online. They didn't call a customer service line. And they selected terms like, we want to target ads to people who express interest in Jew hater and how to burn Jews. MARTIN: Those exact phrases? SHAHANI: Yes. Those exact phrases. MARTIN: Wow. SHAHANI: And Facebook accepted their money, $30, and placed the ad, which in this case wasn't anti-Semitic material. It was just a link to a news article. Then ProPublica called Facebook and said, (laughter) yeah, you guys are letting us target to anti-Semitic subgroups. Those ad terms have since disappeared from the platform. And Facebook says they weren't common or widespread. MARTIN: But still, it seems like a big oversight on their part. SHAHANI: Yeah, absolutely. You know, and think of it this way. Facebook's business is based on letting advertisers do exactly what ProPublica did, which is targeting the most personal, even insidious parts of ourselves. OK? There's an industry term for this. It's called psychographic marketing. In the old days, if you were placing ads, you relied on demographics. But with psychographics, you go deeper. You don't just advertise to, say, men in Baltimore, age 19 to 35, who are black. You can add interests, like cop killer. And if Facebook finds and zaps that term, you pick a proxy - you know, say, a band or a movie that's all about mowing down cops. MARTIN: Wow. That is a problem with a - I imagine, a difficult solution, if any. I mean, how do you fix that? SHAHANI: Yeah. There's not a silver bullet here. You know, Facebook has been focused on growth - on hypergrowth. Every quarter, the CEO, Mark Zuckerberg, gets on a quarterly earnings call and shares these dazzling numbers about how much their mobile advertising business has grown. And, you know, something I think about is, what if Zuckerberg also reported on an error rate or a harm rate, you know, just like in the 20th-century industry, you might see disclosures around carbon emissions. What if Facebook and other data companies had to create and report a kind of harm metric, you know, for hate speech, calls to violence, Russian influence on U. S. elections? You know, that doesn't exist. I'm just thinking out loud here. MARTIN: Yeah. SHAHANI: Facebook, by the way, pays for NPR's video content, some of it. MARTIN: So before we let you go, Google is also facing some hot water over some allegations about hiring or paying. What's going on? SHAHANI: Yeah. On Thursday, plaintiffs filed a class-action lawsuit in California. It's on behalf of all women employed by Google in the state over the last four years. And the claim is Google is breaking the law, labor laws, by paying women less than men for substantially similar work. MARTIN: All right. NPR's Aarti Shahani reporting on two controversies facing a couple of big tech giants, Facebook and Google, this morning. Thanks so much, Aarti. SHAHANI: Thank you. [EDITOR'S NOTE: We heard back from a lot of listeners on this story. Many complained about the example we gave to portray the dangerous search terms used by some Facebook advertisers that use targeted ads. The intent of the example was to illustrate how online advertisers searched extreme subgroups. We didn't mean to either offend anyone or perpetuate a stereotype; the specific example we used was provided by a leading online marketer that uses Facebook tools. We should have made that clearer during the conversation. ] (SOUNDBITE OF REKI'S \"MOONBEAM\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-09-16-551467158": {"title": "What It Might Take To Stop The Data Breaches : NPR", "url": "https://www.npr.org/2017/09/16/551467158/what-it-might-take-to-stop-the-data-breaches", "author": "No author found", "published_date": "2017-09-16", "content": "SCOTT SIMON, HOST: There seems to be a new big breach of personal data every few weeks. But this latest case in which Equifax, the credit reporting agency, was hacked seems especially massive. The Social Security numbers, dates of birth and other personal information of 143 million Americans was potentially exposed. Zeynep Tufekci argues that the underlying problem isn't a technical failure; it's political. Zeynep's a contributing opinion writer for The New York Times. She joins us now from Chapel Hill, N. C. Thanks so much for being with us. ZEYNEP TUFEKCI: Thank you for inviting me. SIMON: Since this hack was revealed, the Federal Trade Commission has announced an investigation. Equifax's stock price, I guess, has tumbled a bit. And last night, two Equifax executives stepped down. Do you think this means real change is ahead? TUFEKCI: I would like to know the conditions under which they stepped down. Very often, the step down is riding into the sunset with tens of millions of dollars. When Yahoo had many really huge breaches under the tenure of their CEO Marissa Mayer - and she just stepped down this summer with about $200 million in total compensation. So that doesn't sound like a punishment to me. I would like to be punished that way. (LAUGHTER)TUFEKCI: I mean, I'm a former programmer. I'm pretty sympathetic to the idea that software will have bugs. But every time we hear of these breaches, most of the time, including in this Equifax case, it turns out that it was neglect and underinvestment. The problem that caused the breach was a software update that was available that they just did not implement. SIMON: U. S. citizens don't feel that they've been dealt with fairly because of this breach. TUFEKCI: And they have not been. Yeah, they have not been. SIMON: Well - but what can they do about it? People don't even really do business, per se, with Equifax. TUFEKCI: Right - because we are their product. We're not their consumers. We are not the - they are usurping our data. They're taking our data, and they're selling it to others. So they really don't care about us. And the automotive industry is a good example. They were dragged into regulation, and they were dragged into installing seatbelts and paying attention to car safety. And with much pressure, with much regulation, with much effort from consumers, they did. And it was good for the industry, too. It's a better industry, healthier industry right now. So this isn't going to work - I can't withdraw from Equifax. I didn't even have that right to do that. So this isn't going to work without some level of oversight, some level of regulation and some real, genuine accountability. As I said, if a person - if the little guy makes a tiny mistake with a credit card payment, they suffer severe consequences. We need to have proportionate consequences for the company, for the people who oversee it and for the whole industry. And if those are not in place, the next company knows that they can just keep ignoring the security aspect; they can underinvest. Something happens, it's a few days of bad press. I talk to you; you talk to me. They go their merry way to their million-dollar retirement - at worst. And that's the worst that happens to them. I - the incentives are not aligned for them to protect us, and we need to change that. SIMON: Zeynep Tufekci at the University of North Carolina, thanks so much for being with us. TUFEKCI: Thank you for inviting me. SCOTT SIMON, HOST:  There seems to be a new big breach of personal data every few weeks. But this latest case in which Equifax, the credit reporting agency, was hacked seems especially massive. The Social Security numbers, dates of birth and other personal information of 143 million Americans was potentially exposed. Zeynep Tufekci argues that the underlying problem isn't a technical failure; it's political. Zeynep's a contributing opinion writer for The New York Times. She joins us now from Chapel Hill, N. C. Thanks so much for being with us. ZEYNEP TUFEKCI: Thank you for inviting me. SIMON: Since this hack was revealed, the Federal Trade Commission has announced an investigation. Equifax's stock price, I guess, has tumbled a bit. And last night, two Equifax executives stepped down. Do you think this means real change is ahead? TUFEKCI: I would like to know the conditions under which they stepped down. Very often, the step down is riding into the sunset with tens of millions of dollars. When Yahoo had many really huge breaches under the tenure of their CEO Marissa Mayer - and she just stepped down this summer with about $200 million in total compensation. So that doesn't sound like a punishment to me. I would like to be punished that way. (LAUGHTER) TUFEKCI: I mean, I'm a former programmer. I'm pretty sympathetic to the idea that software will have bugs. But every time we hear of these breaches, most of the time, including in this Equifax case, it turns out that it was neglect and underinvestment. The problem that caused the breach was a software update that was available that they just did not implement. SIMON: U. S. citizens don't feel that they've been dealt with fairly because of this breach. TUFEKCI: And they have not been. Yeah, they have not been. SIMON: Well - but what can they do about it? People don't even really do business, per se, with Equifax. TUFEKCI: Right - because we are their product. We're not their consumers. We are not the - they are usurping our data. They're taking our data, and they're selling it to others. So they really don't care about us. And the automotive industry is a good example. They were dragged into regulation, and they were dragged into installing seatbelts and paying attention to car safety. And with much pressure, with much regulation, with much effort from consumers, they did. And it was good for the industry, too. It's a better industry, healthier industry right now. So this isn't going to work - I can't withdraw from Equifax. I didn't even have that right to do that. So this isn't going to work without some level of oversight, some level of regulation and some real, genuine accountability. As I said, if a person - if the little guy makes a tiny mistake with a credit card payment, they suffer severe consequences. We need to have proportionate consequences for the company, for the people who oversee it and for the whole industry. And if those are not in place, the next company knows that they can just keep ignoring the security aspect; they can underinvest. Something happens, it's a few days of bad press. I talk to you; you talk to me. They go their merry way to their million-dollar retirement - at worst. And that's the worst that happens to them. I - the incentives are not aligned for them to protect us, and we need to change that. SIMON: Zeynep Tufekci at the University of North Carolina, thanks so much for being with us. TUFEKCI: Thank you for inviting me.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-09-16-551358693": {"title": "High-Tech 'Bodega' Falls Short Of The Real Thing : NPR", "url": "https://www.npr.org/2017/09/16/551358693/high-tech-bodega-falls-short-of-tthe-real-thing", "author": "No author found", "published_date": "2017-09-16", "content": "SCOTT SIMON, HOST: A couple of high-tech entrepreneurs thought they'd put a personable name on an impersonal product. Paul McDonald and Ashwath Rajan, formerly of Google, unveiled a box this week with glass doors stocked with nonperishable items that people can unlock with their cell phones while a camera records what they take and charges them. It's essentially a tech-connected vending machine. But the entrepreneurs chose a name for their venture that many people found offensive - bodega. The name's taken from small neighborhood shops, usually in New York, stocked with products people run out of or suddenly crave - candy, gum, soda and, yes, cigarettes, newspapers, lottery tickets, condoms, tampons and soap. Many bodegas are in Hispanic neighborhoods run by Hispanic and Asian shopkeepers. They become a stop for people out to walk their dogs or take a stroll from their apartments who decide to linger for a few minutes to buy a magazine or candy bar and talk to other people about how bad the Mets are, how nice the weather is, and kvetch about politicians, landlords and the Number 7 train from Flushing. Bodegas are often the place sixth graders stop after school to buy a Coke or a candy bar. The bodega owners know their name and tells them, run home and do your homework. The bodega owner will often let a good customer just take something they need if they have no money until they get their paycheck. There is no app for that. Real bodegas are small affordable businesses you don't need a stock offering to open. But if the high-tech-minibar faux bodega takes off, it could be at the expense of bodegas owned by real people who keep a cat on the counter and become vital characters in a neighborhood. To me, it's like sacrilegious. You want to take this name and use it to make money off it, Frank Garcia, who chairs the State Coalition of Hispanic Chambers of Commerce, told The New York Post. The instant reaction on social media was so sharp that Paul McDonald and Ashwath Rajan had to quickly write on Medium, we did some homework - speaking to New Yorkers, branding people, and even running some survey work asking about the name and any potential offense it might cause. But it's clear that we may not have been asking the right questions of the right people. Despite our best intentions and our admiration for traditional bodegas, we clearly hit a nerve, said the entrepreneurs. We intended only admiration. But their statement leaves a question unanswered - will the name stay? (SOUNDBITE OF PRETTY LIGHTS' \"YELLOW BIRD\") SCOTT SIMON, HOST:  A couple of high-tech entrepreneurs thought they'd put a personable name on an impersonal product. Paul McDonald and Ashwath Rajan, formerly of Google, unveiled a box this week with glass doors stocked with nonperishable items that people can unlock with their cell phones while a camera records what they take and charges them. It's essentially a tech-connected vending machine. But the entrepreneurs chose a name for their venture that many people found offensive - bodega. The name's taken from small neighborhood shops, usually in New York, stocked with products people run out of or suddenly crave - candy, gum, soda and, yes, cigarettes, newspapers, lottery tickets, condoms, tampons and soap. Many bodegas are in Hispanic neighborhoods run by Hispanic and Asian shopkeepers. They become a stop for people out to walk their dogs or take a stroll from their apartments who decide to linger for a few minutes to buy a magazine or candy bar and talk to other people about how bad the Mets are, how nice the weather is, and kvetch about politicians, landlords and the Number 7 train from Flushing. Bodegas are often the place sixth graders stop after school to buy a Coke or a candy bar. The bodega owners know their name and tells them, run home and do your homework. The bodega owner will often let a good customer just take something they need if they have no money until they get their paycheck. There is no app for that. Real bodegas are small affordable businesses you don't need a stock offering to open. But if the high-tech-minibar faux bodega takes off, it could be at the expense of bodegas owned by real people who keep a cat on the counter and become vital characters in a neighborhood. To me, it's like sacrilegious. You want to take this name and use it to make money off it, Frank Garcia, who chairs the State Coalition of Hispanic Chambers of Commerce, told The New York Post. The instant reaction on social media was so sharp that Paul McDonald and Ashwath Rajan had to quickly write on Medium, we did some homework - speaking to New Yorkers, branding people, and even running some survey work asking about the name and any potential offense it might cause. But it's clear that we may not have been asking the right questions of the right people. Despite our best intentions and our admiration for traditional bodegas, we clearly hit a nerve, said the entrepreneurs. We intended only admiration. But their statement leaves a question unanswered - will the name stay? (SOUNDBITE OF PRETTY LIGHTS' \"YELLOW BIRD\")", "section": "Simon Says", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-09-17-551670875": {"title": "Apple Gets Mixed Reactions To New iPhone's Facial Recognition Technology : NPR", "url": "https://www.npr.org/2017/09/17/551670875/apple-gets-mixed-reactions-to-new-iphones-facial-recognition-technology", "author": "No author found", "published_date": "2017-09-17", "content": "MICHEL MARTIN, HOST: When Apple announced the new iPhone can use facial recognition technology to unlock the device, the response may not have been what Apple had hoped for. The feature immediately raised privacy and security concerns. To hear more about that, we're joined now by Clare Garvie. She's an associate at the Center on Privacy and Technology at Georgetown Law Center and co-author of \"The Perpetual Line Up: Unregulated Police Face Recognition In America. \" She's with us now in our studios in Washington, D. C. Clare Garvie, thanks so much for joining us. CLARE GARVIE: Thank you for having me on. MARTIN: So lay out the privacy and security concerns for us. It sounds - I mean, the technology, first, if you think about it, sounds really cool. So what's the concern? GARVIE: That's right. The technology is both convenient and it's really cool. And, frankly, I don't see too many privacy and security concerns with the way Apple has chosen to deploy face recognition. What I'm far more concerned about is as face recognition becomes normalized, as it becomes something that we use on an hour to hour basis to send an animated emoji, to check the weather, to send a text, what's going to happen is we get very comfortable with it. And we forget that it's used by any number of actors in ways we may not know about that is both less accurate and more privacy concerning than the way that Apple has chosen to use it. MARTIN: Well, give us the worst-case scenario. Give us some scenarios that would cause concern. GARVIE: So right now happening in Russia, face recognition has been used to scan anti-government or anti-corruption protests, identify and then publicly name the people at those anti-government protests. What this means is these people will be subject to intimidation, if not arrest, for their political beliefs. Now, before someone says, well, wait, that's Russia. Why should we in the U. S. care about that? The fact remains in the U. S. , it's very much a rules-free zone when it comes to face recognition. Law enforcement across the country use this technology in various ways without any laws governing its use. Evidence suggests that it was used on protesters after the death of Freddie Gray in police custody. It looks like face recognition was used on social media posts that protesters were posting from demonstration sites. So the law enforcement agents on the ground could, in almost real time, get the identities, the names of the people at those protests. We're a country where we do not necessarily need to show our papers every time we walk down the street. If law enforcement demands our identity, we don't necessarily need to give it. And yet, our faces - now, something we have to present in public - have now done that work for us. MARTIN: Sounds to me that your concern isn't so much this particular technology but that - what? - that it opens the door to a broader use? Is that really Apple's fault or responsibility? GARVIE: I don't believe it's Apple's fault. And I think Apple has thought very, very carefully about a number of the security concerns. They have chosen to store the face template, if you will, locally on the phone, which means that it's a lot more secure against being hacked and being stolen. The real concern is that, as face recognition becomes normalized, we may stop worrying about the very real concerns that we should be worrying about as we increasingly are subjected to face recognition that we can't opt out of. MARTIN: That's Clare Garvie. She is an associate at the Center on Privacy and Technology at Georgetown University's Law Center. She was kind enough to join us at our studios in Washington, D. C. Clare Garvie, thanks so much for speaking with us. GARVIE: Thanks for having me on. MICHEL MARTIN, HOST:  When Apple announced the new iPhone can use facial recognition technology to unlock the device, the response may not have been what Apple had hoped for. The feature immediately raised privacy and security concerns. To hear more about that, we're joined now by Clare Garvie. She's an associate at the Center on Privacy and Technology at Georgetown Law Center and co-author of \"The Perpetual Line Up: Unregulated Police Face Recognition In America. \" She's with us now in our studios in Washington, D. C. Clare Garvie, thanks so much for joining us. CLARE GARVIE: Thank you for having me on. MARTIN: So lay out the privacy and security concerns for us. It sounds - I mean, the technology, first, if you think about it, sounds really cool. So what's the concern? GARVIE: That's right. The technology is both convenient and it's really cool. And, frankly, I don't see too many privacy and security concerns with the way Apple has chosen to deploy face recognition. What I'm far more concerned about is as face recognition becomes normalized, as it becomes something that we use on an hour to hour basis to send an animated emoji, to check the weather, to send a text, what's going to happen is we get very comfortable with it. And we forget that it's used by any number of actors in ways we may not know about that is both less accurate and more privacy concerning than the way that Apple has chosen to use it. MARTIN: Well, give us the worst-case scenario. Give us some scenarios that would cause concern. GARVIE: So right now happening in Russia, face recognition has been used to scan anti-government or anti-corruption protests, identify and then publicly name the people at those anti-government protests. What this means is these people will be subject to intimidation, if not arrest, for their political beliefs. Now, before someone says, well, wait, that's Russia. Why should we in the U. S. care about that? The fact remains in the U. S. , it's very much a rules-free zone when it comes to face recognition. Law enforcement across the country use this technology in various ways without any laws governing its use. Evidence suggests that it was used on protesters after the death of Freddie Gray in police custody. It looks like face recognition was used on social media posts that protesters were posting from demonstration sites. So the law enforcement agents on the ground could, in almost real time, get the identities, the names of the people at those protests. We're a country where we do not necessarily need to show our papers every time we walk down the street. If law enforcement demands our identity, we don't necessarily need to give it. And yet, our faces - now, something we have to present in public - have now done that work for us. MARTIN: Sounds to me that your concern isn't so much this particular technology but that - what? - that it opens the door to a broader use? Is that really Apple's fault or responsibility? GARVIE: I don't believe it's Apple's fault. And I think Apple has thought very, very carefully about a number of the security concerns. They have chosen to store the face template, if you will, locally on the phone, which means that it's a lot more secure against being hacked and being stolen. The real concern is that, as face recognition becomes normalized, we may stop worrying about the very real concerns that we should be worrying about as we increasingly are subjected to face recognition that we can't opt out of. MARTIN: That's Clare Garvie. She is an associate at the Center on Privacy and Technology at Georgetown University's Law Center. She was kind enough to join us at our studios in Washington, D. C. Clare Garvie, thanks so much for speaking with us. GARVIE: Thanks for having me on.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-09-17-551604487": {"title": "What To Do When Your Personal Information Gets Hacked : NPR", "url": "https://www.npr.org/2017/09/17/551604487/what-to-do-when-your-personal-information-gets-hacked", "author": "No author found", "published_date": "2017-09-17", "content": "LULU GARCIA-NAVARRO, HOST: Here's a sobering thought. There's a good chance that you are one of the 143 million U. S. consumers whose personal information was exposed after the hack of Equifax. That's one of the major credit reporting agencies. Your name, Social Security number, birth date, address - all potentially out there, leaving you open to identity theft. So are you one of them? How could that impact you, and how do you protect yourself? Here to help guide us is Lisa Gerstner. She's a contributing editor at Kiplinger's Personal Finance. And she joins me now. Welcome to the program. LISA GERSTNER: Thank you for having me. GARCIA-NAVARRO: All right. So walk us through this. How do you find out if you've been impacted by this hack? GERSTNER: Well, you can go to the site that Equifax has set up to get an idea of whether you may have been impacted. Honestly, at this point, I think it's probably safe for most of us to assume that our information is out there somewhere, whether it was this breach, whether it was some other breach. It's just been so rampant in the past few years that that's the premise I think people should be working from right now. GARCIA-NAVARRO: All right. I'm going to check if it's happened to me. GERSTNER: OK. I think it's Equifax security 2017, if I'm remembering that URL properly. GARCIA-NAVARRO: OK, hold on. Equifax security 2017. Let's see what that pops up. GERSTNER: There's a button that says potential impact. And that's where you check your name. GARCIA-NAVARRO: It's asking for my last name, which I'm putting in. It's asking for the last six digits of my Social Security, which I'm not going to say on air. And then let's see what it says. OK. Based on the information provided, we believe that your personal information may have been impacted by this incident. So bad news for me. It's telling me to enroll in TrustedID Premier. What is that? GERSTNER: Yes. So when you enroll in TrustedID Premier, It gives you different services to help protect against or detect identity theft. So one of them is three-bureau credit monitoring. They'll monitor your credit report from each of the three major credit agencies for any changes like a new address, new accounts. It'll help you identify if someone has tried to open accounts in your name. So it's just this package of services they're offering for free. But it's only for a year. So you have to keep that in mind - that after a year, you're still going to need to protect yourself beyond what the service offers. GARCIA-NAVARRO: But what if I don't want to use Equifax? Because, frankly, they were the ones that were breached. So, you know, are there other options? GERSTNER: There are other options if you're wary of using Equifax. There are other credit-monitoring services, for example. Credit Karma is one. It's free. And they just announced they're adding more to their service. So along with monitoring your TransUnion credit report for you, they're going to start monitoring your Equifax report for free. So that covers two out of the three agencies. Now, ideally, you want to cover all three. There are paid services from companies like LifeLock and Identity Guard that offer three bureau monitoring. And the best thing you can do in terms of checking your credit reports, as well, is going to annualcreditreport. com. Every 12 months, you're entitled to a free credit report from each of those three major agencies. And you can look through them and look for any problems. GARCIA-NAVARRO: You've written that the strongest measure you can take is to put a freeze on your credit files. How does that work? GERSTNER: Right. So when you put a freeze on your credit files, it blocks new creditors from seeing your credit report. And that's if someone is trying to get credit in your name. They're not going to be able to. So it at least guards you from new account fraud. Now, you still have to be on guard for fraud on your existing accounts. You need to check your credit card statements - all of these different things outside of new account fraud. But it is one area that you can really do some strong prevention on. GARCIA-NAVARRO: Well, I'm going to now spend the rest of my afternoon doing everything that you just advised. Lisa Gerstner is a contributing editor at Kiplinger's Personal Finance. Thank you so much. GERSTNER: Thank you. LULU GARCIA-NAVARRO, HOST:  Here's a sobering thought. There's a good chance that you are one of the 143 million U. S. consumers whose personal information was exposed after the hack of Equifax. That's one of the major credit reporting agencies. Your name, Social Security number, birth date, address - all potentially out there, leaving you open to identity theft. So are you one of them? How could that impact you, and how do you protect yourself? Here to help guide us is Lisa Gerstner. She's a contributing editor at Kiplinger's Personal Finance. And she joins me now. Welcome to the program. LISA GERSTNER: Thank you for having me. GARCIA-NAVARRO: All right. So walk us through this. How do you find out if you've been impacted by this hack? GERSTNER: Well, you can go to the site that Equifax has set up to get an idea of whether you may have been impacted. Honestly, at this point, I think it's probably safe for most of us to assume that our information is out there somewhere, whether it was this breach, whether it was some other breach. It's just been so rampant in the past few years that that's the premise I think people should be working from right now. GARCIA-NAVARRO: All right. I'm going to check if it's happened to me. GERSTNER: OK. I think it's Equifax security 2017, if I'm remembering that URL properly. GARCIA-NAVARRO: OK, hold on. Equifax security 2017. Let's see what that pops up. GERSTNER: There's a button that says potential impact. And that's where you check your name. GARCIA-NAVARRO: It's asking for my last name, which I'm putting in. It's asking for the last six digits of my Social Security, which I'm not going to say on air. And then let's see what it says. OK. Based on the information provided, we believe that your personal information may have been impacted by this incident. So bad news for me. It's telling me to enroll in TrustedID Premier. What is that? GERSTNER: Yes. So when you enroll in TrustedID Premier, It gives you different services to help protect against or detect identity theft. So one of them is three-bureau credit monitoring. They'll monitor your credit report from each of the three major credit agencies for any changes like a new address, new accounts. It'll help you identify if someone has tried to open accounts in your name. So it's just this package of services they're offering for free. But it's only for a year. So you have to keep that in mind - that after a year, you're still going to need to protect yourself beyond what the service offers. GARCIA-NAVARRO: But what if I don't want to use Equifax? Because, frankly, they were the ones that were breached. So, you know, are there other options? GERSTNER: There are other options if you're wary of using Equifax. There are other credit-monitoring services, for example. Credit Karma is one. It's free. And they just announced they're adding more to their service. So along with monitoring your TransUnion credit report for you, they're going to start monitoring your Equifax report for free. So that covers two out of the three agencies. Now, ideally, you want to cover all three. There are paid services from companies like LifeLock and Identity Guard that offer three bureau monitoring. And the best thing you can do in terms of checking your credit reports, as well, is going to annualcreditreport. com. Every 12 months, you're entitled to a free credit report from each of those three major agencies. And you can look through them and look for any problems. GARCIA-NAVARRO: You've written that the strongest measure you can take is to put a freeze on your credit files. How does that work? GERSTNER: Right. So when you put a freeze on your credit files, it blocks new creditors from seeing your credit report. And that's if someone is trying to get credit in your name. They're not going to be able to. So it at least guards you from new account fraud. Now, you still have to be on guard for fraud on your existing accounts. You need to check your credit card statements - all of these different things outside of new account fraud. But it is one area that you can really do some strong prevention on. GARCIA-NAVARRO: Well, I'm going to now spend the rest of my afternoon doing everything that you just advised. Lisa Gerstner is a contributing editor at Kiplinger's Personal Finance. Thank you so much. GERSTNER: Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-09-18-551043687": {"title": "Looking For Analog: Old Button-Mashing Arcades Come Back For A New Generation : NPR", "url": "https://www.npr.org/2017/09/18/551043687/looking-for-analog-old-button-mashing-arcades-come-back-for-a-new-generation", "author": "No author found", "published_date": "2017-09-18", "content": "AILSA CHANG, HOST: People used to have to go to arcades to play video games, and then video games went to the family TV. But retro is cool, and people are seeing that it's fun to leave the house after all. The number of arcades in the U. S. has been growing over the past five years, and that's creating demand for new games that have that old-school feel. Patrick Smith of member station WBEZ reports. (SOUNDBITE OF ARCADE AMBIENCE)PATRICK SMITH, BYLINE: I'm at one of the largest video game arcades in the world in suburban Chicago. Galloping Ghost opened here in Brookfield seven years ago. It's an unassuming, single-story brick building that seems to go on forever as you walk through it, each corner bursting with beeping, blinking and flashing arcade cabinets. Owner Doc Mack says they have more than 600 games. DOC MACK: The outset wasn't to become, like, the largest arcade in the world by any means. I have a huge collecting problem that I've had since childhood, so it was something I should have seen coming, but who knew? SMITH: Max says on the weekends, they get hundreds of customers arriving from all over the country. MACK: The reason why people come to an arcade - there's a different social element to it than just playing it at home. On one sunny Saturday, the place starts filling up as soon as the doors open at 11. Erica Deitzel traveled from Milwaukee with her young sons for a birthday party. ERICA DEITZEL: I remember playing \"Pac Man,\" \"Space Invaders\" when they very first came out. I was young, and me and my sister would play for hours. We'd bring rolls of quarters. SMITH: And Rebecca Lastovich is here to help her boyfriend celebrate his 18th birthday. REBECCA LASTOVICH: I know I didn't grow up with arcades, but it's very nostalgic, and I mean I enjoy talking with my dad about it. It's just something that we kind of bonded over. BOB COONEY: You definitely see Gen-Xers go for the nostalgia portion, but that's not the driver of the business. The driver of the business is the market that's going back to vinyl and looking for more analog experiences. SMITH: That's Bob Cooney, a consultant for what's called the location-based entertainment industry. Like Mac, he says the resurgence of arcades is driven mostly by young people who grew up playing video games but are now trying to get out of the solitary activity and connect with others. COONEY: And so you're starting to see a resurgence of pinball in pinball arcades, classic arcade games. SMITH: That resurgence is creating a demand that can't be met by old or refurbished games like \"Pac Man,\" \"Street fighter\" and \"Sea Wolf\" alone. Mac says people want new games that both give a retro feel and support the social atmosphere of arcades. That's why he's been working for years on his own fighting game called \"Dark Presence. \"(SOUNDBITE OF ARCHIVED RECORDING)MACK: Hey, everybody. This is Doc Mack from the Galloping Ghost Arcade. SMITH: Mac unveiled a demo earlier this year at the Midwest Gaming Classic in suburban Milwaukee. \"Dark Presence\" is a 2-D, two-person fighter game like \"Mortal Kombat\" with new-age flourishes. Twenty-nine-year-old Peyton Robbins was one of the first in line to play. PEYTON ROBBINS: It's really impressive considering that there's pretty much nothing like this ever being produced anymore. It's like a relic from the past, but it still looks pretty incredible. SMITH: Robbins was one of thousands of people who flocked to the Midwest Gaming Classic this year looking to check out games, compete in tournaments and just connect with their fellow arcade enthusiasts. Like other young people across the country, they're looking to arcades as a way to combine their love of gaming with socialization. For NPR News, I'm Patrick Smith in Chicago. AILSA CHANG, HOST:  People used to have to go to arcades to play video games, and then video games went to the family TV. But retro is cool, and people are seeing that it's fun to leave the house after all. The number of arcades in the U. S. has been growing over the past five years, and that's creating demand for new games that have that old-school feel. Patrick Smith of member station WBEZ reports. (SOUNDBITE OF ARCADE AMBIENCE) PATRICK SMITH, BYLINE: I'm at one of the largest video game arcades in the world in suburban Chicago. Galloping Ghost opened here in Brookfield seven years ago. It's an unassuming, single-story brick building that seems to go on forever as you walk through it, each corner bursting with beeping, blinking and flashing arcade cabinets. Owner Doc Mack says they have more than 600 games. DOC MACK: The outset wasn't to become, like, the largest arcade in the world by any means. I have a huge collecting problem that I've had since childhood, so it was something I should have seen coming, but who knew? SMITH: Max says on the weekends, they get hundreds of customers arriving from all over the country. MACK: The reason why people come to an arcade - there's a different social element to it than just playing it at home. On one sunny Saturday, the place starts filling up as soon as the doors open at 11. Erica Deitzel traveled from Milwaukee with her young sons for a birthday party. ERICA DEITZEL: I remember playing \"Pac Man,\" \"Space Invaders\" when they very first came out. I was young, and me and my sister would play for hours. We'd bring rolls of quarters. SMITH: And Rebecca Lastovich is here to help her boyfriend celebrate his 18th birthday. REBECCA LASTOVICH: I know I didn't grow up with arcades, but it's very nostalgic, and I mean I enjoy talking with my dad about it. It's just something that we kind of bonded over. BOB COONEY: You definitely see Gen-Xers go for the nostalgia portion, but that's not the driver of the business. The driver of the business is the market that's going back to vinyl and looking for more analog experiences. SMITH: That's Bob Cooney, a consultant for what's called the location-based entertainment industry. Like Mac, he says the resurgence of arcades is driven mostly by young people who grew up playing video games but are now trying to get out of the solitary activity and connect with others. COONEY: And so you're starting to see a resurgence of pinball in pinball arcades, classic arcade games. SMITH: That resurgence is creating a demand that can't be met by old or refurbished games like \"Pac Man,\" \"Street fighter\" and \"Sea Wolf\" alone. Mac says people want new games that both give a retro feel and support the social atmosphere of arcades. That's why he's been working for years on his own fighting game called \"Dark Presence. \" (SOUNDBITE OF ARCHIVED RECORDING) MACK: Hey, everybody. This is Doc Mack from the Galloping Ghost Arcade. SMITH: Mac unveiled a demo earlier this year at the Midwest Gaming Classic in suburban Milwaukee. \"Dark Presence\" is a 2-D, two-person fighter game like \"Mortal Kombat\" with new-age flourishes. Twenty-nine-year-old Peyton Robbins was one of the first in line to play. PEYTON ROBBINS: It's really impressive considering that there's pretty much nothing like this ever being produced anymore. It's like a relic from the past, but it still looks pretty incredible. SMITH: Robbins was one of thousands of people who flocked to the Midwest Gaming Classic this year looking to check out games, compete in tournaments and just connect with their fellow arcade enthusiasts. Like other young people across the country, they're looking to arcades as a way to combine their love of gaming with socialization. For NPR News, I'm Patrick Smith in Chicago.", "section": "Games & Humor", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-09-20-552269857": {"title": "Quantity Of 'Skills' Doesn't Mean Quality In Amazon Echo's Alexa : NPR", "url": "https://www.npr.org/2017/09/20/552269857/quantity-of-skills-doesnt-mean-quality-in-amazon-echos-alexa", "author": "No author found", "published_date": "2017-09-20", "content": "MARY LOUISE KELLY, HOST: If you have an Amazon Echo then you know Alexa. She's the voice-enabled assistant who can do all sorts of stuff - tell you the weather, call you an Uber. From KERA in Dallas, Lauren Silverman explains how Alexa learned so many skills and also why quantity does not always mean quality. And we should note Amazon does sponsor some programming on NPR. LAUREN SILVERMAN: Hey, Alexa. Open cat facts. COMPUTERIZED VOICE: Here's your cat fact. Tigers are excellent swimmers and do not avoid water. SILVERMAN: Alexa knows a lot, and not just about cats. At the start of the year, she knew how to do 7,000 things. Now she has more than 15,000 so-called skills. That's way more than the 60 you can activate with Microsoft's Cortana-powered speaker or the hundreds of third-party apps you can trigger by saying hey, Google, to a Google Home speaker. Part of the reason for Amazon's skill explosion? Independent coders, like the group gathered here at a downtown Dallas bootcamp at Coding Dojo. PRAGATI SRIVASTAVA: Alexa, can you play some Bollywood music? COMPUTERIZED VOICE: Playing Bollywood music. SILVERMAN: Pragati Srivastava is a software-engineering student at the University of Texas at Dallas. She's developed an app for Microsoft's virtual assistant and now wants to set one up for the Amazon Echo at her house. SRIVASTAVA: Probably a music app. SILVERMAN: Amazon has made it really easy to develop a skill in a few hours, and most get certified. Adam Marchick, CEO of the research company VoiceLabs, says that's part of the problem. ADAM MARCHICK: If you look at the 15,000 apps, how many apps are really high-quality? A small fraction. SILVERMAN: There are lots of apps or skills reviewers like to make fun of. Among them, Egg Facts, Fart Sounds Generator, and Remember Your Keys. That last one reminds you to grab your keys, but only if you ask Alexa to open Remember Your Keys. COMPUTERIZED VOICE: Go find your keys. You can't leave without them. SILVERMAN: It's the first skill developed by Seattle-based creator Wing Mui. Mui didn't really expect anyone to download it. According to VoiceLabs' research, even when people download a skill, there's only a 3 percent chance they'll open it again after the first week. Natalie Hereth, PR manager for Amazon Alexa, says no idea is too silly. NATALIE HERETH: It's early days. We like the fact that developers are experimenting with skills. SILVERMAN: For these skills to gain traction, Marchick says Amazon will need to attract more experienced developers. The company has announced plans to start paying some top-performing developers, but right now it mostly offers perks like free devices, T-shirts and socks. MARCHICK: Is that a sustainable strategy? No. If I spend 50 hours to make a quality app, do I either get vanity, millions of users or money? And right now very few apps are getting those things. SILVERMAN: Dallas developer Darian Johnson hopes he will see a check for the most popular skill he's created called Chess Master. DARIAN JOHNSON: You can ask Alexa to recommend a move. That's the most complicated one I've built. SILVERMAN: In a way, you're essentially working for Amazon for free. JOHNSON: Yeah (laughter). There are - there are days I feel like it, but I - I think I get something out of it, too. So I'm learning a lot of new skills. SILVERMAN: For now the thrill of coding is enough. But Johnson admits he still gets frustrated when Alexa doesn't understand his commands. Back at the Coding Dojo bootcamp, Pragati Srivastava tries to remain patient. SRIVASTAVA: Alexa? COMPUTERIZED VOICE: Please try again. SRIVASTAVA: Alexa? Alexa? SILVERMAN: One day, voice assistants will play the right Bollywood song, maybe even heat-up our cars before we leave the house. But for the most part, even market leader Alexa is still best at simple tasks like reciting cat facts. Lauren Silverman, NPR News. MARY LOUISE KELLY, HOST:  If you have an Amazon Echo then you know Alexa. She's the voice-enabled assistant who can do all sorts of stuff - tell you the weather, call you an Uber. From KERA in Dallas, Lauren Silverman explains how Alexa learned so many skills and also why quantity does not always mean quality. And we should note Amazon does sponsor some programming on NPR. LAUREN SILVERMAN: Hey, Alexa. Open cat facts. COMPUTERIZED VOICE: Here's your cat fact. Tigers are excellent swimmers and do not avoid water. SILVERMAN: Alexa knows a lot, and not just about cats. At the start of the year, she knew how to do 7,000 things. Now she has more than 15,000 so-called skills. That's way more than the 60 you can activate with Microsoft's Cortana-powered speaker or the hundreds of third-party apps you can trigger by saying hey, Google, to a Google Home speaker. Part of the reason for Amazon's skill explosion? Independent coders, like the group gathered here at a downtown Dallas bootcamp at Coding Dojo. PRAGATI SRIVASTAVA: Alexa, can you play some Bollywood music? COMPUTERIZED VOICE: Playing Bollywood music. SILVERMAN: Pragati Srivastava is a software-engineering student at the University of Texas at Dallas. She's developed an app for Microsoft's virtual assistant and now wants to set one up for the Amazon Echo at her house. SRIVASTAVA: Probably a music app. SILVERMAN: Amazon has made it really easy to develop a skill in a few hours, and most get certified. Adam Marchick, CEO of the research company VoiceLabs, says that's part of the problem. ADAM MARCHICK: If you look at the 15,000 apps, how many apps are really high-quality? A small fraction. SILVERMAN: There are lots of apps or skills reviewers like to make fun of. Among them, Egg Facts, Fart Sounds Generator, and Remember Your Keys. That last one reminds you to grab your keys, but only if you ask Alexa to open Remember Your Keys. COMPUTERIZED VOICE: Go find your keys. You can't leave without them. SILVERMAN: It's the first skill developed by Seattle-based creator Wing Mui. Mui didn't really expect anyone to download it. According to VoiceLabs' research, even when people download a skill, there's only a 3 percent chance they'll open it again after the first week. Natalie Hereth, PR manager for Amazon Alexa, says no idea is too silly. NATALIE HERETH: It's early days. We like the fact that developers are experimenting with skills. SILVERMAN: For these skills to gain traction, Marchick says Amazon will need to attract more experienced developers. The company has announced plans to start paying some top-performing developers, but right now it mostly offers perks like free devices, T-shirts and socks. MARCHICK: Is that a sustainable strategy? No. If I spend 50 hours to make a quality app, do I either get vanity, millions of users or money? And right now very few apps are getting those things. SILVERMAN: Dallas developer Darian Johnson hopes he will see a check for the most popular skill he's created called Chess Master. DARIAN JOHNSON: You can ask Alexa to recommend a move. That's the most complicated one I've built. SILVERMAN: In a way, you're essentially working for Amazon for free. JOHNSON: Yeah (laughter). There are - there are days I feel like it, but I - I think I get something out of it, too. So I'm learning a lot of new skills. SILVERMAN: For now the thrill of coding is enough. But Johnson admits he still gets frustrated when Alexa doesn't understand his commands. Back at the Coding Dojo bootcamp, Pragati Srivastava tries to remain patient. SRIVASTAVA: Alexa? COMPUTERIZED VOICE: Please try again. SRIVASTAVA: Alexa? Alexa? SILVERMAN: One day, voice assistants will play the right Bollywood song, maybe even heat-up our cars before we leave the house. But for the most part, even market leader Alexa is still best at simple tasks like reciting cat facts. Lauren Silverman, NPR News.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-09-22-552986970": {"title": "London Officials Say Uber Is Unfit To Operate In City : NPR", "url": "https://www.npr.org/2017/09/22/552986970/london-officials-say-uber-is-unfit-to-operate-in-city", "author": "No author found", "published_date": "2017-09-22", "content": "AILSA CHANG, HOST: Uber may not be able to operate in London for much longer. The top transportation authority there says it will not renew Uber's license. The ride-hailing service is appealing that decision. And in the meantime, Uber can keep operating. London's move is being applauded by taxi drivers, as you might expect, but many Uber customers are not so happy. NPR's Chris Arnold reports. CHRIS ARNOLD, BYLINE: In London today, people are being forced to envision life without Uber cars. It's a bleak vision for Yurr-Ann Chin and Svenya Tishmyer (ph). UNIDENTIFIED WOMAN: Taxis are so expensive in London, so I usually rely on Uber at the moments during the night to get home from bars or clubs because the Tube doesn't go at night. ARNOLD: Of course people could try to grab one of those stately looking black cabs. Arun Sundararajan is a business professor at NYU who was born in the U. K. ARUN SUNDARARAJAN: Of all the cities in the world, London's taxi service is perhaps the most iconic - you know, black cabs driving around - and most closely tied to the identity of the city. ARNOLD: And because of that, there could be some politics going on here to protect the taxi drivers. And Sundararajan says that the move could also be a part of a more general backlash against big tech companies from abroad. SUNDARARAJAN: The fact that it is a non-European or non-British platform that is dominating what used to be a locally provided service. ARNOLD: OK, but there is still a reason that Uber is popular in London. JACOB KIRKEGAARD: Anybody who has taken a black cab in London knows that this is a pricey service that is not always available where you need it. ARNOLD: That's Jacob Kirkegaard, an economist with the Peterson Institute. He says London's subway, or Tube system, is crowded. KIRKEGAARD: London is a city whose infrastructure greatly benefits from the, in many ways, complimentary service of a company like Uber. ARNOLD: But he says a series of glaringly bad missteps by the company has left it vulnerable. Perhaps the worst, the ride-hailing service angered regulators around the world with its so-called Greyball program which deceived officials by showing them fake Uber cars when they looked at the app. KIRKEGAARD: There is a federal criminal investigation here in the United States that they used this Greyball software to basically trick local regulators so that they couldn't identify individual drivers, so they couldn't check the identity of these drivers. That is a serious charge. ARNOLD: Traditional taxi companies have pointed to sexual assault complaints against Uber drivers to raise safety concerns, and the London regulators faulted the company's approach to reporting, quote, \"serious criminal offenses. \" Uber says it complies with the same background checks that the cab drivers undergo in London and that it works closely with police. In the end, Kirkegaard thinks that London might force some changes on Uber, but he would be surprised if the city actually bans Uber cars. KIRKEGAARD: The U. K. is voting for Brexit, and you know, they really want to send the signal, we're still open for business. Banning a cheap source of transportation within the city is a step in the other direction. ARNOLD: Meanwhile, today more than 300,000 people have already signed an online petition asking the mayor to reverse the decision to ban Uber in London. Chris Arnold, NPR News. (SOUNDBITE OF MURS AND 9TH WONDER SONG, \"FUNERAL FOR A KILLER\") AILSA CHANG, HOST:  Uber may not be able to operate in London for much longer. The top transportation authority there says it will not renew Uber's license. The ride-hailing service is appealing that decision. And in the meantime, Uber can keep operating. London's move is being applauded by taxi drivers, as you might expect, but many Uber customers are not so happy. NPR's Chris Arnold reports. CHRIS ARNOLD, BYLINE: In London today, people are being forced to envision life without Uber cars. It's a bleak vision for Yurr-Ann Chin and Svenya Tishmyer (ph). UNIDENTIFIED WOMAN: Taxis are so expensive in London, so I usually rely on Uber at the moments during the night to get home from bars or clubs because the Tube doesn't go at night. ARNOLD: Of course people could try to grab one of those stately looking black cabs. Arun Sundararajan is a business professor at NYU who was born in the U. K. ARUN SUNDARARAJAN: Of all the cities in the world, London's taxi service is perhaps the most iconic - you know, black cabs driving around - and most closely tied to the identity of the city. ARNOLD: And because of that, there could be some politics going on here to protect the taxi drivers. And Sundararajan says that the move could also be a part of a more general backlash against big tech companies from abroad. SUNDARARAJAN: The fact that it is a non-European or non-British platform that is dominating what used to be a locally provided service. ARNOLD: OK, but there is still a reason that Uber is popular in London. JACOB KIRKEGAARD: Anybody who has taken a black cab in London knows that this is a pricey service that is not always available where you need it. ARNOLD: That's Jacob Kirkegaard, an economist with the Peterson Institute. He says London's subway, or Tube system, is crowded. KIRKEGAARD: London is a city whose infrastructure greatly benefits from the, in many ways, complimentary service of a company like Uber. ARNOLD: But he says a series of glaringly bad missteps by the company has left it vulnerable. Perhaps the worst, the ride-hailing service angered regulators around the world with its so-called Greyball program which deceived officials by showing them fake Uber cars when they looked at the app. KIRKEGAARD: There is a federal criminal investigation here in the United States that they used this Greyball software to basically trick local regulators so that they couldn't identify individual drivers, so they couldn't check the identity of these drivers. That is a serious charge. ARNOLD: Traditional taxi companies have pointed to sexual assault complaints against Uber drivers to raise safety concerns, and the London regulators faulted the company's approach to reporting, quote, \"serious criminal offenses. \" Uber says it complies with the same background checks that the cab drivers undergo in London and that it works closely with police. In the end, Kirkegaard thinks that London might force some changes on Uber, but he would be surprised if the city actually bans Uber cars. KIRKEGAARD: The U. K. is voting for Brexit, and you know, they really want to send the signal, we're still open for business. Banning a cheap source of transportation within the city is a step in the other direction. ARNOLD: Meanwhile, today more than 300,000 people have already signed an online petition asking the mayor to reverse the decision to ban Uber in London. Chris Arnold, NPR News. (SOUNDBITE OF MURS AND 9TH WONDER SONG, \"FUNERAL FOR A KILLER\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-09-22-552726960": {"title": "The Next Big Focus In The Russia Investigations: Social Media : NPR", "url": "https://www.npr.org/2017/09/22/552726960/the-next-big-focus-in-the-russia-investigations-social-media", "author": "No author found", "published_date": "2017-09-22", "content": "", "section": "National Security", "disclaimer": ""}, "2017-09-24-552966487": {"title": "The Russia Investigations: Paul Manafort Has A Bad Week; Twitter, Facebook In The Hot Seat : NPR", "url": "https://www.npr.org/2017/09/24/552966487/the-russia-investigations-bad-week-for-manafort-social-networks-in-the-hot-seat", "author": "No author found", "published_date": "2017-09-24", "content": "", "section": "National Security", "disclaimer": ""}, "2017-09-25-553532488": {"title": "Russian-Linked Election Ads Highlight Scope Of Facebook's Power : NPR", "url": "https://www.npr.org/2017/09/25/553532488/russian-linked-election-ads-highlight-scope-of-facebooks-power", "author": "No author found", "published_date": "2017-09-25", "content": "AILSA CHANG, HOST: For months, Facebook has denied that fake news circulating on its platform had a hand in President Trump's election victory last year. Now it is admitting as much. We'll look at what's changed on this week's All Tech Considered. (SOUNDBITE OF MUSIC)CHANG: Facebook last week gave Congress thousands of ads on the social network that it says are linked to Russia, and CEO Mark Zuckerberg announced other moves designed to prevent foreign governments from using Facebook to influence future elections. To talk about all of this we have NPR's Laura Sydell with us now. Hi, Laura. LAURA SYDELL, BYLINE: Hello. CHANG: What exactly is Facebook doing right now? SYDELL: It's making changes to the process of placing political ads on the network. Now users are going to be able to see an advertiser's web page, see who's behind the ads, what other ads the sponsor has and who else is being shown the ads. And this might enable a user to maybe understand the deeper motivations of the advertiser. Then the company's also requiring advertisers to disclose who sponsored their advertisements. And it will add another 250 employees to focus on election integrity and security. CHANG: What specifically brought this on? What finally nudged Facebook into action? SYDELL: There was a lot of pressure on the company from Congress to look more deeply. In fact, the Russians had managed to evade Facebook's security. And according to a report in The Washington Post, once it looked a little harder, Facebook discovered that members of a hacking group connected to Russia's military intelligence unit, GRU, began creating fake Facebook accounts to amplify stolen emails from the Democratic National Committee. And that goes back as early as June of 2016. CHANG: Now, all of this is a big turnaround for the CEO of Facebook, Mark Zuckerberg, because in November he denied that fake news on Facebook played any role in the election. I believe he said that he felt U. S. citizens were making their voting decisions based on their - how did he put it? - their lived experience. SYDELL: It's been a long journey for Mark Zuckerberg. Silicon Valley has a longtime adherence to the principles of free speech and this idea that no censorship and open exchange of ideas is just good. Since then, Zuckerberg has kind of changed. It's now been widely reported that shortly after the November election he was approached by then-President Obama who was convinced that Facebook had spread fake news that had been planted by the Russians. And in the months since, Congress has been putting more and more pressure on the company. CHANG: Now, how did Facebook miss this connection between political ads and Russia for so long? Is there something wrong with the way it screens advertisers? SYDELL: That is a question that gets to a very core issue about Facebook and, frankly, a lot of the tech industry. In the past, when - in the advertising industry actual humans would go out, find advertisers and sell to them. Now all of this is done by computer algorithm. And if you explain this in the most simple terms, an advertiser simply goes on to Facebook, sets up an account, says what kind of person they want to target, and the ads go out to that particular kind of person. Facebook does program its algorithms to look for fraud. But if you've got a smart foreign agent - say, Russia - familiar with how those algorithms work, they can evade them. CHANG: So what can we expect next? SYDELL: I think that Mark Zuckerberg took these recent steps because he wants to avoid more action by Congress. I mean, this is a company that's got 70 percent of all U. S. adults on the platform. So now Senate Democrats are working on legislation that would require web platforms - and that also includes Google and others - to disclose the names of individuals and organizations that spend more than $10,000 on election-related advertisements. And I suspect that's an effort we're going to be hearing a lot more about. CHANG: That's NPR's digital culture correspondent, Laura Sydell. Thanks, Laura. SYDELL: You are welcome. AILSA CHANG, HOST:  For months, Facebook has denied that fake news circulating on its platform had a hand in President Trump's election victory last year. Now it is admitting as much. We'll look at what's changed on this week's All Tech Considered. (SOUNDBITE OF MUSIC) CHANG: Facebook last week gave Congress thousands of ads on the social network that it says are linked to Russia, and CEO Mark Zuckerberg announced other moves designed to prevent foreign governments from using Facebook to influence future elections. To talk about all of this we have NPR's Laura Sydell with us now. Hi, Laura. LAURA SYDELL, BYLINE: Hello. CHANG: What exactly is Facebook doing right now? SYDELL: It's making changes to the process of placing political ads on the network. Now users are going to be able to see an advertiser's web page, see who's behind the ads, what other ads the sponsor has and who else is being shown the ads. And this might enable a user to maybe understand the deeper motivations of the advertiser. Then the company's also requiring advertisers to disclose who sponsored their advertisements. And it will add another 250 employees to focus on election integrity and security. CHANG: What specifically brought this on? What finally nudged Facebook into action? SYDELL: There was a lot of pressure on the company from Congress to look more deeply. In fact, the Russians had managed to evade Facebook's security. And according to a report in The Washington Post, once it looked a little harder, Facebook discovered that members of a hacking group connected to Russia's military intelligence unit, GRU, began creating fake Facebook accounts to amplify stolen emails from the Democratic National Committee. And that goes back as early as June of 2016. CHANG: Now, all of this is a big turnaround for the CEO of Facebook, Mark Zuckerberg, because in November he denied that fake news on Facebook played any role in the election. I believe he said that he felt U. S. citizens were making their voting decisions based on their - how did he put it? - their lived experience. SYDELL: It's been a long journey for Mark Zuckerberg. Silicon Valley has a longtime adherence to the principles of free speech and this idea that no censorship and open exchange of ideas is just good. Since then, Zuckerberg has kind of changed. It's now been widely reported that shortly after the November election he was approached by then-President Obama who was convinced that Facebook had spread fake news that had been planted by the Russians. And in the months since, Congress has been putting more and more pressure on the company. CHANG: Now, how did Facebook miss this connection between political ads and Russia for so long? Is there something wrong with the way it screens advertisers? SYDELL: That is a question that gets to a very core issue about Facebook and, frankly, a lot of the tech industry. In the past, when - in the advertising industry actual humans would go out, find advertisers and sell to them. Now all of this is done by computer algorithm. And if you explain this in the most simple terms, an advertiser simply goes on to Facebook, sets up an account, says what kind of person they want to target, and the ads go out to that particular kind of person. Facebook does program its algorithms to look for fraud. But if you've got a smart foreign agent - say, Russia - familiar with how those algorithms work, they can evade them. CHANG: So what can we expect next? SYDELL: I think that Mark Zuckerberg took these recent steps because he wants to avoid more action by Congress. I mean, this is a company that's got 70 percent of all U. S. adults on the platform. So now Senate Democrats are working on legislation that would require web platforms - and that also includes Google and others - to disclose the names of individuals and organizations that spend more than $10,000 on election-related advertisements. And I suspect that's an effort we're going to be hearing a lot more about. CHANG: That's NPR's digital culture correspondent, Laura Sydell. Thanks, Laura. SYDELL: You are welcome.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-09-27-554057389": {"title": "Ready Or Not, Twitter Is Doubling A Tweet's Character Limit To 280 : NPR", "url": "https://www.npr.org/2017/09/27/554057389/ready-or-not-twitter-is-doubling-a-tweets-character-limit-to-280", "author": "No author found", "published_date": "2017-09-27", "content": "ROBERT SIEGEL, HOST: Twitter announced yesterday that it is doubling its character limit. This is so important, we'll do the math for you - 140 times two is 280 characters. AILSA CHANG, HOST: (Laughter) But wait. Before you start to type away your expanded thoughts, this is just a small group trial. Twitter won't say much about who is in that small group, but if you are when you go to compose a tweet, you will see the number 280 in the bottom right. SIEGEL: Now, comedy writer Jess Dweck did not see that number. JESS DWECK: I was - I wouldn't say upset because, honestly, who cares? It's Twitter. But my initial reaction was negative just because the kind of beauty of Twitter is that it forces you to be really concise. CHANG: That did not stop her from dreaming up what she'd say in 280 characters. She tweeted it as a photo. SIEGEL: (Reading) Brevity is the soul of wit, you see, because wit is all about having a sharp, clever response, and there is nothing sharp or clever about needing excess verbiage to explain your point. So I would say that brevity, being brief, is how you best achieve wittiness and capture its soul. CHANG: Jess Dweck actually got her first TV writing job after someone noticed her funny tweets about the news. She says this news has her confused about the company's priorities. DWECK: So the main complaint was Twitter needs to stop harassment from racists, literal Nazis, and then their solution was like, oh, let's actually double the amount of harassment they can do. SIEGEL: Tanya Chen, a deputy social news editor at BuzzFeed News, noted the same reaction. TANYA CHEN: There were even some pretty dark jokes about how this just allows Twitter trolls to send you even longer and more specific death threats. And, of course, there were a lot of jokes about Trump and his use of Twitter, many jokes about now this giving him more of a platform, more of an opportunity, more room to declare war on multiple countries at the same time. CHANG: Twitter's co-founder tweeted yesterday that the company is pursuing efforts to combat harassment. SIEGEL: There's a high possibility that Twitter will roll out the new 280-character limit more widely in the near future. It's being tested in all languages except Chinese, Korean and Japanese. Twitter's reasoning is that in those languages you can already fit in a lot of information in a single character. ROBERT SIEGEL, HOST:  Twitter announced yesterday that it is doubling its character limit. This is so important, we'll do the math for you - 140 times two is 280 characters. AILSA CHANG, HOST:  (Laughter) But wait. Before you start to type away your expanded thoughts, this is just a small group trial. Twitter won't say much about who is in that small group, but if you are when you go to compose a tweet, you will see the number 280 in the bottom right. SIEGEL: Now, comedy writer Jess Dweck did not see that number. JESS DWECK: I was - I wouldn't say upset because, honestly, who cares? It's Twitter. But my initial reaction was negative just because the kind of beauty of Twitter is that it forces you to be really concise. CHANG: That did not stop her from dreaming up what she'd say in 280 characters. She tweeted it as a photo. SIEGEL: (Reading) Brevity is the soul of wit, you see, because wit is all about having a sharp, clever response, and there is nothing sharp or clever about needing excess verbiage to explain your point. So I would say that brevity, being brief, is how you best achieve wittiness and capture its soul. CHANG: Jess Dweck actually got her first TV writing job after someone noticed her funny tweets about the news. She says this news has her confused about the company's priorities. DWECK: So the main complaint was Twitter needs to stop harassment from racists, literal Nazis, and then their solution was like, oh, let's actually double the amount of harassment they can do. SIEGEL: Tanya Chen, a deputy social news editor at BuzzFeed News, noted the same reaction. TANYA CHEN: There were even some pretty dark jokes about how this just allows Twitter trolls to send you even longer and more specific death threats. And, of course, there were a lot of jokes about Trump and his use of Twitter, many jokes about now this giving him more of a platform, more of an opportunity, more room to declare war on multiple countries at the same time. CHANG: Twitter's co-founder tweeted yesterday that the company is pursuing efforts to combat harassment. SIEGEL: There's a high possibility that Twitter will roll out the new 280-character limit more widely in the near future. It's being tested in all languages except Chinese, Korean and Japanese. Twitter's reasoning is that in those languages you can already fit in a lot of information in a single character.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-09-28-554292680": {"title": "Trump Deletes Luther Strange Tweets After Alabama Loss, Raising Legal Questions : NPR", "url": "https://www.npr.org/2017/09/28/554292680/trump-deleted-strange-tweets-after-luthers-loss", "author": "No author found", "published_date": "2017-09-28", "content": "", "section": "Politics", "disclaimer": ""}, "2017-09-28-554024047": {"title": "As Scrutiny Of Social Networks Grows, Influence Attacks Continue In Real Time : NPR", "url": "https://www.npr.org/2017/09/28/554024047/as-scrutiny-of-social-networks-grows-influence-attacks-continue-in-real-time", "author": "No author found", "published_date": "2017-09-28", "content": "", "section": "Politics", "disclaimer": ""}, "2017-09-29-553772957": {"title": "2 Viral Twitter Poets Are Rewriting The Book On Astrology : NPR", "url": "https://www.npr.org/2017/09/29/553772957/two-viral-twitter-poets-are-rewriting-the-book-on-astrology", "author": "No author found", "published_date": "2017-09-29", "content": "", "section": "Culture", "disclaimer": ""}, "2017-09-29-554424193": {"title": "The Pitfalls Of Social Media Advertising : NPR", "url": "https://www.npr.org/2017/09/29/554424193/the-pitfalls-of-social-media-advertising", "author": "No author found", "published_date": "2017-09-29", "content": "RACHEL MARTIN, HOST: A whole lot of companies invest a whole lot of money in social media. It's a powerful and pretty cheap way to advertise new products or services. But new social science research finds that companies may be paying a hidden price for those cheap ads. NPR social science correspondent Shankar Vedantam talked about it with our co-host, David Greene. DAVID GREENE, BYLINE: So I could imagine this being a problem if you're a business and you're on social media and you're like, you know, posting offensive stuff. But you're saying there's something fundamental here that the businesses might not realize? SHANKAR VEDANTAM, BYLINE: That's exactly right. I think the fundamental problem is that even as social media draws people who are potential buyers, it runs the risk of potentially harming the long-term relationship between the organization that's doing the post and its audience. I was speaking with Shuting Wang. She's a Ph. D. student at Temple University. Along with Brad Greenwood and Paul Pavlou, Wang analyzed a Chinese fashion company that used the Chinese equivalent of Facebook, a platform called WeChat, to sell its products. Wang found that the post did increase sales, but this turned out to be a short-term benefit that was more than counterbalanced by long-term pitfalls. SHUTING WANG: The increase in short-term purchase may induce firms to intensively post and invest on social media, but our findings show that the firms may be misguided. GREENE: Misguided. OK, so the firm not realizing what the long-term pitfall might be. What is it? VEDANTAM: Exactly. The long-term pitfall is that even as promotional messages attract some buyers, they also annoy other people. In fact, they might annoy many more people than those who act on the message to buy something. Wang and her colleagues find that posts increase sales by 5 percent. So this is a visible benefit the company sees in the short term, but it also increases the likelihood that people unfollow the company by 300 percent. Over the long term, the researchers find that social media promotional messages actually might decrease sales. WANG: For some consumers, those postings could be very annoying and interactive. However, we're not saying that firms should not post on social media. Instead, we suggest firms to be more strategic and they should consider who to target, when to post and what to post. GREENE: OK. I think I'm getting this, Shankar. So I might see something in social media. It might be a new product. I might go buy it. But if this company sends me four posts a day, I'm like, get this out of my feed. I'm going to unfollow you now. VEDANTAM: That's exactly right. And, you know, so companies might actually need to do a better job targeting people for when they want to buy something and also what state of mind they're in. One of the things the study finds, David, is that the negative effect of social media are strongest in big cities and at busy times. So these are the people who are most annoyed with promotional messaging that they do not find relevant. There's an old joke in advertising, David. I know half my advertising budget is wasted, I just don't know which half. GREENE: (Laughter). VEDANTAM: This research suggests, you know, at least on social media, half your budget might not just be wasted, it might be cannibalizing what the other half is doing. GREENE: Interesting. Well, it's a serious thing for businesses to think about. VEDANTAM: Indeed. GREENE: Shankar, thanks. VEDANTAM: Thank you, David. GREENE: Shankar Vedantam is NPR's social science correspondent. He brings us stories like that one. He's also the host of a podcast that explores the unseen patterns in human behavior. It is called Hidden Brain. RACHEL MARTIN, HOST:  A whole lot of companies invest a whole lot of money in social media. It's a powerful and pretty cheap way to advertise new products or services. But new social science research finds that companies may be paying a hidden price for those cheap ads. NPR social science correspondent Shankar Vedantam talked about it with our co-host, David Greene. DAVID GREENE, BYLINE: So I could imagine this being a problem if you're a business and you're on social media and you're like, you know, posting offensive stuff. But you're saying there's something fundamental here that the businesses might not realize? SHANKAR VEDANTAM, BYLINE: That's exactly right. I think the fundamental problem is that even as social media draws people who are potential buyers, it runs the risk of potentially harming the long-term relationship between the organization that's doing the post and its audience. I was speaking with Shuting Wang. She's a Ph. D. student at Temple University. Along with Brad Greenwood and Paul Pavlou, Wang analyzed a Chinese fashion company that used the Chinese equivalent of Facebook, a platform called WeChat, to sell its products. Wang found that the post did increase sales, but this turned out to be a short-term benefit that was more than counterbalanced by long-term pitfalls. SHUTING WANG: The increase in short-term purchase may induce firms to intensively post and invest on social media, but our findings show that the firms may be misguided. GREENE: Misguided. OK, so the firm not realizing what the long-term pitfall might be. What is it? VEDANTAM: Exactly. The long-term pitfall is that even as promotional messages attract some buyers, they also annoy other people. In fact, they might annoy many more people than those who act on the message to buy something. Wang and her colleagues find that posts increase sales by 5 percent. So this is a visible benefit the company sees in the short term, but it also increases the likelihood that people unfollow the company by 300 percent. Over the long term, the researchers find that social media promotional messages actually might decrease sales. WANG: For some consumers, those postings could be very annoying and interactive. However, we're not saying that firms should not post on social media. Instead, we suggest firms to be more strategic and they should consider who to target, when to post and what to post. GREENE: OK. I think I'm getting this, Shankar. So I might see something in social media. It might be a new product. I might go buy it. But if this company sends me four posts a day, I'm like, get this out of my feed. I'm going to unfollow you now. VEDANTAM: That's exactly right. And, you know, so companies might actually need to do a better job targeting people for when they want to buy something and also what state of mind they're in. One of the things the study finds, David, is that the negative effect of social media are strongest in big cities and at busy times. So these are the people who are most annoyed with promotional messaging that they do not find relevant. There's an old joke in advertising, David. I know half my advertising budget is wasted, I just don't know which half. GREENE: (Laughter). VEDANTAM: This research suggests, you know, at least on social media, half your budget might not just be wasted, it might be cannibalizing what the other half is doing. GREENE: Interesting. Well, it's a serious thing for businesses to think about. VEDANTAM: Indeed. GREENE: Shankar, thanks. VEDANTAM: Thank you, David. GREENE: Shankar Vedantam is NPR's social science correspondent. He brings us stories like that one. He's also the host of a podcast that explores the unseen patterns in human behavior. It is called Hidden Brain.", "section": "Hidden Brain", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-09-30-554635540": {"title": "White House Aides Used Private Email For Official Business: 'Just Very, Very Stupid' : NPR", "url": "https://www.npr.org/2017/09/30/554635540/white-house-aides-use-private-email-for-official-business-not-criminal-it-s-just", "author": "No author found", "published_date": "2017-09-30", "content": "SCOTT SIMON, HOST: The House Oversight Committee is asking the White House for a list of aides who've used private email accounts for official business. This request comes after confirmation that President Trump's son-in-law and top adviser, Jared Kushner, used a personal account for at least some White House business. NPR White House correspondent Tamara Keith has this look at what the rules are for these kinds of communications. TAMARA KEITH, BYLINE: The Presidential Records Act has, since 1978, made it plain that the president and his advisers need to preserve all presidential records. NATE JONES: Essentially, the law on the books since the Nixon administration says that the public needs to know the official business of the federal government. KEITH: Nate Jones is with the National Security Archive, an open government group. Presidential records include emails and text messages. In 2014, Jones says the law was updated. JONES: To make it crystal clear that you couldn't use personal or any other email and that if you did, for example, for convenience, or if the email was broken, or the occasions that we all know in real life - if you did, you had to forward it to the official account within 20 days. KEITH: This was all prompted by something that happened during the George W. Bush administration. Richard Painter was chief White House ethics lawyer at the time and instructed all aides and officials that they shouldn't use non-government emails for official business. RICHARD PAINTER: But a number of people chose to use Republican National Committee email for official United States government business. And then the Republican National Committee's server apparently deleted it. KEITH: Millions of emails went missing, though they were recovered much later. Painter says there are two main reasons why using personal email for official business is problematic - for records preservation and because of the risk that classified information could end up on nongovernment systems. But Painter says it seems to keep happening. PAINTER: You know, it was embarrassing. And I would have hoped that Secretary Clinton would've learned from that. Apparently, she didn't. And I would hope that the Trump administration would've learn from what has happened before, as well. And, apparently, they don't learn the lesson, either. KEITH: Jared Kushner, the president's son-in-law and adviser, sent or received about a hundred work-related emails on his personal account from January through August - usually forwarded articles or an exchange initiated by someone else. That is according to a statement from his attorney, Abbe Lowell. Lowell added, quote, \"all nonpersonal emails were forwarded to his official address, and all have been preserved in any event. \" But that passive voice - were forwarded - catches Jones's ear. JONES: The key thing that Mr. Kushner's lawyer didn't say was if he forwarded the emails before 20 days were over or not because, if he did, he would be in the clear. But if he forwarded his emails to the official account after, he did break the law. KEITH: Kushner's lawyer did not respond to questions about when Kushner forwarded the emails. to his official account. But here's the thing. Even if Kushner did violate the Presidential Records Act, there aren't many consequences - possible disciplinary action. PAINTER: It's not a criminal offense. It's just very, very stupid. KEITH: Again, Richard Painter. PAINTER: None of this is criminal. Nobody's getting locked up. But it really is very, very poor judgment. KEITH: Reports in Politico and The New York Times indicate Kushner is not the only senior Trump White House aide, past or present, to use a personal account. The House Oversight Committee has set an October 9 deadline for the White House to respond to its request for information about who has been using personal email for government business. Tamara Keith, NPR News, Washington. SCOTT SIMON, HOST:  The House Oversight Committee is asking the White House for a list of aides who've used private email accounts for official business. This request comes after confirmation that President Trump's son-in-law and top adviser, Jared Kushner, used a personal account for at least some White House business. NPR White House correspondent Tamara Keith has this look at what the rules are for these kinds of communications. TAMARA KEITH, BYLINE: The Presidential Records Act has, since 1978, made it plain that the president and his advisers need to preserve all presidential records. NATE JONES: Essentially, the law on the books since the Nixon administration says that the public needs to know the official business of the federal government. KEITH: Nate Jones is with the National Security Archive, an open government group. Presidential records include emails and text messages. In 2014, Jones says the law was updated. JONES: To make it crystal clear that you couldn't use personal or any other email and that if you did, for example, for convenience, or if the email was broken, or the occasions that we all know in real life - if you did, you had to forward it to the official account within 20 days. KEITH: This was all prompted by something that happened during the George W. Bush administration. Richard Painter was chief White House ethics lawyer at the time and instructed all aides and officials that they shouldn't use non-government emails for official business. RICHARD PAINTER: But a number of people chose to use Republican National Committee email for official United States government business. And then the Republican National Committee's server apparently deleted it. KEITH: Millions of emails went missing, though they were recovered much later. Painter says there are two main reasons why using personal email for official business is problematic - for records preservation and because of the risk that classified information could end up on nongovernment systems. But Painter says it seems to keep happening. PAINTER: You know, it was embarrassing. And I would have hoped that Secretary Clinton would've learned from that. Apparently, she didn't. And I would hope that the Trump administration would've learn from what has happened before, as well. And, apparently, they don't learn the lesson, either. KEITH: Jared Kushner, the president's son-in-law and adviser, sent or received about a hundred work-related emails on his personal account from January through August - usually forwarded articles or an exchange initiated by someone else. That is according to a statement from his attorney, Abbe Lowell. Lowell added, quote, \"all nonpersonal emails were forwarded to his official address, and all have been preserved in any event. \" But that passive voice - were forwarded - catches Jones's ear. JONES: The key thing that Mr. Kushner's lawyer didn't say was if he forwarded the emails before 20 days were over or not because, if he did, he would be in the clear. But if he forwarded his emails to the official account after, he did break the law. KEITH: Kushner's lawyer did not respond to questions about when Kushner forwarded the emails. to his official account. But here's the thing. Even if Kushner did violate the Presidential Records Act, there aren't many consequences - possible disciplinary action. PAINTER: It's not a criminal offense. It's just very, very stupid. KEITH: Again, Richard Painter. PAINTER: None of this is criminal. Nobody's getting locked up. But it really is very, very poor judgment. KEITH: Reports in Politico and The New York Times indicate Kushner is not the only senior Trump White House aide, past or present, to use a personal account. The House Oversight Committee has set an October 9 deadline for the White House to respond to its request for information about who has been using personal email for government business. Tamara Keith, NPR News, Washington.", "section": "Politics", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-10-01-554933075": {"title": "What Can We Learn About The Effects Of Social Media Ads? : NPR", "url": "https://www.npr.org/2017/10/01/554933075/what-can-we-learn-about-the-effects-of-social-media-ads", "author": "No author found", "published_date": "2017-10-01", "content": "MICHEL MARTIN, HOST: Now, information keeps coming out about Russia's role in the 2016 presidential election, particularly the Russians' use of Facebook and Twitter. Now, initially, the focus was on the spread of false information - fake news. But now the focus is on something else - posts that play up social divisions. Last month, Facebook said a Russian-based agency had bought $100,000 worth of ads on its platforms during the campaign season. Last week, The Washington Post and CNN reported that ads bought by Russian operatives targeted groups concerned about African-Americans such as Black Lives Matter and even zeroed in on users in Baltimore and Ferguson, Mo. , places that had seen civil unrest. To learn more about how the social media ad buys are supposed to work, we called Scott Tranter, director of analytics for a Washington, D. C. , based data and technology firm. He's a Republican who ran digital analysis for Senator Marco Rubio's presidential run. I started our conversation by asking about the Russians' $100,000 ad buy on Facebook. SCOTT TRANTER: A hundred-thousand dollars is a drop in the bucket in terms of the amount of money you need to spend to get an impact online. And, you know, I think everyone's focused on, oh, $100,000 is a lot. Your average presidential campaign was probably spending anywhere from $10,000 to $100,000 a week for almost a year. So you can kind of see where $100,000 is a lot of money, but in the grand scheme of things, not necessarily a lot of money if you want to have an effect. So at least my opinion is I think if the Russians were really trying to do something and if it truly was them that we're going to find more. MARTIN: And so what's the goal here? What have we learned about what these ads were meant to do? TRANTER: When you're on the Internet, you're trying to - especially on all advertising - you're trying to evoke a response, right? So when we're doing a traditional political campaign, we want to evoke a response in the person we're speaking to, whether it be emotional, whether that be visceral or something like that. We want them to have a response to it and make a connection to our candidate. And so these ads were clearly divisive. They were designed to get a visceral reaction and create some action potentially at the voting booth or potentially in certain people's minds. MARTIN: So what does - is the goal to get people to vote? These ads don't really mention candidates, at least so far as we know. So what was the point there? TRANTER: I'll have to speculate outside my expertise but it's kind of like maybe they didn't necessarily want a specific candidate, they just wanted to create turmoil. Because if you create turmoil, then you muddy the waters and you make it difficult for everyone there. And if you look at it, a lot of these ads were played over a year ago. It's something that we're going to be talking about for a long time. So if you're the Russians, this is - whether or not you got the candidate you wanted, this is actually having an effect. MARTIN: You know, a number of far-right groups already promulgate the same kinds of information. I'm thinking about Breitbart, for example, which tends to be very interested in crimes committed by African-Americans. Similarly, there are African-American-oriented legitimate information sites which are very interested in reporting on misconduct toward African-Americans or particularly police misconduct toward African-Americans. And so how is what the Russians are - or what we believe the Russians were doing different from what these groups, which we know are run by Americans, are doing? TRANTER: You mean from a tactics standpoint? MARTIN: Yeah. How is it different? TRANTER: I would say the tactics are pretty standard. You're picking a hot-button issue. You're putting some explosive content or explosive accusations around it and you're trying to get people to react. They're adding amplification of a message. So, for instance, the ads we're specifically talking about, the ads around the Black Lives Matter stuff and specifically targeting Ferguson, specifically targeting around Baltimore, I mean, that was an issue that was widely - correctly covered on lots of local news, lots of national news. And then all of a sudden, they said, hey, here's a constituency that if we put ads in front, we're going to get them to respond. MARTIN: So for people who support Donald Trump and who are happy that he was elected, you know, setting aside the whole question of whether there was collusion or not because that's not at all what we're talking about here, but for people who are happy that he's elected and say, so what, so what that they did that, so what if it helped him, what would you say? TRANTER: Well, the fact that they were able to a use advertising medium that skirted around some of the regulations that the other political communications have is worrisome. As a practitioner, as an expert in this field, if I know that someone can spend some money and potentially affect a race that I'm in, I'm worried about that because our job is to play by the rules. Our job is to abide the law. And our job is to make sure that we target the right people with the right message. And so when I see someone coming in and spending money and affecting an outcome that we're supposed to not playing by the rules, yeah, we should be worried about it. And we're not talking about a football game. We're not talking about, you know, your kid's baseball game. We're talking about our democracy. So whenever we play around with that, we should be very careful and make sure that we understand how this is being played and who's being involved. MARTIN: That's Scott Tranter He's the director of analytics for a Washington, D. C. , based data and technology consultancy. He was the former director of analytics for the Marco Rubio presidential campaign and he's working with a number of Republican campaigns in the Washington, D. C. , area in this election cycle. Thanks so much for coming in. TRANTER: Thank you for having me. (SOUNDBITE OF LITTLE PEOPLE'S \"MOON\") MICHEL MARTIN, HOST:  Now, information keeps coming out about Russia's role in the 2016 presidential election, particularly the Russians' use of Facebook and Twitter. Now, initially, the focus was on the spread of false information - fake news. But now the focus is on something else - posts that play up social divisions. Last month, Facebook said a Russian-based agency had bought $100,000 worth of ads on its platforms during the campaign season. Last week, The Washington Post and CNN reported that ads bought by Russian operatives targeted groups concerned about African-Americans such as Black Lives Matter and even zeroed in on users in Baltimore and Ferguson, Mo. , places that had seen civil unrest. To learn more about how the social media ad buys are supposed to work, we called Scott Tranter, director of analytics for a Washington, D. C. , based data and technology firm. He's a Republican who ran digital analysis for Senator Marco Rubio's presidential run. I started our conversation by asking about the Russians' $100,000 ad buy on Facebook. SCOTT TRANTER: A hundred-thousand dollars is a drop in the bucket in terms of the amount of money you need to spend to get an impact online. And, you know, I think everyone's focused on, oh, $100,000 is a lot. Your average presidential campaign was probably spending anywhere from $10,000 to $100,000 a week for almost a year. So you can kind of see where $100,000 is a lot of money, but in the grand scheme of things, not necessarily a lot of money if you want to have an effect. So at least my opinion is I think if the Russians were really trying to do something and if it truly was them that we're going to find more. MARTIN: And so what's the goal here? What have we learned about what these ads were meant to do? TRANTER: When you're on the Internet, you're trying to - especially on all advertising - you're trying to evoke a response, right? So when we're doing a traditional political campaign, we want to evoke a response in the person we're speaking to, whether it be emotional, whether that be visceral or something like that. We want them to have a response to it and make a connection to our candidate. And so these ads were clearly divisive. They were designed to get a visceral reaction and create some action potentially at the voting booth or potentially in certain people's minds. MARTIN: So what does - is the goal to get people to vote? These ads don't really mention candidates, at least so far as we know. So what was the point there? TRANTER: I'll have to speculate outside my expertise but it's kind of like maybe they didn't necessarily want a specific candidate, they just wanted to create turmoil. Because if you create turmoil, then you muddy the waters and you make it difficult for everyone there. And if you look at it, a lot of these ads were played over a year ago. It's something that we're going to be talking about for a long time. So if you're the Russians, this is - whether or not you got the candidate you wanted, this is actually having an effect. MARTIN: You know, a number of far-right groups already promulgate the same kinds of information. I'm thinking about Breitbart, for example, which tends to be very interested in crimes committed by African-Americans. Similarly, there are African-American-oriented legitimate information sites which are very interested in reporting on misconduct toward African-Americans or particularly police misconduct toward African-Americans. And so how is what the Russians are - or what we believe the Russians were doing different from what these groups, which we know are run by Americans, are doing? TRANTER: You mean from a tactics standpoint? MARTIN: Yeah. How is it different? TRANTER: I would say the tactics are pretty standard. You're picking a hot-button issue. You're putting some explosive content or explosive accusations around it and you're trying to get people to react. They're adding amplification of a message. So, for instance, the ads we're specifically talking about, the ads around the Black Lives Matter stuff and specifically targeting Ferguson, specifically targeting around Baltimore, I mean, that was an issue that was widely - correctly covered on lots of local news, lots of national news. And then all of a sudden, they said, hey, here's a constituency that if we put ads in front, we're going to get them to respond. MARTIN: So for people who support Donald Trump and who are happy that he was elected, you know, setting aside the whole question of whether there was collusion or not because that's not at all what we're talking about here, but for people who are happy that he's elected and say, so what, so what that they did that, so what if it helped him, what would you say? TRANTER: Well, the fact that they were able to a use advertising medium that skirted around some of the regulations that the other political communications have is worrisome. As a practitioner, as an expert in this field, if I know that someone can spend some money and potentially affect a race that I'm in, I'm worried about that because our job is to play by the rules. Our job is to abide the law. And our job is to make sure that we target the right people with the right message. And so when I see someone coming in and spending money and affecting an outcome that we're supposed to not playing by the rules, yeah, we should be worried about it. And we're not talking about a football game. We're not talking about, you know, your kid's baseball game. We're talking about our democracy. So whenever we play around with that, we should be very careful and make sure that we understand how this is being played and who's being involved. MARTIN: That's Scott Tranter He's the director of analytics for a Washington, D. C. , based data and technology consultancy. He was the former director of analytics for the Marco Rubio presidential campaign and he's working with a number of Republican campaigns in the Washington, D. C. , area in this election cycle. Thanks so much for coming in. TRANTER: Thank you for having me. (SOUNDBITE OF LITTLE PEOPLE'S \"MOON\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-10-01-554552848": {"title": "The Russia Investigations: Sens. Burr, Warner To Give Update; Spotlight On Twitter : NPR", "url": "https://www.npr.org/2017/10/01/554552848/the-russia-investigations-sens-burr-warner-to-give-update-spotlight-on-twitter", "author": "No author found", "published_date": "2017-10-01", "content": "", "section": "National Security", "disclaimer": ""}, "2017-10-02-555103005": {"title": "Facebook Surrenders Russian-Linked Influence Ads To Congress : NPR", "url": "https://www.npr.org/2017/10/02/555103005/facebook-surrenders-russian-linked-influence-ads-to-congress", "author": "No author found", "published_date": "2017-10-02", "content": "", "section": "National Security", "disclaimer": ""}, "2017-10-03-555417831": {"title": "Out Of The Gate, Tesla Stumbles On Its Mass-Market Model 3 Car : NPR", "url": "https://www.npr.org/2017/10/03/555417831/out-of-the-gate-tesla-stumbles-on-mass-market-car", "author": "No author found", "published_date": "2017-10-03", "content": "", "section": "Business", "disclaimer": ""}, "2017-10-04-555638795": {"title": "Sen. Richard Burr Says Question Still 'Open' About U.S. Collusion With Russia : NPR", "url": "https://www.npr.org/2017/10/04/555638795/question-still-open-about-u-s-collusion-with-russian-influence-campaign", "author": "No author found", "published_date": "2017-10-04", "content": "", "section": "The Impact of War", "disclaimer": ""}, "2017-10-05-555922305": {"title": "Report: Hackers Stole NSA Cybertools In Another Breach Via Another Contractor : NPR", "url": "https://www.npr.org/2017/10/05/555922305/report-hackers-stole-nsa-cybertools-in-another-breach-via-another-contractor", "author": "No author found", "published_date": "2017-10-05", "content": "", "section": "National Security", "disclaimer": ""}, "2017-10-05-555333479": {"title": "'Blade Runner 2049' And The Theaters That Shake Your Groove Thing For You : NPR", "url": "https://www.npr.org/2017/10/05/555333479/blade-runner-2049-and-the-theaters-that-shake-your-groove-thing-for-you", "author": "No author found", "published_date": "2017-10-05", "content": "", "section": "Pop Culture Happy Hour", "disclaimer": ""}, "2017-10-08-556159942": {"title": "Senators Say Russia Probe Is 'Incomplete'; Trump Jr. May Return To The Hill : NPR", "url": "https://www.npr.org/2017/10/08/556159942/the-russia-investigations-intelligence-committee-update-muellers-team-meets-stee", "author": "No author found", "published_date": "2017-10-08", "content": "", "section": "The Impact of War", "disclaimer": ""}, "2017-10-12-556924313": {"title": "Smart Shoe Benefits From A Reboot : NPR", "url": "https://www.npr.org/2017/10/12/556924313/after-a-failed-launch-smart-shoe-benefits-from-a-reboot", "author": "No author found", "published_date": "2017-10-12", "content": "", "section": "Changing The World One Invention At A Time", "disclaimer": ""}, "2017-10-12-557040239": {"title": "In The Age Of Concierge Apps, Real-Life Concierges Tout The 'Human Element' : NPR", "url": "https://www.npr.org/2017/10/12/557040239/in-the-age-of-concierge-apps-real-life-concierges-tout-the-human-element", "author": "No author found", "published_date": "2017-10-12", "content": "", "section": "Economy", "disclaimer": ""}, "2017-10-12-557181869": {"title": "Investigators Chase Missing Pieces Of Facebook, Twitter Role In Russian Meddling : NPR", "url": "https://www.npr.org/2017/10/12/557181869/investigators-chase-missing-pieces-of-facebook-twitter-role-in-russian-mischief", "author": "No author found", "published_date": "2017-10-12", "content": "", "section": "The Impact of War", "disclaimer": ""}, "2017-10-13-557421075": {"title": "Ali Velshi: In An Age Of \"Alternative Facts,\" How Do We Know What's True?  : NPR", "url": "https://www.npr.org/2017/10/13/557421075/ali-velshi-in-an-age-of-alternative-facts-how-do-we-know-what-s-true", "author": "No author found", "published_date": "2017-10-13", "content": "GUY RAZ, HOST: It's the TED Radio Hour from NPR. I'm Guy Raz. And on the show today, ideas about manipulation, about truth and lies and what happens when sometimes it's hard for people to see the difference. ALI VELSHI: I think manipulation is trying to get somebody to think a certain way or act a certain way. And I think that certainly in my line of work, it's a step beyond what most journalists think their role is. RAZ: This is Ali Velshi. VELSHI: I am an anchor and co-host of a couple of shows at MSNBC and NBC News. RAZ: I mean, so, I mean, when it comes to your self-image as a reporter, as a journalist, like, I mean, I'm assuming you think of yourself as a - somebody who's trying to seek the truth. VELSHI: Right, an arbiter, a truth-seeker, to some degree an advocate for my viewers or readers or listeners. So it was almost the opposite, in my mind, of manipulation. It was the idea that if I can give you the fullest picture, the most information and answer the toughest questions or ask them on your behalf, you will make better decisions using your own faculties. And so, to me, it didn't occur to me that manipulation, when I started this industry, was a role that journalists could play. RAZ: But for the most part, that's all changed in the past few years with the rise of made-up news stories on the Internet. . . (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED JOURNALIST: A fake story alleging Hillary Clinton and her campaign chairman, John Podesta, were involved in a child sex ring. RAZ: . . . And the spread of misinformation. . . (SOUNDBITE OF ARCHIVED RECORDING)KELLYANNE CONWAY: Alternative facts to that. But the point remains. . . CHUCK TODD: Wait a minute. Alternative facts? RAZ: . . . And the election of a president who's declared war on the mainstream media. (SOUNDBITE OF ARCHIVED RECORDING)PRESIDENT DONALD TRUMP: A few days ago, I called the fake news the enemy of the people, and they are. They are the enemy of the people. RAZ: So now that we're living in an era of fake news, how do we even begin to understand who's manipulating whom? Here's Ali Velshi on the TED stage. (SOUNDBITE OF TED TALK)VELSHI: Part of the problem is that when the president of the United States is encouraging his supporters to believe that the media is not just out of touch or somewhat ineffective but it's actually lying, it causes a problem. And that's just one in a range of problems that are caused by this fake news phenomenon. At its lowest level, it's a time suck. It confuses you. It causes you to spend your time trying to discern between fake news and real news. And I think over time, it can blunt your ability to actually do so. I'll give you an example. A BuzzFeed study said that in 2016, of the top 20 fake news stories on Facebook, they had 8. 7 million shares, comments, reactions. Of the top 20 real news stories by major news organizations, they had 1. 7 million fewer. So fake news is crowding out real news. It means that journalists like me, instead of following other stories and giving you new journalism and telling you stories about new things, we're busy debunking myths. And that's part of the problem that we've got. (SOUNDBITE OF MUSIC)RAZ: When did you start to notice that just objectively false news stories, lies sort of masking as real news stories, were happening and were starting to influence people? VELSHI: So I had known, as a journalist, that there were websites that were peddling misinformation or false information. And I'd certainly known it from other countries. So, for instance, I covered - not in person, but from here - I covered the war in Rwanda. And that was almost entirely fueled by what we now know to be fake news. It was radio stations that would perpetuate myths against a particular ethnic group and would do that. And when I studied it more, I found out that that happened in Nazi Germany a lot. And it's actually pretty pervasive. But we assumed that with the degree of digital penetration we have in the United States, people had the wherewithal to say, oh, that's a lie or this is a kooky conspiracy. RAZ: 'Cause I can just look it up. I could just look it up. VELSHI: I could look it up, right. And one thing that I have learned is that a lot of people don't triangulate. When I say triangulate, they don't have three independent reference points in which to say, oh, that's interesting. I listen to NPR. I read the Wall Street Journal. And I listen to this radio show. And only the radio show is saying that Hillary Clinton is running a sex slave ring out of a basement of a pizza parlor in suburban D. C. Strange that the other ones wouldn't cover that because you'd think that was a good story. And if you don't know that there are other sources who are reporting on something differently or not reporting on it at all, you don't necessarily know that your news source might not be telling you the truth. And not only that, speaking of manipulation, you are now so beholden to that news source, you're so into it that you will be convinced that the others are lying to you. (SOUNDBITE OF TED TALK)VELSHI: On December 4, I tweeted this out. And notice at the bottom it was retweeted 11,000 times. I tweeted - breaking news, the U. S. Army Corps of Engineers halts the Dakota Access Pipeline work, telling the Standing Rock Reservation that the current route for the pipeline will be denied. This was a very controversial issue. I had this news earlier than most people did, which is why it spread so many times because people wanted to distribute this information. But one of the first responses I got to this tweet was, what's your source? Now, come on. I'm not a journalism student. I'm a veteran journalist in my 24th year of this business. If I spread breaking news that is false or wrong, I am going to at the very least get disciplined and I could actually get fired. But increasingly, I am getting pushback on social media from people who accuse me of purveying fake news. There will - if you put in my name on, you know, my handle and fake news - #fakenews - you'll see things show up. And when you de-legitimize journalism and when you de-legitimize facts and when you do that, you create a vacuum in one of the most important checks in civil, economic and political discourse. (SOUNDBITE OF MUSIC)VELSHI: It's very, very dangerous. It worries me a great deal because, you know, in years gone by, I actually worried about being accurate. Now I worry about being accurate as much as I always did, possibly more so. But I also worry about the accusation that comes on Twitter with the hashtag #fakenews. Anybody who doesn't agree with my perspective now labels me a liar. And how do I deal with that? RAZ: Ali, I hear you. I hear your commitment and your passion and all of these things you're saying, but it seems like you're on the losing side. It seems like manipulative news is winning. VELSHI: Yeah. And as a numbers guy, I would say that that's quite possible. But they are winning because the parties in play have not acknowledged that they're winning. They have not sort of said it. Facebook is starting to face that reality. Google is looking at it. We're looking at the money that is made. It just pays better to have fake news. Fake news takes none of the resources that it takes for me to do a story, doesn't need the producers. If you're making stuff up, you don't actually need fact checkers and researchers and people like that. It is much cheaper to make fake news. And it's much more lucrative because you don't have to actually make people want to read the headline because you've invented the headline. So once we all decide that this is really dangerous, Facebook will build the right algorithms and they'll re-do their revenue streams so that they're not rewarding that kind of dishonest behavior. We'll all start to figure it out. And I think we'll be able to shore up our end and push forward and change things. (SOUNDBITE OF TED TALK)VELSHI: Remember what journalism is meant to do. It has two purposes. The first one is to bear witness, to simply be there to say that something is happening. But the second one is more important, it's to hold power to account. And together, let's not go down a road where we end up in a world where not only are we not speaking truth to power but we're not even able to discern the truth. Thank you. (APPLAUSE)RAZ: Ali Velshi. He's an anchor and co-host at MSNBC. You can see Ali's full talk at ted. npr. org. On the show today, ideas about how our actions, our thoughts, even our memories can be manipulated. (SOUNDBITE OF MUSIC) GUY RAZ, HOST:  It's the TED Radio Hour from NPR. I'm Guy Raz. And on the show today, ideas about manipulation, about truth and lies and what happens when sometimes it's hard for people to see the difference. ALI VELSHI: I think manipulation is trying to get somebody to think a certain way or act a certain way. And I think that certainly in my line of work, it's a step beyond what most journalists think their role is. RAZ: This is Ali Velshi. VELSHI: I am an anchor and co-host of a couple of shows at MSNBC and NBC News. RAZ: I mean, so, I mean, when it comes to your self-image as a reporter, as a journalist, like, I mean, I'm assuming you think of yourself as a - somebody who's trying to seek the truth. VELSHI: Right, an arbiter, a truth-seeker, to some degree an advocate for my viewers or readers or listeners. So it was almost the opposite, in my mind, of manipulation. It was the idea that if I can give you the fullest picture, the most information and answer the toughest questions or ask them on your behalf, you will make better decisions using your own faculties. And so, to me, it didn't occur to me that manipulation, when I started this industry, was a role that journalists could play. RAZ: But for the most part, that's all changed in the past few years with the rise of made-up news stories on the Internet. . . (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED JOURNALIST: A fake story alleging Hillary Clinton and her campaign chairman, John Podesta, were involved in a child sex ring. RAZ: . . . And the spread of misinformation. . . (SOUNDBITE OF ARCHIVED RECORDING) KELLYANNE CONWAY: Alternative facts to that. But the point remains. . . CHUCK TODD: Wait a minute. Alternative facts? RAZ: . . . And the election of a president who's declared war on the mainstream media. (SOUNDBITE OF ARCHIVED RECORDING) PRESIDENT DONALD TRUMP: A few days ago, I called the fake news the enemy of the people, and they are. They are the enemy of the people. RAZ: So now that we're living in an era of fake news, how do we even begin to understand who's manipulating whom? Here's Ali Velshi on the TED stage. (SOUNDBITE OF TED TALK) VELSHI: Part of the problem is that when the president of the United States is encouraging his supporters to believe that the media is not just out of touch or somewhat ineffective but it's actually lying, it causes a problem. And that's just one in a range of problems that are caused by this fake news phenomenon. At its lowest level, it's a time suck. It confuses you. It causes you to spend your time trying to discern between fake news and real news. And I think over time, it can blunt your ability to actually do so. I'll give you an example. A BuzzFeed study said that in 2016, of the top 20 fake news stories on Facebook, they had 8. 7 million shares, comments, reactions. Of the top 20 real news stories by major news organizations, they had 1. 7 million fewer. So fake news is crowding out real news. It means that journalists like me, instead of following other stories and giving you new journalism and telling you stories about new things, we're busy debunking myths. And that's part of the problem that we've got. (SOUNDBITE OF MUSIC) RAZ: When did you start to notice that just objectively false news stories, lies sort of masking as real news stories, were happening and were starting to influence people? VELSHI: So I had known, as a journalist, that there were websites that were peddling misinformation or false information. And I'd certainly known it from other countries. So, for instance, I covered - not in person, but from here - I covered the war in Rwanda. And that was almost entirely fueled by what we now know to be fake news. It was radio stations that would perpetuate myths against a particular ethnic group and would do that. And when I studied it more, I found out that that happened in Nazi Germany a lot. And it's actually pretty pervasive. But we assumed that with the degree of digital penetration we have in the United States, people had the wherewithal to say, oh, that's a lie or this is a kooky conspiracy. RAZ: 'Cause I can just look it up. I could just look it up. VELSHI: I could look it up, right. And one thing that I have learned is that a lot of people don't triangulate. When I say triangulate, they don't have three independent reference points in which to say, oh, that's interesting. I listen to NPR. I read the Wall Street Journal. And I listen to this radio show. And only the radio show is saying that Hillary Clinton is running a sex slave ring out of a basement of a pizza parlor in suburban D. C. Strange that the other ones wouldn't cover that because you'd think that was a good story. And if you don't know that there are other sources who are reporting on something differently or not reporting on it at all, you don't necessarily know that your news source might not be telling you the truth. And not only that, speaking of manipulation, you are now so beholden to that news source, you're so into it that you will be convinced that the others are lying to you. (SOUNDBITE OF TED TALK) VELSHI: On December 4, I tweeted this out. And notice at the bottom it was retweeted 11,000 times. I tweeted - breaking news, the U. S. Army Corps of Engineers halts the Dakota Access Pipeline work, telling the Standing Rock Reservation that the current route for the pipeline will be denied. This was a very controversial issue. I had this news earlier than most people did, which is why it spread so many times because people wanted to distribute this information. But one of the first responses I got to this tweet was, what's your source? Now, come on. I'm not a journalism student. I'm a veteran journalist in my 24th year of this business. If I spread breaking news that is false or wrong, I am going to at the very least get disciplined and I could actually get fired. But increasingly, I am getting pushback on social media from people who accuse me of purveying fake news. There will - if you put in my name on, you know, my handle and fake news - #fakenews - you'll see things show up. And when you de-legitimize journalism and when you de-legitimize facts and when you do that, you create a vacuum in one of the most important checks in civil, economic and political discourse. (SOUNDBITE OF MUSIC) VELSHI: It's very, very dangerous. It worries me a great deal because, you know, in years gone by, I actually worried about being accurate. Now I worry about being accurate as much as I always did, possibly more so. But I also worry about the accusation that comes on Twitter with the hashtag #fakenews. Anybody who doesn't agree with my perspective now labels me a liar. And how do I deal with that? RAZ: Ali, I hear you. I hear your commitment and your passion and all of these things you're saying, but it seems like you're on the losing side. It seems like manipulative news is winning. VELSHI: Yeah. And as a numbers guy, I would say that that's quite possible. But they are winning because the parties in play have not acknowledged that they're winning. They have not sort of said it. Facebook is starting to face that reality. Google is looking at it. We're looking at the money that is made. It just pays better to have fake news. Fake news takes none of the resources that it takes for me to do a story, doesn't need the producers. If you're making stuff up, you don't actually need fact checkers and researchers and people like that. It is much cheaper to make fake news. And it's much more lucrative because you don't have to actually make people want to read the headline because you've invented the headline. So once we all decide that this is really dangerous, Facebook will build the right algorithms and they'll re-do their revenue streams so that they're not rewarding that kind of dishonest behavior. We'll all start to figure it out. And I think we'll be able to shore up our end and push forward and change things. (SOUNDBITE OF TED TALK) VELSHI: Remember what journalism is meant to do. It has two purposes. The first one is to bear witness, to simply be there to say that something is happening. But the second one is more important, it's to hold power to account. And together, let's not go down a road where we end up in a world where not only are we not speaking truth to power but we're not even able to discern the truth. Thank you. (APPLAUSE) RAZ: Ali Velshi. He's an anchor and co-host at MSNBC. You can see Ali's full talk at ted. npr. org. On the show today, ideas about how our actions, our thoughts, even our memories can be manipulated. (SOUNDBITE OF MUSIC)", "section": "TED Radio Hour", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-10-13-557428061": {"title": "Steve Ramirez: If We Could Erase Memories ... Should We? : NPR", "url": "https://www.npr.org/2017/10/13/557428061/steve-ramirez-if-we-could-erase-memories-should-we", "author": "No author found", "published_date": "2017-10-13", "content": "GUY RAZ, HOST: So we've just been hearing from Elizabeth about how easy it is to manipulate memories through the power of suggestion. But what if we could take it one step further? (SOUNDBITE OF MUSIC)RAZ: So, Steve, first of all, introduce yourself. Tell me your first and last name, and what do you do? STEVE RAMIREZ: Sure. My name's Steve Ramirez, and I'm an assistant professor of neuroscience at Boston University. RAZ: And Steve's research is focused on a different kind of memory manipulation, and his interest in this, it all began with a breakup. RAMIREZ: Yeah. So it turns out breakups are not fun. RAZ: It was during his first year of grad school. RAMIREZ: And I was going through a pretty, like, I would say traumatic in quotes breakup. RAZ: And during that breakup, Steve started to relate to a character he'd seen in a movie, \"Eternal Sunshine Of The Spotless Mind\" with Jim Carrey. RAMIREZ: And Kate Winslet. RAZ: Kate Winslet, of course, yeah. And what's that story again? RAMIREZ: Yeah. So the premise is that, you know, this is sometime in the near future where you can go in and erase memories. (SOUNDBITE OF FILM, \"ETERNAL SUNSHINE OF THE SPOTLESS MIND\")JIM CARREY: (As Joel Barish) She's there with this guy. And she looks at me like she doesn't even know who I am. RAMIREZ: And then this couple that recently broke up was so debilitated by their once-fond memories of each other that Jim Carrey's character wants to go in and have a small procedure where they erase those memories. (SOUNDBITE OF FILM, \"ETERNAL SUNSHINE OF THE SPOTLESS MIND\")UNIDENTIFIED ACTOR #1: (As character) Actually creating a map of your brain. UNIDENTIFIED ACTOR #2: (As character) OK. Let's get started. RAMIREZ: And then, as those memories are being erased, he starts realizing like maybe - maybe I don't want to erase them, or maybe if I do erase them, it's going to change my identity. (SOUNDBITE OF FILM, \"ETERNAL SUNSHINE OF THE SPOTLESS MIND\")CARREY: (As Joel Barish) Please, let me keep this memory, just this one. RAMIREZ: Are you doomed to repeat the past if you can't remember it? So the premise of the movie is, would you do it? RAZ: You are a neuroscientist. You study the brain. RAMIREZ: Yes. RAZ: Is that - is that movie, like, plausible in any way? RAMIREZ: So yes and no. The idea that you can erase a memory, like, yeah. I mean, like, we - you can see cases of amnesia that happens during a particular kind of brain damage or Alzheimer's or things like that. So we know that memories can be erased. It's just a matter of how. Like, what's - what's the intervention in the brain that's leading to memory erasure? And in the movie, it kind of throws the baby out with the bathwater a little bit too much because you don't have to get rid of the entire memory of this person and the breakup and the sights and sounds and smells. So given what we know about neuroscience these days, we can go in and try to suppress, for example, the emotional components of a memory but leaving the memory of what happened intact. RAZ: So that difficult breakup Steve had in college, it eventually led him to design a research experiment a lot like the one in the movie. He tells a story on the TED stage. And just a quick note - Steve was joined onstage by his former collaborator Xu Liu, who sadly passed away in 2015. (SOUNDBITE OF TED TALK)RAMIREZ: For the longest time, all I would do is recall the memory of this person over and over again, wishing that I could get rid of that gut-wrenching, visceral, blah feeling. Now, as it turns out, I'm a neuroscientist, so I knew that the memory of that person and the awful emotional undertones that color in that memory are largely mediated by separate brain systems. And so I thought, what if we could go to the brain and edit out that nauseating feeling but while keeping the memory of that person intact? And then I realized maybe that's a little bit lofty for now, so what if we could start off by going into the brain and just finding a single memory to begin with? Could we jumpstart that memory back to life, maybe even play with the contents of that memory? All that said, there is one person in the entire world right now that I really hope is not watching this talk. (LAUGHTER)XU LIU: As neuroscientists, we're working the lab with mice trying to understand how memory works. And today, we hope to convince you that now we're actually able to activate a memory in the brain at the speed of light. To do this, there's only two simple steps to follow. First, you find and label a memory in the brain, and then, you activate it with a switch - as simple as that. (LAUGHTER)RAZ: Well, their experiment was a little more complicated than that. Basically, Steve and Xu brought a bunch of mice to their lab and then looked at the memory region of their brains called the hippocampus, and then they shot pulses of light into certain cells that were associated with a specific memory. The idea was to implant a new memory in place of the old one. It's a technique called optogenetics. RAMIREZ: Opto meaning light and then genetics, of course, because genetics. Like, that's how we go in and start engineering these brain cells. And it's literally shooting a laser into the brain. It's a small optic fiber that's about the width of a cocktail straw, and you can gently nestle it in whatever brain area you would like and then shoot light onto that brain area and then see what happens when you turn those brain cells on. And we did that successfully with a memory. RAZ: Oh, wait, wait, hold on one second. What was the memory you were trying to reactivate? Like - I don't know - like, the mouse was, like, eating a big piece of cheese or something like that. RAMIREZ: (Laughter) So mice can form a million and one different kinds of memories. But we wanted to start with one where we could say, OK, the animal looks like it's recalling the memory or not. Like, we wanted it to be as binary as it gets. And to do that, we chose to try to activate a mildly negative memory and not because we are evil scientists in white coats and you want to give these mice a negative experience. No, it's that recalling a negative memory in animals is easier to look at and say, well, if the animal is recalling a negative memory, usually what they do is they just huddle in a corner and remain immobile. We call it freezing behavior because the animal looks like it's freezing in place. So we were trying to reactivate a freezing response. Like, did the animal freeze when we turned the light on? Because, if so, it begins to support the idea that the animal's recalling a negative memory, which we had successfully demonstrated. RAZ: Right. So - OK, so the mouse freaks out or gets really scared because all of a sudden you've probably triggered a memory of it being, you know, cornered by a cat or something. I watched a lot of \"Tom And Jerry. \" But who knows what it was. It was some bad experience. And then what happened when you removed the shining light from the brain? RAMIREZ: Then the behavior goes back to normal. It doesn't show evidence of recalling a memory anymore. Now, that's good and bad. So that's good because it means, you know, we can say that those effects are, quote, unquote, \"reversible\" because you can induce memory and then you can reverse it and go back to some kind of baseline. It's not good if you're trying to reprogram the brain permanently and especially in a therapeutic manner, which is some of the stuff that my lab currently does now, which is what if you turned those brain cells on and off a lot? What if you chronically stimulate those brain cells to try to induce some kind of therapeutic-like changes in the brain? RAZ: Yeah. I mean, you could imagine. And we're not there yet. We're very far away from this. But you could imagine taking somebody who experienced a trauma or a veteran from war who was suffering from PTSD and activating neutral memory in their brain so as to prevent them from re-experiencing that trauma. RAMIREZ: So exactly. And it's not at all crazy because it's something that - you know, we're not going to go in and start doing optogenetics in human brains to try to manipulate memories anytime soon. But what we try to do is say - well, OK, so mouse brains are like in 1988 - I don't know - Toyota Camry. And then human brains are probably like a 2030 Lamborghini. So they work slightly differently, but the principles of how wheels move, the principles of how an engine starts are still there. They're still conserved. So we can still learn a lot about human brains by having an ongoing dialogue between rodent researchers and human brain researchers. (SOUNDBITE OF TED TALK)RAMIREZ: And for me personally, I see a world where we can reactivate any kind of memory that we'd like. I also see a world where we can erase unwanted memories. Now, I even see a world where editing memories is something of a reality because we're living in a time where it's possible to pluck questions from the tree of science fiction and to ground them in experimental reality. And finally, what do we make of all this? How do we push this technology forward? These are the questions that should not remain just inside of the lab. So let's think together as a team about what this all means and where we can and should go from here. (SOUNDBITE OF MUSIC)RAZ: I mean, you have to think that this technology could fall into the wrong hands. I mean, somebody could want to implant false memories in a person or eliminate important memories that could bear witness. I mean, that's the path we're heading down. RAMIREZ: You know, the way I think about it is everything under the sun could be used for good and bad. And now - you know, Mark Twain has this great quote that history doesn't repeat itself but it does rhyme. So we could take lessons from the history of science and ask - the last time technological game-changers happened, what did people do good? And what did people do bad? And, like, when it went bad, why did it go bad? So for instance, one thing that we can take a lesson from is from the Human Genome Project, which, in the '80s, was a humongous buzz. And then it was this race to sequence the human genome. And then immediately, of course, people were thinking like - well, what if we can modify our own genomes? Like, this smells a lot like eugenics. Like, how do we prevent that from happening? And what happens is that conversation starts two decades before the human genome was even sequenced. And by starting that conversation 20 years ago, you have the social and ideally legal infrastructure to prevent its misuse. So we can do the same thing with manipulating memories now - that by worrying about it being misused, we can have this conversation now - two, three decades in advance of whenever something like this is possible in people - and when Day 0 gets there, we'll have enough social and legal infrastructure where it's on everybody's minds and ideally keep it in a regulated and morally responsible manner. RAZ: But I mean, even if we have all the right conversations. I mean, even if we don't misuse this technology, I'm still a little bit troubled by the potential of this because it suggests that nothing is going to be real. Like, everything could potentially be falsified or manipulated or invented. RAMIREZ: And I think that, in that case, you know we basically - we reinvent ourselves daily with the new memories that we form. And I think it's more of - ideally, we could embrace the dynamism that is memory. Or, like, we can embrace that - by being in a reconstructive process, for instance, some people think that - or have shown, for instance, that the same machinery that helps us recall memories, such as the hippocampus, by and large is not just the same machinery that's responsible for false memories, but it's also the same machinery that lets us imagine the future and lets us put ourselves in future scenarios. And then, in that case, having a reconstructive, you know, chalkboard there is a good thing because we can put ourselves, in our mind's eye, in future situations. And we can imagine what tomorrow is going to be like. And we can imagine what we're going to do and recombine elements of our past into something new, into something creative. So there is something to say about - like, the fact that memory is modifiable might also permit for us to be flexible in the way that we imagine the future, which, you know, sort of is one of the core things that define us as humans. (SOUNDBITE OF MUSIC)RAZ: Steve Ramirez - he's an assistant professor of neuroscience at Boston University. You can watch the full talk he gave with Xu Liu at ted. com. (SOUNDBITE OF SONG, \"HIDDEN PERSUASION\")FRANK SINATRA: (Singing) For real - your hidden persuasion seems quite sincere. Perhaps my evasion is meaningless fear. RAZ: Hey, thanks for listening to our show, Manipulation, this week. If you want to find out more about who was on it, go to ted. npr. org. To see hundreds more TED Talks, check out ted. com or the TED app. And you can listen to this show anytime by subscribing to our podcast. Do it now on Apple Podcasts or however you get your podcasts. Our production staff here at NPR includes Jeff Rogers, Sanaz Meshkinpour, Jinae West, Neva Grant, Rund Abdelfatah and Rachel Faulkner with help from Daniel Shukin and Tony Lu. Our intern is Benjamin Klempay. Our partners at TED are Chris Anderson, Colin Helms, Anna Phelan and Janet Lee. I'm Guy Raz, and you've been listening to ideas worth spreading right here on the TED Radio Hour from NPR. (SOUNDBITE OF FRANK SINATRA'S \"HIDDEN PERSUASION\") GUY RAZ, HOST:  So we've just been hearing from Elizabeth about how easy it is to manipulate memories through the power of suggestion. But what if we could take it one step further? (SOUNDBITE OF MUSIC) RAZ: So, Steve, first of all, introduce yourself. Tell me your first and last name, and what do you do? STEVE RAMIREZ: Sure. My name's Steve Ramirez, and I'm an assistant professor of neuroscience at Boston University. RAZ: And Steve's research is focused on a different kind of memory manipulation, and his interest in this, it all began with a breakup. RAMIREZ: Yeah. So it turns out breakups are not fun. RAZ: It was during his first year of grad school. RAMIREZ: And I was going through a pretty, like, I would say traumatic in quotes breakup. RAZ: And during that breakup, Steve started to relate to a character he'd seen in a movie, \"Eternal Sunshine Of The Spotless Mind\" with Jim Carrey. RAMIREZ: And Kate Winslet. RAZ: Kate Winslet, of course, yeah. And what's that story again? RAMIREZ: Yeah. So the premise is that, you know, this is sometime in the near future where you can go in and erase memories. (SOUNDBITE OF FILM, \"ETERNAL SUNSHINE OF THE SPOTLESS MIND\") JIM CARREY: (As Joel Barish) She's there with this guy. And she looks at me like she doesn't even know who I am. RAMIREZ: And then this couple that recently broke up was so debilitated by their once-fond memories of each other that Jim Carrey's character wants to go in and have a small procedure where they erase those memories. (SOUNDBITE OF FILM, \"ETERNAL SUNSHINE OF THE SPOTLESS MIND\") UNIDENTIFIED ACTOR #1: (As character) Actually creating a map of your brain. UNIDENTIFIED ACTOR #2: (As character) OK. Let's get started. RAMIREZ: And then, as those memories are being erased, he starts realizing like maybe - maybe I don't want to erase them, or maybe if I do erase them, it's going to change my identity. (SOUNDBITE OF FILM, \"ETERNAL SUNSHINE OF THE SPOTLESS MIND\") CARREY: (As Joel Barish) Please, let me keep this memory, just this one. RAMIREZ: Are you doomed to repeat the past if you can't remember it? So the premise of the movie is, would you do it? RAZ: You are a neuroscientist. You study the brain. RAMIREZ: Yes. RAZ: Is that - is that movie, like, plausible in any way? RAMIREZ: So yes and no. The idea that you can erase a memory, like, yeah. I mean, like, we - you can see cases of amnesia that happens during a particular kind of brain damage or Alzheimer's or things like that. So we know that memories can be erased. It's just a matter of how. Like, what's - what's the intervention in the brain that's leading to memory erasure? And in the movie, it kind of throws the baby out with the bathwater a little bit too much because you don't have to get rid of the entire memory of this person and the breakup and the sights and sounds and smells. So given what we know about neuroscience these days, we can go in and try to suppress, for example, the emotional components of a memory but leaving the memory of what happened intact. RAZ: So that difficult breakup Steve had in college, it eventually led him to design a research experiment a lot like the one in the movie. He tells a story on the TED stage. And just a quick note - Steve was joined onstage by his former collaborator Xu Liu, who sadly passed away in 2015. (SOUNDBITE OF TED TALK) RAMIREZ: For the longest time, all I would do is recall the memory of this person over and over again, wishing that I could get rid of that gut-wrenching, visceral, blah feeling. Now, as it turns out, I'm a neuroscientist, so I knew that the memory of that person and the awful emotional undertones that color in that memory are largely mediated by separate brain systems. And so I thought, what if we could go to the brain and edit out that nauseating feeling but while keeping the memory of that person intact? And then I realized maybe that's a little bit lofty for now, so what if we could start off by going into the brain and just finding a single memory to begin with? Could we jumpstart that memory back to life, maybe even play with the contents of that memory? All that said, there is one person in the entire world right now that I really hope is not watching this talk. (LAUGHTER) XU LIU: As neuroscientists, we're working the lab with mice trying to understand how memory works. And today, we hope to convince you that now we're actually able to activate a memory in the brain at the speed of light. To do this, there's only two simple steps to follow. First, you find and label a memory in the brain, and then, you activate it with a switch - as simple as that. (LAUGHTER) RAZ: Well, their experiment was a little more complicated than that. Basically, Steve and Xu brought a bunch of mice to their lab and then looked at the memory region of their brains called the hippocampus, and then they shot pulses of light into certain cells that were associated with a specific memory. The idea was to implant a new memory in place of the old one. It's a technique called optogenetics. RAMIREZ: Opto meaning light and then genetics, of course, because genetics. Like, that's how we go in and start engineering these brain cells. And it's literally shooting a laser into the brain. It's a small optic fiber that's about the width of a cocktail straw, and you can gently nestle it in whatever brain area you would like and then shoot light onto that brain area and then see what happens when you turn those brain cells on. And we did that successfully with a memory. RAZ: Oh, wait, wait, hold on one second. What was the memory you were trying to reactivate? Like - I don't know - like, the mouse was, like, eating a big piece of cheese or something like that. RAMIREZ: (Laughter) So mice can form a million and one different kinds of memories. But we wanted to start with one where we could say, OK, the animal looks like it's recalling the memory or not. Like, we wanted it to be as binary as it gets. And to do that, we chose to try to activate a mildly negative memory and not because we are evil scientists in white coats and you want to give these mice a negative experience. No, it's that recalling a negative memory in animals is easier to look at and say, well, if the animal is recalling a negative memory, usually what they do is they just huddle in a corner and remain immobile. We call it freezing behavior because the animal looks like it's freezing in place. So we were trying to reactivate a freezing response. Like, did the animal freeze when we turned the light on? Because, if so, it begins to support the idea that the animal's recalling a negative memory, which we had successfully demonstrated. RAZ: Right. So - OK, so the mouse freaks out or gets really scared because all of a sudden you've probably triggered a memory of it being, you know, cornered by a cat or something. I watched a lot of \"Tom And Jerry. \" But who knows what it was. It was some bad experience. And then what happened when you removed the shining light from the brain? RAMIREZ: Then the behavior goes back to normal. It doesn't show evidence of recalling a memory anymore. Now, that's good and bad. So that's good because it means, you know, we can say that those effects are, quote, unquote, \"reversible\" because you can induce memory and then you can reverse it and go back to some kind of baseline. It's not good if you're trying to reprogram the brain permanently and especially in a therapeutic manner, which is some of the stuff that my lab currently does now, which is what if you turned those brain cells on and off a lot? What if you chronically stimulate those brain cells to try to induce some kind of therapeutic-like changes in the brain? RAZ: Yeah. I mean, you could imagine. And we're not there yet. We're very far away from this. But you could imagine taking somebody who experienced a trauma or a veteran from war who was suffering from PTSD and activating neutral memory in their brain so as to prevent them from re-experiencing that trauma. RAMIREZ: So exactly. And it's not at all crazy because it's something that - you know, we're not going to go in and start doing optogenetics in human brains to try to manipulate memories anytime soon. But what we try to do is say - well, OK, so mouse brains are like in 1988 - I don't know - Toyota Camry. And then human brains are probably like a 2030 Lamborghini. So they work slightly differently, but the principles of how wheels move, the principles of how an engine starts are still there. They're still conserved. So we can still learn a lot about human brains by having an ongoing dialogue between rodent researchers and human brain researchers. (SOUNDBITE OF TED TALK) RAMIREZ: And for me personally, I see a world where we can reactivate any kind of memory that we'd like. I also see a world where we can erase unwanted memories. Now, I even see a world where editing memories is something of a reality because we're living in a time where it's possible to pluck questions from the tree of science fiction and to ground them in experimental reality. And finally, what do we make of all this? How do we push this technology forward? These are the questions that should not remain just inside of the lab. So let's think together as a team about what this all means and where we can and should go from here. (SOUNDBITE OF MUSIC) RAZ: I mean, you have to think that this technology could fall into the wrong hands. I mean, somebody could want to implant false memories in a person or eliminate important memories that could bear witness. I mean, that's the path we're heading down. RAMIREZ: You know, the way I think about it is everything under the sun could be used for good and bad. And now - you know, Mark Twain has this great quote that history doesn't repeat itself but it does rhyme. So we could take lessons from the history of science and ask - the last time technological game-changers happened, what did people do good? And what did people do bad? And, like, when it went bad, why did it go bad? So for instance, one thing that we can take a lesson from is from the Human Genome Project, which, in the '80s, was a humongous buzz. And then it was this race to sequence the human genome. And then immediately, of course, people were thinking like - well, what if we can modify our own genomes? Like, this smells a lot like eugenics. Like, how do we prevent that from happening? And what happens is that conversation starts two decades before the human genome was even sequenced. And by starting that conversation 20 years ago, you have the social and ideally legal infrastructure to prevent its misuse. So we can do the same thing with manipulating memories now - that by worrying about it being misused, we can have this conversation now - two, three decades in advance of whenever something like this is possible in people - and when Day 0 gets there, we'll have enough social and legal infrastructure where it's on everybody's minds and ideally keep it in a regulated and morally responsible manner. RAZ: But I mean, even if we have all the right conversations. I mean, even if we don't misuse this technology, I'm still a little bit troubled by the potential of this because it suggests that nothing is going to be real. Like, everything could potentially be falsified or manipulated or invented. RAMIREZ: And I think that, in that case, you know we basically - we reinvent ourselves daily with the new memories that we form. And I think it's more of - ideally, we could embrace the dynamism that is memory. Or, like, we can embrace that - by being in a reconstructive process, for instance, some people think that - or have shown, for instance, that the same machinery that helps us recall memories, such as the hippocampus, by and large is not just the same machinery that's responsible for false memories, but it's also the same machinery that lets us imagine the future and lets us put ourselves in future scenarios. And then, in that case, having a reconstructive, you know, chalkboard there is a good thing because we can put ourselves, in our mind's eye, in future situations. And we can imagine what tomorrow is going to be like. And we can imagine what we're going to do and recombine elements of our past into something new, into something creative. So there is something to say about - like, the fact that memory is modifiable might also permit for us to be flexible in the way that we imagine the future, which, you know, sort of is one of the core things that define us as humans. (SOUNDBITE OF MUSIC) RAZ: Steve Ramirez - he's an assistant professor of neuroscience at Boston University. You can watch the full talk he gave with Xu Liu at ted. com. (SOUNDBITE OF SONG, \"HIDDEN PERSUASION\") FRANK SINATRA: (Singing) For real - your hidden persuasion seems quite sincere. Perhaps my evasion is meaningless fear. RAZ: Hey, thanks for listening to our show, Manipulation, this week. If you want to find out more about who was on it, go to ted. npr. org. To see hundreds more TED Talks, check out ted. com or the TED app. And you can listen to this show anytime by subscribing to our podcast. Do it now on Apple Podcasts or however you get your podcasts. Our production staff here at NPR includes Jeff Rogers, Sanaz Meshkinpour, Jinae West, Neva Grant, Rund Abdelfatah and Rachel Faulkner with help from Daniel Shukin and Tony Lu. Our intern is Benjamin Klempay. Our partners at TED are Chris Anderson, Colin Helms, Anna Phelan and Janet Lee. I'm Guy Raz, and you've been listening to ideas worth spreading right here on the TED Radio Hour from NPR. (SOUNDBITE OF FRANK SINATRA'S \"HIDDEN PERSUASION\")", "section": "TED Radio Hour", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-10-13-557418328": {"title": "Tristan Harris: Do Our Devices Control More Than We Think? : NPR", "url": "https://www.npr.org/2017/10/13/557418328/tristan-harris-do-our-devices-control-more-than-we-think", "author": "No author found", "published_date": "2017-10-13", "content": "GUY RAZ, HOST: It's the TED Radio Hour from NPR. I'm Guy Raz. So these days, our attention is pretty much up for grabs. (SOUNDBITE OF TYPING ON SMARTPHONE, SNAPCHAT ALERTS)RAZ: And the stuff that's trying the hardest to get it. . . (SOUNDBITE OF TYPING ON SMARTPHONE, SNAPCHAT ALERTS)RAZ: . . . Is usually right at our fingertips. And while we think we're the ones who get to decide how to spend our time, is that really the truth? TRISTAN HARRIS: You know, what - what does it mean to manipulate people, to persuade or pull on - on their instincts? RAZ: This is Tristan Harris, and Tristan used to be part of the tech industry. He was a design ethicist at Google. HARRIS: And I was there for about a year working first on, you know, sort of assistant-like features in Inbox, which became sort of the next version of Gmail. RAZ: But then after basically spending his whole career in Silicon Valley, something in Tristan changed. HARRIS: As much as we wanted to make life better for people and explain things to people, at the end of the day, it was about capturing attention. You know, how would we hook people into spending more time on the screen or driving more page views or getting people to click on ads? And I didn't like that. And so you started to see technology not as a vehicle for improving people's lives, but really as a means to persuade people to do things. And so persuasion became the dominant way that I came to see everything in the world. You know, you get disenchanted when you see how much of all this time that we spend in front of screens and clicking on these buttons and inviting people to connect and accepting invitations and, you know, liking back articles and getting back to people, and you just say, what is this adding up to? You know, what - what - how is this actually better for life? RAZ: On the show today, ideas about manipulation, about the things that can make us believe and act in certain ways, sometimes without us even knowing, from our addiction to smartphones to the rise of fake news, even the ways we remember and experience our lives. And for Tristan Harris, manipulation is about how we use technology and how some tech companies use us. HARRIS: You know, it's not like a smartphone is a device that you access. You don't access your smartphone. You live by your smartphone. People wake up in the morning and it's, like, 80 percent of people, the first thing they do, they turn out of bed and they - they pull their smartphone out, right? And they see what's on the screen. And the second, you know, that that happens, it's like they're programming their whole mind and their day to think about things in a certain way. RAZ: If you are - if you use a smartphone or you are - or you use the internet today, are you being manipulated? HARRIS: I think by definition to look at the screen, to use the internet, thoughts and choices enter the flow of our experience that were not authored by us. And more and more of our thoughts during the day come from the things that we have been thinking about and seeing from the screens that we're constantly checking. You know, you don't have to be using the screen every moment for it to be guiding your thoughts, right? And so invisibly, the entire - you know, it's like the David Foster Wallace \"This Is Water\" speech, you know? We're swimming in this water. We're the fish. And you ask the other fish, you know, what do you - how do you like this water we're swimming in? And he says, what's water? You know, we're swimming in this digital environment that is created, you know, and handcrafted by a handful of companies with deliberate goals to capture human attention. And now you have two billion people, which is like, what is it, 25 percent of the world's population and 90 percent of the world's GDP, whose thoughts are shaped by this handful of 20 to 40, 35-year-old mostly engineers and designers in California. Neil Postman, you know, one of my favorite deep thinkers about how technology affects society, said, what is the problem for which this technology is the solution? RAZ: Tristan Harris laid out his case on the TED stage. (SOUNDBITE OF TED TALK)HARRIS: The internet is not evolving at random. The reason it feels like it's sucking us in the way it is is because of this race for attention. We know where this is going. Technology is not neutral. And it becomes this race to the bottom of the brainstem of who can go lower to get it. Let me give you an example of Snapchat. If you didn't know, Snapchat is the No. 1 way that teenagers in the United States communicate. So if you're like me and you use text messages to communicate, Snapchat is that for teenagers. And there's, like, a hundred million of them that use it. And they invented a feature called Snapstreaks which shows the number of days in a row that two people have communicated with each other. In other words, what they just did is they gave two people something they don't want to lose. Because if you're a teenager and you have 150 days in a row, you don't want that to go away. And so think of the little blocks of time that that schedules in kids minds. This isn't theoretical. When kids go on vacation, it's been shown they give their passwords up to five other friends to keep their Snapstreaks going even when they can't do it. And they have, like, 30 of these things, and so they have to get through photo - taking photos of just pictures or walls or feelings just to get through their day. So it's not even like they're having real conversations. We have a temptation to think about this as, oh, they're just using, you know, Snapchat the way we used to gossip on the telephone. It's probably OK. Well, what this misses is that in the 1970s when you were just gossiping on the telephone, there wasn't a hundred engineers on the other side of the screen who knew exactly how your psychology worked and orchestrated you into a double bind with each other. (SOUNDBITE OF MUSIC)RAZ: I mean, it's like it's - (laughter). It's a - it's a little bit like - and I don't want to take this analogy too far - of how tobacco companies have known for a long time how to grow, you know, tobacco with either no or low nicotine. But - but they didn't. They actually increased the amount of nicotine. HARRIS: That's right. And this is even worse than that. And I'm not trying to be alarmist, but the reason why it's different than just tobacco is that it's actually social. You know, there's always this narrative - you know, we always worry about new technologies. People worried about newspapers on the subway, we're not talking to each other. People worried about TV, we're just going to amuse ourselves to death, which is, honestly, partially true. You know, human beings are resilient. But what this misses is there's three new elements that get missed in this conversation. The first is that we've never had a medium that was so totalizing. Two billion people checking 150 times a day from the moment that they get up in the morning to every bathroom break, to every coffee line, to every, you know, going to sleep at night. So it's a totalizing kind of environment. You know, we go from using a product to being jacked into the matrix. Except the matrix is this sort of soft, invisible matrix that's kind of created by a few different companies, Apple, Google and Facebook. The second one is that it's social, right? TV, radio didn't - didn't say these are where your friends are hanging out and where you've been left out. We never made it easier to show what you should be jealous of in other people's lives. And the last thing is that it's intelligent and personalized, and it gets better every day. So, you know, TV or radio didn't watch what you looked at and then try to dynamically change the course of the television show whereas Facebook is a monolithic AI that basically says, every single time you click, you're teaching us what will keep you here. RAZ: What - I mean, what you're suggesting is that there are a handful of companies, maybe three, four or five, that have more manipulative power over - over the human species than anything or anyone has had at any time in our history. HARRIS: Absolutely. And this is the thing that people miss. It's, like, why are we so obsessed with governments? I mean, two billion people use Facebook every day. That's more than the number of followers of Christianity. One-point-five billion people use YouTube every day. Every day. And that's more than the number of followers of Islam. So these things have an enormous amount of influence, more than any other government, over people's daily thoughts and beliefs. So, you know, for everything we want governments to be held accountable to, why in the world would we not have something that holds technology companies accountable to human values as opposed to just capturing attention, which is the only thing that they answer to, is this stock market in capturing attention? RAZ: Well, I mean, that's a thing. I mean, you're talking about this incredible ability to manipulate our thoughts and our choices. But I think in response these companies would say, well, these are choices people make. We live in a - in a capitalistic society. I mean, we are businesses, and of course we're vying for people's attention because that translates into - into money. This is an old story. This isn't new. Businesses have been doing this since time immemorial. HARRIS: Yeah. Well, this is the classic defense that the companies make, is, if you don't like the product just use a different product. But this is so dishonest. (Laughter). Because if you're a teenager and all of your friends, all the conversations they have, all the parties that they go to, if it's through Snapchat, are you going to choose not to use Snapchat? You know, the - I've studied cults in my research on persuasion, and I've actually gone into cults. And one of the things that cults do is they pull on you by pulling on all your friends. If they can - if they can make it so that all of your friends are just the people who are in the cult, you can't leave the cult. And the thing about social media is that all of your friends are in the cult. (SOUNDBITE OF TED TALK)HARRIS: So I'm here today because the costs are so obvious. I don't know a more urgent problem than this because this problem is underneath all other problems. It's not just taking away our agency to spend our attention and live the lives that we want. It's changing the way that we have our conversations, it's changing our democracy and it's changing our ability to have the conversations and relationships we want with each other. And it affects everyone because a billion people have one of these in their pocket. RAZ: I mean, every time we think that we've - we've sort of cracked the code as humans, like, you know, we've created this thing where you can always be connected to everyone and everything. But every time we seem to introduce something like that, someone figures out how to game it. HARRIS: Yeah. The history of the tech industry is filled with positive intentions and good ideas that are incomplete and game-able, right? And they're incomplete because they don't capture all the other externalities. The more these attention companies profit, they put - they profit while pushing all of the social and inner externalities downstream because it's polluting our inner world and it's polluting our social cohesion and our ability to actually understand each other because we have to agree on reality. If we can't agree on reality then we can't solve some of the most existential threats that face us. And so this is why we have to change the system. This is not, you know, a fun, philosophical conversation. I'm here because this is literally an existential threat to our future and - and to our present. And elections around the world are still being shaped, an entire polarization of societies is being shaped today by this algorithm. And the need for accountability is enormous. RAZ: Tristan Harris. He's a former design ethicist at Google, and he now works at the nonprofit Time Well Spent which is trying to reform the tech industry. You can see Tristan's full talk at ted. com. On the show today, ideas about manipulation. I'm Guy Raz, and you're listening to the TED Radio Hour from NPR. (SOUNDBITE OF MUSIC) GUY RAZ, HOST:  It's the TED Radio Hour from NPR. I'm Guy Raz. So these days, our attention is pretty much up for grabs. (SOUNDBITE OF TYPING ON SMARTPHONE, SNAPCHAT ALERTS) RAZ: And the stuff that's trying the hardest to get it. . . (SOUNDBITE OF TYPING ON SMARTPHONE, SNAPCHAT ALERTS) RAZ: . . . Is usually right at our fingertips. And while we think we're the ones who get to decide how to spend our time, is that really the truth? TRISTAN HARRIS: You know, what - what does it mean to manipulate people, to persuade or pull on - on their instincts? RAZ: This is Tristan Harris, and Tristan used to be part of the tech industry. He was a design ethicist at Google. HARRIS: And I was there for about a year working first on, you know, sort of assistant-like features in Inbox, which became sort of the next version of Gmail. RAZ: But then after basically spending his whole career in Silicon Valley, something in Tristan changed. HARRIS: As much as we wanted to make life better for people and explain things to people, at the end of the day, it was about capturing attention. You know, how would we hook people into spending more time on the screen or driving more page views or getting people to click on ads? And I didn't like that. And so you started to see technology not as a vehicle for improving people's lives, but really as a means to persuade people to do things. And so persuasion became the dominant way that I came to see everything in the world. You know, you get disenchanted when you see how much of all this time that we spend in front of screens and clicking on these buttons and inviting people to connect and accepting invitations and, you know, liking back articles and getting back to people, and you just say, what is this adding up to? You know, what - what - how is this actually better for life? RAZ: On the show today, ideas about manipulation, about the things that can make us believe and act in certain ways, sometimes without us even knowing, from our addiction to smartphones to the rise of fake news, even the ways we remember and experience our lives. And for Tristan Harris, manipulation is about how we use technology and how some tech companies use us. HARRIS: You know, it's not like a smartphone is a device that you access. You don't access your smartphone. You live by your smartphone. People wake up in the morning and it's, like, 80 percent of people, the first thing they do, they turn out of bed and they - they pull their smartphone out, right? And they see what's on the screen. And the second, you know, that that happens, it's like they're programming their whole mind and their day to think about things in a certain way. RAZ: If you are - if you use a smartphone or you are - or you use the internet today, are you being manipulated? HARRIS: I think by definition to look at the screen, to use the internet, thoughts and choices enter the flow of our experience that were not authored by us. And more and more of our thoughts during the day come from the things that we have been thinking about and seeing from the screens that we're constantly checking. You know, you don't have to be using the screen every moment for it to be guiding your thoughts, right? And so invisibly, the entire - you know, it's like the David Foster Wallace \"This Is Water\" speech, you know? We're swimming in this water. We're the fish. And you ask the other fish, you know, what do you - how do you like this water we're swimming in? And he says, what's water? You know, we're swimming in this digital environment that is created, you know, and handcrafted by a handful of companies with deliberate goals to capture human attention. And now you have two billion people, which is like, what is it, 25 percent of the world's population and 90 percent of the world's GDP, whose thoughts are shaped by this handful of 20 to 40, 35-year-old mostly engineers and designers in California. Neil Postman, you know, one of my favorite deep thinkers about how technology affects society, said, what is the problem for which this technology is the solution? RAZ: Tristan Harris laid out his case on the TED stage. (SOUNDBITE OF TED TALK) HARRIS: The internet is not evolving at random. The reason it feels like it's sucking us in the way it is is because of this race for attention. We know where this is going. Technology is not neutral. And it becomes this race to the bottom of the brainstem of who can go lower to get it. Let me give you an example of Snapchat. If you didn't know, Snapchat is the No. 1 way that teenagers in the United States communicate. So if you're like me and you use text messages to communicate, Snapchat is that for teenagers. And there's, like, a hundred million of them that use it. And they invented a feature called Snapstreaks which shows the number of days in a row that two people have communicated with each other. In other words, what they just did is they gave two people something they don't want to lose. Because if you're a teenager and you have 150 days in a row, you don't want that to go away. And so think of the little blocks of time that that schedules in kids minds. This isn't theoretical. When kids go on vacation, it's been shown they give their passwords up to five other friends to keep their Snapstreaks going even when they can't do it. And they have, like, 30 of these things, and so they have to get through photo - taking photos of just pictures or walls or feelings just to get through their day. So it's not even like they're having real conversations. We have a temptation to think about this as, oh, they're just using, you know, Snapchat the way we used to gossip on the telephone. It's probably OK. Well, what this misses is that in the 1970s when you were just gossiping on the telephone, there wasn't a hundred engineers on the other side of the screen who knew exactly how your psychology worked and orchestrated you into a double bind with each other. (SOUNDBITE OF MUSIC) RAZ: I mean, it's like it's - (laughter). It's a - it's a little bit like - and I don't want to take this analogy too far - of how tobacco companies have known for a long time how to grow, you know, tobacco with either no or low nicotine. But - but they didn't. They actually increased the amount of nicotine. HARRIS: That's right. And this is even worse than that. And I'm not trying to be alarmist, but the reason why it's different than just tobacco is that it's actually social. You know, there's always this narrative - you know, we always worry about new technologies. People worried about newspapers on the subway, we're not talking to each other. People worried about TV, we're just going to amuse ourselves to death, which is, honestly, partially true. You know, human beings are resilient. But what this misses is there's three new elements that get missed in this conversation. The first is that we've never had a medium that was so totalizing. Two billion people checking 150 times a day from the moment that they get up in the morning to every bathroom break, to every coffee line, to every, you know, going to sleep at night. So it's a totalizing kind of environment. You know, we go from using a product to being jacked into the matrix. Except the matrix is this sort of soft, invisible matrix that's kind of created by a few different companies, Apple, Google and Facebook. The second one is that it's social, right? TV, radio didn't - didn't say these are where your friends are hanging out and where you've been left out. We never made it easier to show what you should be jealous of in other people's lives. And the last thing is that it's intelligent and personalized, and it gets better every day. So, you know, TV or radio didn't watch what you looked at and then try to dynamically change the course of the television show whereas Facebook is a monolithic AI that basically says, every single time you click, you're teaching us what will keep you here. RAZ: What - I mean, what you're suggesting is that there are a handful of companies, maybe three, four or five, that have more manipulative power over - over the human species than anything or anyone has had at any time in our history. HARRIS: Absolutely. And this is the thing that people miss. It's, like, why are we so obsessed with governments? I mean, two billion people use Facebook every day. That's more than the number of followers of Christianity. One-point-five billion people use YouTube every day. Every day. And that's more than the number of followers of Islam. So these things have an enormous amount of influence, more than any other government, over people's daily thoughts and beliefs. So, you know, for everything we want governments to be held accountable to, why in the world would we not have something that holds technology companies accountable to human values as opposed to just capturing attention, which is the only thing that they answer to, is this stock market in capturing attention? RAZ: Well, I mean, that's a thing. I mean, you're talking about this incredible ability to manipulate our thoughts and our choices. But I think in response these companies would say, well, these are choices people make. We live in a - in a capitalistic society. I mean, we are businesses, and of course we're vying for people's attention because that translates into - into money. This is an old story. This isn't new. Businesses have been doing this since time immemorial. HARRIS: Yeah. Well, this is the classic defense that the companies make, is, if you don't like the product just use a different product. But this is so dishonest. (Laughter). Because if you're a teenager and all of your friends, all the conversations they have, all the parties that they go to, if it's through Snapchat, are you going to choose not to use Snapchat? You know, the - I've studied cults in my research on persuasion, and I've actually gone into cults. And one of the things that cults do is they pull on you by pulling on all your friends. If they can - if they can make it so that all of your friends are just the people who are in the cult, you can't leave the cult. And the thing about social media is that all of your friends are in the cult. (SOUNDBITE OF TED TALK) HARRIS: So I'm here today because the costs are so obvious. I don't know a more urgent problem than this because this problem is underneath all other problems. It's not just taking away our agency to spend our attention and live the lives that we want. It's changing the way that we have our conversations, it's changing our democracy and it's changing our ability to have the conversations and relationships we want with each other. And it affects everyone because a billion people have one of these in their pocket. RAZ: I mean, every time we think that we've - we've sort of cracked the code as humans, like, you know, we've created this thing where you can always be connected to everyone and everything. But every time we seem to introduce something like that, someone figures out how to game it. HARRIS: Yeah. The history of the tech industry is filled with positive intentions and good ideas that are incomplete and game-able, right? And they're incomplete because they don't capture all the other externalities. The more these attention companies profit, they put - they profit while pushing all of the social and inner externalities downstream because it's polluting our inner world and it's polluting our social cohesion and our ability to actually understand each other because we have to agree on reality. If we can't agree on reality then we can't solve some of the most existential threats that face us. And so this is why we have to change the system. This is not, you know, a fun, philosophical conversation. I'm here because this is literally an existential threat to our future and - and to our present. And elections around the world are still being shaped, an entire polarization of societies is being shaped today by this algorithm. And the need for accountability is enormous. RAZ: Tristan Harris. He's a former design ethicist at Google, and he now works at the nonprofit Time Well Spent which is trying to reform the tech industry. You can see Tristan's full talk at ted. com. On the show today, ideas about manipulation. I'm Guy Raz, and you're listening to the TED Radio Hour from NPR. (SOUNDBITE OF MUSIC)", "section": "TED Radio Hour", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-10-15-557417481": {"title": "The Russia Investigations: Facebook Makes Nice, Imbroglio Sucks In More Tech Firms : NPR", "url": "https://www.npr.org/2017/10/15/557417481/the-russia-investigations-facebook-makes-nice-imbroglio-sucks-in-more-tech-firms", "author": "No author found", "published_date": "2017-10-15", "content": "", "section": "National Security", "disclaimer": ""}, "2017-10-16-558160399": {"title": "Hurricane Maria Could Offer A Chance To Build A New Tech Infrastructure In Puerto Rico : NPR", "url": "https://www.npr.org/2017/10/16/558160399/hurricane-maria-could-offer-a-chance-to-build-a-new-tech-infrastructure-in-puert", "author": "No author found", "published_date": "2017-10-16", "content": "MARY LOUISE KELLY, HOST: In Puerto Rico, nearly a month after Hurricane Maria hit, much of the island is still without power or cell phone service or Wi-Fi. That represents a crisis for people living in Puerto Rico, but also maybe an opportunity. That's our topic for this week's All Tech Considered. (SOUNDBITE OF MUSIC)KELLY: Big tech companies are contemplating the chance to build a new tech infrastructure from scratch in Puerto Rico. Ina Fried has been talking to folks at some of those big tech companies. She's chief technology correspondent for Axios. Hi there. Welcome. INA FRIED: Good to be here. KELLY: Which companies are we talking about? Which tech firms are working in Puerto Rico right now? FRIED: It's a lot of the big-name companies you'd expect and a few that you might not. Facebook, Cisco, Google are all there both trying to assist in the rebuilding as well as in the emergency response efforts so far. KELLY: And I heard that some of them are actually - they're kind of shacking up together. They're actually living side by side to try to collaborate. FRIED: There is. There's a group called NetHope that's actually a coalition of the big world charities. And it's the tech arm of those charities. And they pull volunteers from all these different firms. And they've actually rented three houses in Puerto Rico. And so you have people from those companies, yeah, living side by side and working side by side. KELLY: Talk us through some of the ideas that they are coming up with to try to bring some of these services back, and then think big about, if you're trying to rebuild Puerto Rico from scratch, what opportunities are out there. FRIED: The first thing you have to do is get communication in any way that you can. So in the early days, as it's really a rescue, recovery, emergency operation, they used primarily satellite phones because there isn't infrastructure and they need to be able to communicate. But that's expensive and not sustainable. So the next thing they try and do is look for some sort of short- to mid-term operation that doesn't rely on such an expensive technology. And here's where things get interesting. One of the options that's coming to the plate is the parent company of Google, Alphabet, has this idea called Project Loon that comes out of its X research unit. And the idea is to use these high-altitude balloons to connect the cell phones in areas where the infrastructure is down. And they have preliminary approval from the FCC to try this out in Puerto Rico. KELLY: I mean, I'm guessing priority No. 1 is trying to get power restored across the island. It's hard to think about terribly high-tech things if people aren't able to turn their light switch on on their wall. How is that effort going? And what is the thinking as these tech companies move in and try to move that along? FRIED: That's still really slow going. And it's causing, as you mentioned, a lot of follow-on problems. So the water system is actually tied to the power system. So you have the dual problem of they don't have power and they don't have clean water. And those are huge problems. Obviously, a lack of clean water could lead to waterborne diseases, sanitation issues. And the power issue itself, it's hard to do much work. So we're seeing some interesting longer-term things. Tesla's CEO, Elon Musk, tweeted out, hey, can I help? And that actually sparked a discussion with Puerto Rico's governor. And they're looking into whether solar and batteries might be a longer-term solution. There is opportunity here that things, when they do get built back, will be built back significantly better than they were before the hurricane. KELLY: Are you able to gauge whether these tech companies are working together at least for now? Or are they competing? I mean, these are competitors in the tech markets. FRIED: I mean, the really neat thing about this is certainly in the emergency response through NetHope these companies really do work side by side. They set aside their competitive things. And this isn't really a moneymaking opportunity in the short term. It becomes one when we talk about rebuilding. And I think you will see some of the same companies that are working side by side as volunteers today competing for contracts down the road for the actual rebuilding. So they haven't given up on capitalism altogether. KELLY: Well, that prompts my last question, which is, who will pay? Because Puerto Rico is broke, and these technologies are not going to be cheap. FRIED: Yeah, the tech companies aren't going to provide this for free. So, I mean, ultimately it will have to come through either the dollars being allocated for the relief effort or additional investments. These will be costly expenditures. Hopefully the political will will be there to make this happen. But certainly none of these companies are offering to rebuild it for free. KELLY: Ina Fried, thanks so much. FRIED: You're most welcome. KELLY: Ina Fried, chief technology correspondent for Axios, talking about the challenges and opportunities ahead in Puerto Rico. MARY LOUISE KELLY, HOST:  In Puerto Rico, nearly a month after Hurricane Maria hit, much of the island is still without power or cell phone service or Wi-Fi. That represents a crisis for people living in Puerto Rico, but also maybe an opportunity. That's our topic for this week's All Tech Considered. (SOUNDBITE OF MUSIC) KELLY: Big tech companies are contemplating the chance to build a new tech infrastructure from scratch in Puerto Rico. Ina Fried has been talking to folks at some of those big tech companies. She's chief technology correspondent for Axios. Hi there. Welcome. INA FRIED: Good to be here. KELLY: Which companies are we talking about? Which tech firms are working in Puerto Rico right now? FRIED: It's a lot of the big-name companies you'd expect and a few that you might not. Facebook, Cisco, Google are all there both trying to assist in the rebuilding as well as in the emergency response efforts so far. KELLY: And I heard that some of them are actually - they're kind of shacking up together. They're actually living side by side to try to collaborate. FRIED: There is. There's a group called NetHope that's actually a coalition of the big world charities. And it's the tech arm of those charities. And they pull volunteers from all these different firms. And they've actually rented three houses in Puerto Rico. And so you have people from those companies, yeah, living side by side and working side by side. KELLY: Talk us through some of the ideas that they are coming up with to try to bring some of these services back, and then think big about, if you're trying to rebuild Puerto Rico from scratch, what opportunities are out there. FRIED: The first thing you have to do is get communication in any way that you can. So in the early days, as it's really a rescue, recovery, emergency operation, they used primarily satellite phones because there isn't infrastructure and they need to be able to communicate. But that's expensive and not sustainable. So the next thing they try and do is look for some sort of short- to mid-term operation that doesn't rely on such an expensive technology. And here's where things get interesting. One of the options that's coming to the plate is the parent company of Google, Alphabet, has this idea called Project Loon that comes out of its X research unit. And the idea is to use these high-altitude balloons to connect the cell phones in areas where the infrastructure is down. And they have preliminary approval from the FCC to try this out in Puerto Rico. KELLY: I mean, I'm guessing priority No. 1 is trying to get power restored across the island. It's hard to think about terribly high-tech things if people aren't able to turn their light switch on on their wall. How is that effort going? And what is the thinking as these tech companies move in and try to move that along? FRIED: That's still really slow going. And it's causing, as you mentioned, a lot of follow-on problems. So the water system is actually tied to the power system. So you have the dual problem of they don't have power and they don't have clean water. And those are huge problems. Obviously, a lack of clean water could lead to waterborne diseases, sanitation issues. And the power issue itself, it's hard to do much work. So we're seeing some interesting longer-term things. Tesla's CEO, Elon Musk, tweeted out, hey, can I help? And that actually sparked a discussion with Puerto Rico's governor. And they're looking into whether solar and batteries might be a longer-term solution. There is opportunity here that things, when they do get built back, will be built back significantly better than they were before the hurricane. KELLY: Are you able to gauge whether these tech companies are working together at least for now? Or are they competing? I mean, these are competitors in the tech markets. FRIED: I mean, the really neat thing about this is certainly in the emergency response through NetHope these companies really do work side by side. They set aside their competitive things. And this isn't really a moneymaking opportunity in the short term. It becomes one when we talk about rebuilding. And I think you will see some of the same companies that are working side by side as volunteers today competing for contracts down the road for the actual rebuilding. So they haven't given up on capitalism altogether. KELLY: Well, that prompts my last question, which is, who will pay? Because Puerto Rico is broke, and these technologies are not going to be cheap. FRIED: Yeah, the tech companies aren't going to provide this for free. So, I mean, ultimately it will have to come through either the dollars being allocated for the relief effort or additional investments. These will be costly expenditures. Hopefully the political will will be there to make this happen. But certainly none of these companies are offering to rebuild it for free. KELLY: Ina Fried, thanks so much. FRIED: You're most welcome. KELLY: Ina Fried, chief technology correspondent for Axios, talking about the challenges and opportunities ahead in Puerto Rico.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-10-16-558103413": {"title": "After Hurricane Power Outages, Looking To Alaska's Microgrids For A Better Way : NPR", "url": "https://www.npr.org/2017/10/16/558103413/after-hurricane-power-outages-looking-to-alaskas-microgrids-for-a-better-way", "author": "No author found", "published_date": "2017-10-16", "content": "KELLY MCEVERS, HOST: Puerto Rico might want to look north - far north - for one solution to its infrastructure problems. Alaska's remote communities have had to power themselves for decades. One has managed to do that almost entirely on renewable energy. Rachel Waldholz of Alaska's Energy Desk explains. RACHEL WALDHOLZ, BYLINE: Kodiak, Alaska, is one of the busiest fishing ports in the country. And it smells like it. The waterfront is lined with seafood plants. At the Ocean Beauty plant, James Turner gives a tour of the slime line. JAMES TURNER: So we call it the slime line 'cause it's a wet environment. WALDHOLZ: Inside, it's a maze of conveyor belts. There are canning machines, pressure cookers, freezers. The power for all of that is generated right here on the island, mostly from a hydro dam. But 10 years ago, Kodiak had a problem. It was relying more and more on diesel generators, and diesel prices were sky high and unpredictable. Jennifer Richcreek works for the Kodiak Electric Association, the local utility. JENNIFER RICHCREEK: When you have that threat of a diesel bill hanging over your head every month, that is very motivating to find solutions. WALDHOLZ: So the utility set a goal of 95 percent renewable power. They installed six wind turbines and a bank of batteries, and that worked pretty well. But then there was a new challenge at the Kodiak port. (SOUNDBITE OF BELL RINGING)RICK KNIAZIOWSKI: Make sure your hardhats are on pretty tight. It gets a little windy. WALDHOLZ: I am standing way out on the arm of a shipping crane with Rick Kniaziowski. He works for the shipping company Matson. This crane is giant, taller than anything else in sight. And it's electric, a big power hog. If I look down, I can watch the operator lift a container off the cargo ship. Wow, this is so cool (laughter). Every time it does that, it causes a spike in demand on the power grid. That's why back when Kniaziowski first asked the head of the local utility about getting this crane, the answer was no. KNIAZIOWSKI: His eyes got really big and he's like, I just don't see it, Rick. Everyone's TVs are going to brown out, and they're going to either hate you or they're going to hate us. WALDHOLZ: But the utility found a European company that offered a new kind of energy storage - a flywheel. There are two here now, and they look - well, they look like a couple of trailers behind a chain-link fence. But inside they're pretty sci-fi. There's a massive chunk of spinning steel. I'll let Richcreek explain. RICHCREEK: It's in a frictionless vacuum chamber hovered by magnets, which is so cool. WALDHOLZ: The flywheel stores energy as motion and then pumps it out the second a big surge is needed. Kodiak is one of the first places in the world to use a flywheel this way. Altogether, the microgrid on this island operates like an orchestra, each piece watching the rest, responding automatically, millisecond by millisecond. The wind drops suddenly and the flywheel kicks on. As the flywheel slows, the batteries step in. And behind it all, the hydro ramps up. Richcreek says this is the future. RICHCREEK: The solutions are out there. They're outside the box. They may be different. But the industry is changing. WALDHOLZ: The system has drawn interest from around the world, and Kodiak hopes other American communities will take notice, too. For NPR News, I'm Rachel Waldholz in Kodiak, Alaska. MCEVERS: That story comes to us from Alaska's Energy Desk. It's a public media collaboration focused on energy and the environment. KELLY MCEVERS, HOST:  Puerto Rico might want to look north - far north - for one solution to its infrastructure problems. Alaska's remote communities have had to power themselves for decades. One has managed to do that almost entirely on renewable energy. Rachel Waldholz of Alaska's Energy Desk explains. RACHEL WALDHOLZ, BYLINE: Kodiak, Alaska, is one of the busiest fishing ports in the country. And it smells like it. The waterfront is lined with seafood plants. At the Ocean Beauty plant, James Turner gives a tour of the slime line. JAMES TURNER: So we call it the slime line 'cause it's a wet environment. WALDHOLZ: Inside, it's a maze of conveyor belts. There are canning machines, pressure cookers, freezers. The power for all of that is generated right here on the island, mostly from a hydro dam. But 10 years ago, Kodiak had a problem. It was relying more and more on diesel generators, and diesel prices were sky high and unpredictable. Jennifer Richcreek works for the Kodiak Electric Association, the local utility. JENNIFER RICHCREEK: When you have that threat of a diesel bill hanging over your head every month, that is very motivating to find solutions. WALDHOLZ: So the utility set a goal of 95 percent renewable power. They installed six wind turbines and a bank of batteries, and that worked pretty well. But then there was a new challenge at the Kodiak port. (SOUNDBITE OF BELL RINGING) RICK KNIAZIOWSKI: Make sure your hardhats are on pretty tight. It gets a little windy. WALDHOLZ: I am standing way out on the arm of a shipping crane with Rick Kniaziowski. He works for the shipping company Matson. This crane is giant, taller than anything else in sight. And it's electric, a big power hog. If I look down, I can watch the operator lift a container off the cargo ship. Wow, this is so cool (laughter). Every time it does that, it causes a spike in demand on the power grid. That's why back when Kniaziowski first asked the head of the local utility about getting this crane, the answer was no. KNIAZIOWSKI: His eyes got really big and he's like, I just don't see it, Rick. Everyone's TVs are going to brown out, and they're going to either hate you or they're going to hate us. WALDHOLZ: But the utility found a European company that offered a new kind of energy storage - a flywheel. There are two here now, and they look - well, they look like a couple of trailers behind a chain-link fence. But inside they're pretty sci-fi. There's a massive chunk of spinning steel. I'll let Richcreek explain. RICHCREEK: It's in a frictionless vacuum chamber hovered by magnets, which is so cool. WALDHOLZ: The flywheel stores energy as motion and then pumps it out the second a big surge is needed. Kodiak is one of the first places in the world to use a flywheel this way. Altogether, the microgrid on this island operates like an orchestra, each piece watching the rest, responding automatically, millisecond by millisecond. The wind drops suddenly and the flywheel kicks on. As the flywheel slows, the batteries step in. And behind it all, the hydro ramps up. Richcreek says this is the future. RICHCREEK: The solutions are out there. They're outside the box. They may be different. But the industry is changing. WALDHOLZ: The system has drawn interest from around the world, and Kodiak hopes other American communities will take notice, too. For NPR News, I'm Rachel Waldholz in Kodiak, Alaska. MCEVERS: That story comes to us from Alaska's Energy Desk. It's a public media collaboration focused on energy and the environment.", "section": "Energy", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-10-17-557606519": {"title": "How Denver Is Using Lifestyle To Woo Amazon's HQ2 : NPR", "url": "https://www.npr.org/2017/10/17/557606519/denver-failed-to-land-boeing-now-its-using-lifestyle-to-woo-amazon", "author": "No author found", "published_date": "2017-10-17", "content": "RACHEL MARTIN, HOST: Across the country, hundreds of cities are making their pitch to Amazon. City officials have until Thursday to convince Amazon to open their second headquarters in their town. At stake - potentially 50,000 jobs and $5 billion worth of investment. One city that keeps showing up on lists of favorites is Denver. From member station KUNC, Benta Birkeland reports on how the area is pitching itself. BENTA BIRKELAND, BYLINE: Walking through downtown Denver, it's impossible to avoid construction. The city's booming and new buildings are going up everywhere. Denver's filled with trendy restaurants, bike paths, museums and tourists. On this crisp, autumn day, there's a bright blue sky overhead and snow-capped mountain peaks in the distance. Millennials, like 25-year-old old Abigail Scott, are flocking here for good jobs and to live close to the outdoors. ABIGAIL SCOTT: The sunshine is one of my favorite parts. The fact that the snow melts in, like, 5 hours is also another great part. I like that the mountains are visible almost all of the time from the city, gives you a little reminder of what you get to go to. BIRKELAND: The lifestyle here is the central part of the city's pitch to Amazon. J. J. Ament is with the Metro Denver Economic Development Corporation. J J AMENT: Few places in the United States and the world combine our great business climate with our great quality of life. BIRKELAND: For Denver, there's some history here. Sixteen years ago, another Seattle company, Boeing, chose Chicago over Denver for its new headquarters. Many cities are offering Amazon larger tax breaks and more cash up front than Denver's willing to put on the table. But the state's governor, Democrat John Hickenlooper, says the region has bigger selling points. JOHN HICKENLOOPER: The young people that might be in some other city and looking for where to, you know, not just get a job, but to build a family, build a life, that they're going to be more attracted to Colorado. BIRKELAND: But there is a lot of competition from cities, like Atlanta, Washington, D. C. and Raleigh. Rich Fitzgerald is the Allegheny County executive. Lately, he's been putting up to 60 hours a week on Pittsburgh's bid. RICH FITZGERALD: Companies have kind of discovered Pittsburgh's a great place to do business, and that's why Google is here and Intel is here and the Uber driverless car is here. And in fact, not only are young people staying, but there's more young people coming to Pittsburgh. BIRKELAND: He says Pittsburgh has another leg up. The colors of the Steelers, Pirates and Penguins are black and gold, just like Amazon's logo. But sports teams aside, this is an economic decision for Amazon. It says it needs a skilled workforce, major universities, an international airport and mass transit - all ingredients that Denver has. In fact, a New York Times analysis said the city was the best fit for Amazon. But some Coloradans are wary about the idea of even more growth. ANDREA SHINN: There's not really an infrastructure to support 50,000 more jobs. BIRKELAND: Twenty-eight-year-old Andrea Shinn is a chef. She grew up in the Denver region. She's worried about traffic getting worse and housing prices rising higher than they already are. SHINN: And it seems like more people are coming every day, which is wonderful for the economy, I suppose. But I think we've been a little sideswiped, and people are coming a little faster than we can anticipate. BIRKELAND: But Shinn says she understands how the climate and lifestyle draw people to Colorado. She hopes if Amazon does choose Denver, the city won't lose what makes it special to her. For NPR News, I'm Benta Birkeland in Denver. RACHEL MARTIN, HOST:  Across the country, hundreds of cities are making their pitch to Amazon. City officials have until Thursday to convince Amazon to open their second headquarters in their town. At stake - potentially 50,000 jobs and $5 billion worth of investment. One city that keeps showing up on lists of favorites is Denver. From member station KUNC, Benta Birkeland reports on how the area is pitching itself. BENTA BIRKELAND, BYLINE: Walking through downtown Denver, it's impossible to avoid construction. The city's booming and new buildings are going up everywhere. Denver's filled with trendy restaurants, bike paths, museums and tourists. On this crisp, autumn day, there's a bright blue sky overhead and snow-capped mountain peaks in the distance. Millennials, like 25-year-old old Abigail Scott, are flocking here for good jobs and to live close to the outdoors. ABIGAIL SCOTT: The sunshine is one of my favorite parts. The fact that the snow melts in, like, 5 hours is also another great part. I like that the mountains are visible almost all of the time from the city, gives you a little reminder of what you get to go to. BIRKELAND: The lifestyle here is the central part of the city's pitch to Amazon. J. J. Ament is with the Metro Denver Economic Development Corporation. J J AMENT: Few places in the United States and the world combine our great business climate with our great quality of life. BIRKELAND: For Denver, there's some history here. Sixteen years ago, another Seattle company, Boeing, chose Chicago over Denver for its new headquarters. Many cities are offering Amazon larger tax breaks and more cash up front than Denver's willing to put on the table. But the state's governor, Democrat John Hickenlooper, says the region has bigger selling points. JOHN HICKENLOOPER: The young people that might be in some other city and looking for where to, you know, not just get a job, but to build a family, build a life, that they're going to be more attracted to Colorado. BIRKELAND: But there is a lot of competition from cities, like Atlanta, Washington, D. C. and Raleigh. Rich Fitzgerald is the Allegheny County executive. Lately, he's been putting up to 60 hours a week on Pittsburgh's bid. RICH FITZGERALD: Companies have kind of discovered Pittsburgh's a great place to do business, and that's why Google is here and Intel is here and the Uber driverless car is here. And in fact, not only are young people staying, but there's more young people coming to Pittsburgh. BIRKELAND: He says Pittsburgh has another leg up. The colors of the Steelers, Pirates and Penguins are black and gold, just like Amazon's logo. But sports teams aside, this is an economic decision for Amazon. It says it needs a skilled workforce, major universities, an international airport and mass transit - all ingredients that Denver has. In fact, a New York Times analysis said the city was the best fit for Amazon. But some Coloradans are wary about the idea of even more growth. ANDREA SHINN: There's not really an infrastructure to support 50,000 more jobs. BIRKELAND: Twenty-eight-year-old Andrea Shinn is a chef. She grew up in the Denver region. She's worried about traffic getting worse and housing prices rising higher than they already are. SHINN: And it seems like more people are coming every day, which is wonderful for the economy, I suppose. But I think we've been a little sideswiped, and people are coming a little faster than we can anticipate. BIRKELAND: But Shinn says she understands how the climate and lifestyle draw people to Colorado. She hopes if Amazon does choose Denver, the city won't lose what makes it special to her. For NPR News, I'm Benta Birkeland in Denver.", "section": "Business", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-10-17-558092970": {"title": "No Rock 'Em Sock 'Em Here: Behold A U.S. Vs. Japan Giant Robot Duel : NPR", "url": "https://www.npr.org/2017/10/17/558092970/no-rock-em-sock-em-here-behold-a-u-s-vs-japan-giant-robot-duel", "author": "No author found", "published_date": "2017-10-17", "content": "RACHEL MARTIN, HOST: It's happening. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED MAN #1: The age of giant, fighting robots. MARTIN: The first-ever giant robot fight. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED MAN #2: On one side, Team USA. On the other side, we have team Japan. MARTIN: And by giant, we mean 16 feet tall. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED MAN #2: Landing a huge right hook on the top vehicle there. And it comes crashing down. UNIDENTIFIED MAN #3: Nice, nice, nice, nice, nice. MARTIN: The robot fight is airing tonight on the online streaming site Twitch. Here to talk more about this literally groundbreaking event is Gui Cavalcanti of MegaBots, Inc. He is one of the pilots who actually navigated one of these robots that fought in the duel. Gui, thanks so much for being with us. GUI CAVALCANTI: Thank you for having me. It's a pleasure to be here. MARTIN: What in the world. . . CAVALCANTI: (Laughter). MARTIN: . . . Spurred the idea to have giant robots fight each other? CAVALCANTI: You know, we've seen decades and decades of science fiction - right? - all featuring these giant robots fighting. And, you know, me and my co-founder Matt, we're a couple of engineers who specialize in big equipment, and we realized we can actually make those dreams come to life. MARTIN: I love it. So this is a dream - this is a personal dream of yours, now realized. CAVALCANTI: Yes. MARTIN: (Laughter). CAVALCANTI: This is a personal dream of mine come to life. MARTIN: So just so people have a sense of this, I mean, we tried to give a sense of how big these things are, but what do the robots look like and what can they do, exactly? CAVALCANTI: Yeah, so it looks like a very bulky, stocky human being with the red, white and blue all over it. Our robot, Eagle Prime, stands 16 feet tall. Matt and I are inside the robot. MARTIN: Oh, both of you are inside? CAVALCANTI: Yes. MARTIN: Wow. CAVALCANTI: It's a two-seater. MARTIN: OK. CAVALCANTI: I'm the driver in the back watching through monitors to see out of the robot. And then Matt is in the front. MARTIN: What weapons does your robot have at its disposal? CAVALCANTI: So let's see. We brought a couple of cannons, a missile launcher, claw, a giant 48-horsepower chainsaw to the fight. MARTIN: How cool was it to be inside this thing? I mean, this is like if you've seen the movie \"Iron Man,\" it's kind of like that, right? You'd be navigating. . . CAVALCANTI: Yeah. MARTIN: . . . The robot from inside. CAVALCANTI: It's awesome. It's terrifying. We're sitting on top of a 430-horsepower Corvette engine. MARTIN: Wow. CAVALCANTI: So it's like you're sitting in a redlining supercar. And you can actually feel the robot kind of just shaking and quaking around you as you get punched, as you, like, lean into a turn, as you fire the weapons or throw a punch. Like, everything's moving around you. MARTIN: It's dangerous to live your dreams, Gui. It is dangerous to live your dreams. CAVALCANTI: (Laughter) That's exactly right. MARTIN: So this is all insanely fun, but work with me, Gui. CAVALCANTI: Yeah. MARTIN: Was there some larger scientific mission at work here? CAVALCANTI: Our goal at MegaBots is to start a sports league of these robots. So the next step is really, you know, take this concept and make it into the next big arena and stadium sport. It's about what you consume as entertainment being inspirational. Are you going to want to be the NFL player and have a . 0001 percent chance of actually making money playing in the NFL? Or are you going to get inspired to be an engineer or a scientist because you see giant robots fight and you think it's the coolest thing ever? And then you see that these didn't come from nothing. These came from a couple of people dreaming and deciding that they could just do it. MARTIN: Gui Cavalcanti, he is CEO of MegaBots, Inc. The first-ever giant robot fight is going to be streamed online on Twitch. tv tonight at 10:00 p. m. Eastern. Thanks so much for talking with us, Gui. CAVALCANTI: Thank you for having me. RACHEL MARTIN, HOST:  It's happening. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED MAN #1: The age of giant, fighting robots. MARTIN: The first-ever giant robot fight. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED MAN #2: On one side, Team USA. On the other side, we have team Japan. MARTIN: And by giant, we mean 16 feet tall. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED MAN #2: Landing a huge right hook on the top vehicle there. And it comes crashing down. UNIDENTIFIED MAN #3: Nice, nice, nice, nice, nice. MARTIN: The robot fight is airing tonight on the online streaming site Twitch. Here to talk more about this literally groundbreaking event is Gui Cavalcanti of MegaBots, Inc. He is one of the pilots who actually navigated one of these robots that fought in the duel. Gui, thanks so much for being with us. GUI CAVALCANTI: Thank you for having me. It's a pleasure to be here. MARTIN: What in the world. . . CAVALCANTI: (Laughter). MARTIN: . . . Spurred the idea to have giant robots fight each other? CAVALCANTI: You know, we've seen decades and decades of science fiction - right? - all featuring these giant robots fighting. And, you know, me and my co-founder Matt, we're a couple of engineers who specialize in big equipment, and we realized we can actually make those dreams come to life. MARTIN: I love it. So this is a dream - this is a personal dream of yours, now realized. CAVALCANTI: Yes. MARTIN: (Laughter). CAVALCANTI: This is a personal dream of mine come to life. MARTIN: So just so people have a sense of this, I mean, we tried to give a sense of how big these things are, but what do the robots look like and what can they do, exactly? CAVALCANTI: Yeah, so it looks like a very bulky, stocky human being with the red, white and blue all over it. Our robot, Eagle Prime, stands 16 feet tall. Matt and I are inside the robot. MARTIN: Oh, both of you are inside? CAVALCANTI: Yes. MARTIN: Wow. CAVALCANTI: It's a two-seater. MARTIN: OK. CAVALCANTI: I'm the driver in the back watching through monitors to see out of the robot. And then Matt is in the front. MARTIN: What weapons does your robot have at its disposal? CAVALCANTI: So let's see. We brought a couple of cannons, a missile launcher, claw, a giant 48-horsepower chainsaw to the fight. MARTIN: How cool was it to be inside this thing? I mean, this is like if you've seen the movie \"Iron Man,\" it's kind of like that, right? You'd be navigating. . . CAVALCANTI: Yeah. MARTIN: . . . The robot from inside. CAVALCANTI: It's awesome. It's terrifying. We're sitting on top of a 430-horsepower Corvette engine. MARTIN: Wow. CAVALCANTI: So it's like you're sitting in a redlining supercar. And you can actually feel the robot kind of just shaking and quaking around you as you get punched, as you, like, lean into a turn, as you fire the weapons or throw a punch. Like, everything's moving around you. MARTIN: It's dangerous to live your dreams, Gui. It is dangerous to live your dreams. CAVALCANTI: (Laughter) That's exactly right. MARTIN: So this is all insanely fun, but work with me, Gui. CAVALCANTI: Yeah. MARTIN: Was there some larger scientific mission at work here? CAVALCANTI: Our goal at MegaBots is to start a sports league of these robots. So the next step is really, you know, take this concept and make it into the next big arena and stadium sport. It's about what you consume as entertainment being inspirational. Are you going to want to be the NFL player and have a . 0001 percent chance of actually making money playing in the NFL? Or are you going to get inspired to be an engineer or a scientist because you see giant robots fight and you think it's the coolest thing ever? And then you see that these didn't come from nothing. These came from a couple of people dreaming and deciding that they could just do it. MARTIN: Gui Cavalcanti, he is CEO of MegaBots, Inc. The first-ever giant robot fight is going to be streamed online on Twitch. tv tonight at 10:00 p. m. Eastern. Thanks so much for talking with us, Gui. CAVALCANTI: Thank you for having me.", "section": "Sports", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-10-18-556958482": {"title": "Amazon HQ2: Is A Mega-Deal Always Worth It For A Community? : NPR", "url": "https://www.npr.org/2017/10/18/556958482/a-major-distraction-is-a-mega-deal-like-amazon-s-hq2-always-worth-it", "author": "No author found", "published_date": "2017-10-18", "content": "STEVE INSKEEP, HOST: Next, we report on the downside of a bidding war for Amazon. Many cities are competing to be the chosen one, the site for a second Amazon headquarters and 50,000 promised jobs. At the same time, some politicians ask if cities are being played. NPR's Alina Selyukh reports. ALINA SELYUKH, BYLINE: When one of the world's fastest-growing companies says we want to give your city thousands of jobs paying six figures, it's easy to understand why red carpets roll out immediately. Amazon's second headquarters is such a huge moment that Washington, a state with the original Amazon HQ, is also bidding for HQ2. In Atlanta, the bidding even factored in the race for mayor. CATHY WOOLARD: I wrote a letter to Amazon as if I was making a marriage proposal and just had a few things to get off my chest. SELYUKH: Mayoral candidate Cathy Woolard says Atlanta should not be appeasing Amazon with a dowry but asking for a partnership where Amazon would help with affordable housing and transit problems. This kind of message is popping up across the country, ever since Amazon launched the bidding for HQ2 six weeks ago. Among its many asks, the company wants cities to offer financial incentives, which really is a pretty standard procedure. By one estimate, cities and states give up $70 billion a year worth of taxes and other revenues to lure corporations. But Amazon's request, so out in the open, is prompting some very public soul-searching(SOUNDBITE OF PHONE RINGING)SELYUKH: Who usually calls you? GREG LEROY: Lately, it's reporters on Amazon. I can't tell you. . . SELYUKH: Greg LeRoy is the guy to call if you want to know about corporate subsidies. He runs Good Jobs First, a nonprofit watchdog group that tracks what he calls corporate welfare. LeRoy says Amazon's jobs promise is unprecedented if it materializes. And sure, if it does, a surge of wealthy residents would spend more money, boost local businesses, maybe draw in new ones, do good things for the economy. LEROY: Our concern about this deal is that states and cities are going to overspend for the deal so badly that they'll never break even. SELYUKH: And here's the thing - most economic development officials don't actually expect tax incentives to be the deciding factor. (SOUNDBITE OF ARCHIVED RECORDING)PAUL O'NEILL: I never made an investment decision based on the tax code. SELYUKH: That's the voice of Paul O'Neill, the former CEO of the industrial giant Alcoa. Here he is testifying before Congress to become the Bush administration's Treasury secretary in 2001. He was asked what tax code encourages business investment. And he says only a gambler would base a long-term plan on a tax deal. A strategy of a businessman bakes in resources and intelligence. The taxes are a cherry on top. (SOUNDBITE OF ARCHIVED RECORDING)O'NEILL: If you're giving money away, I'll take it, you know? If you want to give me inducements for something I'm going to do anyway, I'll take it. JIM DOYLE: And I often thought as governor it would be sort of nice if all of the governors just got together and said, look, we're just not going to play this anymore. SELYUKH: That's Jim Doyle. He's the former governor of Wisconsin. He was there during the financial crisis in 2008 when GM was closing down plants, including a factory in Janesville in his state. And then GM said it would reopen one plant. So Doyle put together a massive incentive package, hundreds of millions of dollars. DOYLE: In this I think GM really just played Wisconsin. SELYUKH: Because Michigan was the obvious choice, and it kept offering more. DOYLE: When I look back at it, I believe they were going to Michigan. I can understand why they were going to Michigan. They closed more plants in Michigan. But I always felt we got used just as somebody to drive the bidding up. SELYUKH: This happens all the time, says Amy Liu, who runs the Metropolitan Policy Program at the Brookings Institution. AMY LIU: There's a whole system in economic development that has pitted states and cities against each other for corporate relocations. Amazon just happens to be very good at it. SELYUKH: In fact, Amazon has already benefited from more than a billion dollars in taxpayer-funded subsidies for operations like data centers or warehouses. And we should note, Amazon is one of NPR's sponsors, but Liu has an additional worry about the nationwide race for Amazon's HQ2. LIU: It's created a major distraction from what the real day-to-day economic development activity should be. SELYUKH: And that, she says, is not chasing shiny mega deals but the long, arduous work of grooming and nurturing homegrown businesses. Alina Selyukh, NPR News, Washington. (SOUNDBITE OF YPPAH'S \"I'LL HIT THE BREAKS\") STEVE INSKEEP, HOST:  Next, we report on the downside of a bidding war for Amazon. Many cities are competing to be the chosen one, the site for a second Amazon headquarters and 50,000 promised jobs. At the same time, some politicians ask if cities are being played. NPR's Alina Selyukh reports. ALINA SELYUKH, BYLINE: When one of the world's fastest-growing companies says we want to give your city thousands of jobs paying six figures, it's easy to understand why red carpets roll out immediately. Amazon's second headquarters is such a huge moment that Washington, a state with the original Amazon HQ, is also bidding for HQ2. In Atlanta, the bidding even factored in the race for mayor. CATHY WOOLARD: I wrote a letter to Amazon as if I was making a marriage proposal and just had a few things to get off my chest. SELYUKH: Mayoral candidate Cathy Woolard says Atlanta should not be appeasing Amazon with a dowry but asking for a partnership where Amazon would help with affordable housing and transit problems. This kind of message is popping up across the country, ever since Amazon launched the bidding for HQ2 six weeks ago. Among its many asks, the company wants cities to offer financial incentives, which really is a pretty standard procedure. By one estimate, cities and states give up $70 billion a year worth of taxes and other revenues to lure corporations. But Amazon's request, so out in the open, is prompting some very public soul-searching (SOUNDBITE OF PHONE RINGING) SELYUKH: Who usually calls you? GREG LEROY: Lately, it's reporters on Amazon. I can't tell you. . . SELYUKH: Greg LeRoy is the guy to call if you want to know about corporate subsidies. He runs Good Jobs First, a nonprofit watchdog group that tracks what he calls corporate welfare. LeRoy says Amazon's jobs promise is unprecedented if it materializes. And sure, if it does, a surge of wealthy residents would spend more money, boost local businesses, maybe draw in new ones, do good things for the economy. LEROY: Our concern about this deal is that states and cities are going to overspend for the deal so badly that they'll never break even. SELYUKH: And here's the thing - most economic development officials don't actually expect tax incentives to be the deciding factor. (SOUNDBITE OF ARCHIVED RECORDING) PAUL O'NEILL: I never made an investment decision based on the tax code. SELYUKH: That's the voice of Paul O'Neill, the former CEO of the industrial giant Alcoa. Here he is testifying before Congress to become the Bush administration's Treasury secretary in 2001. He was asked what tax code encourages business investment. And he says only a gambler would base a long-term plan on a tax deal. A strategy of a businessman bakes in resources and intelligence. The taxes are a cherry on top. (SOUNDBITE OF ARCHIVED RECORDING) O'NEILL: If you're giving money away, I'll take it, you know? If you want to give me inducements for something I'm going to do anyway, I'll take it. JIM DOYLE: And I often thought as governor it would be sort of nice if all of the governors just got together and said, look, we're just not going to play this anymore. SELYUKH: That's Jim Doyle. He's the former governor of Wisconsin. He was there during the financial crisis in 2008 when GM was closing down plants, including a factory in Janesville in his state. And then GM said it would reopen one plant. So Doyle put together a massive incentive package, hundreds of millions of dollars. DOYLE: In this I think GM really just played Wisconsin. SELYUKH: Because Michigan was the obvious choice, and it kept offering more. DOYLE: When I look back at it, I believe they were going to Michigan. I can understand why they were going to Michigan. They closed more plants in Michigan. But I always felt we got used just as somebody to drive the bidding up. SELYUKH: This happens all the time, says Amy Liu, who runs the Metropolitan Policy Program at the Brookings Institution. AMY LIU: There's a whole system in economic development that has pitted states and cities against each other for corporate relocations. Amazon just happens to be very good at it. SELYUKH: In fact, Amazon has already benefited from more than a billion dollars in taxpayer-funded subsidies for operations like data centers or warehouses. And we should note, Amazon is one of NPR's sponsors, but Liu has an additional worry about the nationwide race for Amazon's HQ2. LIU: It's created a major distraction from what the real day-to-day economic development activity should be. SELYUKH: And that, she says, is not chasing shiny mega deals but the long, arduous work of grooming and nurturing homegrown businesses. Alina Selyukh, NPR News, Washington. (SOUNDBITE OF YPPAH'S \"I'LL HIT THE BREAKS\")", "section": "Business", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-10-22-559086726": {"title": "The Russia Investigations: Interference Impacted Real Life; Senators Propose New Law : NPR", "url": "https://www.npr.org/2017/10/22/559086726/the-russia-investigations-interference-impacted-real-life-senators-propose-new-l", "author": "No author found", "published_date": "2017-10-22", "content": "", "section": "The Impact of War", "disclaimer": ""}, "2017-10-25-559905735": {"title": "Under Congressional Microscope, Twitter Vows New 'Transparency' On Ads : NPR", "url": "https://www.npr.org/2017/10/25/559905735/under-congressional-microscope-twitter-vows-new-transparency-on-ads", "author": "No author found", "published_date": "2017-10-25", "content": "", "section": "Tech Titans And The Information Complex", "disclaimer": ""}, "2017-10-26-560276801": {"title": "Twitter Says It Will Ban Ads From Russian News Agencies After Interference In 2016 Election : NPR", "url": "https://www.npr.org/2017/10/26/560276801/twitter-says-it-will-ban-ads-from-russian-news-agencies-after-interference-in-20", "author": "No author found", "published_date": "2017-10-26", "content": "ROBERT SIEGEL, HOST: Twitter has announced that from now on, it will reject all advertising from the Russian news outlets Sputnik and Russia Today, or RT. It will also give away the nearly $2 million it earned from past advertising. Both Sputnik and RT are backed directly by the Kremlin, and U. S. intelligence officials say both were used by the Russian government to help throw the U. S. presidential election into chaos. NPR media correspondent David Folkenflik joins us now with more on Twitter's move. David, it's long been known that these two news outlets answer to Moscow. Why is Twitter doing this now? DAVID FOLKENFLIK, BYLINE: Well, you know, the U. S. intelligence officials came to the conclusion the Russians were trying to disrupt things basically a year ago. It announced earlier this year that they had concluded that the effort was there to really help put a thumb on the scales for President Trump or for now President Trump. And then, you know, not so many weeks ago, U. S. officials decided to try to make RT and Sputnik register as foreign agents - that is, as entities explicitly trying to do the will of the Russian government in the sense that a lobbyist might or, you know, a - I mean, an agent, somebody acting on the government's behalf, not simply as a news organization owned by the government. This has put a lot of pressure on organizations that do business with RT and Sputnik to figure out how to respond. SIEGEL: Well, is Twitter now saying that it agrees with U. S. intelligence agencies that the Russian news outlets tried to tip the election to Trump? FOLKENFLIK: Twitter's official statements have actually been relatively restrained, just sort of acknowledging the effort to disrupt and that the ability of RT to take advantage of the viral nature of social media platforms, particularly Twitter in this instance, are things that they have to take into account. SIEGEL: And what are the Russian news outlets - say about this? FOLKENFLIK: Well, they're saying a few things. They're accusing Twitter of hypocrisy. They're pointing out that Twitter officials came to them with a rather extensive plan to step up their advertising on the site and that, you know, that Twitter had courted their business. In addition, Russian officials at the Foreign Ministry are saying that this violates all kinds of United States and international protections on freedom of expression, that these are journalistic outlets. And you know, there is the point being made, I think with validity, that the ads really accomplished less in many cases than some of the content and the news coverage, the framing of things, the misinformation, disinformation and actual stories that got picked up without - for amplification without any subsidy, without any advertising at all. SIEGEL: Now, the Russians of course aren't the only ones getting a tough look from Capitol Hill. Three committees are questioning tech giants next week, Twitter among them. You think that had something to do with Twitter's announcement today? FOLKENFLIK: Oh, I think that's not incidental at all. I think there's a great desire on Capitol Hill to understand how this disruption worked. You know, some more than others want to take action to ensure, to press these companies, to take actions to ensure that this kind of disruption doesn't happen. There's some pressure for greater transparency, and of course Twitter and Facebook and Google have always wanted to protect their secret sauce and their algorithms. And in some corners, there's a desire to try to pressure these social media outlets in such a way that if they don't take greater responsibility, that they could be regulated. And I think that's the greatest fear of all for these social media platform. So you're seeing them start to take actions and to take conciliatory measures to at least publicly signal their discomfort, which - what occurred on their platforms in the hope of staving off greater government action. SIEGEL: That's NPR's David Folkenflik on the news that Twitter has announced that it will reject all advertising from the Russian news outlets Sputnik and Russia Today. David, thanks. FOLKENFLIK: You bet. (SOUNDBITE OF ST. LENOX SONG, \"KOREA\") ROBERT SIEGEL, HOST:  Twitter has announced that from now on, it will reject all advertising from the Russian news outlets Sputnik and Russia Today, or RT. It will also give away the nearly $2 million it earned from past advertising. Both Sputnik and RT are backed directly by the Kremlin, and U. S. intelligence officials say both were used by the Russian government to help throw the U. S. presidential election into chaos. NPR media correspondent David Folkenflik joins us now with more on Twitter's move. David, it's long been known that these two news outlets answer to Moscow. Why is Twitter doing this now? DAVID FOLKENFLIK, BYLINE: Well, you know, the U. S. intelligence officials came to the conclusion the Russians were trying to disrupt things basically a year ago. It announced earlier this year that they had concluded that the effort was there to really help put a thumb on the scales for President Trump or for now President Trump. And then, you know, not so many weeks ago, U. S. officials decided to try to make RT and Sputnik register as foreign agents - that is, as entities explicitly trying to do the will of the Russian government in the sense that a lobbyist might or, you know, a - I mean, an agent, somebody acting on the government's behalf, not simply as a news organization owned by the government. This has put a lot of pressure on organizations that do business with RT and Sputnik to figure out how to respond. SIEGEL: Well, is Twitter now saying that it agrees with U. S. intelligence agencies that the Russian news outlets tried to tip the election to Trump? FOLKENFLIK: Twitter's official statements have actually been relatively restrained, just sort of acknowledging the effort to disrupt and that the ability of RT to take advantage of the viral nature of social media platforms, particularly Twitter in this instance, are things that they have to take into account. SIEGEL: And what are the Russian news outlets - say about this? FOLKENFLIK: Well, they're saying a few things. They're accusing Twitter of hypocrisy. They're pointing out that Twitter officials came to them with a rather extensive plan to step up their advertising on the site and that, you know, that Twitter had courted their business. In addition, Russian officials at the Foreign Ministry are saying that this violates all kinds of United States and international protections on freedom of expression, that these are journalistic outlets. And you know, there is the point being made, I think with validity, that the ads really accomplished less in many cases than some of the content and the news coverage, the framing of things, the misinformation, disinformation and actual stories that got picked up without - for amplification without any subsidy, without any advertising at all. SIEGEL: Now, the Russians of course aren't the only ones getting a tough look from Capitol Hill. Three committees are questioning tech giants next week, Twitter among them. You think that had something to do with Twitter's announcement today? FOLKENFLIK: Oh, I think that's not incidental at all. I think there's a great desire on Capitol Hill to understand how this disruption worked. You know, some more than others want to take action to ensure, to press these companies, to take actions to ensure that this kind of disruption doesn't happen. There's some pressure for greater transparency, and of course Twitter and Facebook and Google have always wanted to protect their secret sauce and their algorithms. And in some corners, there's a desire to try to pressure these social media outlets in such a way that if they don't take greater responsibility, that they could be regulated. And I think that's the greatest fear of all for these social media platform. So you're seeing them start to take actions and to take conciliatory measures to at least publicly signal their discomfort, which - what occurred on their platforms in the hope of staving off greater government action. SIEGEL: That's NPR's David Folkenflik on the news that Twitter has announced that it will reject all advertising from the Russian news outlets Sputnik and Russia Today. David, thanks. FOLKENFLIK: You bet. (SOUNDBITE OF ST. LENOX SONG, \"KOREA\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-10-26-560136311": {"title": "How 5 Tech Giants Have Become More Like Governments Than Companies : NPR", "url": "https://www.npr.org/2017/10/26/560136311/how-5-tech-giants-have-become-more-like-governments-than-companies", "author": "No author found", "published_date": "2017-10-26", "content": "TERRY GROSS, HOST: This is FRESH AIR. I'm Terry Gross. It's difficult to get jazzed about smartphones and social networks when they might be ruining the world. That's what my guest, Farhad Manjoo, writes. And he's been covering tech for 20 years. For the last three, he's written the New York Times column \"State Of The Art\" in which he explores how the latest tech ideas are shaping the future. Now he's writing a series about the Frightful Five. That's his name for tech giants Apple, Amazon, Google, Facebook and Microsoft, which make up half of the top 10 most valuable companies on the American stock market and which Manjoo says collectively influence just about everything else that happens in tech, as well as the rest of the global economy. He's also writing a book about the five. Farhad Manjoo, welcome to FRESH AIR. What makes the Frightful Five frightful? What did they have to do to get on your list? FARHAD MANJOO: So what makes them frightful, first of all, is that they are very, very big. And they play a huge role - they all play sort of huge roles in our lives kind of personally and at a kind of society-wide level. So if you live kind of a modern American life, it's impossible to, you know, to live without all of them for most people. And more than that, they sort of are being asked to do and they kind of know more about us than any corporations in history. They're more - they've become kind of more like governments than companies with the amount of money they have, with the kind of power they have over democracy in society. We're seeing that with the way that, you know, news on Facebook and Google affected the election, with their impact on the economy, you know, the way they're disrupting kind of how retail works, with their impact on jobs and inequality. And eventually, you know, they're all working on artificial intelligence. And their technologies will affect probably most of our jobs. Most of the ways that people make money now are going to be changed by technologies that these companies make. GROSS: Yeah. And when you say that they're like governments, they're sometimes more like governments than corporations, you point out that they're doing things that government - that our government used to do in terms of innovation. What are some examples that you're thinking of? MANJOO: Yeah. So, you know, many of the technologies that we use today at kind of their earliest levels were started by grants for the Defense Department or just kind of basic science research. Now a lot of that is being done by these companies. Artificial intelligence is kind of the primary example. These companies are going to be building the future of transportation in the United States, in the world. You know, they're building self-driving cars. They're building drones. They're building kind of the infrastructure of the United States - the infrastructure of the next 20, 30, 40 years in ways that we used to look to kind of governments to do. You know, Amazon has a fleet of planes, drones. It is in the kind of shipping business. It affects stores around you. Much of the kind of physical world around you is being shaped by, you know, that one company. And you can point to kind of similar ways that all the other companies are shaping the world around you in ways that are sort of huge economically and socially and that are kind of unavoidable. Like essentially - in one of my pieces, I wrote that they kind of blanket the entire society in their technology, and you can't really escape them. GROSS: When we talk about Apple, Amazon, Google, Facebook and Microsoft, we're also talking about companies that most people don't know are owned by these five mega tech companies. So what are some examples of things that we might not associate with Apple, Amazon, Google, Facebook and Microsoft but really are part of them? MANJOO: Right. So Facebook, for example, also owns Instagram - one of the most popular social networks in the world. It owns WhatsApp, which is I think the most popular messaging app other than a couple that are in China. And, you know, it owns Facebook, which reaches 2 billion people a month. Google, in addition to kind of the Google search engine, it has a whole suite of mapping technologies. So there's Google Maps, but there's also Waze, another popular app for getting around. Google owns YouTube. Amazon, in addition to Amazon the store, it owns many different kind of media and publishing properties, so Audible, which has audio books. Amazon also owns Zappos the shoe company. It sort of owns this suite of different e-commerce sites. And Amazon is sort of doing more than shopping now. One of its huge ventures is artificial intelligence. And you can personify it through their device called the Amazon Echo, which you put in your house and you talk to. It's your assistant. So, you know, these are examples of companies and products that are part of the five. And they really exemplify the way the five are going into - you know, they're really stretched far horizontally. Kind of every product or service that you might want to use, you're going to touch one of these companies. I think Google is the most - is the perfect example of this. So what Google did a couple years ago is they switched from being Google, Google incorporated to Alphabet. So Alphabet is a holding company, many people may not have heard of it. Every time I write about Alphabet I have to very - I have to specify that we're actually talking about Google. But what Alphabet is is it's a holding company that has Google. Google is its sort of biggest property, but then it has a whole bunch of other companies you may not have heard of. One of them is like their research lab called Google X, another is something called Google Brain, which is a company that is looking at ways to have artificial intelligence do things like medical diagnosis. There is a self-driving car company called Waymo. There's another health company called Verily. There's sort of a suite of companies that are under this alphabet umbrella related to Google. So they get all their money from Google but, you know, in the future, the plan is that Google as an entity will be just one of many different companies owned by this larger company that will, you know, affect everything that we do. GROSS: So like the origin stories for like Google, Facebook and Apple, they're all about like a guy or a couple of guys in a garage or dorm room dreaming up these great ideas that lead to something remarkably innovative. But now you're saying now that these companies that they dreamed of are so big, they're actually in some ways suppressing innovation - the innovations of other, you know, men and women in their dorm rooms or garages dreaming up ideas. So in what ways do you think that these companies now sometimes suppress innovation? MANJOO: This, I think, is the huge change in how the tech industry works now versus how it worked back when some of these companies were starting up. It's still possible to come out to Silicon Valley and start, you know, some new app, some - create some new piece of hardware that lots of people like and that takes the world by storm. But there's now kind of a ceiling on how successful your idea can be, and the ceiling is kind of determined by these five companies. So one of the things that these five companies have done kind of masterfully is create these platforms that startups have to use to get to customers. So they all own these cloud-storage services. So Amazon is an example. If you want to store your media online - so, for example, all the movies that you watch on Netflix are actually stored on Amazon servers - so every time you use Netflix, Netflix is kind of paying Amazon for that kind of storage. GROSS: I have to tell you, I was really surprised when I read that. I didn't know that. MANJOO: Yeah. It's surprising, first of all, because they're such different companies. You wouldn't really know - you wouldn't really think that they would have that kind of connection. And then they're also competitors. Netflix makes original TV shows and so does Amazon. And so, you know, in this way, Netflix has this dependence on one of its competitors. There are lots of different examples of this though. There - you know, all app makers have to put their apps in the Apple app store or the Google app store. And when they sell in those apps, 30 percent of that money goes to Apple or Google. They all have to advertise on Facebook or Google to get customers because that's become the way to advertise on digital platforms. And so any new app - Uber, Airbnb, Netflix, all the other sort of smaller companies online - have to go through these five to get to their customers. And what ends up happening is that other companies succeed, but always these five benefit off of that success. GROSS: So what's an example of how one of these big companies dealt with a new startup or a new innovation that might've been competitive or appealing? MANJOO: Yeah. The best example we've seen recently is sort of what's happened to Snapchat. So Snapchat is a very popular and really innovative idea. So Snapchat is an app where primarily teenagers, young people, send messages that disappear. So they don't last forever. You send a picture and kind of a caption to your friend. They see it for a little while, and it disappears. And the other thing you do on this app is you make something called a story, which is like a slideshow of your day. And after a day, your friends see it and then it goes away. And these were very popular. And Facebook, which is obviously the leader in social networking, they noticed the popularity of Snap, and several times they tried to buy the company. Facebook offered Snap $3 billion, and Snap turned them down. And then earlier this year Snap went public on the stock market, and it was sort of this huge event for them. You know, this is the next step in kind of the evolution of their company. And right after that, Facebook copied Stories, this format that's very popular on Snapchat. It copied it to essentially all of Facebook's platforms, and basically overnight the version of Stories in Instagram, in Facebook's company, became far more popular than Stories in Snapchat. And ever since then Snapchat's stock has suffered, and analysts and other people I talked to have a much kind of dimmer view of the future of that company than they did before because Facebook is gunning for them, and it's just really hard to see how they can kind of get out from under that competition. GROSS: So you see that as an example of how one of the big companies can suppress or co-opt the innovation of a startup? MANJOO: Yeah. It's the role of startups in the modern tech economy is to provide, you know, ideas for the big companies to kind of run with and make money from. And the other thing that the startups do is they pay a lot of money for the goods and services that the big companies provide. So half of Snapchat's revenues actually go to Google because Google hosts the actual content on Snapchat. So in this weird way, you know, Snapchat is paying half of its revenues to Google, one of the five. It's being copied left and right by another of the five, Facebook. And it's trying to make money in the Internet ad economy, and the biggest players in the Internet ad economy are Google and Facebook. So it's also competing with them for advertisers. It's a really unenviable position to be in. GROSS: Well, let's take a break here, and then we'll talk some more about what my guest, Farhad Manjoo, calls the frightful five, which is Apple, Amazon, Google, Facebook and Microsoft. He writes the tech column \"State Of The Art\" for The New York Times, and he's doing a series on this group that he calls the frightful five. We're going to be right back after a break. This is FRESH AIR. (SOUNDBITE OF MUSIC)GROSS: This is FRESH AIR, and if you're just joining us, my guest is Farhad Manjoo, who writes about tech for The New York Times. He writes the \"State Of The Art\" column, which explores how the latest tech ideas are shaping the future. And he's now writing a series about big tech companies, the ones he calls the frightful five - Apple, Amazon, Google, Facebook and Microsoft. Now, you say the frightful five are so big, and yet they're not regulated by the government and they don't really fit into the standards that we measure monopolies by. Like, they don't conform to monopoly standards. So what's different about these tech companies from companies that we might consider a monopoly? MANJOO: So one of the differences is that they're new and they're growing in new markets. And in those markets, it's sort of - in some ways it's kind of too early to call them the winners, according to regulators. And other ways, they've sort of grown really quickly, but many people see sort of more room to grow. So it's, according to regulators and others who study these markets, kind of perhaps too soon to say that they've won. But for example, you know, Amazon has disrupted essentially all of the retail business, like, everyone from Walmart to, you know, every mom and pop shop has some fear and strategy for responding to the threat of Amazon. But if you look at kind of the size of Amazon and the scope of the entire retail business, it's not that big. It's not even half of all online sales, and it's something like 8 percent of all retail sales in the United States. So it's growing very quickly, and it has built this infrastructure for kind of the future of commerce. It's built all these warehouses and this very efficient way of shipping goods to people. And everyone who understands e-commerce understands that, like, the future of retail in America belongs to Amazon. But at this point, it's small. And so for regulators who worry about. . . GROSS: Wait. Small when measured against overall retail numbers and. . . MANJOO: Right. So yes. So at this point. . . GROSS: 'Cause there's nothing small about Amazon so (laughter). . . MANJOO: (Laughter) You're right. GROSS: . . . Sounds like a contradiction. MANJOO: Yeah. But at this point it's, you know, it's about a quarter of the size of Walmart. It's growing very quickly, growing faster than than Walmart is, but it's only a quarter of the size of Walmart. It just beat out last year sales of Costco, and it is a very small percentage of overall retail. So if you're a regulator worried about kind of monopolies, a monopoly threat, it's difficult to kind of look at traditional ways of measuring monopolies, like how much market concentration there is. Or another thing you'd worry about is, is this company big enough that it's able to kind of control prices? Well, Amazon is not that big. It's not sort of, you know, if you're worried about suppliers of goods being priced out, you really would worry about Walmart more. I mean, Walmart is sort of known for low prices and its demands on suppliers to constantly lower their prices. And so for regulators who are worried about the dominance of a single company on a sector, Amazon presents this real puzzle for them. In fact it's such a puzzle that progressives and people on the left who've studied antitrust say that we need a whole new slate of laws and regulations to contain Amazon and to regulate it than we do now. The fundamentally kind of antitrust laws that we have today don't work for Amazon. GROSS: So what kind of laws are they thinking about? MANJOO: So there was this - one of the interesting things I discovered in looking at these five companies is that there's been this sea change in America in how we think about dangerous kind of corporate dominance. And before the 1980s, we were essentially a lot more strict in the United States about corporate size. And you know, the government was a lot more interventionist in preventing mergers that may affect how a market works. And what happened in the 1980s is that, you know, a group of economists and lawyers known as the Chicago School and the Reagan administration kind of completely changed how we looked at corporate dominance in America, especially about sort of the danger, how we thought of the dangers of monopolies. And so the upshot of that is they looked mostly at price when determining whether a merger could go through, whether a company could get bigger. And they didn't look at sort of non-price effects like customer service or the effect on suppliers or the effect on the environment or adjacent industries. If you look at price only, you won't - you're not likely to kind of stop Amazon because one of the benefits that Amazon has had is that investors sort of have been betting on kind of constant growth from Amazon, and as a result they don't really expect Amazon to be very profitable. Amazon is sort of famously not profitable at all because it reinvests everything it makes into building out more warehouses and building, you know, to getting bigger for the next year. And so Amazon really doesn't have to raise prices. It constantly lowers prices. It has this effect on the rest of the of the retail business that results in lower prices. So if you were looking at prices alone, you would say this is a great company. It's great for customers that this company is kind of constantly lowering prices and forcing everyone else to lower prices. Under the kind of current view of antitrust, Amazon seems like a positive force rather than a negative force. But if you go back, according to, you know, the people who want us to rethink how we do antitrust, if you go back to kind of a pre-1980s view of this structure and this market, you would see that Amazon is sort of, you know, getting its kind of corporate tentacles into a large part of the economy, into shipping, and how warehouses work and robots. Things that will allow it to dominate in the future that we're kind of just not good at regulating at this point. GROSS: My guest is Farhad Manjoo, who writes The New York Times tech column \"State Of The Art,\" and he's writing a series about the tech giants he calls the frightful five - Apple, Amazon, Google, Microsoft and Facebook. After we take a short break, he'll talk about the dark side of Google and smartphones and why he set up cameras in his home that record everything his family does in the living room and dining room. I'm Terry Gross, and this is FRESH AIR. (SOUNDBITE OF MUSIC)GROSS: This is FRESH AIR. I'm Terry Gross back with Farhad Manjoo, who writes The New York Times tech column \"State Of The Art\" about how the latest tech ideas are shaping the future. He's now writing a series about the tech giants he calls the frightful five - Apple, Amazon, Google, Facebook and Microsoft. The frightful five are also the subject of a book he's writing. He says there's an ongoing debate about whether they should be regulated, but they're hard to regulate because they're so different from the type of corporate giants that antitrust laws were designed for. So, you know, one of the things people are wondering, like, should this be regulated is, fake news. And, you know, Facebook and Twitter are responding to concerns about fake news and where are ads coming from. So Twitter has issued, like, new guidelines for what it's going to do. You want to run through - Twitter's not part of your frightful five, but it's still pretty big, and it's important in the context of what we're talking about. Do you want to just run through some of the things they plan on doing? MANJOO: Yeah. Both Twitter and Facebook sort of had these - posted these guidelines earlier, which is they plan to - they say they plan to show you who's running these ads, who's sort of - who's paying for the ads and to be more transparent about other ads that those people have posted. So If you - so one of the problems that we've seen is that, you know, these kind of shady groups that are not kind of identified - you don't know where the money is coming from. You don't know what their agenda is. You don't know what other advertisements they've run. They've been able to kind of place these ads all over Facebook and Twitter and kind of affect the news and, you know, protests and kind of just society in America under these guidelines that companies are rolling out voluntarily. But you know, there might be legislation to this effect. That will be less possible because you'll be able to - it's plausible you'll be able to kind of find out who's running these campaigns. GROSS: In terms of Facebook, aren't they considering, like, working with fact-checking partners and labeling stories that are disputed as fake news? MANJOO: Yeah. So one of the real difficulties about looking at these companies is that in some ways, regulating them, making them better gives them more power. So Facebook is now - so Facebook's news feed is sort of one of the most popular places for getting news in the world. It's you know - combined, more people read it than, you know, all the major newspapers in the country, the TV networks. It's extremely influential. And right now there's very little fact-checking that Facebook does, which is, you know, what led to this proliferation of fake news and these kind of echo chambers that people have. The solution to that could be that Facebook decides it's going to partner with fact-checking companies, and perhaps it might do fact-checking itself. And Facebook would sort of be in some way the arbiter for what's right and wrong on Facebook. That may help with the fake news problem. I think it's unclear at this point. But the kind of upshot of that is, on the other hand, you get Facebook kind of acting as something like the ministry of information for kind of every country in which it operates, where, you know, it might be able to decide, like, this is true, and this is not true. How it'll make those decisions and who it'll employ to make those decisions I think is a big question. And, like, suddenly it's going to have this power, and it's going to come about perhaps as a solution to another problem that it itself caused. GROSS: So throughout this interview, we've been hearing a lot of your, you know, kind of criticisms about these five companies. And we should say you're hardly a technophobe. And reading about how you have your house wired (laughter) - you've got, like, everything in your house. You've got, like, all the gadgets and all the new, like, Internet of things kind of things. So let's start with, like - you wrote a column about how you've basically made your home into a reality show because your living room and - is it dining room. . . MANJOO: Yeah. GROSS: . . . Are wired with cameras that - kind of like a lot of public bathrooms, when you walk in in those bathrooms, the lights turn on. When you walk out, they turn off because they have, like, motion sensors. And that's how these cameras are wired. So describe for us the setup that you have with these cameras and why you're doing it. MANJOO: OK, so I'll describe the setup first. So they're - it's sort of in the public places of our house so, I mean, not the bedrooms - so the dining room, the living room, the kitchen. GROSS: And not the bathroom (laughter). MANJOO: Not the bathroom, yes. And there are a bunch of cameras. I think there are five now. And they kind of get all angles. And the reason I'm doing it is because I have two kids - young kids, 7 and 5 - almost 5. And you know, like everyone else who raises kids today, I take a lot of photos of them and a lot of videos, but I always feel like I'm missing stuff. They're extremely, like, cute. And I'm busy, and they say things, and I - and, like, I always worry that I'm just, like, missing their lives. So I got this idea because I saw some researchers had done this. Like, psychology researchers had a videotaped their own children to kind of look at their language development. And I thought, wouldn't that be super interesting to do that, to just have memories of my kids? It took a lot of lobbying of my wife, who is just not a tech person at all. And she, you know, was worried about the privacy implications and just, like, the idea of being surveilled in your house. Eventually I convinced her. I managed to kind of get her buy-in. We've been doing it for about a year now. And it'll be interesting, you know? It'll be really just, like, fascinating to me to watch those videos in the future and to show my kids those videos, you know, like, if my daughter who's now 5 is, like, 25 and to show her, like, what she looked like and what she said. And you know, I'd love to have memories of my own childhood from then. And I think they will appreciate that in the future. GROSS: OK. So part of what I'm hearing here is you saying, like, you're too busy to watch your kids grow up, so you retire, you'll be able to watch the TV version (laughter). MANJOO: Yeah. I mean, I'll cop to that. It's - that is a slightly cynical way to put it, but I don't think it's wrong. I mean, I think in many instances, we do now miss out on our children. I try not to. And you know, one of the things this helps me with is I don't have to pick up my phone to take videos of them. I can sort of just be in the moment. Like, we were - I was playing video games with my son last night, and he, like, said - you know, he was just, like, very - it was just very interesting and memorable for me to watch him, like, learn how to play this video game. And I would like to see that again (laughter) at some point. And so the idea of having that is - and it just feels like I'm capturing these memories that will one day be useful. GROSS: So have you been using those videos to settle arguments such as, no, I did tell you about this; you say I didn't, but I'm telling you I did, and now we will watch the tape and prove that I am right? MANJOO: It has been tempting. (LAUGHTER)MANJOO: I have wanted to do that. I've just resisted 'cause I don't - especially with my wife, like, I don't want to have the video sort of come between us. I have used it as, like, a disciplinary tool with my kids. So like, I've told my son, you know, like, not to start a fight with his sister. And then, like, I've sort of slyly mentioned I will be able to see if you did, you know, if they're alone in the room or something. And that's the kind of extent that I've used it - just kind of as a warning that I can look back at what's happening. GROSS: So my understanding is - right? - that the system that you have, the camera system - it records for a week, and then it deletes everything at the end of a week except for the things you've asked it to save. MANJOO: Yeah, that's how it works. It's like a surveillance camera at a convenience store, you know, it has a loop. GROSS: (Laughter) Just what everybody wants in their home. MANJOO: Exactly. It has a loop, a seven day, you know, storage of everything you take. So when something memorable happens, something I just want to capture, I write a note to myself of the time in my phone. And then once a week, I look at the videos. I go back to that time, and then I save those videos. GROSS: So what's a moment you're really glad you were able to preserve on video? MANJOO: It's the small things. So it's like we're having dinner and my daughter says something completely unexpected, like, makes a joke for the first time - like, this has happened - you know, says something that makes the whole rest of the family laugh. And she's 5. And so that's like - it happens once for the first time. And it like surprised her. And she got kind of embarrassed about it. And she didn't know that, like, making everyone laugh was like a good thing, was like something that people wanted to do. She thought that we were laughing at her. It was like a cute moment and a touching moment. And, you know, ordinarily, like, we'd just forget that. You just never have that moment. And now I have that. It's just like - dinners - really interesting things happen at dinner, I've realized after this. And just having those moments is going to be really fun in the future. GROSS: So your kids are 7 and 4 now. Do they understand that cameras are recording them? And if so, does it make them self-conscious? MANJOO: They do understand that cameras are recording them because I've shown them the videos. It hasn't made them self-conscious. What's actually happened is it's sort of done the opposite. It's made them performative. So my daughter will like - like if we play a song, she'll like go to the camera and sort of do a dance for the camera. And I think this is the influence of YouTube. They watch YouTube. And on YouTube, there's, you know, kids their age performing for cameras. Like, they have their own sort of YouTube shows. And because my kids watch YouTube and have these cameras that they know sort of are recording things that can be on YouTube, it seems like they act like - they try to act like YouTube stars, like people are watching them and they're trying to cultivate an audience. GROSS: Well, I think about how really different that was from like when I was growing up and the only people who were on video were people on TV. And there were only a few channels, so very few people were on TV. And it just seemed so, like, remarkable and impossible. And it's just amazing how like in a few decades how radically things can change. I know I'm stating the obvious, but it's no less remarkable even though it's obvious. MANJOO: Yeah. Yeah. No, I agree with that. I mean, I really wonder what my children's sort of conception of celebrity is going to be. They follow a YouTube star who's - it's weird even calling someone a YouTube star. He has - he's, you know, I think around 10 years old. And he has a following of, I think, a few million people on YouTube. And he just does kid stuff. Like he plays and he plays with toys and plays video games. And other kids watch him do this. We were on vacation in Hawaii, and we passed a kid that my kids swore was that kid, the sort of the YouTube star. And it was as if they had seen like, you know, the biggest celebrity. Like, they were shy. They were talking to each other about, like, whether that was him. They wanted to like go and search for him and get his autograph. It was like, you know, very cute and wondrous to see, but it was something I'd never heard of in like in my own definition would not sort of qualify as a celebrity, as someone worth meeting. But for them, he was like the biggest star of all time. GROSS: Also interesting. (Laughter) OK. If you're just joining us, my guest is Farhad Manjoo. And he writes the \"State Of The Art\" column at The New York Times, which explores how the latest tech ideas are shaping the future. He's now writing a series about the tech companies he calls the Frightful Five - Apple, Amazon, Google, Facebook and Microsoft. He's also writing a book about these companies. We're going to take a short break and then be right back. This is FRESH AIR. (SOUNDBITE OF OF MONTREAL'S \"FABERGE FALLS FOR SHUGGIE\")GROSS: This is FRESH AIR. And if you're just joining us, my guest is Farhad Manjoo, who writes the \"State Of The Art\" tech column for The New York Times and is now writing a series of articles about the tech companies he calls the Frightful Five - Apple, Amazon, Google, Facebook and Microsoft. So throughout this interview, we've been hearing a lot of your, you know, kind of criticisms about these five companies. And you write, it's difficult to get jazzed about smartphones and social networks when they might be ruining the world (laughter) and that technologies that we were most excited about 10 years ago are now implicated in just about every catastrophe of the day. MANJOO: Yeah. It is difficult for me to get excited about technology anymore. Like, you know, I write a column about technology. And like, as a result of that, I get to try out basically everything there is. And it's sort of been my dream job because I like wanted to do that. I'm interested in the future, and I'm interested in sort of what's going to happen with all this new stuff. But my sort of default position about whether this stuff is going to be good or bad in the world has changed. So in the past, my kind of reflexive bias of a new piece of technology was - tended toward optimism. You know, I had the feeling that probably it's better than the stuff we have now, and because it's better than the stuff we have now, it's going to kind of make us more efficient or help us like connect with people. And that has to be good. And, you know, that's the way - that's sort of the default position of, I think, everyone in Silicon Valley. Like, people who run these companies have this idea that any new piece of technology is probably going to be good. And my own view has shifted on that. I think that we should all be more skeptical of the unseen and longer-term potential dangers of these technologies before we kind of rush to embrace them. And my default view is no longer sort of optimism. It's more - it's, like, skepticism and just a more balanced view of, like - like, this thing could be big. It could be important. But it could be important in positive ways and plausibly very negative ways and that we should consider sort of both of those things. GROSS: What's an example of something that you initially thought was really positive and you came to see the dark side of it? I'm sure there's many examples to choose from here (laughter). MANJOO: (Laughter) Yeah. I mean, a really kind of clear example is Google, the search engine. So it just sounds - it sounds obvious that providing the world information for free on demand is going to be good. Like, throughout human history, we have been better when we learn more, when we get more information, when we produce more, when we share more. That's sort of the story behind public libraries and, like, encyclopedias and just books and printing in general. And so you would imagine that having that be accessible to the whole world would just naturally be good. And there are many arguments that, you know - there's sort of a lot of benefit I think from having Google as a search engine and having all this information. But on the other hand, there's no doubt that Google has led to, you know - has fed the rise of conspiracy thinking in America. Like, anyone can produce some piece of content that questions some completely valid fact about the world. They can put together a lot of information that suggests there's another point of view. Like, there are people who believe that the Earth is flat. And they can make YouTube videos about it, and they can make web pages about it. And then a lot of people start talking about it, and that starts trending on Google. Like, you will search for 9/11 or, like, whether the Earth is flat or not, and you will find at the very, you know, in prominent locations on Google this other view of the world. And you can get sucked into that and you can start believing things that are completely not true as a result of this tool that was made to enlighten the world. So you know, that's, like, an example of, you know, something that people thought would be obviously good. And it's just much more complicated than we initially thought. GROSS: OK, well, (laughter) you have an interesting job. Thank you so much for telling us about it. MANJOO: Thanks so much for having me. This was really fun. GROSS: No, my pleasure. Farhad Manjoo writes The New York Times tech column \"State Of The Art\" and is writing a series on the tech giants he calls the \"Frightful Five: Apple, Google, Facebook, Microsoft, and Amazon. \" He's also writing a book about them. After we take a short break, Justin Chang will review the new film \"The Square,\" which won the top prize at this year's Cannes Film Festival. This is FRESH AIR. (SOUNDBITE OF MUSIC) TERRY GROSS, HOST:  This is FRESH AIR. I'm Terry Gross. It's difficult to get jazzed about smartphones and social networks when they might be ruining the world. That's what my guest, Farhad Manjoo, writes. And he's been covering tech for 20 years. For the last three, he's written the New York Times column \"State Of The Art\" in which he explores how the latest tech ideas are shaping the future. Now he's writing a series about the Frightful Five. That's his name for tech giants Apple, Amazon, Google, Facebook and Microsoft, which make up half of the top 10 most valuable companies on the American stock market and which Manjoo says collectively influence just about everything else that happens in tech, as well as the rest of the global economy. He's also writing a book about the five. Farhad Manjoo, welcome to FRESH AIR. What makes the Frightful Five frightful? What did they have to do to get on your list? FARHAD MANJOO: So what makes them frightful, first of all, is that they are very, very big. And they play a huge role - they all play sort of huge roles in our lives kind of personally and at a kind of society-wide level. So if you live kind of a modern American life, it's impossible to, you know, to live without all of them for most people. And more than that, they sort of are being asked to do and they kind of know more about us than any corporations in history. They're more - they've become kind of more like governments than companies with the amount of money they have, with the kind of power they have over democracy in society. We're seeing that with the way that, you know, news on Facebook and Google affected the election, with their impact on the economy, you know, the way they're disrupting kind of how retail works, with their impact on jobs and inequality. And eventually, you know, they're all working on artificial intelligence. And their technologies will affect probably most of our jobs. Most of the ways that people make money now are going to be changed by technologies that these companies make. GROSS: Yeah. And when you say that they're like governments, they're sometimes more like governments than corporations, you point out that they're doing things that government - that our government used to do in terms of innovation. What are some examples that you're thinking of? MANJOO: Yeah. So, you know, many of the technologies that we use today at kind of their earliest levels were started by grants for the Defense Department or just kind of basic science research. Now a lot of that is being done by these companies. Artificial intelligence is kind of the primary example. These companies are going to be building the future of transportation in the United States, in the world. You know, they're building self-driving cars. They're building drones. They're building kind of the infrastructure of the United States - the infrastructure of the next 20, 30, 40 years in ways that we used to look to kind of governments to do. You know, Amazon has a fleet of planes, drones. It is in the kind of shipping business. It affects stores around you. Much of the kind of physical world around you is being shaped by, you know, that one company. And you can point to kind of similar ways that all the other companies are shaping the world around you in ways that are sort of huge economically and socially and that are kind of unavoidable. Like essentially - in one of my pieces, I wrote that they kind of blanket the entire society in their technology, and you can't really escape them. GROSS: When we talk about Apple, Amazon, Google, Facebook and Microsoft, we're also talking about companies that most people don't know are owned by these five mega tech companies. So what are some examples of things that we might not associate with Apple, Amazon, Google, Facebook and Microsoft but really are part of them? MANJOO: Right. So Facebook, for example, also owns Instagram - one of the most popular social networks in the world. It owns WhatsApp, which is I think the most popular messaging app other than a couple that are in China. And, you know, it owns Facebook, which reaches 2 billion people a month. Google, in addition to kind of the Google search engine, it has a whole suite of mapping technologies. So there's Google Maps, but there's also Waze, another popular app for getting around. Google owns YouTube. Amazon, in addition to Amazon the store, it owns many different kind of media and publishing properties, so Audible, which has audio books. Amazon also owns Zappos the shoe company. It sort of owns this suite of different e-commerce sites. And Amazon is sort of doing more than shopping now. One of its huge ventures is artificial intelligence. And you can personify it through their device called the Amazon Echo, which you put in your house and you talk to. It's your assistant. So, you know, these are examples of companies and products that are part of the five. And they really exemplify the way the five are going into - you know, they're really stretched far horizontally. Kind of every product or service that you might want to use, you're going to touch one of these companies. I think Google is the most - is the perfect example of this. So what Google did a couple years ago is they switched from being Google, Google incorporated to Alphabet. So Alphabet is a holding company, many people may not have heard of it. Every time I write about Alphabet I have to very - I have to specify that we're actually talking about Google. But what Alphabet is is it's a holding company that has Google. Google is its sort of biggest property, but then it has a whole bunch of other companies you may not have heard of. One of them is like their research lab called Google X, another is something called Google Brain, which is a company that is looking at ways to have artificial intelligence do things like medical diagnosis. There is a self-driving car company called Waymo. There's another health company called Verily. There's sort of a suite of companies that are under this alphabet umbrella related to Google. So they get all their money from Google but, you know, in the future, the plan is that Google as an entity will be just one of many different companies owned by this larger company that will, you know, affect everything that we do. GROSS: So like the origin stories for like Google, Facebook and Apple, they're all about like a guy or a couple of guys in a garage or dorm room dreaming up these great ideas that lead to something remarkably innovative. But now you're saying now that these companies that they dreamed of are so big, they're actually in some ways suppressing innovation - the innovations of other, you know, men and women in their dorm rooms or garages dreaming up ideas. So in what ways do you think that these companies now sometimes suppress innovation? MANJOO: This, I think, is the huge change in how the tech industry works now versus how it worked back when some of these companies were starting up. It's still possible to come out to Silicon Valley and start, you know, some new app, some - create some new piece of hardware that lots of people like and that takes the world by storm. But there's now kind of a ceiling on how successful your idea can be, and the ceiling is kind of determined by these five companies. So one of the things that these five companies have done kind of masterfully is create these platforms that startups have to use to get to customers. So they all own these cloud-storage services. So Amazon is an example. If you want to store your media online - so, for example, all the movies that you watch on Netflix are actually stored on Amazon servers - so every time you use Netflix, Netflix is kind of paying Amazon for that kind of storage. GROSS: I have to tell you, I was really surprised when I read that. I didn't know that. MANJOO: Yeah. It's surprising, first of all, because they're such different companies. You wouldn't really know - you wouldn't really think that they would have that kind of connection. And then they're also competitors. Netflix makes original TV shows and so does Amazon. And so, you know, in this way, Netflix has this dependence on one of its competitors. There are lots of different examples of this though. There - you know, all app makers have to put their apps in the Apple app store or the Google app store. And when they sell in those apps, 30 percent of that money goes to Apple or Google. They all have to advertise on Facebook or Google to get customers because that's become the way to advertise on digital platforms. And so any new app - Uber, Airbnb, Netflix, all the other sort of smaller companies online - have to go through these five to get to their customers. And what ends up happening is that other companies succeed, but always these five benefit off of that success. GROSS: So what's an example of how one of these big companies dealt with a new startup or a new innovation that might've been competitive or appealing? MANJOO: Yeah. The best example we've seen recently is sort of what's happened to Snapchat. So Snapchat is a very popular and really innovative idea. So Snapchat is an app where primarily teenagers, young people, send messages that disappear. So they don't last forever. You send a picture and kind of a caption to your friend. They see it for a little while, and it disappears. And the other thing you do on this app is you make something called a story, which is like a slideshow of your day. And after a day, your friends see it and then it goes away. And these were very popular. And Facebook, which is obviously the leader in social networking, they noticed the popularity of Snap, and several times they tried to buy the company. Facebook offered Snap $3 billion, and Snap turned them down. And then earlier this year Snap went public on the stock market, and it was sort of this huge event for them. You know, this is the next step in kind of the evolution of their company. And right after that, Facebook copied Stories, this format that's very popular on Snapchat. It copied it to essentially all of Facebook's platforms, and basically overnight the version of Stories in Instagram, in Facebook's company, became far more popular than Stories in Snapchat. And ever since then Snapchat's stock has suffered, and analysts and other people I talked to have a much kind of dimmer view of the future of that company than they did before because Facebook is gunning for them, and it's just really hard to see how they can kind of get out from under that competition. GROSS: So you see that as an example of how one of the big companies can suppress or co-opt the innovation of a startup? MANJOO: Yeah. It's the role of startups in the modern tech economy is to provide, you know, ideas for the big companies to kind of run with and make money from. And the other thing that the startups do is they pay a lot of money for the goods and services that the big companies provide. So half of Snapchat's revenues actually go to Google because Google hosts the actual content on Snapchat. So in this weird way, you know, Snapchat is paying half of its revenues to Google, one of the five. It's being copied left and right by another of the five, Facebook. And it's trying to make money in the Internet ad economy, and the biggest players in the Internet ad economy are Google and Facebook. So it's also competing with them for advertisers. It's a really unenviable position to be in. GROSS: Well, let's take a break here, and then we'll talk some more about what my guest, Farhad Manjoo, calls the frightful five, which is Apple, Amazon, Google, Facebook and Microsoft. He writes the tech column \"State Of The Art\" for The New York Times, and he's doing a series on this group that he calls the frightful five. We're going to be right back after a break. This is FRESH AIR. (SOUNDBITE OF MUSIC) GROSS: This is FRESH AIR, and if you're just joining us, my guest is Farhad Manjoo, who writes about tech for The New York Times. He writes the \"State Of The Art\" column, which explores how the latest tech ideas are shaping the future. And he's now writing a series about big tech companies, the ones he calls the frightful five - Apple, Amazon, Google, Facebook and Microsoft. Now, you say the frightful five are so big, and yet they're not regulated by the government and they don't really fit into the standards that we measure monopolies by. Like, they don't conform to monopoly standards. So what's different about these tech companies from companies that we might consider a monopoly? MANJOO: So one of the differences is that they're new and they're growing in new markets. And in those markets, it's sort of - in some ways it's kind of too early to call them the winners, according to regulators. And other ways, they've sort of grown really quickly, but many people see sort of more room to grow. So it's, according to regulators and others who study these markets, kind of perhaps too soon to say that they've won. But for example, you know, Amazon has disrupted essentially all of the retail business, like, everyone from Walmart to, you know, every mom and pop shop has some fear and strategy for responding to the threat of Amazon. But if you look at kind of the size of Amazon and the scope of the entire retail business, it's not that big. It's not even half of all online sales, and it's something like 8 percent of all retail sales in the United States. So it's growing very quickly, and it has built this infrastructure for kind of the future of commerce. It's built all these warehouses and this very efficient way of shipping goods to people. And everyone who understands e-commerce understands that, like, the future of retail in America belongs to Amazon. But at this point, it's small. And so for regulators who worry about. . . GROSS: Wait. Small when measured against overall retail numbers and. . . MANJOO: Right. So yes. So at this point. . . GROSS: 'Cause there's nothing small about Amazon so (laughter). . . MANJOO: (Laughter) You're right. GROSS: . . . Sounds like a contradiction. MANJOO: Yeah. But at this point it's, you know, it's about a quarter of the size of Walmart. It's growing very quickly, growing faster than than Walmart is, but it's only a quarter of the size of Walmart. It just beat out last year sales of Costco, and it is a very small percentage of overall retail. So if you're a regulator worried about kind of monopolies, a monopoly threat, it's difficult to kind of look at traditional ways of measuring monopolies, like how much market concentration there is. Or another thing you'd worry about is, is this company big enough that it's able to kind of control prices? Well, Amazon is not that big. It's not sort of, you know, if you're worried about suppliers of goods being priced out, you really would worry about Walmart more. I mean, Walmart is sort of known for low prices and its demands on suppliers to constantly lower their prices. And so for regulators who are worried about the dominance of a single company on a sector, Amazon presents this real puzzle for them. In fact it's such a puzzle that progressives and people on the left who've studied antitrust say that we need a whole new slate of laws and regulations to contain Amazon and to regulate it than we do now. The fundamentally kind of antitrust laws that we have today don't work for Amazon. GROSS: So what kind of laws are they thinking about? MANJOO: So there was this - one of the interesting things I discovered in looking at these five companies is that there's been this sea change in America in how we think about dangerous kind of corporate dominance. And before the 1980s, we were essentially a lot more strict in the United States about corporate size. And you know, the government was a lot more interventionist in preventing mergers that may affect how a market works. And what happened in the 1980s is that, you know, a group of economists and lawyers known as the Chicago School and the Reagan administration kind of completely changed how we looked at corporate dominance in America, especially about sort of the danger, how we thought of the dangers of monopolies. And so the upshot of that is they looked mostly at price when determining whether a merger could go through, whether a company could get bigger. And they didn't look at sort of non-price effects like customer service or the effect on suppliers or the effect on the environment or adjacent industries. If you look at price only, you won't - you're not likely to kind of stop Amazon because one of the benefits that Amazon has had is that investors sort of have been betting on kind of constant growth from Amazon, and as a result they don't really expect Amazon to be very profitable. Amazon is sort of famously not profitable at all because it reinvests everything it makes into building out more warehouses and building, you know, to getting bigger for the next year. And so Amazon really doesn't have to raise prices. It constantly lowers prices. It has this effect on the rest of the of the retail business that results in lower prices. So if you were looking at prices alone, you would say this is a great company. It's great for customers that this company is kind of constantly lowering prices and forcing everyone else to lower prices. Under the kind of current view of antitrust, Amazon seems like a positive force rather than a negative force. But if you go back, according to, you know, the people who want us to rethink how we do antitrust, if you go back to kind of a pre-1980s view of this structure and this market, you would see that Amazon is sort of, you know, getting its kind of corporate tentacles into a large part of the economy, into shipping, and how warehouses work and robots. Things that will allow it to dominate in the future that we're kind of just not good at regulating at this point. GROSS: My guest is Farhad Manjoo, who writes The New York Times tech column \"State Of The Art,\" and he's writing a series about the tech giants he calls the frightful five - Apple, Amazon, Google, Microsoft and Facebook. After we take a short break, he'll talk about the dark side of Google and smartphones and why he set up cameras in his home that record everything his family does in the living room and dining room. I'm Terry Gross, and this is FRESH AIR. (SOUNDBITE OF MUSIC) GROSS: This is FRESH AIR. I'm Terry Gross back with Farhad Manjoo, who writes The New York Times tech column \"State Of The Art\" about how the latest tech ideas are shaping the future. He's now writing a series about the tech giants he calls the frightful five - Apple, Amazon, Google, Facebook and Microsoft. The frightful five are also the subject of a book he's writing. He says there's an ongoing debate about whether they should be regulated, but they're hard to regulate because they're so different from the type of corporate giants that antitrust laws were designed for. So, you know, one of the things people are wondering, like, should this be regulated is, fake news. And, you know, Facebook and Twitter are responding to concerns about fake news and where are ads coming from. So Twitter has issued, like, new guidelines for what it's going to do. You want to run through - Twitter's not part of your frightful five, but it's still pretty big, and it's important in the context of what we're talking about. Do you want to just run through some of the things they plan on doing? MANJOO: Yeah. Both Twitter and Facebook sort of had these - posted these guidelines earlier, which is they plan to - they say they plan to show you who's running these ads, who's sort of - who's paying for the ads and to be more transparent about other ads that those people have posted. So If you - so one of the problems that we've seen is that, you know, these kind of shady groups that are not kind of identified - you don't know where the money is coming from. You don't know what their agenda is. You don't know what other advertisements they've run. They've been able to kind of place these ads all over Facebook and Twitter and kind of affect the news and, you know, protests and kind of just society in America under these guidelines that companies are rolling out voluntarily. But you know, there might be legislation to this effect. That will be less possible because you'll be able to - it's plausible you'll be able to kind of find out who's running these campaigns. GROSS: In terms of Facebook, aren't they considering, like, working with fact-checking partners and labeling stories that are disputed as fake news? MANJOO: Yeah. So one of the real difficulties about looking at these companies is that in some ways, regulating them, making them better gives them more power. So Facebook is now - so Facebook's news feed is sort of one of the most popular places for getting news in the world. It's you know - combined, more people read it than, you know, all the major newspapers in the country, the TV networks. It's extremely influential. And right now there's very little fact-checking that Facebook does, which is, you know, what led to this proliferation of fake news and these kind of echo chambers that people have. The solution to that could be that Facebook decides it's going to partner with fact-checking companies, and perhaps it might do fact-checking itself. And Facebook would sort of be in some way the arbiter for what's right and wrong on Facebook. That may help with the fake news problem. I think it's unclear at this point. But the kind of upshot of that is, on the other hand, you get Facebook kind of acting as something like the ministry of information for kind of every country in which it operates, where, you know, it might be able to decide, like, this is true, and this is not true. How it'll make those decisions and who it'll employ to make those decisions I think is a big question. And, like, suddenly it's going to have this power, and it's going to come about perhaps as a solution to another problem that it itself caused. GROSS: So throughout this interview, we've been hearing a lot of your, you know, kind of criticisms about these five companies. And we should say you're hardly a technophobe. And reading about how you have your house wired (laughter) - you've got, like, everything in your house. You've got, like, all the gadgets and all the new, like, Internet of things kind of things. So let's start with, like - you wrote a column about how you've basically made your home into a reality show because your living room and - is it dining room. . . MANJOO: Yeah. GROSS: . . . Are wired with cameras that - kind of like a lot of public bathrooms, when you walk in in those bathrooms, the lights turn on. When you walk out, they turn off because they have, like, motion sensors. And that's how these cameras are wired. So describe for us the setup that you have with these cameras and why you're doing it. MANJOO: OK, so I'll describe the setup first. So they're - it's sort of in the public places of our house so, I mean, not the bedrooms - so the dining room, the living room, the kitchen. GROSS: And not the bathroom (laughter). MANJOO: Not the bathroom, yes. And there are a bunch of cameras. I think there are five now. And they kind of get all angles. And the reason I'm doing it is because I have two kids - young kids, 7 and 5 - almost 5. And you know, like everyone else who raises kids today, I take a lot of photos of them and a lot of videos, but I always feel like I'm missing stuff. They're extremely, like, cute. And I'm busy, and they say things, and I - and, like, I always worry that I'm just, like, missing their lives. So I got this idea because I saw some researchers had done this. Like, psychology researchers had a videotaped their own children to kind of look at their language development. And I thought, wouldn't that be super interesting to do that, to just have memories of my kids? It took a lot of lobbying of my wife, who is just not a tech person at all. And she, you know, was worried about the privacy implications and just, like, the idea of being surveilled in your house. Eventually I convinced her. I managed to kind of get her buy-in. We've been doing it for about a year now. And it'll be interesting, you know? It'll be really just, like, fascinating to me to watch those videos in the future and to show my kids those videos, you know, like, if my daughter who's now 5 is, like, 25 and to show her, like, what she looked like and what she said. And you know, I'd love to have memories of my own childhood from then. And I think they will appreciate that in the future. GROSS: OK. So part of what I'm hearing here is you saying, like, you're too busy to watch your kids grow up, so you retire, you'll be able to watch the TV version (laughter). MANJOO: Yeah. I mean, I'll cop to that. It's - that is a slightly cynical way to put it, but I don't think it's wrong. I mean, I think in many instances, we do now miss out on our children. I try not to. And you know, one of the things this helps me with is I don't have to pick up my phone to take videos of them. I can sort of just be in the moment. Like, we were - I was playing video games with my son last night, and he, like, said - you know, he was just, like, very - it was just very interesting and memorable for me to watch him, like, learn how to play this video game. And I would like to see that again (laughter) at some point. And so the idea of having that is - and it just feels like I'm capturing these memories that will one day be useful. GROSS: So have you been using those videos to settle arguments such as, no, I did tell you about this; you say I didn't, but I'm telling you I did, and now we will watch the tape and prove that I am right? MANJOO: It has been tempting. (LAUGHTER) MANJOO: I have wanted to do that. I've just resisted 'cause I don't - especially with my wife, like, I don't want to have the video sort of come between us. I have used it as, like, a disciplinary tool with my kids. So like, I've told my son, you know, like, not to start a fight with his sister. And then, like, I've sort of slyly mentioned I will be able to see if you did, you know, if they're alone in the room or something. And that's the kind of extent that I've used it - just kind of as a warning that I can look back at what's happening. GROSS: So my understanding is - right? - that the system that you have, the camera system - it records for a week, and then it deletes everything at the end of a week except for the things you've asked it to save. MANJOO: Yeah, that's how it works. It's like a surveillance camera at a convenience store, you know, it has a loop. GROSS: (Laughter) Just what everybody wants in their home. MANJOO: Exactly. It has a loop, a seven day, you know, storage of everything you take. So when something memorable happens, something I just want to capture, I write a note to myself of the time in my phone. And then once a week, I look at the videos. I go back to that time, and then I save those videos. GROSS: So what's a moment you're really glad you were able to preserve on video? MANJOO: It's the small things. So it's like we're having dinner and my daughter says something completely unexpected, like, makes a joke for the first time - like, this has happened - you know, says something that makes the whole rest of the family laugh. And she's 5. And so that's like - it happens once for the first time. And it like surprised her. And she got kind of embarrassed about it. And she didn't know that, like, making everyone laugh was like a good thing, was like something that people wanted to do. She thought that we were laughing at her. It was like a cute moment and a touching moment. And, you know, ordinarily, like, we'd just forget that. You just never have that moment. And now I have that. It's just like - dinners - really interesting things happen at dinner, I've realized after this. And just having those moments is going to be really fun in the future. GROSS: So your kids are 7 and 4 now. Do they understand that cameras are recording them? And if so, does it make them self-conscious? MANJOO: They do understand that cameras are recording them because I've shown them the videos. It hasn't made them self-conscious. What's actually happened is it's sort of done the opposite. It's made them performative. So my daughter will like - like if we play a song, she'll like go to the camera and sort of do a dance for the camera. And I think this is the influence of YouTube. They watch YouTube. And on YouTube, there's, you know, kids their age performing for cameras. Like, they have their own sort of YouTube shows. And because my kids watch YouTube and have these cameras that they know sort of are recording things that can be on YouTube, it seems like they act like - they try to act like YouTube stars, like people are watching them and they're trying to cultivate an audience. GROSS: Well, I think about how really different that was from like when I was growing up and the only people who were on video were people on TV. And there were only a few channels, so very few people were on TV. And it just seemed so, like, remarkable and impossible. And it's just amazing how like in a few decades how radically things can change. I know I'm stating the obvious, but it's no less remarkable even though it's obvious. MANJOO: Yeah. Yeah. No, I agree with that. I mean, I really wonder what my children's sort of conception of celebrity is going to be. They follow a YouTube star who's - it's weird even calling someone a YouTube star. He has - he's, you know, I think around 10 years old. And he has a following of, I think, a few million people on YouTube. And he just does kid stuff. Like he plays and he plays with toys and plays video games. And other kids watch him do this. We were on vacation in Hawaii, and we passed a kid that my kids swore was that kid, the sort of the YouTube star. And it was as if they had seen like, you know, the biggest celebrity. Like, they were shy. They were talking to each other about, like, whether that was him. They wanted to like go and search for him and get his autograph. It was like, you know, very cute and wondrous to see, but it was something I'd never heard of in like in my own definition would not sort of qualify as a celebrity, as someone worth meeting. But for them, he was like the biggest star of all time. GROSS: Also interesting. (Laughter) OK. If you're just joining us, my guest is Farhad Manjoo. And he writes the \"State Of The Art\" column at The New York Times, which explores how the latest tech ideas are shaping the future. He's now writing a series about the tech companies he calls the Frightful Five - Apple, Amazon, Google, Facebook and Microsoft. He's also writing a book about these companies. We're going to take a short break and then be right back. This is FRESH AIR. (SOUNDBITE OF OF MONTREAL'S \"FABERGE FALLS FOR SHUGGIE\") GROSS: This is FRESH AIR. And if you're just joining us, my guest is Farhad Manjoo, who writes the \"State Of The Art\" tech column for The New York Times and is now writing a series of articles about the tech companies he calls the Frightful Five - Apple, Amazon, Google, Facebook and Microsoft. So throughout this interview, we've been hearing a lot of your, you know, kind of criticisms about these five companies. And you write, it's difficult to get jazzed about smartphones and social networks when they might be ruining the world (laughter) and that technologies that we were most excited about 10 years ago are now implicated in just about every catastrophe of the day. MANJOO: Yeah. It is difficult for me to get excited about technology anymore. Like, you know, I write a column about technology. And like, as a result of that, I get to try out basically everything there is. And it's sort of been my dream job because I like wanted to do that. I'm interested in the future, and I'm interested in sort of what's going to happen with all this new stuff. But my sort of default position about whether this stuff is going to be good or bad in the world has changed. So in the past, my kind of reflexive bias of a new piece of technology was - tended toward optimism. You know, I had the feeling that probably it's better than the stuff we have now, and because it's better than the stuff we have now, it's going to kind of make us more efficient or help us like connect with people. And that has to be good. And, you know, that's the way - that's sort of the default position of, I think, everyone in Silicon Valley. Like, people who run these companies have this idea that any new piece of technology is probably going to be good. And my own view has shifted on that. I think that we should all be more skeptical of the unseen and longer-term potential dangers of these technologies before we kind of rush to embrace them. And my default view is no longer sort of optimism. It's more - it's, like, skepticism and just a more balanced view of, like - like, this thing could be big. It could be important. But it could be important in positive ways and plausibly very negative ways and that we should consider sort of both of those things. GROSS: What's an example of something that you initially thought was really positive and you came to see the dark side of it? I'm sure there's many examples to choose from here (laughter). MANJOO: (Laughter) Yeah. I mean, a really kind of clear example is Google, the search engine. So it just sounds - it sounds obvious that providing the world information for free on demand is going to be good. Like, throughout human history, we have been better when we learn more, when we get more information, when we produce more, when we share more. That's sort of the story behind public libraries and, like, encyclopedias and just books and printing in general. And so you would imagine that having that be accessible to the whole world would just naturally be good. And there are many arguments that, you know - there's sort of a lot of benefit I think from having Google as a search engine and having all this information. But on the other hand, there's no doubt that Google has led to, you know - has fed the rise of conspiracy thinking in America. Like, anyone can produce some piece of content that questions some completely valid fact about the world. They can put together a lot of information that suggests there's another point of view. Like, there are people who believe that the Earth is flat. And they can make YouTube videos about it, and they can make web pages about it. And then a lot of people start talking about it, and that starts trending on Google. Like, you will search for 9/11 or, like, whether the Earth is flat or not, and you will find at the very, you know, in prominent locations on Google this other view of the world. And you can get sucked into that and you can start believing things that are completely not true as a result of this tool that was made to enlighten the world. So you know, that's, like, an example of, you know, something that people thought would be obviously good. And it's just much more complicated than we initially thought. GROSS: OK, well, (laughter) you have an interesting job. Thank you so much for telling us about it. MANJOO: Thanks so much for having me. This was really fun. GROSS: No, my pleasure. Farhad Manjoo writes The New York Times tech column \"State Of The Art\" and is writing a series on the tech giants he calls the \"Frightful Five: Apple, Google, Facebook, Microsoft, and Amazon. \" He's also writing a book about them. After we take a short break, Justin Chang will review the new film \"The Square,\" which won the top prize at this year's Cannes Film Festival. This is FRESH AIR. (SOUNDBITE OF MUSIC)", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-10-26-560199026": {"title": "Twitter Bans Ads From Russian State Media, Citing Election Interference Efforts : NPR", "url": "https://www.npr.org/2017/10/26/560199026/twitter-ends-russian-state-media-advertisements-citing-2016-interference-efforts", "author": "No author found", "published_date": "2017-10-26", "content": "", "section": "Tech Titans And The Information Complex", "disclaimer": ""}, "2017-10-27-560293602": {"title": "Prisons of Our Own Making | Hidden Brain : NPR", "url": "https://www.npr.org/2017/10/27/560293602/radio-replay-prisons-of-our-own-making", "author": "No author found", "published_date": "2017-10-27", "content": "SHANKAR VEDANTAM, HOST: This is HIDDEN BRAIN. I'm Shankar Vedantam. UNIDENTIFIED EXERCISE INSTRUCTOR: And then see if can begin to deepen your breath here - a nice, long inhale in (inhales) and a nice, long juicy exhale out (exhales). VEDANTAM: There are some commonly accepted ideas about what it means to be healthy. Healthy people eat lots of fruits and vegetables. They don't do drugs. And of course, they exercise. UNIDENTIFIED EXERCISE INSTRUCTOR: Draw your palms together at the heart. Take a deep breath in. Each time we. . . VEDANTAM: While physical activity and food dominate our discussions about well-being, the importance of social interaction is often overlooked. UNIDENTIFIED WOMAN #1: I think the movie was better than the book. UNIDENTIFIED MAN #1: I'm all right. UNIDENTIFIED WOMAN #2: What's your horoscope? UNIDENTIFIED MAN #2: I'd like a large cappuccino with. . UNIDENTIFIED WOMAN #3: Long time, no see. UNIDENTIFIED WOMAN #4: How are you? VEDANTAM: There's a large and growing body of research about how critical social contact is to human survival. UNIDENTIFIED MAN #3: That outfit looks so good on you. Where'd you get those shoes? UNIDENTIFIED WOMAN #5: I'll have a double espresso, please. VEDANTAM: A University of Utah study showed that people with strong relationships have lower blood pressure than lonelier counterparts. UNIDENTIFIED WOMAN #6: I've got to read that book still. UNIDENTIFIED MAN #4: What time is it? UNIDENTIFIED WOMAN #7: It's time for you to get a watch. UNIDENTIFIED WOMAN #8: I'm a huge Carolina fan. UNIDENTIFIED MAN #5: Can you pass the salt? VEDANTAM: Researchers at the University of Chicago found that people who report strong feelings of loneliness are more likely to binge eat. UNIDENTIFIED MAN #6: That place has the best donuts. UNIDENTIFIED WOMAN #9: That place has the worst donuts. UNIDENTIFIED WOMAN #10: I'll take two scoops of mint chocolate chip. VEDANTAM: And at Harvard, one study found that people with good relationships actually live longer and live happier. UNIDENTIFIED WOMAN #11: Happy birthday. UNIDENTIFIED MAN #7: Happy birthday. UNIDENTIFIED WOMAN #12: Happy birthday. UNIDENTIFIED MAN #8: Feliz cumpleanos. VEDANTAM: Our social ties are unquestionably at the core of what it means to be human. UNIDENTIFIED MAN #9: Anything good on Netflix? UNIDENTIFIED WOMAN #13: I just got back from (unintelligible). UNIDENTIFIED MAN #10: Are you going to happy hour tonight? (CROSSTALK)UNIDENTIFIED WOMAN #14: When is the next train coming? UNIDENTIFIED MAN #11: Dinner after work? UNIDENTIFIED WOMAN #15: Long time, no see. UNIDENTIFIED WOMAN #16: Good job. UNIDENTIFIED WOMAN #17: All right, so take a left turn on. . . UNIDENTIFIED MAN #12: How was your weekend? (CROSSTALK)VEDANTAM: So what happens if you're cut off from human contact? (SOUNDBITE OF MUSIC)VEDANTAM: Later in the show, we talk about the effects of long-term solitary confinement. KERAMET REITER: People talk about not having seen the moon in years or decades and how much they miss that. And then people talk about missing just pure human touch. (SOUNDBITE OF MUSIC)VEDANTAM: First, though, we start by exploring the other end of the spectrum, interaction overload. (SOUNDBITE OF MUSIC)VEDANTAM: In her 20s and 30s, Rachel Leonard lived all over the United States. RACHEL LEONARD: Out in Colorado and upstate New York. And I lived in Vermont for a long time. And then I was living in Asheville, N. C. VEDANTAM: And she traveled - all over the world. She met lots of different people in all these places. To keep in touch with them, she signed up for Facebook. LEONARD: I was traveling in Central America, 2006 and 2007. And I did not have a phone, and I was in pretty remote areas. I signed up then because I kept meeting all these wonderful people. And one of the ways to immediately, you know, connect with them was to friend them on Facebook. VEDANTAM: The site became an important tool for Rachel to keep in touch with people she'd met on her travels, to share her adventures with friends and family back home. LEONARD: That's actually when I started sharing, like, my travels with other friends - my pictures of my trip. VEDANTAM: But as much as Rachel loved traveling and felt good about the choices she'd made in her life, other feelings started to sneak up on her. Having Facebook also allowed her to see what everyone else was up to while she was backpacking in Central America or moving from one city to another. LEONARD: You know, everybody is getting married. Some people have one child. Some people have two children. All my friends have these high-power jobs, and they own houses and all of these things. VEDANTAM: These feelings were at the back of her mind a few years later when she met a guy and decided to start a relationship. LEONARD: I met him, and I had been planning to leave the country and go to Southeast Asia to teach. And I met him in December. And I was supposed to leave in June, and I didn't go. VEDANTAM: Her new boyfriend asked her to stay with him in Asheville, N. C. She wasn't sure it was the right thing to do, but she agreed. LEONARD: It was a turning point in my life in lots of ways because, up until then, I'd kind of been this free spirit and did what I wanted and traveled a lot and still had that wanderlust. But I was also 33 and kind of looking around and realizing that other people were getting married and having kids. And I decided maybe I should try this out. VEDANTAM: Soon, like so many of her friends, she was posting pictures and details about her happy relationship. LEONARD: We got engaged pretty quickly. And, you know, at this time, I'm posting my pictures. I'm posting our hikes. We lived in, you know, the Blue Ridge Mountains, so we'd have these beautiful hikes and this lovely little town, and of course I'm posting all of this. VEDANTAM: Her engagement was chronicled, the new house they moved into, the view from the porch. All of it look beautiful on Facebook. LEONARD: If you looked only from the porch, you could see mountains straight. But if you looked to the left, you could see this huge factory. But of course I didn't take pictures of the factory 'cause why would you do that? VEDANTAM: Because Facebook is not a place for pictures of ugly factories. LEONARD: It was very taboo not to share positivity. No one ever put negative stuff on there. And if they did, people were like - what's going on with blah, blah, blah? So it was always about being positive and showing your best side and your best moments. VEDANTAM: Facebook is also not a place for ambivalence. Celebrating triumph? That's welcome. Mourning a tragedy? That's OK, too. Expressing uncertainty and doubt? Not so much. We all intuitively understand the rules. Posts about engagements and babies will receive ravenous applause. News about a grandparent passing away will elicit virtual hugs. But fears about not making rent, marital tensions, hesitations about becoming a parent? Those are verboten. Rachel started to feel constricted. The more she posted about her happy life on social media, the greater the disconnect she felt with her real life. LEONARD: I know now that at the time, while it looked great and it looked right, it didn't really feel right for me. But I think that putting it out there and having my friends say - oh, this looks so wonderful. You look so happy. This is great - it was kind of my way of convincing myself it was. And I'd say that the more things didn't feel great, the more I posted. (SOUNDBITE OF MUSIC)VEDANTAM: The gulf widened between her real relationship and the Facebook version. LEONARD: What I'm not posting is that we fought a lot. And what seemed to be kind of perfect to other people was not. VEDANTAM: When the new couple took a trip to Charleston, Rachel says her friends on Facebook only saw the beautiful pictures. She posted photos of the two of them sitting on the beach, drinking mimosas, eating good food. LEONARD: And really, we were fighting the entire time. I had actually tried to break up with him, and it was a miserable trip. But I didn't tell anybody that. And I - you know, what I shared was the pictures of us in front of the fountain or at the aquarium or eating something delicious and not that we fought 90 percent of the time. You're kind of curating your life with just these very specific moments, the best of the best that you're putting up there with no context. VEDANTAM: More and more, Rachel found that she was turning to social media for validation. She wanted confirmation from her social media feed that her life was on track. The more she posted photos of her relationship, the more positive feedback she got. Like. . . LEONARD: I'm so happy for you. You're finally settling down - 'cause I'd been traveling forever. And, you know, you look great. You two look beautiful together. VEDANTAM: So Rachel convinced herself that this was what she wanted. She had constructed a beautiful version of the truth, and now she felt she had to live it. She got married, posted photos of the wedding. She says that she and her husband moved to a new city. They both got jobs. They bought a house, put down roots. LEONARD: You know, on the outside, it looked like we had this beautiful new house. And he had this great new job, and I had this great new job. And still, things were not good. VEDANTAM: The house looked beautiful from the outside but ended up being costly and difficult to fix. Worse than that, Rachel increasingly felt she was with the wrong person. LEONARD: The best way that I can put it is that we were just not suited for each other. And I knew it. I think that part of my psyche was just trying to ignore all of these signs that were just this person and I were not - we were not matched well. VEDANTAM: Rachel quickly got pregnant. She had a difficult pregnancy. But, again, that wasn't something she shared on social media. LEONARD: It was taboo to say that this doesn't feel good, this is really hard - as if you're not grateful that you were pregnant. And instead of being able to say those things out loud, I just posted pictures of my growing belly and, you know, cute things and working on the nursery and, you know, things like that instead of really focusing - or sharing what was going on for me internally. VEDANTAM: The unhappier Rachel felt, the more she posted. And she spent a lot of time looking at other people's posts, too. LEONARD: I would just scour other people's lives. I would just - to compare, you know, their happiness against my happiness, you know. Am I - I felt like I shouldn't be feeling the way I was feeling. VEDANTAM: It seemed like the grass was always greener for everyone else. Everyone else seemed more successful, happier in their marriages, having more fun with their pregnancies and the early days of motherhood. (SOUNDBITE OF MUSIC)VEDANTAM: Eventually, Rachel's marriage fell apart. She says she decided to move back to Cleveland, where her family is from, along with her son. And in that moment, something happened. LEONARD: You know, what was really interesting was when I knew I was moving back to Cleveland, I was trying to kind of put feelers out there because I knew I needed to find a job. And I didn't know how to say it without really saying what was going on. And so I, you know, posted that my son and I were coming back to Cleveland and we'd be there in June and I was looking for some - you know, a new adventure, something like that - put some spin on it. And I got so many private messages from friends of mine who were like, are you guys getting divorced? Blah, blah, blah, and I have been separated for six months or we're getting divorced or I've been divorced for two years. I had no idea. These were people who I looked at their lives. And maybe if I hadn't been so hyperfocused on my life, I would have maybe noticed that their husbands were not in all the pictures anymore. It was eye-opening. VEDANTAM: Once the spell was broken, Rachel realized something. LEONARD: I look at social media differently now. In fact, when people are posting a ton of stuff, I'm always kind of like - I wonder what other story is happening - not that there has to be doom and gloom and negativity. But there's always another story. There's always something else going on. There's context you could never pick up if you didn't know. VEDANTAM: There's always another story. We might know this intellectually, but we still often feel a sense of social comparison when we look at our social media feeds. OHAD BARZILAY: So it's not that you think that others are happier than you are. But you need to prove yourself to yourself over and over again. And this social comparison engagement makes you less happy. VEDANTAM: When we come back, we'll explore how the amount of time you spend on social media can determine how happy you are. Stay with us. This is NPR. (SOUNDBITE OF MUSIC)VEDANTAM: This is HIDDEN BRAIN. I'm Shankar Vedantam. (SOUNDBITE OF FILM, \"THE TRUMAN SHOW\")UNIDENTIFIED ACTOR #1: (As character) All over the world, in every language and culture, Truman is the ultimate media star, uniting us all in history's greatest entertainment endeavor, \"The Truman Show. \"VEDANTAM: In the 1998 movie \"The Truman Show,\" Jim Carrey is a star of his own reality TV show but he doesn't know it. His entire world is constructed by producers. His wife, his kids, his colleagues, they're all actors. His life is a series of scenes shot to appeal to an audience. (SOUNDBITE OF FILM, \"THE TRUMAN SHOW\")UNIDENTIFIED ACTOR #2: (As character) Truman's life is as real as anyone else's life. It's merely slightly planned. VEDANTAM: Truman eventually found that living inside a television set kept him from discovering his real life. Like Truman, many of us today find ourselves living inside a carefully curated world. The difference? These worlds are of our own making, on Facebook, Instagram and Twitter. When I first heard Rachel Leonard's story, I kept thinking about a tragic irony. She constructed a fake world to keep up with the happy lives of all her friends on Facebook, but many of her friends were doing exactly the same thing. They were trying to keep up with her. Everyone was posting pictures of that beautiful vacation. No one was saying anything about the fight they'd had during the car trip. LEONARD: What I'm not posting is that we fought a lot. VEDANTAM: You don't need me to tell you that there are many wonderful things about social media. It gives us an easy way to stay in touch with people we care about. But many studies have shown that people who use social media frequently appear to be unhappier than those who don't. Until recently, it was impossible to say whether this was correlation or causation. Do lonely people spend more time on social media in an effort to escape their loneliness, or is social media itself causing people to feel isolated? A recent study at Tel Aviv University has provided what may be the first experiment to sort out correlation from causation. BARZILAY: Yes. So my name is Ohad Barzilay, and I am a faculty member at the Coller School of Management in Tel Aviv University. VEDANTAM: Ohad and his colleagues wanted to test whether spending time on Facebook actually made people feel worse. They happened on what psychologists call a natural experiment. A security firm in Israel decided to restrict the Facebook use of its employees. No one was allowed to use Facebook at all for security reasons. The employees had to delete their accounts if they wanted to continue working for the company. But then after some time, the firm decided to allow some employees to reopen their accounts. They effectively created two groups, one that used Facebook, one that didn't. None of these people were choosing which group to be in so it couldn't be that people who are unhappy were the ones choosing to use Facebook. Ohad and his colleagues collected data about the employees from the time no one was allowed to use Facebook and a few months after some employees were allowed to use the social media website. BARZILAY: We decided to focus on Facebook's effect on social comparison, the perceptions of others' lives and happiness. VEDANTAM: Social comparison, the very thing Rachel struggled with, looking at other people's lives and trying to figure out whether she measured up. LEONARD: I would just scour other people's lives. I would, just to compare, you know, their happiness against my happiness. VEDANTAM: Ohad and his colleagues looked at both groups, and they found a few interesting things. BARZILAY: Our first finding is that using Facebook makes you more comparative. You compare yourself to others more often. You judge yourself, you compare. Am I better or worse than my friends? Am I happier? Are they happier? And so on. VEDANTAM: One surprising thing is that the study did not find that people thought others had better lives. They weren't fooled by all the happy vacation and anniversary pictures posted by their friends. BARZILAY: We know that people post on Facebook mostly positive things and they under-post negative things about their lives. So other studies have argued that users that use Facebook think that their friends have better lives than they have. So we did not find any support for this argument, and we think that maybe people make a correction in their perception and they know that people present a better version of themselves. VEDANTAM: In other words, many people reach the same conclusion that Rachel did. LEONARD: There's always another story. VEDANTAM: In spite of this, the researchers found that the employees who used Facebook became less happy over time compared to those who were prevented from using Facebook. BARZILAY: Being engaged in excessive social comparison decreased one's happiness. So it's not that you think that others are happier than you are, but you need to prove yourself to yourself over and over again, and this social comparison engagement makes you less happy. VEDANTAM: You need to prove yourself to yourself over and over again. In other words, it's not enough for many of us to know we're having a good time. It's not enough to take a beautiful photo, filter it, post it, see how our friends react. We also want our lives to be better, or at least as good as the lives of our friends. Comparing yourself to others doesn't just steal happiness because you discover that other people seem happier than you are. Comparing yourself to others steals happiness because the very act of comparison takes you out of the life you're living. It takes you out of the moment. The fear that others are leading happier lives than you are has a common nickname, FOMO, the fear of missing out. BARBARA KAHN: This particular thing of FOMO for me came from my daughter. My daughter's in her late 20s, and I just observed her friends and she experiencing FOMO and just driving themselves crazy from it. VEDANTAM: Barbara Kahn is a researcher at the University of Pennsylvania who studies perception and decision making. She became interested in studying FOMO after observing a situation with one of her daughter's friends. KAHN: One of her friends chose to go to a wedding in a beautiful locale instead of going to a beach weekend where the other friends were going to be. And instead of enjoying the wedding that she was at, she was looking at Facebook and looking at the activities of her friends at this beach weekend, which was a routine thing. It wasn't a special occasion at all. VEDANTAM: Here's the crucial part. The friend who went to the exotic locale for the wedding didn't think the beach was a better option. She chose to go to the wedding because she felt it was the better choice. Seeing her friends back at the beach didn't make her question her decision, but it did take her mind away from the beautiful spot she was in. KAHN: I think people make decisions and then FOMO undermines their enjoyment of the decisions that they've made. VEDANTAM: Now, as Barbara Kahn points out, FOMO means a lot of different things to different people. It's entirely possible, for example, that the friends who went to the beach vacation were looking at photos from the beautiful destination wedding and feeling like they were the ones who were missing out. But Barbara says the type of FOMO she ended up focusing on through a series of experiments is a very specific feeling. KAHN: What we found out from a lot of experiments that we ran, the thing that was generating the FOMO, the feelings of fear of missing out, it isn't really a fear. It's like a social anxiety, and it's really more about what are your friends doing in building up their social group history that you're missing out on? So it's not really about the experience per se. In all of our experiments, we found that it was really more a function of an anxiety that something might happen in a group experience that will shape the group history in the future that you may not be part of, and that will undermine your group belongingness. And in fact when we went back and said, OK, if you could make this decision again, would you choose to go to the beach weekend or to the wedding - although we didn't use that example in our studies, but that kind of thing - would you choose to go to the clearly better experience, or would you go to the routine thing your friends were doing on a regular basis? Almost every time, people said, no, I'd go to the exotic event. It wasn't that they didn't think that the exotic event was better and the smarter decision. They had no regret about making that decision. What they were anxious about - and we're using the word anxiety - was that maybe something would happen in the group that would forever change the dynamics of the group, and they wouldn't have been there when it happened. VEDANTAM: To be sure, envy and social anxiety were not invented by Facebook and Instagram and Snapchat, but Barbara Kahn says these platforms make us much more aware of all the things that are happening without us. She's run a series of experiments, each with a couple hundred undergraduates, testing the hypothesis that FOMO undermines our happiness with the decisions we've made. KAHN: What I think social media does is it allows you to see these routine things your friends are doing that you really never paid much attention to before, but when you see it on your phone or, you know, if you're looking on a tablet or online and you're just observing that your friends are doing something and you're not there, that's something you didn't get to see before. And suddenly you have this pang. I wonder what they're talking about. Or, what's happening? I'm not there. VEDANTAM: So even if you spent the day ziplining through the Costa Rican rain forest, when you get back to your hotel that night and check Facebook, knowing your friends are having a barbecue in Poughkeepsie diminishes some of the pleasure of the ziplining adventure. After seeing the photos of your friends in Poughkeepsie, Costa Rica now seems a little less magical. FOMO, the fear of missing out, leads to actually missing out. KAHN: Assume you have an opportunity to go to a concert of a musician you love and you never get to see, or you get to go to an exotic vacation, and you choose to do that rather than go to a routine barbecue with your friend. It's exactly set up like that. So we say assume you do that. Then the experiment is, in one condition, we say now assume while you're on vacation, you pick up your phone and you see your friends enjoying themselves at the barbecue. And in the other condition, which is the controlled condition, you pick up your phone and you scroll and you look at something, but it's not pictures of your friends. And then what we do is we - before we ask you to look at those pictures, before that manipulation, we measure how much you're enjoying your Hawaii vacation or the exotic concert or whatever. We have you either look at the pictures of your friends or not, and then we measure again how much are you enjoying where you are now? And what we find is a significant decrease in enjoyment when you've looked at the pictures than when you haven't. VEDANTAM: Barbara Kahn and her team are doing more experiments, but if their findings hold, they say something really sad about our use of social media. The fictional worlds we construct there can make our friends feel their lives are inadequate, and the fictional worlds our friends construct can make our lives feel duller than they actually are. As for Rachel, she's in a new relationship now and she says she's happy. She has a new job, and she and her son are doing well, but she doesn't feel the need to publicize any of this on Facebook. LEONARD: I don't take a lot of pictures anymore. If I'm there in a moment, and I'm having that moment, who's the picture for, you know? Is it for me to remember, or is it - you know, I'm - I am trying to live more presently for myself and for my son and just for my own mental well-being. VEDANTAM: She's asked her new boyfriend not to post about their relationship on social media, either. This time, the good moments and the bad will be theirs alone. (SOUNDBITE OF MUSIC)VEDANTAM: While many of us spend too much time on social media interacting with friends and acquaintances, some of us have too little contact with fellow human beings. (SOUNDBITE OF RADIO SHOW)UNIDENTIFIED RADIO HOST: All right. And next up, we have Diana (ph) shouting out to the Polunsky Unit. DIANA: Hito (ph), it's Mama D. I know I sound kind of different. I'm very sick right now, got diagnosed with pneumonia. Been sick already for quite some time now. VEDANTAM: This is the voice of a woman calling into a radio show on the Texas station KPFA. She has a personal message for a prison inmate. (SOUNDBITE OF RADIO SHOW)DIANA: Anyway, I want to tell you, Hito, that Mama D loves you. I always think of you. And it's just getting harder and harder. I know I'm not supposed to cry 'cause you're going to get mad at me. But I can't help but feel so much love for you. VEDANTAM: Calling into a program like this is one of the few ways for spouses and parents and children to communicate with prisoners, especially inmates in solitary confinement. In recent years, both liberals and conservatives worried about the psychological and financial costs of long-term solitary confinement have raised questions about the practice. In the second half of our show, we explore what happens inside the prison cells that few people ever see and the psychological effects of being alone for long periods of time. That's coming up in just a moment. I'm Shankar Vedantam. And you're listening to HIDDEN BRAIN from NPR. (SOUNDBITE OF MUSIC)VEDANTAM: This is HIDDEN BRAIN. I'm Shankar Vedantam. Social contact is a fundamental aspect of human life. So what's it like to spend vast stretches of time in solitary confinement, to live without the hundreds of interactions that most of us have with people around us every day? Keramet Reiter has spent more than a decade researching the effects of loneliness on these inmates. She's a professor of criminology at the University of California Irvine and the author of the book \"23/7: Pelican Bay Prison And The Rise Of Long-Term Solitary Confinement. \" Besides being a researcher, she's also been a prisoner's rights activist at Human Rights Watch. Keramet, welcome to HIDDEN BRAIN. REITER: Thanks for having me, Shankar. VEDANTAM: You can't tell the story of solitary confinement without understanding the story of a man named George Jackson. He was sent to prison in the early 1960s after pleading guilty to armed robbery. And he was sentenced to a term of one year to life. What was the thinking behind this kind of indeterminate sentence? REITER: So the idea for someone like George Jackson was that he would go to prison, and he'd have to prove that he'd been rehabilitated before he could get out of prison. Around the time Jackson went to prison, however, people started to look at these indeterminate sentences and realize that they were having truly disproportionate impacts depending on the race of the person with the sentence. So white people had a much easier time convincing prison officials that they had been reformed and should be let out of prison than African-American men like George Jackson happened to be. So George Jackson found himself, essentially, stuck in prison. Years went by when he was denied parole, and he became radicalized in this process. He wrote a book of best-selling letters that achieved national and international acclaim - letters to his family and to his lawyers - articulating his revolutionary politics and the problems with things like this indeterminate sentence. This brought him to the attention of prison officials, and he was accused of murdering a prison guard in the early 1970s. And he was preemptively sent to death row at San Quentin while he awaited a death penalty trial for that murder he was accused of. And while on death row at San Quentin - in an isolation unit, interestingly - one day, his lawyer came in to visit him. And this story that prison officials tell - and it's been repeated many times - is that his lawyers snuck a 9-millimeter gun into him inside of a tape recorder and that Jackson then used that gun to try to escape from this isolation unit. All we actually know is that he was shot to death on the San Quentin prison yard as he ran out of that isolation unit. And when staff ran into the unit to see what had happened, they found three officers and two more prisoners who'd been stabbed to death. So this was the most violent day in California's prison history ever - six deaths total on August 21, 1971. And this moment is a moment that people point to in California as incredibly important in understanding why the state needed long-term solitary confinement units. And similar things happened across the U. S. And prison officials in other states point to those moments. So two weeks after George Jackson died, the revolt at Attica happened. Similarly, following that, prisoners were locked into their cells. And that became a moment people pointed to as a justification for really long-term solitary confinement. VEDANTAM: You also tell a story of a prison administrator Carl Larson, who began his career the same year that George Jackson went to prison. I understand you interviewed Carl Larson. And his view gives us a glimpse into the other side of the story, how prison guards and prison officials see the need for solitary confinement. REITER: So Carl Larson was one of the earlier people I interviewed in doing this work. And to my surprise, we got to be friends. I came at this work from a perspective of a prisoner's rights advocate very critical of the system. But as I got to know Carl Larson, I saw that he had a really interesting perspective on the system. And he was one of the first people to point me to the story of George Jackson and to explain how scary it was to be a guard working in the California prisons in the 1970s when these deaths were happening and to make that fear real for me in a way that helped me to understand why he thought a long-term-solitary-confinement facility made sense. So Carl Larson is particularly interesting because, as you said, he started out as a - as an officer in the 1970s in California prisons, actually even earlier. And then he worked his way up through the system, becoming a warden and then becoming head of the prison construction projects that California engaged in in the 1980s when the state built one of these long-term-solitary-confinement supermax facilities. And he takes credit for designing one of the first of these institutions. And that's really interesting because he's a prison administrator. He's not an architect. He's not an expert in exactly what kinds of punishments work. He didn't have a law degree. He had just worked in prisons. And he designed this completely new facility. VEDANTAM: I understand that there was some interesting architectural features with this facility, Pelican Bay. The cement for the facility was poured in one large block and - so that the cells were not built in individual units. REITER: So one of the things that's striking about the place is it's made of these poured concrete cells. So they're incredibly easy to hose down, which is - the fact that they can stay clean is important because courts earlier had criticized isolation units for being really dirty. And they're grouped together into these pods of eight. And then the pods of eight are grouped together again into these tessellated T-structures so that one officer can look out over six pods of cells at a time. So it's a modern panopticon. And that also - that allows - the fact that there are no windows makes it really easy to just fit all these blocks together, if you can imagine that structure. VEDANTAM: I'm wondering, Keramet, if you can actually just describe what one of these cells looks like? Give me a sense of what's in the cell, how big it is. What does it actually feel like to be in one of these units? REITER: So the cells in these units are generally about 8 by 10 feet. So imagine a wheelchair-accessible bathroom stall or a generous parking space - pretty small. You can, you know, almost reach from one end of the cell to the other. And they're fairly self-contained. So they contain a poured concrete ledge with a very thin piece of foam over it, and that's the bed. And then there's another sort of concrete bit protruding that is a desk-and-seat combination. So it's just like a concrete block that a prisoner could sit on and write there. And then there's - in another corner there's a steel, usually toilet-sink combination. So it's just, you know, one smooth steel object that has running water and plumbing for the prisoner. Sometimes there are showers in these cells, but generally, it's just a sink and a toilet. And, again, if the prisoner is lucky and they can afford it and the system they're in allows it, they might have a TV or a radio. And usually they're allowed maybe a few books at a time and a little bit of paper for writing letters or doing legal paperwork. (SOUNDBITE OF MUSIC)VEDANTAM: To be clear, many prisoners in solitary have been found guilty of heinous crimes including murder, rape and terrorism. But here's something you might not know. Some are there because they're difficult to manage or because of bureaucratic inertia. While judges and juries decide whether someone should go to prison, a decision that can be appealed in court, typically it's prison officials who decide whether someone should be in solitary confinement. I asked Keramet to describe the kind of prisoner who ends up in solitary. REITER: There's been shockingly little research over time on who ends up in solitary confinement and how. And it's very hard to track across states. But as people have paid more attention to this and through the work I've done, I've started to see some patterns that there's a disproportionate racial impact of solitary confinement. So we know that in our prisons in general, African-Americans and Latinos are more likely to be in prison than - in the general prison population. They're doubly likely, again, to be in solitary confinement than even the general prison population. And that's often because gang members are being targeted for long-term isolation, especially in states like California. Prison systems are not putting people there based on some act or rule that they broke but based on their status as dangerous. So prisoners get labeled dangerous gang members and they get sent to isolation indefinitely. In general, I think one way to think about people who end up in isolation is that it's often the people who are really difficult for the system to manage. So that might include seriously mentally-ill prisoners. There's recent research showing that transgender prisoners are really likely to end up in isolation, that pregnant women end up there. So people who the system just isn't equipped to provide resources to can end up there also. VEDANTAM: Keramet Reiter is a professor of criminology at the University of California, Irvine and the author of \"23/7: Pelican Bay Prison And The Rise Of Long-Term Solitary Confinement. \" So the rise of these institutions coincided in some ways with a decline or closing down of various institutions for the mentally ill, which speaks, of course, to the point that you were just making. But I also understand that this is reflected in the number of suicides we see in solitary confinement compared to the general prison population. REITER: There is a very close relationship between solitary confinement and mental illness. One way to understand that is that in the 1970s and early '80s when mental institutions closed was the same time that mass incarceration and rates of incarceration are increasing across the United States. And that meant that some mentally ill people unsurprisingly ended up in prisons. And one of the arguments I make is that as those people ended up in prison, they tended to be put into solitary confinement. And that's one explanation for the fact that rates of suicide in solitary confinement can be twice as high as in the general prison population or even higher and that rates of mental illness and isolation can be high. And often there's a real chicken-and-egg problem of, you know, did a person get sent to isolation because they were mentally ill and states have tried to limit that, or do people in isolation develop mental illnesses? VEDANTAM: Most of us are never going to see the inside of a supermax. But we often do see scenes of solitary confinement described in pop culture. One of those examples is the TV show \"Orange Is The New Black. \" We have a bit of tape. The character Piper is put into a security housing unit and starts speaking to a voice she hears through the grate of her cell. (SOUNDBITE OF TV SHOW, \"ORANGE IS THE NEW BLACK\")TAYLOR SCHILLING: (As Piper Chapman) How long have you been down here? LAVERNE COX: (As Sophia Burset) I lost track. I don't know - nine months, a year. SCHILLING: (As Piper Chapman) A year - that's insane. COX: (As Sophia Burset) They keep the lights on, so you lose all sense of time. It's not living. I mean, yeah, you're breathing. But you ain't a real person no more. It's bad. You start to see [expletive] that ain't there. You start to hear voices. SCHILLING: (As Piper Chapman) Oh, my God. COX: (As Sophia Burset) They keep you here until they break you. SCHILLING: (As Piper Burset) I feel like I'm going to throw up. VEDANTAM: Keramet, I'm wondering how accurate that description is of what life's actually like in solitary confinement. REITER: I do think that the disembodied voice that you hear talking to Piper is accurate on a number of levels. The voice is kind of flattened in effect. And the prisoner was describing hearing voices, hallucinations. That's a very common side effect of isolation. And people talk about time - the way they perceive time changing because there is no way to mark time. People talk about it exactly as that prisoner said. It's not that it even feels long. It's just that it's almost endless, that days can kind of, in a weird, counterintuitive way, fly by because there's nothing marking anything about a day or week. So in that sense, it's accurate. (SOUNDBITE OF MUSIC)VEDANTAM: I want to spend a moment talking about your own role in looking at this. On the one hand, you are a researcher who has spent time studying the question. But as you yourself have said, you know, you're also a prison rights advocate. You've been an activist at Human Rights Watch and other organizations. How do you preserve your ability to be analytical about the subject while you also have what are very clearly strong views about solitary confinement? REITER: You know, when I went to interview Carl Larson, he said, well, you're a Berkeley liberal (laughter). So he asked me to do some background reading and prove that I was serious. And I would listen to him. And so I actually think in the process of doing this work, I have become more open-minded and been criticized by advocates for talking so directly and so extensively to prison officials. And so I've had the interesting experience of trying to keep the conversation open across a really broad spectrum of perspectives on this process. And I think in that way, I've been able to try to at least incorporate these different perspectives and tease apart the arguments and the positions people are coming from. And I do think that in reform, prison officials have to walk into these institutions and engage with these prisoners day in and day out. And they also need to be part of the reform conversation. And through this process, you know, surprisingly, even though I came basically from the other side, if you want to think of it in terms of sides, I've come to see that perspective. VEDANTAM: Keramet, what sorts of things do people in solitary confinement say they miss? What are the kind of things that you miss that the rest of us might not think about? REITER: So people talk about not having seen the moon in years or decades and how much they miss that. And then people talk about missing just pure human touch. And you know, I tell a story in the book about a prisoner who - his cell door and the cell door of the prisoner next to him were accidentally opened at the same time. And they were rival gang members. But they had been talking to each other, shouting through the cell walls. And when the cell doors opened, they just reached around and grabbed each other's hands and held on because it had been so long since either of them had had a gentle human touch like that. VEDANTAM: Prisoners often stay alone in their cells for 22 or 23 hours a day. And you found that perhaps the only way to actually manage this psychologically is to stick to a series of very, very rigid routines. Tell me about those routines. REITER: The prisoners who I was able to interview in this research to understand their experiences tended to be the prisoners who survived. And so they did develop all kinds of coping mechanisms. And one of the ones I heard about again and again was that they would wake up, you know, first thing in the morning, 5 a. m. And they would do thousands of repetitive exercises, often what prisoners called burpees - so a combination of jumping jacks, push-ups and sit-ups - and, you know, literally a few thousand in the morning to start out their day and then clean their cells, write letters, work on legal cases. And in general in these units, if prisoners are following the rules and they have money being sent in from family, they can buy either a TV or a radio. And prisoners who develop these routines talk about really limiting the time they spend listening to media, so maybe only an hour a day or two hours a day or a special show they like to watch so that they were keeping both their bodies and their minds really busy really consciously over the course of the day. And interestingly, prisoners talk about having trouble letting go of these routines once they got out of prison, that they would still do those thousands of burpees every morning at 5 a. m. when they got up and that their ability to control everything in their space in that 8-by-10 cell they live in is also hard to let go of, that they could keep - you know, a prisoner described to me how he could keep the cap of his toothpaste perfectly clean. And it was really hard when he had a roommate when he got out of prison - the fact that he couldn't control the cap of the toothpaste anymore - so kind of gives you a sense of how intense it is to survive and then how long those coping mechanisms linger afterwards. VEDANTAM: You talk in the book, Keramet, about inmates trying a number of different things to not just be physically active and mentally active but emotionally expressive, to try and find ways to do artistic things. Can you talk about that for a moment? REITER: Prisoners do struggle to find ways to express themselves. And sometimes that's becoming really good at the law and litigating cases. But very often it's teaching themselves to draw, sometimes teaching themselves to speak a new language, sometimes teaching themselves to sew. One of my favorite stories was a prisoner who told me that he was in isolation for a number of months. And I'm not even sure how he made himself a needle. I know that he pulled threads out of the jumpsuits they're given in order to make thread. And then he started tailoring his clothes so that they fit better. They're often given these very loose jumpsuits. And so he would add cuffs or shorten the sleeves. And I think other prisoners found out about him doing this. And in some cases, a friendly officer would pass a uniform back and forth. And he started tailoring other people's uniforms. It's kind of - and not that anyone is even seeing them. But it's this amazing kind of self-expression and community that they're managing to create in this place. VEDANTAM: I'm sure they're going to be people who say, look; there are lots of people in these units who really are the worst of the worst. Maybe not all of them are, but some of them probably are. Some of them probably are really violent and really dangerous and ought to be there. And I'm wondering, do you ever feel that they might be people who need to be in solitary confinement? REITER: So there are certainly people in isolation who are dangerous. One of the really important points of analysis is the length of time people are spending in isolation, the fact that people - we're not talking about weeks or months. We're talking about years and decades often and that even people who might have been fairly scary or dangerous in their 20s are unlikely to be that way into their 40s and 50s. And as we look at decades of these policies, we see that even some of the people who have been held up as the scariest, the system didn't control them very well while they were in it. And they're doing surprisingly well outside of isolation. So it really does call the practice into question on all different levels. VEDANTAM: So your book comes at a time when many liberals and conservatives have joined hands to call for prison reform. For one thing, keeping people in prison and keeping someone in solitary confinement is very, very expensive. Give us a sense of how expensive it is and whether these ideological pairings are triggering any change in the system. REITER: So solitary confinement is astronomically expensive. In states like California, it costs about $45,000 per prisoner per year to keep someone in the general prison population. And it costs about $90,000 per prisoner per year to keep someone in isolation. So the cost of running the facilities is really expensive because these prisoners in isolation, you know - every need has to be met by someone working in the prison, whether it's delivering mail or or delivering legal documents or getting them a meal. So that's how the costs go up. And the costs of the facilities are also expensive to build these kinds of technologically advanced facilities. And that's not even wrapped into that per-prisoner per-year cost. So I think that has been part of the reform conversation, as you suggest, that perhaps there might be a less-expensive way to do this. One other cost of isolation is that the vast majority of people, even from long-term solitary confinement, ultimately get out of prison. It's a - it's - 95 to 98 percent of all prisoners get out eventually, and that's surprisingly true of people in isolation, too. And so there's the question of, what are the social impacts of letting people out? And I think in combination those economic costs and the social costs, people are beginning to think about alternatives. And that is a conversation that is - crosses political lines. And prison, as I suggested, in many states - legislators are initiating reforms. Some litigation has happened. But in many states, prison officials within the system are looking at the norms changing and the critics of this practice and initiating their own reform, saying what can we do to reduce our reliance on this practice? (SOUNDBITE OF MUSIC)VEDANTAM: Keramet Reiter is a professor at the University of California at Irvine. She's the author of the book \"23/7: Pelican Bay Prison And The Rise Of Long-Term Solitary Confinement. \" Keramet, thank you for joining me on HIDDEN BRAIN today. REITER: Thanks for having me. (SOUNDBITE OF MUSIC)VEDANTAM: This week's show was produced by Maggie Penman and Parth Shah. It was edited by Tara Boyle. Our team includes Rhaina Cohen, Jenny Schmidt and Renee Klahr. Our engineers are Andy Huether and Jay Sciz (ph). NPR's vice president for programming and audience development is Anya Grundmann. If you liked the show, check out our weekly podcast. Search for HIDDEN BRAIN in NPR One, iTunes or wherever you find your podcasts. You can also follow the show on Facebook, Twitter and Instagram and listen to my stories on Morning Edition each week on your local public radio station. I'm Shankar Vedantam. See you next week. (SOUNDBITE OF MUSIC) SHANKAR VEDANTAM, HOST:  This is HIDDEN BRAIN. I'm Shankar Vedantam. UNIDENTIFIED EXERCISE INSTRUCTOR: And then see if can begin to deepen your breath here - a nice, long inhale in (inhales) and a nice, long juicy exhale out (exhales). VEDANTAM: There are some commonly accepted ideas about what it means to be healthy. Healthy people eat lots of fruits and vegetables. They don't do drugs. And of course, they exercise. UNIDENTIFIED EXERCISE INSTRUCTOR: Draw your palms together at the heart. Take a deep breath in. Each time we. . . VEDANTAM: While physical activity and food dominate our discussions about well-being, the importance of social interaction is often overlooked. UNIDENTIFIED WOMAN #1: I think the movie was better than the book. UNIDENTIFIED MAN #1: I'm all right. UNIDENTIFIED WOMAN #2: What's your horoscope? UNIDENTIFIED MAN #2: I'd like a large cappuccino with. . UNIDENTIFIED WOMAN #3: Long time, no see. UNIDENTIFIED WOMAN #4: How are you? VEDANTAM: There's a large and growing body of research about how critical social contact is to human survival. UNIDENTIFIED MAN #3: That outfit looks so good on you. Where'd you get those shoes? UNIDENTIFIED WOMAN #5: I'll have a double espresso, please. VEDANTAM: A University of Utah study showed that people with strong relationships have lower blood pressure than lonelier counterparts. UNIDENTIFIED WOMAN #6: I've got to read that book still. UNIDENTIFIED MAN #4: What time is it? UNIDENTIFIED WOMAN #7: It's time for you to get a watch. UNIDENTIFIED WOMAN #8: I'm a huge Carolina fan. UNIDENTIFIED MAN #5: Can you pass the salt? VEDANTAM: Researchers at the University of Chicago found that people who report strong feelings of loneliness are more likely to binge eat. UNIDENTIFIED MAN #6: That place has the best donuts. UNIDENTIFIED WOMAN #9: That place has the worst donuts. UNIDENTIFIED WOMAN #10: I'll take two scoops of mint chocolate chip. VEDANTAM: And at Harvard, one study found that people with good relationships actually live longer and live happier. UNIDENTIFIED WOMAN #11: Happy birthday. UNIDENTIFIED MAN #7: Happy birthday. UNIDENTIFIED WOMAN #12: Happy birthday. UNIDENTIFIED MAN #8: Feliz cumpleanos. VEDANTAM: Our social ties are unquestionably at the core of what it means to be human. UNIDENTIFIED MAN #9: Anything good on Netflix? UNIDENTIFIED WOMAN #13: I just got back from (unintelligible). UNIDENTIFIED MAN #10: Are you going to happy hour tonight? (CROSSTALK) UNIDENTIFIED WOMAN #14: When is the next train coming? UNIDENTIFIED MAN #11: Dinner after work? UNIDENTIFIED WOMAN #15: Long time, no see. UNIDENTIFIED WOMAN #16: Good job. UNIDENTIFIED WOMAN #17: All right, so take a left turn on. . . UNIDENTIFIED MAN #12: How was your weekend? (CROSSTALK) VEDANTAM: So what happens if you're cut off from human contact? (SOUNDBITE OF MUSIC) VEDANTAM: Later in the show, we talk about the effects of long-term solitary confinement. KERAMET REITER: People talk about not having seen the moon in years or decades and how much they miss that. And then people talk about missing just pure human touch. (SOUNDBITE OF MUSIC) VEDANTAM: First, though, we start by exploring the other end of the spectrum, interaction overload. (SOUNDBITE OF MUSIC) VEDANTAM: In her 20s and 30s, Rachel Leonard lived all over the United States. RACHEL LEONARD: Out in Colorado and upstate New York. And I lived in Vermont for a long time. And then I was living in Asheville, N. C. VEDANTAM: And she traveled - all over the world. She met lots of different people in all these places. To keep in touch with them, she signed up for Facebook. LEONARD: I was traveling in Central America, 2006 and 2007. And I did not have a phone, and I was in pretty remote areas. I signed up then because I kept meeting all these wonderful people. And one of the ways to immediately, you know, connect with them was to friend them on Facebook. VEDANTAM: The site became an important tool for Rachel to keep in touch with people she'd met on her travels, to share her adventures with friends and family back home. LEONARD: That's actually when I started sharing, like, my travels with other friends - my pictures of my trip. VEDANTAM: But as much as Rachel loved traveling and felt good about the choices she'd made in her life, other feelings started to sneak up on her. Having Facebook also allowed her to see what everyone else was up to while she was backpacking in Central America or moving from one city to another. LEONARD: You know, everybody is getting married. Some people have one child. Some people have two children. All my friends have these high-power jobs, and they own houses and all of these things. VEDANTAM: These feelings were at the back of her mind a few years later when she met a guy and decided to start a relationship. LEONARD: I met him, and I had been planning to leave the country and go to Southeast Asia to teach. And I met him in December. And I was supposed to leave in June, and I didn't go. VEDANTAM: Her new boyfriend asked her to stay with him in Asheville, N. C. She wasn't sure it was the right thing to do, but she agreed. LEONARD: It was a turning point in my life in lots of ways because, up until then, I'd kind of been this free spirit and did what I wanted and traveled a lot and still had that wanderlust. But I was also 33 and kind of looking around and realizing that other people were getting married and having kids. And I decided maybe I should try this out. VEDANTAM: Soon, like so many of her friends, she was posting pictures and details about her happy relationship. LEONARD: We got engaged pretty quickly. And, you know, at this time, I'm posting my pictures. I'm posting our hikes. We lived in, you know, the Blue Ridge Mountains, so we'd have these beautiful hikes and this lovely little town, and of course I'm posting all of this. VEDANTAM: Her engagement was chronicled, the new house they moved into, the view from the porch. All of it look beautiful on Facebook. LEONARD: If you looked only from the porch, you could see mountains straight. But if you looked to the left, you could see this huge factory. But of course I didn't take pictures of the factory 'cause why would you do that? VEDANTAM: Because Facebook is not a place for pictures of ugly factories. LEONARD: It was very taboo not to share positivity. No one ever put negative stuff on there. And if they did, people were like - what's going on with blah, blah, blah? So it was always about being positive and showing your best side and your best moments. VEDANTAM: Facebook is also not a place for ambivalence. Celebrating triumph? That's welcome. Mourning a tragedy? That's OK, too. Expressing uncertainty and doubt? Not so much. We all intuitively understand the rules. Posts about engagements and babies will receive ravenous applause. News about a grandparent passing away will elicit virtual hugs. But fears about not making rent, marital tensions, hesitations about becoming a parent? Those are verboten. Rachel started to feel constricted. The more she posted about her happy life on social media, the greater the disconnect she felt with her real life. LEONARD: I know now that at the time, while it looked great and it looked right, it didn't really feel right for me. But I think that putting it out there and having my friends say - oh, this looks so wonderful. You look so happy. This is great - it was kind of my way of convincing myself it was. And I'd say that the more things didn't feel great, the more I posted. (SOUNDBITE OF MUSIC) VEDANTAM: The gulf widened between her real relationship and the Facebook version. LEONARD: What I'm not posting is that we fought a lot. And what seemed to be kind of perfect to other people was not. VEDANTAM: When the new couple took a trip to Charleston, Rachel says her friends on Facebook only saw the beautiful pictures. She posted photos of the two of them sitting on the beach, drinking mimosas, eating good food. LEONARD: And really, we were fighting the entire time. I had actually tried to break up with him, and it was a miserable trip. But I didn't tell anybody that. And I - you know, what I shared was the pictures of us in front of the fountain or at the aquarium or eating something delicious and not that we fought 90 percent of the time. You're kind of curating your life with just these very specific moments, the best of the best that you're putting up there with no context. VEDANTAM: More and more, Rachel found that she was turning to social media for validation. She wanted confirmation from her social media feed that her life was on track. The more she posted photos of her relationship, the more positive feedback she got. Like. . . LEONARD: I'm so happy for you. You're finally settling down - 'cause I'd been traveling forever. And, you know, you look great. You two look beautiful together. VEDANTAM: So Rachel convinced herself that this was what she wanted. She had constructed a beautiful version of the truth, and now she felt she had to live it. She got married, posted photos of the wedding. She says that she and her husband moved to a new city. They both got jobs. They bought a house, put down roots. LEONARD: You know, on the outside, it looked like we had this beautiful new house. And he had this great new job, and I had this great new job. And still, things were not good. VEDANTAM: The house looked beautiful from the outside but ended up being costly and difficult to fix. Worse than that, Rachel increasingly felt she was with the wrong person. LEONARD: The best way that I can put it is that we were just not suited for each other. And I knew it. I think that part of my psyche was just trying to ignore all of these signs that were just this person and I were not - we were not matched well. VEDANTAM: Rachel quickly got pregnant. She had a difficult pregnancy. But, again, that wasn't something she shared on social media. LEONARD: It was taboo to say that this doesn't feel good, this is really hard - as if you're not grateful that you were pregnant. And instead of being able to say those things out loud, I just posted pictures of my growing belly and, you know, cute things and working on the nursery and, you know, things like that instead of really focusing - or sharing what was going on for me internally. VEDANTAM: The unhappier Rachel felt, the more she posted. And she spent a lot of time looking at other people's posts, too. LEONARD: I would just scour other people's lives. I would just - to compare, you know, their happiness against my happiness, you know. Am I - I felt like I shouldn't be feeling the way I was feeling. VEDANTAM: It seemed like the grass was always greener for everyone else. Everyone else seemed more successful, happier in their marriages, having more fun with their pregnancies and the early days of motherhood. (SOUNDBITE OF MUSIC) VEDANTAM: Eventually, Rachel's marriage fell apart. She says she decided to move back to Cleveland, where her family is from, along with her son. And in that moment, something happened. LEONARD: You know, what was really interesting was when I knew I was moving back to Cleveland, I was trying to kind of put feelers out there because I knew I needed to find a job. And I didn't know how to say it without really saying what was going on. And so I, you know, posted that my son and I were coming back to Cleveland and we'd be there in June and I was looking for some - you know, a new adventure, something like that - put some spin on it. And I got so many private messages from friends of mine who were like, are you guys getting divorced? Blah, blah, blah, and I have been separated for six months or we're getting divorced or I've been divorced for two years. I had no idea. These were people who I looked at their lives. And maybe if I hadn't been so hyperfocused on my life, I would have maybe noticed that their husbands were not in all the pictures anymore. It was eye-opening. VEDANTAM: Once the spell was broken, Rachel realized something. LEONARD: I look at social media differently now. In fact, when people are posting a ton of stuff, I'm always kind of like - I wonder what other story is happening - not that there has to be doom and gloom and negativity. But there's always another story. There's always something else going on. There's context you could never pick up if you didn't know. VEDANTAM: There's always another story. We might know this intellectually, but we still often feel a sense of social comparison when we look at our social media feeds. OHAD BARZILAY: So it's not that you think that others are happier than you are. But you need to prove yourself to yourself over and over again. And this social comparison engagement makes you less happy. VEDANTAM: When we come back, we'll explore how the amount of time you spend on social media can determine how happy you are. Stay with us. This is NPR. (SOUNDBITE OF MUSIC) VEDANTAM: This is HIDDEN BRAIN. I'm Shankar Vedantam. (SOUNDBITE OF FILM, \"THE TRUMAN SHOW\") UNIDENTIFIED ACTOR #1: (As character) All over the world, in every language and culture, Truman is the ultimate media star, uniting us all in history's greatest entertainment endeavor, \"The Truman Show. \" VEDANTAM: In the 1998 movie \"The Truman Show,\" Jim Carrey is a star of his own reality TV show but he doesn't know it. His entire world is constructed by producers. His wife, his kids, his colleagues, they're all actors. His life is a series of scenes shot to appeal to an audience. (SOUNDBITE OF FILM, \"THE TRUMAN SHOW\") UNIDENTIFIED ACTOR #2: (As character) Truman's life is as real as anyone else's life. It's merely slightly planned. VEDANTAM: Truman eventually found that living inside a television set kept him from discovering his real life. Like Truman, many of us today find ourselves living inside a carefully curated world. The difference? These worlds are of our own making, on Facebook, Instagram and Twitter. When I first heard Rachel Leonard's story, I kept thinking about a tragic irony. She constructed a fake world to keep up with the happy lives of all her friends on Facebook, but many of her friends were doing exactly the same thing. They were trying to keep up with her. Everyone was posting pictures of that beautiful vacation. No one was saying anything about the fight they'd had during the car trip. LEONARD: What I'm not posting is that we fought a lot. VEDANTAM: You don't need me to tell you that there are many wonderful things about social media. It gives us an easy way to stay in touch with people we care about. But many studies have shown that people who use social media frequently appear to be unhappier than those who don't. Until recently, it was impossible to say whether this was correlation or causation. Do lonely people spend more time on social media in an effort to escape their loneliness, or is social media itself causing people to feel isolated? A recent study at Tel Aviv University has provided what may be the first experiment to sort out correlation from causation. BARZILAY: Yes. So my name is Ohad Barzilay, and I am a faculty member at the Coller School of Management in Tel Aviv University. VEDANTAM: Ohad and his colleagues wanted to test whether spending time on Facebook actually made people feel worse. They happened on what psychologists call a natural experiment. A security firm in Israel decided to restrict the Facebook use of its employees. No one was allowed to use Facebook at all for security reasons. The employees had to delete their accounts if they wanted to continue working for the company. But then after some time, the firm decided to allow some employees to reopen their accounts. They effectively created two groups, one that used Facebook, one that didn't. None of these people were choosing which group to be in so it couldn't be that people who are unhappy were the ones choosing to use Facebook. Ohad and his colleagues collected data about the employees from the time no one was allowed to use Facebook and a few months after some employees were allowed to use the social media website. BARZILAY: We decided to focus on Facebook's effect on social comparison, the perceptions of others' lives and happiness. VEDANTAM: Social comparison, the very thing Rachel struggled with, looking at other people's lives and trying to figure out whether she measured up. LEONARD: I would just scour other people's lives. I would, just to compare, you know, their happiness against my happiness. VEDANTAM: Ohad and his colleagues looked at both groups, and they found a few interesting things. BARZILAY: Our first finding is that using Facebook makes you more comparative. You compare yourself to others more often. You judge yourself, you compare. Am I better or worse than my friends? Am I happier? Are they happier? And so on. VEDANTAM: One surprising thing is that the study did not find that people thought others had better lives. They weren't fooled by all the happy vacation and anniversary pictures posted by their friends. BARZILAY: We know that people post on Facebook mostly positive things and they under-post negative things about their lives. So other studies have argued that users that use Facebook think that their friends have better lives than they have. So we did not find any support for this argument, and we think that maybe people make a correction in their perception and they know that people present a better version of themselves. VEDANTAM: In other words, many people reach the same conclusion that Rachel did. LEONARD: There's always another story. VEDANTAM: In spite of this, the researchers found that the employees who used Facebook became less happy over time compared to those who were prevented from using Facebook. BARZILAY: Being engaged in excessive social comparison decreased one's happiness. So it's not that you think that others are happier than you are, but you need to prove yourself to yourself over and over again, and this social comparison engagement makes you less happy. VEDANTAM: You need to prove yourself to yourself over and over again. In other words, it's not enough for many of us to know we're having a good time. It's not enough to take a beautiful photo, filter it, post it, see how our friends react. We also want our lives to be better, or at least as good as the lives of our friends. Comparing yourself to others doesn't just steal happiness because you discover that other people seem happier than you are. Comparing yourself to others steals happiness because the very act of comparison takes you out of the life you're living. It takes you out of the moment. The fear that others are leading happier lives than you are has a common nickname, FOMO, the fear of missing out. BARBARA KAHN: This particular thing of FOMO for me came from my daughter. My daughter's in her late 20s, and I just observed her friends and she experiencing FOMO and just driving themselves crazy from it. VEDANTAM: Barbara Kahn is a researcher at the University of Pennsylvania who studies perception and decision making. She became interested in studying FOMO after observing a situation with one of her daughter's friends. KAHN: One of her friends chose to go to a wedding in a beautiful locale instead of going to a beach weekend where the other friends were going to be. And instead of enjoying the wedding that she was at, she was looking at Facebook and looking at the activities of her friends at this beach weekend, which was a routine thing. It wasn't a special occasion at all. VEDANTAM: Here's the crucial part. The friend who went to the exotic locale for the wedding didn't think the beach was a better option. She chose to go to the wedding because she felt it was the better choice. Seeing her friends back at the beach didn't make her question her decision, but it did take her mind away from the beautiful spot she was in. KAHN: I think people make decisions and then FOMO undermines their enjoyment of the decisions that they've made. VEDANTAM: Now, as Barbara Kahn points out, FOMO means a lot of different things to different people. It's entirely possible, for example, that the friends who went to the beach vacation were looking at photos from the beautiful destination wedding and feeling like they were the ones who were missing out. But Barbara says the type of FOMO she ended up focusing on through a series of experiments is a very specific feeling. KAHN: What we found out from a lot of experiments that we ran, the thing that was generating the FOMO, the feelings of fear of missing out, it isn't really a fear. It's like a social anxiety, and it's really more about what are your friends doing in building up their social group history that you're missing out on? So it's not really about the experience per se. In all of our experiments, we found that it was really more a function of an anxiety that something might happen in a group experience that will shape the group history in the future that you may not be part of, and that will undermine your group belongingness. And in fact when we went back and said, OK, if you could make this decision again, would you choose to go to the beach weekend or to the wedding - although we didn't use that example in our studies, but that kind of thing - would you choose to go to the clearly better experience, or would you go to the routine thing your friends were doing on a regular basis? Almost every time, people said, no, I'd go to the exotic event. It wasn't that they didn't think that the exotic event was better and the smarter decision. They had no regret about making that decision. What they were anxious about - and we're using the word anxiety - was that maybe something would happen in the group that would forever change the dynamics of the group, and they wouldn't have been there when it happened. VEDANTAM: To be sure, envy and social anxiety were not invented by Facebook and Instagram and Snapchat, but Barbara Kahn says these platforms make us much more aware of all the things that are happening without us. She's run a series of experiments, each with a couple hundred undergraduates, testing the hypothesis that FOMO undermines our happiness with the decisions we've made. KAHN: What I think social media does is it allows you to see these routine things your friends are doing that you really never paid much attention to before, but when you see it on your phone or, you know, if you're looking on a tablet or online and you're just observing that your friends are doing something and you're not there, that's something you didn't get to see before. And suddenly you have this pang. I wonder what they're talking about. Or, what's happening? I'm not there. VEDANTAM: So even if you spent the day ziplining through the Costa Rican rain forest, when you get back to your hotel that night and check Facebook, knowing your friends are having a barbecue in Poughkeepsie diminishes some of the pleasure of the ziplining adventure. After seeing the photos of your friends in Poughkeepsie, Costa Rica now seems a little less magical. FOMO, the fear of missing out, leads to actually missing out. KAHN: Assume you have an opportunity to go to a concert of a musician you love and you never get to see, or you get to go to an exotic vacation, and you choose to do that rather than go to a routine barbecue with your friend. It's exactly set up like that. So we say assume you do that. Then the experiment is, in one condition, we say now assume while you're on vacation, you pick up your phone and you see your friends enjoying themselves at the barbecue. And in the other condition, which is the controlled condition, you pick up your phone and you scroll and you look at something, but it's not pictures of your friends. And then what we do is we - before we ask you to look at those pictures, before that manipulation, we measure how much you're enjoying your Hawaii vacation or the exotic concert or whatever. We have you either look at the pictures of your friends or not, and then we measure again how much are you enjoying where you are now? And what we find is a significant decrease in enjoyment when you've looked at the pictures than when you haven't. VEDANTAM: Barbara Kahn and her team are doing more experiments, but if their findings hold, they say something really sad about our use of social media. The fictional worlds we construct there can make our friends feel their lives are inadequate, and the fictional worlds our friends construct can make our lives feel duller than they actually are. As for Rachel, she's in a new relationship now and she says she's happy. She has a new job, and she and her son are doing well, but she doesn't feel the need to publicize any of this on Facebook. LEONARD: I don't take a lot of pictures anymore. If I'm there in a moment, and I'm having that moment, who's the picture for, you know? Is it for me to remember, or is it - you know, I'm - I am trying to live more presently for myself and for my son and just for my own mental well-being. VEDANTAM: She's asked her new boyfriend not to post about their relationship on social media, either. This time, the good moments and the bad will be theirs alone. (SOUNDBITE OF MUSIC) VEDANTAM: While many of us spend too much time on social media interacting with friends and acquaintances, some of us have too little contact with fellow human beings. (SOUNDBITE OF RADIO SHOW) UNIDENTIFIED RADIO HOST: All right. And next up, we have Diana (ph) shouting out to the Polunsky Unit. DIANA: Hito (ph), it's Mama D. I know I sound kind of different. I'm very sick right now, got diagnosed with pneumonia. Been sick already for quite some time now. VEDANTAM: This is the voice of a woman calling into a radio show on the Texas station KPFA. She has a personal message for a prison inmate. (SOUNDBITE OF RADIO SHOW) DIANA: Anyway, I want to tell you, Hito, that Mama D loves you. I always think of you. And it's just getting harder and harder. I know I'm not supposed to cry 'cause you're going to get mad at me. But I can't help but feel so much love for you. VEDANTAM: Calling into a program like this is one of the few ways for spouses and parents and children to communicate with prisoners, especially inmates in solitary confinement. In recent years, both liberals and conservatives worried about the psychological and financial costs of long-term solitary confinement have raised questions about the practice. In the second half of our show, we explore what happens inside the prison cells that few people ever see and the psychological effects of being alone for long periods of time. That's coming up in just a moment. I'm Shankar Vedantam. And you're listening to HIDDEN BRAIN from NPR. (SOUNDBITE OF MUSIC) VEDANTAM: This is HIDDEN BRAIN. I'm Shankar Vedantam. Social contact is a fundamental aspect of human life. So what's it like to spend vast stretches of time in solitary confinement, to live without the hundreds of interactions that most of us have with people around us every day? Keramet Reiter has spent more than a decade researching the effects of loneliness on these inmates. She's a professor of criminology at the University of California Irvine and the author of the book \"23/7: Pelican Bay Prison And The Rise Of Long-Term Solitary Confinement. \" Besides being a researcher, she's also been a prisoner's rights activist at Human Rights Watch. Keramet, welcome to HIDDEN BRAIN. REITER: Thanks for having me, Shankar. VEDANTAM: You can't tell the story of solitary confinement without understanding the story of a man named George Jackson. He was sent to prison in the early 1960s after pleading guilty to armed robbery. And he was sentenced to a term of one year to life. What was the thinking behind this kind of indeterminate sentence? REITER: So the idea for someone like George Jackson was that he would go to prison, and he'd have to prove that he'd been rehabilitated before he could get out of prison. Around the time Jackson went to prison, however, people started to look at these indeterminate sentences and realize that they were having truly disproportionate impacts depending on the race of the person with the sentence. So white people had a much easier time convincing prison officials that they had been reformed and should be let out of prison than African-American men like George Jackson happened to be. So George Jackson found himself, essentially, stuck in prison. Years went by when he was denied parole, and he became radicalized in this process. He wrote a book of best-selling letters that achieved national and international acclaim - letters to his family and to his lawyers - articulating his revolutionary politics and the problems with things like this indeterminate sentence. This brought him to the attention of prison officials, and he was accused of murdering a prison guard in the early 1970s. And he was preemptively sent to death row at San Quentin while he awaited a death penalty trial for that murder he was accused of. And while on death row at San Quentin - in an isolation unit, interestingly - one day, his lawyer came in to visit him. And this story that prison officials tell - and it's been repeated many times - is that his lawyers snuck a 9-millimeter gun into him inside of a tape recorder and that Jackson then used that gun to try to escape from this isolation unit. All we actually know is that he was shot to death on the San Quentin prison yard as he ran out of that isolation unit. And when staff ran into the unit to see what had happened, they found three officers and two more prisoners who'd been stabbed to death. So this was the most violent day in California's prison history ever - six deaths total on August 21, 1971. And this moment is a moment that people point to in California as incredibly important in understanding why the state needed long-term solitary confinement units. And similar things happened across the U. S. And prison officials in other states point to those moments. So two weeks after George Jackson died, the revolt at Attica happened. Similarly, following that, prisoners were locked into their cells. And that became a moment people pointed to as a justification for really long-term solitary confinement. VEDANTAM: You also tell a story of a prison administrator Carl Larson, who began his career the same year that George Jackson went to prison. I understand you interviewed Carl Larson. And his view gives us a glimpse into the other side of the story, how prison guards and prison officials see the need for solitary confinement. REITER: So Carl Larson was one of the earlier people I interviewed in doing this work. And to my surprise, we got to be friends. I came at this work from a perspective of a prisoner's rights advocate very critical of the system. But as I got to know Carl Larson, I saw that he had a really interesting perspective on the system. And he was one of the first people to point me to the story of George Jackson and to explain how scary it was to be a guard working in the California prisons in the 1970s when these deaths were happening and to make that fear real for me in a way that helped me to understand why he thought a long-term-solitary-confinement facility made sense. So Carl Larson is particularly interesting because, as you said, he started out as a - as an officer in the 1970s in California prisons, actually even earlier. And then he worked his way up through the system, becoming a warden and then becoming head of the prison construction projects that California engaged in in the 1980s when the state built one of these long-term-solitary-confinement supermax facilities. And he takes credit for designing one of the first of these institutions. And that's really interesting because he's a prison administrator. He's not an architect. He's not an expert in exactly what kinds of punishments work. He didn't have a law degree. He had just worked in prisons. And he designed this completely new facility. VEDANTAM: I understand that there was some interesting architectural features with this facility, Pelican Bay. The cement for the facility was poured in one large block and - so that the cells were not built in individual units. REITER: So one of the things that's striking about the place is it's made of these poured concrete cells. So they're incredibly easy to hose down, which is - the fact that they can stay clean is important because courts earlier had criticized isolation units for being really dirty. And they're grouped together into these pods of eight. And then the pods of eight are grouped together again into these tessellated T-structures so that one officer can look out over six pods of cells at a time. So it's a modern panopticon. And that also - that allows - the fact that there are no windows makes it really easy to just fit all these blocks together, if you can imagine that structure. VEDANTAM: I'm wondering, Keramet, if you can actually just describe what one of these cells looks like? Give me a sense of what's in the cell, how big it is. What does it actually feel like to be in one of these units? REITER: So the cells in these units are generally about 8 by 10 feet. So imagine a wheelchair-accessible bathroom stall or a generous parking space - pretty small. You can, you know, almost reach from one end of the cell to the other. And they're fairly self-contained. So they contain a poured concrete ledge with a very thin piece of foam over it, and that's the bed. And then there's another sort of concrete bit protruding that is a desk-and-seat combination. So it's just like a concrete block that a prisoner could sit on and write there. And then there's - in another corner there's a steel, usually toilet-sink combination. So it's just, you know, one smooth steel object that has running water and plumbing for the prisoner. Sometimes there are showers in these cells, but generally, it's just a sink and a toilet. And, again, if the prisoner is lucky and they can afford it and the system they're in allows it, they might have a TV or a radio. And usually they're allowed maybe a few books at a time and a little bit of paper for writing letters or doing legal paperwork. (SOUNDBITE OF MUSIC) VEDANTAM: To be clear, many prisoners in solitary have been found guilty of heinous crimes including murder, rape and terrorism. But here's something you might not know. Some are there because they're difficult to manage or because of bureaucratic inertia. While judges and juries decide whether someone should go to prison, a decision that can be appealed in court, typically it's prison officials who decide whether someone should be in solitary confinement. I asked Keramet to describe the kind of prisoner who ends up in solitary. REITER: There's been shockingly little research over time on who ends up in solitary confinement and how. And it's very hard to track across states. But as people have paid more attention to this and through the work I've done, I've started to see some patterns that there's a disproportionate racial impact of solitary confinement. So we know that in our prisons in general, African-Americans and Latinos are more likely to be in prison than - in the general prison population. They're doubly likely, again, to be in solitary confinement than even the general prison population. And that's often because gang members are being targeted for long-term isolation, especially in states like California. Prison systems are not putting people there based on some act or rule that they broke but based on their status as dangerous. So prisoners get labeled dangerous gang members and they get sent to isolation indefinitely. In general, I think one way to think about people who end up in isolation is that it's often the people who are really difficult for the system to manage. So that might include seriously mentally-ill prisoners. There's recent research showing that transgender prisoners are really likely to end up in isolation, that pregnant women end up there. So people who the system just isn't equipped to provide resources to can end up there also. VEDANTAM: Keramet Reiter is a professor of criminology at the University of California, Irvine and the author of \"23/7: Pelican Bay Prison And The Rise Of Long-Term Solitary Confinement. \" So the rise of these institutions coincided in some ways with a decline or closing down of various institutions for the mentally ill, which speaks, of course, to the point that you were just making. But I also understand that this is reflected in the number of suicides we see in solitary confinement compared to the general prison population. REITER: There is a very close relationship between solitary confinement and mental illness. One way to understand that is that in the 1970s and early '80s when mental institutions closed was the same time that mass incarceration and rates of incarceration are increasing across the United States. And that meant that some mentally ill people unsurprisingly ended up in prisons. And one of the arguments I make is that as those people ended up in prison, they tended to be put into solitary confinement. And that's one explanation for the fact that rates of suicide in solitary confinement can be twice as high as in the general prison population or even higher and that rates of mental illness and isolation can be high. And often there's a real chicken-and-egg problem of, you know, did a person get sent to isolation because they were mentally ill and states have tried to limit that, or do people in isolation develop mental illnesses? VEDANTAM: Most of us are never going to see the inside of a supermax. But we often do see scenes of solitary confinement described in pop culture. One of those examples is the TV show \"Orange Is The New Black. \" We have a bit of tape. The character Piper is put into a security housing unit and starts speaking to a voice she hears through the grate of her cell. (SOUNDBITE OF TV SHOW, \"ORANGE IS THE NEW BLACK\") TAYLOR SCHILLING: (As Piper Chapman) How long have you been down here? LAVERNE COX: (As Sophia Burset) I lost track. I don't know - nine months, a year. SCHILLING: (As Piper Chapman) A year - that's insane. COX: (As Sophia Burset) They keep the lights on, so you lose all sense of time. It's not living. I mean, yeah, you're breathing. But you ain't a real person no more. It's bad. You start to see [expletive] that ain't there. You start to hear voices. SCHILLING: (As Piper Chapman) Oh, my God. COX: (As Sophia Burset) They keep you here until they break you. SCHILLING: (As Piper Burset) I feel like I'm going to throw up. VEDANTAM: Keramet, I'm wondering how accurate that description is of what life's actually like in solitary confinement. REITER: I do think that the disembodied voice that you hear talking to Piper is accurate on a number of levels. The voice is kind of flattened in effect. And the prisoner was describing hearing voices, hallucinations. That's a very common side effect of isolation. And people talk about time - the way they perceive time changing because there is no way to mark time. People talk about it exactly as that prisoner said. It's not that it even feels long. It's just that it's almost endless, that days can kind of, in a weird, counterintuitive way, fly by because there's nothing marking anything about a day or week. So in that sense, it's accurate. (SOUNDBITE OF MUSIC) VEDANTAM: I want to spend a moment talking about your own role in looking at this. On the one hand, you are a researcher who has spent time studying the question. But as you yourself have said, you know, you're also a prison rights advocate. You've been an activist at Human Rights Watch and other organizations. How do you preserve your ability to be analytical about the subject while you also have what are very clearly strong views about solitary confinement? REITER: You know, when I went to interview Carl Larson, he said, well, you're a Berkeley liberal (laughter). So he asked me to do some background reading and prove that I was serious. And I would listen to him. And so I actually think in the process of doing this work, I have become more open-minded and been criticized by advocates for talking so directly and so extensively to prison officials. And so I've had the interesting experience of trying to keep the conversation open across a really broad spectrum of perspectives on this process. And I think in that way, I've been able to try to at least incorporate these different perspectives and tease apart the arguments and the positions people are coming from. And I do think that in reform, prison officials have to walk into these institutions and engage with these prisoners day in and day out. And they also need to be part of the reform conversation. And through this process, you know, surprisingly, even though I came basically from the other side, if you want to think of it in terms of sides, I've come to see that perspective. VEDANTAM: Keramet, what sorts of things do people in solitary confinement say they miss? What are the kind of things that you miss that the rest of us might not think about? REITER: So people talk about not having seen the moon in years or decades and how much they miss that. And then people talk about missing just pure human touch. And you know, I tell a story in the book about a prisoner who - his cell door and the cell door of the prisoner next to him were accidentally opened at the same time. And they were rival gang members. But they had been talking to each other, shouting through the cell walls. And when the cell doors opened, they just reached around and grabbed each other's hands and held on because it had been so long since either of them had had a gentle human touch like that. VEDANTAM: Prisoners often stay alone in their cells for 22 or 23 hours a day. And you found that perhaps the only way to actually manage this psychologically is to stick to a series of very, very rigid routines. Tell me about those routines. REITER: The prisoners who I was able to interview in this research to understand their experiences tended to be the prisoners who survived. And so they did develop all kinds of coping mechanisms. And one of the ones I heard about again and again was that they would wake up, you know, first thing in the morning, 5 a. m. And they would do thousands of repetitive exercises, often what prisoners called burpees - so a combination of jumping jacks, push-ups and sit-ups - and, you know, literally a few thousand in the morning to start out their day and then clean their cells, write letters, work on legal cases. And in general in these units, if prisoners are following the rules and they have money being sent in from family, they can buy either a TV or a radio. And prisoners who develop these routines talk about really limiting the time they spend listening to media, so maybe only an hour a day or two hours a day or a special show they like to watch so that they were keeping both their bodies and their minds really busy really consciously over the course of the day. And interestingly, prisoners talk about having trouble letting go of these routines once they got out of prison, that they would still do those thousands of burpees every morning at 5 a. m. when they got up and that their ability to control everything in their space in that 8-by-10 cell they live in is also hard to let go of, that they could keep - you know, a prisoner described to me how he could keep the cap of his toothpaste perfectly clean. And it was really hard when he had a roommate when he got out of prison - the fact that he couldn't control the cap of the toothpaste anymore - so kind of gives you a sense of how intense it is to survive and then how long those coping mechanisms linger afterwards. VEDANTAM: You talk in the book, Keramet, about inmates trying a number of different things to not just be physically active and mentally active but emotionally expressive, to try and find ways to do artistic things. Can you talk about that for a moment? REITER: Prisoners do struggle to find ways to express themselves. And sometimes that's becoming really good at the law and litigating cases. But very often it's teaching themselves to draw, sometimes teaching themselves to speak a new language, sometimes teaching themselves to sew. One of my favorite stories was a prisoner who told me that he was in isolation for a number of months. And I'm not even sure how he made himself a needle. I know that he pulled threads out of the jumpsuits they're given in order to make thread. And then he started tailoring his clothes so that they fit better. They're often given these very loose jumpsuits. And so he would add cuffs or shorten the sleeves. And I think other prisoners found out about him doing this. And in some cases, a friendly officer would pass a uniform back and forth. And he started tailoring other people's uniforms. It's kind of - and not that anyone is even seeing them. But it's this amazing kind of self-expression and community that they're managing to create in this place. VEDANTAM: I'm sure they're going to be people who say, look; there are lots of people in these units who really are the worst of the worst. Maybe not all of them are, but some of them probably are. Some of them probably are really violent and really dangerous and ought to be there. And I'm wondering, do you ever feel that they might be people who need to be in solitary confinement? REITER: So there are certainly people in isolation who are dangerous. One of the really important points of analysis is the length of time people are spending in isolation, the fact that people - we're not talking about weeks or months. We're talking about years and decades often and that even people who might have been fairly scary or dangerous in their 20s are unlikely to be that way into their 40s and 50s. And as we look at decades of these policies, we see that even some of the people who have been held up as the scariest, the system didn't control them very well while they were in it. And they're doing surprisingly well outside of isolation. So it really does call the practice into question on all different levels. VEDANTAM: So your book comes at a time when many liberals and conservatives have joined hands to call for prison reform. For one thing, keeping people in prison and keeping someone in solitary confinement is very, very expensive. Give us a sense of how expensive it is and whether these ideological pairings are triggering any change in the system. REITER: So solitary confinement is astronomically expensive. In states like California, it costs about $45,000 per prisoner per year to keep someone in the general prison population. And it costs about $90,000 per prisoner per year to keep someone in isolation. So the cost of running the facilities is really expensive because these prisoners in isolation, you know - every need has to be met by someone working in the prison, whether it's delivering mail or or delivering legal documents or getting them a meal. So that's how the costs go up. And the costs of the facilities are also expensive to build these kinds of technologically advanced facilities. And that's not even wrapped into that per-prisoner per-year cost. So I think that has been part of the reform conversation, as you suggest, that perhaps there might be a less-expensive way to do this. One other cost of isolation is that the vast majority of people, even from long-term solitary confinement, ultimately get out of prison. It's a - it's - 95 to 98 percent of all prisoners get out eventually, and that's surprisingly true of people in isolation, too. And so there's the question of, what are the social impacts of letting people out? And I think in combination those economic costs and the social costs, people are beginning to think about alternatives. And that is a conversation that is - crosses political lines. And prison, as I suggested, in many states - legislators are initiating reforms. Some litigation has happened. But in many states, prison officials within the system are looking at the norms changing and the critics of this practice and initiating their own reform, saying what can we do to reduce our reliance on this practice? (SOUNDBITE OF MUSIC) VEDANTAM: Keramet Reiter is a professor at the University of California at Irvine. She's the author of the book \"23/7: Pelican Bay Prison And The Rise Of Long-Term Solitary Confinement. \" Keramet, thank you for joining me on HIDDEN BRAIN today. REITER: Thanks for having me. (SOUNDBITE OF MUSIC) VEDANTAM: This week's show was produced by Maggie Penman and Parth Shah. It was edited by Tara Boyle. Our team includes Rhaina Cohen, Jenny Schmidt and Renee Klahr. Our engineers are Andy Huether and Jay Sciz (ph). NPR's vice president for programming and audience development is Anya Grundmann. If you liked the show, check out our weekly podcast. Search for HIDDEN BRAIN in NPR One, iTunes or wherever you find your podcasts. You can also follow the show on Facebook, Twitter and Instagram and listen to my stories on Morning Edition each week on your local public radio station. I'm Shankar Vedantam. See you next week. (SOUNDBITE OF MUSIC)", "section": "Hidden Brain", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-10-29-560569373": {"title": "Are Social Media Sites Doing Enough To Combat Rumors And False News? : NPR", "url": "https://www.npr.org/2017/10/29/560569373/are-social-media-sites-doing-enough-to-combat-rumors-and-false-news", "author": "No author found", "published_date": "2017-10-29", "content": "MICHEL MARTIN, HOST: It was never easy, but these days, law enforcement is facing a new kind of challenge that can make their jobs even harder - stopping the spread of rumors and fake news. NPR's David Schaper reports that firefighters in California's wine country recently got embroiled in a battle over fake news, even as they were still trying to extinguish those devastating wildfires that killed 42 people. DAVID SCHAPER, BYLINE: In the midst of a recent news briefing to update efforts to contain more than 15 raging wildfires, various evacuation orders and the number of people reported missing, Sonoma County Sheriff Rob Giordano had to change the subject. (SOUNDBITE OF ARCHIVED RECORDING)ROBERT GIORDANO: I want to talk about something. There's a little rumor control issue. . . SCHAPER: Giordano explained that a couple of days earlier, his officers had arrested a homeless man for starting a small fire in a local park where he was known to sleep in order to keep warm. (SOUNDBITE OF ARCHIVED RECORDING)GIORDANO: . . . The story out there is he's the arsonist for these fires. That is not the case. There's no indication he is related to these fires at all. GIORDANO: The erroneous story came from Breitbart News, the right-wing website run by President Trump's former political strategist, Steve Bannon. The article claimed an undocumented immigrant had been, quote, \"arrested for suspicion of arson in wine country fires that have killed at least 40 residents. \" That, Sheriff Giordano said, simply wasn't true. (SOUNDBITE OF ARCHIVED RECORDING)GIORDANO: I just wanted to kill that speculation right now so we didn't have things running too far out of control. SCHAPER: But even though it was shot down by the sheriff, debunked by fact-checking organizations and Breitbart added a clarification, the original story did spin out of control. One version of the false narrative was shared on Facebook 75,000 times, and that doesn't even include the number of times the story was tweeted out or shared elsewhere. It's an example of how false information is being spread through big social media platforms. And it raises questions about whether companies such as Facebook and Twitter are doing enough to stop it. Because even as the wildfires still raged, the false stories ignited a squabble. The Trump administration's top immigration official criticized the sheriff's office for leaving the community vulnerable to dangerous individuals, leading Giordano to call those statements inaccurate and inflammatory. This isn't the only time in recent weeks that law enforcement authorities have had to spend time and resources during a crisis to try to stop rumors and misinformation. In Houston, after Hurricane Harvey, phony news photographs proliferated on social media, supposedly showing the airport under water. And authorities also had to quell false rumors that levees had burst and that a dam had failed. And in Clark County, Nev. , after the Las Vegas massacre, Sheriff Joe Lombardo angrily addressed virally spreading conspiracy theories, including one about a second shooter. (SOUNDBITE OF ARCHIVED RECORDING)JOE LOMBARDO: There is no conspiracy. Nobody is attempting to hide anything in reference to this investigation. SCHAPER: With the advent of social media allowing people to tweet out rumors, fact or to deliberately spread false information to promote a political point of view, law enforcement officials across the country increasingly find themselves in need of truth squads. SANDRA HUTCHENS: We are hiring people that do just that. . . SCHAPER: Sandra Hutchens is sheriff of Orange County, Calif. , and president of the Major County Sheriffs of America. HUTCHENS: . . . That just communicate with the public and try and get that information out there to counter a lot of the negative, and, in some cases, false news that's out there. SCHAPER: It is resource-intensive at a time when budgets are tight. But Hutchens says law enforcement authorities need a strong social media presence of their own to quell misinformation that could put residents in danger. She acknowledges, though, that some people still believe a false narrative instead of the facts. HUTCHENS: You know, the political tempo is so high right now. And I think that, then, people are just not listening to what the truth is. SCHAPER: To some degree, that is what the creators and spreaders of false content intend. They use automated systems to search for misleading articles and misinformation that reinforce certain points of view and then promote them in the social media feeds of people who are inclined to believe and share them. Indiana University journalism professor Elaine Monaghan says Facebook, Twitter and other social media platforms need to do a better job policing misinformation. ELAINE MONAGHAN: Too much news is being caddied there that it's incumbent on these organizations that are making money from news to act responsibly in the dissemination of it. SCHAPER: It's likely that some members of Congress will ask that of Google, Facebook and Twitter when executives from those tech companies appear at hearings on Capitol Hill this week. David Schaper, NPR News. MICHEL MARTIN, HOST:  It was never easy, but these days, law enforcement is facing a new kind of challenge that can make their jobs even harder - stopping the spread of rumors and fake news. NPR's David Schaper reports that firefighters in California's wine country recently got embroiled in a battle over fake news, even as they were still trying to extinguish those devastating wildfires that killed 42 people. DAVID SCHAPER, BYLINE: In the midst of a recent news briefing to update efforts to contain more than 15 raging wildfires, various evacuation orders and the number of people reported missing, Sonoma County Sheriff Rob Giordano had to change the subject. (SOUNDBITE OF ARCHIVED RECORDING) ROBERT GIORDANO: I want to talk about something. There's a little rumor control issue. . . SCHAPER: Giordano explained that a couple of days earlier, his officers had arrested a homeless man for starting a small fire in a local park where he was known to sleep in order to keep warm. (SOUNDBITE OF ARCHIVED RECORDING) GIORDANO: . . . The story out there is he's the arsonist for these fires. That is not the case. There's no indication he is related to these fires at all. GIORDANO: The erroneous story came from Breitbart News, the right-wing website run by President Trump's former political strategist, Steve Bannon. The article claimed an undocumented immigrant had been, quote, \"arrested for suspicion of arson in wine country fires that have killed at least 40 residents. \" That, Sheriff Giordano said, simply wasn't true. (SOUNDBITE OF ARCHIVED RECORDING) GIORDANO: I just wanted to kill that speculation right now so we didn't have things running too far out of control. SCHAPER: But even though it was shot down by the sheriff, debunked by fact-checking organizations and Breitbart added a clarification, the original story did spin out of control. One version of the false narrative was shared on Facebook 75,000 times, and that doesn't even include the number of times the story was tweeted out or shared elsewhere. It's an example of how false information is being spread through big social media platforms. And it raises questions about whether companies such as Facebook and Twitter are doing enough to stop it. Because even as the wildfires still raged, the false stories ignited a squabble. The Trump administration's top immigration official criticized the sheriff's office for leaving the community vulnerable to dangerous individuals, leading Giordano to call those statements inaccurate and inflammatory. This isn't the only time in recent weeks that law enforcement authorities have had to spend time and resources during a crisis to try to stop rumors and misinformation. In Houston, after Hurricane Harvey, phony news photographs proliferated on social media, supposedly showing the airport under water. And authorities also had to quell false rumors that levees had burst and that a dam had failed. And in Clark County, Nev. , after the Las Vegas massacre, Sheriff Joe Lombardo angrily addressed virally spreading conspiracy theories, including one about a second shooter. (SOUNDBITE OF ARCHIVED RECORDING) JOE LOMBARDO: There is no conspiracy. Nobody is attempting to hide anything in reference to this investigation. SCHAPER: With the advent of social media allowing people to tweet out rumors, fact or to deliberately spread false information to promote a political point of view, law enforcement officials across the country increasingly find themselves in need of truth squads. SANDRA HUTCHENS: We are hiring people that do just that. . . SCHAPER: Sandra Hutchens is sheriff of Orange County, Calif. , and president of the Major County Sheriffs of America. HUTCHENS: . . . That just communicate with the public and try and get that information out there to counter a lot of the negative, and, in some cases, false news that's out there. SCHAPER: It is resource-intensive at a time when budgets are tight. But Hutchens says law enforcement authorities need a strong social media presence of their own to quell misinformation that could put residents in danger. She acknowledges, though, that some people still believe a false narrative instead of the facts. HUTCHENS: You know, the political tempo is so high right now. And I think that, then, people are just not listening to what the truth is. SCHAPER: To some degree, that is what the creators and spreaders of false content intend. They use automated systems to search for misleading articles and misinformation that reinforce certain points of view and then promote them in the social media feeds of people who are inclined to believe and share them. Indiana University journalism professor Elaine Monaghan says Facebook, Twitter and other social media platforms need to do a better job policing misinformation. ELAINE MONAGHAN: Too much news is being caddied there that it's incumbent on these organizations that are making money from news to act responsibly in the dissemination of it. SCHAPER: It's likely that some members of Congress will ask that of Google, Facebook and Twitter when executives from those tech companies appear at hearings on Capitol Hill this week. David Schaper, NPR News.", "section": "Tech Titans And The Information Complex", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-10-29-560660157": {"title": "When Politicians Block Critics On Social Media : NPR", "url": "https://www.npr.org/2017/10/29/560660157/when-politicians-block-critics-on-social-media", "author": "No author found", "published_date": "2017-10-29", "content": "LULU GARCIA-NAVARRO, HOST: For politicians, interacting with their constituents comes with the job. But social media makes it easy for lawmakers to do something it's hard to do in real life. They can block people who follow them on Twitter or Facebook. That's drawing the scrutiny of free-speech advocates. From member station KUER in Salt Lake City, Julia Ritchey explores how local politicians are handling their critics online. JULIA RITCHEY, BYLINE: Republican State Senator Todd Weiler is well-known among followers of Utah's political landscape. He freely admits he can be pretty sarcastic online and regularly tussles with critics on Twitter under the handle @gopTODD. TODD WEILER: I mean, I kind of like to show people who I really am. And it's not a mean, nasty person. But it is someone who likes to laugh at himself and will occasionally laugh at others. RITCHEY: While Weiler says he doesn't do it all that often, he does block people. Take what happened last February. Air pollution was peculiarly bad that week, as it often is during the winter here. So Jessica Rawson tweeted at Weiler after seeing him use what she thought was a mocking tone about air quality. This is what she tweeted. JESSICA RAWSON: The disrespect you show your constituents is appalling. We are all choking and want to see serious action on this issue. RITCHEY: And just like that, Weiler blocked her. A couple of weeks ago, while talking to the senator about his online habits, I asked if he'd be willing to talk to Rawson. To my surprise, he agreed. Hey, this is Julia at KUER News. I'm actually sitting here with Senator Todd Weiler right now. So I was just going to put you on speakerphone really quick. WEILER: Hi, Jessica. RAWSON: Hello. Good morning. WEILER: Good morning. RITCHEY: Rawson was new to Twitter at the time. She says she was really surprised when he blocked her. RAWSON: I had never been blocked by anyone (laughter). And my comment was critical, but I didn't feel like maybe block-worthy (laughter). WEILER: Well, my guess was you caught me when the air quality outside was bad because it's bad every February typically. RAWSON: Sure. WEILER: And I probably - it was during the session, so you were probably the eighth or ninth or 10th person that blamed me for that bad air that day. And I just probably had enough. I'm like, I'm not going to put up with this. RITCHEY: Being one of the most active members of the Utah legislature online means Weiler attracts more flak than most. He says he only really has issues with people who make personal attacks on him, his family or his Mormon faith. John Mejia, legal director of the ACLU of Utah, says, yes, obscenity and personal threats are not acceptable. But he's noticed more elected officials across the political spectrum are shutting out constituents. JOHN MEJIA: And so from our perspective, if you're blocking somebody from commenting or even receiving your comments, that's a form of censorship that we felt had to stop. RITCHEY: As for Senator Weiler and Jessica Rawson, they talked for almost half an hour. Rawson said she did some more research after being blocked and learned Weiler is actually pretty active on clean air issues. During their conversation, Weiler admitted he doesn't take Twitter that seriously. And maybe that's the problem. WEILER: Twitter's more of a game for me. And I will say I learned a lot on Twitter, and I have never tried to cocoon myself like some people do, you know, to only have an echo chamber where I'm hearing what other Republicans are saying. RITCHEY: Before they ended the call, Weiler told Rawson he had unblocked her, and he hopes they stay in touch. WEILER: I'm not a mean person in real life. And I'm not typically a mean person on Twitter. So. . . RAWSON: Hopefully, that's the same for me, right (laughter)? WEILER: Yeah. RITCHEY: Both said they learned a lot from their conversation. Rawson says she doesn't want to seem like some kind of online troll. And Weiler says he doesn't, either. He says the phone call reminds him that the most meaningful engagement happens through talking to one another, not a tweet. For NPR News in Salt Lake City, I'm Julia Ritchey. LULU GARCIA-NAVARRO, HOST:  For politicians, interacting with their constituents comes with the job. But social media makes it easy for lawmakers to do something it's hard to do in real life. They can block people who follow them on Twitter or Facebook. That's drawing the scrutiny of free-speech advocates. From member station KUER in Salt Lake City, Julia Ritchey explores how local politicians are handling their critics online. JULIA RITCHEY, BYLINE: Republican State Senator Todd Weiler is well-known among followers of Utah's political landscape. He freely admits he can be pretty sarcastic online and regularly tussles with critics on Twitter under the handle @gopTODD. TODD WEILER: I mean, I kind of like to show people who I really am. And it's not a mean, nasty person. But it is someone who likes to laugh at himself and will occasionally laugh at others. RITCHEY: While Weiler says he doesn't do it all that often, he does block people. Take what happened last February. Air pollution was peculiarly bad that week, as it often is during the winter here. So Jessica Rawson tweeted at Weiler after seeing him use what she thought was a mocking tone about air quality. This is what she tweeted. JESSICA RAWSON: The disrespect you show your constituents is appalling. We are all choking and want to see serious action on this issue. RITCHEY: And just like that, Weiler blocked her. A couple of weeks ago, while talking to the senator about his online habits, I asked if he'd be willing to talk to Rawson. To my surprise, he agreed. Hey, this is Julia at KUER News. I'm actually sitting here with Senator Todd Weiler right now. So I was just going to put you on speakerphone really quick. WEILER: Hi, Jessica. RAWSON: Hello. Good morning. WEILER: Good morning. RITCHEY: Rawson was new to Twitter at the time. She says she was really surprised when he blocked her. RAWSON: I had never been blocked by anyone (laughter). And my comment was critical, but I didn't feel like maybe block-worthy (laughter). WEILER: Well, my guess was you caught me when the air quality outside was bad because it's bad every February typically. RAWSON: Sure. WEILER: And I probably - it was during the session, so you were probably the eighth or ninth or 10th person that blamed me for that bad air that day. And I just probably had enough. I'm like, I'm not going to put up with this. RITCHEY: Being one of the most active members of the Utah legislature online means Weiler attracts more flak than most. He says he only really has issues with people who make personal attacks on him, his family or his Mormon faith. John Mejia, legal director of the ACLU of Utah, says, yes, obscenity and personal threats are not acceptable. But he's noticed more elected officials across the political spectrum are shutting out constituents. JOHN MEJIA: And so from our perspective, if you're blocking somebody from commenting or even receiving your comments, that's a form of censorship that we felt had to stop. RITCHEY: As for Senator Weiler and Jessica Rawson, they talked for almost half an hour. Rawson said she did some more research after being blocked and learned Weiler is actually pretty active on clean air issues. During their conversation, Weiler admitted he doesn't take Twitter that seriously. And maybe that's the problem. WEILER: Twitter's more of a game for me. And I will say I learned a lot on Twitter, and I have never tried to cocoon myself like some people do, you know, to only have an echo chamber where I'm hearing what other Republicans are saying. RITCHEY: Before they ended the call, Weiler told Rawson he had unblocked her, and he hopes they stay in touch. WEILER: I'm not a mean person in real life. And I'm not typically a mean person on Twitter. So. . . RAWSON: Hopefully, that's the same for me, right (laughter)? WEILER: Yeah. RITCHEY: Both said they learned a lot from their conversation. Rawson says she doesn't want to seem like some kind of online troll. And Weiler says he doesn't, either. He says the phone call reminds him that the most meaningful engagement happens through talking to one another, not a tweet. For NPR News in Salt Lake City, I'm Julia Ritchey.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-10-29-560467747": {"title": "Canada's 'Welcome' To Immigrants Has Some Unintended Consequences : NPR", "url": "https://www.npr.org/2017/10/29/560467747/canadas-balancing-act-on-immigration", "author": "No author found", "published_date": "2017-10-29", "content": "LULU GARCIA-NAVARRO, HOST: It just got more complicated for people from other countries to stay and work in the United States. This past week, the Trump administration announced that immigrant workers with H-1B visas will no longer be able to get them renewed without a full re-evaluation of their case. That's often a lengthy, involved and expensive process. These are coveted visas for highly skilled people. It's one of the many significant changes President Trump has made to the U. S. immigration system, that includes his travel ban which has been fiercely disputed in court since it was announced in January. The president says he's working to put America and Americans first. But his immigration policies have had serious implications for Canada, as we found out on a trip to our northern border. Right after the U. S. election, Mike Tippett had an idea. MIKE TIPPETT: November is when we started talking about it. . . GARCIA-NAVARRO: Tippett says his friends in Silicon Valley were nervous after the election because of Donald Trump's attitude on immigration. We meet Tippett at a coffee shop in a trendy part of Vancouver called Gastown. Their concern, he told us. . . TIPPETT: . . . Many of the startups and technology companies in the States and, indeed, across the globe are made up of people who are not necessarily from that country. GARCIA-NAVARRO: About half of all American startups were founded by immigrants. And when Donald Trump took office, American tech companies worried that getting international employees work visas in the U. S. would get a lot harder. But Tippett had a solution to offer them - move to Vancouver. And Vancouver's tech industry has been growing for years now. Big companies have big operations in the city. TIPPETT: Amazon, Slack, Microsoft, SAP. . . GARCIA-NAVARRO: Vancouver's appeal? - it's a quick flight from San Francisco and a two-hour drive from Seattle, same time zone, same language. Labor's cheaper. Tippett predicted there would be a surge of tech workers looking for an alternative to America. And so he founded his company True North. TIPPETT: And what we do is we help them come up here, get incorporated, deal with all the tax and other legal issues, immigration issues and then move up whoever wants to come up here. We say, come on up (laughter). We think it's a great opportunity for Vancouver and, I think, Canada, generally. GARCIA-NAVARRO: Tippett says Silicon Valley is still the place to be. But each highly skilled worker that moves to Canada is America's loss. TIPPETT: America used to be this place where you could go and have some assurances that, you know, you could live the American dream. You could be successful. You're not going to get kicked out. And that was a safe place to be. And I think that notion has been largely shattered. Whereas Canada has gone the other direction and said, you know, we are that place. And you can come here, and you're not going to get kicked out. GARCIA-NAVARRO: Alex Modon heard that message. He has a small startup in Silicon Valley. ALEX MODON: And a couple of our members of our core founding team are from India. We originally had them over here in the States with tourist visas working together, formulating the beginning thoughts of our idea and our company and really starting to get off the ground. GARCIA-NAVARRO: So Modon hired a lawyer to get them work visas in the U. S. But the months dragged on, and the bills racked up. MODON: We've spent tens of thousands of dollars doing it. At this point, we've certainly lost count as to what that specific dollar amount is. But it's a sizable chunk as you're at a startup, right? And like those - that money's super important because that's like head count for another person. GARCIA-NAVARRO: But even after all that, his Indian coworkers didn't get permission to stay in America. Now, it's important to clarify that the H-1B visas that Modon's team was applying for have always been restricted. Only a limited number are handed out each year. But Modon says he didn't think it was going to get any easier under the Trump administration. So his team hired True North to help his co-founders move to Vancouver where they got work permits in a matter of weeks. MODON: We're probably a pretty good example of folks who will end up building a piece for our company in another country, not because that's the first choice but because that's the necessary choice. GARCIA-NAVARRO: Canada is now aggressively marketing itself as an alternative to Silicon Valley. This summer, it launched a program that fast-tracks the immigration process for tech workers. But it's not just highly skilled workers who are taking Canada at its word that it is friendly to immigrants. The message has had some unintended consequences. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED MAN #1: Canadian Prime Minister Justin Trudeau has a message for refugees rejected by Donald Trump - Canada welcomes you. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED WOMAN: Hashtag #WelcomeToCanada has been trending. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED MAN #2: This week, refugee shelters became so overcrowded that they were forced to open the Montreal Olympic Stadium. . . GARCIA-NAVARRO: Already this year, more than 15,000 people have illegally crossed the border from the United States to Canada. At the Immigrant Services Society of British Columbia, a translator helps a newly arrived Iranian couple set up a bank account. UNIDENTIFIED TRANSLATOR: He's going to have his own, and she's going to have her own. And they can't share. They can't share. GARCIA-NAVARRO: ISS is a nonprofit that helps immigrants and refugees settle in Canada. Mona Hassennia is one of the center's directors. MONA HASSENNIA: I would say around 80 percent, maybe over that, of our clients are actually walking through the U. S. border. So they're coming into Canada having come through the U. S. usually on a visitor's visa with no intention of wanting to stay in the U. S. GARCIA-NAVARRO: Why are they tell you that they're doing that? HASSENNIA: I think the biggest reason that they're coming is they don't feel that there's safety in the United States. And it's funny. One of the clients, you know, very recently was telling us, I came to Vancouver because I was invited. And we're kind of all looking at each other and thinking, well, who invited you? They said, well, the prime minister of Canada. And it's this hashtag #WelcomeRefugees. And this is really a feeling that's across the board with many of our clients. They really feel that, you know. . . GARCIA-NAVARRO: . . . They're personally invited by Prime Minister Trudeau. HASSENNIA: Exactly, exactly. AHMED HUSSEN: The prime minister was welcoming those who are seeking protection and who are genuine refugees. GARCIA-NAVARRO: Ahmed Hussen is Canada's Minister of Immigration, Refugees and Citizenship. Hussen himself was a refugee. He came to Canada from Somalia as a teenager. He says they're now trying to counter the impression that Canada has an open border. HUSSEN: If you are just coming because you want a better life and a better opportunity, then you have to apply and regulate economic immigration program and not try to cross the border. We've told people that that's not the way to go. It's illegal. It's potentially dangerous. GARCIA-NAVARRO: Have you had to sort of backpedal that message a little bit to make it clear that the border is not just open for anyone who wants to come into Canada? HUSSEN: It's not a question of backpedaling. There is a lot of misinformation to certain communities in the United States who are given the wrong impression about Canada. To correct that misinformation, we've been deploying resources from our consulates in various American cities to to correct the record with some of the diaspora communities saying, look. You're welcome to Canada, but you have to - it doesn't mean that you can just show up because of your perception of what Canada is about. GARCIA-NAVARRO: The Trump administration's travel ban has run into a series of legal challenges. But the perception that America is closing its door to immigrants remains. Canada is trying to capitalize on that, but it's struggling to figure out what the hashtag #WelcomeToCanada actually means. They're wooing highly skilled immigrants while dissuading refugees from coming north. Illegal crossings were down in September. The influx, though, has provoked a backlash in Canada. A recent poll found that just over half of Canadians think their government is being too generous to asylum-seekers. (SOUNDBITE OF MUSIC) LULU GARCIA-NAVARRO, HOST:  It just got more complicated for people from other countries to stay and work in the United States. This past week, the Trump administration announced that immigrant workers with H-1B visas will no longer be able to get them renewed without a full re-evaluation of their case. That's often a lengthy, involved and expensive process. These are coveted visas for highly skilled people. It's one of the many significant changes President Trump has made to the U. S. immigration system, that includes his travel ban which has been fiercely disputed in court since it was announced in January. The president says he's working to put America and Americans first. But his immigration policies have had serious implications for Canada, as we found out on a trip to our northern border. Right after the U. S. election, Mike Tippett had an idea. MIKE TIPPETT: November is when we started talking about it. . . GARCIA-NAVARRO: Tippett says his friends in Silicon Valley were nervous after the election because of Donald Trump's attitude on immigration. We meet Tippett at a coffee shop in a trendy part of Vancouver called Gastown. Their concern, he told us. . . TIPPETT: . . . Many of the startups and technology companies in the States and, indeed, across the globe are made up of people who are not necessarily from that country. GARCIA-NAVARRO: About half of all American startups were founded by immigrants. And when Donald Trump took office, American tech companies worried that getting international employees work visas in the U. S. would get a lot harder. But Tippett had a solution to offer them - move to Vancouver. And Vancouver's tech industry has been growing for years now. Big companies have big operations in the city. TIPPETT: Amazon, Slack, Microsoft, SAP. . . GARCIA-NAVARRO: Vancouver's appeal? - it's a quick flight from San Francisco and a two-hour drive from Seattle, same time zone, same language. Labor's cheaper. Tippett predicted there would be a surge of tech workers looking for an alternative to America. And so he founded his company True North. TIPPETT: And what we do is we help them come up here, get incorporated, deal with all the tax and other legal issues, immigration issues and then move up whoever wants to come up here. We say, come on up (laughter). We think it's a great opportunity for Vancouver and, I think, Canada, generally. GARCIA-NAVARRO: Tippett says Silicon Valley is still the place to be. But each highly skilled worker that moves to Canada is America's loss. TIPPETT: America used to be this place where you could go and have some assurances that, you know, you could live the American dream. You could be successful. You're not going to get kicked out. And that was a safe place to be. And I think that notion has been largely shattered. Whereas Canada has gone the other direction and said, you know, we are that place. And you can come here, and you're not going to get kicked out. GARCIA-NAVARRO: Alex Modon heard that message. He has a small startup in Silicon Valley. ALEX MODON: And a couple of our members of our core founding team are from India. We originally had them over here in the States with tourist visas working together, formulating the beginning thoughts of our idea and our company and really starting to get off the ground. GARCIA-NAVARRO: So Modon hired a lawyer to get them work visas in the U. S. But the months dragged on, and the bills racked up. MODON: We've spent tens of thousands of dollars doing it. At this point, we've certainly lost count as to what that specific dollar amount is. But it's a sizable chunk as you're at a startup, right? And like those - that money's super important because that's like head count for another person. GARCIA-NAVARRO: But even after all that, his Indian coworkers didn't get permission to stay in America. Now, it's important to clarify that the H-1B visas that Modon's team was applying for have always been restricted. Only a limited number are handed out each year. But Modon says he didn't think it was going to get any easier under the Trump administration. So his team hired True North to help his co-founders move to Vancouver where they got work permits in a matter of weeks. MODON: We're probably a pretty good example of folks who will end up building a piece for our company in another country, not because that's the first choice but because that's the necessary choice. GARCIA-NAVARRO: Canada is now aggressively marketing itself as an alternative to Silicon Valley. This summer, it launched a program that fast-tracks the immigration process for tech workers. But it's not just highly skilled workers who are taking Canada at its word that it is friendly to immigrants. The message has had some unintended consequences. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED MAN #1: Canadian Prime Minister Justin Trudeau has a message for refugees rejected by Donald Trump - Canada welcomes you. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED WOMAN: Hashtag #WelcomeToCanada has been trending. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED MAN #2: This week, refugee shelters became so overcrowded that they were forced to open the Montreal Olympic Stadium. . . GARCIA-NAVARRO: Already this year, more than 15,000 people have illegally crossed the border from the United States to Canada. At the Immigrant Services Society of British Columbia, a translator helps a newly arrived Iranian couple set up a bank account. UNIDENTIFIED TRANSLATOR: He's going to have his own, and she's going to have her own. And they can't share. They can't share. GARCIA-NAVARRO: ISS is a nonprofit that helps immigrants and refugees settle in Canada. Mona Hassennia is one of the center's directors. MONA HASSENNIA: I would say around 80 percent, maybe over that, of our clients are actually walking through the U. S. border. So they're coming into Canada having come through the U. S. usually on a visitor's visa with no intention of wanting to stay in the U. S. GARCIA-NAVARRO: Why are they tell you that they're doing that? HASSENNIA: I think the biggest reason that they're coming is they don't feel that there's safety in the United States. And it's funny. One of the clients, you know, very recently was telling us, I came to Vancouver because I was invited. And we're kind of all looking at each other and thinking, well, who invited you? They said, well, the prime minister of Canada. And it's this hashtag #WelcomeRefugees. And this is really a feeling that's across the board with many of our clients. They really feel that, you know. . . GARCIA-NAVARRO: . . . They're personally invited by Prime Minister Trudeau. HASSENNIA: Exactly, exactly. AHMED HUSSEN: The prime minister was welcoming those who are seeking protection and who are genuine refugees. GARCIA-NAVARRO: Ahmed Hussen is Canada's Minister of Immigration, Refugees and Citizenship. Hussen himself was a refugee. He came to Canada from Somalia as a teenager. He says they're now trying to counter the impression that Canada has an open border. HUSSEN: If you are just coming because you want a better life and a better opportunity, then you have to apply and regulate economic immigration program and not try to cross the border. We've told people that that's not the way to go. It's illegal. It's potentially dangerous. GARCIA-NAVARRO: Have you had to sort of backpedal that message a little bit to make it clear that the border is not just open for anyone who wants to come into Canada? HUSSEN: It's not a question of backpedaling. There is a lot of misinformation to certain communities in the United States who are given the wrong impression about Canada. To correct that misinformation, we've been deploying resources from our consulates in various American cities to to correct the record with some of the diaspora communities saying, look. You're welcome to Canada, but you have to - it doesn't mean that you can just show up because of your perception of what Canada is about. GARCIA-NAVARRO: The Trump administration's travel ban has run into a series of legal challenges. But the perception that America is closing its door to immigrants remains. Canada is trying to capitalize on that, but it's struggling to figure out what the hashtag #WelcomeToCanada actually means. They're wooing highly skilled immigrants while dissuading refugees from coming north. Illegal crossings were down in September. The influx, though, has provoked a backlash in Canada. A recent poll found that just over half of Canadians think their government is being too generous to asylum-seekers. (SOUNDBITE OF MUSIC)", "section": "World", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-10-29-559557869": {"title": "Foreign Interference Has Bedeviled D.C. For Decades, With No Easy Reponse : NPR", "url": "https://www.npr.org/2017/10/29/559557869/foreign-interference-has-bedeviled-d-c-for-decades-with-no-easy-reponse", "author": "No author found", "published_date": "2017-10-29", "content": "", "section": "National Security", "disclaimer": ""}, "2017-10-29-560431220": {"title": "The Russia Investigations: Countdown To The Big Show; Republicans Strike Back : NPR", "url": "https://www.npr.org/2017/10/29/560431220/the-russia-investigations-countdown-to-the-big-show-republicans-strike-back", "author": "No author found", "published_date": "2017-10-29", "content": "", "section": "National Security", "disclaimer": ""}, "2017-10-30-560767502": {"title": "Amid Privacy Concerns, Mattel Shelved Planned Device For Kids : NPR", "url": "https://www.npr.org/2017/10/30/560767502/mattel-shelved-its-aristotle-device-for-kids-over-privacy-concerns", "author": "No author found", "published_date": "2017-10-30", "content": "DAVID GREENE, HOST:  Artificial intelligence is making its way into everyday life. Digital assistants can help you make a grocery list or maybe keep your home climate-controlled. But what if the devices in your home got involved in raising your kids. Well, we have two stories today from NPR's health team on parenting in the age of Alexa. First NPR's Allison Aubrey reports on a talking device that toymaker Mattel pulled from the market. ALLISON AUBREY, BYLINE: When Mattel first introduced dolls that could talk back in the 1960s, this was considered novel. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED MAN: Meet the most amazing doll all time. . . AUBREY: Pull a ring, and this doll could speak. (SOUNDBITE OF ARCHIVED RECORDING)CHATTY CATHY: Would you like pickle ice cream (laughter)? AUBREY: But what she couldn't do was listen or interact. And Chatty Cathy certainly could not send information to the cloud. Flash forward 50 years, and technology has changed. Mattel's latest device, something the company planned to call Aristotle, could get to know your child, even respond to your kids needs. If your baby cried, Aristotle could play a lullaby. JOSH GOLIN: There is a huge world of difference between a Chatty Cathy and an Aristotle. AUBREY: That's Josh Golin. He's an advocate with the group Campaign for a Commercial-Free Childhood. When he first heard about Aristotle. . . GOLIN: My first thought was, wow, is this creepy. AUBREY: In marketing materials, the Aristotle device looks like a baby monitor with a camera. It was designed to be connected to the Internet and placed in a kid's bedroom. GOLIN: You're talking about a device that was designed to displace essential parenting functions like soothing a crying baby or reading a bedtime story so that children would form an attachment to it. And then that device could be used to collect all sorts of information on a child in their own bedroom. AUBREY: Now, some tech bloggers wrote enthusiastically about Aristotle and its planned release. But the buzz quickly turned to criticism when pediatricians, parents, even politicians weighed in. Two lawmakers on Capitol Hill wrote to Mattel with privacy concerns. What was the company going to do with all that information they were collecting from children? Thousands of people signed petitions asking Mattel to pull the plug, which the company did this month. Pediatrician Jenny Radesky of the University of Michigan says the pressure was on. JENNY RADESKY: We have to remember that children don't really understand concepts such as privacy or machine-learning or the way that the device might be reacting to them or manipulating them. AUBREY: Radesky says when technology is feeding your kids play ideas, this can limit their creative thinking. And the device could drive them away from interactions with their parents and friends. RADESKY: Evidence shows that children learn a lot more from technology when they have an adult scaffolding them and helping them apply what they've learned. AUBREY: That technology isn't going away. Artificial intelligence is becoming more responsive. The question is, can devices be designed to help bring parents and children together? Allison Aubrey, NPR News. DAVID GREENE, HOST:   Artificial intelligence is making its way into everyday life. Digital assistants can help you make a grocery list or maybe keep your home climate-controlled. But what if the devices in your home got involved in raising your kids. Well, we have two stories today from NPR's health team on parenting in the age of Alexa. First NPR's Allison Aubrey reports on a talking device that toymaker Mattel pulled from the market. ALLISON AUBREY, BYLINE: When Mattel first introduced dolls that could talk back in the 1960s, this was considered novel. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED MAN: Meet the most amazing doll all time. . . AUBREY: Pull a ring, and this doll could speak. (SOUNDBITE OF ARCHIVED RECORDING) CHATTY CATHY: Would you like pickle ice cream (laughter)? AUBREY: But what she couldn't do was listen or interact. And Chatty Cathy certainly could not send information to the cloud. Flash forward 50 years, and technology has changed. Mattel's latest device, something the company planned to call Aristotle, could get to know your child, even respond to your kids needs. If your baby cried, Aristotle could play a lullaby. JOSH GOLIN: There is a huge world of difference between a Chatty Cathy and an Aristotle. AUBREY: That's Josh Golin. He's an advocate with the group Campaign for a Commercial-Free Childhood. When he first heard about Aristotle. . . GOLIN: My first thought was, wow, is this creepy. AUBREY: In marketing materials, the Aristotle device looks like a baby monitor with a camera. It was designed to be connected to the Internet and placed in a kid's bedroom. GOLIN: You're talking about a device that was designed to displace essential parenting functions like soothing a crying baby or reading a bedtime story so that children would form an attachment to it. And then that device could be used to collect all sorts of information on a child in their own bedroom. AUBREY: Now, some tech bloggers wrote enthusiastically about Aristotle and its planned release. But the buzz quickly turned to criticism when pediatricians, parents, even politicians weighed in. Two lawmakers on Capitol Hill wrote to Mattel with privacy concerns. What was the company going to do with all that information they were collecting from children? Thousands of people signed petitions asking Mattel to pull the plug, which the company did this month. Pediatrician Jenny Radesky of the University of Michigan says the pressure was on. JENNY RADESKY: We have to remember that children don't really understand concepts such as privacy or machine-learning or the way that the device might be reacting to them or manipulating them. AUBREY: Radesky says when technology is feeding your kids play ideas, this can limit their creative thinking. And the device could drive them away from interactions with their parents and friends. RADESKY: Evidence shows that children learn a lot more from technology when they have an adult scaffolding them and helping them apply what they've learned. AUBREY: That technology isn't going away. Artificial intelligence is becoming more responsive. The question is, can devices be designed to help bring parents and children together? Allison Aubrey, NPR News.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-10-30-560576172": {"title": "4 Big Stories To Watch This Week, From Taxes To The Russia Investigations To Niger : NPR", "url": "https://www.npr.org/2017/10/30/560576172/4-big-stories-to-watch-this-week-from-taxes-to-the-russia-investigations-to-nige", "author": "No author found", "published_date": "2017-10-30", "content": "", "section": "Politics", "disclaimer": ""}, "2017-10-30-560042987": {"title": "Russians Targeted U.S. Racial Divisions Long Before 2016 And Black Lives Matter : NPR", "url": "https://www.npr.org/2017/10/30/560042987/russians-targeted-u-s-racial-divisions-long-before-2016-and-black-lives-matter", "author": "No author found", "published_date": "2017-10-30", "content": "", "section": "National Security", "disclaimer": ""}, "2017-10-31-561246207": {"title": "How One Group Is Monitoring Cyber Trolls Potentially Tied To The Kremlin : NPR", "url": "https://www.npr.org/2017/10/31/561246207/how-one-group-is-monitoring-cyber-trolls-potentially-tied-to-the-kremlin", "author": "No author found", "published_date": "2017-10-31", "content": "ARI SHAPIRO, HOST:  Lots of Russian-linked accounts are trying to grab Americans' attention right now. And one reason we know that is that a group in Washington has created an online dashboard to keep track of those accounts. The group is called the Alliance for Securing Democracy. It's part of the German Marshall Fund in Washington. And here to tell us what is trending this week among Russian bots and trolls is director Laura Rosenberger. Hi, Laura. LAURA ROSENBERGER: Great to be here, Ari. SHAPIRO: Before we dig into this dashboard, tell us how the project actually works. ROSENBERGER: We have this dashboard. It's called the Hamilton 68 dashboard. And the dashboard is tracking about 600 accounts that are a network or really derived from a few different networks that are promoting messaging that is furthering the Kremlin's interests. It's trying to get the Americans to talk about things that the Russians would like us to be talking about. SHAPIRO: So let's actually pull up the dashboard right now and see what these Russian-affiliated accounts are talking about right now. And I see that the No. 1 trending hashtag is #PodestaGroup. This is referring to the Democratic lobbyist Tony Podesta. The top URLs, the first one is Justice Department document unsealed yesterday related to the indictments, and the second one is a story, \"Tony Podesta Stepping Down From Lobbying Giant Amid Mueller Probe. \" Why would this be of such interest to these Russian-affiliated accounts? ROSENBERGER: Of course the big news of the week is actually the indictment of Paul Manafort and Richard Gates - you know, both former Trump campaign officials, Paul Manafort the former chairman of the campaign - and the guilty plea of George Papadopoulos, a foreign policy adviser. SHAPIRO: And their names are below Podesta on this list. ROSENBERGER: Mmm hmm (ph). What we see here is a classic Russian tactic called whataboutism. It's basically trying to muddy the waters, to obfuscate truth, to create the idea that everything is relative, that, oh, look; both the Democrats and the Republicans are in trouble for Russia stuff when the reality is, you know, Tony Podesta hasn't been indicted for anything at this point. To think about sort of what they're doing here is a lot of times they're simply amplifying stories that they believe is useful to them, trying to basically. . . SHAPIRO: Well, fake news is the wrong term. ROSENBERGER: Fake news is completely the wrong term. I mean, disinformation is sort of what we use most generally. But, I mean, these are information operations that span a scale. They're trying to use the social media platforms to distort the information curve, to make certain things trend, to make certain things more popular, to influence certain segments of the conversation in order to basically shape the overarching narrative and conversation that we see happening. SHAPIRO: Should the tech companies be doing this work that you're doing here? ROSENBERGER: I think that the tech companies have certainly been evolving in how they think about their responsibilities on these issues. I certainly hope that they are all doing this internally. The fact that every week they continue to uncover additional ways that their platforms were exploited by the Russian networks indicates to me that whatever they're doing internally, it's still not quite enough. SHAPIRO: That's Laura Rosenberger, director of the Alliance for Securing Democracy and a senior fellow at the German Marshall Fund of the United States. Thanks for coming into our studio. ROSENBERGER: Thanks, Ari. ARI SHAPIRO, HOST:   Lots of Russian-linked accounts are trying to grab Americans' attention right now. And one reason we know that is that a group in Washington has created an online dashboard to keep track of those accounts. The group is called the Alliance for Securing Democracy. It's part of the German Marshall Fund in Washington. And here to tell us what is trending this week among Russian bots and trolls is director Laura Rosenberger. Hi, Laura. LAURA ROSENBERGER: Great to be here, Ari. SHAPIRO: Before we dig into this dashboard, tell us how the project actually works. ROSENBERGER: We have this dashboard. It's called the Hamilton 68 dashboard. And the dashboard is tracking about 600 accounts that are a network or really derived from a few different networks that are promoting messaging that is furthering the Kremlin's interests. It's trying to get the Americans to talk about things that the Russians would like us to be talking about. SHAPIRO: So let's actually pull up the dashboard right now and see what these Russian-affiliated accounts are talking about right now. And I see that the No. 1 trending hashtag is #PodestaGroup. This is referring to the Democratic lobbyist Tony Podesta. The top URLs, the first one is Justice Department document unsealed yesterday related to the indictments, and the second one is a story, \"Tony Podesta Stepping Down From Lobbying Giant Amid Mueller Probe. \" Why would this be of such interest to these Russian-affiliated accounts? ROSENBERGER: Of course the big news of the week is actually the indictment of Paul Manafort and Richard Gates - you know, both former Trump campaign officials, Paul Manafort the former chairman of the campaign - and the guilty plea of George Papadopoulos, a foreign policy adviser. SHAPIRO: And their names are below Podesta on this list. ROSENBERGER: Mmm hmm (ph). What we see here is a classic Russian tactic called whataboutism. It's basically trying to muddy the waters, to obfuscate truth, to create the idea that everything is relative, that, oh, look; both the Democrats and the Republicans are in trouble for Russia stuff when the reality is, you know, Tony Podesta hasn't been indicted for anything at this point. To think about sort of what they're doing here is a lot of times they're simply amplifying stories that they believe is useful to them, trying to basically. . . SHAPIRO: Well, fake news is the wrong term. ROSENBERGER: Fake news is completely the wrong term. I mean, disinformation is sort of what we use most generally. But, I mean, these are information operations that span a scale. They're trying to use the social media platforms to distort the information curve, to make certain things trend, to make certain things more popular, to influence certain segments of the conversation in order to basically shape the overarching narrative and conversation that we see happening. SHAPIRO: Should the tech companies be doing this work that you're doing here? ROSENBERGER: I think that the tech companies have certainly been evolving in how they think about their responsibilities on these issues. I certainly hope that they are all doing this internally. The fact that every week they continue to uncover additional ways that their platforms were exploited by the Russian networks indicates to me that whatever they're doing internally, it's still not quite enough. SHAPIRO: That's Laura Rosenberger, director of the Alliance for Securing Democracy and a senior fellow at the German Marshall Fund of the United States. Thanks for coming into our studio. ROSENBERGER: Thanks, Ari.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-10-31-560481040": {"title": "Facebook, Google, Twitter Testify On Capitol Hill, Detail Russian Interference Efforts : NPR", "url": "https://www.npr.org/2017/10/31/560481040/russian-interference-campaign-was-broader-than-first-known-big-tech-tells-hill", "author": "No author found", "published_date": "2017-10-31", "content": "", "section": "Tech Titans And The Information Complex", "disclaimer": ""}, "2017-10-31-560420077": {"title": "Fed Up With Uncivil Discourse Online, Lawmakers Block Their Constituents : NPR", "url": "https://www.npr.org/2017/10/31/560420077/fed-up-with-uncivil-discourse-online-lawmakers-block-their-constituents", "author": "No author found", "published_date": "2017-10-31", "content": "", "section": "Politics", "disclaimer": ""}, "2017-11-01-561356326": {"title": "Lawmakers Grill Tech Firms On Russia's Use Of Social Media To Influence 2016 Election : NPR", "url": "https://www.npr.org/2017/11/01/561356326/lawmakers-grill-tech-firms-on-russias-use-of-social-media-to-influence-2016-elec", "author": "No author found", "published_date": "2017-11-01", "content": "DAVID GREENE, HOST: Today, senators on Capitol Hill are digging into a big question - how much did Russia use social media to influence a presidential election in this country? This is an issue we have been covering on NPR all week long. Now, this morning, lawyers from Facebook, Google and Twitter have been grilled by members of the Senate intelligence committee. They'll likely face the same in the House intelligence committee later this afternoon. NPR's Aarti Shahani is covering all of this. She's in our studios in Washington. Hey, Aarti. AARTI SHAHANI, BYLINE: Hi. GREENE: So I guess the big question on my mind is are senators actually learning anything about what Russia was able to pull off here using U. S. tech firms? SHAHANI: So this is a really key point. The hearing so far is very focused on establishing the basics, and it is not a simple story line, OK? It's not Russian operatives with a hundred thousand dollars delivered the election the President Trump, right? GREENE: (Laughter) Well, that would be straight and easy. We could all get out of here. SHAHANI: Right, right. So in his opening remarks, Senator Richard Burr, a Republican from North Carolina, you know, he really hit that point that from what we know so far the three states most targeted by the foreign ads were Maryland, Missouri and New York. None of them are swing states. And again, from what they know, more of the geographically targeted ads they ran in 2015, not 2016, which isn't what you'd expect. You'd expect a ramp up to November, right? GREENE: Yeah, certainly, if you're trying to influence an election, you would not expect it to be. . . SHAHANI: To go down. GREENE: . . . At its height in 2015. SHAHANI: Correct, correct. GREENE: Yeah. SHAHANI: Wrong direction. GREENE: Yeah. You keep emphasizing from what they know. I mean, what - explain that because what don't we know? It sounds like a lot. SHAHANI: So much. I mean, that's my skepticism and the senators' too, you know, what really happened, the impact, the numbers? It's a moving target. Several weeks ago, a Facebook security chief said that Russian-linked accounts spent $100,000 total, OK? Then in advance of yesterday's hearing, the company says there were 80,000 ads that reached 126 million people, which, you know, it just sounds like a far bigger footprint. GREENE: Yeah. SHAHANI: And then it also turns out 16 million people were reached on Instagram, which Facebook also owns. So, you know, will the size get bigger? It could. And that's a key point Senator Mark Warner raised, a Democrat from Virginia. Warner is someone who made a fortune as a tech investor, OK? He knows. And let's have a listen to his opening remarks. (SOUNDBITE OF ARCHIVED RECORDING)MARK WARNER: Someone who deeply respects the tech industry and who was involved in that industry for more than 20 years, it's taken me quite a bit of time - and I'm still learning - to truly understand the nature of this threat. Even I struggled to keep up with the language and the mechanics, the difference between bots, trolls and fake accounts, how they generate likes, tweets and shares. SHAHANI: You know, see - you hear that from someone who is a tech insider and you figure they've got a lot of homework to do. GREENE: It sounds that way. And Senator Warner basically saying you're not going to get anything past me because I know this world. Has the committee looked at any specific political ads to get an idea of what was really happening, or are they just focusing on numbers? SHAHANI: Yeah, no, David, this is key. So Senator Burr talked about two Facebook groups associated with the Internet Research Agency, the Russian troll group based in Saint Petersburg. The first group called the Heart of Texas has - it had 250,000 followers. It promoted protests and causes and anti-immigration and anti-Muslim sentiments. Now, a second group called United Muslims of America, it had 328,000 followers and claimed to support pro-Islamic themes - tagline is I'm Muslim and I'm proud. Now, both of these groups organized rallies - one anti-Muslim, one pro-Muslim - at the same time and same place in front of an Islamic center in Houston. So what does that tell us? Two things. First of all, it's not just digital. There is a straight line from online to real world. GREENE: Yeah. SHAHANI: And, you know, it's rabble-rousing. GREENE: All right. NPR's Aarti Shahani. Thanks, Aarti. SHAHANI: Thank you. DAVID GREENE, HOST:  Today, senators on Capitol Hill are digging into a big question - how much did Russia use social media to influence a presidential election in this country? This is an issue we have been covering on NPR all week long. Now, this morning, lawyers from Facebook, Google and Twitter have been grilled by members of the Senate intelligence committee. They'll likely face the same in the House intelligence committee later this afternoon. NPR's Aarti Shahani is covering all of this. She's in our studios in Washington. Hey, Aarti. AARTI SHAHANI, BYLINE: Hi. GREENE: So I guess the big question on my mind is are senators actually learning anything about what Russia was able to pull off here using U. S. tech firms? SHAHANI: So this is a really key point. The hearing so far is very focused on establishing the basics, and it is not a simple story line, OK? It's not Russian operatives with a hundred thousand dollars delivered the election the President Trump, right? GREENE: (Laughter) Well, that would be straight and easy. We could all get out of here. SHAHANI: Right, right. So in his opening remarks, Senator Richard Burr, a Republican from North Carolina, you know, he really hit that point that from what we know so far the three states most targeted by the foreign ads were Maryland, Missouri and New York. None of them are swing states. And again, from what they know, more of the geographically targeted ads they ran in 2015, not 2016, which isn't what you'd expect. You'd expect a ramp up to November, right? GREENE: Yeah, certainly, if you're trying to influence an election, you would not expect it to be. . . SHAHANI: To go down. GREENE: . . . At its height in 2015. SHAHANI: Correct, correct. GREENE: Yeah. SHAHANI: Wrong direction. GREENE: Yeah. You keep emphasizing from what they know. I mean, what - explain that because what don't we know? It sounds like a lot. SHAHANI: So much. I mean, that's my skepticism and the senators' too, you know, what really happened, the impact, the numbers? It's a moving target. Several weeks ago, a Facebook security chief said that Russian-linked accounts spent $100,000 total, OK? Then in advance of yesterday's hearing, the company says there were 80,000 ads that reached 126 million people, which, you know, it just sounds like a far bigger footprint. GREENE: Yeah. SHAHANI: And then it also turns out 16 million people were reached on Instagram, which Facebook also owns. So, you know, will the size get bigger? It could. And that's a key point Senator Mark Warner raised, a Democrat from Virginia. Warner is someone who made a fortune as a tech investor, OK? He knows. And let's have a listen to his opening remarks. (SOUNDBITE OF ARCHIVED RECORDING) MARK WARNER: Someone who deeply respects the tech industry and who was involved in that industry for more than 20 years, it's taken me quite a bit of time - and I'm still learning - to truly understand the nature of this threat. Even I struggled to keep up with the language and the mechanics, the difference between bots, trolls and fake accounts, how they generate likes, tweets and shares. SHAHANI: You know, see - you hear that from someone who is a tech insider and you figure they've got a lot of homework to do. GREENE: It sounds that way. And Senator Warner basically saying you're not going to get anything past me because I know this world. Has the committee looked at any specific political ads to get an idea of what was really happening, or are they just focusing on numbers? SHAHANI: Yeah, no, David, this is key. So Senator Burr talked about two Facebook groups associated with the Internet Research Agency, the Russian troll group based in Saint Petersburg. The first group called the Heart of Texas has - it had 250,000 followers. It promoted protests and causes and anti-immigration and anti-Muslim sentiments. Now, a second group called United Muslims of America, it had 328,000 followers and claimed to support pro-Islamic themes - tagline is I'm Muslim and I'm proud. Now, both of these groups organized rallies - one anti-Muslim, one pro-Muslim - at the same time and same place in front of an Islamic center in Houston. So what does that tell us? Two things. First of all, it's not just digital. There is a straight line from online to real world. GREENE: Yeah. SHAHANI: And, you know, it's rabble-rousing. GREENE: All right. NPR's Aarti Shahani. Thanks, Aarti. SHAHANI: Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-11-01-560481387": {"title": "Facebook, Twitter And Google On Capitol Hill For More Russia Interference Questions : NPR", "url": "https://www.npr.org/2017/11/01/560481387/how-russian-backed-agitation-online-spilled-into-the-real-world-in-2016", "author": "No author found", "published_date": "2017-11-01", "content": "", "section": "Tech Titans And The Information Complex", "disclaimer": ""}, "2017-11-01-561203044": {"title": "Charges, Hearings Sharpen The Big Picture About Russia's Influence Campaign : NPR", "url": "https://www.npr.org/2017/11/01/561203044/charges-hearings-sharpen-the-big-picture-about-russias-influence-campaign", "author": "No author found", "published_date": "2017-11-01", "content": "", "section": "Analysis", "disclaimer": ""}, "2017-11-02-561671231": {"title": "How Facebook's Ads Could Change Following The Russian Debacle : NPR", "url": "https://www.npr.org/2017/11/02/561671231/how-facebooks-ads-could-change-following-the-russian-debacle", "author": "No author found", "published_date": "2017-11-02", "content": "MARY LOUISE KELLY, HOST:  This week, representatives from Facebook, Google and Twitter were on Capitol Hill, but not the CEOs, the people calling the shots. They sent their lawyers instead. And over two days of hearings, they tried to convince lawmakers there is no need to regulate their platforms. NPR's Aarti Shahani reports. AARTI SHAHANI, BYLINE: Senators wanted to understand not just the metrics - how much money did Facebook make off Russia-linked ads? How many Twitter users are bots? - but the motivations of the tech titans. (SOUNDBITE OF ARCHIVED RECORDING)ANGUS KING: I must say, though, I'm disappointed that you're here and not your CEOs. SHAHANI: Senator Angus King, a Maine independent. (SOUNDBITE OF ARCHIVED RECORDING)KING: If we go through this exercise again, we would appreciate seeing the top people who are actually making the decision. SHAHANI: He wasn't the only one. (SOUNDBITE OF ARCHIVED RECORDING)JOE MANCHIN: Are you or your CEOs concerned about the threat and damage your companies can do to the U. S. with your far-reaching power? SHAHANI: Senator Joe Manchin, West Virginia Democrat. (SOUNDBITE OF ARCHIVED RECORDING)MANCHIN: Are you concerned about that? Do your CEOs - do you talk about the threats to the United States of America, or your domicile? Or is it basically just a business model? SHAHANI: Facebook celebrity executives Mark Zuckerberg and Sheryl Sandberg were not on Capitol Hill yesterday when Congress grilled the company's top lawyers about divisive Russian propaganda and the threat to democracy. Instead, they were on an earnings call with investors. (SOUNDBITE OF ARCHIVED RECORDING)MARK ZUCKERBERG: Thanks everyone for joining us today. SHAHANI: CEO Zuckerberg. (SOUNDBITE OF ARCHIVED RECORDING)ZUCKERBERG: And we had our first ever quarter with more than $10 billion in revenue. SHAHANI: $10 billion fueled by the company's dominance in online advertising. But just a minute into opening remarks, there is a but. (SOUNDBITE OF ARCHIVED RECORDING)ZUCKERBERG: But none of that matters if our services are used in a way that doesn't bring people closer together. SHAHANI: The CEO veers from metrics to politics. And by doing that, he is signaling two things to investors - one, I care and two, I'm on top of it. (SOUNDBITE OF ARCHIVED RECORDING)ZUCKERBERG: I am dead serious about this. And the reason I'm talking about this on our earnings call is that I've directed our teams to invest so much in security on top of the other investments we're making that it will significantly impact our profitability going forward. And I wanted our investors to hear that directly from me. SHAHANI: He says over the next year, Facebook will double the people working on safety and security from 10,000 to 20,000, and that protecting online communities is more important than maximizing profits. The company says it'll build tools to reveal which advertisers are placing which ads. RENEE DIRESTA: What they came out with was more than I expected. This might be me having very low expectations at this point. SHAHANI: Renee DiResta is a tech entrepreneur and advocate for data transparency. She says Facebook downplayed the Russia threat a lot. Just weeks ago, they claimed Russia-linked ads reached 10 million users. This week, that number skyrocketed to 126 million. The company is changing its tune, and she has a theory about why. Facebook, as well as Google and Twitter, are trying to avoid regulation. It's a self-preservation instinct, in her words. DIRESTA: And that is what is really motivating these decisions by the platforms. They, of course, hope to get ahead of it because regulation is arduous. SHAHANI: Social media experts are watching to see how far the companies go in accepting responsibility for the ads that users post. Ginny Marvin, an editor at Search Engine Land, a marketer trade publication, makes a subtle but important point. The tech platforms are promising to vigorously check political ads, - ads for candidates. But they haven't talked about issue ads, like for or against gun control. GINNY MARVIN: These are opinions that people have. And we are just the platform. We can't step in and police that. SHAHANI: She expects that in the next round of debates, the conflict between how the tech companies see themselves - as private platforms - and how lawmakers increasingly see them - as public squares - will come to a head. Aarti Shahani, NPR News, Washington. (SOUNDBITE OF EL HUERVO'S \"DAISUKE\") MARY LOUISE KELLY, HOST:   This week, representatives from Facebook, Google and Twitter were on Capitol Hill, but not the CEOs, the people calling the shots. They sent their lawyers instead. And over two days of hearings, they tried to convince lawmakers there is no need to regulate their platforms. NPR's Aarti Shahani reports. AARTI SHAHANI, BYLINE: Senators wanted to understand not just the metrics - how much money did Facebook make off Russia-linked ads? How many Twitter users are bots? - but the motivations of the tech titans. (SOUNDBITE OF ARCHIVED RECORDING) ANGUS KING: I must say, though, I'm disappointed that you're here and not your CEOs. SHAHANI: Senator Angus King, a Maine independent. (SOUNDBITE OF ARCHIVED RECORDING) KING: If we go through this exercise again, we would appreciate seeing the top people who are actually making the decision. SHAHANI: He wasn't the only one. (SOUNDBITE OF ARCHIVED RECORDING) JOE MANCHIN: Are you or your CEOs concerned about the threat and damage your companies can do to the U. S. with your far-reaching power? SHAHANI: Senator Joe Manchin, West Virginia Democrat. (SOUNDBITE OF ARCHIVED RECORDING) MANCHIN: Are you concerned about that? Do your CEOs - do you talk about the threats to the United States of America, or your domicile? Or is it basically just a business model? SHAHANI: Facebook celebrity executives Mark Zuckerberg and Sheryl Sandberg were not on Capitol Hill yesterday when Congress grilled the company's top lawyers about divisive Russian propaganda and the threat to democracy. Instead, they were on an earnings call with investors. (SOUNDBITE OF ARCHIVED RECORDING) MARK ZUCKERBERG: Thanks everyone for joining us today. SHAHANI: CEO Zuckerberg. (SOUNDBITE OF ARCHIVED RECORDING) ZUCKERBERG: And we had our first ever quarter with more than $10 billion in revenue. SHAHANI: $10 billion fueled by the company's dominance in online advertising. But just a minute into opening remarks, there is a but. (SOUNDBITE OF ARCHIVED RECORDING) ZUCKERBERG: But none of that matters if our services are used in a way that doesn't bring people closer together. SHAHANI: The CEO veers from metrics to politics. And by doing that, he is signaling two things to investors - one, I care and two, I'm on top of it. (SOUNDBITE OF ARCHIVED RECORDING) ZUCKERBERG: I am dead serious about this. And the reason I'm talking about this on our earnings call is that I've directed our teams to invest so much in security on top of the other investments we're making that it will significantly impact our profitability going forward. And I wanted our investors to hear that directly from me. SHAHANI: He says over the next year, Facebook will double the people working on safety and security from 10,000 to 20,000, and that protecting online communities is more important than maximizing profits. The company says it'll build tools to reveal which advertisers are placing which ads. RENEE DIRESTA: What they came out with was more than I expected. This might be me having very low expectations at this point. SHAHANI: Renee DiResta is a tech entrepreneur and advocate for data transparency. She says Facebook downplayed the Russia threat a lot. Just weeks ago, they claimed Russia-linked ads reached 10 million users. This week, that number skyrocketed to 126 million. The company is changing its tune, and she has a theory about why. Facebook, as well as Google and Twitter, are trying to avoid regulation. It's a self-preservation instinct, in her words. DIRESTA: And that is what is really motivating these decisions by the platforms. They, of course, hope to get ahead of it because regulation is arduous. SHAHANI: Social media experts are watching to see how far the companies go in accepting responsibility for the ads that users post. Ginny Marvin, an editor at Search Engine Land, a marketer trade publication, makes a subtle but important point. The tech platforms are promising to vigorously check political ads, - ads for candidates. But they haven't talked about issue ads, like for or against gun control. GINNY MARVIN: These are opinions that people have. And we are just the platform. We can't step in and police that. SHAHANI: She expects that in the next round of debates, the conflict between how the tech companies see themselves - as private platforms - and how lawmakers increasingly see them - as public squares - will come to a head. Aarti Shahani, NPR News, Washington. (SOUNDBITE OF EL HUERVO'S \"DAISUKE\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-11-02-561521906": {"title": "AP: 'Digital Hit List' Provides Evidence Of Hackers' Links To Kremlin : NPR", "url": "https://www.npr.org/2017/11/02/561521906/ap-digital-hit-list-provides-evidence-of-hackers-links-to-kremlin", "author": "No author found", "published_date": "2017-11-02", "content": "DAVID GREENE, HOST:  At the time that Russia was believed to be hacking to try and influence the U. S. presidential election that may have just been part of their plans. The Associated Press is out this morning with essentially a hit list of what it reports were targets of Russian hacking. One of the reporters who wrote that AP story is Raphael Satter. He joins us on Skype this morning. Good morning. RAPHAEL SATTER: Good morning. GREENE: So who does it appear Russia was targeting and why? SATTER: Thousands of people from all over the world. We've got about 160 countries here on this list. But the overwhelming majority of them seem to come from countries that are of special interest to Moscow - countries like Ukraine or Syria or Georgia, neighboring countries in the post-Soviet space and, of course, the United States. GREENE: So does this undermine, potentially, the narrative that Russia had this very narrow specific plan to try and influence the U. S. presidential election? This might have been just one part of a master plan to hack into a lot of countries in - you know, to help their interests. SATTER: I think the data fixed a variety of arguments. So some might see this as evidence that the Russians weren't particularly interested in the Democrats, and I think that you could make that argument. Some might see this as evidence that the Russians were particularly interested in the Democrats because our data does show that about 130 individual members of the Democratic Party or employees or supporters were targeted by these hackers. That's an unusually high number. They don't usually go after a single political party quite like they do the Democrats. So there's some stuff that the data doesn't quite tell us. GREENE: Now, the hackers responsible - I know that they're known as Fancy Bear, that name. They accidentally left some of their phishing out on the Internet, which is how you ultimately got access to it in your reporting. But how certain are we that Fancy Bear is tied to the government in Russia? SATTER: We can't make that argument based on the data that we have at our disposal. What we can say is that Fancy Bear's interests seem to coincide almost perfectly with the interest of the Kremlin. So, for example, they're very interested in opposition politicians in Russia, in anti-corruption campaigners in Russia. Well, we know that the Kremlin is very interested in those people, too. They're very interested in Syrian rebels and Ukrainian fighters. Well, we know that Russia is fighting those people as we speak. So the interests seem to line up pretty perfectly. GREENE: So there's also a personal note in all of this for you. Your dad was one of the people on this hit list? SATTER: Yeah, he was. That was a little bit of a shock - it was a little bit of a shock to discover that. Now, we knew, of course, that my father was hacked because it happened last year. And it was written about by other journalists. When I took a look at Secureworks' lists, I saw his name on there. And we went back through his emails and, sure enough, there was a malicious email right when the list said there would be. So I said it was a shock, but actually it wasn't that much of a shock. It was more startling than anything else. GREENE: (Laughter) I guess. And your dad, we should say, is an author and Russia specialist who has criticized the Kremlin. So maybe startling, but not so much of a shock. SATTER: Yeah, not surprising. GREENE: Yeah. Raphael Satter from the Associated Press, thanks for your reporting and thanks for taking the time this morning. SATTER: Thank you. DAVID GREENE, HOST:   At the time that Russia was believed to be hacking to try and influence the U. S. presidential election that may have just been part of their plans. The Associated Press is out this morning with essentially a hit list of what it reports were targets of Russian hacking. One of the reporters who wrote that AP story is Raphael Satter. He joins us on Skype this morning. Good morning. RAPHAEL SATTER: Good morning. GREENE: So who does it appear Russia was targeting and why? SATTER: Thousands of people from all over the world. We've got about 160 countries here on this list. But the overwhelming majority of them seem to come from countries that are of special interest to Moscow - countries like Ukraine or Syria or Georgia, neighboring countries in the post-Soviet space and, of course, the United States. GREENE: So does this undermine, potentially, the narrative that Russia had this very narrow specific plan to try and influence the U. S. presidential election? This might have been just one part of a master plan to hack into a lot of countries in - you know, to help their interests. SATTER: I think the data fixed a variety of arguments. So some might see this as evidence that the Russians weren't particularly interested in the Democrats, and I think that you could make that argument. Some might see this as evidence that the Russians were particularly interested in the Democrats because our data does show that about 130 individual members of the Democratic Party or employees or supporters were targeted by these hackers. That's an unusually high number. They don't usually go after a single political party quite like they do the Democrats. So there's some stuff that the data doesn't quite tell us. GREENE: Now, the hackers responsible - I know that they're known as Fancy Bear, that name. They accidentally left some of their phishing out on the Internet, which is how you ultimately got access to it in your reporting. But how certain are we that Fancy Bear is tied to the government in Russia? SATTER: We can't make that argument based on the data that we have at our disposal. What we can say is that Fancy Bear's interests seem to coincide almost perfectly with the interest of the Kremlin. So, for example, they're very interested in opposition politicians in Russia, in anti-corruption campaigners in Russia. Well, we know that the Kremlin is very interested in those people, too. They're very interested in Syrian rebels and Ukrainian fighters. Well, we know that Russia is fighting those people as we speak. So the interests seem to line up pretty perfectly. GREENE: So there's also a personal note in all of this for you. Your dad was one of the people on this hit list? SATTER: Yeah, he was. That was a little bit of a shock - it was a little bit of a shock to discover that. Now, we knew, of course, that my father was hacked because it happened last year. And it was written about by other journalists. When I took a look at Secureworks' lists, I saw his name on there. And we went back through his emails and, sure enough, there was a malicious email right when the list said there would be. So I said it was a shock, but actually it wasn't that much of a shock. It was more startling than anything else. GREENE: (Laughter) I guess. And your dad, we should say, is an author and Russia specialist who has criticized the Kremlin. So maybe startling, but not so much of a shock. SATTER: Yeah, not surprising. GREENE: Yeah. Raphael Satter from the Associated Press, thanks for your reporting and thanks for taking the time this morning. SATTER: Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-11-02-561446855": {"title": "Facebook, Twitter And Google Faced Tough Questions, Hours Of Hearings Over Russian Interference : NPR", "url": "https://www.npr.org/2017/11/02/561446855/tough-questions-hours-of-hearings-but-no-silver-bullet-on-russian-tech-interfere", "author": "No author found", "published_date": "2017-11-02", "content": "", "section": "Tech Titans And The Information Complex", "disclaimer": ""}, "2017-11-03-561952364": {"title": "Trump's Twitter Account Down For 11 Minutes : NPR", "url": "https://www.npr.org/2017/11/03/561952364/trumps-twitter-deleted", "author": "No author found", "published_date": "2017-11-03", "content": "MARY LOUISE KELLY, HOST: Eleven minutes - that's how long President Trump's Twitter account was down last night. Twitter says it was taken down by someone at the company, and that is raising all kinds of questions about the security of the president's favorite means of communication. Here to help answer some of those questions is NPR's Laura Sydell. Hey, Laura. LAURA SYDELL, BYLINE: Hello. KELLY: What have you been able to learn about how this happened? SYDELL: Well, what we do know is that reportedly this was a contract employee of the company, and it was that employee's last day on the job. Now, in a statement, all Twitter would say is that they've implemented security measures to make sure it won't happen again. And they said they're not going to give us any more details about their internal investigation. But a lot of people who monitor Twitter for content that violates its rules, I should add, are in - contractors who are in Asia. And my sources say that contractors have had the ability to flag and take down accounts that violate Twitter rules in, say, the Philippines. KELLY: I mean, it's just incredible that a contractor leaving Twitter has the ability to take down the president's Twitter account. Do we know, by the way, if it was intentional? SYDELL: We don't know. We don't know. KELLY: What kind of alarm bells is this ringing, though, for cybersecurity experts as they look at this? SYDELL: Well, you know, I would say it's ringing quite a few. I mean, there is the possibility that somebody could, say, break into the president's account and start tweeting on his behalf. And given that the president uses the platform to announce policy, discuss relations with North Korea. . . KELLY: He tweets, and it moves the markets, yeah. SYDELL: That's right. You know, or it could start a war. This is worrisome. And Twitter is not a company that's known to be the most organized about security, historically speaking. And I say this having spoken to several people who used to work there fairly recently. Twitter has a problem competing with talent. You know, the much bigger, more wealthier companies - Facebook, Apple, Google - are looking for the best talent. So Twitter's got to compete for those people. I've also learned from sources that during the election, Trump's Twitter account was managed with outside software. So this is a way to help a candidate manage and curate followers on his account, but that also makes it more easily hackable. And it wouldn't be easy to hack. I want to make that clear. But his account would sure be an enticing target to a lot of people. KELLY: It sure would. In the seconds we've got left, should we all be rethinking the way that we use Twitter and other social media if the president's account isn't safe? SYDELL: Yes, I actually do think that we should. Twitter is not known for its security. And again, it has contractors on the other side of the world monitoring its content, making decisions. I will quickly throw in - the IRS has got this down. It makes it really - it protects accounts from being accessed by employees, you know, so - really carefully. So maybe Twitter should take a page from the IRS. KELLY: NPR's Laura Sydell, thanks so much. SYDELL: You're welcome. MARY LOUISE KELLY, HOST:  Eleven minutes - that's how long President Trump's Twitter account was down last night. Twitter says it was taken down by someone at the company, and that is raising all kinds of questions about the security of the president's favorite means of communication. Here to help answer some of those questions is NPR's Laura Sydell. Hey, Laura. LAURA SYDELL, BYLINE: Hello. KELLY: What have you been able to learn about how this happened? SYDELL: Well, what we do know is that reportedly this was a contract employee of the company, and it was that employee's last day on the job. Now, in a statement, all Twitter would say is that they've implemented security measures to make sure it won't happen again. And they said they're not going to give us any more details about their internal investigation. But a lot of people who monitor Twitter for content that violates its rules, I should add, are in - contractors who are in Asia. And my sources say that contractors have had the ability to flag and take down accounts that violate Twitter rules in, say, the Philippines. KELLY: I mean, it's just incredible that a contractor leaving Twitter has the ability to take down the president's Twitter account. Do we know, by the way, if it was intentional? SYDELL: We don't know. We don't know. KELLY: What kind of alarm bells is this ringing, though, for cybersecurity experts as they look at this? SYDELL: Well, you know, I would say it's ringing quite a few. I mean, there is the possibility that somebody could, say, break into the president's account and start tweeting on his behalf. And given that the president uses the platform to announce policy, discuss relations with North Korea. . . KELLY: He tweets, and it moves the markets, yeah. SYDELL: That's right. You know, or it could start a war. This is worrisome. And Twitter is not a company that's known to be the most organized about security, historically speaking. And I say this having spoken to several people who used to work there fairly recently. Twitter has a problem competing with talent. You know, the much bigger, more wealthier companies - Facebook, Apple, Google - are looking for the best talent. So Twitter's got to compete for those people. I've also learned from sources that during the election, Trump's Twitter account was managed with outside software. So this is a way to help a candidate manage and curate followers on his account, but that also makes it more easily hackable. And it wouldn't be easy to hack. I want to make that clear. But his account would sure be an enticing target to a lot of people. KELLY: It sure would. In the seconds we've got left, should we all be rethinking the way that we use Twitter and other social media if the president's account isn't safe? SYDELL: Yes, I actually do think that we should. Twitter is not known for its security. And again, it has contractors on the other side of the world monitoring its content, making decisions. I will quickly throw in - the IRS has got this down. It makes it really - it protects accounts from being accessed by employees, you know, so - really carefully. So maybe Twitter should take a page from the IRS. KELLY: NPR's Laura Sydell, thanks so much. SYDELL: You're welcome.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-11-04-562137089": {"title": "Social Media Companies Can Block Foreign Interference With Technology It Already Has : NPR", "url": "https://www.npr.org/2017/11/04/562137089/social-media-companies-can-block-foreign-interference-with-technology-it-already", "author": "No author found", "published_date": "2017-11-04", "content": "NOEL KING, HOST: Federal indictments against three people in President Trump's orbit dominated the headlines this week. But on Capitol Hill, there was another Russia story. Lawyers from Facebook, Google and Twitter faced tough questions from Congress about how foreign actors used their platforms to influence the 2016 election. Facebook now says around 130 million Americans were exposed to content created by alleged Russian operatives. Now, all three companies say they plan to try to stop this from happening again. The question is, what can they really do? For some answers, we're joined by Hany Farid. He chairs the computer science department at Dartmouth. Professor Farid created software that is used by tech companies to find and remove bad content like child pornography. And he says his technology could be modified for some of these newer problems. Professor Farid, thanks for coming on the show. HANY FARID: Thanks for having me. KING: So tell me about the software that you invented. FARID: Yeah. so back in the mid-2000s, we developed a technology called PhotoDNA that is currently being used by the major platforms to find and remove child pornography. And so the approach we took is a bit of a hybrid approach. Humans flag the illegal or inappropriate content, and then the computer goes in and extracts from that content a distinct digital signature. And then we just sit at the pipe of a Facebook. And every single upload that comes up, you extract the same type of signature. You compare it to a database of known bad content, and you can very quickly and accurately remove that kind of content. KING: The companies that were being grilled on Capitol Hill this week - Google, Facebook, Twitter - are they currently using your software? FARID: They are. Facebook has been using it since 2010, Twitter since 2011 and Google fairly recently in 2016 started using it but only in the child pornography space. So they have yet to deploy that same technology as aggressively and widespread in the counter-extremism, fake news, election tampering, these issues that we're hearing about. KING: Your software has prevented child pornography from being transmitted. Can it do the same with fake political ads coming from Russia? FARID: To some extent, yes, and to some extent, no. So to the extent that these fake articles have images or videos that we have flagged as being part of a fake news story, you can take exactly the same technology and deploy it on the fight against fake news. We're also going to have to change the business model of how we promote news stories. It can't just be the things that are clicked on the most - the click bait. We have to start getting some idea of reliability. We have to start thinking about this is not just about engagement, how many eyes can I get on a story? But it should also be about trust, and that requires a really fundamental difference in thinking on these platforms and how they want to engage with their customers. KING: Was there anything that Facebook and Twitter and Google could have done to stop Russia from buying and spreading fake ads? FARID: Sure. There's absolutely things they could have done. They could have had more transparency in reporting on who's buying the ads. They could have changed the business model on how they promote articles not just who's clicking on those modes, but what is more reliable. They could have had humans in the loop reviewing the purchases. So they absolutely could have done more, but part of the business model is to fully automate all these things so that they could work at the scale of billions and billions of people. So it's in many ways baked into the system - the system that they created. They could have created a system or modified a system to have more checks and balances but they didn't. And now the question is, what are they going to do next? KING: Tech companies really do seem nervous about instituting regulation to stop false information from spreading online. Why is that? FARID: Yeah, that's a good question. It's so interesting because when we were working on the child pornography problem back in the mid-2000s, we had similar concerns from the tech companies. They said things like, well, how do you define child pornography? How do we know what the age is? What is the definition of sexually explicit? And, look, the easiest thing to do is to have a platform with no rules and regulations. It's easy because there's no inconsistency, right? Everything goes and if something's illegal, that's a law enforcement problem. And as soon as you get into the business of saying, this is appropriate, this is not appropriate, this is legal, this is not legal, you open yourself up to complex problems. I don't think we should shy away from those complex problems because I think the cost of not doing it is simply too high. That should not be an excuse for inaction. KING: Hany Farid is chair of the department of computer science at Dartmouth College. Professor Farid, thanks so much for coming on. FARID: Thanks for having me. NOEL KING, HOST:  Federal indictments against three people in President Trump's orbit dominated the headlines this week. But on Capitol Hill, there was another Russia story. Lawyers from Facebook, Google and Twitter faced tough questions from Congress about how foreign actors used their platforms to influence the 2016 election. Facebook now says around 130 million Americans were exposed to content created by alleged Russian operatives. Now, all three companies say they plan to try to stop this from happening again. The question is, what can they really do? For some answers, we're joined by Hany Farid. He chairs the computer science department at Dartmouth. Professor Farid created software that is used by tech companies to find and remove bad content like child pornography. And he says his technology could be modified for some of these newer problems. Professor Farid, thanks for coming on the show. HANY FARID: Thanks for having me. KING: So tell me about the software that you invented. FARID: Yeah. so back in the mid-2000s, we developed a technology called PhotoDNA that is currently being used by the major platforms to find and remove child pornography. And so the approach we took is a bit of a hybrid approach. Humans flag the illegal or inappropriate content, and then the computer goes in and extracts from that content a distinct digital signature. And then we just sit at the pipe of a Facebook. And every single upload that comes up, you extract the same type of signature. You compare it to a database of known bad content, and you can very quickly and accurately remove that kind of content. KING: The companies that were being grilled on Capitol Hill this week - Google, Facebook, Twitter - are they currently using your software? FARID: They are. Facebook has been using it since 2010, Twitter since 2011 and Google fairly recently in 2016 started using it but only in the child pornography space. So they have yet to deploy that same technology as aggressively and widespread in the counter-extremism, fake news, election tampering, these issues that we're hearing about. KING: Your software has prevented child pornography from being transmitted. Can it do the same with fake political ads coming from Russia? FARID: To some extent, yes, and to some extent, no. So to the extent that these fake articles have images or videos that we have flagged as being part of a fake news story, you can take exactly the same technology and deploy it on the fight against fake news. We're also going to have to change the business model of how we promote news stories. It can't just be the things that are clicked on the most - the click bait. We have to start getting some idea of reliability. We have to start thinking about this is not just about engagement, how many eyes can I get on a story? But it should also be about trust, and that requires a really fundamental difference in thinking on these platforms and how they want to engage with their customers. KING: Was there anything that Facebook and Twitter and Google could have done to stop Russia from buying and spreading fake ads? FARID: Sure. There's absolutely things they could have done. They could have had more transparency in reporting on who's buying the ads. They could have changed the business model on how they promote articles not just who's clicking on those modes, but what is more reliable. They could have had humans in the loop reviewing the purchases. So they absolutely could have done more, but part of the business model is to fully automate all these things so that they could work at the scale of billions and billions of people. So it's in many ways baked into the system - the system that they created. They could have created a system or modified a system to have more checks and balances but they didn't. And now the question is, what are they going to do next? KING: Tech companies really do seem nervous about instituting regulation to stop false information from spreading online. Why is that? FARID: Yeah, that's a good question. It's so interesting because when we were working on the child pornography problem back in the mid-2000s, we had similar concerns from the tech companies. They said things like, well, how do you define child pornography? How do we know what the age is? What is the definition of sexually explicit? And, look, the easiest thing to do is to have a platform with no rules and regulations. It's easy because there's no inconsistency, right? Everything goes and if something's illegal, that's a law enforcement problem. And as soon as you get into the business of saying, this is appropriate, this is not appropriate, this is legal, this is not legal, you open yourself up to complex problems. I don't think we should shy away from those complex problems because I think the cost of not doing it is simply too high. That should not be an excuse for inaction. KING: Hany Farid is chair of the department of computer science at Dartmouth College. Professor Farid, thanks so much for coming on. FARID: Thanks for having me.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-11-05-562058208": {"title": "How Russia Weaponized Social Media With 'Social Bots' : NPR", "url": "https://www.npr.org/2017/11/05/562058208/how-russia-weaponized-social-media-with-social-bots", "author": "No author found", "published_date": "2017-11-05", "content": "LULU GARCIA-NAVARRO, HOST: Information warfare may be as old as war itself. And lawmakers are now addressing its newest weapon. Top lawyers from Google, Facebook and Twitter testified this week about Russian interference in the 2016 presidential election. One of the terms on the agenda - social bots, computer programs that mimic real people on social media. NPR's Eric Westervelt has our story. ERIC WESTERVELT, BYLINE: Experts who hunt bots for a living aren't convinced the tech giants are doing enough to combat the malicious use of social bots, programs that imitate human behavior on the web or your digital device. DAN KAMINSKY: We have this joke in computer security. It's a game. It's called nation-state or teenager because any particular attack really could be both. WESTERVELT: That's Dan Kaminsky, co-founder of the cybersecurity firm White Ops. You could call him one of the nation's foremost bot hunters. Bots are everywhere. For example, they help you with virtual customer service. And on your smartphone, chatbots help dictate messages. But each bot can be programmed with its own unique identity, Kaminsky says, and used easily for ad fraud or to spread misinformation and propaganda as we saw during last year's presidential race. KAMINSKY: There are absolutely clever bots out there. But it's not like these are, you know, wild, artificial intelligences. They're no more artificially intelligent than the printing press. WESTERVELT: But in the last few years, Kaminsky says, he began to see exceptions to that. He helped take down what's been dubbed Methbot. Russian hackers using so-called bot farms created thousands of fake websites to dupe web marketers into buying millions of dollars worth of video ads. Companies thought thousands of real people had viewed these ads. In fact, they were bots designed to imitate real web surfers. It was one of the largest ad fraud attacks in the history of the web. Kaminsky says Methbot was new, a very scalable, sophisticated criminal operation and, in retrospect, something of a Russian-bot shot across the bow. KAMINSKY: Custom coding, custom engineering, custom operations - those were certainly well beyond, you know, your average 12-year-old in Poughkeepsie. And it tells you things about other similar attacks. WESTERVELT: Methbot was ad fraud. But Russian hackers used social bots in new, effective ways in the election. At the hearings on Capitol Hill, Clint Watts with the Foreign Policy Research Institute warns senators that the social bot problem will only get worse if tech giants don't take stronger collective action now. (SOUNDBITE OF ARCHIVED RECORDING)CLINT WATTS: They can create accounts that look like you and talk like you, which makes you more likely to believe it. The other thing is it can replicate a message so many times, the more times you see it the more likely you are to believe it. So it can actually create false worlds in the social media space. WESTERVELT: Research shows that many of the Russian social bots were programmed to direct tweets at users with lots of followers and influence. That helped make some false claims spread farther faster. Bot expert Sam Woolley is research director of the Digital Intelligence Lab. He says he heard too much in the hearings about Russian political ads and not enough about how tech companies might work together to combat social bots. SAM WOOLLEY: There are so many other mechanisms from group pages on Facebook to private rooms on Twitter that can be used to spread propaganda and misinformation. And we know we're used by the Russian government to do that. So we need to move the focus beyond just the political advertisements and toward the larger scale attacks that were going on. WESTERVELT: The tech firms insist they're taking adequate action. But the hackers, Woolley says, and their bot armies on the march are often one step ahead. Eric Westervelt, NPR News, San Francisco. LULU GARCIA-NAVARRO, HOST:  Information warfare may be as old as war itself. And lawmakers are now addressing its newest weapon. Top lawyers from Google, Facebook and Twitter testified this week about Russian interference in the 2016 presidential election. One of the terms on the agenda - social bots, computer programs that mimic real people on social media. NPR's Eric Westervelt has our story. ERIC WESTERVELT, BYLINE: Experts who hunt bots for a living aren't convinced the tech giants are doing enough to combat the malicious use of social bots, programs that imitate human behavior on the web or your digital device. DAN KAMINSKY: We have this joke in computer security. It's a game. It's called nation-state or teenager because any particular attack really could be both. WESTERVELT: That's Dan Kaminsky, co-founder of the cybersecurity firm White Ops. You could call him one of the nation's foremost bot hunters. Bots are everywhere. For example, they help you with virtual customer service. And on your smartphone, chatbots help dictate messages. But each bot can be programmed with its own unique identity, Kaminsky says, and used easily for ad fraud or to spread misinformation and propaganda as we saw during last year's presidential race. KAMINSKY: There are absolutely clever bots out there. But it's not like these are, you know, wild, artificial intelligences. They're no more artificially intelligent than the printing press. WESTERVELT: But in the last few years, Kaminsky says, he began to see exceptions to that. He helped take down what's been dubbed Methbot. Russian hackers using so-called bot farms created thousands of fake websites to dupe web marketers into buying millions of dollars worth of video ads. Companies thought thousands of real people had viewed these ads. In fact, they were bots designed to imitate real web surfers. It was one of the largest ad fraud attacks in the history of the web. Kaminsky says Methbot was new, a very scalable, sophisticated criminal operation and, in retrospect, something of a Russian-bot shot across the bow. KAMINSKY: Custom coding, custom engineering, custom operations - those were certainly well beyond, you know, your average 12-year-old in Poughkeepsie. And it tells you things about other similar attacks. WESTERVELT: Methbot was ad fraud. But Russian hackers used social bots in new, effective ways in the election. At the hearings on Capitol Hill, Clint Watts with the Foreign Policy Research Institute warns senators that the social bot problem will only get worse if tech giants don't take stronger collective action now. (SOUNDBITE OF ARCHIVED RECORDING) CLINT WATTS: They can create accounts that look like you and talk like you, which makes you more likely to believe it. The other thing is it can replicate a message so many times, the more times you see it the more likely you are to believe it. So it can actually create false worlds in the social media space. WESTERVELT: Research shows that many of the Russian social bots were programmed to direct tweets at users with lots of followers and influence. That helped make some false claims spread farther faster. Bot expert Sam Woolley is research director of the Digital Intelligence Lab. He says he heard too much in the hearings about Russian political ads and not enough about how tech companies might work together to combat social bots. SAM WOOLLEY: There are so many other mechanisms from group pages on Facebook to private rooms on Twitter that can be used to spread propaganda and misinformation. And we know we're used by the Russian government to do that. So we need to move the focus beyond just the political advertisements and toward the larger scale attacks that were going on. WESTERVELT: The tech firms insist they're taking adequate action. But the hackers, Woolley says, and their bot armies on the march are often one step ahead. Eric Westervelt, NPR News, San Francisco.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-11-05-561904209": {"title": "The Russia Investigations: D.C. Braces For More From Mueller; Ripple Effects Widen : NPR", "url": "https://www.npr.org/2017/11/05/561904209/the-russia-investigations-d-c-braces-for-more-from-mueller-ripple-effects-widen", "author": "No author found", "published_date": "2017-11-05", "content": "", "section": "National Security", "disclaimer": ""}, "2017-11-07-562619853": {"title": "What Happens When Artificial Intelligence Is Taught To See Like Humans : NPR", "url": "https://www.npr.org/2017/11/07/562619853/what-happens-when-artificial-intelligence-is-taught-to-see-like-humans", "author": "No author found", "published_date": "2017-11-07", "content": "ROBERT SIEGEL, HOST: When a website needs to make sure that you are really human, it might use a system known as CAPTCHA. KELLY MCEVERS, HOST: It's like a puzzle. On screen you see a series of squiggly numbers or letters, and you're asked to type those symbols out to let the owner of the website know you are not a robot. SIEGEL: If you are a robot, please stop listening to this story now. MCEVERS: The CAPTCHA system is based on the way our brains recognize different variations of a shape, like knowing that a cursive B is the same as a typed B. SIEGEL: We mention all this to tell you that recently we learned that the robots won. The artificial intelligence company Vicarious used technology it perfected to defeat one CAPTCHA system. They're trying to teach robots to see the way humans see. SCOTT PHOENIX: And to give them that skill, we need to design a visual system that works a lot like the human brain. SIEGEL: Scott Phoenix is co-founder of Vicarious. PHOENIX: And we humans are able to do tasks and recognize objects with only, you know, very few examples, sometimes just one example. And that's part of what gives us our super powers. MCEVERS: Before this, scientists had to feed thousands of examples into a machine to get it to understand what something looked like, even something as simple as a letter of the alphabet. SIEGEL: So if AI can figure out a puzzle only humans are supposed to crack, does this mean that websites will be more vulnerable to bots? Scott Phoenix says no. He says big tech firms think about a lot more than CAPTCHAS when they design security features for their sites. PHOENIX: What geographic location the IP address of the computer is coming from and what other websites it tends to visit. And is it acting like a human or is it acting like a robot? MCEVERS: And New York-based technology writer Charles Choi says the security fears stirred up by Vicarious' breakthrough actually miss the point. CHARLES CHOI: My view of technology like this isn't, like, oh, no, people are going to find a way to crack these things 'cause people are always going to find a way to crack these things. But it's more like, how much better can we make computers at acting human? SIEGEL: This does not mean the end of CAPTCHA as a security tool. The ones that ask us to pick similar sorts of objects out of an array of photos like cars or street signs - only humans can figure those out for now. (SOUNDBITE OF YPPAH'S \"GUMBALL MACHINE WEEKEND\") ROBERT SIEGEL, HOST:  When a website needs to make sure that you are really human, it might use a system known as CAPTCHA. KELLY MCEVERS, HOST:  It's like a puzzle. On screen you see a series of squiggly numbers or letters, and you're asked to type those symbols out to let the owner of the website know you are not a robot. SIEGEL: If you are a robot, please stop listening to this story now. MCEVERS: The CAPTCHA system is based on the way our brains recognize different variations of a shape, like knowing that a cursive B is the same as a typed B. SIEGEL: We mention all this to tell you that recently we learned that the robots won. The artificial intelligence company Vicarious used technology it perfected to defeat one CAPTCHA system. They're trying to teach robots to see the way humans see. SCOTT PHOENIX: And to give them that skill, we need to design a visual system that works a lot like the human brain. SIEGEL: Scott Phoenix is co-founder of Vicarious. PHOENIX: And we humans are able to do tasks and recognize objects with only, you know, very few examples, sometimes just one example. And that's part of what gives us our super powers. MCEVERS: Before this, scientists had to feed thousands of examples into a machine to get it to understand what something looked like, even something as simple as a letter of the alphabet. SIEGEL: So if AI can figure out a puzzle only humans are supposed to crack, does this mean that websites will be more vulnerable to bots? Scott Phoenix says no. He says big tech firms think about a lot more than CAPTCHAS when they design security features for their sites. PHOENIX: What geographic location the IP address of the computer is coming from and what other websites it tends to visit. And is it acting like a human or is it acting like a robot? MCEVERS: And New York-based technology writer Charles Choi says the security fears stirred up by Vicarious' breakthrough actually miss the point. CHARLES CHOI: My view of technology like this isn't, like, oh, no, people are going to find a way to crack these things 'cause people are always going to find a way to crack these things. But it's more like, how much better can we make computers at acting human? SIEGEL: This does not mean the end of CAPTCHA as a security tool. The ones that ask us to pick similar sorts of objects out of an array of photos like cars or street signs - only humans can figure those out for now. (SOUNDBITE OF YPPAH'S \"GUMBALL MACHINE WEEKEND\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-11-07-562619816": {"title": "How The World Of Private Investigation Has Changed : NPR", "url": "https://www.npr.org/2017/11/07/562619816/how-the-world-of-private-investigation-has-changed", "author": "No author found", "published_date": "2017-11-07", "content": "ROBERT SIEGEL, HOST: The latest bombshell story about Harvey Weinstein is all about big-time private investigators digging for dirt on his accusers. Ronan Farrow writes in The New Yorker about how Weinstein tried to prevent publication of stories about him, stories which have led to dozens of allegations of sexual harassment and, in some cases, rape. Farrow told NPR's Morning Edition today that Weinstein hired several international corporate intelligence firms. One of them called Black Cube describes itself as a select group of veterans from the Israeli elite intelligence units. Here's how Farrow described that operation. (SOUNDBITE OF ARCHIVED BROADCAST)RONAN FARROW: In Black Cube's case, that included human intelligence tactics targeting women, targeting journalists, showing up in their lives using fake identities, using fake companies as a front. This was detailed. This was aggressive. And according to the women I spoke to, this was terrifying. SIEGEL: We're going to talk now with Ronen Bergman, who is an Israeli journalist. He writes for the Israeli paper Yedioth Ahronoth as well as for The New York Times about intelligence. Welcome to the program. RONEN BERGMAN: Thank you so much, Robert, for inviting me. SIEGEL: And I should say you're speaking to us via Skype. Ronen Bergman, what do you know about this company Black Cube? BERGMAN: So Black Cube, as they indicated about themself, are indeed a company composed of veterans of Israeli intelligence including the Mossad but mainly from Israeli military intelligence called Aman. And they are experts with the various realms of intelligence, including SIGINT, hacking and, as we heard, human intelligence. SIEGEL: So their typical client would be someone in business and somebody presumably with a lot of money to spend. BERGMAN: A lot of money - people that are trying either to collect intelligence on specific targets, achieve all sorts of I would say, like, operations, spreading of information about someone and also trying to prevent information from being published or even trying to get down Internet sites or publications over the Internet that are harmful to their clients. SIEGEL: The story in The New Yorker relates an incident in which a woman who evidently works for Black Cube used a fake name, represented herself as working for a fake investment company. She claimed to be launching an initiative to combat discrimination against women in the workplace. And she tried to befriend an accuser of Weinstein's and was evidently gathering information about her for Weinstein, working through Weinstein's lawyer. Does that sound like this kind of work to you? And does it sound like a private investigator or more like an intelligence agent? BERGMAN: Well, it sounds like someone who works for Black Cube who comes with vast experience from Israeli intelligence, you know, the same sort of mindset and originality and experience that someone who served many, many years in Israeli intelligence and were doing all these operations on behalf of the Israeli state is now doing on behalf of a private company. SIEGEL: Sounds like a strange kind of business and that if they had, say, succeeded in intimidating women not to tell their stories to reporters about Harvey Weinstein or if they'd intimidated The New York Times and made them not publish a story about Harvey Weinstein, you can't exactly put it in the company brochure that, you know, we helped a leading movie producer squelch stories about his alleged sexual harassment of women. How do you brag about your accomplishments in this kind of work? BERGMAN: Well, Robert, I think that these kind of interviews and reports that The New Yorker has just published and the interview that we are conducting now - these are the best business development actions that these companies can take. The clients are seeing this as just another ample proof that companies like Black Cube - and again, I don't know about this incident, but companies at least like Black Cube are willing to do whatever possible - and they have the capability, the knowledge, paying very little attribution to the law - whatever possible for their clients. SIEGEL: Although in fairness, The New Yorker story is all about a job that didn't work. That is, the accusers of Harvey Weinstein ultimately did talk. And The New York Times did publish, and The New Yorker did publish. So you could say, well, they failed on that one. BERGMAN: Yeah. So it just proved that sometimes even the most trained, limitless people cannot stop a truthful, profound and deep investigative journalism. And this is just a good news. SIEGEL: That's Israeli journalist Ronen Bergman. Ronen, thanks for talking with us today. BERGMAN: Thank you so much, Robert. SIEGEL: And we asked Black Cube for comment, and their statement said the company operates in full compliance with the law. ROBERT SIEGEL, HOST:  The latest bombshell story about Harvey Weinstein is all about big-time private investigators digging for dirt on his accusers. Ronan Farrow writes in The New Yorker about how Weinstein tried to prevent publication of stories about him, stories which have led to dozens of allegations of sexual harassment and, in some cases, rape. Farrow told NPR's Morning Edition today that Weinstein hired several international corporate intelligence firms. One of them called Black Cube describes itself as a select group of veterans from the Israeli elite intelligence units. Here's how Farrow described that operation. (SOUNDBITE OF ARCHIVED BROADCAST) RONAN FARROW: In Black Cube's case, that included human intelligence tactics targeting women, targeting journalists, showing up in their lives using fake identities, using fake companies as a front. This was detailed. This was aggressive. And according to the women I spoke to, this was terrifying. SIEGEL: We're going to talk now with Ronen Bergman, who is an Israeli journalist. He writes for the Israeli paper Yedioth Ahronoth as well as for The New York Times about intelligence. Welcome to the program. RONEN BERGMAN: Thank you so much, Robert, for inviting me. SIEGEL: And I should say you're speaking to us via Skype. Ronen Bergman, what do you know about this company Black Cube? BERGMAN: So Black Cube, as they indicated about themself, are indeed a company composed of veterans of Israeli intelligence including the Mossad but mainly from Israeli military intelligence called Aman. And they are experts with the various realms of intelligence, including SIGINT, hacking and, as we heard, human intelligence. SIEGEL: So their typical client would be someone in business and somebody presumably with a lot of money to spend. BERGMAN: A lot of money - people that are trying either to collect intelligence on specific targets, achieve all sorts of I would say, like, operations, spreading of information about someone and also trying to prevent information from being published or even trying to get down Internet sites or publications over the Internet that are harmful to their clients. SIEGEL: The story in The New Yorker relates an incident in which a woman who evidently works for Black Cube used a fake name, represented herself as working for a fake investment company. She claimed to be launching an initiative to combat discrimination against women in the workplace. And she tried to befriend an accuser of Weinstein's and was evidently gathering information about her for Weinstein, working through Weinstein's lawyer. Does that sound like this kind of work to you? And does it sound like a private investigator or more like an intelligence agent? BERGMAN: Well, it sounds like someone who works for Black Cube who comes with vast experience from Israeli intelligence, you know, the same sort of mindset and originality and experience that someone who served many, many years in Israeli intelligence and were doing all these operations on behalf of the Israeli state is now doing on behalf of a private company. SIEGEL: Sounds like a strange kind of business and that if they had, say, succeeded in intimidating women not to tell their stories to reporters about Harvey Weinstein or if they'd intimidated The New York Times and made them not publish a story about Harvey Weinstein, you can't exactly put it in the company brochure that, you know, we helped a leading movie producer squelch stories about his alleged sexual harassment of women. How do you brag about your accomplishments in this kind of work? BERGMAN: Well, Robert, I think that these kind of interviews and reports that The New Yorker has just published and the interview that we are conducting now - these are the best business development actions that these companies can take. The clients are seeing this as just another ample proof that companies like Black Cube - and again, I don't know about this incident, but companies at least like Black Cube are willing to do whatever possible - and they have the capability, the knowledge, paying very little attribution to the law - whatever possible for their clients. SIEGEL: Although in fairness, The New Yorker story is all about a job that didn't work. That is, the accusers of Harvey Weinstein ultimately did talk. And The New York Times did publish, and The New Yorker did publish. So you could say, well, they failed on that one. BERGMAN: Yeah. So it just proved that sometimes even the most trained, limitless people cannot stop a truthful, profound and deep investigative journalism. And this is just a good news. SIEGEL: That's Israeli journalist Ronen Bergman. Ronen, thanks for talking with us today. BERGMAN: Thank you so much, Robert. SIEGEL: And we asked Black Cube for comment, and their statement said the company operates in full compliance with the law.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-11-09-563096836": {"title": "Texas Gunman's Locked Cellphone Renews Debate Over Encryption : NPR", "url": "https://www.npr.org/2017/11/09/563096836/texas-gunmans-locked-cellphone-renews-debate-over-encryption", "author": "No author found", "published_date": "2017-11-09", "content": "", "section": "Here & Now Compass", "disclaimer": ""}, "2017-11-09-563050434": {"title": "Once An Underground Currency, Bitcoin Emerges As 'A New Way To Track Information' : NPR", "url": "https://www.npr.org/2017/11/09/563050434/once-an-underground-currency-bitcoin-emerges-as-a-new-way-to-track-information", "author": "No author found", "published_date": "2017-11-09", "content": "TERRY GROSS, HOST: This is FRESH AIR. I'm Terry Gross. There's so much I have to learn each day in preparation for interviews that when I don't absolutely have to know something, I sometimes give myself permission not to learn about it. And that's been my attitude toward bitcoin until now. Or, to put it another way, when both Bjork and Microsoft are accepting bitcoin, it's time. So we're going to talk about what bitcoin is and how it's used in the underground and legit marketplaces, how it's become a vehicle for investors and how big banks are starting to copy it. My guest, Nathaniel Popper, is a technology reporter for The New York Times who's been covering digital currency. A couple of years ago he wrote a book about bitcoin called \"Digital Gold. \" Nathaniel Popper, welcome to FRESH AIR. So for those of us who have never used bitcoin and don't really understand how it works, you tell me, why should we care? NATHANIEL POPPER: Well, I think that there are a number of layers on which this bitcoin thing is interesting. I mean, on the most sort of immediate level, people are using bitcoin in really interesting ways. I think people are using it as a sort of black market currency to buy drugs and make ransom payments, and it is allowing for essentially new types of crime. But I think it also is pointing in the direction of where money might be going, and I think it tells us something about what money is. And then, you know, to zoom out even more broadly, I think it's really interesting because it's not just a new kind of software or a new kind of money. It is essentially a social movement. You know, it has taken off because it has won-over thousands, tens of thousands, millions of people around the world. And I think it's really interesting to think about what it is about this thing that has been so interesting to people. GROSS: So just give us a sense of the scope. Like, how much money is invested in bitcoin now? POPPER: Well, if you were to buy all of the bitcoin out in the world right now at the price this week, you would pay something like $120 billion. So that's the sort of simple way of thinking about the size of the bitcoin economy. That is, just for comparison's sake, larger than the value of Goldman Sachs or Morgan Stanley, larger than the value of PayPal. So that value is stored in something like 17 million bitcoins that are distributed around the world. GROSS: OK. So what is a bitcoin? POPPER: Well, to start with, and I think the thing that probably most people are aware of, it's essentially a digital token that you can buy and sell. But I think one of the reasons bitcoin has remained so confusing to people is that it's that digital token but then it's also the network on which it lives. And it's it's really the network that makes it so different. And so we refer to bitcoin, we refer to that network as essentially the bitcoin network. And it's something more like the internet. It's a decentralized network of computers around the world where all of these bitcoin live. GROSS: So was it created to solve certain problems with money as we know it? POPPER: Yes. I mean, this idea when it first emerged in late 2008, actually on Halloween of 2008, was the culmination of really decades of work among a sort of small group of computer scientists and activists who were worried about - their biggest concern was around privacy. They were really worried that, you know, in the existing system when money became digital. So when we started to be able to move money around on computers with credit cards, every transaction that you made was tracked and could later be monitored by the government or by big companies. And so, you know, a big part of the work that went into this was to essentially create an anonymous digital cash. And so that was one strain of thinking that went into this. But the other big strain when this came out was that this was essentially two months after Lehman Brothers went bankrupt. So right in the heart of the financial crisis. And there was a lot of distrust of both Wall Street and the big banks, but also of central banks. And here this was introduced as a new form of money that could exist independent of all of these institutions that people were so skeptical of. GROSS: So the people who created bitcoin, 'cause it grew out of a movement, wanted privacy. But I'm not sure exactly where the line is between privacy and secrecy, but there's been a lot of secrecy surrounding the use of bitcoin because the first place it really took off was the underground market, like, on the dark web, the black markets on the dark web selling drugs and sex, right? POPPER: Right. For sure. I mean, the line between privacy and secrecy is always very, very fuzzy, and I think that a lot of the technologies that are out there to provide privacy are also sort of abused on the other side from people wanting to do things that they don't want the government to be watching. And so yes, I mean, bitcoin sort of came out of this idealistic impulse. And, you know, after it was announced by the creator of bitcoin, this character known as Satoshi Nakamoto, it sort of stumbled along for two years, and, you know, you could send bitcoin around, but they really weren't worth anything at that point. And it really kind of gained its first reason for being with the creation of the Silk Road, which was this, you know, online black market sort of eBay where you could buy drugs. And the Silk Road, the creator of the Silk Road realized that bitcoin made this possible for the first time. It was, frankly, quite hard to buy drugs online before this because if you did, the police would just go ask PayPal or Visa, you know, who had sent this money to buy this baggie of heroin or marijuana, and PayPal would give those records over and the person would get arrested. With bitcoin, you could send that money and nobody would know where the money came from, and that sort of gave rise to this whole new online market. GROSS: And it's the same phenomenon with ransomware, when somebody's computer is basically being held hostage by malware, and the only way to get access to your computer back is to pay the designated amount of ransom money in bitcoin. But, of course, experts warn that even if you pay it, you might not necessarily get access to your computer again. But - so that's something that's caught on. POPPER: Yeah. I mean, that's been a big thing that's risen up in the last two years, and. . . GROSS: And I should say that applies not just to individual computers, but also to, like, whole networks and to hospitals and, you know, around the globe. POPPER: Yeah. I mean, it's created enormous problems for companies, for governments. You've seen, yeah, hospitals that have had to just go back to analog recordkeeping for weeks. I think it was the San Francisco Chronicle, or maybe it was a radio station here that basically had to stop using computers because their computers were all frozen by a ransomware attack. And ransomware was really something that existed before bitcoin. But, you know, in tech speak, it didn't scale without bitcoin. Before, somebody would have to go get a money order and send it around the world physically. That's not an easy thing to do. With bitcoin, you can now send, you know, $500 to the captor of your files in the Ukraine or Russia, and the transaction is done in 20 minutes. And, you know, that is possible because of this new way that bitcoin works, which, you know, the first sort of real-world uses of that have not been altogether positive ones for the world, I think. GROSS: In terms of the dark web and the illegal, you know, the markets for illegal goods on the dark web that you have to pay for with bitcoin, some of those sites have been shut down, including Silk Road, the one that you mentioned, and more legit uses of bitcoin are emerging now. So what are some examples of that? POPPER: Well, the idealism that fueled bitcoin at the beginning, the place where you've seen that playing out is in countries where people have their money trapped or are losing money because the local currency is, you know, is experiencing hyper inflation and so people are losing all of their savings and looking somewhere outside of the government's control to put money. And so you've seen that in countries like Venezuela and Argentina. You even hear about it in Zimbabwe. You know, in those places, people have always clamored to exchange their local currency for dollars because dollars were so much more reliable, but there was, you know, a real shortage of dollars. And when you got the dollars, you frequently had to sort of put them under your mattress, which wasn't terribly secure. You know, the vision with bitcoin is that in those sorts of places, you can now trade your local currency for bitcoin and have a somewhat more stable place to keep your money then, you know, the bolivar or the Argentine peso. So that's sort of, I think, one place where people like to talk about - talk up, bitcoin aficionados like to talk up. I mean, it's also very easy to sort of move money around the globe so, you know, it takes a long time right now to make a sort of pretty basic bank transfer to India, to China. You know, that can take weeks and, you know, require sort of fees at every step along the way. The idea with bitcoin is, you know, you can send it right now and it's there in essentially 10 minutes. And the person can log in and they don't have to get approval from anybody. You know, that's particularly attractive in countries where it's hard for people to get bank accounts and where, you know, places like India, again, or Africa, where people are sort of locked out of the online economy because they can't get a credit card, they can't get a debit card. You know, they can't sign up for Netflix. Now you can sign up for Netflix very easily in India or Africa, even if you don't have a credit card, thanks to bitcoin. GROSS: We need to take a short break here so let me reintroduce you. If you're just joining us, my guest is Nathaniel Popper, and we're talking about bitcoin. He's been writing about digital currency for several years. He's a tech reporter at The New York Times, and a couple of years ago, he wrote a book about bitcoin called \"Digital Gold. \" We'll be right back. This is FRESH AIR. (SOUNDBITE OF MUSIC)GROSS: This is FRESH AIR, and if you're just joining us, we're talking about bitcoin and other digital currencies. And my guest, Nathaniel Popper, has been writing about bitcoin for several years. He's a tech reporter for The New York Times and the author of a book about bitcoin called \"Digital Gold. \" So I'm not sure we know who invented money, but we do know who invented bitcoin. Except we don't know because. . . POPPER: (Laughter). GROSS: (Laughter) Because. . . POPPER: That's a good way of putting it. GROSS: Yeah. It's a pseudonym. He never really revealed who he was. Even you, who have been covering this for years, don't know who he is. POPPER: Right. GROSS: I'm sorry. Yeah. I don't even know it's a he, right? POPPER: I was going to say that. So people frequently say he, she, they or it in case it is a sort of autonomous, you know, being that created this of some sort. But, you know, what we do know is that the person who first introduced this back in 2008 and then released the first software a few months later went by the name of Satoshi Nakamoto and communicated essentially only by email, would get on sort of chats and sort of social media forums, but always under that Satoshi Nakamoto pseudonym. And a few years into bitcoin's existence, right as it was beginning to take off, Satoshi essentially signed off and disappeared, you know, sent the last email, gave control of the system over to the people who had been drawn to it and were, you know, working on the software at that point. And since then there's been a sort of manhunt for, you know, to discover the true identity of Satoshi Nakamoto. And a bunch of names have been floated over time. I wrote a story when my book came out about the person who - one of the people who was widely viewed as the most likely candidate. But all of the people who have been, you know, fingered as potential Satoshi Nakamotos have denied essentially that they are, except for, I should say, one person who claimed to be Satoshi Nakamoto and won over a certain number of people. This got a lot of news, I think, maybe a year or two back, this guy named Craig Wright from Australia who claimed that he was Satoshi. But as people looked into it and looked into the sort of electronic records - it was quite a chase - I think most people concluded that this was not in fact Satoshi Nakamoto. GROSS: So when Satoshi Nakamoto, whoever that is, started bitcoin, he or she issued something between, like, guidelines and a manifesto. Like, a nine-page document. Can you sum up, for those of us who don't really understand this (laughter), the principles that were laid out in those nine pages? POPPER: Sure. Yeah, so this was the original. It's called Satoshi's White Paper. You know, it has this sort of iconic status, this nine-page PDF that was released in early - in late 2008. And it sort of described how this system was going to work. And it said it would be a sort of electronic cache, and there were going to be certain rules that would govern this electronic cache. There would only ever be 21 million bitcoins created. That rule was sort of stated there at the beginning. And that was created so that it would have a sort of scarcity like gold and - which might lead people to think there was going to be a value in it. If there wasn't going to be an unlimited number of them, that might confer a certain value on bitcoin, which it has ended up doing. So that was one rule. The other rules were about how Bitcoin would be distributed. It's not - there wasn't going to be a bank of bitcoin that would distribute them to everybody. They were going to be sort of slowly dripped out over time to people who joined the network. And I think that's the most important thing about the rules around bitcoin was that it was going to be a network of computers, sort of like the Internet, that anybody could join and anybody could support this. And that would allow for bitcoin to exist independent of any sort of central source of authority. There wasn't going to be a government here. There wasn't going to be a company. There was going to be this network of computers that was supporting it, and that means that anybody can join that network and send money to anybody else. And so those were sort of the basic rules that were laid down. And I should say that in the first months after this was proposed, this was not a rousing success. There were, you know, a handful of people, you know, maybe eight people who responded to this idea. Most of whom thought that there was no way that it could work. GROSS: Well, for this to work, it really requires a level of faith. When you're talking about, say, dollars, it's backed up by the U. S. government. And if you have money in a bank, a certain amount of it is backed up by the FDIC. You know, if you invest in the stock market, it's going to fluctuate, but you have shares in something whereas with bitcoin it just seems like an act of faith in bitcoin. POPPER: Well, you are certainly right. I should note I think that, you know, all of those instances you just mentioned - the U. S. dollar is backed up by the U. S. government, by the FDIC - that's true. I mean, if you kind of dig a little deeper, you know, what you're expressing faith in when you express faith in the dollar is essentially the U. S. government and the FDIC. You're believing that those are going to be around. And obviously, that's not maybe a hard thing to believe in, but there's some chance that it won't happen. And certainly there are countries where the government has issued currency and then the government has fallen and the currency has turned out to be worthless. So to a degree, money is always about faith. It's about believing that the thing you're holding in your hand is going to be worth something tomorrow, next week, in a month and that somebody will take it and give you something in exchange. The same is true with bitcoin. And certainly, there are not the institutions backing it up that you have for the U. S. dollar or for stocks. But what is backing it up is this network. And so you in essence are sort of expressing your faith in that network and the power of the network and the power of the rules behind bitcoin to draw people to this currency and to make people think that the network, you know, may outlive the U. S. government. I wouldn't argue that myself. I don't know the odds. I would say probably the odds of the U. S. government outlasting the bitcoin network are good. But I think that a lot of people have - had assumed that bitcoin - that the bitcoin network wouldn't survive to, you know, through the first year, much less the first eight years, which it's done. And it's sort of continued to kind of engender this faith among the people who believe in it, who follow it. GROSS: My guest is Nathaniel Popper, a tech reporter for The New York Times and the author of a book about bitcoin called \"Digital Gold. \" After we take a short break, we'll talk more about how the bitcoin system works and how bitcoin are created by huge server farms competing against each other. And David Edelstein will review the new movie \"Three Billboards Outside Ebbing, Missouri\" starring Frances McDormand. I'm Terry Gross, and this is FRESH AIR. (SOUNDBITE OF MUSIC)GROSS: This is FRESH AIR. I'm Terry Gross. We're talking about bitcoin, the digital currency that was created in 2008. Although its roots were in idealism and libertarianism, it first became widely used for purchases on the dark web, the sites on the Internet black market selling drugs and sex. But this digital currency is now being used for more mainstream purchases. Big banks are starting to find uses for some of the innovative structure of the bitcoin system. My guest, Nathaniel Popper, is a tech reporter for The New York Times. A couple of years ago, he wrote a book about bitcoin called \"Digital Gold. \"So when bitcoin was first released into the world, it was determined by the person who released it, who goes by the name Satoshi Nakamoto, he or she determined how much bitcoin there would be in this world. There's a finite amount of bitcoin that will ever be released to make sure that, like gold, it retains its value. So it's a kind of complicated process how bitcoin is created or mined. Mined is the word that's used. New bitcoin is mined. So would you just tell us a little bit, like, in a comprehensive way about how new bitcoin is mined? POPPER: It's a dangerous question, and it's a hard one to answer simply, but, you know, the answer to how bitcoin are created does sort of give you some glimpse into the inner workings of how this thing functions and why it has survived as long as it has. I mean, essentially, bitcoin released onto the network every 10 minutes. A new block of bitcoin is released onto the network every 10 minutes. And this started on the very first day. On the very first day, there was zero bitcoin in the world. And after 10 minutes - after about 10 minutes, 50 bitcoin were released to one of the computers that was hooked into the network, which at that point was Satoshi Nakamoto's computers. They were almost the only computers that were hooked in at that point. But the rules of bitcoin - the software determine how those bitcoins, those new bitcoins being released, are going to be distributed to people. And the first thing that this does is that it encourages people to join the network. You can essentially - at least early on, you could essentially get free bitcoin if you joined the network. And so it incentivized people to join the network. The other thing it did was that it got those computers to start keeping the records for the network. So if you want to win those bitcoins, essentially you have to start working as an accountant for the network and registering all the new transactions that come in. And if you are doing that - the more computers you add to help, you know, serve as accountant for the network, the better chance you have of winning bitcoins. And so that is how sort of the records are kept, and that's how you get people to volunteer to keep the records. You give them new bitcoins. You offer these new bitcoins. So over time, that incentive system has generated this enormous network. Right now, there's something like 13,000 nodes or computers hooked into the network that are helping to keep these records. And a lot of those are mining, trying to win these new bitcoins. And so this complicated economic system was set up with lots of incentives in there to get people to participate and to sort of create the foundation for this decentralized network to keep all the records. GROSS: So you can't just say, well, I want to create new bitcoin. It's a kind of interesting process. You're basically competing with other people who also want to create new bitcoin. So what do you have? Do you have, like, a lot of computers competing with each other? And what's the competition? Like, what are the. . . POPPER: Yeah. GROSS: Who decides who wins? POPPER: You know, we're slipping down the rabbit hole here and I. . . GROSS: Yeah, that's what I was afraid of, but. . . POPPER: Let's make sure not to go. . . GROSS: Yeah. POPPER: Let's make sure not to go too deep data because it's based on cryptography and encryption, which is sort of the leading edge of math, you know, basically really hard math problems you have to solve. But at the most basic, computers are trying to process all the transactions coming into the bitcoin network as quickly as possible. And the faster you do it, the more efficiently you do it, the better chance you have of winning bitcoin. There's an element of luck in it. It's somewhat like a lottery, but essentially the person with the most computing power has the best chance of winning the lottery. And so what's that - what that's created today is a world in which you have literally server farms in outer - inner Mongolia, in Tibet, in Iceland. Anywhere where you can get cheap electricity to run computers very fast, people have set up basically server farms, big, you know, buildings just filled with computers trying to sort of unlock these new bitcoins but also sort of serving as the backbone of this network. And, you know, the more computers you have joined in, the more secure the network is, the harder it is to attack. And it's this crazy world in which - I mean, literally in China, which has become one of the most, you know, one of the places where you have the most bitcoin mining, you know, spread all around China, you have next to - you know, next to hydroelectric dams and next to a coal plants, people have set up these server farms that are dedicated to doing nothing but mining bitcoin. GROSS: I know you visited a server farm in Iceland. Did you go to one in China, too? POPPER: I went a couple years ago to one in China. They have gotten a lot bigger and more sophisticated since then. I mean, there are literally sort of towns that are built around this in China where you have people just living in the bitcoin mining facility, you know, Chinese people who really - you know, the people who are working there are sort of the custodians. They - most of them have no idea really what's going on or how the system works. But it's - you know, it's created this whole economy. GROSS: So bitcoin is being used as an investment vehicle in the U. S. It's being used for investing, in speculation. How is that playing out here? POPPER: Well, very well for the people who bought it early on. I mean, a bitcoin this week is worth something like $7,500. You know, a year ago, it was worth less than $1,000. And that has attracted a whole bunch of new people to this. It's attracted people around the world. Here, what you've seen is a lot of hedge funds getting into this game. So there are now hedge funds being set up. Something like 100 hedge funds in the last year have been set up to invest exclusively in virtual currencies, bitcoin as well as some of the competitors that have sprung up. GROSS: Wow. Well, say this is a bubble, what happens (laughter)? I mean, like, the price of bitcoin has been shooting straight up, but things that go up sometimes come back down. POPPER: Yes. I mean, if you look at the chart of the bitcoin price since it was born, it is just a series of spikes and then drops, and then spikes and then drops. And over time, you know, you get the spike, and it drops down to a level that is generally still higher than where it was before the spike, but lower than the spike. And so I think a lot of people are asking right now how long this can go on. And certainly, you've heard numerous CEOs of banks say, this is unsustainable; this is a bubble; this is going to crash. And I think there's no doubt that there probably is going to be some reckoning here. I mean, this meets many of the definitions of a bubble. People are speculating on the future value and desire for bitcoin. People are speculating that this will serve more purposes in the future and will be more valuable to more people in the future than it is today. And they're betting - a lot of people are just betting that the price is going to go up without knowing anything about it. And those are a lot of the characteristics that you see in bubbles. I mean, you know, the counterargument is that this is the first time that we've had a scarce digital resource. So I - the Internet, until now - most things on the Internet, you can copy and paste, right? That's what the music industry found. You can copy and paste an MP3. You can copy and paste a movie file. Things aren't scarce on the Internet, and one of the things that bitcoin did through this weird, complicated system of incentives is, it created a scarce digital asset for the first time. So a lot of people think about this now as something like digital gold. You know, this is a place where you can keep your money because there's only going to be so many of them, and the system works, and it's in some ways better than gold because, you know, gold, you can't carry across a border secretly. You can't - you can try to stuff it in your underwear. But, you know, gold, people can - it's hard to travel with gold. Bitcoin - as long as you have that password, you can go somewhere else with internet access and you have access to your money. So that's the sort of thesis on this. But I think that the sort of expectations and the types of people who are getting into this right now, a lot of them are not terribly sophisticated. GROSS: So of the maximum 21 million bitcoin that can be released by - what were - year was it, 2040? POPPER: 2140, yeah. GROSS: 2140, right - oh, 21 - wow, 2140. POPPER: We got a while. GROSS: Wow. POPPER: We're talking about a distant future. GROSS: I'm hearing, like, 2040. That's, like - that's so far away. POPPER: It is. GROSS: OK, so how many bitcoin have already been released? POPPER: We're getting close to 17 million. So the reward to people who are helping to support the network falls in half every four years. So initially, it was 50, and then 25 and now we're down to 12 1/2, and it'll sort of keep going down like that until it approaches zero. And I think, obviously, part of the idea is, they will be worth more, so the 12 1/2 that are released now are actually worth a lot more than the 25 that you were getting a year ago. GROSS: OK, it's time for a short break. Let me reintroduce you. My guest is Nathaniel Popper. We're talking about bitcoin, and he's been writing about bitcoin for several years. He's a tech reporter for The New York Times who wrote a book a couple of years ago about bitcoin called \"Digital Gold. \" Back after this short break - this is FRESH AIR. (SOUNDBITE OF JAY-Z SONG, \"DECEMBER 4TH\")GROSS: This is FRESH AIR. And if you're just joining us, my guest is Nathaniel Popper. He's a tech reporter at The New York Times. And we're talking about bitcoin - digital currency - and he's been covering bitcoin for several years. A couple of years ago, he wrote a book about it called \"Digital Gold. \"So, you know, whether you use bitcoin or not, whether you think it's going to last or not, the architecture of the system seems pretty ingenious. And there are major banks and even the New York Stock Exchange, you know, that are picking up on some of the architecture to borrow it for their own purposes, and what they're borrowing from is what's called the blockchain. Would you explain what that is and how, like, major banks are trying to borrow that system? POPPER: Sure. Well, I think the blockchain, in the simplest sense, is the record of all the bitcoin transactions. It's a ledger, a sort of a spreadsheet on which bitcoin transactions are recorded. But what's special about the bitcoin ledger - the bitcoin blockchain - is that it's not kept by a central institution. It's kept by a bunch of people, and part of the idea is that it's a bunch of people who don't trust each other but can use this system to have a sort of shared record of their assets. And so this blockchain idea, this idea of keeping records in a decentralized way so that anybody can consult it and that nobody is in charge - that idea of the blockchain is something that's piqued a lot of interest in the financial industry but also in a whole bunch of other industries. IBM has made this one of their biggest pushes over the last few years to kind of try to regain relevance. They have made a big move into the blockchain industry, as has Microsoft. And they're essentially making a bet that this is a new way to track information. And, you know, we live in an information economy, and so if you can come up with new ways to track and store information more reliably, it has the potential to recreate some of the foundations of the information economy. It really sounds rather vague. You know, when you just look at something like the financial industry, the banks are looking at this as, you know - maybe instead of paying the New York Stock Exchange to buy and sell stocks there, and then transfer the money for us, and move the stocks back and forth and make sure all the records are kept, maybe we - all the banks - we can just set up a blockchain where we can all trade, and we don't have to pay anybody in the middle, and we can keep track of all those records, and all of us can do it without trusting any of the other people in the system. And that's the sort of basic idea that I think has given rise to this whole new industry. GROSS: So you're not allowed to invest in bitcoin because you cover it for The New York Times. Are you allowed to use it, and have you used it? POPPER: Yes. I mean, our take at The New York Times has basically been, I can have enough to play with and understand it. And I think the understanding has generally been that, you know, those bitcoins essentially belong to The New York Times so that I don't get any big ideas. But yeah, I mean, I'm in there on a daily basis trying to understand how these things work, how you move between different currencies, how it can move around the world. And that's been an important part of reporting on this. GROSS: So if you want to get bitcoin to make purchases, how do you get it? POPPER: Well, companies - not surprisingly, companies have sprung up to make this very easy for you to take your money and give you bitcoin. You know, there's - probably the biggest company in the United States is a company called Coinbase, which is essentially a sort of Charles Schwab or an E-Trade for bitcoin. You send them money, and then you can trade on their platform. You can move in and out of bitcoin. And then you can take your money out and transfer it back to your bank. And they've made it very easy so that anybody - you know, so it's as easy as - probably easier than buying a stock is through E-Trade. And part of what's interesting there - I guess that's not too surprising. What's interesting is that the government and regulators have essentially allowed this to happen, have said, this is OK. New York - state of New York has created a BitLicense that Coinbase has, and that makes it easier for them to do this and easier to get bank accounts. And so at least in the United States, the government has sort of said, we're going to let this happen; we realize there might be something of value here, so we're not going to try to kill this. GROSS: Have you had any great bitcoin adventures in researching your book or writing for The New York Times that you could share for - share with us? POPPER: I mean, this whole thing has been such an incredible story. I mean, that's why I was drawn to it. I mean, the number of people who have gone to jail - often shortly after getting fabulously wealthy - is incredible. And so a lot of the stories I talk - tell in my book are these stories of these astronomic rises followed by these incredible falls. And oftentimes, I was there. You know, I - you know, one of the main characters in my book, I met him in this bar that he had essentially bought a piece of using bitcoin and where he would have these bitcoin parties, where he met his girlfriend. You know, they took bitcoin for - the waiters and waitresses took bitcoin. And he was on top of the world. He had just come back from Argentina. He was traveling around. A week later, he got stopped at the airport by the police, went to trial, ended up in jail. And, you know, I was talking to him at every stage along the way. And I've had that experience in so many different realms - you know, in Iceland, in China, in Argentina. And just to see the way that this technology has created these little universes of - it's only - they're like little science fiction cells where these people are imagining these new futures, and, you know, in each place - in China, Argentina, everywhere you go - it has evolved in different ways. And so just to see the way that this software, you know, it - that this piece of program that this anonymous person wrote - the way it can sprout up and create all these things in the real world - you know, going to these gorges in China where there are now people just living in these enormous industrial sites, working on this - it's - that's, I think, what's been the most incredible to see. GROSS: Well, Nathaniel Popper, I want to thank you so much for talking with us. POPPER: Thank you so much for having me. GROSS: Nathaniel Popper is a tech reporter for The New York Times and the author of a book about bitcoin called \"Digital Gold. \" After we take a short break, David Edelstein will review the new movie \"Three Billboards Outside Ebbing, Missouri. \" This is FRESH AIR. (SOUNDBITE OF JUSTIN HURWITZ'S \"SURPRISE\") TERRY GROSS, HOST:  This is FRESH AIR. I'm Terry Gross. There's so much I have to learn each day in preparation for interviews that when I don't absolutely have to know something, I sometimes give myself permission not to learn about it. And that's been my attitude toward bitcoin until now. Or, to put it another way, when both Bjork and Microsoft are accepting bitcoin, it's time. So we're going to talk about what bitcoin is and how it's used in the underground and legit marketplaces, how it's become a vehicle for investors and how big banks are starting to copy it. My guest, Nathaniel Popper, is a technology reporter for The New York Times who's been covering digital currency. A couple of years ago he wrote a book about bitcoin called \"Digital Gold. \" Nathaniel Popper, welcome to FRESH AIR. So for those of us who have never used bitcoin and don't really understand how it works, you tell me, why should we care? NATHANIEL POPPER: Well, I think that there are a number of layers on which this bitcoin thing is interesting. I mean, on the most sort of immediate level, people are using bitcoin in really interesting ways. I think people are using it as a sort of black market currency to buy drugs and make ransom payments, and it is allowing for essentially new types of crime. But I think it also is pointing in the direction of where money might be going, and I think it tells us something about what money is. And then, you know, to zoom out even more broadly, I think it's really interesting because it's not just a new kind of software or a new kind of money. It is essentially a social movement. You know, it has taken off because it has won-over thousands, tens of thousands, millions of people around the world. And I think it's really interesting to think about what it is about this thing that has been so interesting to people. GROSS: So just give us a sense of the scope. Like, how much money is invested in bitcoin now? POPPER: Well, if you were to buy all of the bitcoin out in the world right now at the price this week, you would pay something like $120 billion. So that's the sort of simple way of thinking about the size of the bitcoin economy. That is, just for comparison's sake, larger than the value of Goldman Sachs or Morgan Stanley, larger than the value of PayPal. So that value is stored in something like 17 million bitcoins that are distributed around the world. GROSS: OK. So what is a bitcoin? POPPER: Well, to start with, and I think the thing that probably most people are aware of, it's essentially a digital token that you can buy and sell. But I think one of the reasons bitcoin has remained so confusing to people is that it's that digital token but then it's also the network on which it lives. And it's it's really the network that makes it so different. And so we refer to bitcoin, we refer to that network as essentially the bitcoin network. And it's something more like the internet. It's a decentralized network of computers around the world where all of these bitcoin live. GROSS: So was it created to solve certain problems with money as we know it? POPPER: Yes. I mean, this idea when it first emerged in late 2008, actually on Halloween of 2008, was the culmination of really decades of work among a sort of small group of computer scientists and activists who were worried about - their biggest concern was around privacy. They were really worried that, you know, in the existing system when money became digital. So when we started to be able to move money around on computers with credit cards, every transaction that you made was tracked and could later be monitored by the government or by big companies. And so, you know, a big part of the work that went into this was to essentially create an anonymous digital cash. And so that was one strain of thinking that went into this. But the other big strain when this came out was that this was essentially two months after Lehman Brothers went bankrupt. So right in the heart of the financial crisis. And there was a lot of distrust of both Wall Street and the big banks, but also of central banks. And here this was introduced as a new form of money that could exist independent of all of these institutions that people were so skeptical of. GROSS: So the people who created bitcoin, 'cause it grew out of a movement, wanted privacy. But I'm not sure exactly where the line is between privacy and secrecy, but there's been a lot of secrecy surrounding the use of bitcoin because the first place it really took off was the underground market, like, on the dark web, the black markets on the dark web selling drugs and sex, right? POPPER: Right. For sure. I mean, the line between privacy and secrecy is always very, very fuzzy, and I think that a lot of the technologies that are out there to provide privacy are also sort of abused on the other side from people wanting to do things that they don't want the government to be watching. And so yes, I mean, bitcoin sort of came out of this idealistic impulse. And, you know, after it was announced by the creator of bitcoin, this character known as Satoshi Nakamoto, it sort of stumbled along for two years, and, you know, you could send bitcoin around, but they really weren't worth anything at that point. And it really kind of gained its first reason for being with the creation of the Silk Road, which was this, you know, online black market sort of eBay where you could buy drugs. And the Silk Road, the creator of the Silk Road realized that bitcoin made this possible for the first time. It was, frankly, quite hard to buy drugs online before this because if you did, the police would just go ask PayPal or Visa, you know, who had sent this money to buy this baggie of heroin or marijuana, and PayPal would give those records over and the person would get arrested. With bitcoin, you could send that money and nobody would know where the money came from, and that sort of gave rise to this whole new online market. GROSS: And it's the same phenomenon with ransomware, when somebody's computer is basically being held hostage by malware, and the only way to get access to your computer back is to pay the designated amount of ransom money in bitcoin. But, of course, experts warn that even if you pay it, you might not necessarily get access to your computer again. But - so that's something that's caught on. POPPER: Yeah. I mean, that's been a big thing that's risen up in the last two years, and. . . GROSS: And I should say that applies not just to individual computers, but also to, like, whole networks and to hospitals and, you know, around the globe. POPPER: Yeah. I mean, it's created enormous problems for companies, for governments. You've seen, yeah, hospitals that have had to just go back to analog recordkeeping for weeks. I think it was the San Francisco Chronicle, or maybe it was a radio station here that basically had to stop using computers because their computers were all frozen by a ransomware attack. And ransomware was really something that existed before bitcoin. But, you know, in tech speak, it didn't scale without bitcoin. Before, somebody would have to go get a money order and send it around the world physically. That's not an easy thing to do. With bitcoin, you can now send, you know, $500 to the captor of your files in the Ukraine or Russia, and the transaction is done in 20 minutes. And, you know, that is possible because of this new way that bitcoin works, which, you know, the first sort of real-world uses of that have not been altogether positive ones for the world, I think. GROSS: In terms of the dark web and the illegal, you know, the markets for illegal goods on the dark web that you have to pay for with bitcoin, some of those sites have been shut down, including Silk Road, the one that you mentioned, and more legit uses of bitcoin are emerging now. So what are some examples of that? POPPER: Well, the idealism that fueled bitcoin at the beginning, the place where you've seen that playing out is in countries where people have their money trapped or are losing money because the local currency is, you know, is experiencing hyper inflation and so people are losing all of their savings and looking somewhere outside of the government's control to put money. And so you've seen that in countries like Venezuela and Argentina. You even hear about it in Zimbabwe. You know, in those places, people have always clamored to exchange their local currency for dollars because dollars were so much more reliable, but there was, you know, a real shortage of dollars. And when you got the dollars, you frequently had to sort of put them under your mattress, which wasn't terribly secure. You know, the vision with bitcoin is that in those sorts of places, you can now trade your local currency for bitcoin and have a somewhat more stable place to keep your money then, you know, the bolivar or the Argentine peso. So that's sort of, I think, one place where people like to talk about - talk up, bitcoin aficionados like to talk up. I mean, it's also very easy to sort of move money around the globe so, you know, it takes a long time right now to make a sort of pretty basic bank transfer to India, to China. You know, that can take weeks and, you know, require sort of fees at every step along the way. The idea with bitcoin is, you know, you can send it right now and it's there in essentially 10 minutes. And the person can log in and they don't have to get approval from anybody. You know, that's particularly attractive in countries where it's hard for people to get bank accounts and where, you know, places like India, again, or Africa, where people are sort of locked out of the online economy because they can't get a credit card, they can't get a debit card. You know, they can't sign up for Netflix. Now you can sign up for Netflix very easily in India or Africa, even if you don't have a credit card, thanks to bitcoin. GROSS: We need to take a short break here so let me reintroduce you. If you're just joining us, my guest is Nathaniel Popper, and we're talking about bitcoin. He's been writing about digital currency for several years. He's a tech reporter at The New York Times, and a couple of years ago, he wrote a book about bitcoin called \"Digital Gold. \" We'll be right back. This is FRESH AIR. (SOUNDBITE OF MUSIC) GROSS: This is FRESH AIR, and if you're just joining us, we're talking about bitcoin and other digital currencies. And my guest, Nathaniel Popper, has been writing about bitcoin for several years. He's a tech reporter for The New York Times and the author of a book about bitcoin called \"Digital Gold. \" So I'm not sure we know who invented money, but we do know who invented bitcoin. Except we don't know because. . . POPPER: (Laughter). GROSS: (Laughter) Because. . . POPPER: That's a good way of putting it. GROSS: Yeah. It's a pseudonym. He never really revealed who he was. Even you, who have been covering this for years, don't know who he is. POPPER: Right. GROSS: I'm sorry. Yeah. I don't even know it's a he, right? POPPER: I was going to say that. So people frequently say he, she, they or it in case it is a sort of autonomous, you know, being that created this of some sort. But, you know, what we do know is that the person who first introduced this back in 2008 and then released the first software a few months later went by the name of Satoshi Nakamoto and communicated essentially only by email, would get on sort of chats and sort of social media forums, but always under that Satoshi Nakamoto pseudonym. And a few years into bitcoin's existence, right as it was beginning to take off, Satoshi essentially signed off and disappeared, you know, sent the last email, gave control of the system over to the people who had been drawn to it and were, you know, working on the software at that point. And since then there's been a sort of manhunt for, you know, to discover the true identity of Satoshi Nakamoto. And a bunch of names have been floated over time. I wrote a story when my book came out about the person who - one of the people who was widely viewed as the most likely candidate. But all of the people who have been, you know, fingered as potential Satoshi Nakamotos have denied essentially that they are, except for, I should say, one person who claimed to be Satoshi Nakamoto and won over a certain number of people. This got a lot of news, I think, maybe a year or two back, this guy named Craig Wright from Australia who claimed that he was Satoshi. But as people looked into it and looked into the sort of electronic records - it was quite a chase - I think most people concluded that this was not in fact Satoshi Nakamoto. GROSS: So when Satoshi Nakamoto, whoever that is, started bitcoin, he or she issued something between, like, guidelines and a manifesto. Like, a nine-page document. Can you sum up, for those of us who don't really understand this (laughter), the principles that were laid out in those nine pages? POPPER: Sure. Yeah, so this was the original. It's called Satoshi's White Paper. You know, it has this sort of iconic status, this nine-page PDF that was released in early - in late 2008. And it sort of described how this system was going to work. And it said it would be a sort of electronic cache, and there were going to be certain rules that would govern this electronic cache. There would only ever be 21 million bitcoins created. That rule was sort of stated there at the beginning. And that was created so that it would have a sort of scarcity like gold and - which might lead people to think there was going to be a value in it. If there wasn't going to be an unlimited number of them, that might confer a certain value on bitcoin, which it has ended up doing. So that was one rule. The other rules were about how Bitcoin would be distributed. It's not - there wasn't going to be a bank of bitcoin that would distribute them to everybody. They were going to be sort of slowly dripped out over time to people who joined the network. And I think that's the most important thing about the rules around bitcoin was that it was going to be a network of computers, sort of like the Internet, that anybody could join and anybody could support this. And that would allow for bitcoin to exist independent of any sort of central source of authority. There wasn't going to be a government here. There wasn't going to be a company. There was going to be this network of computers that was supporting it, and that means that anybody can join that network and send money to anybody else. And so those were sort of the basic rules that were laid down. And I should say that in the first months after this was proposed, this was not a rousing success. There were, you know, a handful of people, you know, maybe eight people who responded to this idea. Most of whom thought that there was no way that it could work. GROSS: Well, for this to work, it really requires a level of faith. When you're talking about, say, dollars, it's backed up by the U. S. government. And if you have money in a bank, a certain amount of it is backed up by the FDIC. You know, if you invest in the stock market, it's going to fluctuate, but you have shares in something whereas with bitcoin it just seems like an act of faith in bitcoin. POPPER: Well, you are certainly right. I should note I think that, you know, all of those instances you just mentioned - the U. S. dollar is backed up by the U. S. government, by the FDIC - that's true. I mean, if you kind of dig a little deeper, you know, what you're expressing faith in when you express faith in the dollar is essentially the U. S. government and the FDIC. You're believing that those are going to be around. And obviously, that's not maybe a hard thing to believe in, but there's some chance that it won't happen. And certainly there are countries where the government has issued currency and then the government has fallen and the currency has turned out to be worthless. So to a degree, money is always about faith. It's about believing that the thing you're holding in your hand is going to be worth something tomorrow, next week, in a month and that somebody will take it and give you something in exchange. The same is true with bitcoin. And certainly, there are not the institutions backing it up that you have for the U. S. dollar or for stocks. But what is backing it up is this network. And so you in essence are sort of expressing your faith in that network and the power of the network and the power of the rules behind bitcoin to draw people to this currency and to make people think that the network, you know, may outlive the U. S. government. I wouldn't argue that myself. I don't know the odds. I would say probably the odds of the U. S. government outlasting the bitcoin network are good. But I think that a lot of people have - had assumed that bitcoin - that the bitcoin network wouldn't survive to, you know, through the first year, much less the first eight years, which it's done. And it's sort of continued to kind of engender this faith among the people who believe in it, who follow it. GROSS: My guest is Nathaniel Popper, a tech reporter for The New York Times and the author of a book about bitcoin called \"Digital Gold. \" After we take a short break, we'll talk more about how the bitcoin system works and how bitcoin are created by huge server farms competing against each other. And David Edelstein will review the new movie \"Three Billboards Outside Ebbing, Missouri\" starring Frances McDormand. I'm Terry Gross, and this is FRESH AIR. (SOUNDBITE OF MUSIC) GROSS: This is FRESH AIR. I'm Terry Gross. We're talking about bitcoin, the digital currency that was created in 2008. Although its roots were in idealism and libertarianism, it first became widely used for purchases on the dark web, the sites on the Internet black market selling drugs and sex. But this digital currency is now being used for more mainstream purchases. Big banks are starting to find uses for some of the innovative structure of the bitcoin system. My guest, Nathaniel Popper, is a tech reporter for The New York Times. A couple of years ago, he wrote a book about bitcoin called \"Digital Gold. \" So when bitcoin was first released into the world, it was determined by the person who released it, who goes by the name Satoshi Nakamoto, he or she determined how much bitcoin there would be in this world. There's a finite amount of bitcoin that will ever be released to make sure that, like gold, it retains its value. So it's a kind of complicated process how bitcoin is created or mined. Mined is the word that's used. New bitcoin is mined. So would you just tell us a little bit, like, in a comprehensive way about how new bitcoin is mined? POPPER: It's a dangerous question, and it's a hard one to answer simply, but, you know, the answer to how bitcoin are created does sort of give you some glimpse into the inner workings of how this thing functions and why it has survived as long as it has. I mean, essentially, bitcoin released onto the network every 10 minutes. A new block of bitcoin is released onto the network every 10 minutes. And this started on the very first day. On the very first day, there was zero bitcoin in the world. And after 10 minutes - after about 10 minutes, 50 bitcoin were released to one of the computers that was hooked into the network, which at that point was Satoshi Nakamoto's computers. They were almost the only computers that were hooked in at that point. But the rules of bitcoin - the software determine how those bitcoins, those new bitcoins being released, are going to be distributed to people. And the first thing that this does is that it encourages people to join the network. You can essentially - at least early on, you could essentially get free bitcoin if you joined the network. And so it incentivized people to join the network. The other thing it did was that it got those computers to start keeping the records for the network. So if you want to win those bitcoins, essentially you have to start working as an accountant for the network and registering all the new transactions that come in. And if you are doing that - the more computers you add to help, you know, serve as accountant for the network, the better chance you have of winning bitcoins. And so that is how sort of the records are kept, and that's how you get people to volunteer to keep the records. You give them new bitcoins. You offer these new bitcoins. So over time, that incentive system has generated this enormous network. Right now, there's something like 13,000 nodes or computers hooked into the network that are helping to keep these records. And a lot of those are mining, trying to win these new bitcoins. And so this complicated economic system was set up with lots of incentives in there to get people to participate and to sort of create the foundation for this decentralized network to keep all the records. GROSS: So you can't just say, well, I want to create new bitcoin. It's a kind of interesting process. You're basically competing with other people who also want to create new bitcoin. So what do you have? Do you have, like, a lot of computers competing with each other? And what's the competition? Like, what are the. . . POPPER: Yeah. GROSS: Who decides who wins? POPPER: You know, we're slipping down the rabbit hole here and I. . . GROSS: Yeah, that's what I was afraid of, but. . . POPPER: Let's make sure not to go. . . GROSS: Yeah. POPPER: Let's make sure not to go too deep data because it's based on cryptography and encryption, which is sort of the leading edge of math, you know, basically really hard math problems you have to solve. But at the most basic, computers are trying to process all the transactions coming into the bitcoin network as quickly as possible. And the faster you do it, the more efficiently you do it, the better chance you have of winning bitcoin. There's an element of luck in it. It's somewhat like a lottery, but essentially the person with the most computing power has the best chance of winning the lottery. And so what's that - what that's created today is a world in which you have literally server farms in outer - inner Mongolia, in Tibet, in Iceland. Anywhere where you can get cheap electricity to run computers very fast, people have set up basically server farms, big, you know, buildings just filled with computers trying to sort of unlock these new bitcoins but also sort of serving as the backbone of this network. And, you know, the more computers you have joined in, the more secure the network is, the harder it is to attack. And it's this crazy world in which - I mean, literally in China, which has become one of the most, you know, one of the places where you have the most bitcoin mining, you know, spread all around China, you have next to - you know, next to hydroelectric dams and next to a coal plants, people have set up these server farms that are dedicated to doing nothing but mining bitcoin. GROSS: I know you visited a server farm in Iceland. Did you go to one in China, too? POPPER: I went a couple years ago to one in China. They have gotten a lot bigger and more sophisticated since then. I mean, there are literally sort of towns that are built around this in China where you have people just living in the bitcoin mining facility, you know, Chinese people who really - you know, the people who are working there are sort of the custodians. They - most of them have no idea really what's going on or how the system works. But it's - you know, it's created this whole economy. GROSS: So bitcoin is being used as an investment vehicle in the U. S. It's being used for investing, in speculation. How is that playing out here? POPPER: Well, very well for the people who bought it early on. I mean, a bitcoin this week is worth something like $7,500. You know, a year ago, it was worth less than $1,000. And that has attracted a whole bunch of new people to this. It's attracted people around the world. Here, what you've seen is a lot of hedge funds getting into this game. So there are now hedge funds being set up. Something like 100 hedge funds in the last year have been set up to invest exclusively in virtual currencies, bitcoin as well as some of the competitors that have sprung up. GROSS: Wow. Well, say this is a bubble, what happens (laughter)? I mean, like, the price of bitcoin has been shooting straight up, but things that go up sometimes come back down. POPPER: Yes. I mean, if you look at the chart of the bitcoin price since it was born, it is just a series of spikes and then drops, and then spikes and then drops. And over time, you know, you get the spike, and it drops down to a level that is generally still higher than where it was before the spike, but lower than the spike. And so I think a lot of people are asking right now how long this can go on. And certainly, you've heard numerous CEOs of banks say, this is unsustainable; this is a bubble; this is going to crash. And I think there's no doubt that there probably is going to be some reckoning here. I mean, this meets many of the definitions of a bubble. People are speculating on the future value and desire for bitcoin. People are speculating that this will serve more purposes in the future and will be more valuable to more people in the future than it is today. And they're betting - a lot of people are just betting that the price is going to go up without knowing anything about it. And those are a lot of the characteristics that you see in bubbles. I mean, you know, the counterargument is that this is the first time that we've had a scarce digital resource. So I - the Internet, until now - most things on the Internet, you can copy and paste, right? That's what the music industry found. You can copy and paste an MP3. You can copy and paste a movie file. Things aren't scarce on the Internet, and one of the things that bitcoin did through this weird, complicated system of incentives is, it created a scarce digital asset for the first time. So a lot of people think about this now as something like digital gold. You know, this is a place where you can keep your money because there's only going to be so many of them, and the system works, and it's in some ways better than gold because, you know, gold, you can't carry across a border secretly. You can't - you can try to stuff it in your underwear. But, you know, gold, people can - it's hard to travel with gold. Bitcoin - as long as you have that password, you can go somewhere else with internet access and you have access to your money. So that's the sort of thesis on this. But I think that the sort of expectations and the types of people who are getting into this right now, a lot of them are not terribly sophisticated. GROSS: So of the maximum 21 million bitcoin that can be released by - what were - year was it, 2040? POPPER: 2140, yeah. GROSS: 2140, right - oh, 21 - wow, 2140. POPPER: We got a while. GROSS: Wow. POPPER: We're talking about a distant future. GROSS: I'm hearing, like, 2040. That's, like - that's so far away. POPPER: It is. GROSS: OK, so how many bitcoin have already been released? POPPER: We're getting close to 17 million. So the reward to people who are helping to support the network falls in half every four years. So initially, it was 50, and then 25 and now we're down to 12 1/2, and it'll sort of keep going down like that until it approaches zero. And I think, obviously, part of the idea is, they will be worth more, so the 12 1/2 that are released now are actually worth a lot more than the 25 that you were getting a year ago. GROSS: OK, it's time for a short break. Let me reintroduce you. My guest is Nathaniel Popper. We're talking about bitcoin, and he's been writing about bitcoin for several years. He's a tech reporter for The New York Times who wrote a book a couple of years ago about bitcoin called \"Digital Gold. \" Back after this short break - this is FRESH AIR. (SOUNDBITE OF JAY-Z SONG, \"DECEMBER 4TH\") GROSS: This is FRESH AIR. And if you're just joining us, my guest is Nathaniel Popper. He's a tech reporter at The New York Times. And we're talking about bitcoin - digital currency - and he's been covering bitcoin for several years. A couple of years ago, he wrote a book about it called \"Digital Gold. \" So, you know, whether you use bitcoin or not, whether you think it's going to last or not, the architecture of the system seems pretty ingenious. And there are major banks and even the New York Stock Exchange, you know, that are picking up on some of the architecture to borrow it for their own purposes, and what they're borrowing from is what's called the blockchain. Would you explain what that is and how, like, major banks are trying to borrow that system? POPPER: Sure. Well, I think the blockchain, in the simplest sense, is the record of all the bitcoin transactions. It's a ledger, a sort of a spreadsheet on which bitcoin transactions are recorded. But what's special about the bitcoin ledger - the bitcoin blockchain - is that it's not kept by a central institution. It's kept by a bunch of people, and part of the idea is that it's a bunch of people who don't trust each other but can use this system to have a sort of shared record of their assets. And so this blockchain idea, this idea of keeping records in a decentralized way so that anybody can consult it and that nobody is in charge - that idea of the blockchain is something that's piqued a lot of interest in the financial industry but also in a whole bunch of other industries. IBM has made this one of their biggest pushes over the last few years to kind of try to regain relevance. They have made a big move into the blockchain industry, as has Microsoft. And they're essentially making a bet that this is a new way to track information. And, you know, we live in an information economy, and so if you can come up with new ways to track and store information more reliably, it has the potential to recreate some of the foundations of the information economy. It really sounds rather vague. You know, when you just look at something like the financial industry, the banks are looking at this as, you know - maybe instead of paying the New York Stock Exchange to buy and sell stocks there, and then transfer the money for us, and move the stocks back and forth and make sure all the records are kept, maybe we - all the banks - we can just set up a blockchain where we can all trade, and we don't have to pay anybody in the middle, and we can keep track of all those records, and all of us can do it without trusting any of the other people in the system. And that's the sort of basic idea that I think has given rise to this whole new industry. GROSS: So you're not allowed to invest in bitcoin because you cover it for The New York Times. Are you allowed to use it, and have you used it? POPPER: Yes. I mean, our take at The New York Times has basically been, I can have enough to play with and understand it. And I think the understanding has generally been that, you know, those bitcoins essentially belong to The New York Times so that I don't get any big ideas. But yeah, I mean, I'm in there on a daily basis trying to understand how these things work, how you move between different currencies, how it can move around the world. And that's been an important part of reporting on this. GROSS: So if you want to get bitcoin to make purchases, how do you get it? POPPER: Well, companies - not surprisingly, companies have sprung up to make this very easy for you to take your money and give you bitcoin. You know, there's - probably the biggest company in the United States is a company called Coinbase, which is essentially a sort of Charles Schwab or an E-Trade for bitcoin. You send them money, and then you can trade on their platform. You can move in and out of bitcoin. And then you can take your money out and transfer it back to your bank. And they've made it very easy so that anybody - you know, so it's as easy as - probably easier than buying a stock is through E-Trade. And part of what's interesting there - I guess that's not too surprising. What's interesting is that the government and regulators have essentially allowed this to happen, have said, this is OK. New York - state of New York has created a BitLicense that Coinbase has, and that makes it easier for them to do this and easier to get bank accounts. And so at least in the United States, the government has sort of said, we're going to let this happen; we realize there might be something of value here, so we're not going to try to kill this. GROSS: Have you had any great bitcoin adventures in researching your book or writing for The New York Times that you could share for - share with us? POPPER: I mean, this whole thing has been such an incredible story. I mean, that's why I was drawn to it. I mean, the number of people who have gone to jail - often shortly after getting fabulously wealthy - is incredible. And so a lot of the stories I talk - tell in my book are these stories of these astronomic rises followed by these incredible falls. And oftentimes, I was there. You know, I - you know, one of the main characters in my book, I met him in this bar that he had essentially bought a piece of using bitcoin and where he would have these bitcoin parties, where he met his girlfriend. You know, they took bitcoin for - the waiters and waitresses took bitcoin. And he was on top of the world. He had just come back from Argentina. He was traveling around. A week later, he got stopped at the airport by the police, went to trial, ended up in jail. And, you know, I was talking to him at every stage along the way. And I've had that experience in so many different realms - you know, in Iceland, in China, in Argentina. And just to see the way that this technology has created these little universes of - it's only - they're like little science fiction cells where these people are imagining these new futures, and, you know, in each place - in China, Argentina, everywhere you go - it has evolved in different ways. And so just to see the way that this software, you know, it - that this piece of program that this anonymous person wrote - the way it can sprout up and create all these things in the real world - you know, going to these gorges in China where there are now people just living in these enormous industrial sites, working on this - it's - that's, I think, what's been the most incredible to see. GROSS: Well, Nathaniel Popper, I want to thank you so much for talking with us. POPPER: Thank you so much for having me. GROSS: Nathaniel Popper is a tech reporter for The New York Times and the author of a book about bitcoin called \"Digital Gold. \" After we take a short break, David Edelstein will review the new movie \"Three Billboards Outside Ebbing, Missouri. \" This is FRESH AIR. (SOUNDBITE OF JUSTIN HURWITZ'S \"SURPRISE\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-11-10-563378647": {"title": "Self-Driving Cars Aren't Quite Ready For City Streets : NPR", "url": "https://www.npr.org/2017/11/10/563378647/self-driving-cars-arent-quite-ready-for-city-streets", "author": "No author found", "published_date": "2017-11-10", "content": "ROBERT SIEGEL, HOST: In the march to a future of self-driving cars, there was a setback this week. A self-driving shuttle got into a crash on its first day out on the streets of Las Vegas. Two hours into its debut, a large truck backed into it. KELLY MCEVERS, HOST: An executive from a company that sponsors the shuttle was soon on the scene. Here's what Chris Barker of the company Keolis told Las Vegas TV station KSNV News 3. (SOUNDBITE OF ARCHIVED RECORDING)CHRIS BARKER: The shuttle was proceeding up this street. This truck sort of backing up. The shuttle stopped, and the truck kept moving and backed into the front of the vehicle even though the vehicle had actually safely stopped and was waiting for the truck to yield. MCEVERS: Luckily no one was hurt. SIEGEL: The American Automobile Association is a partner in this project, and it's not too worried about the damage to the vehicle. JOHN MORENO: 'Tis but a scratch. SIEGEL: That's AAA's John Moreno. MORENO: It was lightly dented, and it literally has a Band-Aid over it much like a toddler falling and scraping its knee. MCEVERS: Moreno says this is exactly the sort of real-world lesson the autonomous shuttle needed to learn. He says now they will reprogram it to get out safely the next time it is in a similar situation. MORENO: You know, as we know, over 90 percent of all accidents are a result of some form of human error. And what happened in Las Vegas was no different. MCEVERS: Linda Bailey works for the National Association of City Transportation Officials. It is planning for the day when all cities will have autonomous vehicles. She says people will be people, and cities with robot vehicles will have to take that into account. LINDA BAILEY: The idea that we're going to start pointing fingers about it's the human's fault, is the computer's fault - the main thing for a city is to come in and say, how do we make this work for everybody? SIEGEL: And despite the first-day drama, the Las Vegas shuttle is continuing its downtown loop and picking up passengers for free. (SOUNDBITE OF VAMPIRE WEEKEND SONG, \"OXFORD COMMA\") ROBERT SIEGEL, HOST:  In the march to a future of self-driving cars, there was a setback this week. A self-driving shuttle got into a crash on its first day out on the streets of Las Vegas. Two hours into its debut, a large truck backed into it. KELLY MCEVERS, HOST:  An executive from a company that sponsors the shuttle was soon on the scene. Here's what Chris Barker of the company Keolis told Las Vegas TV station KSNV News 3. (SOUNDBITE OF ARCHIVED RECORDING) CHRIS BARKER: The shuttle was proceeding up this street. This truck sort of backing up. The shuttle stopped, and the truck kept moving and backed into the front of the vehicle even though the vehicle had actually safely stopped and was waiting for the truck to yield. MCEVERS: Luckily no one was hurt. SIEGEL: The American Automobile Association is a partner in this project, and it's not too worried about the damage to the vehicle. JOHN MORENO: 'Tis but a scratch. SIEGEL: That's AAA's John Moreno. MORENO: It was lightly dented, and it literally has a Band-Aid over it much like a toddler falling and scraping its knee. MCEVERS: Moreno says this is exactly the sort of real-world lesson the autonomous shuttle needed to learn. He says now they will reprogram it to get out safely the next time it is in a similar situation. MORENO: You know, as we know, over 90 percent of all accidents are a result of some form of human error. And what happened in Las Vegas was no different. MCEVERS: Linda Bailey works for the National Association of City Transportation Officials. It is planning for the day when all cities will have autonomous vehicles. She says people will be people, and cities with robot vehicles will have to take that into account. LINDA BAILEY: The idea that we're going to start pointing fingers about it's the human's fault, is the computer's fault - the main thing for a city is to come in and say, how do we make this work for everybody? SIEGEL: And despite the first-day drama, the Las Vegas shuttle is continuing its downtown loop and picking up passengers for free. (SOUNDBITE OF VAMPIRE WEEKEND SONG, \"OXFORD COMMA\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-11-12-563398606": {"title": "Instagram Crowds May Be Ruining Nature : NPR", "url": "https://www.npr.org/2017/11/12/563398606/instagram-crowds-may-be-ruining-nature", "author": "No author found", "published_date": "2017-11-12", "content": "LULU GARCIA-NAVARRO, HOST:  You scroll through your friend's Instagram feed and see the most beautiful spot and think, I want to go there. It's natural, right? And so you do. Turns out that you are part of the problem, according to Brent Knepper. In the online article \"Instagram Is Loving Nature To Death,\" the travel photographer says that thanks to the photo sharing app, some of the best kept secrets of the natural world are drawing big crowds and literally altering the landscape. Brent Knepper joins me now from Chicago. Welcome to the program. BRENT KNEPPER: Thanks for having me. GARCIA-NAVARRO: Social media gets blamed for everything, I think (laughter). But in this case, it does seem to be true. Can you tell us a little bit about Horseshoe Bend in northern Arizona, which you use as an example. Describe that for us first, if you would. KNEPPER: So Horseshoe Bend is this beautiful spot 7 miles up the Colorado River from the Grand Canyon. And the bend is very unique as far as waterway travels down there, where it makes a complete 180 degree turn in a canyon a thousand feet deep. And it's a very lovely place as long as we're willing to share it with the crowd. GARCIA-NAVARRO: So tell me about that - share it with a crowd. Construction, apparently, has begun in a parking lot that will accommodate more cars at the spot. And there's also going to be a new viewing platform. But how is that related to Instagram? KNEPPER: So I ran the numbers, and the numbers do check out. As far as on Instagram, Horseshoe Bend's popularity, be it in its hashtag or in its geotag, is normally 10 times as popular as anything else in that area. GARCIA-NAVARRO: But is that really a problem? Doesn't that popularity just mean that it might not be as unique, but it's still beautiful? It's still there. People can see it. KNEPPER: Well, popularity is very important. The outdoor world needs more visitors and better accessibility. The difficulty with managing that side of it is that construction can have adverse effects to the natural areas if you start doing different buildings and that sort of thing on top of it, but yes. GARCIA-NAVARRO: Is this an anomaly, though, when we're talking just about Horseshoe Bend or have you seen other spaces that have changed? KNEPPER: I have. A smaller one in Colorado is Conundrum Hot Springs. After it became a spot for people to easily find on social media, the amount of visitorship (ph) went up really high. And since this is a very remote location where people kind of hang around for a long time in the hot springs, they ran out of places to go to the bathroom. As a result, Conundrum Hot Springs had to be shut down for a little bit while park rangers were up there with shovels to relieve that issue. GARCIA-NAVARRO: Meaning they were building bathrooms because people were just, like, basically. . . KNEPPER: Bathrooms were not built. They literally had to shovel up everyone's waste and pack it out for them. GARCIA-NAVARRO: Oh, that does not sound like a very fun experience. And what about Vance Creek Bridge? KNEPPER: Yeah. So Vance Creek Bridge is probably the most famous spot within the Instagram nature niche. It is the second tallest bridge in the U. S. It's privately owned. And it's about a two-hour drive outside of Seattle. Vance Creek Bridge - its location was revealed around 2012 on Instagram. And since then, visitorship has just exploded. And as a result of vandalism, graffiti and a couple of unresolved campfires that caught the bridge on fire, they're just going to tear it down now. GARCIA-NAVARRO: They're going to tear down the bridge? KNEPPER: Yes. GARCIA-NAVARRO: What do you think is driving this for people? I mean, I might see a beautiful picture on Instagram and think, yeah, OK, I want to go to that place. But what is it that people get from going to a place that a lot of people have visited? KNEPPER: Well, there's definitely a community aspect to it. There's nothing wrong with seeing a cool space on the Internet and deciding to go there. It's just, you know, maybe don't start fires on it and clean up your poop. GARCIA-NAVARRO: Travel photographer Brent Knepper, thank you so much for joining us. KNEPPER: Thank you. (SOUNDBITE OF LYMBYC SYSTYM'S \"PARABOLOID\") LULU GARCIA-NAVARRO, HOST:   You scroll through your friend's Instagram feed and see the most beautiful spot and think, I want to go there. It's natural, right? And so you do. Turns out that you are part of the problem, according to Brent Knepper. In the online article \"Instagram Is Loving Nature To Death,\" the travel photographer says that thanks to the photo sharing app, some of the best kept secrets of the natural world are drawing big crowds and literally altering the landscape. Brent Knepper joins me now from Chicago. Welcome to the program. BRENT KNEPPER: Thanks for having me. GARCIA-NAVARRO: Social media gets blamed for everything, I think (laughter). But in this case, it does seem to be true. Can you tell us a little bit about Horseshoe Bend in northern Arizona, which you use as an example. Describe that for us first, if you would. KNEPPER: So Horseshoe Bend is this beautiful spot 7 miles up the Colorado River from the Grand Canyon. And the bend is very unique as far as waterway travels down there, where it makes a complete 180 degree turn in a canyon a thousand feet deep. And it's a very lovely place as long as we're willing to share it with the crowd. GARCIA-NAVARRO: So tell me about that - share it with a crowd. Construction, apparently, has begun in a parking lot that will accommodate more cars at the spot. And there's also going to be a new viewing platform. But how is that related to Instagram? KNEPPER: So I ran the numbers, and the numbers do check out. As far as on Instagram, Horseshoe Bend's popularity, be it in its hashtag or in its geotag, is normally 10 times as popular as anything else in that area. GARCIA-NAVARRO: But is that really a problem? Doesn't that popularity just mean that it might not be as unique, but it's still beautiful? It's still there. People can see it. KNEPPER: Well, popularity is very important. The outdoor world needs more visitors and better accessibility. The difficulty with managing that side of it is that construction can have adverse effects to the natural areas if you start doing different buildings and that sort of thing on top of it, but yes. GARCIA-NAVARRO: Is this an anomaly, though, when we're talking just about Horseshoe Bend or have you seen other spaces that have changed? KNEPPER: I have. A smaller one in Colorado is Conundrum Hot Springs. After it became a spot for people to easily find on social media, the amount of visitorship (ph) went up really high. And since this is a very remote location where people kind of hang around for a long time in the hot springs, they ran out of places to go to the bathroom. As a result, Conundrum Hot Springs had to be shut down for a little bit while park rangers were up there with shovels to relieve that issue. GARCIA-NAVARRO: Meaning they were building bathrooms because people were just, like, basically. . . KNEPPER: Bathrooms were not built. They literally had to shovel up everyone's waste and pack it out for them. GARCIA-NAVARRO: Oh, that does not sound like a very fun experience. And what about Vance Creek Bridge? KNEPPER: Yeah. So Vance Creek Bridge is probably the most famous spot within the Instagram nature niche. It is the second tallest bridge in the U. S. It's privately owned. And it's about a two-hour drive outside of Seattle. Vance Creek Bridge - its location was revealed around 2012 on Instagram. And since then, visitorship has just exploded. And as a result of vandalism, graffiti and a couple of unresolved campfires that caught the bridge on fire, they're just going to tear it down now. GARCIA-NAVARRO: They're going to tear down the bridge? KNEPPER: Yes. GARCIA-NAVARRO: What do you think is driving this for people? I mean, I might see a beautiful picture on Instagram and think, yeah, OK, I want to go to that place. But what is it that people get from going to a place that a lot of people have visited? KNEPPER: Well, there's definitely a community aspect to it. There's nothing wrong with seeing a cool space on the Internet and deciding to go there. It's just, you know, maybe don't start fires on it and clean up your poop. GARCIA-NAVARRO: Travel photographer Brent Knepper, thank you so much for joining us. KNEPPER: Thank you. (SOUNDBITE OF LYMBYC SYSTYM'S \"PARABOLOID\")", "section": "Environment", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-11-13-563894789": {"title": "How One Man Easily Tricked High-Profile People Online Using False Identities : NPR", "url": "https://www.npr.org/2017/11/13/563894789/how-one-man-easily-tricked-high-profile-people-online-using-false-identities", "author": "No author found", "published_date": "2017-11-13", "content": "ELISE HU, HOST: From the White House homeland security adviser to Jared Kushner's private lawyer, many people connected to the White House have exchanged personal emails with an English web designer named James Linton. To be clear, they didn't know they were corresponding with James Linton. He always pretended to be someone else, someone in their inner circle. Linton's pranks - some would call them scams - serve as a cautionary tale to really anyone who uses email. I first asked James Linton about one of his best-known targets, former White House communications director Anthony Scaramucci. JAMES LINTON: Yeah, I think with Anthony Scaramucci it was probably his first week in the job. He seemed like a very good target. He seemed like somebody that would be interesting to kind of interact with. So I set up an account as Reince Priebus. HU: Reince Priebus, the former White House chief of staff. LINTON: Yeah, exactly, because they had a bit of an axe to grind with each other. HU: So you emailed Anthony Scaramucci as Reince Priebus? LINTON: Yes, and as Jon Huntsman Jr. , the Russian envoy for America. So as I was pushing him as Priebus, he was actually contacting Huntsman Jr. for a bit of support. And that was me, too. So it was a bit of a funny situation to be in. HU: Just for some clarity, can you explain to us how this operation worked, how you were able to end up in email exchanges with newsmakers? LINTON: I mean, it was I guess relatively straightforward. I'd select the person who I was trying to target, I guess, for want of a better phrase, and then deciding if I could get hold of the email address easily enough would be a big factor. If I thought I could, then I'd think about who I could be, which character I could adopt which would be friendly enough to them that they would kind of answer back quite candidly. And then it was just going online, setting up a quick email address. Yeah, it's really not that tricky. HU: So you'd go online, set up an email address, and say that - you know, enter in the name field first name, last name of a famous person. LINTON: Yeah, Jared Kushner, say. . . HU: OK. LINTON: . . . Or - yeah. Yeah. It really was that easy. HU: And you mentioned that you were enjoying it. You call these folks targets. Did your conscience never bother you, though, that you were pretending to be other people and getting away with this sort of prank or scam? LINTON: I guess, I mean, with hindsight there were ones that maybe went a little bit further than I maybe would have done if it'd been completely measured. But this kind of thing had grown so organically anyway, I kind of just had to take a feel for it at each turn and just hope that it would kind of be sort of morally and ethically sound in my head, I guess, if not everybody else's. HU: We should point out, of course, that pretending to be someone else is obviously illegal in many jurisdictions. And at the very least, you could find yourself the target of a civil lawsuit. So why'd you do it? LINTON: I don't - I mean, originally, it was driven by a desire to get even, I guess, with the CEO of Barclays bank, who I felt I had a bit of a personal grievance with. And then after that it just kind of naturally went on from there. I thought, it can't be this easy at every bank, so I did quite a few banks, one after the other. And then natural kind of progression just seemed to be to try the White House. I presumed that would be the most secure place going into. And that wasn't the case. HU: Have you felt any consequences from doing this? LINTON: No, not really. No, nobody's - the White House has never certainly contacted me in any way, shape or form. I thought they maybe wanted to just to ask a few questions regarding security, but I think that their egos are probably a bit big for that. And then I've never heard from any solicitor or enforcement agency ever. HU: Do you think there's any security takeaways from what you were able to do? LINTON: Just be a little bit more aware of how in the zone you get when you're in email. Don't always take it for read that the name you see there is the name that's the person you're speaking to. HU: James, thanks. LINTON: OK, thank you. HU: That's James Linton, who managed to stay anonymous until a few weeks ago, when a British tabloid revealed his identity. Now, he says, he's hung up his keyboard good. (SOUNDBITE OF MINOTAUR SHOCK'S \"MY BURR\") ELISE HU, HOST:  From the White House homeland security adviser to Jared Kushner's private lawyer, many people connected to the White House have exchanged personal emails with an English web designer named James Linton. To be clear, they didn't know they were corresponding with James Linton. He always pretended to be someone else, someone in their inner circle. Linton's pranks - some would call them scams - serve as a cautionary tale to really anyone who uses email. I first asked James Linton about one of his best-known targets, former White House communications director Anthony Scaramucci. JAMES LINTON: Yeah, I think with Anthony Scaramucci it was probably his first week in the job. He seemed like a very good target. He seemed like somebody that would be interesting to kind of interact with. So I set up an account as Reince Priebus. HU: Reince Priebus, the former White House chief of staff. LINTON: Yeah, exactly, because they had a bit of an axe to grind with each other. HU: So you emailed Anthony Scaramucci as Reince Priebus? LINTON: Yes, and as Jon Huntsman Jr. , the Russian envoy for America. So as I was pushing him as Priebus, he was actually contacting Huntsman Jr. for a bit of support. And that was me, too. So it was a bit of a funny situation to be in. HU: Just for some clarity, can you explain to us how this operation worked, how you were able to end up in email exchanges with newsmakers? LINTON: I mean, it was I guess relatively straightforward. I'd select the person who I was trying to target, I guess, for want of a better phrase, and then deciding if I could get hold of the email address easily enough would be a big factor. If I thought I could, then I'd think about who I could be, which character I could adopt which would be friendly enough to them that they would kind of answer back quite candidly. And then it was just going online, setting up a quick email address. Yeah, it's really not that tricky. HU: So you'd go online, set up an email address, and say that - you know, enter in the name field first name, last name of a famous person. LINTON: Yeah, Jared Kushner, say. . . HU: OK. LINTON: . . . Or - yeah. Yeah. It really was that easy. HU: And you mentioned that you were enjoying it. You call these folks targets. Did your conscience never bother you, though, that you were pretending to be other people and getting away with this sort of prank or scam? LINTON: I guess, I mean, with hindsight there were ones that maybe went a little bit further than I maybe would have done if it'd been completely measured. But this kind of thing had grown so organically anyway, I kind of just had to take a feel for it at each turn and just hope that it would kind of be sort of morally and ethically sound in my head, I guess, if not everybody else's. HU: We should point out, of course, that pretending to be someone else is obviously illegal in many jurisdictions. And at the very least, you could find yourself the target of a civil lawsuit. So why'd you do it? LINTON: I don't - I mean, originally, it was driven by a desire to get even, I guess, with the CEO of Barclays bank, who I felt I had a bit of a personal grievance with. And then after that it just kind of naturally went on from there. I thought, it can't be this easy at every bank, so I did quite a few banks, one after the other. And then natural kind of progression just seemed to be to try the White House. I presumed that would be the most secure place going into. And that wasn't the case. HU: Have you felt any consequences from doing this? LINTON: No, not really. No, nobody's - the White House has never certainly contacted me in any way, shape or form. I thought they maybe wanted to just to ask a few questions regarding security, but I think that their egos are probably a bit big for that. And then I've never heard from any solicitor or enforcement agency ever. HU: Do you think there's any security takeaways from what you were able to do? LINTON: Just be a little bit more aware of how in the zone you get when you're in email. Don't always take it for read that the name you see there is the name that's the person you're speaking to. HU: James, thanks. LINTON: OK, thank you. HU: That's James Linton, who managed to stay anonymous until a few weeks ago, when a British tabloid revealed his identity. Now, he says, he's hung up his keyboard good. (SOUNDBITE OF MINOTAUR SHOCK'S \"MY BURR\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-11-15-562900887": {"title": "Oceans May Host Next Wave Of Renewable Energy : NPR", "url": "https://www.npr.org/2017/11/15/562900887/oceans-may-host-next-wave-of-renewable-energy", "author": "No author found", "published_date": "2017-11-15", "content": "RACHEL MARTIN, HOST: I say renewable energy and you probably think wind or maybe the sun. You might be able to put the ocean's waves on that list, too. The Department of Energy is experimenting with this idea. The department is spending $40 million to build a test facility off the Oregon coast. Here's NPR's Jeff Brady. JEFF BRADY, BYLINE: Wave energy has a long way to go before it's ready to power the lights in your house. In fact, Belinda Batten of Oregon State University says engineers aren't quite sure how best to capture the power of the water. BELINDA BATTEN: If you think about the motion of the ocean, it goes up and down when you're out in the water. As you're getting close to the coast, it's going back and forth in surge. Within the ocean, the particles go around in circles. And so we don't know what the right kind of wave energy converter is. BRADY: Batten says the new offshore test facility the federal government is largely financing will help the industry develop. There is research underway now. At Oregon State, it happens in a cavernous gray building with a concrete tank that's almost as long as a football field. Pedro Lomonaco directs OSU's Wave Research Lab. PEDRO LOMONACO: So we will run a wave for you now. BRADY: First, you'll hear the big engine that makes the wave and sends water through the tank. (SOUNDBITE OF WAVE ENGINE)BRADY: Then the wave heads toward us. (SOUNDBITE OF ROLLING WAVE)BRADY: Lomonaco says so far they've tested model versions of wave energy converters. LOMONACO: And we will see how it responds to the waves and how much energy we can capture from them. BRADY: But this testing can only go so far. Belinda Batten says it's important to get out in the ocean. BATTEN: You need that full-scale wave energy converter out there for some time to prove that it's going to survive, to prove what its cost of energy is, and that's also important to attract venture capitalists. BRADY: For the small companies involved in wave energy now, it's too expensive to build their own test facilities. That's why the federal government is largely funding the project about six miles off the central Oregon coast. Wave energy backers like Jason Busch are excited. He heads the Oregon Wave Energy Trust, which estimates 10 percent of the world's energy could come from the ocean. JASON BUSCH: Marine renewables is a vast opportunity. The amount of energy that's in the ocean available for us to utilize is massive, and it's right there. It's right off our shores. BRADY: There are a few concerns. The technology will be expensive at first, and Busch says more research is needed on the environmental effects of wave energy. The fishing industry also has some worries. In deciding where the offshore test facility should be built, Oregon State involved fishermen to make sure it didn't interfere with their business. I met Terry Thompson at the docks in Newport. He's a county commissioner and fisherman and says it took some time to get his busy colleagues together in one room, but once they did, picking a location was easy. TERRY THOMPSON: We don't fish there. Everybody in the room looked around and says we don't fish there either. Ten minutes after we met, here's your site (laughter). BRADY: Sounds like you all needed to have a conference call (laughter). THOMPSON: No, we - no, fishermen don't do conference calls. Fishermen do face to face. BRADY: Construction on the new wave energy test facility is expected to start in 18 months. Jeff Brady, NPR News. RACHEL MARTIN, HOST:  I say renewable energy and you probably think wind or maybe the sun. You might be able to put the ocean's waves on that list, too. The Department of Energy is experimenting with this idea. The department is spending $40 million to build a test facility off the Oregon coast. Here's NPR's Jeff Brady. JEFF BRADY, BYLINE: Wave energy has a long way to go before it's ready to power the lights in your house. In fact, Belinda Batten of Oregon State University says engineers aren't quite sure how best to capture the power of the water. BELINDA BATTEN: If you think about the motion of the ocean, it goes up and down when you're out in the water. As you're getting close to the coast, it's going back and forth in surge. Within the ocean, the particles go around in circles. And so we don't know what the right kind of wave energy converter is. BRADY: Batten says the new offshore test facility the federal government is largely financing will help the industry develop. There is research underway now. At Oregon State, it happens in a cavernous gray building with a concrete tank that's almost as long as a football field. Pedro Lomonaco directs OSU's Wave Research Lab. PEDRO LOMONACO: So we will run a wave for you now. BRADY: First, you'll hear the big engine that makes the wave and sends water through the tank. (SOUNDBITE OF WAVE ENGINE) BRADY: Then the wave heads toward us. (SOUNDBITE OF ROLLING WAVE) BRADY: Lomonaco says so far they've tested model versions of wave energy converters. LOMONACO: And we will see how it responds to the waves and how much energy we can capture from them. BRADY: But this testing can only go so far. Belinda Batten says it's important to get out in the ocean. BATTEN: You need that full-scale wave energy converter out there for some time to prove that it's going to survive, to prove what its cost of energy is, and that's also important to attract venture capitalists. BRADY: For the small companies involved in wave energy now, it's too expensive to build their own test facilities. That's why the federal government is largely funding the project about six miles off the central Oregon coast. Wave energy backers like Jason Busch are excited. He heads the Oregon Wave Energy Trust, which estimates 10 percent of the world's energy could come from the ocean. JASON BUSCH: Marine renewables is a vast opportunity. The amount of energy that's in the ocean available for us to utilize is massive, and it's right there. It's right off our shores. BRADY: There are a few concerns. The technology will be expensive at first, and Busch says more research is needed on the environmental effects of wave energy. The fishing industry also has some worries. In deciding where the offshore test facility should be built, Oregon State involved fishermen to make sure it didn't interfere with their business. I met Terry Thompson at the docks in Newport. He's a county commissioner and fisherman and says it took some time to get his busy colleagues together in one room, but once they did, picking a location was easy. TERRY THOMPSON: We don't fish there. Everybody in the room looked around and says we don't fish there either. Ten minutes after we met, here's your site (laughter). BRADY: Sounds like you all needed to have a conference call (laughter). THOMPSON: No, we - no, fishermen don't do conference calls. Fishermen do face to face. BRADY: Construction on the new wave energy test facility is expected to start in 18 months. Jeff Brady, NPR News.", "section": "National", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-11-16-564674949": {"title": "Why Google Home Has Hard Time Recognizing The Smash Hit 'Despacito' : NPR", "url": "https://www.npr.org/2017/11/16/564674949/why-google-home-has-hard-time-recognizing-the-smash-hit-despacito", "author": "No author found", "published_date": "2017-11-16", "content": "KELLY MCEVERS, HOST: Tonight at the Latin Grammys, the hit song \"Despacito\" is up for four awards, including record of the year. Clearly a lot of people know this song. But it turns out the Google Home personal assistant does not. NPR's Aarti Shahani explains. AARTI SHAHANI, BYLINE: This has been the maddening conversation in my kitchen. OK, Google, play \"Despacito. \"COMPUTER-GENERATED VOICE: My apologies. I don't understand. SHAHANI: All right. Maybe that was too ethnic. I go gringo. OK, Google, play \"Des-pah-see-toe\" (ph). COMPUTER-GENERATED VOICE: Sorry. I don't know how to help with that. SHAHANI: I try again with the song and the name of the artist. I try to spell it out - literally spell. Play \"D-E-S-P-A-C-I-T-O\" (ph). She totally doesn't understand. And then maybe because I'm asking so much, she gets desperate, throws another artist at me. COMPUTER-GENERATED VOICE: OK. Here's Justin Bieber on Spotify. (SOUNDBITE OF SONG, \"FRIENDS\")JUSTIN BIEBER: (Singing) I was wondering about your mama. SHAHANI: (Laughter) No, Justin Bieber is no Luis Fonsi. What's wild about this is I'm not asking for some obscure song Google's never heard of. \"Despacito\" is the single most-viewed video this year on YouTube, which is owned by Google. PARAG CHORDIA: It probably was just out of vocabulary. It wasn't in the computer's lexicon, in the vocabulary of words that it knew about. SHAHANI: Parag Chordia, an expert in artificial intelligence and speech, presents a theory. CHORDIA: And so when it was trying to figure out what that sound was, it didn't know what to map it to. SHAHANI: Google declined to discuss this failure of the home assistant. So I asked Chordia to make an educated guess. He says that even when a song is a YouTube hit, it may not automatically become part of the Google Home dictionary. Words need to be added by humans or by software. He's often had the experience of asking for some Indian classical singer Google Home doesn't know. For example. . . CHORDIA: Tidaquwa - I have said Tidaquwa and that it's - and it's - and you know, it's giving me Shakira. SHAHANI: Now, it's a great theory. Problem is, I debunked it. I established that my Google Home knows the word. OK, Google, do you understand Spanish? COMPUTER-GENERATED VOICE: Yes, I speak Spanish. SHAHANI: OK, Google, why don't you understand what I'm saying in Spanish? COMPUTER-GENERATED VOICE: I'm still learning it, but I can translate for you. Just ask. SHAHANI: OK, Google, translate despacito. COMPUTER-GENERATED VOICE: Slowly. SHAHANI: Yes. She wasn't telling me to say it slowly. That's literally what despacito means. And after asking 23 times, here's what finally happened. OK, Google, play \"Despacito. \"COMPUTER-GENERATED VOICE: Sure - \"Despacito\" by Luis Fonsi. (SOUNDBITE OF SONG, \"DESPACITO\")LUIS FONSI: (Singing in Spanish). SHAHANI: If it weren't in her Spanish vocabulary, this small miracle would not have been possible. So here's theory two by Chordia. Google Home needs training. Even if YouTubers want the song, maybe the people using this new device aren't asking for it as much. So more people have to ask and have to ask in different accents to make the computer's ear more responsive. CHORDIA: So that it knows that, hey, people don't just say this word this way; they also say it this way. And so it just needs examples. SHAHANI: Now, maybe this sounds unlikely given what a megahit we're talking about. For what it's worth, Chordia himself does not believe Google has some agenda against Latin music. CHORDIA: (Laughter) I don't think so given that it's been played I think four and half billion times on YouTube. (SOUNDBITE OF SONG, \"DESPACITO\")FONSI: (Singing in Spanish). SHAHANI: Aarti Shahani, NPR News, San Francisco. (SOUNDBITE OF SONG, \"DESPACITO\")FONSI: (Singing in Spanish). SHAHANI: OK, Google, thank you. COMPUTER-GENERATED VOICE: You're welcome. KELLY MCEVERS, HOST:  Tonight at the Latin Grammys, the hit song \"Despacito\" is up for four awards, including record of the year. Clearly a lot of people know this song. But it turns out the Google Home personal assistant does not. NPR's Aarti Shahani explains. AARTI SHAHANI, BYLINE: This has been the maddening conversation in my kitchen. OK, Google, play \"Despacito. \" COMPUTER-GENERATED VOICE: My apologies. I don't understand. SHAHANI: All right. Maybe that was too ethnic. I go gringo. OK, Google, play \"Des-pah-see-toe\" (ph). COMPUTER-GENERATED VOICE: Sorry. I don't know how to help with that. SHAHANI: I try again with the song and the name of the artist. I try to spell it out - literally spell. Play \"D-E-S-P-A-C-I-T-O\" (ph). She totally doesn't understand. And then maybe because I'm asking so much, she gets desperate, throws another artist at me. COMPUTER-GENERATED VOICE: OK. Here's Justin Bieber on Spotify. (SOUNDBITE OF SONG, \"FRIENDS\") JUSTIN BIEBER: (Singing) I was wondering about your mama. SHAHANI: (Laughter) No, Justin Bieber is no Luis Fonsi. What's wild about this is I'm not asking for some obscure song Google's never heard of. \"Despacito\" is the single most-viewed video this year on YouTube, which is owned by Google. PARAG CHORDIA: It probably was just out of vocabulary. It wasn't in the computer's lexicon, in the vocabulary of words that it knew about. SHAHANI: Parag Chordia, an expert in artificial intelligence and speech, presents a theory. CHORDIA: And so when it was trying to figure out what that sound was, it didn't know what to map it to. SHAHANI: Google declined to discuss this failure of the home assistant. So I asked Chordia to make an educated guess. He says that even when a song is a YouTube hit, it may not automatically become part of the Google Home dictionary. Words need to be added by humans or by software. He's often had the experience of asking for some Indian classical singer Google Home doesn't know. For example. . . CHORDIA: Tidaquwa - I have said Tidaquwa and that it's - and it's - and you know, it's giving me Shakira. SHAHANI: Now, it's a great theory. Problem is, I debunked it. I established that my Google Home knows the word. OK, Google, do you understand Spanish? COMPUTER-GENERATED VOICE: Yes, I speak Spanish. SHAHANI: OK, Google, why don't you understand what I'm saying in Spanish? COMPUTER-GENERATED VOICE: I'm still learning it, but I can translate for you. Just ask. SHAHANI: OK, Google, translate despacito. COMPUTER-GENERATED VOICE: Slowly. SHAHANI: Yes. She wasn't telling me to say it slowly. That's literally what despacito means. And after asking 23 times, here's what finally happened. OK, Google, play \"Despacito. \" COMPUTER-GENERATED VOICE: Sure - \"Despacito\" by Luis Fonsi. (SOUNDBITE OF SONG, \"DESPACITO\") LUIS FONSI: (Singing in Spanish). SHAHANI: If it weren't in her Spanish vocabulary, this small miracle would not have been possible. So here's theory two by Chordia. Google Home needs training. Even if YouTubers want the song, maybe the people using this new device aren't asking for it as much. So more people have to ask and have to ask in different accents to make the computer's ear more responsive. CHORDIA: So that it knows that, hey, people don't just say this word this way; they also say it this way. And so it just needs examples. SHAHANI: Now, maybe this sounds unlikely given what a megahit we're talking about. For what it's worth, Chordia himself does not believe Google has some agenda against Latin music. CHORDIA: (Laughter) I don't think so given that it's been played I think four and half billion times on YouTube. (SOUNDBITE OF SONG, \"DESPACITO\") FONSI: (Singing in Spanish). SHAHANI: Aarti Shahani, NPR News, San Francisco. (SOUNDBITE OF SONG, \"DESPACITO\") FONSI: (Singing in Spanish). SHAHANI: OK, Google, thank you. COMPUTER-GENERATED VOICE: You're welcome.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-11-17-564936504": {"title": "If You Give Sheep Cameras, They'll Help Create Street Maps : NPR", "url": "https://www.npr.org/2017/11/17/564936504/if-you-give-sheep-cameras-theyll-help-create-street-maps", "author": "No author found", "published_date": "2017-11-17", "content": "KELLY MCEVERS, HOST: The Faroe Islands is a tiny archipelago about halfway between Iceland and Norway. LEVI HANSSEN: There are a lot of people that don't even know that we exist. MCEVERS: Levi Hanssen from Visit Faroe Islands says that obscurity has been a problem. ELISE HU, HOST: Like a lot of remote places, Google Street View wasn't available, which meant potential visitors couldn't see what they were missing. So the tourism board decided to enlist some of the locals for help. HANSSEN: We're a population of 50,000 people, but we have approximately 70,000 to 80,000 sheep. MCEVERS: Sheep - you see where this is going. HANSSEN: We strapped cameras on the back of sheep and put the sheep out into the mountains and created our own version. MCEVERS: The sheep started documenting the place with 360-degree cameras that ran on solar power. The technology worked great, but the sheep needed some motivation. HANSSEN: You know, like when you go sheepherding you would sort of stand around them and sort of, you know, usher them in the right direction. And then eventually they started to move, so that's how we did it. (SOUNDBITE OF MUSIC)HU: And eventually they had this video we're hearing and images of the beautiful Faroe Island's landscape. They then uploaded the images to Google Maps. And instead of calling it Street View. . . (SOUNDBITE OF SHEEP BLEATING)DURITA ANDREASSEN: Welcome to Sheep View 360. HU: Sheep View. MCEVERS: And five weeks after Sheep View launched. . . (SOUNDBITE OF ARCHIVED RECORDING)ANDREASSEN: Look. Google is coming. MCEVERS: . . . Google brought their official Street View cameras to map the roads by car. They also brought smaller cameras so the tourism board could capture hiking trails and seashores. HU: The images they collected went live on Google earlier this month along with some of what the sheep captured earlier. Levi Hanssen says they left a few surprises, so hopefully people will still go see them in person. HANSSEN: We think that - you know, that it doesn't harm if we leave some places a bit more mysterious. HU: And one thing to make clear here. . . HANSSEN: The cameras were extremely light. I mean, we're really certain that the sheep couldn't feel anything. MCEVERS: In other words, no sheep were harmed in the making of Sheep View. KELLY MCEVERS, HOST:  The Faroe Islands is a tiny archipelago about halfway between Iceland and Norway. LEVI HANSSEN: There are a lot of people that don't even know that we exist. MCEVERS: Levi Hanssen from Visit Faroe Islands says that obscurity has been a problem. ELISE HU, HOST:  Like a lot of remote places, Google Street View wasn't available, which meant potential visitors couldn't see what they were missing. So the tourism board decided to enlist some of the locals for help. HANSSEN: We're a population of 50,000 people, but we have approximately 70,000 to 80,000 sheep. MCEVERS: Sheep - you see where this is going. HANSSEN: We strapped cameras on the back of sheep and put the sheep out into the mountains and created our own version. MCEVERS: The sheep started documenting the place with 360-degree cameras that ran on solar power. The technology worked great, but the sheep needed some motivation. HANSSEN: You know, like when you go sheepherding you would sort of stand around them and sort of, you know, usher them in the right direction. And then eventually they started to move, so that's how we did it. (SOUNDBITE OF MUSIC) HU: And eventually they had this video we're hearing and images of the beautiful Faroe Island's landscape. They then uploaded the images to Google Maps. And instead of calling it Street View. . . (SOUNDBITE OF SHEEP BLEATING) DURITA ANDREASSEN: Welcome to Sheep View 360. HU: Sheep View. MCEVERS: And five weeks after Sheep View launched. . . (SOUNDBITE OF ARCHIVED RECORDING) ANDREASSEN: Look. Google is coming. MCEVERS: . . . Google brought their official Street View cameras to map the roads by car. They also brought smaller cameras so the tourism board could capture hiking trails and seashores. HU: The images they collected went live on Google earlier this month along with some of what the sheep captured earlier. Levi Hanssen says they left a few surprises, so hopefully people will still go see them in person. HANSSEN: We think that - you know, that it doesn't harm if we leave some places a bit more mysterious. HU: And one thing to make clear here. . . HANSSEN: The cameras were extremely light. I mean, we're really certain that the sheep couldn't feel anything. MCEVERS: In other words, no sheep were harmed in the making of Sheep View.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-11-21-565838123": {"title": "Uber Says Hackers Stole Personal Data Of 57 Million Users : NPR", "url": "https://www.npr.org/2017/11/21/565838123/uber-says-hackers-stole-personal-data-of-57-million-users", "author": "No author found", "published_date": "2017-11-21", "content": "ELISE HU, HOST: Leaders at Uber hid a major hack that exposed the data of 57 million people - users and drivers - for more than a year. The company's new CEO just reported that breach to federal officials and fired his employees in charge of the cover-up. Here to talk about this with us NPR tech reporter Aarti Shahani. Aarti, what happened? AARTI SHAHANI, BYLINE: (Laughter) It's breathtaking. Dara Khosrowshahi published a blog post today after Bloomberg broke the story. He says just recently he learned about the breach. It happened in late-2016 before he took over the company. He said hackers managed to crack into an online safe and download some information, the names and driver's license numbers of around 600,000 drivers in the United States. And then in terms of passengers - in terms of riders, hackers got names, email addresses, mobile phone numbers. You know, we're talking 57 million victims total. Khosrowshahi said that the company investigated, and they did not see any indication that things like trip location history or credit card numbers or bank account numbers or Social Security numbers or dates of birth were stolen. But he also does say that, you know, Uber should have informed regulators about it. HU: Yeah. And this cover-up is also rather surprising. Tell us more about that. SHAHANI: (Laughter) Yeah. This is quite a detail. The man at Uber who was in charge of security - his name is Joe Sullivan - he covered it up according to the Bloomberg report. He didn't let government officials or the public or victims know. And you know, the remarkable detail from the report is that Uber actually paid the hackers a hundred thousand dollars, OK? They paid the hackers to delete the data and keep their mouths shut about it. Sullivan is a man I've interviewed in the past both when he was over at Facebook and then at Uber. He's a former federal prosecutor, a former public servant. And you know, he had an interesting approach to his job. For example, he felt like it was OK for Uber to start using the sensors on drivers' smartphones to track how they drive, how they perform on the job even though many drivers were not aware of this practice and didn't like it. It turns out he didn't feel an obligation to disclose to them that their data was taken either. HU: So what's happening to him, this chief security officer you're talking about? SHAHANI: Well, Uber let go of Sullivan and one of his lieutenants this week. And I think Khosrowshahi is trying to send the message to his employees and investors of, hey, I know Uber has had some very shady business practices, but really we are turning a corner here. And this is really damaging news for Uber. The company just lost a major appeal over in London, OK? The courts there decided Uber has been misclassifying their workers. Uber says everyone who drives for them is a contractor, not an employee. The U. K. court found that to not be true, a legal fiction. Uber is going to fight that ruling. But it is an indicator of how regulators and courts around the world are scrutinizing the company. And Uber - you know, it can't take for granted its business model. It's not there anymore. And of course, you know, over in the U. S. , Uber has been under scrutiny for privacy violations, intentionally concealing its service from public sector workers who want to regulate the company and whatnot. HU: What about the victims, Aarti? What is Uber telling the victims of this hack? SHAHANI: Well, they're doing what every company seems to do after a breach, what Equifax and Yahoo and others have done. They're offering free credit monitoring. Now, whether or not that's effective to block identity theft - that remains to be seen. But it is the standard courtesy these days. HU: NPR's Aarti Shahani speaking to us from San Francisco. Aarti, thank you. SHAHANI: Thank you. ELISE HU, HOST:  Leaders at Uber hid a major hack that exposed the data of 57 million people - users and drivers - for more than a year. The company's new CEO just reported that breach to federal officials and fired his employees in charge of the cover-up. Here to talk about this with us NPR tech reporter Aarti Shahani. Aarti, what happened? AARTI SHAHANI, BYLINE: (Laughter) It's breathtaking. Dara Khosrowshahi published a blog post today after Bloomberg broke the story. He says just recently he learned about the breach. It happened in late-2016 before he took over the company. He said hackers managed to crack into an online safe and download some information, the names and driver's license numbers of around 600,000 drivers in the United States. And then in terms of passengers - in terms of riders, hackers got names, email addresses, mobile phone numbers. You know, we're talking 57 million victims total. Khosrowshahi said that the company investigated, and they did not see any indication that things like trip location history or credit card numbers or bank account numbers or Social Security numbers or dates of birth were stolen. But he also does say that, you know, Uber should have informed regulators about it. HU: Yeah. And this cover-up is also rather surprising. Tell us more about that. SHAHANI: (Laughter) Yeah. This is quite a detail. The man at Uber who was in charge of security - his name is Joe Sullivan - he covered it up according to the Bloomberg report. He didn't let government officials or the public or victims know. And you know, the remarkable detail from the report is that Uber actually paid the hackers a hundred thousand dollars, OK? They paid the hackers to delete the data and keep their mouths shut about it. Sullivan is a man I've interviewed in the past both when he was over at Facebook and then at Uber. He's a former federal prosecutor, a former public servant. And you know, he had an interesting approach to his job. For example, he felt like it was OK for Uber to start using the sensors on drivers' smartphones to track how they drive, how they perform on the job even though many drivers were not aware of this practice and didn't like it. It turns out he didn't feel an obligation to disclose to them that their data was taken either. HU: So what's happening to him, this chief security officer you're talking about? SHAHANI: Well, Uber let go of Sullivan and one of his lieutenants this week. And I think Khosrowshahi is trying to send the message to his employees and investors of, hey, I know Uber has had some very shady business practices, but really we are turning a corner here. And this is really damaging news for Uber. The company just lost a major appeal over in London, OK? The courts there decided Uber has been misclassifying their workers. Uber says everyone who drives for them is a contractor, not an employee. The U. K. court found that to not be true, a legal fiction. Uber is going to fight that ruling. But it is an indicator of how regulators and courts around the world are scrutinizing the company. And Uber - you know, it can't take for granted its business model. It's not there anymore. And of course, you know, over in the U. S. , Uber has been under scrutiny for privacy violations, intentionally concealing its service from public sector workers who want to regulate the company and whatnot. HU: What about the victims, Aarti? What is Uber telling the victims of this hack? SHAHANI: Well, they're doing what every company seems to do after a breach, what Equifax and Yahoo and others have done. They're offering free credit monitoring. Now, whether or not that's effective to block identity theft - that remains to be seen. But it is the standard courtesy these days. HU: NPR's Aarti Shahani speaking to us from San Francisco. Aarti, thank you. SHAHANI: Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-11-22-566098701": {"title": "What The End To Net Neutrality Means For Internet Streaming : NPR", "url": "https://www.npr.org/2017/11/22/566098701/what-the-end-to-net-neutrality-means-for-internet-streaming", "author": "No author found", "published_date": "2017-11-22", "content": "ELISE HU, HOST: The Federal Communications Commission will vote next month to remove nearly every rule on the books that protects the idea of net neutrality. Basically that means Internet service providers like Comcast or AT&T could go from being neutral gateways to everything on the Internet to gatekeepers. They could decide to load some sites more slowly or impose fees for faster service. The rules being repealed are just 2 years old. The FCC's Republican chair, Ajit Pai, says they've hurt the online economy. Here's what he told NPR's Morning Edition today. (SOUNDBITE OF ARCHIVED BROADCAST)AJIT PAI: The Internet wasn't broken in 2015 when these heavy-handed regulations were adopted. And once we remove them, I think we'll continue to see the infrastructure investment that will benefit digital consumers and entrepreneurs alike. HU: Let's get a response to that from Pai's predecessor. Tom Wheeler chaired the FCC when it approved these rules in 2015. Tom Wheeler, thanks for joining us. TOM WHEELER: Thanks for having me. HU: Well, first, net neutrality is a term that can cause our eyes to glaze over. But obviously it's been central to your career. So how do you explain it to people in your life to get folks engaged on the issue? WHEELER: We actually said that we need to talk about this in terms of the open Internet rather than the abstract term net neutrality because that really describes what's going on here. We're talking about - is the Internet, which is the most powerful and pervasive platform in the history of the planet - is it going to be open to all comers, or is it going to be a toll road that the consumer has to pay to get special services or that service providers have to pay to be able to reach the consumer? And what we said was, no, this is an asset that is key to the economy of the 21st century, and it must be open to all. HU: Your successor though, Chairman Ajit Pai, says the Internet wasn't broken in 2015 when you and the commission approved these rules. He calls them heavy-handed. So can you point to anything that got better for consumers over the past two years because of these regulations? WHEELER: After these rules were adopted, we have seen investment in broadband increase. We have seen VC investment in new startups that use the Internet increase. And we have seen an expansion in the kinds of services that are available to consumers. This has been a success. The Internet was indeed broken before the 2015 rules were put in place because the companies were blocking content. They were throttling content. And they even went to court to tell the court under oath that they intended to have fast lanes and slow lanes so that consumers would have to pay more. So with all due respect to the current chairman, he is making up something out of whole cloth that was denied under oath (laughter) by the Internet service providers in court. HU: So what would be the effect on consumers now under the changes that are proposed? WHEELER: Oh, wow. If you like your cable company, then you'll love what's going to happen to the Internet because suddenly the rules - instead of being open, the rules now will resemble very similar to what your rules are if you're a cable company where the cable company decides who you can get access to, what your prices will be. HU: I'm curious, though. Something confusing in all of this is that both sides of the debate say that they support the idea of an open Internet. So sort through this for us. What's the debate over if both sides say, hey, we love the open Internet? WHEELER: I think you've got to start with one key fact, and that is what we found when we were developing the open Internet rules - is that two-thirds of American consumers have at most one choice as to who they can get their Internet access from. That means we're dealing with a monopoly. And when those monopolies turn around and say, oh, we're for an open Internet, what they're really saying is, we're for an open Internet because we can make the rules. And we said, no, we think that the representative of the consumer ought to make those rules. HU: Tom Wheeler served as chairman of the Federal Communications Commission from November 2013 to January of this year. He's now a fellow at the Harvard Kennedy School of Government. Tom Wheeler, thanks for coming on the program. WHEELER: Thanks, Elise. ELISE HU, HOST:  The Federal Communications Commission will vote next month to remove nearly every rule on the books that protects the idea of net neutrality. Basically that means Internet service providers like Comcast or AT&T could go from being neutral gateways to everything on the Internet to gatekeepers. They could decide to load some sites more slowly or impose fees for faster service. The rules being repealed are just 2 years old. The FCC's Republican chair, Ajit Pai, says they've hurt the online economy. Here's what he told NPR's Morning Edition today. (SOUNDBITE OF ARCHIVED BROADCAST) AJIT PAI: The Internet wasn't broken in 2015 when these heavy-handed regulations were adopted. And once we remove them, I think we'll continue to see the infrastructure investment that will benefit digital consumers and entrepreneurs alike. HU: Let's get a response to that from Pai's predecessor. Tom Wheeler chaired the FCC when it approved these rules in 2015. Tom Wheeler, thanks for joining us. TOM WHEELER: Thanks for having me. HU: Well, first, net neutrality is a term that can cause our eyes to glaze over. But obviously it's been central to your career. So how do you explain it to people in your life to get folks engaged on the issue? WHEELER: We actually said that we need to talk about this in terms of the open Internet rather than the abstract term net neutrality because that really describes what's going on here. We're talking about - is the Internet, which is the most powerful and pervasive platform in the history of the planet - is it going to be open to all comers, or is it going to be a toll road that the consumer has to pay to get special services or that service providers have to pay to be able to reach the consumer? And what we said was, no, this is an asset that is key to the economy of the 21st century, and it must be open to all. HU: Your successor though, Chairman Ajit Pai, says the Internet wasn't broken in 2015 when you and the commission approved these rules. He calls them heavy-handed. So can you point to anything that got better for consumers over the past two years because of these regulations? WHEELER: After these rules were adopted, we have seen investment in broadband increase. We have seen VC investment in new startups that use the Internet increase. And we have seen an expansion in the kinds of services that are available to consumers. This has been a success. The Internet was indeed broken before the 2015 rules were put in place because the companies were blocking content. They were throttling content. And they even went to court to tell the court under oath that they intended to have fast lanes and slow lanes so that consumers would have to pay more. So with all due respect to the current chairman, he is making up something out of whole cloth that was denied under oath (laughter) by the Internet service providers in court. HU: So what would be the effect on consumers now under the changes that are proposed? WHEELER: Oh, wow. If you like your cable company, then you'll love what's going to happen to the Internet because suddenly the rules - instead of being open, the rules now will resemble very similar to what your rules are if you're a cable company where the cable company decides who you can get access to, what your prices will be. HU: I'm curious, though. Something confusing in all of this is that both sides of the debate say that they support the idea of an open Internet. So sort through this for us. What's the debate over if both sides say, hey, we love the open Internet? WHEELER: I think you've got to start with one key fact, and that is what we found when we were developing the open Internet rules - is that two-thirds of American consumers have at most one choice as to who they can get their Internet access from. That means we're dealing with a monopoly. And when those monopolies turn around and say, oh, we're for an open Internet, what they're really saying is, we're for an open Internet because we can make the rules. And we said, no, we think that the representative of the consumer ought to make those rules. HU: Tom Wheeler served as chairman of the Federal Communications Commission from November 2013 to January of this year. He's now a fellow at the Harvard Kennedy School of Government. Tom Wheeler, thanks for coming on the program. WHEELER: Thanks, Elise.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-11-24-566387375": {"title": "Why 'Star Wars Battlefront II' Is Creating Such A Big Debate In The Gaming World : NPR", "url": "https://www.npr.org/2017/11/24/566387375/why-star-wars-battlefront-ii-is-creating-such-a-big-debate-in-the-gaming-world", "author": "No author found", "published_date": "2017-11-24", "content": "ARI SHAPIRO, HOST: One of the most anticipated video games of the year has created a huge debate that is reaching beyond the world of gamers into government policy. The game is \"Star Wars Battlefront II. \" And the debate has to do with one of the ways the game creators are trying to make money. Allegra Frank is with the video game news site Polygon and joins us now. Welcome. ALLEGRA FRANK: Hi. Thanks for having me. SHAPIRO: This controversy has to do with something called loot crates, which is basically an industry term for paying to advance in a game. Tell us how it works. FRANK: Right. So they're sort of akin to gambling. Essentially, you pay for a loot crate and inside of a loot crate is a random item. These can be costumes. These can be different attacks or abilities for your characters to make you stronger in the game. It's a variety of things. But the main issue with loot crates is that you never know what you're going to get. It's completely random. SHAPIRO: Purchases in a game are pretty common in smartphone apps or Facebook games, which are usually free or cost very little to play. Why is it so much more controversial in the \"Star Wars\" video game? FRANK: So in \"Star Wars Battlefront II,\" people really sort of got fed up and threw up their hands because loot crates don't only include costumes, which you don't need to have, but they actually include different sorts of items that help you in other modes that will put you against other players. So essentially, there are modes where you have to compete with other people. And if people are willing to spend the money to get those extra items that power them up and give them an advantage, essentially, in the game and you're not willing to spend that money, you will not win. And that is not a lot of fun for people. SHAPIRO: So part of the outrage was from gamers who said, I already spent $60 on this game. I don't want to have to spend more to advance through the levels. Separately, politicians started expressing concern that the game is encouraging gambling. Tell us what's happening in the government related to this game. FRANK: Right. So we're actually seeing two major fronts of politicians speaking out against these. In Belgium, there's the Belgian Gambling Commission, which is actually pointing at certain examples of different games saying these economies are really akin to gambling and sort of investigating those. And then earlier this week we had a Hawaiian rep, Representative Chris Lee, actually say a similar thing of - you know, it's sort of akin to gambling is essentially what he's saying. So we have these high-profile cases now. And one of the major issues here is that these are games that children have access to. So the fact that these games have systems very much similar to gambling and that children can play them is not really sitting well with different government officials and the public at large, frankly. SHAPIRO: How has Electronic Arts, the company behind the game, responded to all of this? FRANK: The first step that EA took is they slashed the prices of some of the characters that were locked behind these loot crates - There were certain characters like Darth Vader that would require a ton of in-game currency or real money to actually access - which didn't exactly sate the fanbase because you still could spend a ton of money trying to get Darth Vader even with the discount. On the night before launch they actually said, we're going to take out the paid economy entirely and try and rework it - they saw all this consumer feedback - and then bring it back into the game at some undefined date. SHAPIRO: Is this just the future of game play and gamers are fighting against a tide? Or do you think Electronic Arts has really been burned with this and other game creators are going to take note and change plans? FRANK: It's interesting to see because microtransactions, loot crates and in-game purchases, that's nothing new. And this isn't even necessarily the most egregious example. I think it's just sort of been the apex. This is sort of representative of the apex of, as you said, a rising tide. So it will be interesting to see if other publishers are sort of going to shy away from the reliance on paid economies. But I doubt they'll actually go away because the way that these games can maintain their longevity for the publisher and the player is introducing additional amounts of content. And oftentimes to recoup the development costs, publishers are sort of - their hands are forced. They have to charge money for these. SHAPIRO: Allegra Frank of the video game news site Polygon, thanks a lot. FRANK: Thanks for having me. ARI SHAPIRO, HOST:  One of the most anticipated video games of the year has created a huge debate that is reaching beyond the world of gamers into government policy. The game is \"Star Wars Battlefront II. \" And the debate has to do with one of the ways the game creators are trying to make money. Allegra Frank is with the video game news site Polygon and joins us now. Welcome. ALLEGRA FRANK: Hi. Thanks for having me. SHAPIRO: This controversy has to do with something called loot crates, which is basically an industry term for paying to advance in a game. Tell us how it works. FRANK: Right. So they're sort of akin to gambling. Essentially, you pay for a loot crate and inside of a loot crate is a random item. These can be costumes. These can be different attacks or abilities for your characters to make you stronger in the game. It's a variety of things. But the main issue with loot crates is that you never know what you're going to get. It's completely random. SHAPIRO: Purchases in a game are pretty common in smartphone apps or Facebook games, which are usually free or cost very little to play. Why is it so much more controversial in the \"Star Wars\" video game? FRANK: So in \"Star Wars Battlefront II,\" people really sort of got fed up and threw up their hands because loot crates don't only include costumes, which you don't need to have, but they actually include different sorts of items that help you in other modes that will put you against other players. So essentially, there are modes where you have to compete with other people. And if people are willing to spend the money to get those extra items that power them up and give them an advantage, essentially, in the game and you're not willing to spend that money, you will not win. And that is not a lot of fun for people. SHAPIRO: So part of the outrage was from gamers who said, I already spent $60 on this game. I don't want to have to spend more to advance through the levels. Separately, politicians started expressing concern that the game is encouraging gambling. Tell us what's happening in the government related to this game. FRANK: Right. So we're actually seeing two major fronts of politicians speaking out against these. In Belgium, there's the Belgian Gambling Commission, which is actually pointing at certain examples of different games saying these economies are really akin to gambling and sort of investigating those. And then earlier this week we had a Hawaiian rep, Representative Chris Lee, actually say a similar thing of - you know, it's sort of akin to gambling is essentially what he's saying. So we have these high-profile cases now. And one of the major issues here is that these are games that children have access to. So the fact that these games have systems very much similar to gambling and that children can play them is not really sitting well with different government officials and the public at large, frankly. SHAPIRO: How has Electronic Arts, the company behind the game, responded to all of this? FRANK: The first step that EA took is they slashed the prices of some of the characters that were locked behind these loot crates - There were certain characters like Darth Vader that would require a ton of in-game currency or real money to actually access - which didn't exactly sate the fanbase because you still could spend a ton of money trying to get Darth Vader even with the discount. On the night before launch they actually said, we're going to take out the paid economy entirely and try and rework it - they saw all this consumer feedback - and then bring it back into the game at some undefined date. SHAPIRO: Is this just the future of game play and gamers are fighting against a tide? Or do you think Electronic Arts has really been burned with this and other game creators are going to take note and change plans? FRANK: It's interesting to see because microtransactions, loot crates and in-game purchases, that's nothing new. And this isn't even necessarily the most egregious example. I think it's just sort of been the apex. This is sort of representative of the apex of, as you said, a rising tide. So it will be interesting to see if other publishers are sort of going to shy away from the reliance on paid economies. But I doubt they'll actually go away because the way that these games can maintain their longevity for the publisher and the player is introducing additional amounts of content. And oftentimes to recoup the development costs, publishers are sort of - their hands are forced. They have to charge money for these. SHAPIRO: Allegra Frank of the video game news site Polygon, thanks a lot. FRANK: Thanks for having me.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-11-24-565673749": {"title": "NASA Uses Students To Develop Virtual Reality Programs : NPR", "url": "https://www.npr.org/2017/11/24/565673749/nasa-taps-young-people-to-help-develop-virtual-reality-technology", "author": "No author found", "published_date": "2017-11-24", "content": "NOEL KING, HOST: NASA has high hopes for virtual reality and wants to use VR for everything - from geological research to fixing satellites. And to that end, they are tapping some new talent - high school students. NPR's Rebecca Hersher has the story. REBECCA HERSHER, BYLINE: Jackson Ames is a senior in Maryland, and one of his hobbies is video games. JACKSON AMES: A lot of games that involve strategy and teamwork. One of my favorite ones is something called \"Onward. \"(SOUNDBITE OF FIREARMS FIRING)HERSHER: Onward is a virtual reality war game. It's supposed to make players feel like they're soldiers fighting a battle. You play with a headset, headphones, a controller in each hand. And everything about it is hyper-realistic. AMES: Yeah, it's much more realistic than anything else. It adds a whole new layer. HERSHER: Ames is 17. He feels totally at home with virtual reality technology. He can't even remember a time when he didn't use computers. Armed with his love of VR and some actual coding skills from high school classes, Ames landed an internship over the summer at NASA's Goddard Space Flight Center. And the guy who hired him is a NASA engineer named Thomas Grubb. Grubb used to play video games as a teenager back in the '80s. But there's just no time for that anymore. And he was really just looking for basic cheap labor to help out on some virtual reality projects. THOMAS GRUBB: I went into this with, like, OK, I'll take a couple interns or whatever. HERSHER: He thought he'd get a college student to help out with debugging and stuff. But when he posted the job. . . GRUBB: I got all these amazing students coming back. And I was like, I want more than this. I ended up with five. HERSHER: And they were super valuable because they understand what works and what doesn't in the virtual world. NASA has some pretty big ambitions for what it wants to do with VR - repair technicians in VR headsets on Earth fixing orbiting satellites in real time, scientists exploring remote locations from their offices. Like the inside of an ancient volcano - that's the program that I tried. GRUBB: All right, so let's put - and it should fit snugly without being too tight. HERSHER: I'm a little nervous about it honestly. GRUBB: I think you'll be OK. But there is definitely some older. . . HERSHER: Now, I'm 28. I'm not a technological dinosaur - at least not yet. Here we go. But honestly, I found the virtual lava tube highly alarming. At first, I felt like I couldn't move at all. No, no, no. Wow. Then when I finally did, I was just bumbling around in this virtual cave. Here we are inside - rocks of the lava tube, the sky above. The real cave is in Idaho. The virtual gray rocks look pixilated, but you still get dizzy looking up. The lava tube is really tall. I can kneel down and virtually measure boulders - at least theoretically, if I can get my body to move right. This is a little weird. How do gamers do it? When I asked Jackson Ames about it, he can barely cover up his impatience. AMES: Well, it's just - I think that it's the future because we've been stuck with using 2-D screens for 30 years (laughter) or something like that. HERSHER: And Grubb agrees. He thinks even if the technology has a learning curve, VR can definitely be helpful for research. GRUBB: You know, it's cheaper to have people go to a lava tube in VR than to actually fly them out there for two weeks and everything else. All of these things can save a lot of money or time - or just enable new things. HERSHER: In a few years, he hopes even the most seasoned NASA scientists will be strapping on virtual reality headsets at work. Rebecca Hersher, NPR News. (SOUNDBITE OF MUSIC) NOEL KING, HOST:  NASA has high hopes for virtual reality and wants to use VR for everything - from geological research to fixing satellites. And to that end, they are tapping some new talent - high school students. NPR's Rebecca Hersher has the story. REBECCA HERSHER, BYLINE: Jackson Ames is a senior in Maryland, and one of his hobbies is video games. JACKSON AMES: A lot of games that involve strategy and teamwork. One of my favorite ones is something called \"Onward. \" (SOUNDBITE OF FIREARMS FIRING) HERSHER: Onward is a virtual reality war game. It's supposed to make players feel like they're soldiers fighting a battle. You play with a headset, headphones, a controller in each hand. And everything about it is hyper-realistic. AMES: Yeah, it's much more realistic than anything else. It adds a whole new layer. HERSHER: Ames is 17. He feels totally at home with virtual reality technology. He can't even remember a time when he didn't use computers. Armed with his love of VR and some actual coding skills from high school classes, Ames landed an internship over the summer at NASA's Goddard Space Flight Center. And the guy who hired him is a NASA engineer named Thomas Grubb. Grubb used to play video games as a teenager back in the '80s. But there's just no time for that anymore. And he was really just looking for basic cheap labor to help out on some virtual reality projects. THOMAS GRUBB: I went into this with, like, OK, I'll take a couple interns or whatever. HERSHER: He thought he'd get a college student to help out with debugging and stuff. But when he posted the job. . . GRUBB: I got all these amazing students coming back. And I was like, I want more than this. I ended up with five. HERSHER: And they were super valuable because they understand what works and what doesn't in the virtual world. NASA has some pretty big ambitions for what it wants to do with VR - repair technicians in VR headsets on Earth fixing orbiting satellites in real time, scientists exploring remote locations from their offices. Like the inside of an ancient volcano - that's the program that I tried. GRUBB: All right, so let's put - and it should fit snugly without being too tight. HERSHER: I'm a little nervous about it honestly. GRUBB: I think you'll be OK. But there is definitely some older. . . HERSHER: Now, I'm 28. I'm not a technological dinosaur - at least not yet. Here we go. But honestly, I found the virtual lava tube highly alarming. At first, I felt like I couldn't move at all. No, no, no. Wow. Then when I finally did, I was just bumbling around in this virtual cave. Here we are inside - rocks of the lava tube, the sky above. The real cave is in Idaho. The virtual gray rocks look pixilated, but you still get dizzy looking up. The lava tube is really tall. I can kneel down and virtually measure boulders - at least theoretically, if I can get my body to move right. This is a little weird. How do gamers do it? When I asked Jackson Ames about it, he can barely cover up his impatience. AMES: Well, it's just - I think that it's the future because we've been stuck with using 2-D screens for 30 years (laughter) or something like that. HERSHER: And Grubb agrees. He thinks even if the technology has a learning curve, VR can definitely be helpful for research. GRUBB: You know, it's cheaper to have people go to a lava tube in VR than to actually fly them out there for two weeks and everything else. All of these things can save a lot of money or time - or just enable new things. HERSHER: In a few years, he hopes even the most seasoned NASA scientists will be strapping on virtual reality headsets at work. Rebecca Hersher, NPR News. (SOUNDBITE OF MUSIC)", "section": "Science", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-11-25-558027840": {"title": "The Left-Wing Tech Investor Running For Governor : NPR", "url": "https://www.npr.org/2017/11/25/558027840/the-left-wing-tech-investor-running-for-governor", "author": "No author found", "published_date": "2017-11-25", "content": "", "section": "Politics", "disclaimer": ""}, "2017-11-25-566438811": {"title": "What's Next For Net Neutrality : NPR", "url": "https://www.npr.org/2017/11/25/566438811/whats-next-for-net-neutrality", "author": "No author found", "published_date": "2017-11-25", "content": "SCOTT SIMON, HOST:  One topic of conversation that maybe didn't make it to your Thanksgiving table is net neutrality. It's an issue that affects us all. Current regulations on Internet service providers bar them from deciding how you access the Web. That means they can't block your access to certain websites or make you pay fees or slow your ability to reach certain content online. The FCC is expected to remove those regulations next month. Now, we should note that NPR's legal counsel has filed comments with the FCC against deregulation. We're joined now by Ina Fried, chief technology correspondent at Axios - joins us from San Francisco. Thanks so much for being with us. INA FRIED: Thanks, Scott. SIMON: I think a lot of people haven't understood until recently that we have a neutral net. FRIED: Yeah. This is something that came about during the Obama administration. I think if you polled people at the time, many people would have thought we already had it. We actually didn't have those rules. But they put in place these rules that were designed to prevent those sorts of slowing down or prioritizing from ever happening. SIMON: What will that landscape look like if the regulations are removed? FRIED: Well, we really don't know. I mean, that is the $64,000 - or, actually, in the billions of dollars - question. Is the current marketplace strong enough that we don't need these rules, or will we see some of the things that happen in other countries, where if you want unlimited Netflix, you not only have to pay Netflix, but you have to pay more to your Internet service provider or where they can speed up their traffic? So if you're AT&T, and you own DirecTV, they can speed the DirecTV content but slow rival video content. And that's a prospect that has a lot of people worried. SIMON: The chairman of the FCC, Ajit Pai, was on Morning Edition this week. And he argument (ph) that the free market approach to the Internet in the 1990s made sense. (SOUNDBITE OF ARCHIVED BROADCAST)AJIT PAI: We saw $1. 5 trillion of investment in networks. We saw companies like Facebook and Amazon and Google become global powerhouses precisely because we had light-touch rules that applied to this Internet. SIMON: And what do you think of that argument now? FRIED: Well, I think, in retrospect, we can say yes, it worked out pretty well. I think the question is, would it still work out well in the future? And it might well. I think the concern is that it might not. Why are we taking away rules that protect the internet on the hope that things will continue to work out? SIMON: There are lots of people who are concerned that there'll be what amounts to second- and third-class citizenship on the net. FRIED: Again, I think that might be a little less likely. It is one of the fears - is that some of the big internet content providers can pay for the best access. And if you are a small news provider, if you're a small music service, if you are a small social network - that you won't be able to pay to have the best service, and it will make it harder to compete. I think the chairman is right that, you know, in the past, the Internet did not suffer before these rules. I think it's tough to make the case that before net neutrality rules were put in place - that the Internet suffered. Obviously, it flourished. I think the question is, when you have it in the control of a few carriers, will things continue to be good just because? And I think that's a really tough question to answer. So I think a lot of people are like, let's not take away these rules. SIMON: Can Congress do something? FRIED: They can. And, in fact, a lot of people on both sides would like to see Congress do it, precisely so we don't have what we've had in the last couple years. Obama is president. There's net neutrality rules. Trump comes in. Those rules get repealed. There may be pressure on both sides to say, look, let's not revisit this every presidential administration. Let's have a set of rules that we all can live with that are consistent and permanent. And I think that might be a good outcome for everyone. SIMON: Ina Fried, chief technology correspondent with Axios, who joined us by Skype, thanks so much for being with us. FRIED: Thanks, Scott. SCOTT SIMON, HOST:   One topic of conversation that maybe didn't make it to your Thanksgiving table is net neutrality. It's an issue that affects us all. Current regulations on Internet service providers bar them from deciding how you access the Web. That means they can't block your access to certain websites or make you pay fees or slow your ability to reach certain content online. The FCC is expected to remove those regulations next month. Now, we should note that NPR's legal counsel has filed comments with the FCC against deregulation. We're joined now by Ina Fried, chief technology correspondent at Axios - joins us from San Francisco. Thanks so much for being with us. INA FRIED: Thanks, Scott. SIMON: I think a lot of people haven't understood until recently that we have a neutral net. FRIED: Yeah. This is something that came about during the Obama administration. I think if you polled people at the time, many people would have thought we already had it. We actually didn't have those rules. But they put in place these rules that were designed to prevent those sorts of slowing down or prioritizing from ever happening. SIMON: What will that landscape look like if the regulations are removed? FRIED: Well, we really don't know. I mean, that is the $64,000 - or, actually, in the billions of dollars - question. Is the current marketplace strong enough that we don't need these rules, or will we see some of the things that happen in other countries, where if you want unlimited Netflix, you not only have to pay Netflix, but you have to pay more to your Internet service provider or where they can speed up their traffic? So if you're AT&T, and you own DirecTV, they can speed the DirecTV content but slow rival video content. And that's a prospect that has a lot of people worried. SIMON: The chairman of the FCC, Ajit Pai, was on Morning Edition this week. And he argument (ph) that the free market approach to the Internet in the 1990s made sense. (SOUNDBITE OF ARCHIVED BROADCAST) AJIT PAI: We saw $1. 5 trillion of investment in networks. We saw companies like Facebook and Amazon and Google become global powerhouses precisely because we had light-touch rules that applied to this Internet. SIMON: And what do you think of that argument now? FRIED: Well, I think, in retrospect, we can say yes, it worked out pretty well. I think the question is, would it still work out well in the future? And it might well. I think the concern is that it might not. Why are we taking away rules that protect the internet on the hope that things will continue to work out? SIMON: There are lots of people who are concerned that there'll be what amounts to second- and third-class citizenship on the net. FRIED: Again, I think that might be a little less likely. It is one of the fears - is that some of the big internet content providers can pay for the best access. And if you are a small news provider, if you're a small music service, if you are a small social network - that you won't be able to pay to have the best service, and it will make it harder to compete. I think the chairman is right that, you know, in the past, the Internet did not suffer before these rules. I think it's tough to make the case that before net neutrality rules were put in place - that the Internet suffered. Obviously, it flourished. I think the question is, when you have it in the control of a few carriers, will things continue to be good just because? And I think that's a really tough question to answer. So I think a lot of people are like, let's not take away these rules. SIMON: Can Congress do something? FRIED: They can. And, in fact, a lot of people on both sides would like to see Congress do it, precisely so we don't have what we've had in the last couple years. Obama is president. There's net neutrality rules. Trump comes in. Those rules get repealed. There may be pressure on both sides to say, look, let's not revisit this every presidential administration. Let's have a set of rules that we all can live with that are consistent and permanent. And I think that might be a good outcome for everyone. SIMON: Ina Fried, chief technology correspondent with Axios, who joined us by Skype, thanks so much for being with us. FRIED: Thanks, Scott.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-11-26-556090186": {"title": "Is The Streetwear Market Headed For The Mainstream?  : NPR", "url": "https://www.npr.org/2017/11/26/556090186/is-the-streetwear-market-headed-for-the-mainstream", "author": "No author found", "published_date": "2017-11-26", "content": "", "section": "Business", "disclaimer": ""}, "2017-11-26-566566932": {"title": "Studying Artificial Intelligence At New York University : NPR", "url": "https://www.npr.org/2017/11/26/566566932/studying-artificial-intelligence-at-new-york-university", "author": "No author found", "published_date": "2017-11-26", "content": "LINDA WERTHEIMER, HOST:  Artificial intelligence is increasingly a part of our daily lives. It helps run our search engines, populating our Facebook feeds. It lets us interact with Siri and Alexa. But the powerful algorithms and predictive systems that make up AI are playing a deeper role in society with some serious implications. Professor Kate Crawford is co-founder of New York University's new AI Now Institute. She says, you're seeing AI at work in health care, education, even criminal justice. (SOUNDBITE OF ARCHIVED RECORDING)KATE CRAWFORD: Criminal justice has sort of very early-stage algorithmic systems that are already being brought to bear. So if we take, for example, courtroom settings, we have predictive risk algorithms that are being used to assist judges in deciding whether or not somebody is high risk for re-offense or low risk. But as we saw in a recent investigation by ProPublica, these systems are already producing twice the false positive rates for black defendants as they are for white defendants. WERTHEIMER: Can you give us a sense of what creates biases in algorithms? And maybe you could give us an example. CRAWFORD: Often, a common cause is the data that's used to train a system. So if we take, for example, a predictive policing system - would be trained on a lot of data about crimes and arrests. And that makes sense. I mean, that's an important data set. But we could also look to the history of who tends to be arrested and who tends to be approached by the police. And we can see that there is also a racial history there and an issue for low-income communities, which is different to those in high-income categories. So they're the types of biases that I think concern us the most. WERTHEIMER: As a civilian in this area, we have no idea how many algorithms are sorting us out as we move through our lives. Is there something, as consumers of information, we should be aware of, we should watch out for? CRAWFORD: I think there's a lot we can do. For example, we're starting to see a lot of early AI systems being applied in hiring in HR. And I think many people, you know, when you're - taking a job interview for example, you don't necessarily ask to say, oh, you know, how am I being assessed here? But these kinds of questions, I think, will become increasingly important as we start to see algorithmic systems have a greater role in decision making. WERTHEIMER: I was thinking about law firms, which, for many years, promoted men. I wonder if that's the kind of thing you mean that would come out of the machine instead of out of the partners of the law firm. CRAWFORD: Yeah, precisely. And let me give you an example. There's a new system that many companies are using right now, which is called HireVue. And what it does is it essentially records a person while they're doing a job interview and then looks at that footage to assess things like - what sorts of gestures do they use? What words do they use? How frequently do they pause? Very, very intimate analyses which they then use to match to their most successful employees. Now, that might make sense. You might say, yes, we want to replicate our most successful employees. But the downside is if that becomes a type of ingrained form of bias - that you're really just, you know, replicating people who already look like and sound like the people at the top of your company. So I think there's a tendency - it's often called automation bias - that we assume that an algorithmic system must be coming up with a more objective or a better result than a human. But that is not necessarily the case. WERTHEIMER: Now, you worked at Microsoft for a long time. So you. . . CRAWFORD: I still do. Yeah, absolutely. WERTHEIMER: You have considerable insight into the industry that is creating these algorithms. Do you think that in the rush to invent new products, they are overlooking questions like the ones you were just raising? Or is this happening deliberately? CRAWFORD: It's certainly not deliberate. But the thing that's really motivated me and my colleagues in setting up the AI Now Institute is that those are seen very much as sort of technical problems. But in actual fact, what these systems are showing us is that data sets are always functions of human history. They reflect who we are. So in many ways, we have to think about these problems as social problems first, not technical. And so for us, that means bringing a lot more disciplines into the room. That means sociology. It means law. It means anthropology, philosophy and history. We can actually learn a lot from these much longer-term studies of how humans interact and how social change occurs. Unfortunately, at the moment, a lot of those decisions are being made by people whose training is purely technical. And in the same way that we wouldn't expect a judge to tune a technical system, we shouldn't be expecting an engineer to understand the intricacies of the criminal justice system. WERTHEIMER: Professor Kate Crawford is co-founder of NYU's just-opened AI Now Institute. Thank you very much. CRAWFORD: It's a pleasure, Linda. LINDA WERTHEIMER, HOST:   Artificial intelligence is increasingly a part of our daily lives. It helps run our search engines, populating our Facebook feeds. It lets us interact with Siri and Alexa. But the powerful algorithms and predictive systems that make up AI are playing a deeper role in society with some serious implications. Professor Kate Crawford is co-founder of New York University's new AI Now Institute. She says, you're seeing AI at work in health care, education, even criminal justice. (SOUNDBITE OF ARCHIVED RECORDING) KATE CRAWFORD: Criminal justice has sort of very early-stage algorithmic systems that are already being brought to bear. So if we take, for example, courtroom settings, we have predictive risk algorithms that are being used to assist judges in deciding whether or not somebody is high risk for re-offense or low risk. But as we saw in a recent investigation by ProPublica, these systems are already producing twice the false positive rates for black defendants as they are for white defendants. WERTHEIMER: Can you give us a sense of what creates biases in algorithms? And maybe you could give us an example. CRAWFORD: Often, a common cause is the data that's used to train a system. So if we take, for example, a predictive policing system - would be trained on a lot of data about crimes and arrests. And that makes sense. I mean, that's an important data set. But we could also look to the history of who tends to be arrested and who tends to be approached by the police. And we can see that there is also a racial history there and an issue for low-income communities, which is different to those in high-income categories. So they're the types of biases that I think concern us the most. WERTHEIMER: As a civilian in this area, we have no idea how many algorithms are sorting us out as we move through our lives. Is there something, as consumers of information, we should be aware of, we should watch out for? CRAWFORD: I think there's a lot we can do. For example, we're starting to see a lot of early AI systems being applied in hiring in HR. And I think many people, you know, when you're - taking a job interview for example, you don't necessarily ask to say, oh, you know, how am I being assessed here? But these kinds of questions, I think, will become increasingly important as we start to see algorithmic systems have a greater role in decision making. WERTHEIMER: I was thinking about law firms, which, for many years, promoted men. I wonder if that's the kind of thing you mean that would come out of the machine instead of out of the partners of the law firm. CRAWFORD: Yeah, precisely. And let me give you an example. There's a new system that many companies are using right now, which is called HireVue. And what it does is it essentially records a person while they're doing a job interview and then looks at that footage to assess things like - what sorts of gestures do they use? What words do they use? How frequently do they pause? Very, very intimate analyses which they then use to match to their most successful employees. Now, that might make sense. You might say, yes, we want to replicate our most successful employees. But the downside is if that becomes a type of ingrained form of bias - that you're really just, you know, replicating people who already look like and sound like the people at the top of your company. So I think there's a tendency - it's often called automation bias - that we assume that an algorithmic system must be coming up with a more objective or a better result than a human. But that is not necessarily the case. WERTHEIMER: Now, you worked at Microsoft for a long time. So you. . . CRAWFORD: I still do. Yeah, absolutely. WERTHEIMER: You have considerable insight into the industry that is creating these algorithms. Do you think that in the rush to invent new products, they are overlooking questions like the ones you were just raising? Or is this happening deliberately? CRAWFORD: It's certainly not deliberate. But the thing that's really motivated me and my colleagues in setting up the AI Now Institute is that those are seen very much as sort of technical problems. But in actual fact, what these systems are showing us is that data sets are always functions of human history. They reflect who we are. So in many ways, we have to think about these problems as social problems first, not technical. And so for us, that means bringing a lot more disciplines into the room. That means sociology. It means law. It means anthropology, philosophy and history. We can actually learn a lot from these much longer-term studies of how humans interact and how social change occurs. Unfortunately, at the moment, a lot of those decisions are being made by people whose training is purely technical. And in the same way that we wouldn't expect a judge to tune a technical system, we shouldn't be expecting an engineer to understand the intricacies of the criminal justice system. WERTHEIMER: Professor Kate Crawford is co-founder of NYU's just-opened AI Now Institute. Thank you very much. CRAWFORD: It's a pleasure, Linda.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-11-27-566808641": {"title": "How Tech Companies Are Catering To Generation Z Teens : NPR", "url": "https://www.npr.org/2017/11/27/566808641/how-tech-companies-are-catering-to-generation-z-teens", "author": "No author found", "published_date": "2017-11-27", "content": "KELLY MCEVERS, HOST: Today is Cyber Monday, and on this week's All Tech Considered we're going to talk about how retailers are going after a key group of consumers - kids. (SOUNDBITE OF MUSIC)MCEVERS: Generation Z, or Americans who were born after 1995, spend $44 billion a year. And Amazon has a new tool to make it easier for teenagers to spend money online. And to talk about this we are joined by Karl Haller of IBM. Thanks for being on the show. KARL HALLER: Thank you. MCEVERS: First, what exactly is Amazon doing? HALLER: Amazon is enabling teens to do something that they've done for years, which is spend their parents' money. Twenty years ago, 30 years ago, that was with cash or with a borrowed credit card in the mall. And when you look at the importance of Generation Z, there are 80 million of them in the U. S. As you mentioned, they spend nearly $50 billion. And they influence spending probably at a level of 10 times or more what they spend themselves. This is a very important generation. So they've introduced something called amazon. com for teens. Teens can sign up with guidelines set by their parents and make purchases directly off of their parents' Amazon account. MCEVERS: So let's say I've got an Amazon Prime account and my 15-year-old, if I had one, wanted to use it. Like, how would that work? HALLER: So the parent would be able to set up the teen with an account, and then the teen would be able to log in with a custom logon ID and browse and make purchases directly on the Amazon app and that the parent then could review and approve purchases based on a variety of preset levels. MCEVERS: We should say here that Amazon is one of NPR's financial supporters. But I'm wondering if you could explain the company's strategy here. I mean, is it just as simple as, you know, trying to get more customers? I mean, there's already so many people who use Amazon. HALLER: Well, if you think about it from Amazon's perspective, the online world still requires customers to have credit cards. Most teens do not yet have - or many teens at least do not yet have their own credit cards. So this is a way for Amazon, again, to tap into a market that was probably one of the few untouched markets that they could tap into. MCEVERS: If you think about those stores in the mall where teenagers used to spend their money or their parents' money, are they still competing for the business of Generation Z or are they losing out to online services? HALLER: Well, definitely I think the stores in the mall still compete for Gen Z just as they compete for all consumers. You know, there have been - there's been a lot written about, you know, the death of retail and the retail apocalypse. MCEVERS: Yeah. HALLER: But it's important to remember that about 90 cents out of every dollar still is spent in a physical store, at least in the U. S. MCEVERS: Oh, wow. HALLER: And if you think about the categories that Amazon has as its strengths, teen clothing is not necessarily one of them. And there's plenty of room still for many different competitors to go after the Gen Z spending. MCEVERS: Karl Haller is a partner with IBM's Global Consumer Industry team. Thank you so much. HALLER: Thank you. (SOUNDBITE OF MINOTAUR SHOCK'S \"MY BURR\") KELLY MCEVERS, HOST:  Today is Cyber Monday, and on this week's All Tech Considered we're going to talk about how retailers are going after a key group of consumers - kids. (SOUNDBITE OF MUSIC) MCEVERS: Generation Z, or Americans who were born after 1995, spend $44 billion a year. And Amazon has a new tool to make it easier for teenagers to spend money online. And to talk about this we are joined by Karl Haller of IBM. Thanks for being on the show. KARL HALLER: Thank you. MCEVERS: First, what exactly is Amazon doing? HALLER: Amazon is enabling teens to do something that they've done for years, which is spend their parents' money. Twenty years ago, 30 years ago, that was with cash or with a borrowed credit card in the mall. And when you look at the importance of Generation Z, there are 80 million of them in the U. S. As you mentioned, they spend nearly $50 billion. And they influence spending probably at a level of 10 times or more what they spend themselves. This is a very important generation. So they've introduced something called amazon. com for teens. Teens can sign up with guidelines set by their parents and make purchases directly off of their parents' Amazon account. MCEVERS: So let's say I've got an Amazon Prime account and my 15-year-old, if I had one, wanted to use it. Like, how would that work? HALLER: So the parent would be able to set up the teen with an account, and then the teen would be able to log in with a custom logon ID and browse and make purchases directly on the Amazon app and that the parent then could review and approve purchases based on a variety of preset levels. MCEVERS: We should say here that Amazon is one of NPR's financial supporters. But I'm wondering if you could explain the company's strategy here. I mean, is it just as simple as, you know, trying to get more customers? I mean, there's already so many people who use Amazon. HALLER: Well, if you think about it from Amazon's perspective, the online world still requires customers to have credit cards. Most teens do not yet have - or many teens at least do not yet have their own credit cards. So this is a way for Amazon, again, to tap into a market that was probably one of the few untouched markets that they could tap into. MCEVERS: If you think about those stores in the mall where teenagers used to spend their money or their parents' money, are they still competing for the business of Generation Z or are they losing out to online services? HALLER: Well, definitely I think the stores in the mall still compete for Gen Z just as they compete for all consumers. You know, there have been - there's been a lot written about, you know, the death of retail and the retail apocalypse. MCEVERS: Yeah. HALLER: But it's important to remember that about 90 cents out of every dollar still is spent in a physical store, at least in the U. S. MCEVERS: Oh, wow. HALLER: And if you think about the categories that Amazon has as its strengths, teen clothing is not necessarily one of them. And there's plenty of room still for many different competitors to go after the Gen Z spending. MCEVERS: Karl Haller is a partner with IBM's Global Consumer Industry team. Thank you so much. HALLER: Thank you. (SOUNDBITE OF MINOTAUR SHOCK'S \"MY BURR\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-11-28-564713772": {"title": "Supreme Court Weighs Police Tracking Of Cellphones Without A Warrant : NPR", "url": "https://www.npr.org/2017/11/28/564713772/can-police-track-you-through-your-cellphone-without-a-warrant", "author": "No author found", "published_date": "2017-11-28", "content": "", "section": "Politics", "disclaimer": ""}, "2017-11-29-567348000": {"title": "Justices May Impose New Limits On Government Access To Cellphone Data : NPR", "url": "https://www.npr.org/2017/11/29/567348000/justices-may-impose-new-limits-on-government-access-to-cellphone-data", "author": "No author found", "published_date": "2017-11-29", "content": "", "section": "Law", "disclaimer": ""}, "2017-11-30-567240968": {"title": "'Chaos' Is At The Heart Of The Trump Camp's Defense About Russia. But It Can Cut Both Ways : NPR", "url": "https://www.npr.org/2017/11/30/567240968/chaos-is-at-the-heart-of-the-trump-camps-defense-but-it-can-cut-both-ways", "author": "No author found", "published_date": "2017-11-30", "content": "", "section": "National Security", "disclaimer": ""}, "2017-12-02-567847567": {"title": "Trump Retweeted A Racist Group, But How Did He Find Its Videos? : NPR", "url": "https://www.npr.org/2017/12/02/567847567/trump-retweeted-a-racist-group-but-how-did-he-get-their-videos", "author": "No author found", "published_date": "2017-12-02", "content": "SCOTT SIMON, HOST: This week, the president of the United States passed along malicious messages from a racist, ultranationalist fringe group directly to 44 million people. Those 44 million follow him on Twitter and may have now retweeted those anti-Muslim messages to millions more. The president tweeted three videos posted by a leader of the group Britain First. All the videos blame Muslims for crimes or offenses. But within hours, they were shown to make claims that are either false or wrenched out of context. Prime Minister Theresa May's office said Britain First seeks to divide communities through their use of hateful narratives that stoke tensions. It's as if the British prime minister had passed along a tweet from David Duke, who, by the way, saw the Britain First videos and tweeted, thank God for Trump. That's why we love him. The videos are anti-Muslim screeds you would hope a middle-school student would recognize as unfounded and inflammatory. But they were tweeted without skepticism or comment by the president of the United States. The president has one of the largest Twitter followings in the world, though not as large, it may pain him to admit, as Katy Perry, Lady Gaga, Barack Obama or Shakira. He boasts that tweeting directly to 44 million people enables him to reach the public without journalism getting in the way. He does not retweet cute cat or recipe videos or opinions that don't amplify his own. Sarah Huckabee Sanders, the White House press secretary, told reporters the president may not know much about Britain First but said, look, I think what he's done is elevate the conversation to talk about a real issue and a real threat. Britain First, which habitually wins less than 1 percent of the vote in elections, thanked the president for elevating their party onto the world stage. How did the president even come across Britain First? I found the group on Twitter and, within seconds, received suggestions from the algorithms for other hypernationalist groups. That's how the platform works. If you look up cute cat videos - and I do - they put other cute animal videos into what you see on Twitter. The president may not have known about Britain First, but algorithms deliver their messages to the president based on what he reads on Twitter. No matter how many thoughtful people are put on the White House staff, the president may be getting his information about vital issues like immigration 280 characters or one deceptive video after another at a time. (SOUNDBITE OF MUSIC) SCOTT SIMON, HOST:  This week, the president of the United States passed along malicious messages from a racist, ultranationalist fringe group directly to 44 million people. Those 44 million follow him on Twitter and may have now retweeted those anti-Muslim messages to millions more. The president tweeted three videos posted by a leader of the group Britain First. All the videos blame Muslims for crimes or offenses. But within hours, they were shown to make claims that are either false or wrenched out of context. Prime Minister Theresa May's office said Britain First seeks to divide communities through their use of hateful narratives that stoke tensions. It's as if the British prime minister had passed along a tweet from David Duke, who, by the way, saw the Britain First videos and tweeted, thank God for Trump. That's why we love him. The videos are anti-Muslim screeds you would hope a middle-school student would recognize as unfounded and inflammatory. But they were tweeted without skepticism or comment by the president of the United States. The president has one of the largest Twitter followings in the world, though not as large, it may pain him to admit, as Katy Perry, Lady Gaga, Barack Obama or Shakira. He boasts that tweeting directly to 44 million people enables him to reach the public without journalism getting in the way. He does not retweet cute cat or recipe videos or opinions that don't amplify his own. Sarah Huckabee Sanders, the White House press secretary, told reporters the president may not know much about Britain First but said, look, I think what he's done is elevate the conversation to talk about a real issue and a real threat. Britain First, which habitually wins less than 1 percent of the vote in elections, thanked the president for elevating their party onto the world stage. How did the president even come across Britain First? I found the group on Twitter and, within seconds, received suggestions from the algorithms for other hypernationalist groups. That's how the platform works. If you look up cute cat videos - and I do - they put other cute animal videos into what you see on Twitter. The president may not have known about Britain First, but algorithms deliver their messages to the president based on what he reads on Twitter. No matter how many thoughtful people are put on the White House staff, the president may be getting his information about vital issues like immigration 280 characters or one deceptive video after another at a time. (SOUNDBITE OF MUSIC)", "section": "Simon Says", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-12-04-568393428": {"title": "The First Text Message Celebrates 25 Years : NPR", "url": "https://www.npr.org/2017/12/04/568393428/the-first-text-messages-celebrates-25-years", "author": "No author found", "published_date": "2017-12-04", "content": "MARY LOUISE KELLY, HOST: How you communicate on the phone says a lot about who you are or at least how old you are. Do you talk or just trade messages? And do your messages contain actual words or just pictures? We take a look at the generational divide over texting on this week's All Tech Considered. (SOUNDBITE OF MUSIC)KELLY MCEVERS, HOST: First, a short history lesson. This story really begins 25 years ago yesterday, December 3, 1992. A British engineer named Neil Papworth sat down at his desktop computer and typed out the world's first text message. He told his story to the website Euronews. (SOUNDBITE OF ARCHIVED RECORDING)NEIL PAPWORTH: The first message was Merry Christmas spelled with the full words, not X-mas (ph). It was Christmas. KELLY: Papworth had been working on a project for the telecommunications company Vodafone. On the receiving end of that Merry Christmas text was Vodafone executive Richard Jarvis. Jarvis read it on his Orbitel 901 cell phone, a phone that weighed more than 4 and a half pounds. MCEVERS: At the time, mobile phones couldn't respond to text messages, so Jarvis didn't return the greeting. And that was it. KELLY: So all of that predates NPR's first mention of cell phone text messaging by more than a year. We first talked about it in a story introduced by Alex Chadwick. (SOUNDBITE OF ARCHIVED BROADCAST)ALEX CHADWICK, BYLINE: The Federal Communications Commission is ready for the next development in wireless communications. KELLY: The FCC was auctioning off radio frequencies to be assigned to new, high-tech paging services. MCEVERS: Reporter Ancel Martinez described the scene. (SOUNDBITE OF ARCHIVED BROADCAST)ANCEL MARTINEZ, BYLINE: Inside the hotel ballroom, representatives from 29 companies typed in their bids for the new frequencies on computer terminals behind drawn curtains. After leaving the booths, executives place hurried calls on hand-held phones or scribble down notes before quickly returning to private suites. Each company officer must decide which frequency to bid on and how many millions they're worth. MCEVERS: Martinez then asked the FCC's Robert Pepper to explain how text messaging might change communications. (SOUNDBITE OF ARCHIVED BROADCAST)ROBERT PEPPER: With these new advanced services it's two-way. So for example, if you get a message saying, can we meet for lunch, you can push a button and say, yes, no. MCEVERS: Just a yes or no - no LOLs, no emojis. KELLY: Perish the thought, especially if you count yourself a member of Generation Z. MARY LOUISE KELLY, HOST:  How you communicate on the phone says a lot about who you are or at least how old you are. Do you talk or just trade messages? And do your messages contain actual words or just pictures? We take a look at the generational divide over texting on this week's All Tech Considered. (SOUNDBITE OF MUSIC) KELLY MCEVERS, HOST:  First, a short history lesson. This story really begins 25 years ago yesterday, December 3, 1992. A British engineer named Neil Papworth sat down at his desktop computer and typed out the world's first text message. He told his story to the website Euronews. (SOUNDBITE OF ARCHIVED RECORDING) NEIL PAPWORTH: The first message was Merry Christmas spelled with the full words, not X-mas (ph). It was Christmas. KELLY: Papworth had been working on a project for the telecommunications company Vodafone. On the receiving end of that Merry Christmas text was Vodafone executive Richard Jarvis. Jarvis read it on his Orbitel 901 cell phone, a phone that weighed more than 4 and a half pounds. MCEVERS: At the time, mobile phones couldn't respond to text messages, so Jarvis didn't return the greeting. And that was it. KELLY: So all of that predates NPR's first mention of cell phone text messaging by more than a year. We first talked about it in a story introduced by Alex Chadwick. (SOUNDBITE OF ARCHIVED BROADCAST) ALEX CHADWICK, BYLINE: The Federal Communications Commission is ready for the next development in wireless communications. KELLY: The FCC was auctioning off radio frequencies to be assigned to new, high-tech paging services. MCEVERS: Reporter Ancel Martinez described the scene. (SOUNDBITE OF ARCHIVED BROADCAST) ANCEL MARTINEZ, BYLINE: Inside the hotel ballroom, representatives from 29 companies typed in their bids for the new frequencies on computer terminals behind drawn curtains. After leaving the booths, executives place hurried calls on hand-held phones or scribble down notes before quickly returning to private suites. Each company officer must decide which frequency to bid on and how many millions they're worth. MCEVERS: Martinez then asked the FCC's Robert Pepper to explain how text messaging might change communications. (SOUNDBITE OF ARCHIVED BROADCAST) ROBERT PEPPER: With these new advanced services it's two-way. So for example, if you get a message saying, can we meet for lunch, you can push a button and say, yes, no. MCEVERS: Just a yes or no - no LOLs, no emojis. KELLY: Perish the thought, especially if you count yourself a member of Generation Z.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-12-06-568920283": {"title": "To Avoid Fires In Flight, Airlines Move To Restrict 'Smart' Luggage : NPR", "url": "https://www.npr.org/2017/12/06/568920283/to-avoid-fires-in-flight-airlines-move-to-restrict-smart-luggage", "author": "No author found", "published_date": "2017-12-06", "content": "KELLY MCEVERS, HOST: Airlines including American, Delta and Alaska have announced restrictions on smart luggage. These are bags and suitcases that have phone chargers built in. Some have scales to get your luggage weight just right. There's even a robot suitcase that follows you around so you don't have to pull it. These features of course require power, often in the form of lithium-ion batteries, and that is what's the problem. Here to tell us more about the new rules on flying with these bags is our own reporter Laurel Wamsley. Hi there. LAUREL WAMSLEY, BYLINE: Hi, Kelly. MCEVERS: So what are the airlines saying about smart luggage? WAMSLEY: Well, they've announced that beginning January 15, customers who have one of these smart bags have to remove the battery. And - well, specifically, they need to be able to remove the battery whether they're checking the bag or carrying it on. So if they're going to check their bag, they have to take out the battery and bring it onboard with them. And then, if the battery does have a battery - if the bag has a bag - battery that can't be removed, they really can't bring it at all. MCEVERS: Are these rules issued by some of the airlines? Are these the rules that were issued by the airlines? I mean, what are the FAA - what does the FAA say about this? WAMSLEY: Right. So these announcements are all from these three different airlines so far, and a couple more say they're considering similar measures. The FAA basically says that these rules follow the guidelines that they already have regarding lithium batteries. They already say that you should carry on devices that have these batteries whenever possible instead of checking them. Basically the FAA - these regulations are basically treating these batteries the same way they already treat spare lithium batteries. MCEVERS: Are these the same batteries that were exploding in Samsung phones last year and in hoverboards the year before that? WAMSLEY: Yes, they are. MCEVERS: OK. WAMSLEY: So these lithium batteries which are found in lots of electronics these days because they're really efficient - they're really small. They pack a lot of power. But the ones in the smart suitcases are bigger than the ones that were in the smartphones that were exploding last year. These ones - you know, they can power a suitcase behind you. They can power a laptop - all these things. So with that bigger size, there's kind of more danger. And also, again, because they're in these suitcases, there are just more of them in the luggage hold. So lithium is just this really reactive material. So if there's any manufacturing errors or anything like that in the devices, they can ignite and cause what's called thermal runaway leading to fire or explosions. MCEVERS: OK, so if they pose a fire hazard, won't they be just as dangerous in a carry-on as they would be in checked luggage? WAMSLEY: Yeah, great question. So I asked a guy at American Airlines about this, and the spokesman told me that the reason why you're still allowed to have these onboard in the cabin is that in the cabin, people can fight the fire if one starts. If a fire breaks out in the cargo hold, it's really hard to fight it because there's no one down there. There's just all these suitcases. But if one breaks out onboard, you can just kind of, you know, dunk the battery in water and things like that and put it out. MCEVERS: So passengers and crew will be fighting a fire? WAMSLEY: Yes, and apparently that's the plan. MCEVERS: American Airlines said it made its announcement ahead of the holidays so people would know about it as they're buying gifts. But what about people who already own one of these suitcases? WAMSLEY: Right. So again, this only affects bags that don't have removable batteries. So if you have one of the bags and the battery is removable, you're fine. You just have to take it out if you're checking it. But if you have one where the battery isn't removable, you should probably pack a different bag. And again, other airlines are looking at similar measures, so you should probably check with your airline before you pack your bag. MCEVERS: NPR's Laurel Wamsley explaining new regulations announced by some airlines on rules for smart luggage. Thank you very much. WAMSLEY: You're welcome. (SOUNDBITE OF THE HAGGIS HORNS' \"CURSE OF THE HAGGIS\") KELLY MCEVERS, HOST:  Airlines including American, Delta and Alaska have announced restrictions on smart luggage. These are bags and suitcases that have phone chargers built in. Some have scales to get your luggage weight just right. There's even a robot suitcase that follows you around so you don't have to pull it. These features of course require power, often in the form of lithium-ion batteries, and that is what's the problem. Here to tell us more about the new rules on flying with these bags is our own reporter Laurel Wamsley. Hi there. LAUREL WAMSLEY, BYLINE: Hi, Kelly. MCEVERS: So what are the airlines saying about smart luggage? WAMSLEY: Well, they've announced that beginning January 15, customers who have one of these smart bags have to remove the battery. And - well, specifically, they need to be able to remove the battery whether they're checking the bag or carrying it on. So if they're going to check their bag, they have to take out the battery and bring it onboard with them. And then, if the battery does have a battery - if the bag has a bag - battery that can't be removed, they really can't bring it at all. MCEVERS: Are these rules issued by some of the airlines? Are these the rules that were issued by the airlines? I mean, what are the FAA - what does the FAA say about this? WAMSLEY: Right. So these announcements are all from these three different airlines so far, and a couple more say they're considering similar measures. The FAA basically says that these rules follow the guidelines that they already have regarding lithium batteries. They already say that you should carry on devices that have these batteries whenever possible instead of checking them. Basically the FAA - these regulations are basically treating these batteries the same way they already treat spare lithium batteries. MCEVERS: Are these the same batteries that were exploding in Samsung phones last year and in hoverboards the year before that? WAMSLEY: Yes, they are. MCEVERS: OK. WAMSLEY: So these lithium batteries which are found in lots of electronics these days because they're really efficient - they're really small. They pack a lot of power. But the ones in the smart suitcases are bigger than the ones that were in the smartphones that were exploding last year. These ones - you know, they can power a suitcase behind you. They can power a laptop - all these things. So with that bigger size, there's kind of more danger. And also, again, because they're in these suitcases, there are just more of them in the luggage hold. So lithium is just this really reactive material. So if there's any manufacturing errors or anything like that in the devices, they can ignite and cause what's called thermal runaway leading to fire or explosions. MCEVERS: OK, so if they pose a fire hazard, won't they be just as dangerous in a carry-on as they would be in checked luggage? WAMSLEY: Yeah, great question. So I asked a guy at American Airlines about this, and the spokesman told me that the reason why you're still allowed to have these onboard in the cabin is that in the cabin, people can fight the fire if one starts. If a fire breaks out in the cargo hold, it's really hard to fight it because there's no one down there. There's just all these suitcases. But if one breaks out onboard, you can just kind of, you know, dunk the battery in water and things like that and put it out. MCEVERS: So passengers and crew will be fighting a fire? WAMSLEY: Yes, and apparently that's the plan. MCEVERS: American Airlines said it made its announcement ahead of the holidays so people would know about it as they're buying gifts. But what about people who already own one of these suitcases? WAMSLEY: Right. So again, this only affects bags that don't have removable batteries. So if you have one of the bags and the battery is removable, you're fine. You just have to take it out if you're checking it. But if you have one where the battery isn't removable, you should probably pack a different bag. And again, other airlines are looking at similar measures, so you should probably check with your airline before you pack your bag. MCEVERS: NPR's Laurel Wamsley explaining new regulations announced by some airlines on rules for smart luggage. Thank you very much. WAMSLEY: You're welcome. (SOUNDBITE OF THE HAGGIS HORNS' \"CURSE OF THE HAGGIS\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-12-08-569118310": {"title": "Tax Bill Favors Adding Robots Over Workers, Critics Say : NPR", "url": "https://www.npr.org/2017/12/08/569118310/tax-bill-favors-adding-robots-over-workers-critics-say", "author": "No author found", "published_date": "2017-12-08", "content": "KELLY MCEVERS, HOST: The tax bill that's now being crafted in Congress is huge. It's more than 400 pages. And we're going to look at two parts of it. First, Republicans call the bill the Tax Cut and Jobs Act. Critics say maybe it should be called the Tax Cut and Robots Act. That's because it doesn't create any new tax incentives that encourage companies specifically to hire workers and create jobs, but it does expand incentives for companies to buy robots and machines that replace workers. NPR's Chris Arnold reports. CHRIS ARNOLD, BYLINE: Republicans say that lowering taxes will boost the economy and create jobs. But critics say there's this really basic imbalance. The tax bill favors buying machines over hiring workers. That doesn't seem right to Carl Pasciuto. He's the president of a high-tech manufacturing company in Woburn, Mass. CARL PASCIUTO: I think they really need to relook at the name and add the missing component of the worker. ARNOLD: Pasciuto's company is called the Custom Group. The factory floor here is full of machines that look kind of like enclosed ski gondolas. Inside them, oil is being sprayed on blocks of metal as automated cutting tools zip around, shaping them into precision parts for nuclear submarines, jet planes, all kinds of stuff. PASCIUTO: There's servos that drag the table to the position that it needs to be in. There's a robotic tool change mechanism. ARNOLD: There are many more machines here than actual workers, and under the emerging tax bill companies would have incentives to buy more. For one thing, they could write the full value of the equipment off their taxes right away. Pasciuto says he's definitely OK with that. PASCIUTO: Absolutely. We're always happy to get any break we can get. ARNOLD: But he says he actually needs well-trained workers more than he needs equipment. PASCIUTO: We do. The equipment is readily available. The workforce isn't. ARNOLD: Pasciuto says he has open positions that he can't fill because he can't find the skilled workers, so he says he sometimes has to buy machines to do the work. But he says if there were a tax incentive for training workers, he and other companies would definitely take advantage of it. And he says that would create more jobs. PASCIUTO: I think that the federal government really needs to look at what they've put in the bill and even it out from an equipment side to a training side as well. ARNOLD: And some labor economists agree with Pasciuto. Daron Acemoglu is an economist at MIT who researches automation and robots. He says first, automation is not a bad thing. It can increase productivity and be an important part of keeping the U. S. economy competitive. But. . . DARON ACEMOGLU: The problem is when you subsidize heavily the adoption of machines instead of people. ARNOLD: Then, he says, you're putting your thumb on the scale against workers. And he says these tax bills do that. He says, let's say that a business could buy a machine to replace three workers, but there's no great cost savings. ACEMOGLU: That means that machine is not a great machine. It's fine. But it's marginal. ARNOLD: So if tax policy was neutral, the business probably wouldn't buy it. But he says even the current law favors machines, and the Republican tax bills tip the scales even more. So if you buy the machine. . . ACEMOGLU: You're going to get a huge handout from the government. ARNOLD: And he says these subsidies kill jobs when there's no good economic reason to replace workers with machines. So like Carl Pasciuto, Acemoglu would like to see incentives for hiring and training. ACEMOGLU: To balance the scales it would be good to encourage firms to invest in their workers. ARNOLD: Gavin Ekins is with the conservative-leaning Tax Foundation. He says it's OK that the scales are tipped towards machines. GAVIN EKINS: In the long run, it's better for the economy. ARNOLD: Ekins says, look. Some machines kill jobs, but some create jobs. If you buy a backhoe, for instance, people have to build it and someone has to drive it. Also, he says, there wasn't time to devise good incentives for training workers in this legislation. But he does agree with Acemoglu on one thing. The House version of the tax bill would drastically raise taxes on many graduate students and workers who get free tuition. And in an economy that needs a better skilled workforce. . . EKINS: Taxing the benefit of getting a free education, this is something that really shouldn't be taxed. ARNOLD: Ekins hopes the Senate version wins out on that point. Chris Arnold, NPR News. KELLY MCEVERS, HOST:  The tax bill that's now being crafted in Congress is huge. It's more than 400 pages. And we're going to look at two parts of it. First, Republicans call the bill the Tax Cut and Jobs Act. Critics say maybe it should be called the Tax Cut and Robots Act. That's because it doesn't create any new tax incentives that encourage companies specifically to hire workers and create jobs, but it does expand incentives for companies to buy robots and machines that replace workers. NPR's Chris Arnold reports. CHRIS ARNOLD, BYLINE: Republicans say that lowering taxes will boost the economy and create jobs. But critics say there's this really basic imbalance. The tax bill favors buying machines over hiring workers. That doesn't seem right to Carl Pasciuto. He's the president of a high-tech manufacturing company in Woburn, Mass. CARL PASCIUTO: I think they really need to relook at the name and add the missing component of the worker. ARNOLD: Pasciuto's company is called the Custom Group. The factory floor here is full of machines that look kind of like enclosed ski gondolas. Inside them, oil is being sprayed on blocks of metal as automated cutting tools zip around, shaping them into precision parts for nuclear submarines, jet planes, all kinds of stuff. PASCIUTO: There's servos that drag the table to the position that it needs to be in. There's a robotic tool change mechanism. ARNOLD: There are many more machines here than actual workers, and under the emerging tax bill companies would have incentives to buy more. For one thing, they could write the full value of the equipment off their taxes right away. Pasciuto says he's definitely OK with that. PASCIUTO: Absolutely. We're always happy to get any break we can get. ARNOLD: But he says he actually needs well-trained workers more than he needs equipment. PASCIUTO: We do. The equipment is readily available. The workforce isn't. ARNOLD: Pasciuto says he has open positions that he can't fill because he can't find the skilled workers, so he says he sometimes has to buy machines to do the work. But he says if there were a tax incentive for training workers, he and other companies would definitely take advantage of it. And he says that would create more jobs. PASCIUTO: I think that the federal government really needs to look at what they've put in the bill and even it out from an equipment side to a training side as well. ARNOLD: And some labor economists agree with Pasciuto. Daron Acemoglu is an economist at MIT who researches automation and robots. He says first, automation is not a bad thing. It can increase productivity and be an important part of keeping the U. S. economy competitive. But. . . DARON ACEMOGLU: The problem is when you subsidize heavily the adoption of machines instead of people. ARNOLD: Then, he says, you're putting your thumb on the scale against workers. And he says these tax bills do that. He says, let's say that a business could buy a machine to replace three workers, but there's no great cost savings. ACEMOGLU: That means that machine is not a great machine. It's fine. But it's marginal. ARNOLD: So if tax policy was neutral, the business probably wouldn't buy it. But he says even the current law favors machines, and the Republican tax bills tip the scales even more. So if you buy the machine. . . ACEMOGLU: You're going to get a huge handout from the government. ARNOLD: And he says these subsidies kill jobs when there's no good economic reason to replace workers with machines. So like Carl Pasciuto, Acemoglu would like to see incentives for hiring and training. ACEMOGLU: To balance the scales it would be good to encourage firms to invest in their workers. ARNOLD: Gavin Ekins is with the conservative-leaning Tax Foundation. He says it's OK that the scales are tipped towards machines. GAVIN EKINS: In the long run, it's better for the economy. ARNOLD: Ekins says, look. Some machines kill jobs, but some create jobs. If you buy a backhoe, for instance, people have to build it and someone has to drive it. Also, he says, there wasn't time to devise good incentives for training workers in this legislation. But he does agree with Acemoglu on one thing. The House version of the tax bill would drastically raise taxes on many graduate students and workers who get free tuition. And in an economy that needs a better skilled workforce. . . EKINS: Taxing the benefit of getting a free education, this is something that really shouldn't be taxed. ARNOLD: Ekins hopes the Senate version wins out on that point. Chris Arnold, NPR News.", "section": "Business", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-12-11-569983759": {"title": "FCC Says It Will Vote On Net Neutrality Despite Millions Of Fake Public Comments : NPR", "url": "https://www.npr.org/2017/12/11/569983759/fcc-says-it-will-vote-on-net-neutrality-despite-millions-of-fake-public-comments", "author": "No author found", "published_date": "2017-12-11", "content": "ROBERT SIEGEL, HOST:  I'm Robert Siegel with All Tech Considered. (SOUNDBITE OF MUSIC)SIEGEL: A lot of people seem to care about net neutrality rules which say that Internet service providers must treat all web traffic equally. The Federal Communications Commission has scheduled a vote for Thursday on whether to abolish the rules, and it's received some 22 million public comments so far. But as NPR's Brian Naylor reports, many of those comments are fake. BRIAN NAYLOR, BYLINE: The Pew Research Center decided to take a close look at all those comments submitted on net neutrality. Aaron Smith, an associate director at the center, says several things popped out. AARON SMITH: Ninety-four percent of the comments, based on our analysis, were submitted multiple times, and in some cases, those comments were submitted many hundreds of thousands of times. NAYLOR: So in other words, almost all of the comments seem to have been parts of organized campaigns to influence the FCC commissioners to vote one way or the other. Now, organized campaigns to influence public policy, whether it be for an agency like the FCC or on issues before Congress, are probably as old as the Republic, but this is taking it to a new level - for instance, the names listed in the public comments. Smith says there were a lot of duplicates. SMITH: The No. 1 name listed when we dug into the comments was the Internet. The Internet submitted about 17,000 comments out of the 22 million. NAYLOR: Common names like John Johnson and John Smith were each on thousands of comments, and there were others that stood out. SMITH: John Oliver (laughter) in theory submitted several thousand comments. Net Neutrality submitted several thousand comments. So we saw a number of areas where names were either duplicated or were in some cases not names at all. NAYLOR: John Oliver is the HBO host who in one of his most-viewed segments argued in favor of net neutrality regulation. (SOUNDBITE OF TV SHOW, \"LAST WEEK TONIGHT WITH JOHN OLIVER\")JOHN OLIVER: The Internet - repository of all human knowledge. NAYLOR: Pew found that the most prevalent comment filed 2. 8 million times was opposed to FCC Chairman Ajit Pai, who wants to roll back the net neutrality regulations. But then the next six most prevalent comments favored Pai's position. New York Attorney General Eric Schneiderman's office conducted its own investigation into the comments and determined that at least a million were fake. Schneiderman, a Democrat, called on the FCC to delay its vote on net neutrality. ERIC SCHNEIDERMAN: You cannot conduct a legitimate vote on a rulemaking proceeding if you have a record that is in shambles as this one is. NAYLOR: It's not clear whether the fake comments were submitted by bots, although Pew found that on several occasions tens of thousands of comments came in at the same precise time. Democratic FCC Commissioner Jessica Rosenworcel says half a million of the fake comments originated from Russian email addresses. She says the issue with the FCC comments calls into question the integrity of the entire public comment process. JESSICA ROSENWORCEL: Agencies open up their doors and in effect ask the American people to tell them what they think about proposed rules, how their lives might be changed by them. It is essential that we come up with ways to manage the integrity of that process in the digital age. NAYLOR: An FCC spokesman says the commission will hold its vote on whether to overturn the net neutrality rules this Thursday as scheduled. Rosenworcel says that shows the FCC's sheer contempt for public input. Brian Naylor, NPR News, Washington. ROBERT SIEGEL, HOST:   I'm Robert Siegel with All Tech Considered. (SOUNDBITE OF MUSIC) SIEGEL: A lot of people seem to care about net neutrality rules which say that Internet service providers must treat all web traffic equally. The Federal Communications Commission has scheduled a vote for Thursday on whether to abolish the rules, and it's received some 22 million public comments so far. But as NPR's Brian Naylor reports, many of those comments are fake. BRIAN NAYLOR, BYLINE: The Pew Research Center decided to take a close look at all those comments submitted on net neutrality. Aaron Smith, an associate director at the center, says several things popped out. AARON SMITH: Ninety-four percent of the comments, based on our analysis, were submitted multiple times, and in some cases, those comments were submitted many hundreds of thousands of times. NAYLOR: So in other words, almost all of the comments seem to have been parts of organized campaigns to influence the FCC commissioners to vote one way or the other. Now, organized campaigns to influence public policy, whether it be for an agency like the FCC or on issues before Congress, are probably as old as the Republic, but this is taking it to a new level - for instance, the names listed in the public comments. Smith says there were a lot of duplicates. SMITH: The No. 1 name listed when we dug into the comments was the Internet. The Internet submitted about 17,000 comments out of the 22 million. NAYLOR: Common names like John Johnson and John Smith were each on thousands of comments, and there were others that stood out. SMITH: John Oliver (laughter) in theory submitted several thousand comments. Net Neutrality submitted several thousand comments. So we saw a number of areas where names were either duplicated or were in some cases not names at all. NAYLOR: John Oliver is the HBO host who in one of his most-viewed segments argued in favor of net neutrality regulation. (SOUNDBITE OF TV SHOW, \"LAST WEEK TONIGHT WITH JOHN OLIVER\") JOHN OLIVER: The Internet - repository of all human knowledge. NAYLOR: Pew found that the most prevalent comment filed 2. 8 million times was opposed to FCC Chairman Ajit Pai, who wants to roll back the net neutrality regulations. But then the next six most prevalent comments favored Pai's position. New York Attorney General Eric Schneiderman's office conducted its own investigation into the comments and determined that at least a million were fake. Schneiderman, a Democrat, called on the FCC to delay its vote on net neutrality. ERIC SCHNEIDERMAN: You cannot conduct a legitimate vote on a rulemaking proceeding if you have a record that is in shambles as this one is. NAYLOR: It's not clear whether the fake comments were submitted by bots, although Pew found that on several occasions tens of thousands of comments came in at the same precise time. Democratic FCC Commissioner Jessica Rosenworcel says half a million of the fake comments originated from Russian email addresses. She says the issue with the FCC comments calls into question the integrity of the entire public comment process. JESSICA ROSENWORCEL: Agencies open up their doors and in effect ask the American people to tell them what they think about proposed rules, how their lives might be changed by them. It is essential that we come up with ways to manage the integrity of that process in the digital age. NAYLOR: An FCC spokesman says the commission will hold its vote on whether to overturn the net neutrality rules this Thursday as scheduled. Rosenworcel says that shows the FCC's sheer contempt for public input. Brian Naylor, NPR News, Washington.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-12-11-569462645": {"title": "In Effort To Court Drivers, Lyft Offering Education Discounts : NPR", "url": "https://www.npr.org/2017/12/11/569462645/in-effort-to-court-drivers-lyft-offering-education-discounts", "author": "No author found", "published_date": "2017-12-11", "content": "KELLY MCEVERS, HOST:  The ride-sharing company Lyft announced an education program for its drivers today. Lyft will offer access to discounted online GED and college courses. The move is an interesting experiment in the gig economy, where a growing class of workers receive no benefits from a boss and yet competition for their time is fierce. Here's NPR's Aarti Shahani. AARTI SHAHANI, BYLINE: Lyft is rolling out this pilot program with Guild Education, a Denver-based startup that plays matchmaker between workers and dozens of nonprofit online schools. I tell Lyft driver Shanae Watkins about it. And her reaction. . . SHANAE WATKINS: Oh, wow. SHAHANI: Does that interest you? WATKINS: Yes, it definitely does. SHAHANI: Watkins, a single mom raising three kids in Baltimore, is working on her bachelor's in psychology, taking online classes. WATKINS: I want to be a behavioral health therapist. I really feel like that's my calling. SHAHANI: She also drives for Uber, GrubHub, Amazon Flex and pretty much feels no loyalty to any of them. It's all about earnings. But if this new education benefit saves her money, she says, she would certainly drive a lot more for Lyft. She's excited. WATKINS: I am excited. Like, as soon as we get off the phone I'm probably going to Google and see what I can read up and what the requirements are on it. SHAHANI: In this new program, drivers get tuition discounts - 5 percent to 20 percent. And the company says the average driver getting a degree saves more than $4,000 dollars a year. Drivers can get an associate's, bachelor's or master's degree online in subjects like IT, nursing, social work, occupational therapy and business. They can also take English as a Second Language classes or get a GED. GABE COHEN: Those who are successful in business listen to their customers. And, you know, in many ways drivers are our customers. SHAHANI: Gabe Cohen is Lyft general manager in Denver. It's a funny paradox in the gig economy. On the one hand, companies like Lyft and Uber claim their workers are contractors who are not entitled to benefits. They fight tooth and nail in court to defend that position. On the other hand, these companies desperately need more drivers, so are trying to figure out what benefits they can offer to appeal to working people. Cohen says this education program is very much an effort to recruit and retain drivers. Uber offers nothing comparable for now. COHEN: The companies that stay true to their values and their mission ultimately will end up being successful. SHAHANI: David Weil, dean at Brandeis University's public policy school, is not impressed. He believes that many Lyft drivers are being misclassified, that they are employees entitled to benefits. And he says Lyft is just doing what many, many employers do. DAVID WEIL: It's a respectful thing for an employer to do for the people who work for them. But I would certainly not in any way give them a pass on the broader issue of how they treat that workforce and how they classify that workforce just because they're providing these benefits. SHAHANI: Lyft audited the pilot program to make sure it does not open the floodgates to new legal claims that workers are employees. In-house lawyers determined it doesn't because only benefits that serve as compensation, like health care, could put the independent contractor status in jeopardy. And note - Lyft is an NPR sponsor. Aarti Shahani, NPR News, San Francisco. KELLY MCEVERS, HOST:   The ride-sharing company Lyft announced an education program for its drivers today. Lyft will offer access to discounted online GED and college courses. The move is an interesting experiment in the gig economy, where a growing class of workers receive no benefits from a boss and yet competition for their time is fierce. Here's NPR's Aarti Shahani. AARTI SHAHANI, BYLINE: Lyft is rolling out this pilot program with Guild Education, a Denver-based startup that plays matchmaker between workers and dozens of nonprofit online schools. I tell Lyft driver Shanae Watkins about it. And her reaction. . . SHANAE WATKINS: Oh, wow. SHAHANI: Does that interest you? WATKINS: Yes, it definitely does. SHAHANI: Watkins, a single mom raising three kids in Baltimore, is working on her bachelor's in psychology, taking online classes. WATKINS: I want to be a behavioral health therapist. I really feel like that's my calling. SHAHANI: She also drives for Uber, GrubHub, Amazon Flex and pretty much feels no loyalty to any of them. It's all about earnings. But if this new education benefit saves her money, she says, she would certainly drive a lot more for Lyft. She's excited. WATKINS: I am excited. Like, as soon as we get off the phone I'm probably going to Google and see what I can read up and what the requirements are on it. SHAHANI: In this new program, drivers get tuition discounts - 5 percent to 20 percent. And the company says the average driver getting a degree saves more than $4,000 dollars a year. Drivers can get an associate's, bachelor's or master's degree online in subjects like IT, nursing, social work, occupational therapy and business. They can also take English as a Second Language classes or get a GED. GABE COHEN: Those who are successful in business listen to their customers. And, you know, in many ways drivers are our customers. SHAHANI: Gabe Cohen is Lyft general manager in Denver. It's a funny paradox in the gig economy. On the one hand, companies like Lyft and Uber claim their workers are contractors who are not entitled to benefits. They fight tooth and nail in court to defend that position. On the other hand, these companies desperately need more drivers, so are trying to figure out what benefits they can offer to appeal to working people. Cohen says this education program is very much an effort to recruit and retain drivers. Uber offers nothing comparable for now. COHEN: The companies that stay true to their values and their mission ultimately will end up being successful. SHAHANI: David Weil, dean at Brandeis University's public policy school, is not impressed. He believes that many Lyft drivers are being misclassified, that they are employees entitled to benefits. And he says Lyft is just doing what many, many employers do. DAVID WEIL: It's a respectful thing for an employer to do for the people who work for them. But I would certainly not in any way give them a pass on the broader issue of how they treat that workforce and how they classify that workforce just because they're providing these benefits. SHAHANI: Lyft audited the pilot program to make sure it does not open the floodgates to new legal claims that workers are employees. In-house lawyers determined it doesn't because only benefits that serve as compensation, like health care, could put the independent contractor status in jeopardy. And note - Lyft is an NPR sponsor. Aarti Shahani, NPR News, San Francisco.", "section": "Business", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-12-12-570248510": {"title": "How Repealing Net Neutrality Could Affect Schools' Internet Access : NPR", "url": "https://www.npr.org/2017/12/12/570248510/how-repealing-net-neutrality-could-affect-schools-internet-access", "author": "No author found", "published_date": "2017-12-12", "content": "KELLY MCEVERS, HOST: On Thursday, the Federal Communications Commission is expected to repeal net neutrality regulations. These are the regulations put in place by President Obama to stop broadband companies like Comcast, AT&T and Verizon from blocking or slowing down what their customers want to access online and charging extra for certain things. There are a lot of critics of this, people who worry about what could happen if these regulations go away. One of them is Richard Culatta. He's the CEO of the International Society for Technology in Education, and he worries about what could happen in schools. Welcome to the show. RICHARD CULATTA: Hi, Kelly. MCEVERS: So just explain this a little bit, if you could. How would a repeal of net neutrality affect, say, my daughter's public school? CULATTA: Yeah, so one of the key elements of the Internet is that it provides immediate access to a huge range of high-quality resources that are really useful for teachers, whether it's videos of science concepts, simulations - could be source materials and images from a Smithsonian gallery. Now, because it's free and because we aren't charging students sitting in a class to see those great resources, they don't really provide any financial incentive for the carriers to provide those at a higher speed. Now, with net neutrality, of course, that was not an issue. But when carriers can choose to prioritize paid content over freely available content, schools really are at risk. MCEVERS: How worried are you that this is really going to affect schools as of Thursday? CULATTA: Well, I think the piece to realize is that Thursday or Friday, we're not going to see much of a difference, right? But over time, I actually am very worried. And I think we all should be worried about this because the types of materials that students, teachers are looking for don't help the bottom line of Internet providers. MCEVERS: And you used to be a teacher, right? CULATTA: I did. MCEVERS: Yeah. I just wondered if you could, like, give us an example of, say, a lesson plan, you know, that would rely on good access to the Internet that might be harder for a teacher to do without net neutrality. CULATTA: Sure. There's a school in Chattanooga - I was visiting Chattanooga recently, and there's a school there where the students in the science class have access to a scanning electron microscope. Scanning electron microscopes are very expensive. The school actually can't afford their own, but because you can control a scanning electron microscope digitally - University of Southern California has put a hi-def camera on top of their scanning electron microscope. And so the students can control. . . MCEVERS: Wow. CULATTA: . . . And do these experiments from Chattanooga, where they would not have access otherwise. Well, all that worked because they have access to high-speed Internet connections. As soon as that gets throttled back, access to those students to conduct those experiments is gone. And this is the whole point of what's so scary about this - is, for years, schools that could afford to have high-quality resources, that could afford to have experts brought in, that could afford to have expert teachers in a whole variety of areas were always ahead. Students in those schools are always ahead. And the Internet, for the first time, leveled that playing field because it didn't matter if you were in a wealthy school or an under-resourced school. And as soon as that goes away, we're back to where we were before, where students are getting shortchanged based on the zip code they live in or, you know, the socioeconomic status of their community because they aren't able to pay for those resources again. MCEVERS: Have broadband companies responded to your criticism, to what you're saying? CULATTA: You know, generally, the response is, don't worry, don't worry; we're, you know - we're not going to do anything. But the catch at the end of the day is, who are those companies answering to, right? They're not answering to my kids' teacher in their school. They're answering to shareholders. MCEVERS: Richard Culatta, thank you so much. CULATTA: Thank you. MCEVERS: Richard Culatta is CEO of the International Society for Technology in Education, and he led the Department of Education's Office of Educational Technology during the Obama administration. KELLY MCEVERS, HOST:  On Thursday, the Federal Communications Commission is expected to repeal net neutrality regulations. These are the regulations put in place by President Obama to stop broadband companies like Comcast, AT&T and Verizon from blocking or slowing down what their customers want to access online and charging extra for certain things. There are a lot of critics of this, people who worry about what could happen if these regulations go away. One of them is Richard Culatta. He's the CEO of the International Society for Technology in Education, and he worries about what could happen in schools. Welcome to the show. RICHARD CULATTA: Hi, Kelly. MCEVERS: So just explain this a little bit, if you could. How would a repeal of net neutrality affect, say, my daughter's public school? CULATTA: Yeah, so one of the key elements of the Internet is that it provides immediate access to a huge range of high-quality resources that are really useful for teachers, whether it's videos of science concepts, simulations - could be source materials and images from a Smithsonian gallery. Now, because it's free and because we aren't charging students sitting in a class to see those great resources, they don't really provide any financial incentive for the carriers to provide those at a higher speed. Now, with net neutrality, of course, that was not an issue. But when carriers can choose to prioritize paid content over freely available content, schools really are at risk. MCEVERS: How worried are you that this is really going to affect schools as of Thursday? CULATTA: Well, I think the piece to realize is that Thursday or Friday, we're not going to see much of a difference, right? But over time, I actually am very worried. And I think we all should be worried about this because the types of materials that students, teachers are looking for don't help the bottom line of Internet providers. MCEVERS: And you used to be a teacher, right? CULATTA: I did. MCEVERS: Yeah. I just wondered if you could, like, give us an example of, say, a lesson plan, you know, that would rely on good access to the Internet that might be harder for a teacher to do without net neutrality. CULATTA: Sure. There's a school in Chattanooga - I was visiting Chattanooga recently, and there's a school there where the students in the science class have access to a scanning electron microscope. Scanning electron microscopes are very expensive. The school actually can't afford their own, but because you can control a scanning electron microscope digitally - University of Southern California has put a hi-def camera on top of their scanning electron microscope. And so the students can control. . . MCEVERS: Wow. CULATTA: . . . And do these experiments from Chattanooga, where they would not have access otherwise. Well, all that worked because they have access to high-speed Internet connections. As soon as that gets throttled back, access to those students to conduct those experiments is gone. And this is the whole point of what's so scary about this - is, for years, schools that could afford to have high-quality resources, that could afford to have experts brought in, that could afford to have expert teachers in a whole variety of areas were always ahead. Students in those schools are always ahead. And the Internet, for the first time, leveled that playing field because it didn't matter if you were in a wealthy school or an under-resourced school. And as soon as that goes away, we're back to where we were before, where students are getting shortchanged based on the zip code they live in or, you know, the socioeconomic status of their community because they aren't able to pay for those resources again. MCEVERS: Have broadband companies responded to your criticism, to what you're saying? CULATTA: You know, generally, the response is, don't worry, don't worry; we're, you know - we're not going to do anything. But the catch at the end of the day is, who are those companies answering to, right? They're not answering to my kids' teacher in their school. They're answering to shareholders. MCEVERS: Richard Culatta, thank you so much. CULATTA: Thank you. MCEVERS: Richard Culatta is CEO of the International Society for Technology in Education, and he led the Department of Education's Office of Educational Technology during the Obama administration.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-12-13-570558113": {"title": "'I Came, I Saw, I Selfied': How Instagram Transformed The Way We Experience Art : NPR", "url": "https://www.npr.org/2017/12/13/570558113/i-came-i-saw-i-selfied-how-instagram-transformed-the-way-we-experience-art", "author": "No author found", "published_date": "2017-12-13", "content": "", "section": "Here & Now Compass", "disclaimer": ""}, "2017-12-14-570723613": {"title": "What Could Change After Net Neutrality Repeal : NPR", "url": "https://www.npr.org/2017/12/14/570723613/what-could-change-after-net-neutrality-repeal", "author": "No author found", "published_date": "2017-12-14", "content": "STEVE INSKEEP, HOST: Let's hear the case against repealing net neutrality rules. The Federal Communications Commission votes on repeal today. The FCC is expected to overturn a policy from President Obama's time which tells your Internet service provider to sell you a level playing field with the same access to all Internet sites. Many, many companies have a stake in this rule, among them, by the way, NPR, whose legal counsel opposes deregulation on behalf of the company. On this program, we've heard President Trump's FCC chairman who favors repeal. Now let's hear Mitchell Baker, of the nonprofit Mozilla Foundation, who does not. MITCHELL BAKER: Here are the things that become possible. One, blocking content. So your ISP provides access to whatever content it is you want to see. These rules change that. ISPs might have packages like cable TV does, and you might have to pay differently depending on the packages, and those packages may well be designed to be most profitable for them but not useful for you. INSKEEP: Are you telling me that the Internet service provider might make me buy a bunch of websites, the equivalent of channels, in order to get to the sites that I actually really want? BAKER: Yes. That's a possibility. So imagine sites just not available to you anymore. Of course, that could be any nature of site, and it could be for any reason. So I sometimes wonder what happens if you express political views that someone doesn't like? Does your site disappear? Does it slow down? That sounds melodramatic, but the rules allow these sorts of things. INSKEEP: So what does it mean if Internet service providers got back these powers to block sites, to slow down sites, to bundle sites in ways that are convenient for them? BAKER: It means that access to the fundamental communication channel of our time, which is the Internet - almost everything goes over the Internet - that what content's available, whether you can access it, how the payment works is all determined by a very small handful of people with very little constraint. So you take all of the things that we were so happy to get away from in cable TV. You bring them back, you make them stronger and you apply them to every aspect of our life. INSKEEP: So that sounds pretty worrisome. But let me present to you a couple of arguments that have been made in favor of getting rid of the net neutrality rules. This comes from the FCC chairman Ajit Pai who was on the program the other day, and he's arguing in favor of a freer approach. Let's listen. (SOUNDBITE OF ARCHIVED BROADCAST)AJIT PAI: I'm in the somewhat unusual position, as a Republican chairman of the FCC, to say that President Clinton got it right in 1996 when he established a free-market based approach to this new thing called the Internet. And the Internet economy we have is a result of his light-touch regulatory vision. We saw $1. 5 trillion of investment in networks, we saw companies like Facebook and Amazon and Google become global powerhouses precisely because we had light-touch rules that applied to this Internet. INSKEEP: Isn't that all true? BAKER: Well, so first I'd say we're not in 1996. And, what makes sense at one period of time doesn't necessarily make sense for another. INSKEEP: Are you saying the Internet was a younger, smaller, less dangerous place in 1996? Is that your point? BAKER: Well, certainly it was younger. Certainly the the business models and what's happening and what's possible are changing. Certainly now we understand what ISPs are interested in doing. So in 1996, I think the idea that they would begin blocking and changing sites, the idea that it could be turned into cable TV, like, those were ideas that weren't really clear to us at the time. And so to say that the system that worked in that generation is the same one that we should use today could conceivably be correct, but, on its own it's not a very strong argument. INSKEEP: Well, let me follow up on that then because another case that is made for getting rid of the net neutrality rules is that they've only been around a couple years, since 2015. That's when the Obama administration approved them, which means that smartphones did develop in the absence of net neutrality rules, and the Internet did explode in the absence of net neutrality rules and the options available to people exploded immensely up until 2015. Why wouldn't that just continue to happen? BAKER: Well, for one thing, you know, businesses change and adapt, and businesses get smarter about how to maximize their revenue as you have more experience. And so now we have another decade of experience, you know, with Internet and Internet access, and so therefore our response to that should also change. INSKEEP: Mitchell Baker is with the Mozilla Foundation. She joined us from our member station KUT in Austin, Texas. Thanks very much. BAKER: Thank you. STEVE INSKEEP, HOST:  Let's hear the case against repealing net neutrality rules. The Federal Communications Commission votes on repeal today. The FCC is expected to overturn a policy from President Obama's time which tells your Internet service provider to sell you a level playing field with the same access to all Internet sites. Many, many companies have a stake in this rule, among them, by the way, NPR, whose legal counsel opposes deregulation on behalf of the company. On this program, we've heard President Trump's FCC chairman who favors repeal. Now let's hear Mitchell Baker, of the nonprofit Mozilla Foundation, who does not. MITCHELL BAKER: Here are the things that become possible. One, blocking content. So your ISP provides access to whatever content it is you want to see. These rules change that. ISPs might have packages like cable TV does, and you might have to pay differently depending on the packages, and those packages may well be designed to be most profitable for them but not useful for you. INSKEEP: Are you telling me that the Internet service provider might make me buy a bunch of websites, the equivalent of channels, in order to get to the sites that I actually really want? BAKER: Yes. That's a possibility. So imagine sites just not available to you anymore. Of course, that could be any nature of site, and it could be for any reason. So I sometimes wonder what happens if you express political views that someone doesn't like? Does your site disappear? Does it slow down? That sounds melodramatic, but the rules allow these sorts of things. INSKEEP: So what does it mean if Internet service providers got back these powers to block sites, to slow down sites, to bundle sites in ways that are convenient for them? BAKER: It means that access to the fundamental communication channel of our time, which is the Internet - almost everything goes over the Internet - that what content's available, whether you can access it, how the payment works is all determined by a very small handful of people with very little constraint. So you take all of the things that we were so happy to get away from in cable TV. You bring them back, you make them stronger and you apply them to every aspect of our life. INSKEEP: So that sounds pretty worrisome. But let me present to you a couple of arguments that have been made in favor of getting rid of the net neutrality rules. This comes from the FCC chairman Ajit Pai who was on the program the other day, and he's arguing in favor of a freer approach. Let's listen. (SOUNDBITE OF ARCHIVED BROADCAST) AJIT PAI: I'm in the somewhat unusual position, as a Republican chairman of the FCC, to say that President Clinton got it right in 1996 when he established a free-market based approach to this new thing called the Internet. And the Internet economy we have is a result of his light-touch regulatory vision. We saw $1. 5 trillion of investment in networks, we saw companies like Facebook and Amazon and Google become global powerhouses precisely because we had light-touch rules that applied to this Internet. INSKEEP: Isn't that all true? BAKER: Well, so first I'd say we're not in 1996. And, what makes sense at one period of time doesn't necessarily make sense for another. INSKEEP: Are you saying the Internet was a younger, smaller, less dangerous place in 1996? Is that your point? BAKER: Well, certainly it was younger. Certainly the the business models and what's happening and what's possible are changing. Certainly now we understand what ISPs are interested in doing. So in 1996, I think the idea that they would begin blocking and changing sites, the idea that it could be turned into cable TV, like, those were ideas that weren't really clear to us at the time. And so to say that the system that worked in that generation is the same one that we should use today could conceivably be correct, but, on its own it's not a very strong argument. INSKEEP: Well, let me follow up on that then because another case that is made for getting rid of the net neutrality rules is that they've only been around a couple years, since 2015. That's when the Obama administration approved them, which means that smartphones did develop in the absence of net neutrality rules, and the Internet did explode in the absence of net neutrality rules and the options available to people exploded immensely up until 2015. Why wouldn't that just continue to happen? BAKER: Well, for one thing, you know, businesses change and adapt, and businesses get smarter about how to maximize their revenue as you have more experience. And so now we have another decade of experience, you know, with Internet and Internet access, and so therefore our response to that should also change. INSKEEP: Mitchell Baker is with the Mozilla Foundation. She joined us from our member station KUT in Austin, Texas. Thanks very much. BAKER: Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-12-14-570262688": {"title": "As FCC Prepares Net-Neutrality Vote, Study Finds Millions of Fake Comments : NPR", "url": "https://www.npr.org/2017/12/14/570262688/as-fcc-prepares-net-neutrality-vote-study-finds-millions-of-fake-comments", "author": "No author found", "published_date": "2017-12-14", "content": "", "section": "Politics", "disclaimer": ""}, "2017-12-15-571199991": {"title": "We LYLAS, But It's Time To Say TTFN As AOL Instant Messenger Signs Off For Good : NPR", "url": "https://www.npr.org/2017/12/15/571199991/we-lylas-but-its-time-to-say-ttfn-as-aol-instant-messanger-signs-off-for-good", "author": "No author found", "published_date": "2017-12-15", "content": "KELLY MCEVERS, HOST: AOL Instant Messenger, or AIM, signed off one final time this morning. The real-time, person-to-person computer messaging system that started 20 years ago was taken offline by its parent company, and along with it millions of archived teenage conversations. Here's NPR producer Kat Lonsdorf. KAT LONSDORF, BYLINE: When I was a teenager, my response to this sound. . . (SOUNDBITE OF DOOR OPENING)LONSDORF: . . . Was practically Pavlovian. My heart would race. My fingers would twitch. I would leap to the family desktop computer. That. . . (SOUNDBITE OF DOOR OPENING)LONSDORF: . . . Was the sweet, sweet sound of a buddy coming online. It might have been my best friend or that cute boy from calculus. They were online. (SOUNDBITE OF TONE)LONSDORF: And ready to chat. (SOUNDBITE OF TONE)LONSDORF: Until my parents needed the dial-up line for an actual phone call. Here's Rob Meyer. He covers tech for The Atlantic. ROBINSON MEYER: All you saw with AIM ever was just the words on the screen. But you were constantly imagining just the scene on the other side and what the person was doing there and how they were reacting. And in that way, it was such an imaginative form of media that made it so ripe for, like, all the possibility and excitement of teenagerhood (ph). LONSDORF: AIM was born in 1997 and grew up during a time when computers were getting cheaper, Internet was getting faster and cell phones were just for talking. By 2002, AIM had more than a hundred million users. Everybody had it. MEYER: Screen names were the, like, way of advancing your relationship with someone. LONSDORF: Which is why creating the perfect screen name was super important. And since we were all teenagers, our screen names were deeply embarrassing. Here's some of my co-workers at NPR. UNIDENTIFIED WOMAN #1: Thehighfivegirl (ph). UNIDENTIFIED WOMAN #2: Blackestofshadowz (ph), shadows spelled with a Z. UNIDENTIFIED MAN #1: CD54flyguy (ph). UNIDENTIFIED WOMAN #3: RJbunny (ph). UNIDENTIFIED MAN #2: Chickenwings33 (ph). I don't know why. I think I thought, like, oh, that's a cool, like, food that dudes eat. LONSDORF: AIM peaked before Facebook existed or Twitter, so this was the first time a lot of us were navigating what to share on the Internet and how, like the away message, which was basically a status update for when you weren't at the computer. CAROLINE MOSS: An away message was sort of like an out-of-office for an 11-year-old. LONSDORF: That's Caroline Moss. She's the 30-year-old behind the Twitter account @YourAwayMessage. MOSS: So you would put up an away message and you would put up, like, song lyrics from a Dave Matthews Band song or, like, a quote from \"The Notebook. \" And you'd pick your font and then you'd pick your color. And you'd be like, I'm out with the girls at the mall. LONSDORF: But then Facebook showed up and smartphones. By 2012, the number of AIM users had dropped off significantly. We'd moved on to adulthood. MOSS: It was there, watching us all grow up from the sidelines. LONSDORF: Until today. (SOUNDBITE OF DOOR CLOSING)LONSDORF: I'm kitkatcutie21, or Kat Lonsdorf. KELLY MCEVERS, HOST:  AOL Instant Messenger, or AIM, signed off one final time this morning. The real-time, person-to-person computer messaging system that started 20 years ago was taken offline by its parent company, and along with it millions of archived teenage conversations. Here's NPR producer Kat Lonsdorf. KAT LONSDORF, BYLINE: When I was a teenager, my response to this sound. . . (SOUNDBITE OF DOOR OPENING) LONSDORF: . . . Was practically Pavlovian. My heart would race. My fingers would twitch. I would leap to the family desktop computer. That. . . (SOUNDBITE OF DOOR OPENING) LONSDORF: . . . Was the sweet, sweet sound of a buddy coming online. It might have been my best friend or that cute boy from calculus. They were online. (SOUNDBITE OF TONE) LONSDORF: And ready to chat. (SOUNDBITE OF TONE) LONSDORF: Until my parents needed the dial-up line for an actual phone call. Here's Rob Meyer. He covers tech for The Atlantic. ROBINSON MEYER: All you saw with AIM ever was just the words on the screen. But you were constantly imagining just the scene on the other side and what the person was doing there and how they were reacting. And in that way, it was such an imaginative form of media that made it so ripe for, like, all the possibility and excitement of teenagerhood (ph). LONSDORF: AIM was born in 1997 and grew up during a time when computers were getting cheaper, Internet was getting faster and cell phones were just for talking. By 2002, AIM had more than a hundred million users. Everybody had it. MEYER: Screen names were the, like, way of advancing your relationship with someone. LONSDORF: Which is why creating the perfect screen name was super important. And since we were all teenagers, our screen names were deeply embarrassing. Here's some of my co-workers at NPR. UNIDENTIFIED WOMAN #1: Thehighfivegirl (ph). UNIDENTIFIED WOMAN #2: Blackestofshadowz (ph), shadows spelled with a Z. UNIDENTIFIED MAN #1: CD54flyguy (ph). UNIDENTIFIED WOMAN #3: RJbunny (ph). UNIDENTIFIED MAN #2: Chickenwings33 (ph). I don't know why. I think I thought, like, oh, that's a cool, like, food that dudes eat. LONSDORF: AIM peaked before Facebook existed or Twitter, so this was the first time a lot of us were navigating what to share on the Internet and how, like the away message, which was basically a status update for when you weren't at the computer. CAROLINE MOSS: An away message was sort of like an out-of-office for an 11-year-old. LONSDORF: That's Caroline Moss. She's the 30-year-old behind the Twitter account @YourAwayMessage. MOSS: So you would put up an away message and you would put up, like, song lyrics from a Dave Matthews Band song or, like, a quote from \"The Notebook. \" And you'd pick your font and then you'd pick your color. And you'd be like, I'm out with the girls at the mall. LONSDORF: But then Facebook showed up and smartphones. By 2012, the number of AIM users had dropped off significantly. We'd moved on to adulthood. MOSS: It was there, watching us all grow up from the sidelines. LONSDORF: Until today. (SOUNDBITE OF DOOR CLOSING) LONSDORF: I'm kitkatcutie21, or Kat Lonsdorf.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-12-15-571199955": {"title": "Can Big Data Really Help Screen Immigrants? : NPR", "url": "https://www.npr.org/2017/12/15/571199955/dhs-wants-to-build-a-computer-system-to-help-determine-who-gets-to-visit-the-u-s", "author": "No author found", "published_date": "2017-12-15", "content": "KELLY MCEVERS, HOST: Can an algorithm tell if you are a terrorist? That is a question that U. S. immigration officials are trying to answer. They want to build a computer system that would help determine who gets to visit or move to the United States. But that has a lot of people worried. NPR's Joel Rose reports. JOEL ROSE, BYLINE: Suppose you're applying for a visa to the United States, but a computer algorithm rejects your application because you criticized American foreign policy on Facebook or because you recently had some financial trouble. That's closer to reality than you might think, says Faiza Patel. She's a lawyer at the nonprofit Brennan Center for Justice. FAIZA PATEL: This is creating this kind of open-ended algorithm which has an enormous potential to be discriminatory. ROSE: Patel is referring to an effort by Immigration and Customs Enforcement, or ICE, to use techniques from the world of big data to screen visa applicants. The project would scour all publicly available data, including social media. President Trump wants to develop a system that admits people who, as he puts it, contribute to national interests, and keep out people who are likely to commit a crime or an act of terrorism. So ICE, in turn, asked software companies if they could build an automated computer system that makes those determinations. CATHY O'NEIL: Any self-respecting data scientist should run away screaming from this. ROSE: Cathy O'Neil is the author of the book \"Weapons Of Math Destruction\" about how algorithms devised by government and the private sector can reinforce bias. She's among more than 50 of the nation's top computer science experts who signed a letter urging the Trump administration to drop the plan. O'Neil says algorithms need data from the past in order to make accurate predictions about the future. The more data, the better the predictions. But compared to consumer transactions, terrorist attacks are extremely rare, so O'Neil worries that this algorithm will make mistakes without any accountability. O'NEIL: What I would call a pseudoscientific excuse to prevent a lot of perfectly good people from coming into our country as immigrants and saying this is a scientific method. Since you're not an expert in science and math, you can't ask any questions, and you have to trust this. ROSE: Critics also say an algorithm couldn't possibly measure how a person might contribute to society. They think it would inevitably rely on something easier to measure, like income, that doesn't tell the applicant's full story. Immigration officials say these concerns are overblown. They insist they are months, if not years, from actually building an algorithm like this. And they're backing away from the original idea of having a computer make the final determination on who gets a visa. Clark Settles oversees the project. CLARK SETTLES: There's not going to be some AI, artificial intelligence, making a decision on whether people can come to the country or whether they can stay here. That's just not the case. ROSE: Settles says the government already collects lots of information about people applying for visas. What the department needs, he says, is an automated tool that will help human analysts sort through all that data so they don't miss anything about a planned terrorist attack, for instance. SETTLES: If there was information about that attack just sitting there in public forums, I would feel horrible if we hadn't done everything within the laws and rules to look at it. ROSE: Companies are interested in building that tool. A number of software providers attended a conference hosted by ICE over the summer. Giant Oak was one of them. It's a data analytics firm in Virginia that already crunches data for the agency. GARY SHIFFMAN: Every day that technology gets better. ROSE: Gary Shiffman is the company's CEO. SHIFFMAN: We should be using the technology to help humans make better decisions. ROSE: Agency officials held another meeting with tech companies last month. But they've changed the name of the project as the controversy surrounding it grew from Extreme Vetting Initiative to Visa Lifecycle Vetting. Joel Rose, NPR News, New York. (SOUNDBITE OF GEOTIC'S \"NAV\") KELLY MCEVERS, HOST:  Can an algorithm tell if you are a terrorist? That is a question that U. S. immigration officials are trying to answer. They want to build a computer system that would help determine who gets to visit or move to the United States. But that has a lot of people worried. NPR's Joel Rose reports. JOEL ROSE, BYLINE: Suppose you're applying for a visa to the United States, but a computer algorithm rejects your application because you criticized American foreign policy on Facebook or because you recently had some financial trouble. That's closer to reality than you might think, says Faiza Patel. She's a lawyer at the nonprofit Brennan Center for Justice. FAIZA PATEL: This is creating this kind of open-ended algorithm which has an enormous potential to be discriminatory. ROSE: Patel is referring to an effort by Immigration and Customs Enforcement, or ICE, to use techniques from the world of big data to screen visa applicants. The project would scour all publicly available data, including social media. President Trump wants to develop a system that admits people who, as he puts it, contribute to national interests, and keep out people who are likely to commit a crime or an act of terrorism. So ICE, in turn, asked software companies if they could build an automated computer system that makes those determinations. CATHY O'NEIL: Any self-respecting data scientist should run away screaming from this. ROSE: Cathy O'Neil is the author of the book \"Weapons Of Math Destruction\" about how algorithms devised by government and the private sector can reinforce bias. She's among more than 50 of the nation's top computer science experts who signed a letter urging the Trump administration to drop the plan. O'Neil says algorithms need data from the past in order to make accurate predictions about the future. The more data, the better the predictions. But compared to consumer transactions, terrorist attacks are extremely rare, so O'Neil worries that this algorithm will make mistakes without any accountability. O'NEIL: What I would call a pseudoscientific excuse to prevent a lot of perfectly good people from coming into our country as immigrants and saying this is a scientific method. Since you're not an expert in science and math, you can't ask any questions, and you have to trust this. ROSE: Critics also say an algorithm couldn't possibly measure how a person might contribute to society. They think it would inevitably rely on something easier to measure, like income, that doesn't tell the applicant's full story. Immigration officials say these concerns are overblown. They insist they are months, if not years, from actually building an algorithm like this. And they're backing away from the original idea of having a computer make the final determination on who gets a visa. Clark Settles oversees the project. CLARK SETTLES: There's not going to be some AI, artificial intelligence, making a decision on whether people can come to the country or whether they can stay here. That's just not the case. ROSE: Settles says the government already collects lots of information about people applying for visas. What the department needs, he says, is an automated tool that will help human analysts sort through all that data so they don't miss anything about a planned terrorist attack, for instance. SETTLES: If there was information about that attack just sitting there in public forums, I would feel horrible if we hadn't done everything within the laws and rules to look at it. ROSE: Companies are interested in building that tool. A number of software providers attended a conference hosted by ICE over the summer. Giant Oak was one of them. It's a data analytics firm in Virginia that already crunches data for the agency. GARY SHIFFMAN: Every day that technology gets better. ROSE: Gary Shiffman is the company's CEO. SHIFFMAN: We should be using the technology to help humans make better decisions. ROSE: Agency officials held another meeting with tech companies last month. But they've changed the name of the project as the controversy surrounding it grew from Extreme Vetting Initiative to Visa Lifecycle Vetting. Joel Rose, NPR News, New York. (SOUNDBITE OF GEOTIC'S \"NAV\")", "section": "National", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-12-19-569474169": {"title": "Being Different Helped A NASA Roboticist Achieve Her Dream  : NPR", "url": "https://www.npr.org/2017/12/19/569474169/being-different-helped-a-nasa-roboticist-achieve-her-dream", "author": "No author found", "published_date": "2017-12-19", "content": "", "section": "Changing The World One Invention At A Time", "disclaimer": ""}, "2017-12-20-571722494": {"title": "Your Favorite Audio Stories Of 2017 On NPR One : NPR", "url": "https://www.npr.org/2017/12/20/571722494/your-favorite-audio-stories-of-2017-on-npr-one", "author": "No author found", "published_date": "2017-12-20", "content": "", "section": "Technology", "disclaimer": ""}, "2017-12-20-571617079": {"title": "Trump's Most Retweeted And Favorited Tweets Of 2017 : NPR", "url": "https://www.npr.org/2017/12/20/571617079/a-year-of-the-trump-presidency-in-tweets", "author": "No author found", "published_date": "2017-12-20", "content": "", "section": "Politics", "disclaimer": ""}, "2017-12-21-572699291": {"title": "You're Not Crazy: Apple Deliberately Slows Down Older iPhones : NPR", "url": "https://www.npr.org/2017/12/21/572699291/youre-not-crazy-apple-confirms-it-slows-your-smartphones-lifespan", "author": "No author found", "published_date": "2017-12-21", "content": "ARI SHAPIRO, HOST:  I'm Ari Shapiro with news that you're not crazy. Apple has confirmed something that iPhone users believed for a long time. When your iPhone gets older, it slows down. And this often happens around the same time the company releases a fancy new phone. NPR's Bill Chappell has dug into this and joins us now. Hey, Bill. BILL CHAPPELL, BYLINE: Hi. SHAPIRO: So there is now data to back up an urban legend. What does Apple say is actually happening to our phones? CHAPPELL: Well, it's saying that because older phones have batteries that can't keep up with the processors that the new phones are using and putting high demands on these batteries, the old phones were prone to have these unexpected shutdowns. So to keep that from happening, they're trying to just slow down the speed of the phone entirely. And that's something people noticed after doing these software updates, updating their operating system. They would notice, hey, my phone's not as perky as it was just last week, you know? And it really came down to Apple acknowledging this this week. This is something people have sort of talked about. It's been, like you said, in the urban legend and rumor department for a long time. SHAPIRO: So Apple says they're not trying to force us to buy a new phone, they're just trying to preserve the life of an old battery? CHAPPELL: Yeah, and they're saying that this is a better experience. They're trying to smooth out these peaks of power demands that the batteries can't quite absorb as they're getting older. I mean, a battery as young as kind of 18 months old still might have trouble keeping up after it's been used for that long. SHAPIRO: Even after just a year and a half. So the phones we're talking about are not even that old. CHAPPELL: Right. These are the iPhone 6 and 7. And right now, Apple - you know, we're - the talk of the town is the iPhone 8, the iPhone 10 or X, depending on how you want to say it. But, you know, these are not, like, some old phone - you know, Apple's been making iPhones for 10 years, and this is - we're not talking about the iPhone 3 or something. SHAPIRO: Why does Apple do this? Do they risk a backlash? CHAPPELL: Well, the backlash has kind of been there to an extent. But, you know, I think Apple's trying to explain. You know, they also said that if conditions are really cold or if the battery has low power anyway, it's trying to kind of put a governor on your device so it can last longer and you won't have it suddenly just fail. I mean, that's not a great outcome either. But, yeah, the backlash is that when this happens, when a new operating system comes out, usually the new operating system is coming out because Apple's putting a new phone out. So those two things together - this - the timing's a little suspicious for people. SHAPIRO: Also, couldn't people get around this by just buying a new battery instead of buying a completely new phone? CHAPPELL: They can do that. You know, and Apple - I mean, Apple would charge around $80 to do that. It takes a few days. That's certainly a lot cheaper than buying a brand-new phone. And, you know, there are people out there arguing that, you know, if the iOS is smart enough to sense when your battery's in a little trouble and needs a little help, it could also trigger an alert that says, hey, you might want to replace this battery. Instead, people are kind of feeling like, oh, my phone is really, really slow, and this new iPhone system is so great. I think I might need a new phone to run it. SHAPIRO: How are people reacting to this revelation? CHAPPELL: Well, a lot of people are relieved that they're not crazy. SHAPIRO: (Laughter). CHAPPELL: I mean, we all need that affirmation every day. . . SHAPIRO: Right. CHAPPELL: . . . In this age. They're relieved about that, but yet they're kind of upset that Apple's been doing this without telling them at all. And it's kind of like if you have a car and you buy it and you drive it off the lot, you expect, you know, the gas tank to keep full and the engine to run and for the company not to suddenly limit how fast you can go in it. SHAPIRO: And if the gas tank stops working, you should be able to easily replace the gas tank without replacing the whole car. CHAPPELL: That would be the idea. SHAPIRO: NPR's Bill Chappell, thanks a lot. CHAPPELL: Thanks, Ari. ARI SHAPIRO, HOST:   I'm Ari Shapiro with news that you're not crazy. Apple has confirmed something that iPhone users believed for a long time. When your iPhone gets older, it slows down. And this often happens around the same time the company releases a fancy new phone. NPR's Bill Chappell has dug into this and joins us now. Hey, Bill. BILL CHAPPELL, BYLINE: Hi. SHAPIRO: So there is now data to back up an urban legend. What does Apple say is actually happening to our phones? CHAPPELL: Well, it's saying that because older phones have batteries that can't keep up with the processors that the new phones are using and putting high demands on these batteries, the old phones were prone to have these unexpected shutdowns. So to keep that from happening, they're trying to just slow down the speed of the phone entirely. And that's something people noticed after doing these software updates, updating their operating system. They would notice, hey, my phone's not as perky as it was just last week, you know? And it really came down to Apple acknowledging this this week. This is something people have sort of talked about. It's been, like you said, in the urban legend and rumor department for a long time. SHAPIRO: So Apple says they're not trying to force us to buy a new phone, they're just trying to preserve the life of an old battery? CHAPPELL: Yeah, and they're saying that this is a better experience. They're trying to smooth out these peaks of power demands that the batteries can't quite absorb as they're getting older. I mean, a battery as young as kind of 18 months old still might have trouble keeping up after it's been used for that long. SHAPIRO: Even after just a year and a half. So the phones we're talking about are not even that old. CHAPPELL: Right. These are the iPhone 6 and 7. And right now, Apple - you know, we're - the talk of the town is the iPhone 8, the iPhone 10 or X, depending on how you want to say it. But, you know, these are not, like, some old phone - you know, Apple's been making iPhones for 10 years, and this is - we're not talking about the iPhone 3 or something. SHAPIRO: Why does Apple do this? Do they risk a backlash? CHAPPELL: Well, the backlash has kind of been there to an extent. But, you know, I think Apple's trying to explain. You know, they also said that if conditions are really cold or if the battery has low power anyway, it's trying to kind of put a governor on your device so it can last longer and you won't have it suddenly just fail. I mean, that's not a great outcome either. But, yeah, the backlash is that when this happens, when a new operating system comes out, usually the new operating system is coming out because Apple's putting a new phone out. So those two things together - this - the timing's a little suspicious for people. SHAPIRO: Also, couldn't people get around this by just buying a new battery instead of buying a completely new phone? CHAPPELL: They can do that. You know, and Apple - I mean, Apple would charge around $80 to do that. It takes a few days. That's certainly a lot cheaper than buying a brand-new phone. And, you know, there are people out there arguing that, you know, if the iOS is smart enough to sense when your battery's in a little trouble and needs a little help, it could also trigger an alert that says, hey, you might want to replace this battery. Instead, people are kind of feeling like, oh, my phone is really, really slow, and this new iPhone system is so great. I think I might need a new phone to run it. SHAPIRO: How are people reacting to this revelation? CHAPPELL: Well, a lot of people are relieved that they're not crazy. SHAPIRO: (Laughter). CHAPPELL: I mean, we all need that affirmation every day. . . SHAPIRO: Right. CHAPPELL: . . . In this age. They're relieved about that, but yet they're kind of upset that Apple's been doing this without telling them at all. And it's kind of like if you have a car and you buy it and you drive it off the lot, you expect, you know, the gas tank to keep full and the engine to run and for the company not to suddenly limit how fast you can go in it. SHAPIRO: And if the gas tank stops working, you should be able to easily replace the gas tank without replacing the whole car. CHAPPELL: That would be the idea. SHAPIRO: NPR's Bill Chappell, thanks a lot. CHAPPELL: Thanks, Ari.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-12-23-572668362": {"title": "The Russia Investigations: Battle Lines Drawn Over Mueller, Justice Dept. And The FBI : NPR", "url": "https://www.npr.org/2017/12/23/572668362/the-russia-investigations-battle-lines-drawn-over-mueller-justice-dept-and-the-f", "author": "No author found", "published_date": "2017-12-23", "content": "", "section": "National Security", "disclaimer": ""}, "2017-12-25-573415866": {"title": "A Look At How Word Prediction Software Works : NPR", "url": "https://www.npr.org/2017/12/25/573415866/a-look-at-how-word-prediction-software-works", "author": "No author found", "published_date": "2017-12-25", "content": "ROBERT SIEGEL, HOST: On this All Tech Considered - my last one before retiring, so I'm allowed to indulge a point of personal curiosity - we're going to hear from someone who works on word prediction. For example, I've got my smartphone open. I'm going to type out a message - capital H. And at the bottom of the screen are three choices. The middle one is hi, which is what I meant - hi. Now I have three choices, and the first one is there, which is what I meant - comma - T-H - thanks is the middle choice. Thanks for is what I meant. And now I'll do J-O-I-N. Joining is the middle choice, I'll tap that. And then us is the choice on the left. Hi there. Thanks for joining us. Ben Medlock, co-founder of SwiftKey, a startup that helped pioneer this technology and that is now part of Microsoft. He joins us from London. Hi. Welcome to the program. BEN MEDLOCK: Hi, Robert. SIEGEL: I'm just wondering, are there some metrics that you've learned in your work? That is, what is the likelihood of when I write a word that we can figure out what three good possibilities are of what the next word is that I have in mind? MEDLOCK: Yeah. So if you imagine that pretty much the simplest thing you could do if you wanted to predict the word that someone's going to want to say is to look at all the words they've said in the past, count them up and then choose the three that occurred most frequently and just suggest those. So that will get you to somewhere around 10 percent accuracy because language is a system where you use a lot of the same words a lot of the time. But, of course, what this doesn't take into account is any context. And so we can do a bit better than that by looking at all the things that you've said in the past again, but now, the context within which you've said them. So let's say you say the words I love. We could then look at all the words you said in that particular context and again count them up and choose the three that have the highest count. And then maybe you get the word you and the word chocolates. SIEGEL: But you're asking what I am likely to do. Are the choices that I see personal and about my use of the language, or would everybody, after seeing hi, see there as one of the most-common words to follow? MEDLOCK: You're actually spot-on. The problem with just the things you've said is that actually there's quite a lot of stuff that you say that you haven't said before in quite that way. So one of the ways we can improve on this idea of just using your own language is to blend it with lots of statistics from lots of other people. SIEGEL: Is there some metric that's known to you and your colleagues in this field as to, you know, what your batting average is, how often you can get it right? MEDLOCK: At the moment, I think it stands around a third of words - in English, at least - we can predict without the user actually having to type anything. SIEGEL: And has that rate been getting better and better over the years? MEDLOCK: It has, yeah. I think if you look back four or five years, we were probably just less than a quarter of the words. Now we're up to a third. And I'd like to think that some day we'll get towards that magic 50 percent. SIEGEL: I'm curious. Having worked on this for some years right now, which, for you, is the more impressive finding - that the way we write is really pretty predictable for most people in most occasions or that word choice shows how individual and surprising human beings are? MEDLOCK: Yeah. I think in some ways, the bread and butter of our technology is the fact that people do use language in predictable ways. And I sometimes like to think about functional language, where you're just trying to get a message across. And you quite often end up saying something that's the same when you don't really want to have to think about that. You'd kind of rather the technology did that for you. On the other hand, there are these times when we really want to be creative with language. And that's where, you know, we really don't have technology that can come anywhere near capturing the beauty of language in that way. So I think both things are very interesting and very fruitful in their different ways. SIEGEL: Well, Ben Medlock of SwiftKey, thanks for talking with us today. MEDLOCK: Thanks, Robert. ROBERT SIEGEL, HOST:  On this All Tech Considered - my last one before retiring, so I'm allowed to indulge a point of personal curiosity - we're going to hear from someone who works on word prediction. For example, I've got my smartphone open. I'm going to type out a message - capital H. And at the bottom of the screen are three choices. The middle one is hi, which is what I meant - hi. Now I have three choices, and the first one is there, which is what I meant - comma - T-H - thanks is the middle choice. Thanks for is what I meant. And now I'll do J-O-I-N. Joining is the middle choice, I'll tap that. And then us is the choice on the left. Hi there. Thanks for joining us. Ben Medlock, co-founder of SwiftKey, a startup that helped pioneer this technology and that is now part of Microsoft. He joins us from London. Hi. Welcome to the program. BEN MEDLOCK: Hi, Robert. SIEGEL: I'm just wondering, are there some metrics that you've learned in your work? That is, what is the likelihood of when I write a word that we can figure out what three good possibilities are of what the next word is that I have in mind? MEDLOCK: Yeah. So if you imagine that pretty much the simplest thing you could do if you wanted to predict the word that someone's going to want to say is to look at all the words they've said in the past, count them up and then choose the three that occurred most frequently and just suggest those. So that will get you to somewhere around 10 percent accuracy because language is a system where you use a lot of the same words a lot of the time. But, of course, what this doesn't take into account is any context. And so we can do a bit better than that by looking at all the things that you've said in the past again, but now, the context within which you've said them. So let's say you say the words I love. We could then look at all the words you said in that particular context and again count them up and choose the three that have the highest count. And then maybe you get the word you and the word chocolates. SIEGEL: But you're asking what I am likely to do. Are the choices that I see personal and about my use of the language, or would everybody, after seeing hi, see there as one of the most-common words to follow? MEDLOCK: You're actually spot-on. The problem with just the things you've said is that actually there's quite a lot of stuff that you say that you haven't said before in quite that way. So one of the ways we can improve on this idea of just using your own language is to blend it with lots of statistics from lots of other people. SIEGEL: Is there some metric that's known to you and your colleagues in this field as to, you know, what your batting average is, how often you can get it right? MEDLOCK: At the moment, I think it stands around a third of words - in English, at least - we can predict without the user actually having to type anything. SIEGEL: And has that rate been getting better and better over the years? MEDLOCK: It has, yeah. I think if you look back four or five years, we were probably just less than a quarter of the words. Now we're up to a third. And I'd like to think that some day we'll get towards that magic 50 percent. SIEGEL: I'm curious. Having worked on this for some years right now, which, for you, is the more impressive finding - that the way we write is really pretty predictable for most people in most occasions or that word choice shows how individual and surprising human beings are? MEDLOCK: Yeah. I think in some ways, the bread and butter of our technology is the fact that people do use language in predictable ways. And I sometimes like to think about functional language, where you're just trying to get a message across. And you quite often end up saying something that's the same when you don't really want to have to think about that. You'd kind of rather the technology did that for you. On the other hand, there are these times when we really want to be creative with language. And that's where, you know, we really don't have technology that can come anywhere near capturing the beauty of language in that way. So I think both things are very interesting and very fruitful in their different ways. SIEGEL: Well, Ben Medlock of SwiftKey, thanks for talking with us today. MEDLOCK: Thanks, Robert.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-12-25-572883081": {"title": "Retro-Games And Consoles Are The Latest Craze In The Gamer World  : NPR", "url": "https://www.npr.org/2017/12/25/572883081/retro-games-and-consoles-are-the-latest-craze-in-the-gamer-world", "author": "No author found", "published_date": "2017-12-25", "content": "NOEL KING, HOST:  Nintendo has a new gaming console. Well, it's kind of new. The Super NES Classic is basically just a smaller version of a system that is almost 30 years old. Despite that, it sold out in hours, which is evidence maybe of a retro gaming craze. NPR's Adhiti Bandlamudi has the story. ADHITI BANDLAMUDI, BYLINE: Kelsey Lewin is a 23-year-old gamer in Seattle, Wash. She owns over 70 different gaming systems, and her collection keeps growing. She wants to play every game on every console. She's a huge fan of Nintendo and finds the Nintendo 64, another kind of console, is especially important to her collection. KELSEY LEWIN: If you go back to the beginnings of when I started falling in love with video games, the Nintendo 64 was a really big part of that. So I do collect from some nostalgic reasons. But, yeah, a lot of it is also just because I know that I haven't played everything, and I would really like to someday. BANDLAMUDI: Lewin co-owns Pink Gorilla Games, a retro and imported videogame store. She says when she orders old consoles her customers buy them right away. A lot of it, she thinks, has to do with nostalgia. LEWIN: I definitely think that's a part of it - a big part of it, even. But a lot of it is still that it just holds up today as well. So they still enjoy playing the NES not just because they remember playing it as a kid, but because it's still fun. BANDLAMUDI: Brian Kim is a 25-year-old gamer from Virginia. He's playing \"Contra,\" one of the classic games that comes pre-downloaded on the Super NES he just bought. BRIAN KIM: When I was younger, my best friend had a Super Nintendo. And I used to go over to his house and I used to play that a lot. And there were a lot of times where I actually - because I didn't have the system I wanted to go to his house, and he wouldn't want to play because he had them. BANDLAMUDI: But these old games aren't easy to play. The controls on these old consoles aren't as sensitive to players' movements as new consoles are. Kim is struggling to play \"Contra. \"KIM: The annoying thing is you can't move and shoot at the same time. You either shoot or you move. Oh, shoot. I fell into the fire. BANDLAMUDI: And along with the revived popularity of these old consoles, there's a growing interest for the games that were played on them, too. \"Contra\" is just one of the games that's part of this revival. But people who collect these games and consoles aren't necessarily getting them to play them over and over again. KIM: It's more so of just being able to say, like, I have this system. I have it as, like, a collectible and have it kind of displayed for myself. BANDLAMUDI: This trend is sweeping the gamer world. Fans are buying other old consoles like the Atari and the Sega Genesis, too. And they're not cheap. When Nintendo brought back the Super NES, it sold for about $80. But if you're trying to get one now on eBay, you could spend anywhere from $150 to $200. Adhiti Bandlamudi, NPR News. (SOUNDBITE OF JAKE KAUFMAN'S \"JUNGLE 1\") NOEL KING, HOST:   Nintendo has a new gaming console. Well, it's kind of new. The Super NES Classic is basically just a smaller version of a system that is almost 30 years old. Despite that, it sold out in hours, which is evidence maybe of a retro gaming craze. NPR's Adhiti Bandlamudi has the story. ADHITI BANDLAMUDI, BYLINE: Kelsey Lewin is a 23-year-old gamer in Seattle, Wash. She owns over 70 different gaming systems, and her collection keeps growing. She wants to play every game on every console. She's a huge fan of Nintendo and finds the Nintendo 64, another kind of console, is especially important to her collection. KELSEY LEWIN: If you go back to the beginnings of when I started falling in love with video games, the Nintendo 64 was a really big part of that. So I do collect from some nostalgic reasons. But, yeah, a lot of it is also just because I know that I haven't played everything, and I would really like to someday. BANDLAMUDI: Lewin co-owns Pink Gorilla Games, a retro and imported videogame store. She says when she orders old consoles her customers buy them right away. A lot of it, she thinks, has to do with nostalgia. LEWIN: I definitely think that's a part of it - a big part of it, even. But a lot of it is still that it just holds up today as well. So they still enjoy playing the NES not just because they remember playing it as a kid, but because it's still fun. BANDLAMUDI: Brian Kim is a 25-year-old gamer from Virginia. He's playing \"Contra,\" one of the classic games that comes pre-downloaded on the Super NES he just bought. BRIAN KIM: When I was younger, my best friend had a Super Nintendo. And I used to go over to his house and I used to play that a lot. And there were a lot of times where I actually - because I didn't have the system I wanted to go to his house, and he wouldn't want to play because he had them. BANDLAMUDI: But these old games aren't easy to play. The controls on these old consoles aren't as sensitive to players' movements as new consoles are. Kim is struggling to play \"Contra. \" KIM: The annoying thing is you can't move and shoot at the same time. You either shoot or you move. Oh, shoot. I fell into the fire. BANDLAMUDI: And along with the revived popularity of these old consoles, there's a growing interest for the games that were played on them, too. \"Contra\" is just one of the games that's part of this revival. But people who collect these games and consoles aren't necessarily getting them to play them over and over again. KIM: It's more so of just being able to say, like, I have this system. I have it as, like, a collectible and have it kind of displayed for myself. BANDLAMUDI: This trend is sweeping the gamer world. Fans are buying other old consoles like the Atari and the Sega Genesis, too. And they're not cheap. When Nintendo brought back the Super NES, it sold for about $80. But if you're trying to get one now on eBay, you could spend anywhere from $150 to $200. Adhiti Bandlamudi, NPR News. (SOUNDBITE OF JAKE KAUFMAN'S \"JUNGLE 1\")", "section": "Culture", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-12-26-570806064": {"title": "Truck Driver By Night, Nuclear Weapon Sleuth By Day : NPR", "url": "https://www.npr.org/2017/12/26/570806064/north-korea-designed-a-nuke-so-did-this-truck-driver", "author": "No author found", "published_date": "2017-12-26", "content": "NOEL KING, HOST: This year, deep inside a mountain, North Korea detonated a giant nuclear bomb. It also launched missiles. And so for the first time since the Cold War ended, a lot of us ordinary Americans have started thinking about nuclear weapons. But one American, a big rig trucker, has been thinking about these weapons for decades, and he can't stop. NPR's Geoff Brumfiel has the story of his obsession with the bomb and what it can tell us about North Korea. GEOFF BRUMFIEL, BYLINE: John Coster-Mullen is 71 years old and lives in Milwaukee. He works for a major trucking firm delivering merchandise to big-box stores. JOHN COSTER-MULLEN: Twelve hours a night, five days one week and six days the next. BRUMFIEL: But for the past 24 years, Coster-Mullen has had an extraordinary hobby. He has carefully recreated detailed designs of America's very first nuclear weapons - Little Boy, the bomb that was dropped on Hiroshima, and Fat Man, the one that fell on Nagasaki. It all began in 1993 with a scheme to make a little money. COSTER-MULLEN: The 50th anniversary was coming up on the bombs, and maybe I could make little replicas of the bombs and sell them. BRUMFIEL: To him, it made sense. He'd grown up at the dawn of the atomic age and loved making models. He figured some like-minded baby boomer might buy them. Now, some companies were already making models of the bombs, but Coster-Mullen noticed their versions looked off. Maybe the tailfins were wrong or something like that. He thought he could do better. COSTER-MULLEN: If you're going to do it, do it real, and I'm a perfectionist. I want everything where it should be. BRUMFIEL: So to make his models, he drove 1,300 miles to the birthplace of the atomic bombs - Los Alamos, N. M. The museum there has accurate, full-scale replicas of Little Boy and Fat Man he could work from. As he designed his models, he decided he'd write a little brochure to go with them. COSTER-MULLEN: And the brochure turned into a 431-page book. BRUMFIEL: Coster-Mullen never sold a single model, but he's been adding to his bomb brochure ever since, building up what are basically complete specs on America's first nuclear weapons. He's traveled the country and the world to glean all sorts of supposedly secret details. COSTER-MULLEN: Nobody leaked anything to me. I found all this information was hiding in plain sight. BRUMFIEL: Like the time he went to a lecture by someone who'd worked on the development of the bombs and the guy had the special commemorative paperweight. COSTER-MULLEN: It turned out that paperweight, that souvenir, the mold they poured the plastic in, it was the same mold they poured the plutonium into to make the cores. BRUMFIEL: The small, nuclear cores at the center of the Fat Man-type bombs. So Coster-Mullen ran up after the lecture, made a few quick measurements and got what was once highly classified information. He also spends a lot of time poring over declassified photographs and documents and thinking about how the pieces they describe fit together. COSTER-MULLEN: I've had a lot of those aha moments where it suddenly hits you. And when I'm driving at night, I've had a lot of these where it flashes in your head and you're like, oh, oh, oh, oh, my. BRUMFIEL: Coster-Mullen lives for those aha moments, and they've added up to a very complete diagram of each bomb. I ask him to show me his design for Fat Man. COSTER-MULLEN: I used to know the page numbers, but when you keep adding stuff, the page numbers get moved around. OK, there we go. BRUMFIEL: Coster-Mullen drew it himself. The level of detail is incredible. COSTER-MULLEN: The central core is the 3. 5, 3. 6-inch diameter plutonium core. That's what they were trying to compress. BRUMFIEL: Coster-Mullen sells his book on Amazon. I tried to contact several former nuclear weapons designers about his work. None of them wanted to comment publicly on it. But Jeffrey Lewis, a scholar at the Middlebury Institute of International Studies, says conversations he's had suggests the designs are reasonably close to the real thing. JEFFREY LEWIS: I'm not in a position to judge, but I observe that people who are seem to take them seriously, and some of those people are alarmed. BRUMFIEL: But Lewis has a little bit of a different take on this. He says Coster-Mullen's odyssey shows nuclear weapons just aren't that hard. LEWIS: If a truck driver from Milwaukee can roughly replicate one, then that tells you that there is nothing mysterious about them. BRUMFIEL: The only hard part is getting the uranium or plutonium to fuel the bomb, which brings us back to North Korea. It has both. Earlier this year, it conducted a massive nuclear test of a powerful weapon at least 10 times more destructive than the Hiroshima bomb. That led to a lot of talk about stopping North Korea from advancing its technology. But Lewis says that may not be possible. LEWIS: I think we watch too many superhero movies. We imagine that we can physically prevent people from doing this, but it is so easy. BRUMFIEL: That's why Lewis says the only way to halt North Korea's progress may be to somehow convince them that it's in their best interest to stop it themselves. Geoff Brumfiel, NPR News. (SOUNDBITE OF APPALACHES' \"PISOECOURSE\") NOEL KING, HOST:  This year, deep inside a mountain, North Korea detonated a giant nuclear bomb. It also launched missiles. And so for the first time since the Cold War ended, a lot of us ordinary Americans have started thinking about nuclear weapons. But one American, a big rig trucker, has been thinking about these weapons for decades, and he can't stop. NPR's Geoff Brumfiel has the story of his obsession with the bomb and what it can tell us about North Korea. GEOFF BRUMFIEL, BYLINE: John Coster-Mullen is 71 years old and lives in Milwaukee. He works for a major trucking firm delivering merchandise to big-box stores. JOHN COSTER-MULLEN: Twelve hours a night, five days one week and six days the next. BRUMFIEL: But for the past 24 years, Coster-Mullen has had an extraordinary hobby. He has carefully recreated detailed designs of America's very first nuclear weapons - Little Boy, the bomb that was dropped on Hiroshima, and Fat Man, the one that fell on Nagasaki. It all began in 1993 with a scheme to make a little money. COSTER-MULLEN: The 50th anniversary was coming up on the bombs, and maybe I could make little replicas of the bombs and sell them. BRUMFIEL: To him, it made sense. He'd grown up at the dawn of the atomic age and loved making models. He figured some like-minded baby boomer might buy them. Now, some companies were already making models of the bombs, but Coster-Mullen noticed their versions looked off. Maybe the tailfins were wrong or something like that. He thought he could do better. COSTER-MULLEN: If you're going to do it, do it real, and I'm a perfectionist. I want everything where it should be. BRUMFIEL: So to make his models, he drove 1,300 miles to the birthplace of the atomic bombs - Los Alamos, N. M. The museum there has accurate, full-scale replicas of Little Boy and Fat Man he could work from. As he designed his models, he decided he'd write a little brochure to go with them. COSTER-MULLEN: And the brochure turned into a 431-page book. BRUMFIEL: Coster-Mullen never sold a single model, but he's been adding to his bomb brochure ever since, building up what are basically complete specs on America's first nuclear weapons. He's traveled the country and the world to glean all sorts of supposedly secret details. COSTER-MULLEN: Nobody leaked anything to me. I found all this information was hiding in plain sight. BRUMFIEL: Like the time he went to a lecture by someone who'd worked on the development of the bombs and the guy had the special commemorative paperweight. COSTER-MULLEN: It turned out that paperweight, that souvenir, the mold they poured the plastic in, it was the same mold they poured the plutonium into to make the cores. BRUMFIEL: The small, nuclear cores at the center of the Fat Man-type bombs. So Coster-Mullen ran up after the lecture, made a few quick measurements and got what was once highly classified information. He also spends a lot of time poring over declassified photographs and documents and thinking about how the pieces they describe fit together. COSTER-MULLEN: I've had a lot of those aha moments where it suddenly hits you. And when I'm driving at night, I've had a lot of these where it flashes in your head and you're like, oh, oh, oh, oh, my. BRUMFIEL: Coster-Mullen lives for those aha moments, and they've added up to a very complete diagram of each bomb. I ask him to show me his design for Fat Man. COSTER-MULLEN: I used to know the page numbers, but when you keep adding stuff, the page numbers get moved around. OK, there we go. BRUMFIEL: Coster-Mullen drew it himself. The level of detail is incredible. COSTER-MULLEN: The central core is the 3. 5, 3. 6-inch diameter plutonium core. That's what they were trying to compress. BRUMFIEL: Coster-Mullen sells his book on Amazon. I tried to contact several former nuclear weapons designers about his work. None of them wanted to comment publicly on it. But Jeffrey Lewis, a scholar at the Middlebury Institute of International Studies, says conversations he's had suggests the designs are reasonably close to the real thing. JEFFREY LEWIS: I'm not in a position to judge, but I observe that people who are seem to take them seriously, and some of those people are alarmed. BRUMFIEL: But Lewis has a little bit of a different take on this. He says Coster-Mullen's odyssey shows nuclear weapons just aren't that hard. LEWIS: If a truck driver from Milwaukee can roughly replicate one, then that tells you that there is nothing mysterious about them. BRUMFIEL: The only hard part is getting the uranium or plutonium to fuel the bomb, which brings us back to North Korea. It has both. Earlier this year, it conducted a massive nuclear test of a powerful weapon at least 10 times more destructive than the Hiroshima bomb. That led to a lot of talk about stopping North Korea from advancing its technology. But Lewis says that may not be possible. LEWIS: I think we watch too many superhero movies. We imagine that we can physically prevent people from doing this, but it is so easy. BRUMFIEL: That's why Lewis says the only way to halt North Korea's progress may be to somehow convince them that it's in their best interest to stop it themselves. Geoff Brumfiel, NPR News. (SOUNDBITE OF APPALACHES' \"PISOECOURSE\")", "section": "National Security", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-12-27-573870644": {"title": "Library Of Congress Announces It Will Be Selective In Which Tweets It Archives : NPR", "url": "https://www.npr.org/2017/12/27/573870644/library-of-congress-announces-it-will-be-selective-in-which-tweets-it-archives", "author": "No author found", "published_date": "2017-12-27", "content": "ROBERT SIEGEL, HOST: Since 2010, the Library of Congress has been collecting every single tweet published on Twitter. The idea was to create a comprehensive public archive of the social media platform for researchers to comb through and to study. But that was all easier said than done. More than half a billion tweets are sent every day, a staggering amount of information to catalog even for one of the world's biggest libraries. And yesterday the library announced that it would scale back its Twitter collection considerably and will now archive tweets on a very selective basis. Professor Michael Zimmer of the University of Wisconsin-Milwaukee has written about the challenges of storing this never-ending stream of social media data, and he joins us now. Welcome to the program. MICHAEL ZIMMER: Thank you, Robert. SIEGEL: Why is the Library of Congress rolling back its original plan to create a Twitter archive? ZIMMER: It's not terribly surprising that they've made this decision. I think when they first made the agreement in 2010, it seemed like an easier task than it's become. In those first few years, they had originally collected about 170 billion tweets. The most recent update they gave us was in 2013. And as you said, since then, there's been about 200 billion tweets per year added, and I think they've realized this is just a much larger task than they anticipated. SIEGEL: And when the Library of Congress would collect data, would they be collecting the text of the tweets or more information than that? ZIMMER: There's actually quite a bit more than just the 140 characters or - now it's 280 characters. By recent count, there's been about 50 different pieces of meta data that comes along with each tweet. So it's not just the text, but it's also your location, your account settings, IP address, whether your account is public or private, who your friends or followers might be. And then they also have to deal with other kind of policy issues like, what if someone later deletes a tweet? Should they remove that from the archive or if I make my account restricted in the future or maybe my tweet turned out to be, you know, harmful or dangerous and my account was banned from the platform? So there's all kinds of interesting policy issues alongside the technical challenges. SIEGEL: The library will still collect tweets on a selective basis. Does that mean that, say, President Trump's tweets will be stored but Joe Blow's tweets about the weather will not be stored? ZIMMER: Yeah, I think it's going to be a combination of notable accounts and also when there's certain events. There might be an election, a protests, a sporting event, and they'll collect, you know, more tweets around those certain kind of moments in time versus the entire archive of every single utterance that we're making on that platform. SIEGEL: And when they began, the Library of Congress promised access to this archive for researchers. Have researchers had that access? ZIMMER: No, not really. The library did have a small program where they were giving people some limited access - who won access - to come into the library and go through the archives. But even those people didn't get true access. They've really struggled with how to organize, how to make this searchable and make it useful for scholars. SIEGEL: You said this wasn't surprising. Are there any other ambitious projects out there that simply underestimated the scale of social media and that are collapsing under the weight of its volume? ZIMMER: Well, there are some successes - the Internet Archive of course, who is trying to archive every website. And there are, you know, smaller projects. There's a Trump Twitter archive where people are trying to collect everything that President Trump tweets. I actually manage The Zuckerberg Files, where I try to archive everything that Mark Zuckerberg says online or in media interviews. But usually these smaller-scale projects are the ones that are more successful. SIEGEL: Well, Professor Zimmer, thanks for talking with us about it today. ZIMMER: Thank you, Robert. SIEGEL: Michael Zimmer is director of the Center for Information Policy Research at the University of Wisconsin-Milwaukee. ROBERT SIEGEL, HOST:  Since 2010, the Library of Congress has been collecting every single tweet published on Twitter. The idea was to create a comprehensive public archive of the social media platform for researchers to comb through and to study. But that was all easier said than done. More than half a billion tweets are sent every day, a staggering amount of information to catalog even for one of the world's biggest libraries. And yesterday the library announced that it would scale back its Twitter collection considerably and will now archive tweets on a very selective basis. Professor Michael Zimmer of the University of Wisconsin-Milwaukee has written about the challenges of storing this never-ending stream of social media data, and he joins us now. Welcome to the program. MICHAEL ZIMMER: Thank you, Robert. SIEGEL: Why is the Library of Congress rolling back its original plan to create a Twitter archive? ZIMMER: It's not terribly surprising that they've made this decision. I think when they first made the agreement in 2010, it seemed like an easier task than it's become. In those first few years, they had originally collected about 170 billion tweets. The most recent update they gave us was in 2013. And as you said, since then, there's been about 200 billion tweets per year added, and I think they've realized this is just a much larger task than they anticipated. SIEGEL: And when the Library of Congress would collect data, would they be collecting the text of the tweets or more information than that? ZIMMER: There's actually quite a bit more than just the 140 characters or - now it's 280 characters. By recent count, there's been about 50 different pieces of meta data that comes along with each tweet. So it's not just the text, but it's also your location, your account settings, IP address, whether your account is public or private, who your friends or followers might be. And then they also have to deal with other kind of policy issues like, what if someone later deletes a tweet? Should they remove that from the archive or if I make my account restricted in the future or maybe my tweet turned out to be, you know, harmful or dangerous and my account was banned from the platform? So there's all kinds of interesting policy issues alongside the technical challenges. SIEGEL: The library will still collect tweets on a selective basis. Does that mean that, say, President Trump's tweets will be stored but Joe Blow's tweets about the weather will not be stored? ZIMMER: Yeah, I think it's going to be a combination of notable accounts and also when there's certain events. There might be an election, a protests, a sporting event, and they'll collect, you know, more tweets around those certain kind of moments in time versus the entire archive of every single utterance that we're making on that platform. SIEGEL: And when they began, the Library of Congress promised access to this archive for researchers. Have researchers had that access? ZIMMER: No, not really. The library did have a small program where they were giving people some limited access - who won access - to come into the library and go through the archives. But even those people didn't get true access. They've really struggled with how to organize, how to make this searchable and make it useful for scholars. SIEGEL: You said this wasn't surprising. Are there any other ambitious projects out there that simply underestimated the scale of social media and that are collapsing under the weight of its volume? ZIMMER: Well, there are some successes - the Internet Archive of course, who is trying to archive every website. And there are, you know, smaller projects. There's a Trump Twitter archive where people are trying to collect everything that President Trump tweets. I actually manage The Zuckerberg Files, where I try to archive everything that Mark Zuckerberg says online or in media interviews. But usually these smaller-scale projects are the ones that are more successful. SIEGEL: Well, Professor Zimmer, thanks for talking with us about it today. ZIMMER: Thank you, Robert. SIEGEL: Michael Zimmer is director of the Center for Information Policy Research at the University of Wisconsin-Milwaukee.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-12-27-573739681": {"title": "Yale University Hackathon Takes Aim At Fake News : NPR", "url": "https://www.npr.org/2017/12/27/573739681/yale-university-hosts-hackathon-aimed-at-fake-news", "author": "No author found", "published_date": "2017-12-27", "content": "NOEL KING, HOST: This month, more than a thousand students gathered at Yale University. They gathered on the basketball courts inside a huge gym and they sat down to code. STEVE INSKEEP, HOST: It was a hackathon - competitors took to the problem of fake news. The winning programmers made an extension that you can add to your Internet browser which is called Open Mind, designed to help separate the bogus from the real. KING: One of the programmers who made Open Mind says the answer to fake news requires more than code. Stefan Uddenberg is a Ph. D. candidate at Yale. STEFAN UDDENBERG: Most approaches try to train a machine to essentially delineate between fake and real news. You can't necessarily be sure that your algorithm is going to be smart enough to do so, so our approach was to rather train people on how to do this themselves. KING: Another member of the team, Michael Lopez-Brau, says that's what Open Mind does - it encourages you to seek more information. MICHAEL LOPEZ-BRAU: So as you're navigating the Web, whether it be social media site or just doing some random Google searches, our app will be tracking your browsing history and basically performing an analysis of what kind of text it is you're reading. INSKEEP: And if the computer notices you leaning in a particular political direction, it's going to let you know. You can actually go to a dashboard, see your own bias and get suggestions for reputable outlets on another side. LOPEZ-BRAU: One, we hope that people will appreciate having a very easy access to news from the other side of the aisle, and two, that people will also appreciate having real-time analytics so that they can better monitor the kind of news that they digest. UDDENBERG: Sort of like how when you're on a diet or something, you're trying to monitor your nutrition intake. The vision for this is like that but for news. KING: The programmers say they're going to launch Open Mind early next year. The prize, by the way, for winning the hackathon is a visit to Congress, where they'll get to show off their product to some very polarized news consumers. (SOUNDBITE OF AMBINATE'S \"DIVIDE\") NOEL KING, HOST:  This month, more than a thousand students gathered at Yale University. They gathered on the basketball courts inside a huge gym and they sat down to code. STEVE INSKEEP, HOST:  It was a hackathon - competitors took to the problem of fake news. The winning programmers made an extension that you can add to your Internet browser which is called Open Mind, designed to help separate the bogus from the real. KING: One of the programmers who made Open Mind says the answer to fake news requires more than code. Stefan Uddenberg is a Ph. D. candidate at Yale. STEFAN UDDENBERG: Most approaches try to train a machine to essentially delineate between fake and real news. You can't necessarily be sure that your algorithm is going to be smart enough to do so, so our approach was to rather train people on how to do this themselves. KING: Another member of the team, Michael Lopez-Brau, says that's what Open Mind does - it encourages you to seek more information. MICHAEL LOPEZ-BRAU: So as you're navigating the Web, whether it be social media site or just doing some random Google searches, our app will be tracking your browsing history and basically performing an analysis of what kind of text it is you're reading. INSKEEP: And if the computer notices you leaning in a particular political direction, it's going to let you know. You can actually go to a dashboard, see your own bias and get suggestions for reputable outlets on another side. LOPEZ-BRAU: One, we hope that people will appreciate having a very easy access to news from the other side of the aisle, and two, that people will also appreciate having real-time analytics so that they can better monitor the kind of news that they digest. UDDENBERG: Sort of like how when you're on a diet or something, you're trying to monitor your nutrition intake. The vision for this is like that but for news. KING: The programmers say they're going to launch Open Mind early next year. The prize, by the way, for winning the hackathon is a visit to Congress, where they'll get to show off their product to some very polarized news consumers. (SOUNDBITE OF AMBINATE'S \"DIVIDE\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-12-29-574693637": {"title": "Apple Issues Apology After Admitting To Slowing Down Older iPhones : NPR", "url": "https://www.npr.org/2017/12/29/574693637/apple-issues-apology-after-admitting-to-slowing-down-older-iphones", "author": "No author found", "published_date": "2017-12-29", "content": "ARI SHAPIRO, HOST: Apple is doing some damage control. iPhone owners were furious when the company admitted that it intentionally slowed down older phones to preserve battery life, Apple said. Some users filed class-action lawsuits. Now the company has put out an unsigned apology. Will Oremus is covering the story for Slate and joins us now. Hi there. WILL OREMUS: Thanks for having me. SHAPIRO: Apple says it is trying to clarify a misunderstanding by releasing this statement. What is the company actually telling customers? OREMUS: There had been these rumors going around for a long time that Apple was intentionally slowing down older iPhones each time it came out with a new one in order to get people to buy the new phone. Now, Apple assures everyone this is not what was happening, but it was discovered that Apple was in fact slowing down older iPhones for a different reason. As their batteries degraded, the phone was unexpectedly shutting down. And so to keep that from happening, they put in place a software mechanism that limited the processor speed. They didn't tell people they were doing that. Now that's what they're apologizing for. SHAPIRO: So part of the apology includes an announcement that they are going to lower the price on a new battery from 79 to $29, at least for a little while. People were pretty outraged about this initial revelation. There are at least a dozen class-action lawsuits. Do you think this is likely to satisfy angry users? OREMUS: You know, I think it is going to cause a bit of a dent to Apple's reputation in some quarters. The people who are familiar with the technical details and people who are longtime loyal Apple customers are likely to forgive the company, especially with this apology and the discount on new batteries. It really does seem like this was an error of communication and not the nefarious scheme that the conspiracy theorists had in mind. SHAPIRO: If this is damaging Apple's reputation, it does not seem to be reflected in holiday sales. According to the analytics website Flurry, which looked at the activation of new devices, about 44 percent of those new devices were iPhones or iPads. Only about a quarter of the new devices were Samsung, which is Apple's biggest rival. OREMUS: Yeah, Apple has some leeway here. I mean, they can make a mistake like this and get away with it because they command such loyalty from their consumers. It also doesn't hurt that their chief rival, Samsung, underwent a much worse PR problem recently with its exploding phones. SHAPIRO: (Laughter) Right. I guess if you have to choose a dying battery or an exploding phone, you'll go with a dying battery (laughter). OREMUS: That's right (laughter). And in fact, Apple does say that the effects whereby they've slowed down the processors on older phones has addressed the unexpected shutdown issue, at least. SHAPIRO: You've written that Apple's big mistake was not slowing down old phones but hiding the fact for so long. Explain what you mean. OREMUS: Apple has this entrenched culture of secrecy. I used to live with a couple of Apple engineers who were dating each other, and they couldn't even talk to each other about what they were doing. This kind of secrecy extends to Apple's communications with the public. They prefer to give information via these carefully stage-managed launch events that we've all come to anticipate. Now, in this case, I think it backfired because it set the stage for the types of rumors that went around, and Apple's refusal to address them earlier allowed these conspiracy theories to flourish. I think Apple has itself to blame for that. SHAPIRO: Will Oremus is the senior technology writer for Slate and co-host of the podcast \"If Then,\" speaking with us on Skype. Thanks so much for joining us. OREMUS: Thanks, Ari. ARI SHAPIRO, HOST:  Apple is doing some damage control. iPhone owners were furious when the company admitted that it intentionally slowed down older phones to preserve battery life, Apple said. Some users filed class-action lawsuits. Now the company has put out an unsigned apology. Will Oremus is covering the story for Slate and joins us now. Hi there. WILL OREMUS: Thanks for having me. SHAPIRO: Apple says it is trying to clarify a misunderstanding by releasing this statement. What is the company actually telling customers? OREMUS: There had been these rumors going around for a long time that Apple was intentionally slowing down older iPhones each time it came out with a new one in order to get people to buy the new phone. Now, Apple assures everyone this is not what was happening, but it was discovered that Apple was in fact slowing down older iPhones for a different reason. As their batteries degraded, the phone was unexpectedly shutting down. And so to keep that from happening, they put in place a software mechanism that limited the processor speed. They didn't tell people they were doing that. Now that's what they're apologizing for. SHAPIRO: So part of the apology includes an announcement that they are going to lower the price on a new battery from 79 to $29, at least for a little while. People were pretty outraged about this initial revelation. There are at least a dozen class-action lawsuits. Do you think this is likely to satisfy angry users? OREMUS: You know, I think it is going to cause a bit of a dent to Apple's reputation in some quarters. The people who are familiar with the technical details and people who are longtime loyal Apple customers are likely to forgive the company, especially with this apology and the discount on new batteries. It really does seem like this was an error of communication and not the nefarious scheme that the conspiracy theorists had in mind. SHAPIRO: If this is damaging Apple's reputation, it does not seem to be reflected in holiday sales. According to the analytics website Flurry, which looked at the activation of new devices, about 44 percent of those new devices were iPhones or iPads. Only about a quarter of the new devices were Samsung, which is Apple's biggest rival. OREMUS: Yeah, Apple has some leeway here. I mean, they can make a mistake like this and get away with it because they command such loyalty from their consumers. It also doesn't hurt that their chief rival, Samsung, underwent a much worse PR problem recently with its exploding phones. SHAPIRO: (Laughter) Right. I guess if you have to choose a dying battery or an exploding phone, you'll go with a dying battery (laughter). OREMUS: That's right (laughter). And in fact, Apple does say that the effects whereby they've slowed down the processors on older phones has addressed the unexpected shutdown issue, at least. SHAPIRO: You've written that Apple's big mistake was not slowing down old phones but hiding the fact for so long. Explain what you mean. OREMUS: Apple has this entrenched culture of secrecy. I used to live with a couple of Apple engineers who were dating each other, and they couldn't even talk to each other about what they were doing. This kind of secrecy extends to Apple's communications with the public. They prefer to give information via these carefully stage-managed launch events that we've all come to anticipate. Now, in this case, I think it backfired because it set the stage for the types of rumors that went around, and Apple's refusal to address them earlier allowed these conspiracy theories to flourish. I think Apple has itself to blame for that. SHAPIRO: Will Oremus is the senior technology writer for Slate and co-host of the podcast \"If Then,\" speaking with us on Skype. Thanks so much for joining us. OREMUS: Thanks, Ari.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-12-29-573054034": {"title": "New Wave Of Electric 2-Wheelers Hits U.S. City Streets : NPR", "url": "https://www.npr.org/2017/12/29/573054034/new-wave-of-electric-2-wheelers-hits-u-s-city-streets", "author": "No author found", "published_date": "2017-12-29", "content": "DAVID GREENE, HOST:  What do you think of an electric bike or a moped? You might think of someone using these things for fun. But elsewhere in the world, from Mexico City to Shanghai, these smaller vehicles are actually vital forms of transportation. They're more affordable. They also help alleviate congestion. Well, now some West Coast startups think mopeds and scooters might present those same advantages here in the United States as well, as NPR's Sonari Glinton reports. SONARI GLINTON, BYLINE: About 10 years ago, electric bikes were having kind of a renaissance. This is from a story by my former NPR colleague John McChesney. For context, John is a baby boomer pedaling up a hill in San Francisco with the aid of an e-bike. (SOUNDBITE OF ARCHIVED BROADCAST)JOHN MCCHESNEY: This is pretty extraordinary because I can tell you, on this hill, I would never, ever attempt it. But I'm still working out, as you can probably begin to hear. OK. Rest break. GLINTON: As that story shows, an e-bike can help you up a steep hill in San Francisco. And they're an alternative to gas-powered motors. Now, some of those smaller gas-powered motors can be more polluting than cars, and that's why a number of startups in Oregon and Southern California have sprouted up to help the commuter who wants something clean and somewhere between a bike and a car. We stand at the front of this tiny manufacturing shop in downtown Pasadena that has about half a dozen workers. You can imagine what Henry Ford or Ransom Olds first car assembly shops looked like - kind of like this. This startup is called URB-E. They make foldable scooters. PETER LEE: As you can see, like station four or five is where it all kind of comes together a little bit more. GLINTON: More than 80 percent of workers in the U. S. get to work alone in a car, truck or SUV. Now, environmentalists have long seen this as a problem, with a new wave of entrepreneurs sensing opportunity. LEE: My name is Peter Lee. I'm the CEO and co-founder of URB-E. URB-E stands for urban electric. We exist to solve the pain points of living in cities. GLINTON: Lee says the biggest pain point - traffic. LEE: So using an Uber and Lyft is great and very convenient, but using a 3,000-pound car to move a 150, 180-pound body one or 2 miles doesn't seem very convenient or efficient to us. GLINTON: Lee says these vehicles solved the problem of the last mile - you know, the trip to the grocery store or those eight blocks to the nearest bus or train. Now, these startups want to make those trips easier and cleaner. RYAN RZPECKI: There needs to be a different class of vehicle. It could be scooters. It could be electric bikes. It could be kick scooters. It could be a lot of different things. But driving around in everybody's own personal automobile is not the way forward. GLINTON: Ryan Rzpecki is CEO of JUMP Mobility. His company makes a shared electric bike. RZPECKI: One, you're not going to get sweaty because you're not exerting yourself nearly as much. Two, you can go up the hills no problem. Three, you can wear normal clothes. And, four, it is cooler. GLINTON: As cities around the globe look to ban cars in their central business districts and parking remains a premium, entrepreneurs say these small vehicles are there to fill in the gaps. LEE: Both feet are on the ground right now. Your right hand is on our throttle, so go ahead and twist that throttle back a little bit slightly. GLINTON: Oh. LEE: There you go. GLINTON: Peter Lee with URB-E lets me go on a joy ride. LEE: And as you go, you can just put your feet on the back pegs. GLINTON: Oh. LEE: And both feet will come up, and there you go. And the right hand is the brake. GLINTON: I think I scared that lady there. If I don't come back, Sonari Glinton, NPR News. (SOUNDBITE OF PRAY FOR SOUND'S \"CONGRATULATIONS, YOU'RE ALIVE\") DAVID GREENE, HOST:   What do you think of an electric bike or a moped? You might think of someone using these things for fun. But elsewhere in the world, from Mexico City to Shanghai, these smaller vehicles are actually vital forms of transportation. They're more affordable. They also help alleviate congestion. Well, now some West Coast startups think mopeds and scooters might present those same advantages here in the United States as well, as NPR's Sonari Glinton reports. SONARI GLINTON, BYLINE: About 10 years ago, electric bikes were having kind of a renaissance. This is from a story by my former NPR colleague John McChesney. For context, John is a baby boomer pedaling up a hill in San Francisco with the aid of an e-bike. (SOUNDBITE OF ARCHIVED BROADCAST) JOHN MCCHESNEY: This is pretty extraordinary because I can tell you, on this hill, I would never, ever attempt it. But I'm still working out, as you can probably begin to hear. OK. Rest break. GLINTON: As that story shows, an e-bike can help you up a steep hill in San Francisco. And they're an alternative to gas-powered motors. Now, some of those smaller gas-powered motors can be more polluting than cars, and that's why a number of startups in Oregon and Southern California have sprouted up to help the commuter who wants something clean and somewhere between a bike and a car. We stand at the front of this tiny manufacturing shop in downtown Pasadena that has about half a dozen workers. You can imagine what Henry Ford or Ransom Olds first car assembly shops looked like - kind of like this. This startup is called URB-E. They make foldable scooters. PETER LEE: As you can see, like station four or five is where it all kind of comes together a little bit more. GLINTON: More than 80 percent of workers in the U. S. get to work alone in a car, truck or SUV. Now, environmentalists have long seen this as a problem, with a new wave of entrepreneurs sensing opportunity. LEE: My name is Peter Lee. I'm the CEO and co-founder of URB-E. URB-E stands for urban electric. We exist to solve the pain points of living in cities. GLINTON: Lee says the biggest pain point - traffic. LEE: So using an Uber and Lyft is great and very convenient, but using a 3,000-pound car to move a 150, 180-pound body one or 2 miles doesn't seem very convenient or efficient to us. GLINTON: Lee says these vehicles solved the problem of the last mile - you know, the trip to the grocery store or those eight blocks to the nearest bus or train. Now, these startups want to make those trips easier and cleaner. RYAN RZPECKI: There needs to be a different class of vehicle. It could be scooters. It could be electric bikes. It could be kick scooters. It could be a lot of different things. But driving around in everybody's own personal automobile is not the way forward. GLINTON: Ryan Rzpecki is CEO of JUMP Mobility. His company makes a shared electric bike. RZPECKI: One, you're not going to get sweaty because you're not exerting yourself nearly as much. Two, you can go up the hills no problem. Three, you can wear normal clothes. And, four, it is cooler. GLINTON: As cities around the globe look to ban cars in their central business districts and parking remains a premium, entrepreneurs say these small vehicles are there to fill in the gaps. LEE: Both feet are on the ground right now. Your right hand is on our throttle, so go ahead and twist that throttle back a little bit slightly. GLINTON: Oh. LEE: There you go. GLINTON: Peter Lee with URB-E lets me go on a joy ride. LEE: And as you go, you can just put your feet on the back pegs. GLINTON: Oh. LEE: And both feet will come up, and there you go. And the right hand is the brake. GLINTON: I think I scared that lady there. If I don't come back, Sonari Glinton, NPR News. (SOUNDBITE OF PRAY FOR SOUND'S \"CONGRATULATIONS, YOU'RE ALIVE\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-12-31-574835604": {"title": "Emojis Of 2018: Bagels, Kangaroos, Redheads Are In. 'Frowning Pile Of Poo' Is Out : NPR", "url": "https://www.npr.org/2017/12/31/574835604/emojis-of-2018-bagels-kangaroos-redheads-are-in-frowning-pile-of-poo-is-out", "author": "No author found", "published_date": "2017-12-31", "content": "RAY SUAREZ, HOST: Staying on the topic of words of the year, let's talk about one of the winners from two years ago - emoji - you know, those little cartoon-like pictures. One of the things to look forward to in 2018 is that dozens of new emojis will be unveiled. One of the most popular additions - redheads. JEREMY BURGE: Red hair, yeah. People felt like they were getting left out. SUAREZ: That's Jeremy Burge. We reached him at his home in London. He's vice-chair of the Unicode Emoji Subcommittee - yes, that's a real thing. He also runs a website called Emojipedia, devoted to every minute change that has happened to the 2,600 emojis over the years. BURGE: This is what I do - emojis from when I wake up until when I go to bed. SUAREZ: Burge is responsible for the new emoji with red hair. BURGE: Even though I don't have red hair myself, that was the No. 1 request we got for the last two years running, so I felt like I should step up and try and make that happen. SUAREZ: The committee looks at all the proposed additions and winnows down the list, in part based on how useful they expect the new emoji to be. So far this year, three proposed emojis didn't make the cut. BURGE: A face with question marks over the eyes, a face that had the letters O and K over the eyes and pile of poo version that was frowning rather and smiling. SUAREZ: Michael Everson was one of the impassioned commenters who helped kill the frowning excrement. We reached him on Skype about an hour west of Dublin. MICHAEL EVERSON: Why do we need to send a picture of this? It's just - ah. It's just offensive - needlessly offensive and pointless. It's not cute. It's not funny. It isn't good in any particular way. I don't mind lobster, parrot, peacock, badger - these are good. These are fine. But is there to be an end of it? Could we not have any class? SUAREZ: Well, if you're looking for class, there's also a cupcake, a superhero, a llama and a teddy bear. Now that's something to smiley face about. RAY SUAREZ, HOST:  Staying on the topic of words of the year, let's talk about one of the winners from two years ago - emoji - you know, those little cartoon-like pictures. One of the things to look forward to in 2018 is that dozens of new emojis will be unveiled. One of the most popular additions - redheads. JEREMY BURGE: Red hair, yeah. People felt like they were getting left out. SUAREZ: That's Jeremy Burge. We reached him at his home in London. He's vice-chair of the Unicode Emoji Subcommittee - yes, that's a real thing. He also runs a website called Emojipedia, devoted to every minute change that has happened to the 2,600 emojis over the years. BURGE: This is what I do - emojis from when I wake up until when I go to bed. SUAREZ: Burge is responsible for the new emoji with red hair. BURGE: Even though I don't have red hair myself, that was the No. 1 request we got for the last two years running, so I felt like I should step up and try and make that happen. SUAREZ: The committee looks at all the proposed additions and winnows down the list, in part based on how useful they expect the new emoji to be. So far this year, three proposed emojis didn't make the cut. BURGE: A face with question marks over the eyes, a face that had the letters O and K over the eyes and pile of poo version that was frowning rather and smiling. SUAREZ: Michael Everson was one of the impassioned commenters who helped kill the frowning excrement. We reached him on Skype about an hour west of Dublin. MICHAEL EVERSON: Why do we need to send a picture of this? It's just - ah. It's just offensive - needlessly offensive and pointless. It's not cute. It's not funny. It isn't good in any particular way. I don't mind lobster, parrot, peacock, badger - these are good. These are fine. But is there to be an end of it? Could we not have any class? SUAREZ: Well, if you're looking for class, there's also a cupcake, a superhero, a llama and a teddy bear. Now that's something to smiley face about.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2017-12-31-574792184": {"title": "Lawsuits Mount As Apple Manages Fallout From Revelation Of Slowed iPhones  : NPR", "url": "https://www.npr.org/2017/12/31/574792184/lawsuits-mount-as-apple-manages-fallout-from-revelation-of-slowed-iphones", "author": "No author found", "published_date": "2017-12-31", "content": "LAUREN FRAYER, HOST: Apple had a message for its customers this past week - we apologize. People have been angry ever since the company confirmed its software update slowed down older iPhone's with aging batteries. Apple says it did that to prevent those iPhones from shutting down unexpectedly. This apology might help on the public relations front, but what about the legal one? Apple's still facing lawsuits from iPhone owners in California, in New York and Illinois. To help sort through this, we're joined by Rory Van Loo. He's an associate professor of law at Boston University with a focus on tech and regulation. Welcome. RORY VAN LOO: Thank you. FRAYER: So lawsuits have been filed in all of these different states. Very broadly, what claims are these lawsuits making against Apple? VAN LOO: There's contract law claims, which essentially amount to, look, we had an agreement that you, Apple, would do certain things, like take good care of my phone and not slow it down, be transparent in what you're telling me you're doing, and you breached that. There's a second category of claims that amount to essentially you harmed something I own. Whether or not we had an agreement, you went and you slowed down something that I bought from you in the past, and you shouldn't have done that. And then there's a third category of claims that are consumer protection violations. So you did something unfair or deceptive. You changed my phone in a harmful way, didn't tell me you were doing that, and that caused me to go and spend a lot of money on a new phone when, if you'd just been transparent with me about what you had been doing, I could have gone and bought a cheaper battery. FRAYER: I gather it varies by state, but what do these plaintiffs need to prove for some of these claims? VAN LOO: The plaintiffs are going to need to prove for their fraud claims in some jurisdictions that Apple intended to promote new phone sales by slowing down old phones. FRAYER: That this was some kind of plot, a sales tactic. VAN LOO: Yes. For all claims, it's going to need to prove some kind of harm. They're going to need to show that Apple intentionally withheld information about slowing down the phone. They're going to need to show that consumers would have made a different decision not to buy a new phone and instead to purchase a lower priced battery in order to establish harm. FRAYER: It's still very early in the legal process, but what are the chances that these lawsuits will win against the tech giant Apple? VAN LOO: All of the lawsuits face an uphill battle. That being said, if I were Apple, I would be nervous right now. For one, Apple has lost a number of cases across the country on some similar arguments in recent years. Just last month, Apple suffered a setback on an older lawsuit, and in that older case, iPhone 4 users had argued that an Apple software update made their phones buggy and unusable even though Apple had said that the software upgrade would enhance performance. And Apple tried to get that case thrown out before it ever got off the ground and, in its initial response, used one of the arguments that it's likely to make in the current cases, which is, look, we told you in the fine print for the software update that things might go wrong, so we never made any promises. FRAYER: So is the moral of the story here we better read that fine print? I mean, every time you have an update and you click OK, OK, I mean, have we agreed to things that we didn't realize we were agreeing to? VAN LOO: Yes and no. I mean, Apple is not going to be protected completely by what it puts in the fine print. And the reason is that you have to be very specific about what you say in the fine print. And as far as I'm aware, it didn't anywhere say we may slow down your phones with our updates. FRAYER: But they did say that now in the apology, that they didn't intentionally shorten the life of a product. VAN LOO: Apple's apology this past week is not going to protect them from what they did last month and last year. And so that's the problem that they face right now. I think the apology is going to make some consumers happier, and it's going to help their image in the court of public opinion, if you will. And that - that's not irrelevant, actually, to lawsuits because judges and juries are human, and so to the extent that Apple is going to appear to be exercising good faith here because of their apology, that's good for Apple, but it doesn't free them of the potential legal liability. FRAYER: Rory Van Loo is an associate professor of law at Boston University. Thank you. VAN LOO: Thank you. LAUREN FRAYER, HOST:  Apple had a message for its customers this past week - we apologize. People have been angry ever since the company confirmed its software update slowed down older iPhone's with aging batteries. Apple says it did that to prevent those iPhones from shutting down unexpectedly. This apology might help on the public relations front, but what about the legal one? Apple's still facing lawsuits from iPhone owners in California, in New York and Illinois. To help sort through this, we're joined by Rory Van Loo. He's an associate professor of law at Boston University with a focus on tech and regulation. Welcome. RORY VAN LOO: Thank you. FRAYER: So lawsuits have been filed in all of these different states. Very broadly, what claims are these lawsuits making against Apple? VAN LOO: There's contract law claims, which essentially amount to, look, we had an agreement that you, Apple, would do certain things, like take good care of my phone and not slow it down, be transparent in what you're telling me you're doing, and you breached that. There's a second category of claims that amount to essentially you harmed something I own. Whether or not we had an agreement, you went and you slowed down something that I bought from you in the past, and you shouldn't have done that. And then there's a third category of claims that are consumer protection violations. So you did something unfair or deceptive. You changed my phone in a harmful way, didn't tell me you were doing that, and that caused me to go and spend a lot of money on a new phone when, if you'd just been transparent with me about what you had been doing, I could have gone and bought a cheaper battery. FRAYER: I gather it varies by state, but what do these plaintiffs need to prove for some of these claims? VAN LOO: The plaintiffs are going to need to prove for their fraud claims in some jurisdictions that Apple intended to promote new phone sales by slowing down old phones. FRAYER: That this was some kind of plot, a sales tactic. VAN LOO: Yes. For all claims, it's going to need to prove some kind of harm. They're going to need to show that Apple intentionally withheld information about slowing down the phone. They're going to need to show that consumers would have made a different decision not to buy a new phone and instead to purchase a lower priced battery in order to establish harm. FRAYER: It's still very early in the legal process, but what are the chances that these lawsuits will win against the tech giant Apple? VAN LOO: All of the lawsuits face an uphill battle. That being said, if I were Apple, I would be nervous right now. For one, Apple has lost a number of cases across the country on some similar arguments in recent years. Just last month, Apple suffered a setback on an older lawsuit, and in that older case, iPhone 4 users had argued that an Apple software update made their phones buggy and unusable even though Apple had said that the software upgrade would enhance performance. And Apple tried to get that case thrown out before it ever got off the ground and, in its initial response, used one of the arguments that it's likely to make in the current cases, which is, look, we told you in the fine print for the software update that things might go wrong, so we never made any promises. FRAYER: So is the moral of the story here we better read that fine print? I mean, every time you have an update and you click OK, OK, I mean, have we agreed to things that we didn't realize we were agreeing to? VAN LOO: Yes and no. I mean, Apple is not going to be protected completely by what it puts in the fine print. And the reason is that you have to be very specific about what you say in the fine print. And as far as I'm aware, it didn't anywhere say we may slow down your phones with our updates. FRAYER: But they did say that now in the apology, that they didn't intentionally shorten the life of a product. VAN LOO: Apple's apology this past week is not going to protect them from what they did last month and last year. And so that's the problem that they face right now. I think the apology is going to make some consumers happier, and it's going to help their image in the court of public opinion, if you will. And that - that's not irrelevant, actually, to lawsuits because judges and juries are human, and so to the extent that Apple is going to appear to be exercising good faith here because of their apology, that's good for Apple, but it doesn't free them of the potential legal liability. FRAYER: Rory Van Loo is an associate professor of law at Boston University. Thank you. VAN LOO: Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2017 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}}