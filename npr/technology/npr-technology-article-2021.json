{"2021-01-04-953314603": {"title": "RIP Flash Player: Adobe Ends Support Of Pioneering Web Animation Technology : NPR", "url": "https://www.npr.org/2021/01/04/953314603/rip-flash-player-adobe-ends-support-of-pioneering-web-animation-technology", "author": "No author found", "published_date": "2021-01-04", "content": "AILSA CHANG, HOST:  A moment now to remember a pioneering Internet technology. Adobe Flash Player is dead. Long live Adobe Flash Player. (SOUNDBITE OF ARCHIVED RECORDING)DAVID FIRTH: (As Salad Fingers) Hello. I like rusty spoons. I like to touch them. AUDIE CORNISH, HOST:  \"Salad Fingers\" was one of the many Web cartoons, games and animations that Flash made possible, but Flash has been on its way out for years. Adobe announced end-of-life plans in 2017 and officially ended support on January 1. ANASTASIA SALTER: Adobe Flash was the tool that reimagined the Web. CORNISH: Anastasia Salter is an associate professor of English at the University of Central Florida. She co-wrote a book on Flash. SALTER: It took us out of a fairly static, text-based Web to an animated, interactive space and really shaped a whole generation of artists and animators. CHANG: Flash helped people create games and stories and other playable work and post them online. Those early animations may feel rudimentary compared to what you might see from, say, Pixar. But in the early 2000s, people like Salter found Flash miraculous. SALTER: No one had really imagined having a tool like that for an individual to make something interactive. And it's where we get kind of all of the cool early experiments like \"Homestar Runner. \"(SOUNDBITE OF ARCHIVED RECORDING)MATT CHAPMAN: (As Strong Bad, singing) Oh, tap your toes and check your email. Hey, Strong Bad, what's up? Can you play the guitar? CORNISH: Salter says people started to migrate away from Flash around 2012. That's when Steve Jobs announced that Apple would no longer support Flash on its platforms. SALTER: And it was really frustrating because Flash was so good at bringing new people into making things. CHANG: Salter says the technologies that took its place weren't as easy to learn. But they operated on open standards not a proprietary one, so Web browsers adapted new standards. And the Adobe Flash Player has now been laid to rest. AILSA CHANG, HOST:   A moment now to remember a pioneering Internet technology. Adobe Flash Player is dead. Long live Adobe Flash Player. (SOUNDBITE OF ARCHIVED RECORDING) DAVID FIRTH: (As Salad Fingers) Hello. I like rusty spoons. I like to touch them. AUDIE CORNISH, HOST:   \"Salad Fingers\" was one of the many Web cartoons, games and animations that Flash made possible, but Flash has been on its way out for years. Adobe announced end-of-life plans in 2017 and officially ended support on January 1. ANASTASIA SALTER: Adobe Flash was the tool that reimagined the Web. CORNISH: Anastasia Salter is an associate professor of English at the University of Central Florida. She co-wrote a book on Flash. SALTER: It took us out of a fairly static, text-based Web to an animated, interactive space and really shaped a whole generation of artists and animators. CHANG: Flash helped people create games and stories and other playable work and post them online. Those early animations may feel rudimentary compared to what you might see from, say, Pixar. But in the early 2000s, people like Salter found Flash miraculous. SALTER: No one had really imagined having a tool like that for an individual to make something interactive. And it's where we get kind of all of the cool early experiments like \"Homestar Runner. \" (SOUNDBITE OF ARCHIVED RECORDING) MATT CHAPMAN: (As Strong Bad, singing) Oh, tap your toes and check your email. Hey, Strong Bad, what's up? Can you play the guitar? CORNISH: Salter says people started to migrate away from Flash around 2012. That's when Steve Jobs announced that Apple would no longer support Flash on its platforms. SALTER: And it was really frustrating because Flash was so good at bringing new people into making things. CHANG: Salter says the technologies that took its place weren't as easy to learn. But they operated on open standards not a proprietary one, so Web browsers adapted new standards. And the Adobe Flash Player has now been laid to rest.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-01-04-953198140": {"title": "Google Workers Launch Union To Press Grievances With Executives : NPR", "url": "https://www.npr.org/2021/01/04/953198140/google-workers-launch-union-to-press-grievances-with-executives", "author": "No author found", "published_date": "2021-01-04", "content": "", "section": "Business", "disclaimer": ""}, "2021-01-05-953677826": {"title": "U.S. Security Agencies: Massive Computer Hack Is 'Likely Russian'  : NPR", "url": "https://www.npr.org/2021/01/05/953677826/u-s-security-agencies-massive-computer-hack-is-likely-russian", "author": "No author found", "published_date": "2021-01-05", "content": "", "section": "National Security", "disclaimer": ""}, "2021-01-05-953515627": {"title": "Facial Recognition And Beyond: Venturing Inside China's 'Surveillance State' : NPR", "url": "https://www.npr.org/2021/01/05/953515627/facial-recognition-and-beyond-journalist-ventures-inside-chinas-surveillance-sta", "author": "No author found", "published_date": "2021-01-05", "content": "DAVE DAVIES, HOST:  This is FRESH AIR. I'm Dave Davies, in today for Terry Gross. Our guest today, journalist Kai Strittmatter, says while Americans worry a lot about the threat Russia poses to the United States, the real challenge to liberal democracy will come not from a stagnant Russia but from the authoritarian economic powerhouse of China. Strittmatter speaks fluent Mandarin and has studied China for more than 30 years. In a new book, he warns that the regime of Chinese President Xi Jinping has embraced an ideological rigidity unknown since the days of Mao Tse-tung and a level of control over its population that is simply unprecedented. Strittmatter describes an astonishing level of surveillance exercised by the Chinese state over its citizens, generating massive databases used to punish people for even minor deviations from expected norms of behavior. And he says China is aggressively using its state-controlled technology firms to infiltrate and influence Western institutions and is marketing its authoritarian system as a model for other nations to follow. Kai Strittmatter was the China correspondent for more than a decade for Suddeutsche Zeitung, one of Germany's largest newspapers. He now works in Copenhagen. His new book is \"We Have Been Harmonized: Life In China's Surveillance State. \" He joins me from his home in Copenhagen. Kai Strittmatter, welcome to FRESH AIR. Xi Jinping takes power in 2012. He has a country riddled with corruption. But he doesn't just bring an economic agenda, does he? KAI STRITTMATTER: No. He surprised all of us, actually. I actually came back to China just a couple of months before he took power. I was there in - for my second stint in Beijing in summer of 2012. And everybody knew that the incoming new strongman had to do something because the country was sort of in a state of crisis. There was, really, a kind of a fin-de-siecle feeling all around in society and politics with whomever you spoke. But actually, most people I spoke to, and even party members and people inside party institutions, they thought that maybe Xi Jinping would start with reforms more in the liberal kind of way, you know, like more towards independence of courts, independence of media and something like this. This was, at least, the hope that many people had. And everybody was completely surprised by how it turned out, really. Nobody had expected that Xi Jinping would do to China what he did. And in fact, actually, he created a completely new creature. It's really a new kind of regime and state that we haven't seen before. DAVIES: You know, it's interesting because, you know, he wears a Western business suit in sharp contrast to the image of, you know, Mao Tse-tung, who wore, you know, the military jacket. Describe his ideological agenda for China. STRITTMATTER: One of the first things he did is he put the party back into control, you know? In the decades before, with the reforms of Deng Xiaoping, the opening of the country, the economic success, the growth, we had seen a much freer society and a much more liberal economy developing. And there was a - there were things like civil society China. And many aspects actually started to resemble a little bit our own societies, you know, which brought many of us, actually, to think - to believe in a kind of China fantasy - you know, someday, China will become like us. So there comes Xi Jinping now. And what he does is he actually does away with many of these things. He does away, in effect, with the China we have come to know for three or four decades. The China that you see now is no longer the China that we all grew up with. And what he did was he put the party back in total control. And he brought back a centralization of power. He brought back one-man rule. He brought back, actually, a cult of personality, things that we haven't seen since the days of Mao Tse-tung. And he brought back ideology in a big way. And he's still - he's speaking a lot about Marx. He has his own thought, you know? In Chinese universities, suddenly, everywhere, there are new faculties springing up teaching the Xi Jinping thoughts and the Xi Jinping ideas. And while he speaks about Marx all the time - you know, Marx was more, like, the kind of idealist thinker of socialism. In fact, what he is, he's more a Leninist. It's more about power in the end. And that is, actually, his big goal. He speaks a lot about making China great again, the big China dream. But, in effect, you know, what he does is and what his main aim is, actually, secure the power of the Communist Party for eternity. DAVIES: Now, you were in China as this began to take shape. Were there ideological purges in universities among journalists? I mean, what was it - how did you see this unfold? STRITTMATTER: Actually, there were, yeah. It was very interesting because there were purges, actually, in waves. And it hit a different segment of society and of the institutions every time. It started with the bloggers, with the Internet, then came universities and the party itself. You know, the party members suddenly started to have to be afraid. A lot of it, actually, took place under the guise of the anti-corruption campaign, because the same people who actually are in charge of the anti-corruption campaign, this is the disciplinary commission of the Communist Party, that's actually the arm of the Communist Party that is responsible for ideological discipline also. And so they conducted these purges. And a lot of times, you know, these purges were accompanied by, for example, show trials, you know? Suddenly you would have a civil rights lawyer on TV being tried for crimes that were obvious he didn't commit. And then, the next time, it was, maybe, a famous show star. Then it was a journalist and so on. And fear came back. The people started to fall silent again. And party control came back. DAVIES: I think one of the strangest measures of how extreme this became that you describe in the book was that donors to the sperm bank at a hospital in Peking had to pass an ideological test. STRITTMATTER: Yes. And that's, of course, one of those absurdities. You know, I'm sure Xi Jinping didn't think of this. But this is how it works in autocratic regimes, you know? You have the big guy on the top. And everybody else is following him. Well, first, you know, they're all ducking away. And then, when there is a policy, they all - they're all trying to second-guess him. And they're all trying to outdo his policies, you know? And so you get these absurd things like the sperm bank you describe are suddenly, you know - you have things reappearing that we didn't see since the times of Mao Tse-tung. Suddenly, you have scientists writing papers about the ozone level in Beijing and air pollution in Beijing as seen from a Marxist perspective, you know, these kind of absurd sort of things that serve as nothing else but a sign of ideological submission. All this was gone. China was a very pragmatic country. This was one of the basic traits of the China of Deng Xiaoping. And suddenly, these absurdities are reappearing. DAVIES: We're going to take a break here. Let me reintroduce you. Kai Strittmatter is a journalist who has spent years reporting on China. His new book is \"We Have Been Harmonized: Life In China's Surveillance State. \" We'll be back after a short break. This is FRESH AIR. (SOUNDBITE OF YING QUARTET'S \"LARGHETTO NOSTALGICO\")DAVIES: This is FRESH AIR. And we're speaking with Kai Strittmatter. He was the China correspondent for more than a decade for one of Germany's largest newspapers. His new book about the growth of authoritarianism and social control in China is \"We Have Been: Harmonized Life In China's Surveillance State. \"You write a lot about the new level of social control. And a lot of it starts with technology. Xi Jinping is determined to make China a leader in artificial intelligence. How does he do it? What are the implications of that? STRITTMATTER: Yeah. This is the thing. So on the one hand, you have a guy who is reintroducing repression on a scale that we haven't seen since Mao Tse-tung. So he's basically, you know, with one foot going back into the past. But with his other foot, he's going far, far into the future and really embracing all this new information technology and artificial intelligence and big data, like, I would say no other government on the planet actually does it, and certainly no other authoritarian government. I mean, this is one of the remarkable things, right? I mean, we have been told for so many years and decades by these tech prophets that every kind of new technology would actually serve the cause of freedom and would undermine and subvert authoritarian rule. Well, the Chinese, they have shown us already for a long time - for example, with the Internet, already for 20 years, more than 20 years - that they're not only not afraid of those new technologies, but on the contrary, they have grown to love them and really love them big time. The Communist Party doesn't see those new technologies as a danger to their rule. On the contrary, they have discovered or they think that, actually, these new technologies give them new instruments that will perfect their rule and will make it - will make their rule crisis-proof. And now, that's the same thing with artificial intelligence and big data. DAVIES: There's a big investment in China in facial recognition technology and a lot of cameras. I mean, these numbers are incredible that you quoted. 2016, there were 176 million surveillance cameras in the country. It's a big country, but that's a lot. And then you say, as many as 600 million surveillance cameras now. Tell us what kind of capability this presents. Where do all these pictures go? How are they used? STRITTMATTER: Yeah. So that's the difference to before, right? I mean, I'm a German, you know? We had the fall of the Berlin Wall in 1989. And then we were actually one of the few countries, I would say, where you actually could study, and you still can study, the means and instruments of dictatorship - of the arms of the dictatorship. We have a state security museum of the former eastern German state security. And one of the lessons that historians have taken from that is, actually, they were overwhelmed by the mass of data that they actually collected by their own paranoia. Now, with new information technology, you know, this is suddenly changing because you're not - no longer having real people sitting. There's no policemen sitting behind these cameras, you know, at a screen and watching them and trying to watch, like - you know, a whole bunch of policemen trying to watch 10,000 cameras. Instead, you have algorithms. You have artificial intelligence, actually, working there. And that makes it much more effective. So for example, already, in 2018 - you know, if you're asking, what have they achieved already? In 2018, The People's Daily, which is the party's central newspaper, it claimed on Twitter, in English language - you can Google that, actually. You know, Twitter is forbidden inside China. But they still use it for propaganda purposes. So you can see they're very proud of these achievements also. So they claimed on Twitter that, already now, their Skynet - this is what they're calling this network of surveillance cameras, Skynet, like the one in \"The Terminator. \" I don't know whether you've seen the movies. Their Skynet is already capable of identifying each and every single one of their 1. 4 billion citizens in the course of one second. DAVIES: What does that mean, to identify them all in one second? What is that describing? STRITTMATTER: That means if you're looking for someone, you know, and you have his or her picture in your database and you feed that picture in your database and you tell the algorithm - or you ask the algorithm, you ask the computer, to tell you the moment once this person is actually stepping on the street, that once they're stepping outside of their home and getting into the reach of one of those surveillance cameras, it doesn't take more than one second that the computer will actually alarm you. They're here and there. And you can go and pick up - pick them up there. DAVIES: You are never alone. (Laughter) Wow. STRITTMATTER: You are never alone, exactly. But a question back then, you know, is it even true? And then, very soon, you realize it doesn't even matter whether it's true or not as long as people believe it. This is one of the central - this is a very important point, you know, because what the Communist Party is doing with all these high-tech surveillance technology now is they're trying to internalizing control, you know? They're trying to make people self-censor themselves much more than they used to do. And once, you know, you believe it's true, it's like you don't even need the policeman at the corner anymore because you're becoming your own policeman. DAVIES: Information is gathered from other methods besides, of course, all of these surveillance cameras. And that's - a lot of that is the digital footprints that Chinese citizens leave. You write that most purchases in China are now digital. Even street beggars use barcodes to collect handouts. This is true? STRITTMATTER: Yeah. DAVIES: What do they use? (LAUGHTER)STRITTMATTER: At least in Beijing they're doing it, you know, because - I mean, everybody has been asking for a long time the question, can authoritarian regimes actually be innovative, you know? And I think China, up to a certain point, has proved, of course they can, you know? In terms of, like, for example, fintech applications or the apps they use on their daily mobile phones, they're really, in some sense, much more advanced to anything that we use. There's this one app on every Chinese mobile phone that's called WeChat. And in WeChat - with WeChat, basically, you can live your whole life in WeChat. You can - it started as a normal chat program like WhatsApp. But very soon, it turned into a kind of Chinese Facebook. Then it became a Chinese Uber. You use - you could get credit. You could apply for credit to your bank with it. You could use it as an ID, actually. You could file your divorce papers through this app to the local court. And you can do all your financial transactions through this app. And that works with barcodes. And they've been using these barcodes for a long time already. I mean, I left China two years ago. But it's been a thing of four and five years. You know, the Chinese, when they look at us - and some of my friends, my Chinese friends, they go travelling to Europe. And they come back and say, oh, it's beautiful in Europe. And it's so romantic. But really, I mean, you're so far behind us, you know? It's really - I can't believe how advanced we are already technologically compared to you, you know? It's so convenient what we can do with our apps and everything. And when they talk about cashless payment - you know, I'm living in Scandinavia now. There's also - cashless payment is the main form of payment. I think 80%, 90% of all transactions are done cashless here. But in Denmark, in Sweden, in Norway, cashless payment means you use your credit card, you know, most of the times. Nobody in China uses credit cards. Nobody has been using them for years. Everybody does everything with their mobile phones, you know? And so you come to the point that even street beggars use them. And they will tell you, it's so convenient. How come you don't use it? Of course, it's convenient. It's amazingly convenient. But at the same time, it's also amazingly convenient for state security. And every single one of your transactions will actually end up on one of their servers. DAVIES: Right. So WeChat is - you know, it's a payment service, kind of like Venmo. You can transfer money. It's a social media platform. It's a messaging app. It's all these other things. STRITTMATTER: Exactly. DAVIES: And the government extracts all this information about you. What's been your experience in terms of seeing how citizens feel the presence of the state through information they get from this WeChat app? STRITTMATTER: I mean, the thing is, you know, Chinese citizens have - they've been used to that. They feel the presence of the state. They've been feeling the presence of the state for all their life. And, of course, I had some friends who actually - they were, in the end - I mean, you realize that sometimes when some of your chats are being censored, you know? Suddenly, words or sentences are missing. That's like the first step before they delete your account or anything. And they never reach the other party. Or you don't actually get part of the conversation that your friends send you. This is, like, something that many Chinese experience. But then, on the next level, it gets - you know, if you're, like, politically interested, if you're, maybe, a little bit in the activist line - I had some friends like this, and I actually had two of them. I saw two of them getting arrested because of their WeChat records, because they had actually, on WeChat, agreed with other people, with friends, to go to a poetry reading where a poet in Beijing was supposed to read some poems supporting the students in Hong Kong in their struggle for democracy. And they never made it to the poetry reading. They were arrested on the way. And it was clearly because of their WeChat conversations. And, actually, I myself had the same experience. I had, like, appointments with friends for interviews. But, like, this one guy, we agreed to meet in a hotel, in a Beijing hotel via WeChat. And I got there. And, like, after half an hour, I get a message from him, this time not on WeChat, but on - through FaceTime or through the iPhone messaging app. And he tells me, I'm sorry I'm late. I'm sure you understand why. And, of course, I immediately knew why. And later then he told me that state security had called him immediately after they saw our appointment on WeChat and told him and threatened him not to come and see me. DAVIES: We're going to take another break here. Let me introduce you. Kai Strittmatter is a veteran China correspondent. His new book is \"We Have Been Harmonized: Life In China's Surveillance State. \" He'll be back to talk more after a short break. I'm Dave Davies. And this is FRESH AIR. (SOUNDBITE OF MUSIC)DAVIES: This is FRESH AIR. I'm Dave Davies, in today for Terry Gross. We're speaking with Kai Strittmatter, a journalist who studied China for more than 30 years and spent more than a decade as the China correspondent for one of Germany's largest newspapers. He has a new book about China's turn towards heavy-handed authoritarianism under President Xi Jinping and its increasingly aggressive posture towards the West. The book is \"We Have Been Harmonized: Life In China's Surveillance State. \"So you've told us about the incredible amount of data that the Chinese security authorities harvest on Chinese citizens, from facial recognition cameras and tracking their purchases and everything else, and how this is used is remarkable. You write about these experiments in social control, in which people are constantly evaluated for their honesty and conformity to social norms. You write that this was spurred in part by Xi Jinping's concern when he came into power that a breakdown of trust in the country was a threat to economic growth. You want to explain this a bit? What kind of dishonesty was threatening the economic health of the country? STRITTMATTER: Yeah, so the thing with China is - as with all authoritarian system, is those really - societies are not really healthy. You know, so the societies in authoritarian systems always are sick societies, and one of the main reasons is because there is no trust. This is not new. This is not something new for China. This has been like this in dictatorships for centuries and millennia. But in China, it's an especially big problem because of the Cultural Revolution because that was such a catastrophic event. That was 10 years under Mao Zedong - 1966 to 1976 - where, you know, this was the time when China was really a totalitarian country. And this was a time where, actually, the great leader, Mao Zedong, he actually had children reporting on their parents and husbands reporting on their wives, actually sending them to labor camps, you know, for just one word, one sentence they said and having them killed, having them executed. Actually, that was one of the stories I did - was a guy who's a lawyer now. When he was 16 years old, he had his own mother executed because he reported her to the authorities because of a sentence she said while they were having dinner, where she said she preferred the old president over Mao Zedong. And he wrote a letter to the local revolutionary committee asking them to actually - literally, asking them - he said she deserves death for that. And actually, she was executed a couple of weeks later. So that was Mao Zedong. That was a time under Mao Zedong. And when you have a system like this, of course, trust is - completely breaks down. You know, even the most intimate relationships are destroyed. So when Xi Jinping came to power, this was really - I think he thought it was one of his main missions that he had to do - was to address this crisis of trust and to bring trust back again, not only because he needed it for his own party but also because this level of distrust is really a big hurdle for economic development. DAVIES: So you write about these programs in various cities around China in which citizens are rated upon their honesty or creditworthiness. One of them is in a city called Rongcheng, if I have the pronunciation right. You want to explain how this works? STRITTMATTER: Yes, Rongcheng, basically, was one of the pilot programs that the Communist Party had set up in different cities for this social credit system. And Rongcheng was the one that was constantly rated No. 1 among all the pilot programs. And I had been speaking to people in Beijing, and one of them told me, a professor who was an adviser for the system - he said, you have to go to Rongcheng and visit the Office of Honesty. And that's already, you know, a name - like a really George Orwell name, the Office of Honesty. So I went there to have a look at the social credit system there. And there it's actually really like right out of a picture book. Every citizen in Rongcheng starts with a score of 1,000 point, and then you can work your way up. You can get more points by doing really good things for society, and you can fall down, you know. They also actually - they copied a little bit the Wall Street model. They can rate you - if you have more than 1,050 points, you can be a Triple A citizen, and then you become a Double A citizen if you fall lower and C and D. If you're a D citizen, you're actually dishonest, and you have less than 599 points. DAVIES: So how do you get or lose points? What kind of activities get you in trouble or get you more points? STRITTMATTER: So, for example, you can earn points if you donate blood or bone marrow or if you give lessons to the neighbor's children that they need for school or - I went to a neighborhood where one lady, she got five points because she actually provided one of her basement rooms for the local choir that sang revolutionary songs then and there. At the same time, you get punished for the things that you're not supposed to do. And you can get punished for, you know, jaywalking. You can get punished for downloading pirated stuff. You can get punished for letting your dog poo-poo on the lawn in front of the neighborhood - for all these kinds of things. So many of these things would be actually actions that we also consider them, you know, not to be good actions and maybe, you know, worthy of being punished. But, of course, then it goes much further, and it also becomes political. And you can also become punished because you endanger the social harmony on the Internet, for example. DAVIES: And when your score starts falling and you're regarded as a disreputable citizen, what are the consequences? STRITTMATTER: What we have to actually say is that they're introducing the system step by step now. It's not yet a nationwide system, and we'll have to see how it develops in the next couple of years. But one thing is already nationwide, and that's the system of blacklists. You know, if you're blacklisted because your social credit is down, then actually you already get sanctioned. For example, you're no longer allowed to take a plane. You're no longer able to buy plane tickets. You're no longer allowed to take a high-speed railway. You're no longer allowed, for example, in expensive hotels. You know, your children are no longer allowed to go to expensive, good schools and things like this. And this is something that's already happening. This is one part of the system that is already active. In 2018, there were more than 17 million people being banned from flying because of the system. DAVIES: Public shaming is part of this, too, right? I think you described a circumstance in which there's a surveillance camera, and if it catches you jaywalking, your face pops up on a little electronic billboard so everybody knows. STRITTMATTER: Exactly. That's happening in some cities. In Shenzhen, for example, in the south, or in Shenyang, in the northeast, you have these billboard systems and cameras, artificial intelligence cameras. When you jaywalk, still already - while you are still in the middle of the road, your face appears on the huge billboard for everybody to see, and next to your face, your name appears, your ID number. Part of it is blackened then so that people, you know, cannot see the whole thing. But the whole point is - we know who you are. This is you. And you are actually - you know, you are actually hurting society this moment right now. So public shaming is a big part of it, yes. DAVIES: I want to take another break here. Let me reintroduce you. We're speaking with Kai Strittmatter. He's a journalist who has spent years reporting on China. His new book is \"We Have Been Harmonized: Life In China's Surveillance State. \" We'll be back in just a moment. This is FRESH AIR. (SOUNDBITE OF MUSIC)DAVIES: This is FRESH AIR. And we're speaking with Kai Strittmatter. He was the China correspondent for more than a decade for one of Germany's largest newspapers. His new book about the growth of authoritarianism and social control in China is \"We Have Been Harmonized: Life In China's Surveillance State. \"You know, there's been a lot written about the Uighur population in China, the Muslim population that has been so persecuted, and there have been, you know, reports of concentration camps. I'm wondering how all of this sophisticated surveillance technology has been used on that population. STRITTMATTER: Yeah, that's the thing. You take all these technologies and you go to Xinjiang, which is the western province where the Uighur population lives, the Muslim population. This is the laboratory where it's all being tried out, actually, you know. On the one hand, you have, like, this huge camp system, reeducation camp system, being set up - sometimes labor camps, sometimes reeducation camps. And on the other hand, who lands there? Who is actually going to these camps? It is the people being caught up in these big data predictive policing systems, you know. And in Xinjiang, it's really extreme because you have all these checkpoints, whenever you come to a checkpoint - you know, and if you walk through a city like Urumqi, you might pass 10, 15, 20 checkpoints on one walk only or one day, you know. And the policemen there, the first thing they will do is they will check your mobile phone, whether you have installed an app that is called Jingwang app - Clean Internet, Clean Net app. And this is an app, actually, that sends information from your mobile phone to the authorities, you know. This is a spyware. This is a spying tool. DAVIES: And it's required for Uighur people? STRITTMATTER: It's required for Uighur people. And if you don't have it, actually, you're getting a record, and you might get punished. Even if you don't have a mobile phone, you're being suspicious, you know, because if you don't have a mobile - why does this person not have a mobile phone? You know, it might make it much harder to track them. They look at how religious you are, how often you go to the mosque, whether you give your children religious names. They collect your DNA, actually, with the help of American companies, you know, technology provided by a company called Thermo Fisher, which was revealed by The New York Times, which is - with many of these high-tech surveillance technology, a lot of it is actually being supplied by Western companies, a lot of them Americans. But in Xinjiang, it gets to a point that is so absurd and scary at the same time that you have, you know, reasons why do you end up in the system. For example, in our own paper, we are part of this international committee for investigative journalism, which published the China cables and another thing called the Karakax List, which are actually internal Chinese government documents. And there are crimes, you know, listed, which are, like, he has relatives abroad. This is why he's suspicious. He has communicated with someone abroad. This is enough. If you send messages through WhatsApp or WeChat to someone abroad, it's enough for you getting into a camp. Or he does not leave his house through the front door - you know, this is something that makes you suspicious. He does not have a lot of contact with his neighbors. All these things are being collected. And then the system, the algorithm, decides whether you are a potential terrorist or not, and then you land in one of those camps. None of the 1 million people that are in these camps has ever been in front of a court - none of them. And none of them has been legally accused of anything. They're all in there because of the big data systems and predictive policing and because the security apparatus thinks they are potentially dangerous. DAVIES: I'm wondering how Chinese citizens regard this. And I don't know that there are reliable opinion polls. And I would imagine some people like the idea that - you know, that there's more control and crime is probably reduced. How do people react? Is there outrage? Is there depression? Is there suicide? What are you seeing? STRITTMATTER: You know, one thing I took away from China is - one lesson I learned is that propaganda works, censorship works, and people actually believe a lot of the things that they heard because they don't have any other information. Also, because there is no public debate on many of these things, you know. There is no tradition of public debate on privacy, data protection and things like this. And the arguments of the government are basically twofold. One is - we've already talked about this - convenience. It makes your life so convenient. And the second thing is what you just said - it makes our life safer. This is especially what they use for the facial recognition and the cameras. And we actually make your life safe and secure. And you can go through the city, you can leave your handbag now in a bus and in a subway train, and nobody will dare take it. And they're right, probably. And many people buy that, and they like that. DAVIES: I'm wondering if you're seeing generational differences in Chinese citizens' response to what's going on. I mean, there are people who lived through Mao's era. There are some around who remember the China before the revolution in 1949. Then, of course, some people are quite young. What differences are you seeing among how people respond to these initiatives? STRITTMATTER: That's a very interesting question because, of course, you have critical people in China. You have a lot of, you know, people who think a lot, who reflect a lot. But most of these people actually belong to a generation that has witnessed the crimes and sins of the Communist Party themselves, especially the generations who have lived through the Cultural Revolution and the generation who has lived through Tiananmen Square - the massacre near Tiananmen Square. Those are the people, I found, who are actually the most critical ones because they have seen, you know, what they think is the true nature of a system like this, the true nature of a party like this, you know? And young people - because propaganda is very successful and the sort of collective amnesia that the party wants to rule is very successful - people don't know. Even in Beijing, people don't speak and they don't know about the Tiananmen massacre, which is, you know, which was only - happened - has had - happening in 1989. You know, remember, 2 million Beijingers were on the streets, marching. Of course, this generation, they all know, but they were afraid to tell their children. Because, you know, what do you do when your child in school suddenly tells the teacher and asks the teacher about Tiananmen massacre? Then you've got serious problems. So they're a lot more open for actually, you know, the propaganda - the party propaganda - as long as the party delivers, as long as their material life is still good and as long as they're safe and wealthy. And at the moment, I would say, you know, this propaganda works especially well because, as I said, the party points to the United States and asks their people, would you rather want to live there? And actually, many of the urban population and the younger ones at the moment are saying, no, we prefer probably China. But that only works as long as the economy is actually in good shape. DAVIES: Before I let you go, when you describe the level of technologically sophisticated surveillance and social control in China, it's pretty dispiriting. And it seems sort of immutable, you know? But the Soviet state once seemed impregnable. And the East German Stasi, you know, had its citizens in terror. But they collapsed eventually under the weight of their own internal contradictions. And it raises the thought that as powerful as the Chinese state is, could the human spirit in the end be stronger? - and that this will all fall someday. STRITTMATTER: The way Xi Jinping is going, I would say actually he looks very strong now. And it's - superficially, it looks as if he's making China really much stronger. But I think under the surface, with a lot of the things he does, he's actually making the party and the country weaker and his old system weaker. Because he did away with a lot of the - not only the freedoms and the freedom to experiment, which was basically, you know, a foundation for economic success also, but he's also doing away with all critics, you know? And with all - he only has people around him that actually, you know, nod to everything he says. And he's making the system blind again. And this is something we saw at the beginning of the coronavirus, you know? Let's not forget, at the moment, they have it under control and they're very successful. But it began with a huge system failure inside China. And that - part of the reason was because he had made the system blinder than it used to be because he didn't allow critical journalists, he didn't allow critical bloggers anymore. So this is something that, in times of crisis, can become very dangerous for a system. So yes, the Chinese system actually might be weaker than it looks like. DAVIES: Well, Kai Strittmatter, thank you so much for spending some time with us. STRITTMATTER: Thank you. DAVIES: Kai Strittmatter is a journalist who's reported on and studied China for more than 30 years. His new book is \"We Have Been Harmonized: Life In China's Surveillance State. \"Coming up, David Bianculli reviews \"Mr. Mayor,\" the new NBC sitcom starring Ted Danson as the mayor of Los Angeles. This is FRESH AIR. (SOUNDBITE OF JIMMY AMADIE'S \"YOU'D BE SO NICE TO COME HOME TO\") DAVE DAVIES, HOST:   This is FRESH AIR. I'm Dave Davies, in today for Terry Gross. Our guest today, journalist Kai Strittmatter, says while Americans worry a lot about the threat Russia poses to the United States, the real challenge to liberal democracy will come not from a stagnant Russia but from the authoritarian economic powerhouse of China. Strittmatter speaks fluent Mandarin and has studied China for more than 30 years. In a new book, he warns that the regime of Chinese President Xi Jinping has embraced an ideological rigidity unknown since the days of Mao Tse-tung and a level of control over its population that is simply unprecedented. Strittmatter describes an astonishing level of surveillance exercised by the Chinese state over its citizens, generating massive databases used to punish people for even minor deviations from expected norms of behavior. And he says China is aggressively using its state-controlled technology firms to infiltrate and influence Western institutions and is marketing its authoritarian system as a model for other nations to follow. Kai Strittmatter was the China correspondent for more than a decade for Suddeutsche Zeitung, one of Germany's largest newspapers. He now works in Copenhagen. His new book is \"We Have Been Harmonized: Life In China's Surveillance State. \" He joins me from his home in Copenhagen. Kai Strittmatter, welcome to FRESH AIR. Xi Jinping takes power in 2012. He has a country riddled with corruption. But he doesn't just bring an economic agenda, does he? KAI STRITTMATTER: No. He surprised all of us, actually. I actually came back to China just a couple of months before he took power. I was there in - for my second stint in Beijing in summer of 2012. And everybody knew that the incoming new strongman had to do something because the country was sort of in a state of crisis. There was, really, a kind of a fin-de-siecle feeling all around in society and politics with whomever you spoke. But actually, most people I spoke to, and even party members and people inside party institutions, they thought that maybe Xi Jinping would start with reforms more in the liberal kind of way, you know, like more towards independence of courts, independence of media and something like this. This was, at least, the hope that many people had. And everybody was completely surprised by how it turned out, really. Nobody had expected that Xi Jinping would do to China what he did. And in fact, actually, he created a completely new creature. It's really a new kind of regime and state that we haven't seen before. DAVIES: You know, it's interesting because, you know, he wears a Western business suit in sharp contrast to the image of, you know, Mao Tse-tung, who wore, you know, the military jacket. Describe his ideological agenda for China. STRITTMATTER: One of the first things he did is he put the party back into control, you know? In the decades before, with the reforms of Deng Xiaoping, the opening of the country, the economic success, the growth, we had seen a much freer society and a much more liberal economy developing. And there was a - there were things like civil society China. And many aspects actually started to resemble a little bit our own societies, you know, which brought many of us, actually, to think - to believe in a kind of China fantasy - you know, someday, China will become like us. So there comes Xi Jinping now. And what he does is he actually does away with many of these things. He does away, in effect, with the China we have come to know for three or four decades. The China that you see now is no longer the China that we all grew up with. And what he did was he put the party back in total control. And he brought back a centralization of power. He brought back one-man rule. He brought back, actually, a cult of personality, things that we haven't seen since the days of Mao Tse-tung. And he brought back ideology in a big way. And he's still - he's speaking a lot about Marx. He has his own thought, you know? In Chinese universities, suddenly, everywhere, there are new faculties springing up teaching the Xi Jinping thoughts and the Xi Jinping ideas. And while he speaks about Marx all the time - you know, Marx was more, like, the kind of idealist thinker of socialism. In fact, what he is, he's more a Leninist. It's more about power in the end. And that is, actually, his big goal. He speaks a lot about making China great again, the big China dream. But, in effect, you know, what he does is and what his main aim is, actually, secure the power of the Communist Party for eternity. DAVIES: Now, you were in China as this began to take shape. Were there ideological purges in universities among journalists? I mean, what was it - how did you see this unfold? STRITTMATTER: Actually, there were, yeah. It was very interesting because there were purges, actually, in waves. And it hit a different segment of society and of the institutions every time. It started with the bloggers, with the Internet, then came universities and the party itself. You know, the party members suddenly started to have to be afraid. A lot of it, actually, took place under the guise of the anti-corruption campaign, because the same people who actually are in charge of the anti-corruption campaign, this is the disciplinary commission of the Communist Party, that's actually the arm of the Communist Party that is responsible for ideological discipline also. And so they conducted these purges. And a lot of times, you know, these purges were accompanied by, for example, show trials, you know? Suddenly you would have a civil rights lawyer on TV being tried for crimes that were obvious he didn't commit. And then, the next time, it was, maybe, a famous show star. Then it was a journalist and so on. And fear came back. The people started to fall silent again. And party control came back. DAVIES: I think one of the strangest measures of how extreme this became that you describe in the book was that donors to the sperm bank at a hospital in Peking had to pass an ideological test. STRITTMATTER: Yes. And that's, of course, one of those absurdities. You know, I'm sure Xi Jinping didn't think of this. But this is how it works in autocratic regimes, you know? You have the big guy on the top. And everybody else is following him. Well, first, you know, they're all ducking away. And then, when there is a policy, they all - they're all trying to second-guess him. And they're all trying to outdo his policies, you know? And so you get these absurd things like the sperm bank you describe are suddenly, you know - you have things reappearing that we didn't see since the times of Mao Tse-tung. Suddenly, you have scientists writing papers about the ozone level in Beijing and air pollution in Beijing as seen from a Marxist perspective, you know, these kind of absurd sort of things that serve as nothing else but a sign of ideological submission. All this was gone. China was a very pragmatic country. This was one of the basic traits of the China of Deng Xiaoping. And suddenly, these absurdities are reappearing. DAVIES: We're going to take a break here. Let me reintroduce you. Kai Strittmatter is a journalist who has spent years reporting on China. His new book is \"We Have Been Harmonized: Life In China's Surveillance State. \" We'll be back after a short break. This is FRESH AIR. (SOUNDBITE OF YING QUARTET'S \"LARGHETTO NOSTALGICO\") DAVIES: This is FRESH AIR. And we're speaking with Kai Strittmatter. He was the China correspondent for more than a decade for one of Germany's largest newspapers. His new book about the growth of authoritarianism and social control in China is \"We Have Been: Harmonized Life In China's Surveillance State. \" You write a lot about the new level of social control. And a lot of it starts with technology. Xi Jinping is determined to make China a leader in artificial intelligence. How does he do it? What are the implications of that? STRITTMATTER: Yeah. This is the thing. So on the one hand, you have a guy who is reintroducing repression on a scale that we haven't seen since Mao Tse-tung. So he's basically, you know, with one foot going back into the past. But with his other foot, he's going far, far into the future and really embracing all this new information technology and artificial intelligence and big data, like, I would say no other government on the planet actually does it, and certainly no other authoritarian government. I mean, this is one of the remarkable things, right? I mean, we have been told for so many years and decades by these tech prophets that every kind of new technology would actually serve the cause of freedom and would undermine and subvert authoritarian rule. Well, the Chinese, they have shown us already for a long time - for example, with the Internet, already for 20 years, more than 20 years - that they're not only not afraid of those new technologies, but on the contrary, they have grown to love them and really love them big time. The Communist Party doesn't see those new technologies as a danger to their rule. On the contrary, they have discovered or they think that, actually, these new technologies give them new instruments that will perfect their rule and will make it - will make their rule crisis-proof. And now, that's the same thing with artificial intelligence and big data. DAVIES: There's a big investment in China in facial recognition technology and a lot of cameras. I mean, these numbers are incredible that you quoted. 2016, there were 176 million surveillance cameras in the country. It's a big country, but that's a lot. And then you say, as many as 600 million surveillance cameras now. Tell us what kind of capability this presents. Where do all these pictures go? How are they used? STRITTMATTER: Yeah. So that's the difference to before, right? I mean, I'm a German, you know? We had the fall of the Berlin Wall in 1989. And then we were actually one of the few countries, I would say, where you actually could study, and you still can study, the means and instruments of dictatorship - of the arms of the dictatorship. We have a state security museum of the former eastern German state security. And one of the lessons that historians have taken from that is, actually, they were overwhelmed by the mass of data that they actually collected by their own paranoia. Now, with new information technology, you know, this is suddenly changing because you're not - no longer having real people sitting. There's no policemen sitting behind these cameras, you know, at a screen and watching them and trying to watch, like - you know, a whole bunch of policemen trying to watch 10,000 cameras. Instead, you have algorithms. You have artificial intelligence, actually, working there. And that makes it much more effective. So for example, already, in 2018 - you know, if you're asking, what have they achieved already? In 2018, The People's Daily, which is the party's central newspaper, it claimed on Twitter, in English language - you can Google that, actually. You know, Twitter is forbidden inside China. But they still use it for propaganda purposes. So you can see they're very proud of these achievements also. So they claimed on Twitter that, already now, their Skynet - this is what they're calling this network of surveillance cameras, Skynet, like the one in \"The Terminator. \" I don't know whether you've seen the movies. Their Skynet is already capable of identifying each and every single one of their 1. 4 billion citizens in the course of one second. DAVIES: What does that mean, to identify them all in one second? What is that describing? STRITTMATTER: That means if you're looking for someone, you know, and you have his or her picture in your database and you feed that picture in your database and you tell the algorithm - or you ask the algorithm, you ask the computer, to tell you the moment once this person is actually stepping on the street, that once they're stepping outside of their home and getting into the reach of one of those surveillance cameras, it doesn't take more than one second that the computer will actually alarm you. They're here and there. And you can go and pick up - pick them up there. DAVIES: You are never alone. (Laughter) Wow. STRITTMATTER: You are never alone, exactly. But a question back then, you know, is it even true? And then, very soon, you realize it doesn't even matter whether it's true or not as long as people believe it. This is one of the central - this is a very important point, you know, because what the Communist Party is doing with all these high-tech surveillance technology now is they're trying to internalizing control, you know? They're trying to make people self-censor themselves much more than they used to do. And once, you know, you believe it's true, it's like you don't even need the policeman at the corner anymore because you're becoming your own policeman. DAVIES: Information is gathered from other methods besides, of course, all of these surveillance cameras. And that's - a lot of that is the digital footprints that Chinese citizens leave. You write that most purchases in China are now digital. Even street beggars use barcodes to collect handouts. This is true? STRITTMATTER: Yeah. DAVIES: What do they use? (LAUGHTER) STRITTMATTER: At least in Beijing they're doing it, you know, because - I mean, everybody has been asking for a long time the question, can authoritarian regimes actually be innovative, you know? And I think China, up to a certain point, has proved, of course they can, you know? In terms of, like, for example, fintech applications or the apps they use on their daily mobile phones, they're really, in some sense, much more advanced to anything that we use. There's this one app on every Chinese mobile phone that's called WeChat. And in WeChat - with WeChat, basically, you can live your whole life in WeChat. You can - it started as a normal chat program like WhatsApp. But very soon, it turned into a kind of Chinese Facebook. Then it became a Chinese Uber. You use - you could get credit. You could apply for credit to your bank with it. You could use it as an ID, actually. You could file your divorce papers through this app to the local court. And you can do all your financial transactions through this app. And that works with barcodes. And they've been using these barcodes for a long time already. I mean, I left China two years ago. But it's been a thing of four and five years. You know, the Chinese, when they look at us - and some of my friends, my Chinese friends, they go travelling to Europe. And they come back and say, oh, it's beautiful in Europe. And it's so romantic. But really, I mean, you're so far behind us, you know? It's really - I can't believe how advanced we are already technologically compared to you, you know? It's so convenient what we can do with our apps and everything. And when they talk about cashless payment - you know, I'm living in Scandinavia now. There's also - cashless payment is the main form of payment. I think 80%, 90% of all transactions are done cashless here. But in Denmark, in Sweden, in Norway, cashless payment means you use your credit card, you know, most of the times. Nobody in China uses credit cards. Nobody has been using them for years. Everybody does everything with their mobile phones, you know? And so you come to the point that even street beggars use them. And they will tell you, it's so convenient. How come you don't use it? Of course, it's convenient. It's amazingly convenient. But at the same time, it's also amazingly convenient for state security. And every single one of your transactions will actually end up on one of their servers. DAVIES: Right. So WeChat is - you know, it's a payment service, kind of like Venmo. You can transfer money. It's a social media platform. It's a messaging app. It's all these other things. STRITTMATTER: Exactly. DAVIES: And the government extracts all this information about you. What's been your experience in terms of seeing how citizens feel the presence of the state through information they get from this WeChat app? STRITTMATTER: I mean, the thing is, you know, Chinese citizens have - they've been used to that. They feel the presence of the state. They've been feeling the presence of the state for all their life. And, of course, I had some friends who actually - they were, in the end - I mean, you realize that sometimes when some of your chats are being censored, you know? Suddenly, words or sentences are missing. That's like the first step before they delete your account or anything. And they never reach the other party. Or you don't actually get part of the conversation that your friends send you. This is, like, something that many Chinese experience. But then, on the next level, it gets - you know, if you're, like, politically interested, if you're, maybe, a little bit in the activist line - I had some friends like this, and I actually had two of them. I saw two of them getting arrested because of their WeChat records, because they had actually, on WeChat, agreed with other people, with friends, to go to a poetry reading where a poet in Beijing was supposed to read some poems supporting the students in Hong Kong in their struggle for democracy. And they never made it to the poetry reading. They were arrested on the way. And it was clearly because of their WeChat conversations. And, actually, I myself had the same experience. I had, like, appointments with friends for interviews. But, like, this one guy, we agreed to meet in a hotel, in a Beijing hotel via WeChat. And I got there. And, like, after half an hour, I get a message from him, this time not on WeChat, but on - through FaceTime or through the iPhone messaging app. And he tells me, I'm sorry I'm late. I'm sure you understand why. And, of course, I immediately knew why. And later then he told me that state security had called him immediately after they saw our appointment on WeChat and told him and threatened him not to come and see me. DAVIES: We're going to take another break here. Let me introduce you. Kai Strittmatter is a veteran China correspondent. His new book is \"We Have Been Harmonized: Life In China's Surveillance State. \" He'll be back to talk more after a short break. I'm Dave Davies. And this is FRESH AIR. (SOUNDBITE OF MUSIC) DAVIES: This is FRESH AIR. I'm Dave Davies, in today for Terry Gross. We're speaking with Kai Strittmatter, a journalist who studied China for more than 30 years and spent more than a decade as the China correspondent for one of Germany's largest newspapers. He has a new book about China's turn towards heavy-handed authoritarianism under President Xi Jinping and its increasingly aggressive posture towards the West. The book is \"We Have Been Harmonized: Life In China's Surveillance State. \" So you've told us about the incredible amount of data that the Chinese security authorities harvest on Chinese citizens, from facial recognition cameras and tracking their purchases and everything else, and how this is used is remarkable. You write about these experiments in social control, in which people are constantly evaluated for their honesty and conformity to social norms. You write that this was spurred in part by Xi Jinping's concern when he came into power that a breakdown of trust in the country was a threat to economic growth. You want to explain this a bit? What kind of dishonesty was threatening the economic health of the country? STRITTMATTER: Yeah, so the thing with China is - as with all authoritarian system, is those really - societies are not really healthy. You know, so the societies in authoritarian systems always are sick societies, and one of the main reasons is because there is no trust. This is not new. This is not something new for China. This has been like this in dictatorships for centuries and millennia. But in China, it's an especially big problem because of the Cultural Revolution because that was such a catastrophic event. That was 10 years under Mao Zedong - 1966 to 1976 - where, you know, this was the time when China was really a totalitarian country. And this was a time where, actually, the great leader, Mao Zedong, he actually had children reporting on their parents and husbands reporting on their wives, actually sending them to labor camps, you know, for just one word, one sentence they said and having them killed, having them executed. Actually, that was one of the stories I did - was a guy who's a lawyer now. When he was 16 years old, he had his own mother executed because he reported her to the authorities because of a sentence she said while they were having dinner, where she said she preferred the old president over Mao Zedong. And he wrote a letter to the local revolutionary committee asking them to actually - literally, asking them - he said she deserves death for that. And actually, she was executed a couple of weeks later. So that was Mao Zedong. That was a time under Mao Zedong. And when you have a system like this, of course, trust is - completely breaks down. You know, even the most intimate relationships are destroyed. So when Xi Jinping came to power, this was really - I think he thought it was one of his main missions that he had to do - was to address this crisis of trust and to bring trust back again, not only because he needed it for his own party but also because this level of distrust is really a big hurdle for economic development. DAVIES: So you write about these programs in various cities around China in which citizens are rated upon their honesty or creditworthiness. One of them is in a city called Rongcheng, if I have the pronunciation right. You want to explain how this works? STRITTMATTER: Yes, Rongcheng, basically, was one of the pilot programs that the Communist Party had set up in different cities for this social credit system. And Rongcheng was the one that was constantly rated No. 1 among all the pilot programs. And I had been speaking to people in Beijing, and one of them told me, a professor who was an adviser for the system - he said, you have to go to Rongcheng and visit the Office of Honesty. And that's already, you know, a name - like a really George Orwell name, the Office of Honesty. So I went there to have a look at the social credit system there. And there it's actually really like right out of a picture book. Every citizen in Rongcheng starts with a score of 1,000 point, and then you can work your way up. You can get more points by doing really good things for society, and you can fall down, you know. They also actually - they copied a little bit the Wall Street model. They can rate you - if you have more than 1,050 points, you can be a Triple A citizen, and then you become a Double A citizen if you fall lower and C and D. If you're a D citizen, you're actually dishonest, and you have less than 599 points. DAVIES: So how do you get or lose points? What kind of activities get you in trouble or get you more points? STRITTMATTER: So, for example, you can earn points if you donate blood or bone marrow or if you give lessons to the neighbor's children that they need for school or - I went to a neighborhood where one lady, she got five points because she actually provided one of her basement rooms for the local choir that sang revolutionary songs then and there. At the same time, you get punished for the things that you're not supposed to do. And you can get punished for, you know, jaywalking. You can get punished for downloading pirated stuff. You can get punished for letting your dog poo-poo on the lawn in front of the neighborhood - for all these kinds of things. So many of these things would be actually actions that we also consider them, you know, not to be good actions and maybe, you know, worthy of being punished. But, of course, then it goes much further, and it also becomes political. And you can also become punished because you endanger the social harmony on the Internet, for example. DAVIES: And when your score starts falling and you're regarded as a disreputable citizen, what are the consequences? STRITTMATTER: What we have to actually say is that they're introducing the system step by step now. It's not yet a nationwide system, and we'll have to see how it develops in the next couple of years. But one thing is already nationwide, and that's the system of blacklists. You know, if you're blacklisted because your social credit is down, then actually you already get sanctioned. For example, you're no longer allowed to take a plane. You're no longer able to buy plane tickets. You're no longer allowed to take a high-speed railway. You're no longer allowed, for example, in expensive hotels. You know, your children are no longer allowed to go to expensive, good schools and things like this. And this is something that's already happening. This is one part of the system that is already active. In 2018, there were more than 17 million people being banned from flying because of the system. DAVIES: Public shaming is part of this, too, right? I think you described a circumstance in which there's a surveillance camera, and if it catches you jaywalking, your face pops up on a little electronic billboard so everybody knows. STRITTMATTER: Exactly. That's happening in some cities. In Shenzhen, for example, in the south, or in Shenyang, in the northeast, you have these billboard systems and cameras, artificial intelligence cameras. When you jaywalk, still already - while you are still in the middle of the road, your face appears on the huge billboard for everybody to see, and next to your face, your name appears, your ID number. Part of it is blackened then so that people, you know, cannot see the whole thing. But the whole point is - we know who you are. This is you. And you are actually - you know, you are actually hurting society this moment right now. So public shaming is a big part of it, yes. DAVIES: I want to take another break here. Let me reintroduce you. We're speaking with Kai Strittmatter. He's a journalist who has spent years reporting on China. His new book is \"We Have Been Harmonized: Life In China's Surveillance State. \" We'll be back in just a moment. This is FRESH AIR. (SOUNDBITE OF MUSIC) DAVIES: This is FRESH AIR. And we're speaking with Kai Strittmatter. He was the China correspondent for more than a decade for one of Germany's largest newspapers. His new book about the growth of authoritarianism and social control in China is \"We Have Been Harmonized: Life In China's Surveillance State. \" You know, there's been a lot written about the Uighur population in China, the Muslim population that has been so persecuted, and there have been, you know, reports of concentration camps. I'm wondering how all of this sophisticated surveillance technology has been used on that population. STRITTMATTER: Yeah, that's the thing. You take all these technologies and you go to Xinjiang, which is the western province where the Uighur population lives, the Muslim population. This is the laboratory where it's all being tried out, actually, you know. On the one hand, you have, like, this huge camp system, reeducation camp system, being set up - sometimes labor camps, sometimes reeducation camps. And on the other hand, who lands there? Who is actually going to these camps? It is the people being caught up in these big data predictive policing systems, you know. And in Xinjiang, it's really extreme because you have all these checkpoints, whenever you come to a checkpoint - you know, and if you walk through a city like Urumqi, you might pass 10, 15, 20 checkpoints on one walk only or one day, you know. And the policemen there, the first thing they will do is they will check your mobile phone, whether you have installed an app that is called Jingwang app - Clean Internet, Clean Net app. And this is an app, actually, that sends information from your mobile phone to the authorities, you know. This is a spyware. This is a spying tool. DAVIES: And it's required for Uighur people? STRITTMATTER: It's required for Uighur people. And if you don't have it, actually, you're getting a record, and you might get punished. Even if you don't have a mobile phone, you're being suspicious, you know, because if you don't have a mobile - why does this person not have a mobile phone? You know, it might make it much harder to track them. They look at how religious you are, how often you go to the mosque, whether you give your children religious names. They collect your DNA, actually, with the help of American companies, you know, technology provided by a company called Thermo Fisher, which was revealed by The New York Times, which is - with many of these high-tech surveillance technology, a lot of it is actually being supplied by Western companies, a lot of them Americans. But in Xinjiang, it gets to a point that is so absurd and scary at the same time that you have, you know, reasons why do you end up in the system. For example, in our own paper, we are part of this international committee for investigative journalism, which published the China cables and another thing called the Karakax List, which are actually internal Chinese government documents. And there are crimes, you know, listed, which are, like, he has relatives abroad. This is why he's suspicious. He has communicated with someone abroad. This is enough. If you send messages through WhatsApp or WeChat to someone abroad, it's enough for you getting into a camp. Or he does not leave his house through the front door - you know, this is something that makes you suspicious. He does not have a lot of contact with his neighbors. All these things are being collected. And then the system, the algorithm, decides whether you are a potential terrorist or not, and then you land in one of those camps. None of the 1 million people that are in these camps has ever been in front of a court - none of them. And none of them has been legally accused of anything. They're all in there because of the big data systems and predictive policing and because the security apparatus thinks they are potentially dangerous. DAVIES: I'm wondering how Chinese citizens regard this. And I don't know that there are reliable opinion polls. And I would imagine some people like the idea that - you know, that there's more control and crime is probably reduced. How do people react? Is there outrage? Is there depression? Is there suicide? What are you seeing? STRITTMATTER: You know, one thing I took away from China is - one lesson I learned is that propaganda works, censorship works, and people actually believe a lot of the things that they heard because they don't have any other information. Also, because there is no public debate on many of these things, you know. There is no tradition of public debate on privacy, data protection and things like this. And the arguments of the government are basically twofold. One is - we've already talked about this - convenience. It makes your life so convenient. And the second thing is what you just said - it makes our life safer. This is especially what they use for the facial recognition and the cameras. And we actually make your life safe and secure. And you can go through the city, you can leave your handbag now in a bus and in a subway train, and nobody will dare take it. And they're right, probably. And many people buy that, and they like that. DAVIES: I'm wondering if you're seeing generational differences in Chinese citizens' response to what's going on. I mean, there are people who lived through Mao's era. There are some around who remember the China before the revolution in 1949. Then, of course, some people are quite young. What differences are you seeing among how people respond to these initiatives? STRITTMATTER: That's a very interesting question because, of course, you have critical people in China. You have a lot of, you know, people who think a lot, who reflect a lot. But most of these people actually belong to a generation that has witnessed the crimes and sins of the Communist Party themselves, especially the generations who have lived through the Cultural Revolution and the generation who has lived through Tiananmen Square - the massacre near Tiananmen Square. Those are the people, I found, who are actually the most critical ones because they have seen, you know, what they think is the true nature of a system like this, the true nature of a party like this, you know? And young people - because propaganda is very successful and the sort of collective amnesia that the party wants to rule is very successful - people don't know. Even in Beijing, people don't speak and they don't know about the Tiananmen massacre, which is, you know, which was only - happened - has had - happening in 1989. You know, remember, 2 million Beijingers were on the streets, marching. Of course, this generation, they all know, but they were afraid to tell their children. Because, you know, what do you do when your child in school suddenly tells the teacher and asks the teacher about Tiananmen massacre? Then you've got serious problems. So they're a lot more open for actually, you know, the propaganda - the party propaganda - as long as the party delivers, as long as their material life is still good and as long as they're safe and wealthy. And at the moment, I would say, you know, this propaganda works especially well because, as I said, the party points to the United States and asks their people, would you rather want to live there? And actually, many of the urban population and the younger ones at the moment are saying, no, we prefer probably China. But that only works as long as the economy is actually in good shape. DAVIES: Before I let you go, when you describe the level of technologically sophisticated surveillance and social control in China, it's pretty dispiriting. And it seems sort of immutable, you know? But the Soviet state once seemed impregnable. And the East German Stasi, you know, had its citizens in terror. But they collapsed eventually under the weight of their own internal contradictions. And it raises the thought that as powerful as the Chinese state is, could the human spirit in the end be stronger? - and that this will all fall someday. STRITTMATTER: The way Xi Jinping is going, I would say actually he looks very strong now. And it's - superficially, it looks as if he's making China really much stronger. But I think under the surface, with a lot of the things he does, he's actually making the party and the country weaker and his old system weaker. Because he did away with a lot of the - not only the freedoms and the freedom to experiment, which was basically, you know, a foundation for economic success also, but he's also doing away with all critics, you know? And with all - he only has people around him that actually, you know, nod to everything he says. And he's making the system blind again. And this is something we saw at the beginning of the coronavirus, you know? Let's not forget, at the moment, they have it under control and they're very successful. But it began with a huge system failure inside China. And that - part of the reason was because he had made the system blinder than it used to be because he didn't allow critical journalists, he didn't allow critical bloggers anymore. So this is something that, in times of crisis, can become very dangerous for a system. So yes, the Chinese system actually might be weaker than it looks like. DAVIES: Well, Kai Strittmatter, thank you so much for spending some time with us. STRITTMATTER: Thank you. DAVIES: Kai Strittmatter is a journalist who's reported on and studied China for more than 30 years. His new book is \"We Have Been Harmonized: Life In China's Surveillance State. \" Coming up, David Bianculli reviews \"Mr. Mayor,\" the new NBC sitcom starring Ted Danson as the mayor of Los Angeles. This is FRESH AIR. (SOUNDBITE OF JIMMY AMADIE'S \"YOU'D BE SO NICE TO COME HOME TO\")", "section": "Asia", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-01-06-954204631": {"title": "Twitter Temporarily Locks Trump's Account : NPR", "url": "https://www.npr.org/2021/01/06/954204631/twitter-temporarily-locks-trumps-account", "author": "No author found", "published_date": "2021-01-06", "content": "MARY LOUISE KELLY, HOST:  In the wake of the armed insurrection at the U. S. Capitol today - still so strange to say those words out loud - Twitter has removed three of President Trump's tweets. And they have locked him out of his account for 12 hours. Twitter is threatening further suspensions if Trump continues to violate its rules. And that is a big blow for the president, of course, whose major means of communication with the public is Twitter. Let me turn now to NPR tech correspondent Bobby Allyn. Hey, Bobby. BOBBY ALLYN, BYLINE: Hey, Mary Louise. KELLY: Hey, Bobby. Little bit of a delay on the line, but let's forge ahead. What exactly was in Trump's tweets today? Just remind us what he was tweeting that drew this response from Twitter. ALLYN: Yeah. So the one that I think got the most attention was a video address that Trump made. And this came after hours and hours of Trump saying nothing, just as some of his reporter - some of his supporters, you know, violently swarmed the Capitol; you know, who were being basically, you know, directed at Trump over his concerns over the, you know, result of the election. And in Trump's video address, he did tell them to go home, but he also, you know, said that he loved them. And he also stoked falsehoods about the result of the election. And this is something that he has been doing for months in the lead-up to the November election. But this video, along with two other tweets that Trump sent today, were deemed to be violations of Twitter's rules. And instead of just slapping a warning label on it - which Twitter historically has done dozens and dozens of times - they took the unprecedented step of deleting them completely, locking down Twitter's account and also saying, President Trump, if you don't stop breaking the rules, we're going to kick you off Twitter forever. KELLY: Yeah. I was just about to ask if they've ever done anything like this again - this 12-hour lockout. It sounds like no. I want to note the video has also now been removed from Facebook and YouTube. I should note Facebook and Google, which owns YouTube, are financial supporters of NPR. What are these platforms saying about why they are doing this, what the thinking is and now? ALLYN: Yeah. So what we often see in these cases, Mary Louise, is one platform will come out and do something bold, and then the rest will follow. And that is what happened here. Facebook took down the video. Then YouTube took down the video. Meanwhile, Twitter had the video up, but they were sort of limiting its spread. Soon enough, they took down the video as well. And again, as the platforms were trying to decide whether or not they should keep this up, they were weighing a lot of things. They were - you know, typically, presidents had a lot of leeway to say what they want because there was an exception to the rules since whatever they said was considered newsworthy. There was sort of a world leaders exception to some of the rules and guidelines on Twitter. KELLY: Right. ALLYN: So they were trying to stick by that. But they were also, you know, looking at how extraordinary the violent scenes that were unfolding on the capital were and said, you know, this video has the potential of worsening some of that violence. And because of that, they said - you know, all the platforms said together, essentially, we have to take this down. This could really be harmful. KELLY: And what kind of reaction are you seeing so far to this? Do people think it is enough to take it down, to maybe locking him out of accounts for a certain period of time? ALLYN: Yeah. I mean, calls for the platforms to remove Trump have really been coming for many years. I mean, as we know, the president has used Twitter, you know, to, you know, threaten his enemies, to even go after, you know, everyday citizens, to stoke all sorts of conspiracy theories. And this, you know, push to so-call de-platform the president has been building and building and building. So I think people who have been calling for it say, yes, you should put him on notice, but maybe you should just ban him now because there are plenty examples in which Trump has gone to Twitter, abused the rules and has suffered no consequences. KELLY: Right. ALLYN: So this is a long time coming. KELLY: All right. NPR's Bobby Allyn reporting. Thank you, Bobby. ALLYN: Thanks, Mary Louise. MARY LOUISE KELLY, HOST:   In the wake of the armed insurrection at the U. S. Capitol today - still so strange to say those words out loud - Twitter has removed three of President Trump's tweets. And they have locked him out of his account for 12 hours. Twitter is threatening further suspensions if Trump continues to violate its rules. And that is a big blow for the president, of course, whose major means of communication with the public is Twitter. Let me turn now to NPR tech correspondent Bobby Allyn. Hey, Bobby. BOBBY ALLYN, BYLINE: Hey, Mary Louise. KELLY: Hey, Bobby. Little bit of a delay on the line, but let's forge ahead. What exactly was in Trump's tweets today? Just remind us what he was tweeting that drew this response from Twitter. ALLYN: Yeah. So the one that I think got the most attention was a video address that Trump made. And this came after hours and hours of Trump saying nothing, just as some of his reporter - some of his supporters, you know, violently swarmed the Capitol; you know, who were being basically, you know, directed at Trump over his concerns over the, you know, result of the election. And in Trump's video address, he did tell them to go home, but he also, you know, said that he loved them. And he also stoked falsehoods about the result of the election. And this is something that he has been doing for months in the lead-up to the November election. But this video, along with two other tweets that Trump sent today, were deemed to be violations of Twitter's rules. And instead of just slapping a warning label on it - which Twitter historically has done dozens and dozens of times - they took the unprecedented step of deleting them completely, locking down Twitter's account and also saying, President Trump, if you don't stop breaking the rules, we're going to kick you off Twitter forever. KELLY: Yeah. I was just about to ask if they've ever done anything like this again - this 12-hour lockout. It sounds like no. I want to note the video has also now been removed from Facebook and YouTube. I should note Facebook and Google, which owns YouTube, are financial supporters of NPR. What are these platforms saying about why they are doing this, what the thinking is and now? ALLYN: Yeah. So what we often see in these cases, Mary Louise, is one platform will come out and do something bold, and then the rest will follow. And that is what happened here. Facebook took down the video. Then YouTube took down the video. Meanwhile, Twitter had the video up, but they were sort of limiting its spread. Soon enough, they took down the video as well. And again, as the platforms were trying to decide whether or not they should keep this up, they were weighing a lot of things. They were - you know, typically, presidents had a lot of leeway to say what they want because there was an exception to the rules since whatever they said was considered newsworthy. There was sort of a world leaders exception to some of the rules and guidelines on Twitter. KELLY: Right. ALLYN: So they were trying to stick by that. But they were also, you know, looking at how extraordinary the violent scenes that were unfolding on the capital were and said, you know, this video has the potential of worsening some of that violence. And because of that, they said - you know, all the platforms said together, essentially, we have to take this down. This could really be harmful. KELLY: And what kind of reaction are you seeing so far to this? Do people think it is enough to take it down, to maybe locking him out of accounts for a certain period of time? ALLYN: Yeah. I mean, calls for the platforms to remove Trump have really been coming for many years. I mean, as we know, the president has used Twitter, you know, to, you know, threaten his enemies, to even go after, you know, everyday citizens, to stoke all sorts of conspiracy theories. And this, you know, push to so-call de-platform the president has been building and building and building. So I think people who have been calling for it say, yes, you should put him on notice, but maybe you should just ban him now because there are plenty examples in which Trump has gone to Twitter, abused the rules and has suffered no consequences. KELLY: Right. ALLYN: So this is a long time coming. KELLY: All right. NPR's Bobby Allyn reporting. Thank you, Bobby. ALLYN: Thanks, Mary Louise.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-01-07-953936034": {"title": "Sweater Design? Gin Rummy? Typing? These Are The Mario Games You've Never Heard Of : NPR", "url": "https://www.npr.org/2021/01/07/953936034/sweater-design-gin-rummy-typing-these-are-the-mario-games-youve-never-heard-of", "author": "No author found", "published_date": "2021-01-07", "content": "", "section": "Gaming", "disclaimer": ""}, "2021-01-08-954760928": {"title": "Twitter Permanently Suspends Trump, Citing 'Risk Of Further Incitement Of Violence' : NPR", "url": "https://www.npr.org/2021/01/08/954760928/twitter-bans-president-trump-citing-risk-of-further-incitement-of-violence", "author": "No author found", "published_date": "2021-01-08", "content": "AILSA CHANG, HOST:  Twitter has permanently suspended the account of President Trump. Navigate to the handle @realDonaldTrump, and now you get this message, quote, \"account suspended. Twitter suspends accounts which violate the Twitter rules. \" Now, many have blamed Trump's tweets and rhetoric for encouraging Wednesday's attack on the U. S. Capitol. And now, two days after that attack, the president of the United States is without his preferred method of public communication. NPR tech correspondent Bobby Allyn joins us now to walk us through this latest development. Hi, Bobby. BOBBY ALLYN, BYLINE: Hey, Ailsa. CHANG: So what exactly did Twitter cite as its rationale for making this move? ALLYN: Twitter said it made the decision in order to prevent the president from inciting further violence around the country. But the company did not make this decision in a vacuum, right? I mean, researchers, civil rights groups, even hundreds of Twitter employees have in recent days called on the company to kick Trump off the platform. So Twitter banning Trump for life only really came after a chorus of people said Trump is not just spreading false claims; he's actually stoking attacks on American democracy itself. CHANG: I mean, yeah, as we said, a lot of people have viewed Trump's tweets and his rhetoric as egging on the mob that attacked the Capitol. But, Bobby, I mean, so many objections have been raised before - over the past four years - to Trump's incendiary tweets. So why do you think Twitter is only now taking this drastic move literally just days away from the end of his presidency? ALLYN: Yeah, that's a good question, and we don't know. But I don't think it's lost on Twitter that Trump, like you said, has 12 days left in office, and Democrats are about to take power in Washington. So I can't say this is what caused the decision, but it's certainly notable that Twitter only banned Trump after it was clear that he had lost power. But yes, he has created a long record on Twitter of misleading, disparaging and just straight-up racist tweets. I mean, remember when Trump tweeted, when the looting starts, the shooting starts in reference to the George Floyd protesters? CHANG: Yes. ALLYN: That got a lot of attention. Yeah. I mean, many said back then that Twitter should ban Trump over that tweet, but they didn't. CHANG: They didn't. OK, so now President Trump is without Facebook. He's without Instagram. He's without Twitter. How crippling is this for him when it comes to his ability to communicate with his supporters? ALLYN: Quite. I mean, this is devastating for him. I mean, many experts say Trump as a political figure could never have existed without Twitter. I mean, the platform has helped him amass just this unbelievable following. It's, you know, propelled his political career. And once he got in the White House, his tweets became, you know, the equivalent of a presidential decree. I mean, just by sending one tweet, in a matter of a second, he could change a national news cycle. He could grab the spotlight back. So now that power is gone. And sure, he can go to a smaller, you know, alternative platform, but not having 88 million followers to directly speak to is unquestionably going to be a major hit to his relevancy. CHANG: Right. OK, so has the White House responded to any of this yet? ALLYN: Not yet, though we heard from Jason Miller, who was a top adviser to Trump, and he called Trump's ban, quote, \"disgusting\" and said, quote, \"big tech wanted to cancel the 75 million people who voted for Trump. \" We also heard from President Trump's son, Donald Trump Jr. , weighing in, saying, quote, \"we are living in Orwell's \"1984,\" where free speech no longer exists in America. \"CHANG: All right. That is NPR's Bobby Allyn. Thank you, Bobby. ALLYN: Thanks, Ailsa. AILSA CHANG, HOST:   Twitter has permanently suspended the account of President Trump. Navigate to the handle @realDonaldTrump, and now you get this message, quote, \"account suspended. Twitter suspends accounts which violate the Twitter rules. \" Now, many have blamed Trump's tweets and rhetoric for encouraging Wednesday's attack on the U. S. Capitol. And now, two days after that attack, the president of the United States is without his preferred method of public communication. NPR tech correspondent Bobby Allyn joins us now to walk us through this latest development. Hi, Bobby. BOBBY ALLYN, BYLINE: Hey, Ailsa. CHANG: So what exactly did Twitter cite as its rationale for making this move? ALLYN: Twitter said it made the decision in order to prevent the president from inciting further violence around the country. But the company did not make this decision in a vacuum, right? I mean, researchers, civil rights groups, even hundreds of Twitter employees have in recent days called on the company to kick Trump off the platform. So Twitter banning Trump for life only really came after a chorus of people said Trump is not just spreading false claims; he's actually stoking attacks on American democracy itself. CHANG: I mean, yeah, as we said, a lot of people have viewed Trump's tweets and his rhetoric as egging on the mob that attacked the Capitol. But, Bobby, I mean, so many objections have been raised before - over the past four years - to Trump's incendiary tweets. So why do you think Twitter is only now taking this drastic move literally just days away from the end of his presidency? ALLYN: Yeah, that's a good question, and we don't know. But I don't think it's lost on Twitter that Trump, like you said, has 12 days left in office, and Democrats are about to take power in Washington. So I can't say this is what caused the decision, but it's certainly notable that Twitter only banned Trump after it was clear that he had lost power. But yes, he has created a long record on Twitter of misleading, disparaging and just straight-up racist tweets. I mean, remember when Trump tweeted, when the looting starts, the shooting starts in reference to the George Floyd protesters? CHANG: Yes. ALLYN: That got a lot of attention. Yeah. I mean, many said back then that Twitter should ban Trump over that tweet, but they didn't. CHANG: They didn't. OK, so now President Trump is without Facebook. He's without Instagram. He's without Twitter. How crippling is this for him when it comes to his ability to communicate with his supporters? ALLYN: Quite. I mean, this is devastating for him. I mean, many experts say Trump as a political figure could never have existed without Twitter. I mean, the platform has helped him amass just this unbelievable following. It's, you know, propelled his political career. And once he got in the White House, his tweets became, you know, the equivalent of a presidential decree. I mean, just by sending one tweet, in a matter of a second, he could change a national news cycle. He could grab the spotlight back. So now that power is gone. And sure, he can go to a smaller, you know, alternative platform, but not having 88 million followers to directly speak to is unquestionably going to be a major hit to his relevancy. CHANG: Right. OK, so has the White House responded to any of this yet? ALLYN: Not yet, though we heard from Jason Miller, who was a top adviser to Trump, and he called Trump's ban, quote, \"disgusting\" and said, quote, \"big tech wanted to cancel the 75 million people who voted for Trump. \" We also heard from President Trump's son, Donald Trump Jr. , weighing in, saying, quote, \"we are living in Orwell's \"1984,\" where free speech no longer exists in America. \" CHANG: All right. That is NPR's Bobby Allyn. Thank you, Bobby. ALLYN: Thanks, Ailsa.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-01-08-954710407": {"title": "Google Workers Speak Out About Why They Formed A Union: 'To Protect Ourselves' : NPR", "url": "https://www.npr.org/2021/01/08/954710407/at-google-hundreds-of-workers-formed-a-labor-union-why-to-protect-ourselves", "author": "No author found", "published_date": "2021-01-08", "content": "NOEL KING, HOST:  Hundreds of Google employees did something this week that is rare in Silicon Valley. They formed a labor union. Some of them talked to NPR's Bobby Allyn about why. And I should note, Google is a financial supporter of NPR. BOBBY ALLYN, BYLINE: After the death of George Floyd, Google engineer Raksha Muthukumar sent an email to colleagues. It included a list of criminal justice reform groups and bail funds for protesters. Soon after, Muthukumar was summoned into a meeting with Google's HR department. RAKSHA MUTHUKUMAR: And I remember that was, like, such a scary experience. It was such a mysterious HR letter. And I was, like, texting friends who had been involved in organizing. And they were like, oh, this is my experience with HR. This is what's happened. Don't forget to, like, take notes on it. ALLYN: She was told that a colleague was offended by her email. One of the fundraisers had used harsh language to describe police. But she wasn't expecting it to land on the radar of higher ups. MUTHUKUMAR: It just seemed like the most neutral thing, sending, like, a little GoFundMe list. And that got me in trouble in some way. ALLYN: A talking to from HR, being demoted or pushed out of the company after speaking out, these are the stories that have consumed Googlers for months. And it set the stage for Muthukumar and several hundred colleagues to form the Alphabet Workers Union, named after Google's parent company. MUTHUKUMAR: The fear of retaliation has always been great. And we've seen retaliation. So this is our chance to protect ourselves. ALLYN: Google employees enjoy cushy salaries and company perks. They've long kept their heads down. But that is changing. The union has been quietly in the works for a year, a year in which some employees have stepped forward to accuse Google of discrimination. Others have openly questioned some of Google's work, like selling technology to U. S. border agents and the military. But what really galvanized the movement was the ouster of prominent Black researcher Timnit Gebru, which thousands of Googlers publicly denounced in an open letter. Alan Morales is a Google engineer who also joined the union. ALAN MORALES: There is massive power that has been concentrated at the executive level. And as a tech employee, it's a very reasonable ask to, you know, ensure that, actually, this labor is being used for something positive that makes the world a better place. ALLYN: The union's members are a tiny fraction of Google's 200,000-some employees and contractors. This union is distinct because it's not seeking collective bargaining power, just a way to influence the company's decisions. In a statement, Google said the company has always, quote, \"worked hard to create a supportive and rewarding workplace,\" saying it will, quote, \"continue engaging directly with all our employees. \"ROSS LAJEUNESSE: That just struck me as an example that they really don't get it. ALLYN: Ross LaJeunesse is a former Google executive. Until 2019, he headed the company's international relations but says he was forced out for promoting human rights in China. He says top executives are likely worried the union will hurt Google's image at a time when public opinion is turning against big tech. LAJEUNESSE: The first thing that the Google executives will be concerned about is potential damage to the brand and to the PR efforts that the company constantly undertakes,ALLYN: LaJeunesse says the union shows that company brass haven't directly engaged with growing calls for reform from some of the company's rank and file. That, he says, could hurt the company long-term. LAJEUNESSE: Really, this should be an alarm to investors and to the board. ALLYN: LaJeunesse says keeping and recruiting some of the brightest stars in tech hinges on Google keeping its reputation. The union could pose a real challenge to that. Bobby Allyn, NPR News, San Francisco. NOEL KING, HOST:   Hundreds of Google employees did something this week that is rare in Silicon Valley. They formed a labor union. Some of them talked to NPR's Bobby Allyn about why. And I should note, Google is a financial supporter of NPR. BOBBY ALLYN, BYLINE: After the death of George Floyd, Google engineer Raksha Muthukumar sent an email to colleagues. It included a list of criminal justice reform groups and bail funds for protesters. Soon after, Muthukumar was summoned into a meeting with Google's HR department. RAKSHA MUTHUKUMAR: And I remember that was, like, such a scary experience. It was such a mysterious HR letter. And I was, like, texting friends who had been involved in organizing. And they were like, oh, this is my experience with HR. This is what's happened. Don't forget to, like, take notes on it. ALLYN: She was told that a colleague was offended by her email. One of the fundraisers had used harsh language to describe police. But she wasn't expecting it to land on the radar of higher ups. MUTHUKUMAR: It just seemed like the most neutral thing, sending, like, a little GoFundMe list. And that got me in trouble in some way. ALLYN: A talking to from HR, being demoted or pushed out of the company after speaking out, these are the stories that have consumed Googlers for months. And it set the stage for Muthukumar and several hundred colleagues to form the Alphabet Workers Union, named after Google's parent company. MUTHUKUMAR: The fear of retaliation has always been great. And we've seen retaliation. So this is our chance to protect ourselves. ALLYN: Google employees enjoy cushy salaries and company perks. They've long kept their heads down. But that is changing. The union has been quietly in the works for a year, a year in which some employees have stepped forward to accuse Google of discrimination. Others have openly questioned some of Google's work, like selling technology to U. S. border agents and the military. But what really galvanized the movement was the ouster of prominent Black researcher Timnit Gebru, which thousands of Googlers publicly denounced in an open letter. Alan Morales is a Google engineer who also joined the union. ALAN MORALES: There is massive power that has been concentrated at the executive level. And as a tech employee, it's a very reasonable ask to, you know, ensure that, actually, this labor is being used for something positive that makes the world a better place. ALLYN: The union's members are a tiny fraction of Google's 200,000-some employees and contractors. This union is distinct because it's not seeking collective bargaining power, just a way to influence the company's decisions. In a statement, Google said the company has always, quote, \"worked hard to create a supportive and rewarding workplace,\" saying it will, quote, \"continue engaging directly with all our employees. \" ROSS LAJEUNESSE: That just struck me as an example that they really don't get it. ALLYN: Ross LaJeunesse is a former Google executive. Until 2019, he headed the company's international relations but says he was forced out for promoting human rights in China. He says top executives are likely worried the union will hurt Google's image at a time when public opinion is turning against big tech. LAJEUNESSE: The first thing that the Google executives will be concerned about is potential damage to the brand and to the PR efforts that the company constantly undertakes, ALLYN: LaJeunesse says the union shows that company brass haven't directly engaged with growing calls for reform from some of the company's rank and file. That, he says, could hurt the company long-term. LAJEUNESSE: Really, this should be an alarm to investors and to the board. ALLYN: LaJeunesse says keeping and recruiting some of the brightest stars in tech hinges on Google keeping its reputation. The union could pose a real challenge to that. Bobby Allyn, NPR News, San Francisco.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-01-08-954046428": {"title": "Why Alibaba Founder Jack Ma Hasn't Been Seen In Public Lately : NPR", "url": "https://www.npr.org/2021/01/08/954046428/alibaba-founder-jack-ma-has-fallen-off-the-radar-here-are-some-clues-why", "author": "No author found", "published_date": "2021-01-08", "content": "STEVE INSKEEP, HOST:  Jack Ma is one of the world's most successful businesspeople. And until recently, he was also among the more visible. The founder of China's giant company Alibaba often turned up in interviews or at conferences or on TV. In 2017, he gave advice at the World Economic Forum. (SOUNDBITE OF ARCHIVED RECORDING)JACK MA: Every day's uncertain. The only certain day was yesterday. That's why I should retire early. INSKEEP: The man who said every day is uncertain now faces an uncertain fate. And the man who often spoke in public has not appeared in months. He recently missed scheduled TV appearances. It's becoming more clear that this billionaire is out of favor with China's government. So what exactly happened to Jack Ma? To find out, we placed a call to Beijing. A tech firm adviser named Duncan Clark knows Jack Ma's business empire. DUNCAN CLARK: Amazon and Alibaba have some similarities, but Alibaba is more than that because imagine if, you know, half of the transactions you do in your day in the U. S. were also controlled by the same company. INSKEEP: Alibaba created a service called Alipay. It's a system for making payments by phone using QR codes. It's now used for billions of transactions and is making cash nearly obsolete. Alipay was spun off into a company called Ant Financial. Last fall, Ant Financial was on the verge of an IPO, an initial public offering of stock, potentially the largest in history. And that's when things started to go wrong. Duncan Clark, who wrote a book about Jack Ma, has known him for decades. CLARK: Jack Ma is an unusual tech entrepreneur in that he's not a tech guy at all. He had a pretty modest background, doesn't come from wealth or connections. He was formerly an English teacher that, on his sort of third attempt outside of the teaching, became a very successful entrepreneur. He's an amazing communicator, which is odd because the reason we're talking about him is that he gave a terrible speech that - much like a bit that didn't go well. INSKEEP: What did he say in October? CLARK: Well, in October, he was speaking at something called a Bund Finance Summit in Shanghai. He was not the most important person in the room if you think in terms of the government regulators who were there. And he proceeded to basically tell them that they were, you know, anachronistic, that you cannot, for example, run an airport like the way you run a train station. And then he effectively - not only he initially launched into an attack on the global financial regulatory system of banking, but then he kind of moved his topic to China and said, as I described, that he thought they were out of touch and that there was a new revolution coming. It was actually almost a call for revolution in terms of the finance sector. INSKEEP: What happened to his IPO after this speech? CLARK: It never happened. The stock was supposed to start trading in both Hong Kong and Shanghai. It was a dual listing. And, you know, initially, the regulators in China said it's suspended. We've never heard an update. Subsequently, the government has announced investigation into the sector, also into Alibaba itself and other tech platforms, saying that, you know, it's a time to check whether there's monopolistic behavior or excess power. So I think underlying this pushing back on Jack Ma is also a reassertion of the role of the state in the economy, which is very much part of President Xi Jinping's agenda. INSKEEP: When and where was Jack Ma last seen, then? CLARK: Then. I mean, basically, I think after he left the stage, in terms of public appearances, there hasn't been one in two months now. My understanding is that he's been told to lay low. I think he just - basically, they want him back in his box. And one wonders if there's some degree of jealousy or irritation for President Xi or, you know, the government in general, that this, you know, rather uncontrollable figure is popping up in different places around the world. INSKEEP: To state the obvious, you can be in a lucrative position but also a very powerful position if you're present when money is changing hands. And here's this guy running this company that is almost literally everywhere that money is changing hands. Is that such a powerful place to be that China's government would be especially concerned about what that company and what its leaders would do? CLARK: Right. Well, there is talk that maybe the government wants to, you know, take a stake or even take over these core payment companies because they're so essential both for the smooth operation of commerce but also on a social level. And this was what Ant did, basically - was use this payment mechanism, which actually, by the way, isn't very profitable because they're not making that much money on these transactions. But all the data they were building up - they were then starting to sell financial products to these consumers because they knew - they could see how much they were earning, how much they were spending. So it's like perfect transparency. So ultimately, yeah, I think the government realized that this power was something - that they needed it themselves. I think there will be a joint statement at some point by the government, maybe Jack personally, to reassure people that - you know, he's - like a proof-of-life kind of thing but also that they're going to work together in some face-saving way. But I don't think the IPO's ever going to happen, and the company will probably be broken up. INSKEEP: Duncan Clark, thanks so much. Pleasure talking with you. CLARK: Thank you. My pleasure. STEVE INSKEEP, HOST:   Jack Ma is one of the world's most successful businesspeople. And until recently, he was also among the more visible. The founder of China's giant company Alibaba often turned up in interviews or at conferences or on TV. In 2017, he gave advice at the World Economic Forum. (SOUNDBITE OF ARCHIVED RECORDING) JACK MA: Every day's uncertain. The only certain day was yesterday. That's why I should retire early. INSKEEP: The man who said every day is uncertain now faces an uncertain fate. And the man who often spoke in public has not appeared in months. He recently missed scheduled TV appearances. It's becoming more clear that this billionaire is out of favor with China's government. So what exactly happened to Jack Ma? To find out, we placed a call to Beijing. A tech firm adviser named Duncan Clark knows Jack Ma's business empire. DUNCAN CLARK: Amazon and Alibaba have some similarities, but Alibaba is more than that because imagine if, you know, half of the transactions you do in your day in the U. S. were also controlled by the same company. INSKEEP: Alibaba created a service called Alipay. It's a system for making payments by phone using QR codes. It's now used for billions of transactions and is making cash nearly obsolete. Alipay was spun off into a company called Ant Financial. Last fall, Ant Financial was on the verge of an IPO, an initial public offering of stock, potentially the largest in history. And that's when things started to go wrong. Duncan Clark, who wrote a book about Jack Ma, has known him for decades. CLARK: Jack Ma is an unusual tech entrepreneur in that he's not a tech guy at all. He had a pretty modest background, doesn't come from wealth or connections. He was formerly an English teacher that, on his sort of third attempt outside of the teaching, became a very successful entrepreneur. He's an amazing communicator, which is odd because the reason we're talking about him is that he gave a terrible speech that - much like a bit that didn't go well. INSKEEP: What did he say in October? CLARK: Well, in October, he was speaking at something called a Bund Finance Summit in Shanghai. He was not the most important person in the room if you think in terms of the government regulators who were there. And he proceeded to basically tell them that they were, you know, anachronistic, that you cannot, for example, run an airport like the way you run a train station. And then he effectively - not only he initially launched into an attack on the global financial regulatory system of banking, but then he kind of moved his topic to China and said, as I described, that he thought they were out of touch and that there was a new revolution coming. It was actually almost a call for revolution in terms of the finance sector. INSKEEP: What happened to his IPO after this speech? CLARK: It never happened. The stock was supposed to start trading in both Hong Kong and Shanghai. It was a dual listing. And, you know, initially, the regulators in China said it's suspended. We've never heard an update. Subsequently, the government has announced investigation into the sector, also into Alibaba itself and other tech platforms, saying that, you know, it's a time to check whether there's monopolistic behavior or excess power. So I think underlying this pushing back on Jack Ma is also a reassertion of the role of the state in the economy, which is very much part of President Xi Jinping's agenda. INSKEEP: When and where was Jack Ma last seen, then? CLARK: Then. I mean, basically, I think after he left the stage, in terms of public appearances, there hasn't been one in two months now. My understanding is that he's been told to lay low. I think he just - basically, they want him back in his box. And one wonders if there's some degree of jealousy or irritation for President Xi or, you know, the government in general, that this, you know, rather uncontrollable figure is popping up in different places around the world. INSKEEP: To state the obvious, you can be in a lucrative position but also a very powerful position if you're present when money is changing hands. And here's this guy running this company that is almost literally everywhere that money is changing hands. Is that such a powerful place to be that China's government would be especially concerned about what that company and what its leaders would do? CLARK: Right. Well, there is talk that maybe the government wants to, you know, take a stake or even take over these core payment companies because they're so essential both for the smooth operation of commerce but also on a social level. And this was what Ant did, basically - was use this payment mechanism, which actually, by the way, isn't very profitable because they're not making that much money on these transactions. But all the data they were building up - they were then starting to sell financial products to these consumers because they knew - they could see how much they were earning, how much they were spending. So it's like perfect transparency. So ultimately, yeah, I think the government realized that this power was something - that they needed it themselves. I think there will be a joint statement at some point by the government, maybe Jack personally, to reassure people that - you know, he's - like a proof-of-life kind of thing but also that they're going to work together in some face-saving way. But I don't think the IPO's ever going to happen, and the company will probably be broken up. INSKEEP: Duncan Clark, thanks so much. Pleasure talking with you. CLARK: Thank you. My pleasure.", "section": "Business", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-01-09-955329265": {"title": "Amazon And Apple Drop Parler : NPR", "url": "https://www.npr.org/2021/01/09/955329265/amazon-and-apple-drop-parler", "author": "No author found", "published_date": "2021-01-09", "content": "", "section": "Technology", "disclaimer": ""}, "2021-01-10-955479411": {"title": "Tech Companies Crack Down On President Trump : NPR", "url": "https://www.npr.org/2021/01/10/955479411/tech-companies-crack-down-on-president-trump", "author": "No author found", "published_date": "2021-01-10", "content": "MICHEL MARTIN, HOST:  President Trump can no longer post messages to Twitter or Facebook. The social media giants have banned him, worried that he could stir up more violence around the country. Trump has reacted by saying he will go elsewhere. But late yesterday, tech companies made it virtually impossible for an alternative popular with Trump supporters to continue to operate. NPR tech reporter Bobby Allyn is with us now to tell us more. Bobby, thanks for joining us. BOBBY ALLYN, BYLINE: Of course. MARTIN: As we know, President Trump has used social media as his megaphone throughout his presidency, particularly Twitter. How significant is it that Twitter kicked him off the platform? ALLYN: You know, Michel, it's really a watershed moment in the tech world. And to be fair, civil rights groups and disinformation researchers have for years been calling on Twitter to do more to rein Trump in. I mean, he's really had this outsized role in polluting the Internet with falsehoods and misleading claims. But it took a violent insurrection attempt on the nation's capital before Twitter said, OK, enough. Now, inside Twitter, there's really been this heated debate about the balancing act between censoring the president of the United States and owning up to enabling violence when the president is responsible for it. So now we have Congress, as we just heard Sue talk about, grappling with whether to impeach Trump over this, law enforcement investigating the incident, and now tech companies responding. Joan Donovan is an expert on online extremism at Harvard. JOAN DONOVAN: The reason why we're experiencing this corporate denial of service is because there are really no other levers possible to stop this group of people from reassembling and either trying this again or trying something else that's just as dangerous. MARTIN: Well, you know, Bobby, as I think everybody knows by now, Trump and his allies say Twitter silencing him is an infringement of free speech. Is there anything to this argument? ALLYN: Legally, no. By law, the platforms have complete discretion over what's allowed on their sites. Look; they're private companies, and private companies have rules. But Twitter has become a public town square. And Trump and his supporters, like you said, say Twitter is muzzling him and robbing him of his free speech. And even the ACLU put out a statement saying it should concern us when tech companies de-platform influential speakers only when they're losing power. MARTIN: Well, tell us about this alternative social media app, Parler, which looks a lot like Twitter. But as I understand it, it promises to take the lightest hand when it comes to free speech. ALLYN: That's right. Yeah, so Parler has become this go-to app for Trump supporters ever since Twitter and Facebook began its crackdown. And on Friday, when Twitter banned Trump, a lot of his supporters say, hey, come on over to Parler. Then Apple and Google made it impossible to download the app on smartphones. And just yesterday, Amazon joined in the crackdown. They announced that it wouldn't host the site anymore starting midnight tonight through its Amazon Web Services. Harvard's Donovan told me that more and more pressure is going to be not just focused on the social media companies, but also on the Web service providers. DONOVAN: It's going to be really important that when they make these decisions, they stick and that they don't walk them back once the heat is off. ALLYN: Yeah. So - and Parler's CEO says, you know, he is scrambling to come up with another way to keep its site alive. But, you know, Michel, big picture - if Parler is crippled, there are a bunch of other smaller sites that cater to right-wing provocateurs. And one of those may very well be, you know, the site where Trump supporters plan their next mass gathering. MARTIN: That was NPR's Bobby Allyn. Bobby, thank you. ALLYN: Thanks, Michel. MICHEL MARTIN, HOST:   President Trump can no longer post messages to Twitter or Facebook. The social media giants have banned him, worried that he could stir up more violence around the country. Trump has reacted by saying he will go elsewhere. But late yesterday, tech companies made it virtually impossible for an alternative popular with Trump supporters to continue to operate. NPR tech reporter Bobby Allyn is with us now to tell us more. Bobby, thanks for joining us. BOBBY ALLYN, BYLINE: Of course. MARTIN: As we know, President Trump has used social media as his megaphone throughout his presidency, particularly Twitter. How significant is it that Twitter kicked him off the platform? ALLYN: You know, Michel, it's really a watershed moment in the tech world. And to be fair, civil rights groups and disinformation researchers have for years been calling on Twitter to do more to rein Trump in. I mean, he's really had this outsized role in polluting the Internet with falsehoods and misleading claims. But it took a violent insurrection attempt on the nation's capital before Twitter said, OK, enough. Now, inside Twitter, there's really been this heated debate about the balancing act between censoring the president of the United States and owning up to enabling violence when the president is responsible for it. So now we have Congress, as we just heard Sue talk about, grappling with whether to impeach Trump over this, law enforcement investigating the incident, and now tech companies responding. Joan Donovan is an expert on online extremism at Harvard. JOAN DONOVAN: The reason why we're experiencing this corporate denial of service is because there are really no other levers possible to stop this group of people from reassembling and either trying this again or trying something else that's just as dangerous. MARTIN: Well, you know, Bobby, as I think everybody knows by now, Trump and his allies say Twitter silencing him is an infringement of free speech. Is there anything to this argument? ALLYN: Legally, no. By law, the platforms have complete discretion over what's allowed on their sites. Look; they're private companies, and private companies have rules. But Twitter has become a public town square. And Trump and his supporters, like you said, say Twitter is muzzling him and robbing him of his free speech. And even the ACLU put out a statement saying it should concern us when tech companies de-platform influential speakers only when they're losing power. MARTIN: Well, tell us about this alternative social media app, Parler, which looks a lot like Twitter. But as I understand it, it promises to take the lightest hand when it comes to free speech. ALLYN: That's right. Yeah, so Parler has become this go-to app for Trump supporters ever since Twitter and Facebook began its crackdown. And on Friday, when Twitter banned Trump, a lot of his supporters say, hey, come on over to Parler. Then Apple and Google made it impossible to download the app on smartphones. And just yesterday, Amazon joined in the crackdown. They announced that it wouldn't host the site anymore starting midnight tonight through its Amazon Web Services. Harvard's Donovan told me that more and more pressure is going to be not just focused on the social media companies, but also on the Web service providers. DONOVAN: It's going to be really important that when they make these decisions, they stick and that they don't walk them back once the heat is off. ALLYN: Yeah. So - and Parler's CEO says, you know, he is scrambling to come up with another way to keep its site alive. But, you know, Michel, big picture - if Parler is crippled, there are a bunch of other smaller sites that cater to right-wing provocateurs. And one of those may very well be, you know, the site where Trump supporters plan their next mass gathering. MARTIN: That was NPR's Bobby Allyn. Bobby, thank you. ALLYN: Thanks, Michel.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-01-11-955709181": {"title": "Tech Giants Join Corporate Reckoning Over Political Spending : NPR", "url": "https://www.npr.org/2021/01/11/955709181/tech-giants-join-corporate-reckoning-over-political-spending", "author": "No author found", "published_date": "2021-01-11", "content": "TONYA MOSLEY, HOST:  Corporate America is looking at money in politics in a new light. A growing list of companies is pausing some political spending after last week's violent attack on the U. S. Capitol. Among them are tech giants - Facebook, Microsoft and Google - and big banks, Goldman Sachs and J. P. Morgan. Full disclosure, those five companies are among NPR's recent sponsors. NPR's Alina Selyukh reports. ALINA SELYUKH, BYLINE: One after another, corporations piled on. One trade group called for the removal of President Trump, and not just any group, the National Association of Manufacturers, a longtime supporter of Trump. Many of the tech and banking giants halted all their political giving, at least for a few months. Marriott, Comcast, Airbnb and others stopped donations to specific Republican lawmakers, those who fought the certification of the election. MEREDITH MCGEHEE: At this moment - right? - at this crisis moment, they sent a really important signal. SELYUKH: Meredith McGehee is the executive director at Issue One, a nonprofit that works to reduce the influence of money in politics. MCGEHEE: You just can't really overemphasize the role that donors play in the current political calculation. SELYUKH: And it's unusual to see so many companies, on their own, without a campaign to pressure them, publicly address how they contribute to the current political state. But there are caveats. This is often the moment when many companies reevaluate their political spending right after an election. Plus, there are many ways companies make political donations. All the corporate statements now are about their official political action committees. But there are also super PACs and tax-exempt groups that don't have to disclose donors. And a lot of corporate spending flows from individuals like executives. The biggest question is, money-in-politics groups ask, will this flurry of corporate reckoning be an epiphany or a fad? Alina Selyukh, NPR News. (SOUNDBITE OF NIHIL YOUNG AND LESS HATE'S \"LOSS\") TONYA MOSLEY, HOST:   Corporate America is looking at money in politics in a new light. A growing list of companies is pausing some political spending after last week's violent attack on the U. S. Capitol. Among them are tech giants - Facebook, Microsoft and Google - and big banks, Goldman Sachs and J. P. Morgan. Full disclosure, those five companies are among NPR's recent sponsors. NPR's Alina Selyukh reports. ALINA SELYUKH, BYLINE: One after another, corporations piled on. One trade group called for the removal of President Trump, and not just any group, the National Association of Manufacturers, a longtime supporter of Trump. Many of the tech and banking giants halted all their political giving, at least for a few months. Marriott, Comcast, Airbnb and others stopped donations to specific Republican lawmakers, those who fought the certification of the election. MEREDITH MCGEHEE: At this moment - right? - at this crisis moment, they sent a really important signal. SELYUKH: Meredith McGehee is the executive director at Issue One, a nonprofit that works to reduce the influence of money in politics. MCGEHEE: You just can't really overemphasize the role that donors play in the current political calculation. SELYUKH: And it's unusual to see so many companies, on their own, without a campaign to pressure them, publicly address how they contribute to the current political state. But there are caveats. This is often the moment when many companies reevaluate their political spending right after an election. Plus, there are many ways companies make political donations. All the corporate statements now are about their official political action committees. But there are also super PACs and tax-exempt groups that don't have to disclose donors. And a lot of corporate spending flows from individuals like executives. The biggest question is, money-in-politics groups ask, will this flurry of corporate reckoning be an epiphany or a fad? Alina Selyukh, NPR News. (SOUNDBITE OF NIHIL YOUNG AND LESS HATE'S \"LOSS\")", "section": "Business", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-01-11-955750196": {"title": "Facebook Taps Former Obama Official As Vice President Of Civil Rights : NPR", "url": "https://www.npr.org/2021/01/11/955750196/facebook-taps-former-obama-official-as-vice-president-of-civil-civil-rights", "author": "No author found", "published_date": "2021-01-11", "content": "", "section": "America Reckons With Racial Injustice", "disclaimer": ""}, "2021-01-11-955719946": {"title": "What Social Media's Crackdown On Trump Says About Big Tech : NPR", "url": "https://www.npr.org/2021/01/11/955719946/what-social-medias-crackdown-on-trump-says-about-big-tech", "author": "No author found", "published_date": "2021-01-11", "content": "AILSA CHANG, HOST:  People talk a lot about Big Tech, and certainly the past few days show just how powerful these companies are. First, Twitter and Facebook suspended President Trump's access to his biggest online megaphones. Then Apple, Google and Amazon cut off Parler, a social media site popular with Trump supporters. And joining us now to unpack all of this is NPR's tech correspondent Shannon Bond. Hey, Shannon. SHANNON BOND, BYLINE: Hey, Ailsa. CHANG: All right, so we should first note that Facebook, Google, Apple and Amazon are all among NPR's financial supporters. All right, so, Shannon, what do you think these pretty aggressive moves tell us about Silicon Valley right now? BOND: Well, Ailsa, you know, when Facebook and Twitter cut off President Trump, it really put the spotlight on something I think we've known for a long time but are just seeing so starkly, which is how much power these Big Tech companies wield. . . CHANG: Yeah. BOND: . . . Because we conduct so much of our lives online. So there were the examples you mentioned but also others that go beyond the question of speech, really, to the bottom line. Stripe and PayPal cut off the ability of the president's campaign and his supporters to raise money and take payments. The e-commerce company Shopify shut down an online shop connected to the Trump that sold merchandise like Make America Great Again hats and another shop owned by the Trump organization that sold things like golf accessories. And so these decisions, they are raising some really big questions. CHANG: What are some of those questions? BOND: Well, maybe the biggest one is all about access. So Amazon, Apple, Google - they have a lot of power over kind of what we think of more of the infrastructure of the Internet. In Apple and Google's cases, they - you know, they decide what apps can go into the app stores. So they decided this weekend to block Parler, the alternative social media site that Trump supporters had flocked to. And that means it's much harder to get Parler on your smartphone, which is, of course, where most people use social media. And then even more significantly, Amazon kicked Parler off its Web hosting service, so it's gone dark. You can't access it at all. Today Parler sued Amazon. And basically, you know, we're really realizing, seeing very tangibly just how much power Big Tech has to decide which companies, which brands, which businesses can effectively exist online. CHANG: OK, sure, that is a lot of power. But isn't all of this bound to put these companies even under more scrutiny going forward? BOND: Yeah, I think that's absolutely fair. And I spoke with Ben Wizner at the American Civil Liberties Union. He said the same thing. He's really concerned about these individual companies' power. Here's what he told me. BEN WIZNER: And it may be that by exercising their right, their constitutional right to decide who can use their products right now, they're going to bring a different kind of regulatory focus down on them about whether we should have let these companies get this big in the first place. BOND: So, you know, this isn't going to go away, Ailsa. I mean, remember; these companies, they're already under a lot of scrutiny. Facebook and Google are facing antitrust investigations. Now we have Congress promising new investigations here. CHANG: Right. BOND: So I think the spotlight just continues. CHANG: Well, I mean, turning to President Trump, he got off - he got cut off from Twitter and Facebook, now Parler. It was a momentary alternative, but that's gone for now. Where will Trump go, do you think? BOND: That is the big question. There are plenty of upstart sites that want him. He might even start his own outlet. I think, Ailsa, it's safe to assume he is not getting off of the Internet for good. CHANG: I think that is safe. That's NPR's Shannon Bond. Thank you, Shannon. BOND: Thanks for having me. AILSA CHANG, HOST:   People talk a lot about Big Tech, and certainly the past few days show just how powerful these companies are. First, Twitter and Facebook suspended President Trump's access to his biggest online megaphones. Then Apple, Google and Amazon cut off Parler, a social media site popular with Trump supporters. And joining us now to unpack all of this is NPR's tech correspondent Shannon Bond. Hey, Shannon. SHANNON BOND, BYLINE: Hey, Ailsa. CHANG: All right, so we should first note that Facebook, Google, Apple and Amazon are all among NPR's financial supporters. All right, so, Shannon, what do you think these pretty aggressive moves tell us about Silicon Valley right now? BOND: Well, Ailsa, you know, when Facebook and Twitter cut off President Trump, it really put the spotlight on something I think we've known for a long time but are just seeing so starkly, which is how much power these Big Tech companies wield. . . CHANG: Yeah. BOND: . . . Because we conduct so much of our lives online. So there were the examples you mentioned but also others that go beyond the question of speech, really, to the bottom line. Stripe and PayPal cut off the ability of the president's campaign and his supporters to raise money and take payments. The e-commerce company Shopify shut down an online shop connected to the Trump that sold merchandise like Make America Great Again hats and another shop owned by the Trump organization that sold things like golf accessories. And so these decisions, they are raising some really big questions. CHANG: What are some of those questions? BOND: Well, maybe the biggest one is all about access. So Amazon, Apple, Google - they have a lot of power over kind of what we think of more of the infrastructure of the Internet. In Apple and Google's cases, they - you know, they decide what apps can go into the app stores. So they decided this weekend to block Parler, the alternative social media site that Trump supporters had flocked to. And that means it's much harder to get Parler on your smartphone, which is, of course, where most people use social media. And then even more significantly, Amazon kicked Parler off its Web hosting service, so it's gone dark. You can't access it at all. Today Parler sued Amazon. And basically, you know, we're really realizing, seeing very tangibly just how much power Big Tech has to decide which companies, which brands, which businesses can effectively exist online. CHANG: OK, sure, that is a lot of power. But isn't all of this bound to put these companies even under more scrutiny going forward? BOND: Yeah, I think that's absolutely fair. And I spoke with Ben Wizner at the American Civil Liberties Union. He said the same thing. He's really concerned about these individual companies' power. Here's what he told me. BEN WIZNER: And it may be that by exercising their right, their constitutional right to decide who can use their products right now, they're going to bring a different kind of regulatory focus down on them about whether we should have let these companies get this big in the first place. BOND: So, you know, this isn't going to go away, Ailsa. I mean, remember; these companies, they're already under a lot of scrutiny. Facebook and Google are facing antitrust investigations. Now we have Congress promising new investigations here. CHANG: Right. BOND: So I think the spotlight just continues. CHANG: Well, I mean, turning to President Trump, he got off - he got cut off from Twitter and Facebook, now Parler. It was a momentary alternative, but that's gone for now. Where will Trump go, do you think? BOND: That is the big question. There are plenty of upstart sites that want him. He might even start his own outlet. I think, Ailsa, it's safe to assume he is not getting off of the Internet for good. CHANG: I think that is safe. That's NPR's Shannon Bond. Thank you, Shannon. BOND: Thanks for having me.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-01-11-955664150": {"title": "Parler Sues Amazon, Seeking To Restore Web Service : Capitol Insurrection Updates : NPR", "url": "https://www.npr.org/2021/01/11/955664150/parler-files-lawsuit-against-amazon-seeking-to-restore-web-service", "author": "No author found", "published_date": "2021-01-11", "content": "", "section": "Capitol Insurrection Updates", "disclaimer": ""}, "2021-01-13-956558906": {"title": "Trump never followed through on a plan to ban TikTok, but India did : Planet Money : NPR", "url": "https://www.npr.org/2021/01/13/956558906/nervous-tiktok", "author": "No author found", "published_date": "2021-01-13", "content": "SYLVIE DOUGLIS, BYLINE: This is PLANET MONEY from NPR. AMANDA ARONCZYK, HOST:  Can you introduce yourself and tell me what your job is? JACK CORBETT, BYLINE: Yeah. My name's Jack Corbett. My job is PLANET MONEY TikTok guy. I make videos for PLANET MONEY on TikTok. ARONCZYK: Are you our intern? CORBETT: No, I'm not. I'm not. I'm not. I never was the PLANET MONEY intern. I was the music video intern last year. But, no, I'm a production assistant for the video team. ARONCZYK: OK. CORBETT: I answer to no one at PLANET MONEY. ARONCZYK: (Laughter) So bold, but not exactly true. Jack officially works for and is paid out of NPR's video team's budget, not by PLANET MONEY, not by TikTok. But full disclosure - last spring, TikTok approached PLANET MONEY, and they said that they wanted our brand of edutainment on the platform. They gave us a small grant. It was part of their Learn On TikTok initiative. CORBETT: I think the wording is TikTok helps fund some of the videos that PLANET MONEY posts on the platform. But, yeah, they have, like, no - they have no, like, editorial say. They're just like, make something educational. ARONCZYK: And by the way, our boss who handles our TikTok contract - he has recused himself from this episode. He didn't see a script. He didn't approve the angles or the sources - none of it. So this past May, making TikTok videos became Jack's full-time job. My favorite video is the one about the price of coffee. You can see Jack. He's looking maybe a little more shaky than usual. (SOUNDBITE OF TIKTOK VIDEO)CORBETT: Coffee doesn't ask silly questions. Coffee understands. I'm a Hufflepuff. I do weekends, comfy clothes, messy hair, a whole lot of coffee and a whole lot of coffee. ARONCZYK: Because making videos like this one is Jack's job, he was pretty alarmed when last July, President Trump made this announcement. (SOUNDBITE OF ARCHIVED RECORDING)PRESIDENT DONALD TRUMP: We're looking at TikTok. We may be banning TikTok. We may be doing some other things. There are a couple of options. ARONCZYK: President Trump declares a ban on TikTok. CORBETT: At first, I was like, oh, no, this is horrible, just 'cause I love the platform so much. And also, I was just getting the hang of it. ARONCZYK: The stated reason for the ban is national security concerns that the app, which is owned by the Chinese company ByteDance, is essentially a piece of spyware, that it's a source of disinformation, that it suppresses free speech. Then, Trump signs two executive orders that essentially say TikTok has 45 days to sell itself to an American company or get banned. TikTokers prepare for the worst. They post these, like, weepy, what if this is really the end kind of videos. This is one from a guy named Old Time Hockey (ph). He lives in a cabin in the Upper Peninsula. (SOUNDBITE OF TIKTOK VIDEO)OLD TIME HOCKEY: It's been a tough year, eh? They say the hottest fires make the hardest steel. Maybe TikTok does go away. Maybe it doesn't. ARONCZYK: This guy - he's really going to miss TikTok. (SOUNDBITE OF TIKTOK VIDEO)OLD TIME HOCKEY: Where else can a man and his dog living in a cabin in the woods make so many buddies? ARONCZYK: The ban - sad. CORBETT: Like, everyone was doing, like, goodbye posts. They were like, you know, follow my Twitter, follow my Instagram, follow my YouTube channel. But, you know, it just doesn't - it's not the same. It's not the same as TikTok. (SOUNDBITE OF BENSON TAYLOR, ET AL. 'S \"GREETINGS PROGRAMS\")ARONCZYK: Hello, and welcome to PLANET MONEY. I'm Amanda Aronczyk. So originally for this episode, Jack was just going to be, like, my interview subject. But then I realized without Jack, I'm just momsplaining (ph) TikTok to you. So, Jack. CORBETT: Hey. ARONCZYK: How's it going? CORBETT: Good, good. Thanks. ARONCZYK: (Laughter). CORBETT: Today on the show, the U. S. versus TikTok. That's TikTok - one word, no spaces. It's not the Kesha song. ARONCZYK: In this show, we are not going to talk about Kesha, but we will look at why the ban was threatened, where it stands now. And then we will visit a country where TikTok has been banned for months. (SOUNDBITE OF BENSON TAYLOR, ET AL. 'S \"GREETINGS PROGRAMS\")ARONCZYK: This past week, there has been what you might call a banning bonanza. Twitter banned President Trump. So did Facebook and Instagram and Snapchat. And TikTok kind of banned Trump. He doesn't actually have a TikTok account. It was like the one major social media platform that he wasn't dominating. CORBETT: His dancing has gone pretty viral on the app. ARONCZYK: Yes, it has. But instead, what TikTok did was ban Trump's incendiary speeches and hashtags like #stormthecapitol. This has made for a strange faceoff, TikTok banning Trump before Trump can actually ban TikTok. And it's meant that this Georgetown law professor who specializes in tech law - he's been getting a lot of calls. ANUPAM CHANDER: So I felt like I should be making TikToks about the TikTok ban - you know, one of those things where you go like this - you know? - et cetera. ARONCZYK: As we're talking, Anupam Chander is kind of dancing, sort of waving his arms. What are you doing with your hand? What do you mean? Like. . . CHANDER: So, like, you know, you point to different - Jack knows what I'm talking about. CORBETT: This is a classic. And we talked about it. As you're dancing, you point to text that appears over the video. So you're, like, doing a really cool dance move, and then, bam, you point to a text box that reads, there are several lawsuits challenging the ban. You keep on doing a dance, and then you point to another box that reads, the Trump administration banned eight more Chinese apps last week. ARONCZYK: Which is true. CHANDER: Yeah, exactly. CORBETT: Those do well. Those do pretty well. ARONCZYK: Anyway, has TikTok been banned or not? CHANDER: TikTok is still very much allowed in the United States. There are rules that say that TikTok should have been banned by now, but those rules haven't been enforced. The requirement that ByteDance was supposed to have sold itself - the deadline for the sale came and went, and nothing happened. ARONCZYK: Still, the possibility of a ban has not actually gone away. Clearly, the government and Big Tech are on a collision course. And this is important. TikTok is really the first superstar social media out of China. The owner is based in Beijing. And that is what has added a whole new pathology to our already growing anxieties over Facebook and Twitter. CHANDER: The worries are simple - one, that TikTok is engaged in propaganda and censorship, and two, that it's engaged in surveillance. Those are the claims made about TikTok. ARONCZYK: So first, let's talk about the claim about surveillance. The current administration suspects that the Chinese government is using TikTok to spy on its users. There's actually a class-action lawsuit that's underway right now that says TikTok is using facial recognition on minors. And the fear is that because ByteDance is in Beijing, that it's beholden to the Chinese government's laws and that they could be pressured to hand over user data. CORBETT: The next claim is about propaganda and censorship. TikTok has been accused of shutting down people's accounts and censoring people's videos. CHANDER: The Chinese version of the TikTok app, Douyin, is very much a censored app. And it is certainly true that TikTok early on censored material that the Chinese government did not like. CORBETT: So videos about the protests in Hong Kong were censored, or about the Uighurs and other ethnic minority groups in China. One of the most famous was posted in 2019. It's by a 17-year-old in New Jersey who started out by doing a tutorial on how to have longer lashes. (SOUNDBITE OF TIKTOK VIDEO)FEROZA AZIZ: Hi, guys. I want to teach you guys how to get long lashes. So the first thing you need to do is grab your lash curler. Curl your lashes, obviously. Then you're going to put them down and use your phone that you're using right now to search up what's happening in China, how they're getting concentration camps. . . CORBETT: A lot of people have this notion that TikTok is just dancing. It's not. It can be really political. From a TikTok-making perspective, this is like the gold standard. This TikTok belongs in a museum. You start with a simple premise or a trend. And as soon as some people might start to scroll past because they're like, I don't need longer lashes, you turn the whole video on its head, and you start explaining something totally unrelated. Subversions like this inspire so many of our TikToks. Anyway, TikTok didn't like the video as much as I do. The 17-year-old says that TikTok suspended her account because of this video. And she says it wasn't the only time. ARONCZYK: TikTok apologized and reinstated her account. As a user, it's clear to you if your account gets suspended. You get a little message that says, your account was permanently banned due to multiple violations of our community guidelines. But the real mystery is in TikTok's secret sauce - how the algorithm works, how it promotes videos or banishes them. CORBETT: So the way to browse TikTok is on the For You page. This is a feed of videos. Once you start browsing, it'll see what kind of videos you're watching or liking. Based on that, it'll populate your For You page with other videos it thinks you'll like. And it's really good. Like, the secret sauce is not just mayonnaise and ketchup. Like, it's scary good. Like, if you really love beekeeping and you scroll long enough, like, eventually, the algorithm is going to find out and put you on beekeeping TikTok. ARONCZYK: Which is a thing. CORBETT: It is a thing. But TikTok occasionally foregoes the algorithm and manually yoinks (ph) certain videos out of circulation, essentially killing the chance of people seeing them. Videos are still available to your followers, so it will get some kind of engagement, but it certainly won't go viral. On TikTok, this is what users call a shadow ban. You don't know your video has been suppressed. You're in the dark. ARONCZYK: We decided to see if we could get a video shadow banned by TikTok's mysterious algorithm. So we made a video about surveillance. You can go see it on our TikTok account. (SOUNDBITE OF TIKTOK VIDEO)CORBETT: Over the last several years, China's been ramping up its surveillance of the Uighurs. So we posted this yesterday. But already, the comments are like, wow, you can already see they suppressed this video, and I hope they don't take this down. But none of the users know whether the video is being suppressed. The thing is, we don't know what the algorithm is doing with the video either. ARONCZYK: We called TikTok up, and they pointed us to their website for an explanation on how the recommendation system works. It says that a video might not get promoted if it's too shocking or under review or if it's spam content trying to artificially increase traffic. Yes, other social media does this, too. But with TikTok, the ability to promote or banish content is being done by a company with ties to the Chinese government. All of this history is what led the current administration to say - you know what? - we need to force the sale of TikTok to an American company or ban it. CORBETT: But actually, banning a super popular social media app that hundreds of millions of people are using all of the time - more complicated than you might expect. ARONCZYK: That is coming up after the break. (SOUNDBITE OF BRIAN FLORES, ET AL. 'S \"GOSPEL TRUTH\")ARONCZYK: The U. S. isn't the only country that has considered banning TikTok. Pakistan, Japan, Indonesia, Australia - their governments have all debated it, too. But this past summer, one country went for it. CORBETT: The country that had more users than anywhere else in the world - India. Their government said, we are banning TikTok. ARONCZYK: Up until then, TikTok had been really big in India. CORBETT: For a while, I had friends who were getting TikToks from India in their algorithms, stuff like someone carving a carrot into a little, tiny slipper (ph). My favorite was this guy who does the traditional TikTok thing, like lip-syncing and dancing, but he did it underwater. His name was Hydroman. There really was all kinds of stuff - like thousands and thousands of trends and just endless memes. ARONCZYK: When we started to look at what happened in India, I messaged a bunch of journalists who live there, and they said we should call up Snigdha Poonam. She's a journalist, and she's an author. And her beat is youth. SNIGDHA POONAM: I mean, social media is very popular in India. Name any platform, whether it's (ph) Facebook and WhatsApp, India happens to be either the first or the second in terms of how many people use it globally. ARONCZYK: So, yeah, the population is very large, but it's also because data is very cheap, phones are very cheap. So even families who might live in places that don't have, say, indoor plumbing, they might still have TikTok. CORBETT: The app was really accessible. It worked in 15 of the languages spoken there. It was popular in rural areas, cities. There were all these different trends - cricket TikTok, making tea TikTok, grandma TikTok, which my friends are on. But. . . ARONCZYK: What's grandmother TikTok? CORBETT: You know, it's just grandmas hanging out, doing grandma stuff. People who have been left out of the mainstream could become instant celebrities. ARONCZYK: But then, this past June, a fight broke out on the disputed border between India and China. It's near what's called, without irony, the Line of Actual Control. Both sides have soldiers there. Tensions escalated. Twenty Indian soldiers were killed. POONAM: There were some casualties on both sides, but only India confirmed that its soldiers had died. ARONCZYK: Is that incident common? Does that happen at that border - like, skirmishes and people getting killed - regularly? Or was that really unusual? POONAM: That was really unusual. Like, on the India-China border, usually that kind of aggression doesn't happen. ARONCZYK: These two countries have been fighting for decades, but there hasn't been a fatality at that border since, like, 1975. CORBETT: Within two weeks of this, India decided that the response would be an economic one. India banned TikTok plus 58 other Chinese apps. Now that ban includes over 200 Chinese apps. ARONCZYK: It's essentially a new kind of trade war. Instead of banning drones or TVs built in China, which sucks if you're trying to buy a drone or a TV, when you ban an app that people spend, like, three hours a day on - which, of course, I would never do. I don't do that. No. I would never. CORBETT: I mean, in the R&D phase for our TikTok, I did. ARONCZYK: When you ban a popular app, people really notice. It's like someone walked into your house and took your TV. Did people think, oh, this'll never happen? Like, there's no way. POONAM: Yeah. Yeah, yeah. I think that people thought that because it just seems so unreal. This doesn't happen in today's world because here's a thing that, like, 200 million people were using. ARONCZYK: Two hundred million people were using TikTok? POONAM: Yeah. I mean, how could they just ban something like that out of the blue? I'm sounding calm now 'cause it's been so many months. But I was quite shocked, and I kept thinking this was, like, a week's thing or two weeks' thing. Maybe the government will talk, and it'll be back. But it just didn't come back. So I just kept thinking of what's going to happen to all of these people. ARONCZYK: One of these people is a woman named Balpreet Kaur (ph). (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED PERSON #2: (Non-English language spoken). ARONCZYK: Balpreet is 30 years old, and she lives in New Delhi. And she's a dance teacher. So in her videos, you can see her belly dancing sometimes or lip-syncing or sometimes both. CORBETT: It's not just lip-syncing, though. The appeal isn't trying to make it look like you're actually the one who's singing. It's capturing the emotion of the song or the trend with your face or with the video somehow. (SOUNDBITE OF MUSIC)UNIDENTIFIED MUSICAL ARTIST: (Singing in non-English language). CORBETT: Balpreet was really good at this. And she had a cast of characters, often her slightly reluctant-looking husband, who were willing to commit to the bid. ARONCZYK: Are you a TikTok star in India? BALPREET KAUR: I was, yeah. ARONCZYK: Did you have a lot of followers? KAUR: Yeah, I had 400K something, yeah. ARONCZYK: And were you able to make money off of TikTok? KAUR: Yeah, I made lots of money from TikTok, even. ARONCZYK: Balpreet got sponsors. She could sometimes make, like, a thousand rupees per video, which is pretty good. It's about 14 bucks. But there, that's a day or half a day's wages. She didn't quit her teaching job, but a significant piece of her income was coming from her TikTok videos. On the day when it happened, like, did the app disappear off your phone? Or, like, what happened to the app? KAUR: Suddenly, it was closed. I mean, I was very upset. CORBETT: Balpreet says she opened the app, and a message popped up. It said, TikTok is complying with the government's ban. And then that was it. The app didn't work anymore. It was removed from the App Store and Play Store. TikTok gave users a grace period to back up their videos, but Balpreet missed it. Everything she had ever posted was gone. KAUR: I lose all of my videos. I just did not save even in my phone. There was also my memories, my first video, which I made with my husband and I got famous. So even I don't have that video, even, in my phone. CORBETT: One of the truly odd things about trying to ban a social media that's used all over the world - while Balpreet can't see her own videos, the rest of us can. ARONCZYK: You know, I think I can see your videos. KAUR: Really? ARONCZYK: Yeah. I mean, I can try. Like, I have TikTok. Do you want me to see if I can find them? KAUR: Oh, nice. Yeah, please. ARONCZYK: I search for her username, and there she was. CORBETT: It feels very post-apocalyptic. All of India's TikToks stop on June 29, 2020 - no new comments, no new videos. It's a land frozen in time. ARONCZYK: On Balpreet's channel, her last video shows her pregnant. She's waiting for her baby to be born. And so I held up my phone so she could see that final video that she hasn't seen in months. KAUR: Oh, my God (laughter). You know, that was, like, the eighth month. ARONCZYK: And now that pregnant lump is a 6-month-old baby boy. KAUR: Do you want to see? ARONCZYK: Sure. KAUR: (Unintelligible), come here. Here's my husband, and here's my little one. ARONCZYK: The whole family comes into view, and the baby - kind of stealing the show. So cute. KAUR: Say hello. CORBETT: The baby does not, in fact, say hello. ARONCZYK: Two weeks later, Balpreet finally gave up waiting for TikTok to come back. She signed up for this app that's called MX TakaTak, which is very fun to say - MX TakaTak. She has replaced her main sidekick, who was her husband, with a new star, her baby boy. Has there been anything good about the fact that TikTok has been banned or has it all been bad? KAUR: If I talk about India - because I'm Indian, if I talk about India - so this is really good. This is really actually good. It is totally fine because we are not using any - another country app. ARONCZYK: She's working on it, but she's not MX TakaTak famous yet. CORBETT: Now there are dozens of TikTok-like apps filling the gap. And this appears to be the real point of India's ban. ARONCZYK: It's about economic nationalism. India is kind of trying to build its own Internet, one that does not rely so heavily on China. And so here is the big question. Does it make sense to do what India did here in the United States - go ahead, ban TikTok? Anupam, the law professor who specializes in tech law, he says no. CHANDER: The worry is that if you proceed down this route, what you do is you essentially say, you can only have apps that are run by domestic companies that are inside our country. And you've removed the global Internet entirely. You basically kneecap global information flow 'cause every country then says this about every other country. That is not a playbook we should borrow. CORBETT: A ban is extreme, and the U. S. government's case that TikTok is spying and censoring isn't even all that strong if you compare what Facebook or Google knows about you. CHANDER: Versus TikTok, which has a very limited amount of information that you are feeding to it, largely consisting in things that you are publishing to the world. So the nature of the data that TikTok was gathering is so much less worrisome, so much less the stuff of blackmail. And the risks are so highly speculative in this case as to be kind of shocking. ARONCZYK: He says that the government's case against TikTok doesn't actually have a ton of hard evidence. And every time the company gets accused of censoring or surveilling its users, they do respond by changing their policies, updating their community guidelines. They admit guilt and promise to change, which is not unlike YouTube or Twitter. CHANDER: TikTok is a California corporation. It's governed by California privacy law, which is actually fairly robust. It's the same rights that you have against Facebook and Google and Twitter. It's not any less because it's owned by a Chinese company. CORBETT: Anupam says that this doesn't have to be all that complicated a problem. The U. S. is the only country in the Western world that still doesn't have a federal privacy law that protects users' data. That can be fixed. CHANDER: The simplest piece of the puzzle is a federal privacy law - right? - so companies that collect massive amounts of data don't abuse that information - abuse that information by selling it willy-nilly or abuse that information by using it in ways that are antithetical to our interests. This, of course, hurts Chinese companies, which have incredible ambitions, global ambitions. And TikTok is the one Chinese company that has become a kind of global champion. ARONCZYK: Even if it is proven that TikTok is doing some of the things that it's been accused of - it's handing our data over to the Chinese government or using facial recognition or cherry-picking social movements to promote or banish - ultimately, Anupam thinks that the banning of TikTok seems kind of arbitrary. Like, there are no shortage of issues with social media right now, but banning just this one app is not going to solve them. CORBETT: And with the new administration coming in, it seems like I might get to keep being PLANET MONEY TikTok guy after all. I don't have to throw out my green screen yet. (SOUNDBITE OF HENRY PARSLEY SONG, \"EARLY HOURS\")CORBETT: You can email us at planetmoney@npr. org. And for now, we have not been banned from Instagram, Facebook, Twitter or even TikTok. Look at that. We are @planetmoney. ARONCZYK: Special thanks to Vivek Gopal and Maya Wang. This episode was produced by James Sneed with help from Gilly Moon, fact-checked by Irena Hwang (ph). Alex Goldmark is our supervising producer, and Bryant Urstadt edits the show. CORBETT: I'm not the PLANET MONEY intern. I'm Jack Corbett. ARONCZYK: And I'm Amanda Aronczyk. This is NPR. Thanks for listening. SYLVIE DOUGLIS, BYLINE: This is PLANET MONEY from NPR. AMANDA ARONCZYK, HOST:   Can you introduce yourself and tell me what your job is? JACK CORBETT, BYLINE: Yeah. My name's Jack Corbett. My job is PLANET MONEY TikTok guy. I make videos for PLANET MONEY on TikTok. ARONCZYK: Are you our intern? CORBETT: No, I'm not. I'm not. I'm not. I never was the PLANET MONEY intern. I was the music video intern last year. But, no, I'm a production assistant for the video team. ARONCZYK: OK. CORBETT: I answer to no one at PLANET MONEY. ARONCZYK: (Laughter) So bold, but not exactly true. Jack officially works for and is paid out of NPR's video team's budget, not by PLANET MONEY, not by TikTok. But full disclosure - last spring, TikTok approached PLANET MONEY, and they said that they wanted our brand of edutainment on the platform. They gave us a small grant. It was part of their Learn On TikTok initiative. CORBETT: I think the wording is TikTok helps fund some of the videos that PLANET MONEY posts on the platform. But, yeah, they have, like, no - they have no, like, editorial say. They're just like, make something educational. ARONCZYK: And by the way, our boss who handles our TikTok contract - he has recused himself from this episode. He didn't see a script. He didn't approve the angles or the sources - none of it. So this past May, making TikTok videos became Jack's full-time job. My favorite video is the one about the price of coffee. You can see Jack. He's looking maybe a little more shaky than usual. (SOUNDBITE OF TIKTOK VIDEO) CORBETT: Coffee doesn't ask silly questions. Coffee understands. I'm a Hufflepuff. I do weekends, comfy clothes, messy hair, a whole lot of coffee and a whole lot of coffee. ARONCZYK: Because making videos like this one is Jack's job, he was pretty alarmed when last July, President Trump made this announcement. (SOUNDBITE OF ARCHIVED RECORDING) PRESIDENT DONALD TRUMP: We're looking at TikTok. We may be banning TikTok. We may be doing some other things. There are a couple of options. ARONCZYK: President Trump declares a ban on TikTok. CORBETT: At first, I was like, oh, no, this is horrible, just 'cause I love the platform so much. And also, I was just getting the hang of it. ARONCZYK: The stated reason for the ban is national security concerns that the app, which is owned by the Chinese company ByteDance, is essentially a piece of spyware, that it's a source of disinformation, that it suppresses free speech. Then, Trump signs two executive orders that essentially say TikTok has 45 days to sell itself to an American company or get banned. TikTokers prepare for the worst. They post these, like, weepy, what if this is really the end kind of videos. This is one from a guy named Old Time Hockey (ph). He lives in a cabin in the Upper Peninsula. (SOUNDBITE OF TIKTOK VIDEO) OLD TIME HOCKEY: It's been a tough year, eh? They say the hottest fires make the hardest steel. Maybe TikTok does go away. Maybe it doesn't. ARONCZYK: This guy - he's really going to miss TikTok. (SOUNDBITE OF TIKTOK VIDEO) OLD TIME HOCKEY: Where else can a man and his dog living in a cabin in the woods make so many buddies? ARONCZYK: The ban - sad. CORBETT: Like, everyone was doing, like, goodbye posts. They were like, you know, follow my Twitter, follow my Instagram, follow my YouTube channel. But, you know, it just doesn't - it's not the same. It's not the same as TikTok. (SOUNDBITE OF BENSON TAYLOR, ET AL. 'S \"GREETINGS PROGRAMS\") ARONCZYK: Hello, and welcome to PLANET MONEY. I'm Amanda Aronczyk. So originally for this episode, Jack was just going to be, like, my interview subject. But then I realized without Jack, I'm just momsplaining (ph) TikTok to you. So, Jack. CORBETT: Hey. ARONCZYK: How's it going? CORBETT: Good, good. Thanks. ARONCZYK: (Laughter). CORBETT: Today on the show, the U. S. versus TikTok. That's TikTok - one word, no spaces. It's not the Kesha song. ARONCZYK: In this show, we are not going to talk about Kesha, but we will look at why the ban was threatened, where it stands now. And then we will visit a country where TikTok has been banned for months. (SOUNDBITE OF BENSON TAYLOR, ET AL. 'S \"GREETINGS PROGRAMS\") ARONCZYK: This past week, there has been what you might call a banning bonanza. Twitter banned President Trump. So did Facebook and Instagram and Snapchat. And TikTok kind of banned Trump. He doesn't actually have a TikTok account. It was like the one major social media platform that he wasn't dominating. CORBETT: His dancing has gone pretty viral on the app. ARONCZYK: Yes, it has. But instead, what TikTok did was ban Trump's incendiary speeches and hashtags like #stormthecapitol. This has made for a strange faceoff, TikTok banning Trump before Trump can actually ban TikTok. And it's meant that this Georgetown law professor who specializes in tech law - he's been getting a lot of calls. ANUPAM CHANDER: So I felt like I should be making TikToks about the TikTok ban - you know, one of those things where you go like this - you know? - et cetera. ARONCZYK: As we're talking, Anupam Chander is kind of dancing, sort of waving his arms. What are you doing with your hand? What do you mean? Like. . . CHANDER: So, like, you know, you point to different - Jack knows what I'm talking about. CORBETT: This is a classic. And we talked about it. As you're dancing, you point to text that appears over the video. So you're, like, doing a really cool dance move, and then, bam, you point to a text box that reads, there are several lawsuits challenging the ban. You keep on doing a dance, and then you point to another box that reads, the Trump administration banned eight more Chinese apps last week. ARONCZYK: Which is true. CHANDER: Yeah, exactly. CORBETT: Those do well. Those do pretty well. ARONCZYK: Anyway, has TikTok been banned or not? CHANDER: TikTok is still very much allowed in the United States. There are rules that say that TikTok should have been banned by now, but those rules haven't been enforced. The requirement that ByteDance was supposed to have sold itself - the deadline for the sale came and went, and nothing happened. ARONCZYK: Still, the possibility of a ban has not actually gone away. Clearly, the government and Big Tech are on a collision course. And this is important. TikTok is really the first superstar social media out of China. The owner is based in Beijing. And that is what has added a whole new pathology to our already growing anxieties over Facebook and Twitter. CHANDER: The worries are simple - one, that TikTok is engaged in propaganda and censorship, and two, that it's engaged in surveillance. Those are the claims made about TikTok. ARONCZYK: So first, let's talk about the claim about surveillance. The current administration suspects that the Chinese government is using TikTok to spy on its users. There's actually a class-action lawsuit that's underway right now that says TikTok is using facial recognition on minors. And the fear is that because ByteDance is in Beijing, that it's beholden to the Chinese government's laws and that they could be pressured to hand over user data. CORBETT: The next claim is about propaganda and censorship. TikTok has been accused of shutting down people's accounts and censoring people's videos. CHANDER: The Chinese version of the TikTok app, Douyin, is very much a censored app. And it is certainly true that TikTok early on censored material that the Chinese government did not like. CORBETT: So videos about the protests in Hong Kong were censored, or about the Uighurs and other ethnic minority groups in China. One of the most famous was posted in 2019. It's by a 17-year-old in New Jersey who started out by doing a tutorial on how to have longer lashes. (SOUNDBITE OF TIKTOK VIDEO) FEROZA AZIZ: Hi, guys. I want to teach you guys how to get long lashes. So the first thing you need to do is grab your lash curler. Curl your lashes, obviously. Then you're going to put them down and use your phone that you're using right now to search up what's happening in China, how they're getting concentration camps. . . CORBETT: A lot of people have this notion that TikTok is just dancing. It's not. It can be really political. From a TikTok-making perspective, this is like the gold standard. This TikTok belongs in a museum. You start with a simple premise or a trend. And as soon as some people might start to scroll past because they're like, I don't need longer lashes, you turn the whole video on its head, and you start explaining something totally unrelated. Subversions like this inspire so many of our TikToks. Anyway, TikTok didn't like the video as much as I do. The 17-year-old says that TikTok suspended her account because of this video. And she says it wasn't the only time. ARONCZYK: TikTok apologized and reinstated her account. As a user, it's clear to you if your account gets suspended. You get a little message that says, your account was permanently banned due to multiple violations of our community guidelines. But the real mystery is in TikTok's secret sauce - how the algorithm works, how it promotes videos or banishes them. CORBETT: So the way to browse TikTok is on the For You page. This is a feed of videos. Once you start browsing, it'll see what kind of videos you're watching or liking. Based on that, it'll populate your For You page with other videos it thinks you'll like. And it's really good. Like, the secret sauce is not just mayonnaise and ketchup. Like, it's scary good. Like, if you really love beekeeping and you scroll long enough, like, eventually, the algorithm is going to find out and put you on beekeeping TikTok. ARONCZYK: Which is a thing. CORBETT: It is a thing. But TikTok occasionally foregoes the algorithm and manually yoinks (ph) certain videos out of circulation, essentially killing the chance of people seeing them. Videos are still available to your followers, so it will get some kind of engagement, but it certainly won't go viral. On TikTok, this is what users call a shadow ban. You don't know your video has been suppressed. You're in the dark. ARONCZYK: We decided to see if we could get a video shadow banned by TikTok's mysterious algorithm. So we made a video about surveillance. You can go see it on our TikTok account. (SOUNDBITE OF TIKTOK VIDEO) CORBETT: Over the last several years, China's been ramping up its surveillance of the Uighurs. So we posted this yesterday. But already, the comments are like, wow, you can already see they suppressed this video, and I hope they don't take this down. But none of the users know whether the video is being suppressed. The thing is, we don't know what the algorithm is doing with the video either. ARONCZYK: We called TikTok up, and they pointed us to their website for an explanation on how the recommendation system works. It says that a video might not get promoted if it's too shocking or under review or if it's spam content trying to artificially increase traffic. Yes, other social media does this, too. But with TikTok, the ability to promote or banish content is being done by a company with ties to the Chinese government. All of this history is what led the current administration to say - you know what? - we need to force the sale of TikTok to an American company or ban it. CORBETT: But actually, banning a super popular social media app that hundreds of millions of people are using all of the time - more complicated than you might expect. ARONCZYK: That is coming up after the break. (SOUNDBITE OF BRIAN FLORES, ET AL. 'S \"GOSPEL TRUTH\") ARONCZYK: The U. S. isn't the only country that has considered banning TikTok. Pakistan, Japan, Indonesia, Australia - their governments have all debated it, too. But this past summer, one country went for it. CORBETT: The country that had more users than anywhere else in the world - India. Their government said, we are banning TikTok. ARONCZYK: Up until then, TikTok had been really big in India. CORBETT: For a while, I had friends who were getting TikToks from India in their algorithms, stuff like someone carving a carrot into a little, tiny slipper (ph). My favorite was this guy who does the traditional TikTok thing, like lip-syncing and dancing, but he did it underwater. His name was Hydroman. There really was all kinds of stuff - like thousands and thousands of trends and just endless memes. ARONCZYK: When we started to look at what happened in India, I messaged a bunch of journalists who live there, and they said we should call up Snigdha Poonam. She's a journalist, and she's an author. And her beat is youth. SNIGDHA POONAM: I mean, social media is very popular in India. Name any platform, whether it's (ph) Facebook and WhatsApp, India happens to be either the first or the second in terms of how many people use it globally. ARONCZYK: So, yeah, the population is very large, but it's also because data is very cheap, phones are very cheap. So even families who might live in places that don't have, say, indoor plumbing, they might still have TikTok. CORBETT: The app was really accessible. It worked in 15 of the languages spoken there. It was popular in rural areas, cities. There were all these different trends - cricket TikTok, making tea TikTok, grandma TikTok, which my friends are on. But. . . ARONCZYK: What's grandmother TikTok? CORBETT: You know, it's just grandmas hanging out, doing grandma stuff. People who have been left out of the mainstream could become instant celebrities. ARONCZYK: But then, this past June, a fight broke out on the disputed border between India and China. It's near what's called, without irony, the Line of Actual Control. Both sides have soldiers there. Tensions escalated. Twenty Indian soldiers were killed. POONAM: There were some casualties on both sides, but only India confirmed that its soldiers had died. ARONCZYK: Is that incident common? Does that happen at that border - like, skirmishes and people getting killed - regularly? Or was that really unusual? POONAM: That was really unusual. Like, on the India-China border, usually that kind of aggression doesn't happen. ARONCZYK: These two countries have been fighting for decades, but there hasn't been a fatality at that border since, like, 1975. CORBETT: Within two weeks of this, India decided that the response would be an economic one. India banned TikTok plus 58 other Chinese apps. Now that ban includes over 200 Chinese apps. ARONCZYK: It's essentially a new kind of trade war. Instead of banning drones or TVs built in China, which sucks if you're trying to buy a drone or a TV, when you ban an app that people spend, like, three hours a day on - which, of course, I would never do. I don't do that. No. I would never. CORBETT: I mean, in the R&D phase for our TikTok, I did. ARONCZYK: When you ban a popular app, people really notice. It's like someone walked into your house and took your TV. Did people think, oh, this'll never happen? Like, there's no way. POONAM: Yeah. Yeah, yeah. I think that people thought that because it just seems so unreal. This doesn't happen in today's world because here's a thing that, like, 200 million people were using. ARONCZYK: Two hundred million people were using TikTok? POONAM: Yeah. I mean, how could they just ban something like that out of the blue? I'm sounding calm now 'cause it's been so many months. But I was quite shocked, and I kept thinking this was, like, a week's thing or two weeks' thing. Maybe the government will talk, and it'll be back. But it just didn't come back. So I just kept thinking of what's going to happen to all of these people. ARONCZYK: One of these people is a woman named Balpreet Kaur (ph). (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED PERSON #2: (Non-English language spoken). ARONCZYK: Balpreet is 30 years old, and she lives in New Delhi. And she's a dance teacher. So in her videos, you can see her belly dancing sometimes or lip-syncing or sometimes both. CORBETT: It's not just lip-syncing, though. The appeal isn't trying to make it look like you're actually the one who's singing. It's capturing the emotion of the song or the trend with your face or with the video somehow. (SOUNDBITE OF MUSIC) UNIDENTIFIED MUSICAL ARTIST: (Singing in non-English language). CORBETT: Balpreet was really good at this. And she had a cast of characters, often her slightly reluctant-looking husband, who were willing to commit to the bid. ARONCZYK: Are you a TikTok star in India? BALPREET KAUR: I was, yeah. ARONCZYK: Did you have a lot of followers? KAUR: Yeah, I had 400K something, yeah. ARONCZYK: And were you able to make money off of TikTok? KAUR: Yeah, I made lots of money from TikTok, even. ARONCZYK: Balpreet got sponsors. She could sometimes make, like, a thousand rupees per video, which is pretty good. It's about 14 bucks. But there, that's a day or half a day's wages. She didn't quit her teaching job, but a significant piece of her income was coming from her TikTok videos. On the day when it happened, like, did the app disappear off your phone? Or, like, what happened to the app? KAUR: Suddenly, it was closed. I mean, I was very upset. CORBETT: Balpreet says she opened the app, and a message popped up. It said, TikTok is complying with the government's ban. And then that was it. The app didn't work anymore. It was removed from the App Store and Play Store. TikTok gave users a grace period to back up their videos, but Balpreet missed it. Everything she had ever posted was gone. KAUR: I lose all of my videos. I just did not save even in my phone. There was also my memories, my first video, which I made with my husband and I got famous. So even I don't have that video, even, in my phone. CORBETT: One of the truly odd things about trying to ban a social media that's used all over the world - while Balpreet can't see her own videos, the rest of us can. ARONCZYK: You know, I think I can see your videos. KAUR: Really? ARONCZYK: Yeah. I mean, I can try. Like, I have TikTok. Do you want me to see if I can find them? KAUR: Oh, nice. Yeah, please. ARONCZYK: I search for her username, and there she was. CORBETT: It feels very post-apocalyptic. All of India's TikToks stop on June 29, 2020 - no new comments, no new videos. It's a land frozen in time. ARONCZYK: On Balpreet's channel, her last video shows her pregnant. She's waiting for her baby to be born. And so I held up my phone so she could see that final video that she hasn't seen in months. KAUR: Oh, my God (laughter). You know, that was, like, the eighth month. ARONCZYK: And now that pregnant lump is a 6-month-old baby boy. KAUR: Do you want to see? ARONCZYK: Sure. KAUR: (Unintelligible), come here. Here's my husband, and here's my little one. ARONCZYK: The whole family comes into view, and the baby - kind of stealing the show. So cute. KAUR: Say hello. CORBETT: The baby does not, in fact, say hello. ARONCZYK: Two weeks later, Balpreet finally gave up waiting for TikTok to come back. She signed up for this app that's called MX TakaTak, which is very fun to say - MX TakaTak. She has replaced her main sidekick, who was her husband, with a new star, her baby boy. Has there been anything good about the fact that TikTok has been banned or has it all been bad? KAUR: If I talk about India - because I'm Indian, if I talk about India - so this is really good. This is really actually good. It is totally fine because we are not using any - another country app. ARONCZYK: She's working on it, but she's not MX TakaTak famous yet. CORBETT: Now there are dozens of TikTok-like apps filling the gap. And this appears to be the real point of India's ban. ARONCZYK: It's about economic nationalism. India is kind of trying to build its own Internet, one that does not rely so heavily on China. And so here is the big question. Does it make sense to do what India did here in the United States - go ahead, ban TikTok? Anupam, the law professor who specializes in tech law, he says no. CHANDER: The worry is that if you proceed down this route, what you do is you essentially say, you can only have apps that are run by domestic companies that are inside our country. And you've removed the global Internet entirely. You basically kneecap global information flow 'cause every country then says this about every other country. That is not a playbook we should borrow. CORBETT: A ban is extreme, and the U. S. government's case that TikTok is spying and censoring isn't even all that strong if you compare what Facebook or Google knows about you. CHANDER: Versus TikTok, which has a very limited amount of information that you are feeding to it, largely consisting in things that you are publishing to the world. So the nature of the data that TikTok was gathering is so much less worrisome, so much less the stuff of blackmail. And the risks are so highly speculative in this case as to be kind of shocking. ARONCZYK: He says that the government's case against TikTok doesn't actually have a ton of hard evidence. And every time the company gets accused of censoring or surveilling its users, they do respond by changing their policies, updating their community guidelines. They admit guilt and promise to change, which is not unlike YouTube or Twitter. CHANDER: TikTok is a California corporation. It's governed by California privacy law, which is actually fairly robust. It's the same rights that you have against Facebook and Google and Twitter. It's not any less because it's owned by a Chinese company. CORBETT: Anupam says that this doesn't have to be all that complicated a problem. The U. S. is the only country in the Western world that still doesn't have a federal privacy law that protects users' data. That can be fixed. CHANDER: The simplest piece of the puzzle is a federal privacy law - right? - so companies that collect massive amounts of data don't abuse that information - abuse that information by selling it willy-nilly or abuse that information by using it in ways that are antithetical to our interests. This, of course, hurts Chinese companies, which have incredible ambitions, global ambitions. And TikTok is the one Chinese company that has become a kind of global champion. ARONCZYK: Even if it is proven that TikTok is doing some of the things that it's been accused of - it's handing our data over to the Chinese government or using facial recognition or cherry-picking social movements to promote or banish - ultimately, Anupam thinks that the banning of TikTok seems kind of arbitrary. Like, there are no shortage of issues with social media right now, but banning just this one app is not going to solve them. CORBETT: And with the new administration coming in, it seems like I might get to keep being PLANET MONEY TikTok guy after all. I don't have to throw out my green screen yet. (SOUNDBITE OF HENRY PARSLEY SONG, \"EARLY HOURS\") CORBETT: You can email us at planetmoney@npr. org. And for now, we have not been banned from Instagram, Facebook, Twitter or even TikTok. Look at that. We are @planetmoney. ARONCZYK: Special thanks to Vivek Gopal and Maya Wang. This episode was produced by James Sneed with help from Gilly Moon, fact-checked by Irena Hwang (ph). Alex Goldmark is our supervising producer, and Bryant Urstadt edits the show. CORBETT: I'm not the PLANET MONEY intern. I'm Jack Corbett. ARONCZYK: And I'm Amanda Aronczyk. This is NPR. Thanks for listening.", "section": "Nervous TikTok", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-01-13-956315555": {"title": "British Tech Company Unveils Robotic Kitchen Assistant : NPR", "url": "https://www.npr.org/2021/01/13/956315555/british-tech-company-unveils-robotic-kitchen-assistant", "author": "No author found", "published_date": "2021-01-13", "content": "TONYA MOSLEY, HOST:  Good morning. I'm Tonya Mosley. (SOUNDBITE OF TV SHOW, \"THE JETSONS\")JEAN VANDER PYL: (As Rosie) Come and get it. MOSLEY: Remember Rosie from \"The Jetsons\"? She was the robot maid who cooked and cleaned for the family. Well, thanks to a British tech company, we're one step closer to Rosie. Moley Robotics unveiled a kitchen robot that can cook 5,000 recipes from scratch. The robot has arms, hands, cameras and sensors that enable it to prepare full meals. The best part - it even does the dishes. It's MORNING EDITION. TONYA MOSLEY, HOST:   Good morning. I'm Tonya Mosley. (SOUNDBITE OF TV SHOW, \"THE JETSONS\") JEAN VANDER PYL: (As Rosie) Come and get it. MOSLEY: Remember Rosie from \"The Jetsons\"? She was the robot maid who cooked and cleaned for the family. Well, thanks to a British tech company, we're one step closer to Rosie. Moley Robotics unveiled a kitchen robot that can cook 5,000 recipes from scratch. The robot has arms, hands, cameras and sensors that enable it to prepare full meals. The best part - it even does the dishes. It's MORNING EDITION.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-01-13-956315576": {"title": "Twitch Streamers Go To Dr. K For Help With Mental Health Issues : NPR", "url": "https://www.npr.org/2021/01/13/956315576/psychiatrist-criticized-for-addressing-mental-health-issues-on-twitch", "author": "No author found", "published_date": "2021-01-13", "content": "RACHEL MARTIN, HOST:  All right. So there's a long history of giving personal advice using the mass media. Dr. Joyce Brothers was a psychologist on TV starting in the 1950s. She opened the door for others, Dr. Ruth, Dr. Phil, Dr. Drew. And now, on the livestreaming platform Twitch, there's Dr. K. NPR's Andrew Limbong looks at how Dr. K addresses mental health for an online community. Just a warning, this piece addresses mental health issues, including suicide. ANDREW LIMBONG, BYLINE: Dr. K is on Twitch talking to a streamer who goes by Hafu. (SOUNDBITE OF ARCHIVED RECORDING)HAFU: My entire gaming career, I've always had people tell me I don't deserve it. And. . . LIMBONG: She's talking about insecurities she's faced being a woman in the male-dominated space of video games and then feeling bad for feeling insecure. Dr. K offers this. (SOUNDBITE OF ARCHIVED RECORDING)ALOK KANOJIA: So I think that what you have is this ball of undigested emotion. LIMBONG: Dr. K says emotions and hurt from Hafu's past feed into how she reacts to things today. (SOUNDBITE OF ARCHIVED RECORDING)KANOJIA: And what I'm telling you is that it's in my experience - and I feel pretty confident about this - you can digest that emotional energy. And once that emotional energy has been digested, the insecurity is gone. LIMBONG: Unprocessed emotions are a common theme in the HealthyGamer_GG Twitch channel, where Dr. K will talk to guests in front of his more than 400,000 followers and ask them about their mental health. Dr. K is Dr. Alok Kanojia, a Harvard-trained, licensed, practicing psychiatrist specializing in addiction. But he thinks the mental health care system isn't equipped to handle a glut of new challenges, apps being designed to keep us scrolling, games built to never end, trolling, burnout. On his stream, Kanojia encourages listening, letting yourself be vulnerable and cry. And he guides people through meditation techniques. (SOUNDBITE OF ARCHIVED RECORDING)KANOJIA: So close your eyes. And I want you to feel the space between your hands. LIMBONG: HealthyGamer was co-founded by Kanojia and his wife Kruti years before their Twitch stream started. As an undergrad, Kanojia played a lot of video games - Starcraft, Diablo II, Warcraft III. And he told me it got to be too much. KANOJIA: And so the more overwhelmed I would feel, the more I'd play video games. And the more I would play video games, the more overwhelmed I would feel. And it turned into a vicious cycle. LIMBONG: He found his way out of the cycle after studying meditation and yoga in India. A few years later, Kanojia was training to be a psychiatrist and asking teachers and mentors about gaming addiction and how to solve it. Nobody had the answers. So he asked his gaming peers about their mental health and found a few common threads. KANOJIA: Challenges around social anxiety. They have challenges around confidence, lacking purpose or meaning. LIMBONG: He talked to groups of them informally, teaching them about meditation and mental health care. This grew into what HealthyGamer is now, not just the Twitch stream. They also offer a program where you can talk to a trained peer counselor. Twitch actually partnered with HealthyGamer to offer the peer counseling to some of its biggest gamers, like Addie Nicole Amick. She sings for the band Halocene, which has been on Twitch for years playing songs, interacting with fans. (SOUNDBITE OF SONG, \"LET IT RAIN\")HALOCENE: (Singing) Not sure why I feel this way. But I'm going to let it rain. LIMBONG: Being on Twitch is the thing that provides her income. But having to be on all the time in front of thousands of people takes its toll. She says HealthyGamer demystified mental health and therapy for her. ADDIE NICOLE AMICK: This is for people that just are struggling with everyday stuff. And it's not that scary. It's not that weird. LIMBONG: Dr. K is careful to say that his streams on Twitch aren't therapy. (SOUNDBITE OF ARCHIVED RECORDING)KANOJIA: Just a reminder that everything we talk about on stream is for educational purposes only. LIMBONG: And participants give written consent before they appear. But being a licensed psychiatrist and having talks that look a lot like therapy on Twitch puts him in a hazy ethical position. Here's Rachel Kowert, a psychologist and research director for Take This, a mental health nonprofit serving the gaming community. RACHEL KOWERT: For me, the line is that mental health advocates do not generally provide direct recommendations or opinions about individual cases, whereas mental health professionals do. LIMBONG: And sometimes, it's unclear which role Kanojia's playing. For instance, here's an exchange from 2019 with popular e-sports player Byron Bernstein, known as Reckful. Bernstein tells Dr. K he'd been diagnosed with bipolar disorder and depression. (SOUNDBITE OF ARCHIVED RECORDING)KANOJIA: You may have clinical depression. But I think what you're describing is not clinical depression. LIMBONG: For Kowert and other critics, this stream crossed the line from advocate to professional. Kanojia told me he chose his words very carefully here to not contradict from Bernstein's previous diagnosis. Last summer, sadly, Bernstein took his own life. After Dr. K heard the news, he went on stream. (SOUNDBITE OF ARCHIVED RECORDING)KANOJIA: And I can do a lot, guys. I really can. And I tried with Reckful, I really did. LIMBONG: Then he asked his audience to help him and each other. (SOUNDBITE OF ARCHIVED RECORDING)KANOJIA: You be vulnerable. You share. Don't worry alone. Remember that your struggles are a multiplayer game, too. If you want to help someone else, start by asking for their help. LIMBONG: Because, he said, he couldn't do it alone. Andrew Limbong, NPR News. (SOUNDBITE OF LIAM THOMAS' \"BITTER FEELING\")MARTIN: If you or someone you know is having suicidal thoughts, reach out for help. The National Suicide Prevention Lifeline is open 24 hours a day, 800-273-8255. (SOUNDBITE OF LIAM THOMAS' \"BITTER FEELING\") RACHEL MARTIN, HOST:   All right. So there's a long history of giving personal advice using the mass media. Dr. Joyce Brothers was a psychologist on TV starting in the 1950s. She opened the door for others, Dr. Ruth, Dr. Phil, Dr. Drew. And now, on the livestreaming platform Twitch, there's Dr. K. NPR's Andrew Limbong looks at how Dr. K addresses mental health for an online community. Just a warning, this piece addresses mental health issues, including suicide. ANDREW LIMBONG, BYLINE: Dr. K is on Twitch talking to a streamer who goes by Hafu. (SOUNDBITE OF ARCHIVED RECORDING) HAFU: My entire gaming career, I've always had people tell me I don't deserve it. And. . . LIMBONG: She's talking about insecurities she's faced being a woman in the male-dominated space of video games and then feeling bad for feeling insecure. Dr. K offers this. (SOUNDBITE OF ARCHIVED RECORDING) ALOK KANOJIA: So I think that what you have is this ball of undigested emotion. LIMBONG: Dr. K says emotions and hurt from Hafu's past feed into how she reacts to things today. (SOUNDBITE OF ARCHIVED RECORDING) KANOJIA: And what I'm telling you is that it's in my experience - and I feel pretty confident about this - you can digest that emotional energy. And once that emotional energy has been digested, the insecurity is gone. LIMBONG: Unprocessed emotions are a common theme in the HealthyGamer_GG Twitch channel, where Dr. K will talk to guests in front of his more than 400,000 followers and ask them about their mental health. Dr. K is Dr. Alok Kanojia, a Harvard-trained, licensed, practicing psychiatrist specializing in addiction. But he thinks the mental health care system isn't equipped to handle a glut of new challenges, apps being designed to keep us scrolling, games built to never end, trolling, burnout. On his stream, Kanojia encourages listening, letting yourself be vulnerable and cry. And he guides people through meditation techniques. (SOUNDBITE OF ARCHIVED RECORDING) KANOJIA: So close your eyes. And I want you to feel the space between your hands. LIMBONG: HealthyGamer was co-founded by Kanojia and his wife Kruti years before their Twitch stream started. As an undergrad, Kanojia played a lot of video games - Starcraft, Diablo II, Warcraft III. And he told me it got to be too much. KANOJIA: And so the more overwhelmed I would feel, the more I'd play video games. And the more I would play video games, the more overwhelmed I would feel. And it turned into a vicious cycle. LIMBONG: He found his way out of the cycle after studying meditation and yoga in India. A few years later, Kanojia was training to be a psychiatrist and asking teachers and mentors about gaming addiction and how to solve it. Nobody had the answers. So he asked his gaming peers about their mental health and found a few common threads. KANOJIA: Challenges around social anxiety. They have challenges around confidence, lacking purpose or meaning. LIMBONG: He talked to groups of them informally, teaching them about meditation and mental health care. This grew into what HealthyGamer is now, not just the Twitch stream. They also offer a program where you can talk to a trained peer counselor. Twitch actually partnered with HealthyGamer to offer the peer counseling to some of its biggest gamers, like Addie Nicole Amick. She sings for the band Halocene, which has been on Twitch for years playing songs, interacting with fans. (SOUNDBITE OF SONG, \"LET IT RAIN\") HALOCENE: (Singing) Not sure why I feel this way. But I'm going to let it rain. LIMBONG: Being on Twitch is the thing that provides her income. But having to be on all the time in front of thousands of people takes its toll. She says HealthyGamer demystified mental health and therapy for her. ADDIE NICOLE AMICK: This is for people that just are struggling with everyday stuff. And it's not that scary. It's not that weird. LIMBONG: Dr. K is careful to say that his streams on Twitch aren't therapy. (SOUNDBITE OF ARCHIVED RECORDING) KANOJIA: Just a reminder that everything we talk about on stream is for educational purposes only. LIMBONG: And participants give written consent before they appear. But being a licensed psychiatrist and having talks that look a lot like therapy on Twitch puts him in a hazy ethical position. Here's Rachel Kowert, a psychologist and research director for Take This, a mental health nonprofit serving the gaming community. RACHEL KOWERT: For me, the line is that mental health advocates do not generally provide direct recommendations or opinions about individual cases, whereas mental health professionals do. LIMBONG: And sometimes, it's unclear which role Kanojia's playing. For instance, here's an exchange from 2019 with popular e-sports player Byron Bernstein, known as Reckful. Bernstein tells Dr. K he'd been diagnosed with bipolar disorder and depression. (SOUNDBITE OF ARCHIVED RECORDING) KANOJIA: You may have clinical depression. But I think what you're describing is not clinical depression. LIMBONG: For Kowert and other critics, this stream crossed the line from advocate to professional. Kanojia told me he chose his words very carefully here to not contradict from Bernstein's previous diagnosis. Last summer, sadly, Bernstein took his own life. After Dr. K heard the news, he went on stream. (SOUNDBITE OF ARCHIVED RECORDING) KANOJIA: And I can do a lot, guys. I really can. And I tried with Reckful, I really did. LIMBONG: Then he asked his audience to help him and each other. (SOUNDBITE OF ARCHIVED RECORDING) KANOJIA: You be vulnerable. You share. Don't worry alone. Remember that your struggles are a multiplayer game, too. If you want to help someone else, start by asking for their help. LIMBONG: Because, he said, he couldn't do it alone. Andrew Limbong, NPR News. (SOUNDBITE OF LIAM THOMAS' \"BITTER FEELING\") MARTIN: If you or someone you know is having suicidal thoughts, reach out for help. The National Suicide Prevention Lifeline is open 24 hours a day, 800-273-8255. (SOUNDBITE OF LIAM THOMAS' \"BITTER FEELING\")", "section": "Mental Health", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-01-14-956468497": {"title": "3 Point And Click Puzzle Games That Are Great For Kids : NPR", "url": "https://www.npr.org/2021/01/14/956468497/for-the-kid-in-your-life-3-video-games-that-play-like-storybooks", "author": "No author found", "published_date": "2021-01-14", "content": "", "section": "Gaming", "disclaimer": ""}, "2021-01-14-956664893": {"title": "Twitter's Jack Dorsey Worries About Precedent Of Banning Trump : NPR", "url": "https://www.npr.org/2021/01/14/956664893/twitter-ceo-tweets-about-banning-trump-from-site", "author": "No author found", "published_date": "2021-01-14", "content": "", "section": "Technology", "disclaimer": ""}, "2021-01-15-957234803": {"title": "Parler Executive Responds To Amazon Cutoff And Defends Approach To Moderation : NPR", "url": "https://www.npr.org/2021/01/15/957234803/parler-executive-responds-to-amazon-cutoff-and-defends-approach-to-moderation", "author": "No author found", "published_date": "2021-01-15", "content": "", "section": "Technology", "disclaimer": ""}, "2021-01-15-948819324": {"title": "Amazon Warehouse Workers To Decide Whether To Form Company's 1st U.S. Union : NPR", "url": "https://www.npr.org/2021/01/15/948819324/amazon-warehouse-workers-to-decide-whether-to-form-companys-first-u-s-union", "author": "No author found", "published_date": "2021-01-15", "content": "", "section": "Business", "disclaimer": ""}, "2021-01-15-956461780": {"title": "Retail Sales Fall For 3rd Straight Month : NPR", "url": "https://www.npr.org/2021/01/15/956461780/retail-spending-dips-for-3rd-straight-month-as-infections-surge", "author": "No author found", "published_date": "2021-01-15", "content": "", "section": "Business", "disclaimer": ""}, "2021-01-15-957141101": {"title": "Parler Insists It Would Not Knowingly Tolerate Criminal Activity On Its Site : NPR", "url": "https://www.npr.org/2021/01/15/957141101/parler-insists-it-would-not-knowingly-tolerate-criminal-activity-on-its-site", "author": "No author found", "published_date": "2021-01-15", "content": "STEVE INSKEEP, HOST:  Parler is still seeking a way back onto the Internet. The company promoted itself as a free-speech site. It attracted a mixture of Republicans, self-identified conservatives, extremists and racists who found Twitter and Facebook too restrictive. Numerous media reports revealed Parler users explicitly calling for violence and then posting videos as they participated in last week's attack on the Capitol. Amazon and other services then cut ties with Parler, which sued. So what is or was the company's responsibility? Parler Chief Policy Officer Amy Peikoff insists free expression was the goal. AMY PEIKOFF: We are trying to allow for maximum freedom of expression consistent with the law. INSKEEP: Parler also promised privacy, saying it would not analyze users' posts. Noted conservative figures were among the company's investors. And when President Trump was knocked off Twitter last week, some of his supporters called on people to migrate to Parler. But that site itself was on the way to being shut down, accused of failing to moderate extremist content. Peikoff maintains that all social media companies were flooded with calls to violence in recent months. What responsibility, if any, does Parler take for the content on your site? PEIKOFF: Our community guidelines were clear that we would not knowingly tolerate criminal activity on the site. We were trying to avoid using a system in which we would scan every piece of content with an automated algorithm. And so what we had was a community jury system in which any person on Parler could, of course, report a piece of content. We had a reporting mechanism. The report goes into a jury portal. And we had a, you know, bunch of volunteer jurors who were adjudicating these cases. And then the verdicts would come down, and the content would get removed as appropriate. INSKEEP: We should be frank that a lot of people migrated to Parler because they felt they could not lie as freely as they wanted to on the other social media platforms. What do you think about that? PEIKOFF: I wouldn't put it that way. I wouldn't put it that way. Not because they said they want to lie. Now, maybe there are some people. Of course, we've had some people come over who were bad actors and then would just tell all kinds of lies and everything else. I think everybody's got that. But people came over - some of them, not all of them - but some of them came over because they thought that they were being treated disproportionately unfairly on other sites and then, yeah, did come over. INSKEEP: Do you take as a company any responsibility for not just calls for violence but just obvious inciting lies about a stolen election? PEIKOFF: No. You know, I don't think that lies in and of themselves are inciting, right? So within a certain context, you could say that certain lies are. We could talk about, for example, whether that one speech that President Trump gave while the events at the Capitol were still going on and, you know, whereas he ended the speech with, go home in peace, but a lot of us found it not very convincing, given all of the preamble at the beginning. You could say, OK, in that context, he's telling certain lies and that that could be seen as a further incitement, given the ongoing activities on the ground at the day. So I see what you're getting at. But in terms of just lies themselves - and can you say that lies themselves are inciting the real world? No. When you're dealing with misinformation, we think the best anecdote is more information. INSKEEP: In Amazon's response to your company's lawsuit, they quote a number of posts on Parler. And I'm reluctant to quote them here, for - I just don't care to spread the messages. But they are obvious lies about a stolen election. There are specific calls to violence, calls for a civil war starting on Inauguration Day, urging people to form militias, urging people to, quote, \"shoot the police,\" urging people to hang specific public officials. This is just a partial list. When you read that list and know that it came across to people on your company, what do you think about? PEIKOFF: I mean, I don't want it there, obviously. But again, the question is, what mechanism do you use to detect and then remove that content? And the model that we had, as I said, as time went on through November and into December, when we started making these changes, we realized that we need to do more. And we were making those changes, and we were in discussions up with Amazon. You know, they dropped this on us on Friday afternoon. And we were telling them what we were doing and that we were willing to do more. We were starting, even, to program a bit of AI to figure out how we could use AI consistent with our mission over the weekend. And we had started tagging some content that way. So we're definitely amenable to this. Nobody wants us on their platform. There is plenty of this content. Or at least there was on Facebook and Twitter, as well. All of them, as - you know, and I've heard from ex-policy people from other platforms saying that the challenges are everywhere. Even when you do use AI, it's not going to be 100% perfect. No, we don't like to see it. It's - it expressly violates our guidelines. And then the challenge is how best effectively to remove it and to make sure that our platform is designed not to encourage the sorts of sentiments that would lead to that type of content being posted in the first place. INSKEEP: Now, in our conversation, Amy Peikoff maintained that the Capitol attackers used other sources of disinformation, too. And that is true. NPR investigated the case of Ashli Babbitt, an attacker who was killed in the Capitol. Her social media feed showed that Babbitt gathered false claims from Fox News TV personalities and guests and repeated them on Twitter in the months before she went to her death. Even after Babbitt was killed, most Republicans in Congress voted, against all the evidence, to object to a Democratic election, following the lead of the defeated president. Whether Parler survives or not, disinformation is widespread. (SOUNDBITE OF PHELIAN'S \"INTRO\") STEVE INSKEEP, HOST:   Parler is still seeking a way back onto the Internet. The company promoted itself as a free-speech site. It attracted a mixture of Republicans, self-identified conservatives, extremists and racists who found Twitter and Facebook too restrictive. Numerous media reports revealed Parler users explicitly calling for violence and then posting videos as they participated in last week's attack on the Capitol. Amazon and other services then cut ties with Parler, which sued. So what is or was the company's responsibility? Parler Chief Policy Officer Amy Peikoff insists free expression was the goal. AMY PEIKOFF: We are trying to allow for maximum freedom of expression consistent with the law. INSKEEP: Parler also promised privacy, saying it would not analyze users' posts. Noted conservative figures were among the company's investors. And when President Trump was knocked off Twitter last week, some of his supporters called on people to migrate to Parler. But that site itself was on the way to being shut down, accused of failing to moderate extremist content. Peikoff maintains that all social media companies were flooded with calls to violence in recent months. What responsibility, if any, does Parler take for the content on your site? PEIKOFF: Our community guidelines were clear that we would not knowingly tolerate criminal activity on the site. We were trying to avoid using a system in which we would scan every piece of content with an automated algorithm. And so what we had was a community jury system in which any person on Parler could, of course, report a piece of content. We had a reporting mechanism. The report goes into a jury portal. And we had a, you know, bunch of volunteer jurors who were adjudicating these cases. And then the verdicts would come down, and the content would get removed as appropriate. INSKEEP: We should be frank that a lot of people migrated to Parler because they felt they could not lie as freely as they wanted to on the other social media platforms. What do you think about that? PEIKOFF: I wouldn't put it that way. I wouldn't put it that way. Not because they said they want to lie. Now, maybe there are some people. Of course, we've had some people come over who were bad actors and then would just tell all kinds of lies and everything else. I think everybody's got that. But people came over - some of them, not all of them - but some of them came over because they thought that they were being treated disproportionately unfairly on other sites and then, yeah, did come over. INSKEEP: Do you take as a company any responsibility for not just calls for violence but just obvious inciting lies about a stolen election? PEIKOFF: No. You know, I don't think that lies in and of themselves are inciting, right? So within a certain context, you could say that certain lies are. We could talk about, for example, whether that one speech that President Trump gave while the events at the Capitol were still going on and, you know, whereas he ended the speech with, go home in peace, but a lot of us found it not very convincing, given all of the preamble at the beginning. You could say, OK, in that context, he's telling certain lies and that that could be seen as a further incitement, given the ongoing activities on the ground at the day. So I see what you're getting at. But in terms of just lies themselves - and can you say that lies themselves are inciting the real world? No. When you're dealing with misinformation, we think the best anecdote is more information. INSKEEP: In Amazon's response to your company's lawsuit, they quote a number of posts on Parler. And I'm reluctant to quote them here, for - I just don't care to spread the messages. But they are obvious lies about a stolen election. There are specific calls to violence, calls for a civil war starting on Inauguration Day, urging people to form militias, urging people to, quote, \"shoot the police,\" urging people to hang specific public officials. This is just a partial list. When you read that list and know that it came across to people on your company, what do you think about? PEIKOFF: I mean, I don't want it there, obviously. But again, the question is, what mechanism do you use to detect and then remove that content? And the model that we had, as I said, as time went on through November and into December, when we started making these changes, we realized that we need to do more. And we were making those changes, and we were in discussions up with Amazon. You know, they dropped this on us on Friday afternoon. And we were telling them what we were doing and that we were willing to do more. We were starting, even, to program a bit of AI to figure out how we could use AI consistent with our mission over the weekend. And we had started tagging some content that way. So we're definitely amenable to this. Nobody wants us on their platform. There is plenty of this content. Or at least there was on Facebook and Twitter, as well. All of them, as - you know, and I've heard from ex-policy people from other platforms saying that the challenges are everywhere. Even when you do use AI, it's not going to be 100% perfect. No, we don't like to see it. It's - it expressly violates our guidelines. And then the challenge is how best effectively to remove it and to make sure that our platform is designed not to encourage the sorts of sentiments that would lead to that type of content being posted in the first place. INSKEEP: Now, in our conversation, Amy Peikoff maintained that the Capitol attackers used other sources of disinformation, too. And that is true. NPR investigated the case of Ashli Babbitt, an attacker who was killed in the Capitol. Her social media feed showed that Babbitt gathered false claims from Fox News TV personalities and guests and repeated them on Twitter in the months before she went to her death. Even after Babbitt was killed, most Republicans in Congress voted, against all the evidence, to object to a Democratic election, following the lead of the defeated president. Whether Parler survives or not, disinformation is widespread. (SOUNDBITE OF PHELIAN'S \"INTRO\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-01-16-957593549": {"title": "How Social Media Can Approach Free Speech During A Polarizing Time : NPR", "url": "https://www.npr.org/2021/01/16/957593549/how-social-media-can-approach-free-speech-during-a-polarizing-time", "author": "No author found", "published_date": "2021-01-16", "content": "SCOTT SIMON, HOST:  After President Trump was permanently suspended from Twitter, right-wing social media platform Parler was booted off of Apple's App Store and Amazon's web-hosting services, effectively putting them both offline. Parler is suing Amazon. We should note that both Apple and Amazon are NPR underwriters. These decisions followed last week's deadly attack at the U. S. Capitol launched by President Trump's extreme supporters and are applauded by many. But many also are concerned the actions might set a precedent for censoring free speech on social media. Daphne Keller, who is the Platform Regulation director at the Stanford Cyber Policy Center, joins us now. Professor, thanks so much for being with us. DAPHNE KELLER: Thanks for having me. SIMON: First big question - do you consider these bans a violation of the First Amendment? KELLER: No, and I can't imagine a court considering them violations of the First Amendment either. There have been more than 30 lawsuits in the U. S. by users saying they have a right to speak on platforms and demanding that platforms reinstate them. And the platforms always win those cases. One big reason is because the First Amendment defines your rights against the government; it doesn't define rights against a private company. SIMON: Yeah. KELLER: Another big reason is because the platforms themselves have their own First Amendment rights to set editorial policy and decide what to take down. SIMON: Yeah. But at the same time, do you have some concerns about these platforms seeming to regulate speech? And I note that Jack Dorsey, the CEO of Twitter, said this week that he thought the ban on President Trump was right, but he's concerned that it might set a precedent. KELLER: You know, I think everyone has that concern. Everyone who pays attention is worried about the idea that a very small number of private companies exercise gatekeeper power over some of the most important forums for public discussion these days. SIMON: And we should note these are some of the same platforms that have complied with tyrannies in some countries that suppress speech, haven't they? KELLER: In some cases, yes. There's globalization that goes on where American platforms at one point were sort of net exporters of First Amendment values, and now they tend to be net importers of European speech rules. But there's a risk that they become importers of Chinese speech rules or Turkish speech rules. SIMON: How can social media companies and web-hosting services moderate or regulate racist and violent messages when a lot of the people who post them speak in a coded language? KELLER: Well, it's hard for a number of reasons. One reason is that we are very far from consensus among the American public about what speech platforms should be taking down. But then beyond that is the point that you raise in your question about, well, once they do set a policy, how can they tell when a new meme or a euphemism is in circulation? And part of the answer is that they employ people who are experts and following the research on this. And so hopefully, the big platforms who can afford to employ those people are relatively up to date. SIMON: What about the concerns some people have that - I'll cite an old example - that someone like Lenny Bruce wouldn't be able to be on these social media platforms now? KELLER: That is absolutely a concern. There's also a risk of the harm from taking down the wrong things falling disproportionately on certain groups - in particular, people of color, people who are not native English speakers. There are studies showing that when platforms rely on automation to figure out whose speech is hateful, they falsely penalize speakers of African American English more than everyone else. So it's not just a speech issue. There's an equality issue. SIMON: Yeah. KELLER: There's also an economic issue with proposing rules that the giant platforms can afford to comply with but their smaller competitors cannot. SIMON: Let me cast back one last time to what Jack Dorsey of Twitter suggested this week. And to paraphrase him, he said, we took the step only reluctantly because we really do seek to be a worldwide platform for a free exchange of ideas all over the world, even ones that some people consider to be offensive. We have to be careful about this because this is the way that some national liberation groups - the only way that they can communicate with each other against a dictatorship. KELLER: I think it's something we all should pay attention to as we press for more takedowns of bad content - the risk that that will become a mechanism for silencing important public discourse. But also, I think they don't want to have to make decisions that will make half of the country very angry with them. Any shift that would let them outsource that decision and point the finger at somebody else, as Facebook is doing with the Facebook Oversight Board, I think they would be very happy to find that. SIMON: Are there some dangers as we become increasingly reliant for these platforms to carry national dialogue - is that instead of people talking to each other and exchanging different ideas, we're going to have everybody crawl under their favorite platform and exchange only ideas there? KELLER: Well, that is a risk in particular as we drive hateful speakers off of mainstream platforms where other people can respond to them and disagree with them into smaller and more marginalized, you know, echo chambers where they're going to hear only views that agree with theirs or views that are more radicalizing. That is one of the costs. SIMON: Daphne Keller, Platform Regulation director at the Stanford Cyber Policy Center, thanks so much for being with us. KELLER: Thank you. (SOUNDBITE OF MUSIC) SCOTT SIMON, HOST:   After President Trump was permanently suspended from Twitter, right-wing social media platform Parler was booted off of Apple's App Store and Amazon's web-hosting services, effectively putting them both offline. Parler is suing Amazon. We should note that both Apple and Amazon are NPR underwriters. These decisions followed last week's deadly attack at the U. S. Capitol launched by President Trump's extreme supporters and are applauded by many. But many also are concerned the actions might set a precedent for censoring free speech on social media. Daphne Keller, who is the Platform Regulation director at the Stanford Cyber Policy Center, joins us now. Professor, thanks so much for being with us. DAPHNE KELLER: Thanks for having me. SIMON: First big question - do you consider these bans a violation of the First Amendment? KELLER: No, and I can't imagine a court considering them violations of the First Amendment either. There have been more than 30 lawsuits in the U. S. by users saying they have a right to speak on platforms and demanding that platforms reinstate them. And the platforms always win those cases. One big reason is because the First Amendment defines your rights against the government; it doesn't define rights against a private company. SIMON: Yeah. KELLER: Another big reason is because the platforms themselves have their own First Amendment rights to set editorial policy and decide what to take down. SIMON: Yeah. But at the same time, do you have some concerns about these platforms seeming to regulate speech? And I note that Jack Dorsey, the CEO of Twitter, said this week that he thought the ban on President Trump was right, but he's concerned that it might set a precedent. KELLER: You know, I think everyone has that concern. Everyone who pays attention is worried about the idea that a very small number of private companies exercise gatekeeper power over some of the most important forums for public discussion these days. SIMON: And we should note these are some of the same platforms that have complied with tyrannies in some countries that suppress speech, haven't they? KELLER: In some cases, yes. There's globalization that goes on where American platforms at one point were sort of net exporters of First Amendment values, and now they tend to be net importers of European speech rules. But there's a risk that they become importers of Chinese speech rules or Turkish speech rules. SIMON: How can social media companies and web-hosting services moderate or regulate racist and violent messages when a lot of the people who post them speak in a coded language? KELLER: Well, it's hard for a number of reasons. One reason is that we are very far from consensus among the American public about what speech platforms should be taking down. But then beyond that is the point that you raise in your question about, well, once they do set a policy, how can they tell when a new meme or a euphemism is in circulation? And part of the answer is that they employ people who are experts and following the research on this. And so hopefully, the big platforms who can afford to employ those people are relatively up to date. SIMON: What about the concerns some people have that - I'll cite an old example - that someone like Lenny Bruce wouldn't be able to be on these social media platforms now? KELLER: That is absolutely a concern. There's also a risk of the harm from taking down the wrong things falling disproportionately on certain groups - in particular, people of color, people who are not native English speakers. There are studies showing that when platforms rely on automation to figure out whose speech is hateful, they falsely penalize speakers of African American English more than everyone else. So it's not just a speech issue. There's an equality issue. SIMON: Yeah. KELLER: There's also an economic issue with proposing rules that the giant platforms can afford to comply with but their smaller competitors cannot. SIMON: Let me cast back one last time to what Jack Dorsey of Twitter suggested this week. And to paraphrase him, he said, we took the step only reluctantly because we really do seek to be a worldwide platform for a free exchange of ideas all over the world, even ones that some people consider to be offensive. We have to be careful about this because this is the way that some national liberation groups - the only way that they can communicate with each other against a dictatorship. KELLER: I think it's something we all should pay attention to as we press for more takedowns of bad content - the risk that that will become a mechanism for silencing important public discourse. But also, I think they don't want to have to make decisions that will make half of the country very angry with them. Any shift that would let them outsource that decision and point the finger at somebody else, as Facebook is doing with the Facebook Oversight Board, I think they would be very happy to find that. SIMON: Are there some dangers as we become increasingly reliant for these platforms to carry national dialogue - is that instead of people talking to each other and exchanging different ideas, we're going to have everybody crawl under their favorite platform and exchange only ideas there? KELLER: Well, that is a risk in particular as we drive hateful speakers off of mainstream platforms where other people can respond to them and disagree with them into smaller and more marginalized, you know, echo chambers where they're going to hear only views that agree with theirs or views that are more radicalizing. That is one of the costs. SIMON: Daphne Keller, Platform Regulation director at the Stanford Cyber Policy Center, thanks so much for being with us. KELLER: Thank you. (SOUNDBITE OF MUSIC)", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-01-17-957512634": {"title": "Social Media Site Gab Is Surging, Even As Critics Blame It For Capitol Violence : NPR", "url": "https://www.npr.org/2021/01/17/957512634/social-media-site-gab-is-surging-even-as-critics-blame-it-for-capitol-violence", "author": "No author found", "published_date": "2021-01-17", "content": "LULU GARCIA-NAVARRO, HOST:  The plans to storm the Capitol were in plain sight on social media, so could social media companies be held legally responsible? NPR's Bobby Allyn takes a look at one social network popular with the far-right. BOBBY ALLYN, BYLINE: Before the insurrection attempt on the Capitol, social media site Gab was lighting up about it. Some of the plans began to get very specific. JONATHAN GREENBLATT: There were directions provided on Gab for which streets to take to avoid the police and which tools to use to help pry open the doors. ALLYN: Jonathan Greenblatt leads the Anti-Defamation League. As federal investigators probe the people behind the attack, Greenblatt says online platforms should bear some responsibility, too, in particular, Gab. GREENBLATT: We need to ascertain right here, right now whether this specific platform was knowingly facilitating an attack in our nation's capital, literally a terror act against the seat of our government. ALLYN: Gab is like an anti-Twitter, popular with Trump supporters. It's where far-right provocateurs who've been banned from Facebook and Twitter go. It has a history of embracing hate. The man who walked into a Pittsburgh synagogue in 2018 and killed 11 people had earlier posted anti-Semitic messages on Gab. On the day of the attack on the Capitol, Gab CEO Andrew Torba posted, quote, \"in a system with rigged elections, there are no longer any viable political solutions. \" In an interview with NPR, Torba says nobody is going to make him take down messages on Gab. He sees that as censoring free speech, and he says new users are now flocking to the site. ANDREW TORBA: Up until last week, our site only had about a million and a half, although this is growing rapidly now by millions. ALLYN: Gab's traffic is up 800%. Torba says he's had to order more servers just to handle the new surge in popularity. As for the Anti-Defamation League's call that Gab be investigated by federal authorities, Torba says the site isn't doing anything wrong. TORBA: We work with law enforcement to remove illegal activity from our site, so if people have politically incorrect opinions, the ADL is just going to have to suck it up and deal with it. ALLYN: Researchers say sites like Gab did help boost turnout for the march on the Capitol which led to the insurrection attempt. But so did the big platforms. Many who showed up heard about it first on Facebook and Twitter. It was promoted with the hashtags #StopTheSteal and #FightForTrump. Here's the thing, though. Tech companies can't be sued for leaving a post up or taking a post down. But what about being criminally prosecuted for the violence that follows? ORIN KERR: It's hard to imagine. ALLYN: Orin Kerr is a former federal prosecutor who's now a Berkeley professor focused on cybercrime. He says to prove that the social media companies were, say, aiding and abetting in the violence, it wouldn't be enough that the platforms knew it might happen. Prosecutors would need to show that the companies had clear intentions. KERR: You actually have to have in your mind that goal, yeah, I want to bring that crime about. And when we're talking about these big companies providing the platforms to hundreds of millions or billions of users, that's not what those companies are about. ALLYN: Ryan Calo, a law professor at the University of Washington, says if you create something dangerous, knowing it can cause harm, usually you can be held liable. But federal law protects tech companies from civil lawsuits and makes it nearly impossible to criminally prosecute them, which is frustrating, Calo says, because Facebook, Twitter and smaller sites like Gab were repeatedly warned that online disinformation could result in offline violence. RYAN CALO: I'm very disappointed. I don't believe that they're shocked, and I think they have culpability. ALLYN: But being morally wrong, Calo says, isn't the same as saying something is a federal crime. Bobby Allyn, NPR News, San Francisco. (SOUNDBITE OF MUSIC) LULU GARCIA-NAVARRO, HOST:   The plans to storm the Capitol were in plain sight on social media, so could social media companies be held legally responsible? NPR's Bobby Allyn takes a look at one social network popular with the far-right. BOBBY ALLYN, BYLINE: Before the insurrection attempt on the Capitol, social media site Gab was lighting up about it. Some of the plans began to get very specific. JONATHAN GREENBLATT: There were directions provided on Gab for which streets to take to avoid the police and which tools to use to help pry open the doors. ALLYN: Jonathan Greenblatt leads the Anti-Defamation League. As federal investigators probe the people behind the attack, Greenblatt says online platforms should bear some responsibility, too, in particular, Gab. GREENBLATT: We need to ascertain right here, right now whether this specific platform was knowingly facilitating an attack in our nation's capital, literally a terror act against the seat of our government. ALLYN: Gab is like an anti-Twitter, popular with Trump supporters. It's where far-right provocateurs who've been banned from Facebook and Twitter go. It has a history of embracing hate. The man who walked into a Pittsburgh synagogue in 2018 and killed 11 people had earlier posted anti-Semitic messages on Gab. On the day of the attack on the Capitol, Gab CEO Andrew Torba posted, quote, \"in a system with rigged elections, there are no longer any viable political solutions. \" In an interview with NPR, Torba says nobody is going to make him take down messages on Gab. He sees that as censoring free speech, and he says new users are now flocking to the site. ANDREW TORBA: Up until last week, our site only had about a million and a half, although this is growing rapidly now by millions. ALLYN: Gab's traffic is up 800%. Torba says he's had to order more servers just to handle the new surge in popularity. As for the Anti-Defamation League's call that Gab be investigated by federal authorities, Torba says the site isn't doing anything wrong. TORBA: We work with law enforcement to remove illegal activity from our site, so if people have politically incorrect opinions, the ADL is just going to have to suck it up and deal with it. ALLYN: Researchers say sites like Gab did help boost turnout for the march on the Capitol which led to the insurrection attempt. But so did the big platforms. Many who showed up heard about it first on Facebook and Twitter. It was promoted with the hashtags #StopTheSteal and #FightForTrump. Here's the thing, though. Tech companies can't be sued for leaving a post up or taking a post down. But what about being criminally prosecuted for the violence that follows? ORIN KERR: It's hard to imagine. ALLYN: Orin Kerr is a former federal prosecutor who's now a Berkeley professor focused on cybercrime. He says to prove that the social media companies were, say, aiding and abetting in the violence, it wouldn't be enough that the platforms knew it might happen. Prosecutors would need to show that the companies had clear intentions. KERR: You actually have to have in your mind that goal, yeah, I want to bring that crime about. And when we're talking about these big companies providing the platforms to hundreds of millions or billions of users, that's not what those companies are about. ALLYN: Ryan Calo, a law professor at the University of Washington, says if you create something dangerous, knowing it can cause harm, usually you can be held liable. But federal law protects tech companies from civil lawsuits and makes it nearly impossible to criminally prosecute them, which is frustrating, Calo says, because Facebook, Twitter and smaller sites like Gab were repeatedly warned that online disinformation could result in offline violence. RYAN CALO: I'm very disappointed. I don't believe that they're shocked, and I think they have culpability. ALLYN: But being morally wrong, Calo says, isn't the same as saying something is a federal crime. Bobby Allyn, NPR News, San Francisco. (SOUNDBITE OF MUSIC)", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-01-21-959350053": {"title": "Facebook Asks Oversight Board Whether Trump's Account Should Be Restored Now : NPR", "url": "https://www.npr.org/2021/01/21/959350053/facebook-asks-oversight-board-whether-trumps-account-should-be-restored-now", "author": "No author found", "published_date": "2021-01-21", "content": "", "section": "Technology", "disclaimer": ""}, "2021-01-21-959335985": {"title": "Facebook Outsources Decision On The Future Of Trump's Account To An Independent Panel : NPR", "url": "https://www.npr.org/2021/01/21/959335985/facebook-outsources-decision-on-the-future-of-trumps-account-to-an-independent-p", "author": "No author found", "published_date": "2021-01-21", "content": "ARI SHAPIRO, HOST:  Now that the transfer of power here in Washington is complete, social media companies need to decide whether they will continue to ban Donald Trump. At Facebook, an independent panel is considering that question. Facebook suspended Trump's account indefinitely hours after a mob of his supporters stormed the Capitol on January 6. In a post, CEO Mark Zuckerberg said the risks of allowing Trump to continue using Facebook in his remaining days in office were simply too great. Nick Clegg is Facebook's vice president for global affairs and communications. And he joins us to talk about this decision. Welcome back to ALL THINGS CONSIDERED. NICK CLEGG: Thanks for inviting me onto your program. SHAPIRO: Why hand over this decision about the future of Trump's Facebook account to an independent board? Why not own it and take responsibility for it yourselves? CLEGG: Well, we certainly take responsibility for the decision we took on January the 7 to indefinitely suspend Donald Trump's access to his Facebook and Instagram accounts. And we believe we took the right decision. We think it was entirely justified by the unprecedented circumstances on that day. But there has been, in my view, legitimate commentary, not only here in the U. S. , but, crucially, from leaders around the world as well, from everyone ranging from, you know, Chancellor Angela Merkel to the president of Mexico. And many of those leaders and other commentators have said, look, they might agree with the steps we took, but they worry about the - what they view as unaccountable power of private companies making big decisions about political speech. And we agree with them. We think it would be much better if there were democratically agreed standards by which we could take these decisions. But they don't exist at the moment. And that's why we created this independent oversight board, made up of figures from journalism, academia and ex-politicians - this oversight board - precisely, a bit like a court, to scrutinize actions we take and decide in a thoughtful way whether we got it right or not. And that's what we're asking them to do. And their decision, by the way, will be binding on us. SHAPIRO: Now, their decision on Donald Trump will be binding. But you've also asked them for broader guidance on how to handle other political leaders who make incendiary posts on Facebook. That recommendation is not binding. And so what are you hoping to learn from that? CLEGG: Well, as you no doubt know, the whole issue of the attitude of social media companies to political speech and how political speech plays out in our platform is a very fraught issue. The attitude we have traditionally taken as a company is this - that in open democracies, it isn't really for a private company to vet everything that politicians say - the good, the bad and the ugly - and that voters should have as much access as possible to what politicians say so that they can make up their own mind at election time. There are, of course, limits to that. And we have policies on hate speech and incitement to violence. And it's precisely those policies, by the way, which were violated by former President Donald Trump and the reason we have indefinitely suspended his access to his account in the way that we have. But it's a major debate about whether we've drawn the lines in the right place. Some people think we should be more aggressive. Others think we should be more permissive. SHAPIRO: As you know, Facebook has been accused of a double standard - suspending Trump's account for inciting violence, but not taking the same action against other world leaders like Rodrigo Duterte of the Philippines or Jair Bolsonaro in Brazil. Can you explain why Facebook has taken different approaches to those world leaders and if the inconsistency is something that you're hoping to address with this recommendation from the board? CLEGG: Well, I first - I wouldn't want your question to leave anyone with the impression that we don't take action against world leaders. We've taken a number of posts down from President Bolsonaro related to COVID, for instance. And look, the touchstone for us - the touchstone principle for us - and people can agree or disagree with it - is this - is where we feel there is speech on our platform where there is a link to an impending risk of real-world violence, then we act - then we act. SHAPIRO: Well, but the question is, do you act on the specific post or do you act on the account? Because Facebook had flagged and even taken down Trump posts before suspending the account. And while you have flagged and taken down posts about COVID-19 by world leaders, you have not suspended other world leaders' accounts. CLEGG: Right, exactly. And what we explained in this instance was that the reason we took this unprecedented step of suspending Donald Trump's access to his Facebook and Instagram accounts was because we felt that what was happening was jeopardizing the peaceful transition of power. And that is why we were very explicit that the indefinite ban was indefinite, but was most definitely in place for at least two weeks until we had the inauguration of yesterday out of the way because we felt there was a real danger, not just to the events that occurred on January 6, but to the wider peaceful, smooth, democratic transfer of power. And that is why in other instances, we might remove content posts, but not suspend the account altogether. By the way, we block or remove accounts all the time. I mean, I think, in fact, millions of accounts every day. There are plenty of circumstances in which we do so. But when it comes to a political leader, we felt the reason why this was so unusual was because we felt it was interfering and it was deliberately being orchestrated in a way in order to interfere with a peaceful transition of power. SHAPIRO: Nick Clegg is Facebook's vice president for global affairs and communications. Thank you for speaking with us. CLEGG: Thank you. ARI SHAPIRO, HOST:   Now that the transfer of power here in Washington is complete, social media companies need to decide whether they will continue to ban Donald Trump. At Facebook, an independent panel is considering that question. Facebook suspended Trump's account indefinitely hours after a mob of his supporters stormed the Capitol on January 6. In a post, CEO Mark Zuckerberg said the risks of allowing Trump to continue using Facebook in his remaining days in office were simply too great. Nick Clegg is Facebook's vice president for global affairs and communications. And he joins us to talk about this decision. Welcome back to ALL THINGS CONSIDERED. NICK CLEGG: Thanks for inviting me onto your program. SHAPIRO: Why hand over this decision about the future of Trump's Facebook account to an independent board? Why not own it and take responsibility for it yourselves? CLEGG: Well, we certainly take responsibility for the decision we took on January the 7 to indefinitely suspend Donald Trump's access to his Facebook and Instagram accounts. And we believe we took the right decision. We think it was entirely justified by the unprecedented circumstances on that day. But there has been, in my view, legitimate commentary, not only here in the U. S. , but, crucially, from leaders around the world as well, from everyone ranging from, you know, Chancellor Angela Merkel to the president of Mexico. And many of those leaders and other commentators have said, look, they might agree with the steps we took, but they worry about the - what they view as unaccountable power of private companies making big decisions about political speech. And we agree with them. We think it would be much better if there were democratically agreed standards by which we could take these decisions. But they don't exist at the moment. And that's why we created this independent oversight board, made up of figures from journalism, academia and ex-politicians - this oversight board - precisely, a bit like a court, to scrutinize actions we take and decide in a thoughtful way whether we got it right or not. And that's what we're asking them to do. And their decision, by the way, will be binding on us. SHAPIRO: Now, their decision on Donald Trump will be binding. But you've also asked them for broader guidance on how to handle other political leaders who make incendiary posts on Facebook. That recommendation is not binding. And so what are you hoping to learn from that? CLEGG: Well, as you no doubt know, the whole issue of the attitude of social media companies to political speech and how political speech plays out in our platform is a very fraught issue. The attitude we have traditionally taken as a company is this - that in open democracies, it isn't really for a private company to vet everything that politicians say - the good, the bad and the ugly - and that voters should have as much access as possible to what politicians say so that they can make up their own mind at election time. There are, of course, limits to that. And we have policies on hate speech and incitement to violence. And it's precisely those policies, by the way, which were violated by former President Donald Trump and the reason we have indefinitely suspended his access to his account in the way that we have. But it's a major debate about whether we've drawn the lines in the right place. Some people think we should be more aggressive. Others think we should be more permissive. SHAPIRO: As you know, Facebook has been accused of a double standard - suspending Trump's account for inciting violence, but not taking the same action against other world leaders like Rodrigo Duterte of the Philippines or Jair Bolsonaro in Brazil. Can you explain why Facebook has taken different approaches to those world leaders and if the inconsistency is something that you're hoping to address with this recommendation from the board? CLEGG: Well, I first - I wouldn't want your question to leave anyone with the impression that we don't take action against world leaders. We've taken a number of posts down from President Bolsonaro related to COVID, for instance. And look, the touchstone for us - the touchstone principle for us - and people can agree or disagree with it - is this - is where we feel there is speech on our platform where there is a link to an impending risk of real-world violence, then we act - then we act. SHAPIRO: Well, but the question is, do you act on the specific post or do you act on the account? Because Facebook had flagged and even taken down Trump posts before suspending the account. And while you have flagged and taken down posts about COVID-19 by world leaders, you have not suspended other world leaders' accounts. CLEGG: Right, exactly. And what we explained in this instance was that the reason we took this unprecedented step of suspending Donald Trump's access to his Facebook and Instagram accounts was because we felt that what was happening was jeopardizing the peaceful transition of power. And that is why we were very explicit that the indefinite ban was indefinite, but was most definitely in place for at least two weeks until we had the inauguration of yesterday out of the way because we felt there was a real danger, not just to the events that occurred on January 6, but to the wider peaceful, smooth, democratic transfer of power. And that is why in other instances, we might remove content posts, but not suspend the account altogether. By the way, we block or remove accounts all the time. I mean, I think, in fact, millions of accounts every day. There are plenty of circumstances in which we do so. But when it comes to a political leader, we felt the reason why this was so unusual was because we felt it was interfering and it was deliberately being orchestrated in a way in order to interfere with a peaceful transition of power. SHAPIRO: Nick Clegg is Facebook's vice president for global affairs and communications. Thank you for speaking with us. CLEGG: Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-01-21-956486352": {"title": "Judge Refuses To Reinstate Parler After Amazon Shut It Down  : NPR", "url": "https://www.npr.org/2021/01/21/956486352/judge-refuses-to-reinstate-parler-after-amazon-shut-it-down", "author": "No author found", "published_date": "2021-01-21", "content": "MARY LOUISE KELLY, HOST:  Changing gears now - a federal judge in Seattle has ruled that Amazon does not have to restore service to Parler. Parler is a social network favored by Trump supporters. Amazon terminated its Web hosting contract with Parler, saying the platform failed to take down posts that encouraged and incited violence. Parler then sued. So that is how we got here. For more on the ruling, we are joined by NPR tech reporter Bobby Allyn. And we should note Amazon is a financial supporter of NPR. Hey there, Bobby. BOBBY ALLYN, BYLINE: Hey, Mary Louise. KELLY: So what exactly is the judge saying here? ALLYN: Yeah. So the federal judge, Barbara Rothstein, said Amazon was well within its rights to end its contract with Parler over posts that were glorifying violence. You know, Parler had a bunch of claims in its lawsuit, but one of them was that Amazon severing ties was anti-competitive, that Amazon was basically trying to hurt a smaller tech company. And the judge said Parler just offered no real evidence of that. So in short, you know, the judge is saying here that Amazon saying no to incendiary speech is perfectly legal. KELLY: Now, Parler is a social network, as we said, relatively new on the scene, popular with Trump supporters. What else do we need to know about it? ALLYN: Yeah. So it's part of a number of sites that are sort of alternative social media sites that have been gaining popularity lately. I mean, one of Parler's biggest supporters was a major donor to former President Donald Trump. And Parler's calling card is being aggressively hands-off when it comes to what people can say and post. But the issue is sometimes that approach has, you know, let things like hate speech and violence go untouched. KELLY: Yeah. Well, and what does today's decision mean for its future? Is this the end of Parler? ALLYN: It very well may be. I mean, you know, Parler's said that, you know, Amazon's move cutting its ties may be - may mean the extinction of Parler. We just have to see. But, you know, right when it happened, Mary Louise, Parler's CEO said, oh, don't worry, everyone. We'll be back up in no time. But that hasn't been so easy because the company's basically become persona non grata on the Internet, and that's because of its role in the Capitol riots. I mean, many planned the violence and documented it at length on Parler, which has now turned into a business problem. I mean, the last six Web hosts Parler has reached out to have refused to work with them. Now, Parler and its 15 million users say that is unfair. But, you know, I talked to many researchers and hate speech experts, and they, on the other hand, are very much welcoming this news of Parler being pushed off the Internet. KELLY: You've given us a taste of what Parler has been saying in its defense. Have they reacted yet to today's decision? ALLYN: Not yet. But Parler's website, if you go to it, is now just sort of a shell. It's, like, this landing page. It has a welcome note. And you can't post or share anything or create an account, but it does have a note from Parler's CEO. And it says, quote, \"We will not let civil discourse perish. \" So Parler is saying that they will try to find a way somehow to reemerge. KELLY: And just situate this in the context of the many legal battles that Big Tech finds itself straight in the middle of these days. ALLYN: Yeah, yeah. So on the one hand, here's this relative upstart, you know, testing the power of Big Tech. And this decision shows Big Tech won. But, you know, there's another story here, and I think it's that this is really a window into how tech companies - you know, Parlers of the world but smaller ones, you know, too - are grappling with the future of speech online. I mean, the insurrection attempt on the Capitol, you know, has caused what some are calling the great deplatforming, right? We saw Trump get banned on social media and now so many others. So these kinds of push-and-pull battles over the balance between, you know, free speech and content moderation. . . KELLY: Right. ALLYN: They are just heating up. KELLY: Thank you, Bobby. ALLYN: Thanks, Mary Louise. KELLY: NPR's Bobby Allyn. MARY LOUISE KELLY, HOST:   Changing gears now - a federal judge in Seattle has ruled that Amazon does not have to restore service to Parler. Parler is a social network favored by Trump supporters. Amazon terminated its Web hosting contract with Parler, saying the platform failed to take down posts that encouraged and incited violence. Parler then sued. So that is how we got here. For more on the ruling, we are joined by NPR tech reporter Bobby Allyn. And we should note Amazon is a financial supporter of NPR. Hey there, Bobby. BOBBY ALLYN, BYLINE: Hey, Mary Louise. KELLY: So what exactly is the judge saying here? ALLYN: Yeah. So the federal judge, Barbara Rothstein, said Amazon was well within its rights to end its contract with Parler over posts that were glorifying violence. You know, Parler had a bunch of claims in its lawsuit, but one of them was that Amazon severing ties was anti-competitive, that Amazon was basically trying to hurt a smaller tech company. And the judge said Parler just offered no real evidence of that. So in short, you know, the judge is saying here that Amazon saying no to incendiary speech is perfectly legal. KELLY: Now, Parler is a social network, as we said, relatively new on the scene, popular with Trump supporters. What else do we need to know about it? ALLYN: Yeah. So it's part of a number of sites that are sort of alternative social media sites that have been gaining popularity lately. I mean, one of Parler's biggest supporters was a major donor to former President Donald Trump. And Parler's calling card is being aggressively hands-off when it comes to what people can say and post. But the issue is sometimes that approach has, you know, let things like hate speech and violence go untouched. KELLY: Yeah. Well, and what does today's decision mean for its future? Is this the end of Parler? ALLYN: It very well may be. I mean, you know, Parler's said that, you know, Amazon's move cutting its ties may be - may mean the extinction of Parler. We just have to see. But, you know, right when it happened, Mary Louise, Parler's CEO said, oh, don't worry, everyone. We'll be back up in no time. But that hasn't been so easy because the company's basically become persona non grata on the Internet, and that's because of its role in the Capitol riots. I mean, many planned the violence and documented it at length on Parler, which has now turned into a business problem. I mean, the last six Web hosts Parler has reached out to have refused to work with them. Now, Parler and its 15 million users say that is unfair. But, you know, I talked to many researchers and hate speech experts, and they, on the other hand, are very much welcoming this news of Parler being pushed off the Internet. KELLY: You've given us a taste of what Parler has been saying in its defense. Have they reacted yet to today's decision? ALLYN: Not yet. But Parler's website, if you go to it, is now just sort of a shell. It's, like, this landing page. It has a welcome note. And you can't post or share anything or create an account, but it does have a note from Parler's CEO. And it says, quote, \"We will not let civil discourse perish. \" So Parler is saying that they will try to find a way somehow to reemerge. KELLY: And just situate this in the context of the many legal battles that Big Tech finds itself straight in the middle of these days. ALLYN: Yeah, yeah. So on the one hand, here's this relative upstart, you know, testing the power of Big Tech. And this decision shows Big Tech won. But, you know, there's another story here, and I think it's that this is really a window into how tech companies - you know, Parlers of the world but smaller ones, you know, too - are grappling with the future of speech online. I mean, the insurrection attempt on the Capitol, you know, has caused what some are calling the great deplatforming, right? We saw Trump get banned on social media and now so many others. So these kinds of push-and-pull battles over the balance between, you know, free speech and content moderation. . . KELLY: Right. ALLYN: They are just heating up. KELLY: Thank you, Bobby. ALLYN: Thanks, Mary Louise. KELLY: NPR's Bobby Allyn.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-01-21-959107276": {"title": "Web Hosts, Services Connecting Websites To The Internet, Gain More Power  : NPR", "url": "https://www.npr.org/2021/01/21/959107276/web-hosts-services-connecting-websites-to-the-internet-gain-more-power", "author": "No author found", "published_date": "2021-01-21", "content": "STEVE INSKEEP, HOST:  We talk a lot about the choices that social media platforms make. What kinds of speech do Facebook or Twitter block? But a less visible part of the Web may be more powerful. It decides whether an online platform survives or goes dark. NPR's Bobby Allyn reports on one front in the fight over online speech. BOBBY ALLYN, BYLINE: If you want to run a site on the Internet, you need a Web host, the service that actually connects a website to the Internet. GREG FALCO: There's guts of the Web that no one ever wants to see or deal with or think about. ALLYN: Well, Greg Falco, a Stanford security researcher, says it might be time to start thinking about it. Web hosting companies have the levers to vast online infrastructure and complete discretion to pull those levers as they see fit. That means they can decide which websites live or die. FALCO: The question becomes tricky of like, when do you actually take someone down? It's a really gray territory. The reality is it comes down to understanding when it reaches some public attention, when there is actually physical implications. ALLYN: For instance, a group of people who go to a website to plan to overthrow government and then use the site to document the attempt by posting photos and videos of the violence. That's the scenario that faced Amazon Web Services, one of the biggest players in the Web hosting world. One of its clients was the social media site Parler, which was filled with post by pro-Trump extremists before and during the storming of the U. S. Capitol. Amazon stopped hosting Parler and the site went dark. To many, this revealed the power of Web hosting, says former Netflix executive Dave Temkin. He's an expert in the infrastructure of the Internet. DAVE TEMKIN: It's absolutely invisible. It just kind of works, and no one knows what it is until it breaks. ALLYN: In justifying cutting Parler off, Amazon said it had warned Parler of 98 examples of posts that, quote, \"clearly encourage and incite violence. \" That went against Amazon's terms of service. If Parler didn't clean up its act, Amazon would hit the kill switch. And that's what happened. To Harvard's Evelyn Douek, who studies online speech, it was a big moment. It raised questions about the power of Web hosts. EVELYN DOUEK: Is that the right place for content moderation to be occurring? Because it's harder to bring accountability to those choices when we don't even know who's making them or how they're being made. ALLYN: In other words, when a Web host has a problem with content, usually these discussions are hashed out between two companies, out of the public light. And Web hosts, unlike social media platforms, aren't used to having to explain these decisions. Another issue, Douek says, is who polices the Web host? She pointed to the 98 pieces of objectionable content Amazon cited about Parler. DOUEK: That - it sort of made me laugh a little bit because, like, has Amazon read the rest of the Internet? Like, 98 pieces of content - or whatever it was - is not that many. I mean, has Amazon read Amazon? ALLYN: The old idea of the Internet as a marketplace of ideas where the best will rise to the top no longer applies. That's being fiercely reconsidered by both social media and the companies that do Web hosting. Temkin, the former Netflix executive, agrees. But he also noted that Web hosts, even those as big as Amazon, can be overwhelmed by the sheer volume of sites they serve. TEMKIN: You know, if you're AWS and you've got hundreds of thousands of customers, you can't actively police what each of those customers are doing with your service. ALLYN: But if you're the one banned from Amazon, why not just find another Web host? Well, Parler has tried, and it's not that easy. The last six Web hosts Parler has approached have all said, no thanks. Parler now only has a shell of a site where no one can post. Bobby Allyn, NPR News, San Francisco. STEVE INSKEEP, HOST:   We talk a lot about the choices that social media platforms make. What kinds of speech do Facebook or Twitter block? But a less visible part of the Web may be more powerful. It decides whether an online platform survives or goes dark. NPR's Bobby Allyn reports on one front in the fight over online speech. BOBBY ALLYN, BYLINE: If you want to run a site on the Internet, you need a Web host, the service that actually connects a website to the Internet. GREG FALCO: There's guts of the Web that no one ever wants to see or deal with or think about. ALLYN: Well, Greg Falco, a Stanford security researcher, says it might be time to start thinking about it. Web hosting companies have the levers to vast online infrastructure and complete discretion to pull those levers as they see fit. That means they can decide which websites live or die. FALCO: The question becomes tricky of like, when do you actually take someone down? It's a really gray territory. The reality is it comes down to understanding when it reaches some public attention, when there is actually physical implications. ALLYN: For instance, a group of people who go to a website to plan to overthrow government and then use the site to document the attempt by posting photos and videos of the violence. That's the scenario that faced Amazon Web Services, one of the biggest players in the Web hosting world. One of its clients was the social media site Parler, which was filled with post by pro-Trump extremists before and during the storming of the U. S. Capitol. Amazon stopped hosting Parler and the site went dark. To many, this revealed the power of Web hosting, says former Netflix executive Dave Temkin. He's an expert in the infrastructure of the Internet. DAVE TEMKIN: It's absolutely invisible. It just kind of works, and no one knows what it is until it breaks. ALLYN: In justifying cutting Parler off, Amazon said it had warned Parler of 98 examples of posts that, quote, \"clearly encourage and incite violence. \" That went against Amazon's terms of service. If Parler didn't clean up its act, Amazon would hit the kill switch. And that's what happened. To Harvard's Evelyn Douek, who studies online speech, it was a big moment. It raised questions about the power of Web hosts. EVELYN DOUEK: Is that the right place for content moderation to be occurring? Because it's harder to bring accountability to those choices when we don't even know who's making them or how they're being made. ALLYN: In other words, when a Web host has a problem with content, usually these discussions are hashed out between two companies, out of the public light. And Web hosts, unlike social media platforms, aren't used to having to explain these decisions. Another issue, Douek says, is who polices the Web host? She pointed to the 98 pieces of objectionable content Amazon cited about Parler. DOUEK: That - it sort of made me laugh a little bit because, like, has Amazon read the rest of the Internet? Like, 98 pieces of content - or whatever it was - is not that many. I mean, has Amazon read Amazon? ALLYN: The old idea of the Internet as a marketplace of ideas where the best will rise to the top no longer applies. That's being fiercely reconsidered by both social media and the companies that do Web hosting. Temkin, the former Netflix executive, agrees. But he also noted that Web hosts, even those as big as Amazon, can be overwhelmed by the sheer volume of sites they serve. TEMKIN: You know, if you're AWS and you've got hundreds of thousands of customers, you can't actively police what each of those customers are doing with your service. ALLYN: But if you're the one banned from Amazon, why not just find another Web host? Well, Parler has tried, and it's not that easy. The last six Web hosts Parler has approached have all said, no thanks. Parler now only has a shell of a site where no one can post. Bobby Allyn, NPR News, San Francisco.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-01-22-959736537": {"title": "Twitter Bans Account Linked To Iran's Supreme Leader : NPR", "url": "https://www.npr.org/2021/01/22/959736537/twitter-bans-account-linked-to-irans-supreme-leader", "author": "No author found", "published_date": "2021-01-22", "content": "", "section": "World", "disclaimer": ""}, "2021-01-22-958877682": {"title": "MeWe CEO: Enforcing Social Media Rules Is 'Messy' Amid Post-Trump Surge : NPR", "url": "https://www.npr.org/2021/01/22/958877682/fast-growing-alternative-to-facebook-twitter-finds-right-wing-surge-messy", "author": "No author found", "published_date": "2021-01-22", "content": "", "section": "Technology", "disclaimer": ""}, "2021-01-23-959985616": {"title": "Facebook Oversight Board Co-Chair On Future Of Trump's Account : NPR", "url": "https://www.npr.org/2021/01/23/959985616/facebook-oversight-board-co-chair-on-future-of-trumps-account", "author": "No author found", "published_date": "2021-01-23", "content": "MICHEL MARTIN, HOST:  After the attack on the U. S. Capitol earlier this month, Facebook, like several other social media companies, suspended President Trump's account. At the time, the company said the account would be suspended indefinitely, at least until the peaceful transfer of power had taken place. So now that that's happened, what's next for the former president's account, an account that he used to spread misinformation throughout his four years in office? Facebook has asked its independent oversight board to take this question on and decide whether Trump should have access to his Facebook and Instagram accounts going forward. The independent oversight board was created last year to make these kinds of complicated decisions, and this will be one of its first big cases. So we're joined now by the co-chair of the oversight board, Jamal Greene. He's a professor at Columbia Law School, focusing on constitutional law regulation and public policy. Mr. Greene, welcome back to the program. Thank you for joining us once again. JAMAL GREENE: Thank you for having me. MARTIN: And I do want to mention here that Facebook is one of NPR's financial supporters. So first, let's go back. What went into the decision behind suspending Trump's account on January 7? Was the oversight board involved in making that decision? GREENE: The oversight board was not involved in the initial decision to suspend. That was a decision made by Facebook and on their side. And Facebook says they did it in response to some posts that faced - that President Trump put up on the site. And the oversight board will have to decide whether that was an appropriate response. MARTIN: And is that the way it's supposed to work? I thought that the - so the oversight board is a reactive body, not a prescriptive body? GREENE: That's right. The oversight board does have the power when asked to help Facebook make certain policy decisions. But the kind of meat of our diet is - a content decision is made by the company or by Instagram. And the board decides whether that was appropriate or not and whether the content should go up - back up onto the platform or stay down. MARTIN: I see. Understood. OK. So a Washington Post article recently reported that research - that the research from Zignal found that online misinformation about the election fell significantly, some 73% after sites like Facebook banned then-President Trump. So I understood from your reporting just now that the oversight board was not involved in the initial decision. But are you willing to say now that it was the right decision, knowing what we know now? GREENE: So I'm not in a position yet to judge the case. I'm not going to prejudge it until we actually hear the case. I think it's quite important to make sure that we have all the facts and are in a proper deliberative posture before we make those kinds of decisions. So, you know, we'll work on it as quickly as we can and with as much principle as we can and see where it goes. MARTIN: So talk to me a bit more, if you would, about what those principles are. Can you sort of describe how the board is approaching this question? GREENE: Sure. The board, which is a diverse body of - right now, we're 20 members. We sit in panels, and the panels deliberate about the question of whether content should be removed or not, and in this case, whether a suspension was appropriate or not. And we draw on both the company's own kind of terms of service, which they refer to as their community standards, and whether they were properly applied. But, also, Facebook has what are called values. Voice is a - is one of those values. Safety is one of those values. Dignity is one of those values. And we are also charged with applying those values. And then there's also kind of an external source of information we rely on, which is international human rights law. So that has standards for when and how freedom of expression can be regulated. Facebook has committed to acting consistent with those standards, and so the board is set up to try to apply those international human rights norms to the behavior of the company. MARTIN: So specifically to Donald Trump, does his civilian status - how does his civilian status weigh now? Does the fact that he's no longer president and that he is now a private citizen - does that factor into the decision-making? GREENE: So potentially - and I don't want to get into exactly what factors the board will rely on in the substantive case before we actually, you know, sit and deliberate about it. But any number of kind of contextual factors can matter in cases when freedom of expression has been limited. MARTIN: And is it accurate that you've been asked to put together broad policy recommendations for Facebook on suspensions of political leaders going forward? And - because I'm sure you know that there's been a lot of criticism that Facebook hasn't applied its policies evenly and that, you know, other world leaders, like, for example, President Rodrigo Duterte of the Philippines - the criticism is that he has violated certain Facebook rules as well. So is that also part of your portfolio to put together recommendations going forward for political leaders like president - like the former president, heads of state at that level? GREENE: Yes, that's right. So Facebook, as part of this case, has asked for policy advice that they are obligated to consider as to whether - how their content standards should relate to political leaders. And this is something that has been a challenge for the company and for other platforms in the past, given that political leaders are very differently situated than ordinary citizens. And so that's going to be one of the things that we look into. MARTIN: And I would say that this is the first big decision that your oversight board has had to make. Do you agree? GREENE: I think that this decision will certainly get a lot of attention. We've been working on a number of cases that should come out pretty soon in terms of the opinions that we're going to be issuing. And those are cases from around the world, you know? Facebook has almost 3 billion users, so there are lots of things that happen in the United States that get a lot of attention. But there are also things that happen elsewhere that get lots of attention. So I wouldn't - I don't know that I'd say it's the first big case we've had. All of the cases are important and raise important issues. But I think it's fair to say that this will get a lot of attention. MARTIN: I take your point. And I do recognize your desire not to inflate your own importance in the world. And I also recognize your desire to give international matters the weight that they deserve. But I am just wondering if this feels like a particularly weighty decision and how you are thinking about that. GREENE: Yeah, so we're aware, certainly, of the attention paid to the case. We're aware of how many eyes will be on it. We're aware of the visibility of the case. So I wouldn't - and it is indeed important. It's not just a matter of optics; it's an important decision. And we'll take it with the weight that it deserves. But I think it is also important to point out that that we take cases from around the world and those are important in the corners of the world that they impact. MARTIN: Before we let you go, is this decision binding? Does Facebook have to take your decision, whatever it is? Or is this merely advisory? GREENE: So Facebook has committed to taking the decision of the oversight board as to whether the content should have been removed or not and whether the suspension was appropriate or not. As to whatever policy advice we give to Facebook, it's committed to respond to that in some way, but it's not obligated necessarily to implement exactly what we say as a policy matter. MARTIN: Well, we await your decision. That was Jamal Greene, co-chair of Facebook's oversight board and professor at Columbia Law School. Professor Greene, we thank you so much for joining us once again. We look forward to talking further. GREENE: Thank you. MICHEL MARTIN, HOST:   After the attack on the U. S. Capitol earlier this month, Facebook, like several other social media companies, suspended President Trump's account. At the time, the company said the account would be suspended indefinitely, at least until the peaceful transfer of power had taken place. So now that that's happened, what's next for the former president's account, an account that he used to spread misinformation throughout his four years in office? Facebook has asked its independent oversight board to take this question on and decide whether Trump should have access to his Facebook and Instagram accounts going forward. The independent oversight board was created last year to make these kinds of complicated decisions, and this will be one of its first big cases. So we're joined now by the co-chair of the oversight board, Jamal Greene. He's a professor at Columbia Law School, focusing on constitutional law regulation and public policy. Mr. Greene, welcome back to the program. Thank you for joining us once again. JAMAL GREENE: Thank you for having me. MARTIN: And I do want to mention here that Facebook is one of NPR's financial supporters. So first, let's go back. What went into the decision behind suspending Trump's account on January 7? Was the oversight board involved in making that decision? GREENE: The oversight board was not involved in the initial decision to suspend. That was a decision made by Facebook and on their side. And Facebook says they did it in response to some posts that faced - that President Trump put up on the site. And the oversight board will have to decide whether that was an appropriate response. MARTIN: And is that the way it's supposed to work? I thought that the - so the oversight board is a reactive body, not a prescriptive body? GREENE: That's right. The oversight board does have the power when asked to help Facebook make certain policy decisions. But the kind of meat of our diet is - a content decision is made by the company or by Instagram. And the board decides whether that was appropriate or not and whether the content should go up - back up onto the platform or stay down. MARTIN: I see. Understood. OK. So a Washington Post article recently reported that research - that the research from Zignal found that online misinformation about the election fell significantly, some 73% after sites like Facebook banned then-President Trump. So I understood from your reporting just now that the oversight board was not involved in the initial decision. But are you willing to say now that it was the right decision, knowing what we know now? GREENE: So I'm not in a position yet to judge the case. I'm not going to prejudge it until we actually hear the case. I think it's quite important to make sure that we have all the facts and are in a proper deliberative posture before we make those kinds of decisions. So, you know, we'll work on it as quickly as we can and with as much principle as we can and see where it goes. MARTIN: So talk to me a bit more, if you would, about what those principles are. Can you sort of describe how the board is approaching this question? GREENE: Sure. The board, which is a diverse body of - right now, we're 20 members. We sit in panels, and the panels deliberate about the question of whether content should be removed or not, and in this case, whether a suspension was appropriate or not. And we draw on both the company's own kind of terms of service, which they refer to as their community standards, and whether they were properly applied. But, also, Facebook has what are called values. Voice is a - is one of those values. Safety is one of those values. Dignity is one of those values. And we are also charged with applying those values. And then there's also kind of an external source of information we rely on, which is international human rights law. So that has standards for when and how freedom of expression can be regulated. Facebook has committed to acting consistent with those standards, and so the board is set up to try to apply those international human rights norms to the behavior of the company. MARTIN: So specifically to Donald Trump, does his civilian status - how does his civilian status weigh now? Does the fact that he's no longer president and that he is now a private citizen - does that factor into the decision-making? GREENE: So potentially - and I don't want to get into exactly what factors the board will rely on in the substantive case before we actually, you know, sit and deliberate about it. But any number of kind of contextual factors can matter in cases when freedom of expression has been limited. MARTIN: And is it accurate that you've been asked to put together broad policy recommendations for Facebook on suspensions of political leaders going forward? And - because I'm sure you know that there's been a lot of criticism that Facebook hasn't applied its policies evenly and that, you know, other world leaders, like, for example, President Rodrigo Duterte of the Philippines - the criticism is that he has violated certain Facebook rules as well. So is that also part of your portfolio to put together recommendations going forward for political leaders like president - like the former president, heads of state at that level? GREENE: Yes, that's right. So Facebook, as part of this case, has asked for policy advice that they are obligated to consider as to whether - how their content standards should relate to political leaders. And this is something that has been a challenge for the company and for other platforms in the past, given that political leaders are very differently situated than ordinary citizens. And so that's going to be one of the things that we look into. MARTIN: And I would say that this is the first big decision that your oversight board has had to make. Do you agree? GREENE: I think that this decision will certainly get a lot of attention. We've been working on a number of cases that should come out pretty soon in terms of the opinions that we're going to be issuing. And those are cases from around the world, you know? Facebook has almost 3 billion users, so there are lots of things that happen in the United States that get a lot of attention. But there are also things that happen elsewhere that get lots of attention. So I wouldn't - I don't know that I'd say it's the first big case we've had. All of the cases are important and raise important issues. But I think it's fair to say that this will get a lot of attention. MARTIN: I take your point. And I do recognize your desire not to inflate your own importance in the world. And I also recognize your desire to give international matters the weight that they deserve. But I am just wondering if this feels like a particularly weighty decision and how you are thinking about that. GREENE: Yeah, so we're aware, certainly, of the attention paid to the case. We're aware of how many eyes will be on it. We're aware of the visibility of the case. So I wouldn't - and it is indeed important. It's not just a matter of optics; it's an important decision. And we'll take it with the weight that it deserves. But I think it is also important to point out that that we take cases from around the world and those are important in the corners of the world that they impact. MARTIN: Before we let you go, is this decision binding? Does Facebook have to take your decision, whatever it is? Or is this merely advisory? GREENE: So Facebook has committed to taking the decision of the oversight board as to whether the content should have been removed or not and whether the suspension was appropriate or not. As to whatever policy advice we give to Facebook, it's committed to respond to that in some way, but it's not obligated necessarily to implement exactly what we say as a policy matter. MARTIN: Well, we await your decision. That was Jamal Greene, co-chair of Facebook's oversight board and professor at Columbia Law School. Professor Greene, we thank you so much for joining us once again. We look forward to talking further. GREENE: Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-01-25-960465875": {"title": "Alternative Social Media Platforms Become Popular Among Some Trump Supporters : NPR", "url": "https://www.npr.org/2021/01/25/960465875/alternative-social-media-platforms-become-popular-among-some-trump-supporters", "author": "No author found", "published_date": "2021-01-25", "content": "ARI SHAPIRO, HOST:  Gab, Telegram, MeWe - those are all the names of social media and messaging apps that you might never have heard about. But they are gaining new users by the millions. The apps have gotten a boost since Facebook and Twitter, among others, kicked Donald Trump off and cracked down on groups involved in organizing the assault on the U. S. Capitol. NPR tech correspondent Shannon Bond looks at how one alternative platform is responding to the new attention. SHANNON BOND, BYLINE: It's a social network called MeWe. That's me and we - get it? And in the past few weeks, millions of people have signed up. MARK WEINSTEIN: In 2020, we went from 6 million to 12 million. And now we're already - it's the middle of January, and we're already over 15. 5 million. BOND: Mark Weinstein launched MeWe back in 2016 as an alternative to Facebook, focused on privacy. That means MeWe doesn't harness users' data to sell ads or decide what content to show them. But privacy is not the only reason people are flocking to MeWe right now. Along with other smaller social networks like Gab and messaging apps like Telegram, it's become popular with Trump supporters who are disillusioned with Facebook and Twitter. Cindy Otis tracks online disinformation at the Alethea Group. CINDY OTIS: People are splintering off into these more fringe platforms that essentially have no content moderation or threat monitoring capability whatsoever. BOND: When Facebook banned groups for spreading false claims about election fraud and organizing Stop the Steal rallies, some sent their members to MeWe, Gab and Parler, another alternative social app. Parler recently went down after Amazon refused to host it because there was too much violent content. Weinstein says MeWe is not Parler or Gab. For one thing, he says he's serious about putting limits on what people can say. WEINSTEIN: I'm a firm believer in moderation. I don't like sites that are anything-goes. I've been quoted saying I think they're disgusting. Good people - right and left and middle - can't handle anything goes. We don't want to be around hate speech. We don't want to be around violence-inciters. BOND: MeWe does have rules, but they're more lax than Facebook and Twitter. The big platforms have banned the QAnon conspiracy, for example, a step MeWe has not taken. In fact, Weinstein accuses Facebook and Twitter of political censorship, which the companies deny. And I should note Facebook is among NPR's financial supporters. MeWe says it removes content and accounts that violate its policies. But journalists and researchers have found things like right-wing militias and discussions of shooting people in a Stop the Steal group on MeWe. WEINSTEIN: And yes, you know, right now, with the influx of people - look; social media is messy. Some bad actors get in all over the place. Look at Facebook. Look at Twitter. I think we're much more nimble than they are. BOND: Weinstein is hiring more moderators for his trust and safety team, currently under a hundred people. But experts say all social networks have to get much more serious about addressing harm by setting clear rules and making sure they can enforce them. Megan Squire of Elon University studies online extremists. MEGAN SQUIRE: I think we all still treat social media companies like they're this inexpensive startup. But maybe they need to be treated more like starting an airplane company or a company that makes cars. I mean, you've got to think about a seatbelt. BOND: She says the risk of not having strong online protections is clear. Just look at the insurrection at the Capitol. Shannon Bond, NPR News. (SOUNDBITE OF BRIGHTBLACK MORNING LIGHT SONG, \"EVERYBODY DAYLIGHT\") ARI SHAPIRO, HOST:   Gab, Telegram, MeWe - those are all the names of social media and messaging apps that you might never have heard about. But they are gaining new users by the millions. The apps have gotten a boost since Facebook and Twitter, among others, kicked Donald Trump off and cracked down on groups involved in organizing the assault on the U. S. Capitol. NPR tech correspondent Shannon Bond looks at how one alternative platform is responding to the new attention. SHANNON BOND, BYLINE: It's a social network called MeWe. That's me and we - get it? And in the past few weeks, millions of people have signed up. MARK WEINSTEIN: In 2020, we went from 6 million to 12 million. And now we're already - it's the middle of January, and we're already over 15. 5 million. BOND: Mark Weinstein launched MeWe back in 2016 as an alternative to Facebook, focused on privacy. That means MeWe doesn't harness users' data to sell ads or decide what content to show them. But privacy is not the only reason people are flocking to MeWe right now. Along with other smaller social networks like Gab and messaging apps like Telegram, it's become popular with Trump supporters who are disillusioned with Facebook and Twitter. Cindy Otis tracks online disinformation at the Alethea Group. CINDY OTIS: People are splintering off into these more fringe platforms that essentially have no content moderation or threat monitoring capability whatsoever. BOND: When Facebook banned groups for spreading false claims about election fraud and organizing Stop the Steal rallies, some sent their members to MeWe, Gab and Parler, another alternative social app. Parler recently went down after Amazon refused to host it because there was too much violent content. Weinstein says MeWe is not Parler or Gab. For one thing, he says he's serious about putting limits on what people can say. WEINSTEIN: I'm a firm believer in moderation. I don't like sites that are anything-goes. I've been quoted saying I think they're disgusting. Good people - right and left and middle - can't handle anything goes. We don't want to be around hate speech. We don't want to be around violence-inciters. BOND: MeWe does have rules, but they're more lax than Facebook and Twitter. The big platforms have banned the QAnon conspiracy, for example, a step MeWe has not taken. In fact, Weinstein accuses Facebook and Twitter of political censorship, which the companies deny. And I should note Facebook is among NPR's financial supporters. MeWe says it removes content and accounts that violate its policies. But journalists and researchers have found things like right-wing militias and discussions of shooting people in a Stop the Steal group on MeWe. WEINSTEIN: And yes, you know, right now, with the influx of people - look; social media is messy. Some bad actors get in all over the place. Look at Facebook. Look at Twitter. I think we're much more nimble than they are. BOND: Weinstein is hiring more moderators for his trust and safety team, currently under a hundred people. But experts say all social networks have to get much more serious about addressing harm by setting clear rules and making sure they can enforce them. Megan Squire of Elon University studies online extremists. MEGAN SQUIRE: I think we all still treat social media companies like they're this inexpensive startup. But maybe they need to be treated more like starting an airplane company or a company that makes cars. I mean, you've got to think about a seatbelt. BOND: She says the risk of not having strong online protections is clear. Just look at the insurrection at the Capitol. Shannon Bond, NPR News. (SOUNDBITE OF BRIGHTBLACK MORNING LIGHT SONG, \"EVERYBODY DAYLIGHT\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-01-26-960855949": {"title": "With Few Details From Health Officials, Volunteers Create COVID-19 Vaccine Database : NPR", "url": "https://www.npr.org/2021/01/26/960855949/with-few-details-from-health-officials-volunteers-create-covid-19-vaccine-databa", "author": "No author found", "published_date": "2021-01-26", "content": "ARI SHAPIRO, HOST:  The vaccine rollout across the country continues to flail. California has administered only about half the COVID-19 shots available in the state. That's why a bunch of volunteer tech workers are stepping in to provide information when the government doesn't. Lesley McClurg of member station KQED explains. LESLEY MCCLURG, BYLINE: A few weeks ago, Tim Schwartz was watching the nightly news. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED REPORTER: New guidelines will be issued today that will expand vaccine eligibility to everyone. . . MCCLURG: Schwartz suddenly qualified for a shot. He's a 67-year-old resident of San Francisco, but he had no idea how to get one. TIM SCHWARTZ: Nobody's calling me, emailing me, telling I'm eligible for anything. MCCLURG: He checked his doctor's office, but they weren't vaccinating people his age. So he went down to his local pharmacist and asked if they were offering shots. SCHWARTZ: And he said no. He had heard from corporate - Walgreens' corporate office that they might in the future get it. MCCLURG: Schwartz started scouring the Internet but to no avail. Even California's public health website didn't provide any links to drive-up sites, walk-up appointments or even a help desk. SCHWARTZ: Oh, it's frustrating that in one of the most tech-savvy cities in the most tech-savvy country in the world that this kind of information is not available to the residents. MCCLURG: Also frustrated by the situation is Patrick McKenzie. He's a tech worker based in Tokyo with ties to California. He was floored that vaccines were sitting on shelves rather than saving lives. PATRICK MCKENZIE: So I tweeted out on Twitter and said, one of the best things that I could imagine a technologist spending time on right now is calling the places that could have the vaccine and putting who says yes in a single place. MCCLURG: The call to arms roused many of McKenzie's followers, which is a hundred thousand people. A group of really smart folks started designing a dashboard immediately. A few hours later, McKenzie checked in on his friends. MCKENZIE: This is all fantastic. You know, just one thing, though - when you're doing the call center management, I have some suggestions. And then one thing led to another. MCCLURG: They launched a website the next morning. Less than a week later, 250 volunteers were calling hundreds of doctors and pharmacists across the state every day. One afternoon, they found 60 new places offering shots just in Los Angeles. Their dashboard, called VaccinateCA, offers up-to-date information about where supplies exist, who qualifies and how to make an appointment. Similar efforts are underway in Michigan, Georgia and Pennsylvania. Throughout the pandemic, private citizens have offered everything from case tallies to risk calculators. GEORGES BENJAMIN: If you go to those sites, you get much more accurate data in a more timely way than even the federal government's delivering, at least today. MCCLURG: Dr. Georges Benjamin is the executive director of the American Public Health Association. BENJAMIN: I think this citizen engagement is here to stay. MCCLURG: Though he stresses crowdsourcing has its limitations. Without regulation, no one is checking to see if information stays accurate or up to date. Plus, it's only available to people with access to technology. Benjamin stresses the vaccine rollout will flail until better information is available for everyone. BENJAMIN: So that means communicating with trusted messengers. That means flyers. That means radio, TV. That means social media. MCCLURG: He hopes the new Biden administration leads communication efforts from the federal level rather than rely on underfunded local health departments. In the meantime, society is depending on volunteers like tech worker Patrick McKenzie to fill the government's void of reliable information. MCKENZIE: I have never worked on anything that feels as important as what we have done in the last week, and I hope that we are able to do it much faster over the next week. MCCLURG: He says his team will keep working day and night as long as their effort ensures more people get their shots. For NPR News, I'm Lesley McClurg in San Francisco. (SOUNDBITE OF MUSIC) ARI SHAPIRO, HOST:   The vaccine rollout across the country continues to flail. California has administered only about half the COVID-19 shots available in the state. That's why a bunch of volunteer tech workers are stepping in to provide information when the government doesn't. Lesley McClurg of member station KQED explains. LESLEY MCCLURG, BYLINE: A few weeks ago, Tim Schwartz was watching the nightly news. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED REPORTER: New guidelines will be issued today that will expand vaccine eligibility to everyone. . . MCCLURG: Schwartz suddenly qualified for a shot. He's a 67-year-old resident of San Francisco, but he had no idea how to get one. TIM SCHWARTZ: Nobody's calling me, emailing me, telling I'm eligible for anything. MCCLURG: He checked his doctor's office, but they weren't vaccinating people his age. So he went down to his local pharmacist and asked if they were offering shots. SCHWARTZ: And he said no. He had heard from corporate - Walgreens' corporate office that they might in the future get it. MCCLURG: Schwartz started scouring the Internet but to no avail. Even California's public health website didn't provide any links to drive-up sites, walk-up appointments or even a help desk. SCHWARTZ: Oh, it's frustrating that in one of the most tech-savvy cities in the most tech-savvy country in the world that this kind of information is not available to the residents. MCCLURG: Also frustrated by the situation is Patrick McKenzie. He's a tech worker based in Tokyo with ties to California. He was floored that vaccines were sitting on shelves rather than saving lives. PATRICK MCKENZIE: So I tweeted out on Twitter and said, one of the best things that I could imagine a technologist spending time on right now is calling the places that could have the vaccine and putting who says yes in a single place. MCCLURG: The call to arms roused many of McKenzie's followers, which is a hundred thousand people. A group of really smart folks started designing a dashboard immediately. A few hours later, McKenzie checked in on his friends. MCKENZIE: This is all fantastic. You know, just one thing, though - when you're doing the call center management, I have some suggestions. And then one thing led to another. MCCLURG: They launched a website the next morning. Less than a week later, 250 volunteers were calling hundreds of doctors and pharmacists across the state every day. One afternoon, they found 60 new places offering shots just in Los Angeles. Their dashboard, called VaccinateCA, offers up-to-date information about where supplies exist, who qualifies and how to make an appointment. Similar efforts are underway in Michigan, Georgia and Pennsylvania. Throughout the pandemic, private citizens have offered everything from case tallies to risk calculators. GEORGES BENJAMIN: If you go to those sites, you get much more accurate data in a more timely way than even the federal government's delivering, at least today. MCCLURG: Dr. Georges Benjamin is the executive director of the American Public Health Association. BENJAMIN: I think this citizen engagement is here to stay. MCCLURG: Though he stresses crowdsourcing has its limitations. Without regulation, no one is checking to see if information stays accurate or up to date. Plus, it's only available to people with access to technology. Benjamin stresses the vaccine rollout will flail until better information is available for everyone. BENJAMIN: So that means communicating with trusted messengers. That means flyers. That means radio, TV. That means social media. MCCLURG: He hopes the new Biden administration leads communication efforts from the federal level rather than rely on underfunded local health departments. In the meantime, society is depending on volunteers like tech worker Patrick McKenzie to fill the government's void of reliable information. MCKENZIE: I have never worked on anything that feels as important as what we have done in the last week, and I hope that we are able to do it much faster over the next week. MCCLURG: He says his team will keep working day and night as long as their effort ensures more people get their shots. For NPR News, I'm Lesley McClurg in San Francisco. (SOUNDBITE OF MUSIC)", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-01-26-960679189": {"title": "My Pillow CEO Mike Lindell Permanently Suspended From Twitter : NPR", "url": "https://www.npr.org/2021/01/26/960679189/my-pillow-ceo-mike-lindell-permanently-suspended-from-twitter", "author": "No author found", "published_date": "2021-01-26", "content": "", "section": "Technology", "disclaimer": ""}, "2021-01-27-961103187": {"title": "Surveillance And Local Police: How Technology Is Evolving Faster Than Regulation : NPR", "url": "https://www.npr.org/2021/01/27/961103187/surveillance-and-local-police-how-technology-is-evolving-faster-than-regulation", "author": "No author found", "published_date": "2021-01-27", "content": "DAVE DAVIES, HOST:  This is FRESH AIR. I'm Dave Davies, in for Terry Gross, who's off this week. By now, many of us are used to the idea that American intelligence services, such as the National Security Agency, have enormous capacities to track our phone calls, emails and movements, and we hope that rational and constitutional rules for their use are set by our elected leaders. But our guest, journalist Jon Fasman, says most of us don't realize that thousands of police departments across the country also have access to some really powerful surveillance tools with relatively little oversight. There are devices that scan and store the locations of thousands of auto license plates they encounter randomly on the street, portable gadgets called Stingrays that electronically mimic a cellphone tower and get every mobile phone within range to yield its data and cameras - cameras everywhere, increasingly with facial recognition software. Fasman's new book explores these new technologies, the questions they raise about privacy and the controls he believes citizens should impose on the agencies that use them. His book is \"We See It All: Liberty And Justice In An Age Of Perpetual Surveillance. \"Jon Fasman is the U. S. digital editor for The Economist and the author of two novels. He joins me from his home in suburban New York. Jon Fasman, welcome to FRESH AIR. You know, this book raises a lot of skeptical questions about law enforcement. And I'd like to begin by just having you explain what kind of time you spent with police officers and police chiefs and sheriffs and others, observing their practice and getting their point of view. JON FASMAN: Well, over the course of my reporting, going back to 2010, when I was the Atlanta correspondent for The Economist, I've written a great deal about criminal justice issues. And I've embedded with a number of departments over the past decade. For this book in particular, I probably spent the most time with the LAPD. I went out with their patrol division, and I spent time with Sean Malinowski, who was then an assistant chief, learning about a predictive policing program they use called PredPol. And we can talk about that later. I also embedded for several days with the Newark Police Department to learn about how technology is used by police officers in their day-to-day jobs. So one of the challenges in writing about this is that I would hear about this technology from tech companies and from police chiefs from a sort of 30,000-foot view. But I really wanted to see how police officers, as they work, integrate technology into their daily jobs, how it changes the sort of practice of being a police officer. DAVIES: OK, so let's talk about some of these technologies. One of the things, of course, that people are aware of is video surveillance. I mean, there are, you know, security cameras in so many places that police typically consult after there are crimes in given areas. But you're looking at ways that this is being expanded. And particularly in Newark, N. J. , police have something called Citizen Virtual Patrol. You want to explain what this is, how it works? FASMAN: Sure. The Citizen Virtual Patrol is a network of cameras placed throughout the city. These are public cameras. Now, one of the things when you talk about CCTV cameras, the overwhelming majority of them are privately owned. But these - the Citizen Virtual Patrol is a network composed of publicly owned cameras that people can access from a laptop. Now, the idea behind this was to sort of allow people to observe and perhaps testify to crimes from behind a veil of anonymity. So it gives people an eye on the entire city. It lets people see what's going on. DAVIES: And, Jon, when you say people, you mean just ordinary citizens. Anybody can dial up and look through these cameras. FASMAN: So that's right. A citizen anywhere can log in to the Citizen Virtual Patrol of Newark. So if I live about 50 miles north of Newark, and I can log in at my desk and see the feed from any one of the 126 cameras that the Newark Public Safety Department has placed around the city. DAVIES: That seems a little intrusive, right? I mean, somebody who just wants to be a busybody - I guess other people would say it's no different from looking out a window, right? You're not peeping into somebody's apartment. What concerns does this raise? FASMAN: That's right. Technically, the cameras don't show anything that an observer on the street couldn't see. So it shows public streets. It's not aimed at anyone's apartment. It's not looking inside anyone's window. On the other hand, it does show people's yards, where they have a slightly higher expectation of privacy, and it could provide some information that people wouldn't want known about them. For instance, if I'm - you know, let's say I had an ex who lived in Newark, and I was watching the camera trained on her house. If I saw her leave with some suitcases and then saw no activity at her house for a couple of days, I could surmise that she wasn't there. I could also know when she goes out, when she comes home, who comes to her house, all these things that, of course, I could find out if I observed her in front of her house, but that would make me visible. This renders me invisible. And it lets me observe, lets anyone who logs in observe an enormous swath of the city. So that's another thing I think we need to think about when we're thinking of police technologies, and that is that any single instance may be unobjectionable. But when it comes to scale, you're talking about something very different. DAVIES: Do the police think that it's been helpful? Have there been any complaints or any notable benefits to, you know, to law enforcement from having all of these windows on the street? FASMAN: The police do think it's been helpful. The police think it helps people keep an eye on their neighborhood. I think the idea was that a citizen of a certain neighborhood could keep an eye on what was happening around her without sort of making herself known to other people around her as someone who was watching. So it lets her keep an eye on what's happening around her behind that veil of anonymity. And the Newark police think that's good for public safety. On the other hand, I spoke to the director Amol Sinha, who's the director of the ACLU of New Jersey, who made the same point that I just made, that what we're talking about is, at scale, quite different. And the cameras sort of give information about people and their private activities that you wouldn't necessarily want to know and that if you did try to find out, you would be observed. This lets you do so anonymously and invisibly. And that anonymity and invisibility has, you know, benefits, according to the Newark police, and also detriments, according to the ACLU. DAVIES: Also in the United States, we're seeing the use of automatic license plate readers, which is - I confess I was not aware of this. Describe what these things are, how big they are, who uses them, what they do. FASMAN: Well, these things are small cameras that attach to police cars. They're things you really wouldn't see unless you were looking for them. They're sort of little, flat cameras either on the front or on the roof of the police car. And what they do is as they pass, they capture an image of each license plate, and they translate that image into just plain letters and numbers. They log the geospatial data, so where the car was and what time it was observed. And it just goes into a - it goes into a database. And so, again, the issue with that is one of scale. There is nothing illegal about the police noting the license plate of cars parked in public, where they were parked, when they were parked there. But if you look down your street and you saw a police officer writing down every license plate all day, every day, you might wonder why he was doing that. A police department, if they had to assign people to do that, might wonder whether it was worth it - right? - whether it was worth the manpower to have someone just noting down license plates. But what these ALPRs do is they obviate those decisions. They make it extremely easy and extremely cheap to always be taking pictures of where cars were at any one time. And unless you live in one of the very few public cities in which you don't need to have a car because public transport is so reliable, then this essentially lets police put together a very granular, sort of detailed roster of where you go and when you go and who you see. And again, this is the sort of thing that they could do. There's nothing illegal about it. But it's a question of what people want from the state. Do they want to have that information on file all the time? DAVIES: So let me make sure I understand this. So police cars that have these license plate readers drive down the street, and they automatically just pick up every license plate within range and. . . FASMAN: Yeah. DAVIES: . . . Feed it into the database. Now, if it finds that there's a stolen car among them, does it flag it or is it simply going into a database? FASMAN: If it finds that the car is stolen or is associated with a crime, then it does flag it. And that's the justification that police departments give. And it's a good justification. I'm not suggesting and writing about the dangers of ALPRs that we eliminate them because it does help find stolen cars. It does help find cars used in crimes. The issue is, what about the 99. 99% of cars that aren't involved in crimes? What do you do with their data? So states have wildly different laws on how long that data can be kept. In New Hampshire, for instance, if the car is not associated with any crime or is not being looked for, then you've got to delete it within three minutes. There are other states that set 24-hour limits. But there are a lot of states that set no limits at all. And they just throw these pictures into a huge database. Often, those databases are poorly secured. So in 2015, there was a journalist who just stumbled onto the Boston Police Department's entire database of ALPR data. It's that sort of thing - the collection at scale, the lack of regulations over how long the information is kept and, often, the lack of security over how it's kept that combine to make these sorts of technologies really worrying. DAVIES: So I can imagine abuse. I mean, if I were stalking someone, you know, someone I'd had a relationship with or someone who's spurned my advances and I get access to this, I can see where they go, where they are all the time, what kind of people they frequent. I could also see police saying, well, after, you know, there's been a terrible crime committed and we've identified a suspect, if they're associated with a license plate, we can look through this huge, searchable mass of data and see, aha, this is where their friends are. Aha, that's where they might just be. Is it used in these ways? FASMAN: That is how it's often used. And you're right to highlight the threat of abuse. I mean, the other threat I can think of is let's say there is a demonstration against police brutality. And there is an individual officer who takes issue with the statements, First Amendment-protected activity, of a certain protester. That officer can then access, in some cases, ALPR data and find out where the person goes, who he sees. He can then basically reverse time and look and see if the car has done anything illegal, has been anywhere it shouldn't have been. And it's that sort of thing, the information it lets police build and store for later use that worries me. DAVIES: So your take is, if you scoop all this stuff up, if the license plates show no reason for retention, it has to be scrapped quickly, right? And the rules are all over the place? FASMAN: The rules are all over the place with a lot of this technology because it's so new, because it changes so quickly. And the rules are all over the place. The degree of oversight that individual police departments have is all over the place. In general, you know, even when there are regulations, there often aren't penalties for violating them or not strong enough penalties. And so it's that sort of thing. This is not - I have not written an anti-technology book. I have written a pro-democracy, pro-regulation book. DAVIES: We need to take a break here. Let me reintroduce you. We are speaking with Jon Fasman. He is the U. S. digital editor for The Economist. His new book is \"We See It All: Liberty And Justice In An Age Of Perpetual Surveillance. \" We'll continue our conversation in just a moment. This is FRESH AIR. (SOUNDBITE OF JOAN JEANRENAUD'S \"AXIS\")DAVIES: This is FRESH AIR. And we're speaking with Jon Fasman. He is the U. S. digital editor for The Economist magazine. He has a new book which explores cutting-edge surveillance technologies employed by local police departments, often with little oversight. The book is called \"We See It All. \" You also write about a technology called ShotSpotter. Tell us about this. FASMAN: ShotSpotter is an acoustic sensor designed to detect the sound of gunshots. And these - I saw these in place in Newark, N. J. They often look like little, white diamonds or rectangles up on traffic light poles. And they're trained to recognize what ShotSpotter calls loud, impulsive sounds between 120 and 160 decibels. When it does hear such a sound, it sends an alert to the ShotSpotter headquarters where a human listens to it and figures out, was that a gunshot? Was it a car backfiring? When I was at ShotSpotter's headquarters in California, there was an alert caused by a truck's Jake Brake, you know, the engine brake that releases a tremendous amount of sound quite quickly. Once it hears a gunshot, it notifies the local police department. It tells the police department how many shots, where, when. And it, essentially, can dispatch officers to a - to the scene of a suspected shooting. DAVIES: Right. Now, that sounds like it would be valuable. I mean, a lot of times, people hear gunshots and don't report them. And if police can get quickly to the scene of a shooting, it would seem there's more chances of either saving a life, apprehending a suspect, assisting a victim. How - what's the record on its performance? FASMAN: The record on its performance is OK, I think. I mean, I'm just judging it by what the company itself has told me, which is that it has solved crimes. It has helped identify shooters and shootings. There are some places that have had less luck with it than others. But in general, it does seem to dispatch officers to a shooting. Now, I was with the Newark Police Department when we got dispatched to two shootings by ShotSpotter. And when we got there, there was nobody there. Now, it's not a panacea, obviously. But it does seem to get police officers to the scene of a shooting. And you're right, the number of gunshots that result in actual police calls is quite low. I think it's something like 9%. And so this is a way of alerting police that a shooting has happened without waiting for someone to call it in. DAVIES: All right. So what might give you pause about recommending this for a department? What are the drawbacks or concerns? FASMAN: Here's what I think is interesting about ShotSpotter. As I was reporting this story, I - you know, I talked to people on buses, trains and cabs. In multiple cities, multiple people from, you know, cab drivers, just people I was sitting next to on trains, people I talked to on the street, a lot of people believed that this sort of technology was being used to overhear private conversations. Now, I think that is extremely unlikely. I think there's - to my knowledge, there's never been a case that's been brought based on a conversation overheard by ShotSpotter. Every police department, everyone from ShotSpotter said it doesn't hear conversations. It's trained to recognize loud, sudden sounds. That's not how people talk. But it's an instructive lesson in how deploying technology can be used to improve or worsen relations between police and the communities they police. I think that in too many instances, police departments approve the purchase of ShotSpotter and deploy them without doing the work of going into communities they police and saying, listen; this is what's going up on these traffic lights. Here is how it works. It doesn't hear conversation. Here's how we know it doesn't hear conversation. If you have any questions about it, please, come and talk to me - as opposed to just citizens, who often come from communities that have a long history of distrust with police built up over years for valid reasons, as opposed to those communities just seeing another piece of tech up there. I mean, you can imagine it yourself. If you were a citizen of color who lived in a community that had a long history of distrust with the police and all of a sudden the police said this hears gunshots, you might think to yourself, what else does it hear, you know? And so it's an instruction - one of the things that I point out in my book is that technology is not good or bad in itself. But police have to be very careful about how they roll it out, have to go out of the way to gain the trust of the public, particularly in those communities that have a long history of distrust of the police. DAVIES: You also write about another device. This is something I had never heard of. I guess the trade name is Stingray for this thing. It's a device that can simulate a cellphone tower so that when you're driving by it, your cellphone thinks it's a mobile phone tower and connects with it. What happens then? FASMAN: Well, once your phone connects with one of these things - the trade name is Stingray. The technical term is IMSI-catcher. IMSI stands for international mobile subscriber information. Every mobile phone has a unique number. And it's that number that identifies itself to the cellphone tower to let the tower know that, hey, this is, you know, Dave Davies' phone. So if you have any messages or texts for Dave Davies, send it to this phone. And IMSI-catcher or Stingray mimics a cellphone tower. And it gets your phone to connect to it. And what happens then is that all of the metadata on your phone, that is the non-voice call data, can then be read. And that includes texts you might send, websites you might browse, who you called and how long you talked for even without knowing the actual substance of the conversation. All of that sort of thing connects to the phone. DAVIES: And does it geolocate you, too? Does it tell. . . FASMAN: Yes, and it tells you - it geolocates you. DAVIES: So what do the police do with this information when they get it? And they must be getting thousands and thousands of cellphones coming in contact with this thing, right? FASMAN: Yeah. And again, increasingly, it's deployed by court order. But that hasn't always been the case. And what happens is even when deployed by court order against a specific subject, the data from every other phone in that area is hoovered up. Now, again, this happens on a stakeout, too, right? If the police are staking out a suspect, they see all kinds of people walking past. The difference is they don't retain the data from all those people walking past. In the case of data hoovered up by Stingrays, that often does get kept for longer than it should. And again, this is an issue in which there's no question that Stingrays can help police catch serious criminals. But there just needs to be some regulations over when they can be used and what happens to the data hoovered up incidentally during those stakeouts. DAVIES: Do these things have to be mounted on towers? FASMAN: No, they do not. They fit in the trunk of a car. They're quite small. They're sort of suitcase-sized. DAVIES: So the typical way it might be used is the police wants to track someone who they suspect is a, you know, major drug dealer or a suspect in a homicide. And they find a spot near that person and wait for the cellphone to interact with the Stingray? FASMAN: That's right. And they're probably just paying attention to that actual cell data. But there's a lot of other data that's taken up in response. I should say, another thing that's striking about Stingrays is that their use is really shrouded in secrecy. So everything that I know about them, everything that we know about them, comes from FOIA requests, comes from court documents. Often, police that use a Stingray, they have to sign a nondisclosure agreement so they won't talk about whether they have it, how it's used. I obviously wrote to the company for an interview. They declined. So its use is quite shrouded in secrecy. DAVIES: OK. But when they scoop up all this other data about hundreds or thousands of other cellphones, does that get retained? Do we know? FASMAN: We don't know for sure. It could get retained. It could get thrown away. This is, again, one of the issues I'm concerned about is we just need transparency in where that data is stored, how it's used. And there need to be limits that communities set for the police and what they can do with it. DAVIES: So this is sort of a gray area of the law. I mean, can departments just set these things up without going to court and getting a warrant? FASMAN: I mean, this - all of this technology that I write about is a gray area of the law because it is so new. So there is often - increasingly, there's pressure from groups like the American Civil Liberties Union, the Electronic Frontier Foundation and groups that are really concerned about the dangers I write about. They have succeeded, I think, in getting some information released to the public. But again, because this technology is new, because we have historically been reluctant to regulate the police, all of these emerging technologies, it's all a legal gray area. DAVIES: Jon Fasman is the U. S. digital editor for The Economist. His new book is \"We See It All: Liberty And Justice In An Age Of Perpetual Surveillance. \" He'll be back to talk more after a break. And David Bianculli reviews the new four-part documentary series from HBO, \"The Lady And The Dale. \" I'm Dave Davies. And this is FRESH AIR. (SOUNDBITE OF MUSIC)DAVIES: This is FRESH AIR. I'm Dave Davies, in for Terry Gross, who's off this week. We're speaking with Jon Fasman, the U. S. digital editor for The Economist magazine. His new book explores cutting-edge surveillance technologies increasingly employed by local police departments around the country, often with little oversight. His book is \"We See It All: Liberty And Justice In An Age Of Perpetual Surveillance\" (ph). One technology that's not so new, but you describe some interesting uses by the police department, are drones. And you describe this pilot program by the Baltimore Police Department. You want to describe what they did, and, you know, what this company does that provide the service? FASMAN: Sure. So the Baltimore Police Department used a company called Persistent Surveillance. And this is a technology that was born on the battlefields in Iraq, in Fallujah. The military wanted to catch people who were leaving IEDs by the side of the road. So what an engineer - there's an engineer named Ross McNutt, naval engineer. He attached low-res cameras to drones and set them to fly over huge swaths of the city sort of in loops. So it actually did keep the city under persistent surveillance. And what they found is that when an IED went off, they could locate the footage and then essentially rewind it. So they could see who planted it, where they came from, where they talked to - who they talked to, where they lived and can solve the crime that way. The BPD decided to use a pilot program and set it over, I think, a huge, sizable swath of East Baltimore. Now, I have seen what this footage looks like, and it is absolutely true that you can't tell a single thing about a single person from the footage. Everybody just looks like little dots. The way BPD used it is it was only in response to a reported crime. So, you know, a shooting or a carjacking, they would locate that incident and basically rewind it and see who did what. It was used to solve killings in Juarez, when Juarez was in the middle of its crime wave. So it's true that - you know, Ross McNutt was very, very adamant that you can't tell anything about any one person, and they are not using it to identify people. But that's certainly a way it could be used, right? What happens if another company attaches better resolution cameras to drones and has them fly lower? What happens if when that happens, you have a police chief who is upset about an anti-police brutality demonstration and decides to rewind the camera on the organizers of that demonstration to see what they might have done that they might be able to be picked up for? It's that sort of thing, even if the current instance of persistent surveillance is not terribly alarming. And again, by not terribly alarming, I mean, even if citizens of a certain city are not alarmed by the prospect that having been committed - having been accused of no crime, they may be observed all the time. Even if this incarnation doesn't let police see who they are, there's nothing stopping another company from doing something that would allow police to track people and observe people all the time. DAVIES: And even if people are represented as dots, I mean, you can imagine misuses, too. If I'm, you know. . . FASMAN: Of course. DAVIES: . . . Stalking my ex-wife, I know her address. I see the dot coming out of her place, and then I see where she's headed. I mean, the interesting thing about this thing in Baltimore was that they didn't announce it to the public and it was revealed in the media. The reaction was substantial, right? FASMAN: Yeah, it was substantial. And this is another problem with technology that I write about. It's how police roll it out that often matters. So, you know, it was a newspaper that broke the story that, you know, the entire east side of Baltimore was under perpetual surveillance. Of course, citizens were outraged. I would be, too. Now, that pilot program stopped, and BPD reintroduced it. And they reintroduced it after extensive public hearings and extensive public discussion. And that suggests that there is, in fact, a difference between a police department saying to itself, hey, let's try this and see how it works, and a police department going to the public and saying, this is what we'd like to do. This is how the tech works. This is what the data is. This is who gets to see it. This is how long we're keeping it. What do you guys think? And then work through with the public what they want, what they're comfortable with, what is acceptable to them. When that happens, this technology that is quite frightening can often be, you know, acceptable to people. DAVIES: And I guess it bears noting that in Baltimore and many big cities, a lot of shootings and murders go unsolved. So information that tracks where a shooter went could be valuable. Do we know anything about how useful it's been? FASMAN: I have not looked into that. I should look into that. But I want to make one point about efficacy as justification. There are a whole lot of things that would help police solve more crimes that are incompatible with living in a free society. The suspension of habeas corpus would probably help police solve more crimes. Keeping everyone under observation all the time would help police solve more crimes. Allowing detention without trial might help the police solve more crimes. But all of these things are incompatible with living in a free, open, liberal democracy. So when we think about these technologies and what we are willing to accept, we shouldn't just think about whether it'll help police solve more crimes because almost all of them will, at least on the margins. The question is, is it worth the cost to our privacy and liberty to implement this technology? And if so, what limits are we willing to set? What penalties do we want for failing to observe these limits? So it's really a question not just of whether the technology works, but is it worth the cost. And if it's not worth the cost, can we devise a way in which the police can have the tool that they want to solve crimes, and we can be comforted that it won't be abused, it won't be used against us, it won't be used to surveil us. DAVIES: We're speaking with Jon Fasman. He is the U. S. digital editor for The Economist magazine. His new book about police surveillance is called \"We See It All. \" We'll continue our conversation in just a moment. This is FRESH AIR. (SOUNDBITE OF AVISHAI COHEN'S \"GBEDE TEMIN\")DAVIES: This is FRESH AIR. And we're speaking with Jon Fasman. He is the U. S. digital editor for The Economist magazine. He has a new book about cutting-edge technologies used by police departments in surveillance efforts. It's called \"We See It All: Liberty And Justice In An Age Of Perpetual Surveillance\" (ph). You write a lot about facial recognition, which is a technology that's getting better and better. It obviously poses some issues in terms of privacy. And you know - and police will typically say they don't use facial recognition as evidence in court. They use it for tips and leads. Typical situation - a serious crime is committed - you know, an assault, a shooting - security cameras catch somebody in the area. They use facial recognition to compare that to a database of mug shots. They find a suspect, and then they bring the victim before a lineup in which the suspect is there or a, you know, a photo lineup - an array of mug shots. Seems like not an unreasonable set of things to do, potentially useful. What is the concern about the way departments are using this? FASMAN: I think there are a few concerns. One of them is about how departments use it and whether they really are hewing to that principle that they profess that this is just a lead, this is not evidence. So what does it mean when a facial recognition system generates a match? It means that the system is telling you this person on camera is probably this person, the mug shot. Now, generally, these systems will generate a list of, you know, 20, 30, 40 possible matches ranked in order. What does it mean if the police catch the 30th person on that list as opposed to the second person on the list? How did they eliminate everyone else? I think another concern is that facial recognition systems, as they exist right now in the United States and Europe, are really bad at recognizing nonwhite people. And that is, I think, partly an artifact of the list of the range of images that they were trained on. But what that means is nonwhite people often run the risk of being falsely identified and, therefore, if not falsely accused, then at least brought into contact with law enforcement in a way that white citizens are not as often. Also, because of the history of overpolicing communities of color, there's the risk that databases will be more filled with nonwhite suspects than white suspects so that a nonwhite suspect stands a greater chance of being identified in a database than a white suspect does. I think that, then, until facial recognition can solve the problem of bias in this case, then we should be very, very suspicious of its deployment. I think we may even want to be sort of cautious about how it's deployed afterward. Now, that is not a call to ban facial recognition entirely. There is a facial recognition system called Clearview that was used to identify a number of suspects in the Capitol insurrection. I think that is all to the good. The question, though, is what about the rest of us? What about our anonymity in public? What about our being put into databases without our consent? What does that mean for our privacy? DAVIES: Right. What - who are in the photo databases that law enforcement uses to compare images that they pick up? I mean, people who have been arrested have mug shots. I mean, again, some of them may have never been convicted. What about things like - I don't know - driver's license photos? Are they used to look for matches? FASMAN: Yes, they are used to look for matches often. As early as 2016, there is a study from Georgetown Law school that found that 1 in every 2 Americans had their faces in an FBI-accessible facial recognition database. That has almost certainly gone up since then. Also, the system that the police use to identify Capitol Hill rioters was called Clearview. One concern with Clearview, though, is that it is not just available to police departments. It is - or it was at some point - available to investors and to some private citizens as well. What this essentially means is that you can't really be sure that you're anonymous in public anymore. So there is a story about a New York City grocery magnate who saw his daughter out on a date with someone, wanted to know who it was, snapped a picture of the guy. And immediately, he knew who the guy was, where he worked, where he lived, that sort of thing. So that's, I think, what's worrying about unregulated facial recognition is the extent to which it imperils your ability to be anonymous in public. DAVIES: You know, it's now used by some airlines for entering, you know, planes there at the gate. Right? Rather than going through and scanning your boarding pass, you can just show them your face. You've encountered that. Your advice is don't do this, don't normalize this. Why? FASMAN: That is my advice. I never, ever use facial recognition to board at gate. And I would advise anyone else who is concerned about our civil liberties not to do it. And that's not because you run some great risk of being, you know, pulled off a plane and detained falsely when you board a plane. It is because the more you opt to use facial recognition in ways that you think are benign, the more it will be used in ways that you may not think are benign. So the reason to avoid using facial recognition to board a plane is that you don't want to normalize this technology at this stage of its existence. You don't want to normalize the fact that your face is - becomes sort of your passport and everywhere you go, you're tracked and recorded. You want to do your best - or at least I think people concerned about civil liberties should want to do their best to make sure that this technology is only used in a specific set of circumstances and a specific set of ways. DAVIES: Another thing you write about is the use of algorithms by courts and police departments. One reason is to decide who ought to be held on bail. You have all these factors - you know, the defendant's past criminal record, age, et cetera. And then there are also algorithms that are designed to guide departments on where to emphasize police patrols. What are your concerns about this kind of technology? It's not exactly surveillance. FASMAN: It's not exactly surveillance. My concern about predictive policing programs - and what I mean by that are these are programs that ingest an enormous amount of historical crime data and say, based on the data, based on past practice, these are the areas that we think are likely to be at elevated risk for crime today. So this is where you need to deploy your patrol officers. My concern about that is that historical crime data is not an objective record of all crimes committed in a city. It is a record of crimes that the police know about. And given the sort of historic pattern of overpolicing minority communities, overpolicing poor communities, these programs run the risk of essentially calcifying past racial biases into current practices. One of the justifications for these programs is that they remove sort of human error, they remove human bias and they're just using data. And you know, it is true that they are not as reliant on human interpretation as sort of past practices may have been. But I think it's important for people to understand there isn't really any such thing as just data. So if one of these predictive policing programs ingests and makes recommendations based on, you know, nuisance crimes, vagrancy, public drinking, things that only get prosecuted because the police are there and police are more present in minority communities and prosecute these sorts of crimes more often there, then you will get a program that essentially is a pernicious feedback loop of racial bias. DAVIES: The overriding theme of your book is that, you know, we're not going to roll back technology. It is here, but we as a democracy need to understand it and impose controls that preserve our civil liberties and, you know, balance that against the legitimate needs of law enforcement. And you cite a potential model here, and that's Oakland, Calif. , which certainly has a troubled history between its police department and African American activist organizations. The - this process began with the Port of Oakland wanting to adopt a high-tech security system. What happened then? FASMAN: That's right. So this is back in 2014. And the port - I think it's called the Domain Awareness System. The port wanted to basically integrate camera feeds from all different city systems - police, fire, public schools. All these things were going to be integrated into one. And, you know, that was happening right as the Snowden story was breaking, and it happened in Oakland, which, as you say, is a city that has a long and justifiably troubled relationship with the police force. So citizens started showing up to public meetings and demanding to know more about how the system would work, opposing the system. From that, there grew an entity called the Oakland Privacy Commission, which is attached to the city council. And it is a commission made up of citizen volunteers, and its job is to evaluate any technology the city uses that has the potential to accrue citizen's private data and to ensure that there are adequate policies regarding its use, regarding retention, regarding sort of misuse, penalties for misuse. And it's funny. When I went out there, I expected to find that the Privacy Commission and the police department were just at loggerheads all the time. What I found was exactly the opposite. The Privacy Commission has never told the police that they can't use a certain piece of technology, but they have ensured that the police explain what they want to do, explain why they need it and set standards for how it's going to be used and report, I believe quarterly, on how often it was deployed and in what circumstances. And I had the police tell me, look - these guys make us think about what we want. They save us from predatory vendors. They ensure that, you know, citizens have a voice in how they're policed. And it has improved relations between police and the local communities. DAVIES: You know, that's such a contrast to so many efforts in which civilian review boards, you know, seek to monitor and regulate some police conduct. And they tend to be very fractious relationships. And the civilian boards, over time, sort of become these advisory groups with little impact. Is the difference here that you had a department that just saw the value? Or was it the interaction, the practice itself, that made the difference? FASMAN: I think it's a bit of both, but I think it's the interaction and practice that had a lot to do with it. This is a group that has a very specific remit. It is technology. Tell us what you want. Tell us why you want it. Tell us how you're going to use it. Report on how you've used it. As long as we do that, as long as we know what you're doing and why, everything's going to be fine. And of course, there are sort of - you know, there exigent circumstance exceptions. If the police want to deploy a drone to chase someone who's just shot somebody so they can see where he's going, of course they can do that; they just have to explain it afterwards. And I think it's that practice, the sort of - the reporting on the part of the police and the willingness of the Privacy Commission to listen and create best practices, and it's that practice that has gotten people talking to each other. And I think that's true, honestly, across the board. You know, I know privacy activists like to complain about the police; police complain about privacy activists. But I really think if you get them in a room talking to each other, instead of, you know, yelling at the TV cameras or whatever - if you get them in a room talking together, I really think in almost every instance, you know, 90% to 95% of things they can agree on. And then those last 5%, it's going to be difficult, but it starts from the ground of a working relationship rather than a poisonous one. DAVIES: Jon Fasman, thank you so much for speaking with us. FASMAN: My pleasure. DAVIES: Jon Fasman is the U. S. digital editor for The Economist. His book is \"We See It All: Liberty And Justice In An Age Of Perpetual Surveillance. \" Coming up, David Bianculli reviews the new four-part documentary series from HBO \"The Lady And The Dale. \" This is FRESH AIR. (SOUNDBITE OF MUSIC) DAVE DAVIES, HOST:   This is FRESH AIR. I'm Dave Davies, in for Terry Gross, who's off this week. By now, many of us are used to the idea that American intelligence services, such as the National Security Agency, have enormous capacities to track our phone calls, emails and movements, and we hope that rational and constitutional rules for their use are set by our elected leaders. But our guest, journalist Jon Fasman, says most of us don't realize that thousands of police departments across the country also have access to some really powerful surveillance tools with relatively little oversight. There are devices that scan and store the locations of thousands of auto license plates they encounter randomly on the street, portable gadgets called Stingrays that electronically mimic a cellphone tower and get every mobile phone within range to yield its data and cameras - cameras everywhere, increasingly with facial recognition software. Fasman's new book explores these new technologies, the questions they raise about privacy and the controls he believes citizens should impose on the agencies that use them. His book is \"We See It All: Liberty And Justice In An Age Of Perpetual Surveillance. \" Jon Fasman is the U. S. digital editor for The Economist and the author of two novels. He joins me from his home in suburban New York. Jon Fasman, welcome to FRESH AIR. You know, this book raises a lot of skeptical questions about law enforcement. And I'd like to begin by just having you explain what kind of time you spent with police officers and police chiefs and sheriffs and others, observing their practice and getting their point of view. JON FASMAN: Well, over the course of my reporting, going back to 2010, when I was the Atlanta correspondent for The Economist, I've written a great deal about criminal justice issues. And I've embedded with a number of departments over the past decade. For this book in particular, I probably spent the most time with the LAPD. I went out with their patrol division, and I spent time with Sean Malinowski, who was then an assistant chief, learning about a predictive policing program they use called PredPol. And we can talk about that later. I also embedded for several days with the Newark Police Department to learn about how technology is used by police officers in their day-to-day jobs. So one of the challenges in writing about this is that I would hear about this technology from tech companies and from police chiefs from a sort of 30,000-foot view. But I really wanted to see how police officers, as they work, integrate technology into their daily jobs, how it changes the sort of practice of being a police officer. DAVIES: OK, so let's talk about some of these technologies. One of the things, of course, that people are aware of is video surveillance. I mean, there are, you know, security cameras in so many places that police typically consult after there are crimes in given areas. But you're looking at ways that this is being expanded. And particularly in Newark, N. J. , police have something called Citizen Virtual Patrol. You want to explain what this is, how it works? FASMAN: Sure. The Citizen Virtual Patrol is a network of cameras placed throughout the city. These are public cameras. Now, one of the things when you talk about CCTV cameras, the overwhelming majority of them are privately owned. But these - the Citizen Virtual Patrol is a network composed of publicly owned cameras that people can access from a laptop. Now, the idea behind this was to sort of allow people to observe and perhaps testify to crimes from behind a veil of anonymity. So it gives people an eye on the entire city. It lets people see what's going on. DAVIES: And, Jon, when you say people, you mean just ordinary citizens. Anybody can dial up and look through these cameras. FASMAN: So that's right. A citizen anywhere can log in to the Citizen Virtual Patrol of Newark. So if I live about 50 miles north of Newark, and I can log in at my desk and see the feed from any one of the 126 cameras that the Newark Public Safety Department has placed around the city. DAVIES: That seems a little intrusive, right? I mean, somebody who just wants to be a busybody - I guess other people would say it's no different from looking out a window, right? You're not peeping into somebody's apartment. What concerns does this raise? FASMAN: That's right. Technically, the cameras don't show anything that an observer on the street couldn't see. So it shows public streets. It's not aimed at anyone's apartment. It's not looking inside anyone's window. On the other hand, it does show people's yards, where they have a slightly higher expectation of privacy, and it could provide some information that people wouldn't want known about them. For instance, if I'm - you know, let's say I had an ex who lived in Newark, and I was watching the camera trained on her house. If I saw her leave with some suitcases and then saw no activity at her house for a couple of days, I could surmise that she wasn't there. I could also know when she goes out, when she comes home, who comes to her house, all these things that, of course, I could find out if I observed her in front of her house, but that would make me visible. This renders me invisible. And it lets me observe, lets anyone who logs in observe an enormous swath of the city. So that's another thing I think we need to think about when we're thinking of police technologies, and that is that any single instance may be unobjectionable. But when it comes to scale, you're talking about something very different. DAVIES: Do the police think that it's been helpful? Have there been any complaints or any notable benefits to, you know, to law enforcement from having all of these windows on the street? FASMAN: The police do think it's been helpful. The police think it helps people keep an eye on their neighborhood. I think the idea was that a citizen of a certain neighborhood could keep an eye on what was happening around her without sort of making herself known to other people around her as someone who was watching. So it lets her keep an eye on what's happening around her behind that veil of anonymity. And the Newark police think that's good for public safety. On the other hand, I spoke to the director Amol Sinha, who's the director of the ACLU of New Jersey, who made the same point that I just made, that what we're talking about is, at scale, quite different. And the cameras sort of give information about people and their private activities that you wouldn't necessarily want to know and that if you did try to find out, you would be observed. This lets you do so anonymously and invisibly. And that anonymity and invisibility has, you know, benefits, according to the Newark police, and also detriments, according to the ACLU. DAVIES: Also in the United States, we're seeing the use of automatic license plate readers, which is - I confess I was not aware of this. Describe what these things are, how big they are, who uses them, what they do. FASMAN: Well, these things are small cameras that attach to police cars. They're things you really wouldn't see unless you were looking for them. They're sort of little, flat cameras either on the front or on the roof of the police car. And what they do is as they pass, they capture an image of each license plate, and they translate that image into just plain letters and numbers. They log the geospatial data, so where the car was and what time it was observed. And it just goes into a - it goes into a database. And so, again, the issue with that is one of scale. There is nothing illegal about the police noting the license plate of cars parked in public, where they were parked, when they were parked there. But if you look down your street and you saw a police officer writing down every license plate all day, every day, you might wonder why he was doing that. A police department, if they had to assign people to do that, might wonder whether it was worth it - right? - whether it was worth the manpower to have someone just noting down license plates. But what these ALPRs do is they obviate those decisions. They make it extremely easy and extremely cheap to always be taking pictures of where cars were at any one time. And unless you live in one of the very few public cities in which you don't need to have a car because public transport is so reliable, then this essentially lets police put together a very granular, sort of detailed roster of where you go and when you go and who you see. And again, this is the sort of thing that they could do. There's nothing illegal about it. But it's a question of what people want from the state. Do they want to have that information on file all the time? DAVIES: So let me make sure I understand this. So police cars that have these license plate readers drive down the street, and they automatically just pick up every license plate within range and. . . FASMAN: Yeah. DAVIES: . . . Feed it into the database. Now, if it finds that there's a stolen car among them, does it flag it or is it simply going into a database? FASMAN: If it finds that the car is stolen or is associated with a crime, then it does flag it. And that's the justification that police departments give. And it's a good justification. I'm not suggesting and writing about the dangers of ALPRs that we eliminate them because it does help find stolen cars. It does help find cars used in crimes. The issue is, what about the 99. 99% of cars that aren't involved in crimes? What do you do with their data? So states have wildly different laws on how long that data can be kept. In New Hampshire, for instance, if the car is not associated with any crime or is not being looked for, then you've got to delete it within three minutes. There are other states that set 24-hour limits. But there are a lot of states that set no limits at all. And they just throw these pictures into a huge database. Often, those databases are poorly secured. So in 2015, there was a journalist who just stumbled onto the Boston Police Department's entire database of ALPR data. It's that sort of thing - the collection at scale, the lack of regulations over how long the information is kept and, often, the lack of security over how it's kept that combine to make these sorts of technologies really worrying. DAVIES: So I can imagine abuse. I mean, if I were stalking someone, you know, someone I'd had a relationship with or someone who's spurned my advances and I get access to this, I can see where they go, where they are all the time, what kind of people they frequent. I could also see police saying, well, after, you know, there's been a terrible crime committed and we've identified a suspect, if they're associated with a license plate, we can look through this huge, searchable mass of data and see, aha, this is where their friends are. Aha, that's where they might just be. Is it used in these ways? FASMAN: That is how it's often used. And you're right to highlight the threat of abuse. I mean, the other threat I can think of is let's say there is a demonstration against police brutality. And there is an individual officer who takes issue with the statements, First Amendment-protected activity, of a certain protester. That officer can then access, in some cases, ALPR data and find out where the person goes, who he sees. He can then basically reverse time and look and see if the car has done anything illegal, has been anywhere it shouldn't have been. And it's that sort of thing, the information it lets police build and store for later use that worries me. DAVIES: So your take is, if you scoop all this stuff up, if the license plates show no reason for retention, it has to be scrapped quickly, right? And the rules are all over the place? FASMAN: The rules are all over the place with a lot of this technology because it's so new, because it changes so quickly. And the rules are all over the place. The degree of oversight that individual police departments have is all over the place. In general, you know, even when there are regulations, there often aren't penalties for violating them or not strong enough penalties. And so it's that sort of thing. This is not - I have not written an anti-technology book. I have written a pro-democracy, pro-regulation book. DAVIES: We need to take a break here. Let me reintroduce you. We are speaking with Jon Fasman. He is the U. S. digital editor for The Economist. His new book is \"We See It All: Liberty And Justice In An Age Of Perpetual Surveillance. \" We'll continue our conversation in just a moment. This is FRESH AIR. (SOUNDBITE OF JOAN JEANRENAUD'S \"AXIS\") DAVIES: This is FRESH AIR. And we're speaking with Jon Fasman. He is the U. S. digital editor for The Economist magazine. He has a new book which explores cutting-edge surveillance technologies employed by local police departments, often with little oversight. The book is called \"We See It All. \" You also write about a technology called ShotSpotter. Tell us about this. FASMAN: ShotSpotter is an acoustic sensor designed to detect the sound of gunshots. And these - I saw these in place in Newark, N. J. They often look like little, white diamonds or rectangles up on traffic light poles. And they're trained to recognize what ShotSpotter calls loud, impulsive sounds between 120 and 160 decibels. When it does hear such a sound, it sends an alert to the ShotSpotter headquarters where a human listens to it and figures out, was that a gunshot? Was it a car backfiring? When I was at ShotSpotter's headquarters in California, there was an alert caused by a truck's Jake Brake, you know, the engine brake that releases a tremendous amount of sound quite quickly. Once it hears a gunshot, it notifies the local police department. It tells the police department how many shots, where, when. And it, essentially, can dispatch officers to a - to the scene of a suspected shooting. DAVIES: Right. Now, that sounds like it would be valuable. I mean, a lot of times, people hear gunshots and don't report them. And if police can get quickly to the scene of a shooting, it would seem there's more chances of either saving a life, apprehending a suspect, assisting a victim. How - what's the record on its performance? FASMAN: The record on its performance is OK, I think. I mean, I'm just judging it by what the company itself has told me, which is that it has solved crimes. It has helped identify shooters and shootings. There are some places that have had less luck with it than others. But in general, it does seem to dispatch officers to a shooting. Now, I was with the Newark Police Department when we got dispatched to two shootings by ShotSpotter. And when we got there, there was nobody there. Now, it's not a panacea, obviously. But it does seem to get police officers to the scene of a shooting. And you're right, the number of gunshots that result in actual police calls is quite low. I think it's something like 9%. And so this is a way of alerting police that a shooting has happened without waiting for someone to call it in. DAVIES: All right. So what might give you pause about recommending this for a department? What are the drawbacks or concerns? FASMAN: Here's what I think is interesting about ShotSpotter. As I was reporting this story, I - you know, I talked to people on buses, trains and cabs. In multiple cities, multiple people from, you know, cab drivers, just people I was sitting next to on trains, people I talked to on the street, a lot of people believed that this sort of technology was being used to overhear private conversations. Now, I think that is extremely unlikely. I think there's - to my knowledge, there's never been a case that's been brought based on a conversation overheard by ShotSpotter. Every police department, everyone from ShotSpotter said it doesn't hear conversations. It's trained to recognize loud, sudden sounds. That's not how people talk. But it's an instructive lesson in how deploying technology can be used to improve or worsen relations between police and the communities they police. I think that in too many instances, police departments approve the purchase of ShotSpotter and deploy them without doing the work of going into communities they police and saying, listen; this is what's going up on these traffic lights. Here is how it works. It doesn't hear conversation. Here's how we know it doesn't hear conversation. If you have any questions about it, please, come and talk to me - as opposed to just citizens, who often come from communities that have a long history of distrust with police built up over years for valid reasons, as opposed to those communities just seeing another piece of tech up there. I mean, you can imagine it yourself. If you were a citizen of color who lived in a community that had a long history of distrust with the police and all of a sudden the police said this hears gunshots, you might think to yourself, what else does it hear, you know? And so it's an instruction - one of the things that I point out in my book is that technology is not good or bad in itself. But police have to be very careful about how they roll it out, have to go out of the way to gain the trust of the public, particularly in those communities that have a long history of distrust of the police. DAVIES: You also write about another device. This is something I had never heard of. I guess the trade name is Stingray for this thing. It's a device that can simulate a cellphone tower so that when you're driving by it, your cellphone thinks it's a mobile phone tower and connects with it. What happens then? FASMAN: Well, once your phone connects with one of these things - the trade name is Stingray. The technical term is IMSI-catcher. IMSI stands for international mobile subscriber information. Every mobile phone has a unique number. And it's that number that identifies itself to the cellphone tower to let the tower know that, hey, this is, you know, Dave Davies' phone. So if you have any messages or texts for Dave Davies, send it to this phone. And IMSI-catcher or Stingray mimics a cellphone tower. And it gets your phone to connect to it. And what happens then is that all of the metadata on your phone, that is the non-voice call data, can then be read. And that includes texts you might send, websites you might browse, who you called and how long you talked for even without knowing the actual substance of the conversation. All of that sort of thing connects to the phone. DAVIES: And does it geolocate you, too? Does it tell. . . FASMAN: Yes, and it tells you - it geolocates you. DAVIES: So what do the police do with this information when they get it? And they must be getting thousands and thousands of cellphones coming in contact with this thing, right? FASMAN: Yeah. And again, increasingly, it's deployed by court order. But that hasn't always been the case. And what happens is even when deployed by court order against a specific subject, the data from every other phone in that area is hoovered up. Now, again, this happens on a stakeout, too, right? If the police are staking out a suspect, they see all kinds of people walking past. The difference is they don't retain the data from all those people walking past. In the case of data hoovered up by Stingrays, that often does get kept for longer than it should. And again, this is an issue in which there's no question that Stingrays can help police catch serious criminals. But there just needs to be some regulations over when they can be used and what happens to the data hoovered up incidentally during those stakeouts. DAVIES: Do these things have to be mounted on towers? FASMAN: No, they do not. They fit in the trunk of a car. They're quite small. They're sort of suitcase-sized. DAVIES: So the typical way it might be used is the police wants to track someone who they suspect is a, you know, major drug dealer or a suspect in a homicide. And they find a spot near that person and wait for the cellphone to interact with the Stingray? FASMAN: That's right. And they're probably just paying attention to that actual cell data. But there's a lot of other data that's taken up in response. I should say, another thing that's striking about Stingrays is that their use is really shrouded in secrecy. So everything that I know about them, everything that we know about them, comes from FOIA requests, comes from court documents. Often, police that use a Stingray, they have to sign a nondisclosure agreement so they won't talk about whether they have it, how it's used. I obviously wrote to the company for an interview. They declined. So its use is quite shrouded in secrecy. DAVIES: OK. But when they scoop up all this other data about hundreds or thousands of other cellphones, does that get retained? Do we know? FASMAN: We don't know for sure. It could get retained. It could get thrown away. This is, again, one of the issues I'm concerned about is we just need transparency in where that data is stored, how it's used. And there need to be limits that communities set for the police and what they can do with it. DAVIES: So this is sort of a gray area of the law. I mean, can departments just set these things up without going to court and getting a warrant? FASMAN: I mean, this - all of this technology that I write about is a gray area of the law because it is so new. So there is often - increasingly, there's pressure from groups like the American Civil Liberties Union, the Electronic Frontier Foundation and groups that are really concerned about the dangers I write about. They have succeeded, I think, in getting some information released to the public. But again, because this technology is new, because we have historically been reluctant to regulate the police, all of these emerging technologies, it's all a legal gray area. DAVIES: Jon Fasman is the U. S. digital editor for The Economist. His new book is \"We See It All: Liberty And Justice In An Age Of Perpetual Surveillance. \" He'll be back to talk more after a break. And David Bianculli reviews the new four-part documentary series from HBO, \"The Lady And The Dale. \" I'm Dave Davies. And this is FRESH AIR. (SOUNDBITE OF MUSIC) DAVIES: This is FRESH AIR. I'm Dave Davies, in for Terry Gross, who's off this week. We're speaking with Jon Fasman, the U. S. digital editor for The Economist magazine. His new book explores cutting-edge surveillance technologies increasingly employed by local police departments around the country, often with little oversight. His book is \"We See It All: Liberty And Justice In An Age Of Perpetual Surveillance\" (ph). One technology that's not so new, but you describe some interesting uses by the police department, are drones. And you describe this pilot program by the Baltimore Police Department. You want to describe what they did, and, you know, what this company does that provide the service? FASMAN: Sure. So the Baltimore Police Department used a company called Persistent Surveillance. And this is a technology that was born on the battlefields in Iraq, in Fallujah. The military wanted to catch people who were leaving IEDs by the side of the road. So what an engineer - there's an engineer named Ross McNutt, naval engineer. He attached low-res cameras to drones and set them to fly over huge swaths of the city sort of in loops. So it actually did keep the city under persistent surveillance. And what they found is that when an IED went off, they could locate the footage and then essentially rewind it. So they could see who planted it, where they came from, where they talked to - who they talked to, where they lived and can solve the crime that way. The BPD decided to use a pilot program and set it over, I think, a huge, sizable swath of East Baltimore. Now, I have seen what this footage looks like, and it is absolutely true that you can't tell a single thing about a single person from the footage. Everybody just looks like little dots. The way BPD used it is it was only in response to a reported crime. So, you know, a shooting or a carjacking, they would locate that incident and basically rewind it and see who did what. It was used to solve killings in Juarez, when Juarez was in the middle of its crime wave. So it's true that - you know, Ross McNutt was very, very adamant that you can't tell anything about any one person, and they are not using it to identify people. But that's certainly a way it could be used, right? What happens if another company attaches better resolution cameras to drones and has them fly lower? What happens if when that happens, you have a police chief who is upset about an anti-police brutality demonstration and decides to rewind the camera on the organizers of that demonstration to see what they might have done that they might be able to be picked up for? It's that sort of thing, even if the current instance of persistent surveillance is not terribly alarming. And again, by not terribly alarming, I mean, even if citizens of a certain city are not alarmed by the prospect that having been committed - having been accused of no crime, they may be observed all the time. Even if this incarnation doesn't let police see who they are, there's nothing stopping another company from doing something that would allow police to track people and observe people all the time. DAVIES: And even if people are represented as dots, I mean, you can imagine misuses, too. If I'm, you know. . . FASMAN: Of course. DAVIES: . . . Stalking my ex-wife, I know her address. I see the dot coming out of her place, and then I see where she's headed. I mean, the interesting thing about this thing in Baltimore was that they didn't announce it to the public and it was revealed in the media. The reaction was substantial, right? FASMAN: Yeah, it was substantial. And this is another problem with technology that I write about. It's how police roll it out that often matters. So, you know, it was a newspaper that broke the story that, you know, the entire east side of Baltimore was under perpetual surveillance. Of course, citizens were outraged. I would be, too. Now, that pilot program stopped, and BPD reintroduced it. And they reintroduced it after extensive public hearings and extensive public discussion. And that suggests that there is, in fact, a difference between a police department saying to itself, hey, let's try this and see how it works, and a police department going to the public and saying, this is what we'd like to do. This is how the tech works. This is what the data is. This is who gets to see it. This is how long we're keeping it. What do you guys think? And then work through with the public what they want, what they're comfortable with, what is acceptable to them. When that happens, this technology that is quite frightening can often be, you know, acceptable to people. DAVIES: And I guess it bears noting that in Baltimore and many big cities, a lot of shootings and murders go unsolved. So information that tracks where a shooter went could be valuable. Do we know anything about how useful it's been? FASMAN: I have not looked into that. I should look into that. But I want to make one point about efficacy as justification. There are a whole lot of things that would help police solve more crimes that are incompatible with living in a free society. The suspension of habeas corpus would probably help police solve more crimes. Keeping everyone under observation all the time would help police solve more crimes. Allowing detention without trial might help the police solve more crimes. But all of these things are incompatible with living in a free, open, liberal democracy. So when we think about these technologies and what we are willing to accept, we shouldn't just think about whether it'll help police solve more crimes because almost all of them will, at least on the margins. The question is, is it worth the cost to our privacy and liberty to implement this technology? And if so, what limits are we willing to set? What penalties do we want for failing to observe these limits? So it's really a question not just of whether the technology works, but is it worth the cost. And if it's not worth the cost, can we devise a way in which the police can have the tool that they want to solve crimes, and we can be comforted that it won't be abused, it won't be used against us, it won't be used to surveil us. DAVIES: We're speaking with Jon Fasman. He is the U. S. digital editor for The Economist magazine. His new book about police surveillance is called \"We See It All. \" We'll continue our conversation in just a moment. This is FRESH AIR. (SOUNDBITE OF AVISHAI COHEN'S \"GBEDE TEMIN\") DAVIES: This is FRESH AIR. And we're speaking with Jon Fasman. He is the U. S. digital editor for The Economist magazine. He has a new book about cutting-edge technologies used by police departments in surveillance efforts. It's called \"We See It All: Liberty And Justice In An Age Of Perpetual Surveillance\" (ph). You write a lot about facial recognition, which is a technology that's getting better and better. It obviously poses some issues in terms of privacy. And you know - and police will typically say they don't use facial recognition as evidence in court. They use it for tips and leads. Typical situation - a serious crime is committed - you know, an assault, a shooting - security cameras catch somebody in the area. They use facial recognition to compare that to a database of mug shots. They find a suspect, and then they bring the victim before a lineup in which the suspect is there or a, you know, a photo lineup - an array of mug shots. Seems like not an unreasonable set of things to do, potentially useful. What is the concern about the way departments are using this? FASMAN: I think there are a few concerns. One of them is about how departments use it and whether they really are hewing to that principle that they profess that this is just a lead, this is not evidence. So what does it mean when a facial recognition system generates a match? It means that the system is telling you this person on camera is probably this person, the mug shot. Now, generally, these systems will generate a list of, you know, 20, 30, 40 possible matches ranked in order. What does it mean if the police catch the 30th person on that list as opposed to the second person on the list? How did they eliminate everyone else? I think another concern is that facial recognition systems, as they exist right now in the United States and Europe, are really bad at recognizing nonwhite people. And that is, I think, partly an artifact of the list of the range of images that they were trained on. But what that means is nonwhite people often run the risk of being falsely identified and, therefore, if not falsely accused, then at least brought into contact with law enforcement in a way that white citizens are not as often. Also, because of the history of overpolicing communities of color, there's the risk that databases will be more filled with nonwhite suspects than white suspects so that a nonwhite suspect stands a greater chance of being identified in a database than a white suspect does. I think that, then, until facial recognition can solve the problem of bias in this case, then we should be very, very suspicious of its deployment. I think we may even want to be sort of cautious about how it's deployed afterward. Now, that is not a call to ban facial recognition entirely. There is a facial recognition system called Clearview that was used to identify a number of suspects in the Capitol insurrection. I think that is all to the good. The question, though, is what about the rest of us? What about our anonymity in public? What about our being put into databases without our consent? What does that mean for our privacy? DAVIES: Right. What - who are in the photo databases that law enforcement uses to compare images that they pick up? I mean, people who have been arrested have mug shots. I mean, again, some of them may have never been convicted. What about things like - I don't know - driver's license photos? Are they used to look for matches? FASMAN: Yes, they are used to look for matches often. As early as 2016, there is a study from Georgetown Law school that found that 1 in every 2 Americans had their faces in an FBI-accessible facial recognition database. That has almost certainly gone up since then. Also, the system that the police use to identify Capitol Hill rioters was called Clearview. One concern with Clearview, though, is that it is not just available to police departments. It is - or it was at some point - available to investors and to some private citizens as well. What this essentially means is that you can't really be sure that you're anonymous in public anymore. So there is a story about a New York City grocery magnate who saw his daughter out on a date with someone, wanted to know who it was, snapped a picture of the guy. And immediately, he knew who the guy was, where he worked, where he lived, that sort of thing. So that's, I think, what's worrying about unregulated facial recognition is the extent to which it imperils your ability to be anonymous in public. DAVIES: You know, it's now used by some airlines for entering, you know, planes there at the gate. Right? Rather than going through and scanning your boarding pass, you can just show them your face. You've encountered that. Your advice is don't do this, don't normalize this. Why? FASMAN: That is my advice. I never, ever use facial recognition to board at gate. And I would advise anyone else who is concerned about our civil liberties not to do it. And that's not because you run some great risk of being, you know, pulled off a plane and detained falsely when you board a plane. It is because the more you opt to use facial recognition in ways that you think are benign, the more it will be used in ways that you may not think are benign. So the reason to avoid using facial recognition to board a plane is that you don't want to normalize this technology at this stage of its existence. You don't want to normalize the fact that your face is - becomes sort of your passport and everywhere you go, you're tracked and recorded. You want to do your best - or at least I think people concerned about civil liberties should want to do their best to make sure that this technology is only used in a specific set of circumstances and a specific set of ways. DAVIES: Another thing you write about is the use of algorithms by courts and police departments. One reason is to decide who ought to be held on bail. You have all these factors - you know, the defendant's past criminal record, age, et cetera. And then there are also algorithms that are designed to guide departments on where to emphasize police patrols. What are your concerns about this kind of technology? It's not exactly surveillance. FASMAN: It's not exactly surveillance. My concern about predictive policing programs - and what I mean by that are these are programs that ingest an enormous amount of historical crime data and say, based on the data, based on past practice, these are the areas that we think are likely to be at elevated risk for crime today. So this is where you need to deploy your patrol officers. My concern about that is that historical crime data is not an objective record of all crimes committed in a city. It is a record of crimes that the police know about. And given the sort of historic pattern of overpolicing minority communities, overpolicing poor communities, these programs run the risk of essentially calcifying past racial biases into current practices. One of the justifications for these programs is that they remove sort of human error, they remove human bias and they're just using data. And you know, it is true that they are not as reliant on human interpretation as sort of past practices may have been. But I think it's important for people to understand there isn't really any such thing as just data. So if one of these predictive policing programs ingests and makes recommendations based on, you know, nuisance crimes, vagrancy, public drinking, things that only get prosecuted because the police are there and police are more present in minority communities and prosecute these sorts of crimes more often there, then you will get a program that essentially is a pernicious feedback loop of racial bias. DAVIES: The overriding theme of your book is that, you know, we're not going to roll back technology. It is here, but we as a democracy need to understand it and impose controls that preserve our civil liberties and, you know, balance that against the legitimate needs of law enforcement. And you cite a potential model here, and that's Oakland, Calif. , which certainly has a troubled history between its police department and African American activist organizations. The - this process began with the Port of Oakland wanting to adopt a high-tech security system. What happened then? FASMAN: That's right. So this is back in 2014. And the port - I think it's called the Domain Awareness System. The port wanted to basically integrate camera feeds from all different city systems - police, fire, public schools. All these things were going to be integrated into one. And, you know, that was happening right as the Snowden story was breaking, and it happened in Oakland, which, as you say, is a city that has a long and justifiably troubled relationship with the police force. So citizens started showing up to public meetings and demanding to know more about how the system would work, opposing the system. From that, there grew an entity called the Oakland Privacy Commission, which is attached to the city council. And it is a commission made up of citizen volunteers, and its job is to evaluate any technology the city uses that has the potential to accrue citizen's private data and to ensure that there are adequate policies regarding its use, regarding retention, regarding sort of misuse, penalties for misuse. And it's funny. When I went out there, I expected to find that the Privacy Commission and the police department were just at loggerheads all the time. What I found was exactly the opposite. The Privacy Commission has never told the police that they can't use a certain piece of technology, but they have ensured that the police explain what they want to do, explain why they need it and set standards for how it's going to be used and report, I believe quarterly, on how often it was deployed and in what circumstances. And I had the police tell me, look - these guys make us think about what we want. They save us from predatory vendors. They ensure that, you know, citizens have a voice in how they're policed. And it has improved relations between police and the local communities. DAVIES: You know, that's such a contrast to so many efforts in which civilian review boards, you know, seek to monitor and regulate some police conduct. And they tend to be very fractious relationships. And the civilian boards, over time, sort of become these advisory groups with little impact. Is the difference here that you had a department that just saw the value? Or was it the interaction, the practice itself, that made the difference? FASMAN: I think it's a bit of both, but I think it's the interaction and practice that had a lot to do with it. This is a group that has a very specific remit. It is technology. Tell us what you want. Tell us why you want it. Tell us how you're going to use it. Report on how you've used it. As long as we do that, as long as we know what you're doing and why, everything's going to be fine. And of course, there are sort of - you know, there exigent circumstance exceptions. If the police want to deploy a drone to chase someone who's just shot somebody so they can see where he's going, of course they can do that; they just have to explain it afterwards. And I think it's that practice, the sort of - the reporting on the part of the police and the willingness of the Privacy Commission to listen and create best practices, and it's that practice that has gotten people talking to each other. And I think that's true, honestly, across the board. You know, I know privacy activists like to complain about the police; police complain about privacy activists. But I really think if you get them in a room talking to each other, instead of, you know, yelling at the TV cameras or whatever - if you get them in a room talking together, I really think in almost every instance, you know, 90% to 95% of things they can agree on. And then those last 5%, it's going to be difficult, but it starts from the ground of a working relationship rather than a poisonous one. DAVIES: Jon Fasman, thank you so much for speaking with us. FASMAN: My pleasure. DAVIES: Jon Fasman is the U. S. digital editor for The Economist. His book is \"We See It All: Liberty And Justice In An Age Of Perpetual Surveillance. \" Coming up, David Bianculli reviews the new four-part documentary series from HBO \"The Lady And The Dale. \" This is FRESH AIR. (SOUNDBITE OF MUSIC)", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-01-27-961063734": {"title": "Verizon Outage Affects Internet Users In The Northeast : NPR", "url": "https://www.npr.org/2021/01/27/961063734/verizon-outage-affects-internet-users-in-the-northeast", "author": "No author found", "published_date": "2021-01-27", "content": "RACHEL MARTIN, HOST:  For some of you, the Internet might be your classroom now or your workplace. For a lot of people in the Northeast yesterday, Verizon FiOS Internet suddenly wasn't working. SARAH MCCAMMON, HOST:  Genevieve Cruz (ph) is a designer in Silver Spring, Md. Her son, who's in ninth grade, was on his lunch break. GENEVIEVE CRUZ: He started experiencing, I guess, lagging on his computer. So I'm looking on Verizon. And then I notice on my end, 'cause I work remote, my server to my company went down. MCCAMMON: Cruz says her son's online learning software would not work. He missed his last two classes. She found a way to work, but the outage was worrying. CRUZ: I was just hoping that it wasn't going to put all of us down. That's all we rely on now with the virtual classes, me working remote. MARTIN: So how big was this? Travis Wright is vice president of products at Ookla. The company's website Downdetector tracks outages through user reports. Wright says it was clear Verizon's service was having a problem. TRAVIS WRIGHT: You know, at sort of the peak of user complaint volume - I'm just double-checking here - you know, we were seeing, you know, 15 to 20,000 reports a minute, which is quite a large number for this particular company. MARTIN: Large, but he has seen bigger. Wright thinks this outage got attention because of how much we've come to depend on Internet service providers. WRIGHT: We're all our own IT support now (laughter) at home, for our kids and families and everything else. And so it's different. We pay a little bit more attention to it. MCCAMMON: Mariely Lopez-Santana is a political scientist in Annandale, Va. Yesterday, she was also IT support for her first-grader. After two hours of class time, the school district sent a message to have her son work on his own. MARIELY LOPEZ-SANTANA: Well, he had a meltdown. You know, he's pretty independent. But of course, he needs some type of guidance, and suddenly there's no guidance. So in the end, we read a book, and that was that. MARTIN: In a statement to NPR, Verizon said the issue affected service throughout the Northeast. It is resolved now, but the company is still trying to figure out what caused it. (SOUNDBITE OF DATA REBEL'S \"AS IT FADES\") RACHEL MARTIN, HOST:   For some of you, the Internet might be your classroom now or your workplace. For a lot of people in the Northeast yesterday, Verizon FiOS Internet suddenly wasn't working. SARAH MCCAMMON, HOST:   Genevieve Cruz (ph) is a designer in Silver Spring, Md. Her son, who's in ninth grade, was on his lunch break. GENEVIEVE CRUZ: He started experiencing, I guess, lagging on his computer. So I'm looking on Verizon. And then I notice on my end, 'cause I work remote, my server to my company went down. MCCAMMON: Cruz says her son's online learning software would not work. He missed his last two classes. She found a way to work, but the outage was worrying. CRUZ: I was just hoping that it wasn't going to put all of us down. That's all we rely on now with the virtual classes, me working remote. MARTIN: So how big was this? Travis Wright is vice president of products at Ookla. The company's website Downdetector tracks outages through user reports. Wright says it was clear Verizon's service was having a problem. TRAVIS WRIGHT: You know, at sort of the peak of user complaint volume - I'm just double-checking here - you know, we were seeing, you know, 15 to 20,000 reports a minute, which is quite a large number for this particular company. MARTIN: Large, but he has seen bigger. Wright thinks this outage got attention because of how much we've come to depend on Internet service providers. WRIGHT: We're all our own IT support now (laughter) at home, for our kids and families and everything else. And so it's different. We pay a little bit more attention to it. MCCAMMON: Mariely Lopez-Santana is a political scientist in Annandale, Va. Yesterday, she was also IT support for her first-grader. After two hours of class time, the school district sent a message to have her son work on his own. MARIELY LOPEZ-SANTANA: Well, he had a meltdown. You know, he's pretty independent. But of course, he needs some type of guidance, and suddenly there's no guidance. So in the end, we read a book, and that was that. MARTIN: In a statement to NPR, Verizon said the issue affected service throughout the Northeast. It is resolved now, but the company is still trying to figure out what caused it. (SOUNDBITE OF DATA REBEL'S \"AS IT FADES\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-01-28-961349400": {"title": "GameStop: How Reddit Traders Occupied Wall Street's Turf : NPR", "url": "https://www.npr.org/2021/01/28/961349400/gamestop-how-reddit-traders-occupied-wall-streets-turf", "author": "No author found", "published_date": "2021-01-28", "content": "", "section": "Business", "disclaimer": ""}, "2021-01-28-961507953": {"title": "Without Their 'Messiah,' QAnon Believers Prepare For A Post-Trump World  : NPR", "url": "https://www.npr.org/2021/01/28/961507953/without-their-messiah-qanon-believers-confront-a-post-trump-world", "author": "No author found", "published_date": "2021-01-28", "content": "DAVE DAVIES, HOST:  This is FRESH AIR. I'm Dave Davies in for Terry Gross, who's off this week. As Donald Trump's presidency neared its end, there was growing evidence among his followers of the influence of QAnon, a set of conspiracy theories holding that Trump was battling a cabal of deep state actors and their celebrity allies who were undermining Trump and engaging in satanic worship and pedophilia. QAnon supporters were well-represented in the deadly assault on the Capitol on January 6. But Trump's departure from the White House and Joe Biden's inauguration as president may have left many QAnon followers angry and confused, since they expected Trump to vanquish his adversaries and remain in power. After the mob stormed the Capitol, Twitter, Facebook and YouTube banned Trump, and many of those social media platforms have targeted QAnon as well. Twitter and Facebook have removed a combined total of more than a hundred thousand QAnon-linked accounts. For some insight into what these events mean for QAnon and other extremist groups in the country, we've invited Craig Timberg to join us. He's a national technology reporter for The Washington Post, specializing in privacy, security and disinformation. He's written on QAnon and related subjects in recent months. Since joining the Post in 1998, he's been a reporter, editor and foreign correspondent and co-authored the book \"Tinderbox: How The West Sparked The AIDS Epidemic And How The World Can Finally Overcome It. \" He joins us from his home in Washington, D. C. Well, Craig Timberg, welcome back to FRESH AIR. I think maybe we should start with just a little primer on what QAnon is. People may have heard the names. Some may be fuzzy on what exactly it is. Just give us the basics. CRAIG TIMBERG: Well, thanks, first of all, for having me on the show. This question you ask is harder than it sounds because we researchers and journalists debate exactly what QAnon is. In fact, our copy editors are questioning whether we should call it a conspiracy theory or an extremist ideology. Some researchers think it's a cult. Some think it's an alternative reality game. So it's a little hard to wrap your brain around. You called it a kind of collection of conspiracy theories, which kind of works for me. But the gist is that there is a person who goes by the pseudonym Q who is supposedly a top secret official in the U. S. government, who is sort of gradually dribbling out the truth about what's really happening in the world. And as you said, a lot of this truth has to do with the idea that prominent Democrats and Hollywood celebrities are pedophiles, that they traffic in children for sex - and they also eat those children on at least some occasions - and that they are working together to undermine the U. S. government and take control of essentially the whole world. And so these ideas have been dribbled out on a forum called 8kun. And people who believe in this then take those sort of cryptic messages, share it among themselves, analyze it, and then, you know, have sort of become a community of sort of, you know, fellow travelers in this stuff that seems so crazy to many of us but actually is a really animating force in a lot of people's lives and has been for years. DAVIES: Right. And they regard Trump as their champion, battling this deep state cabal. And we'll get into this a bit later. But what's the specific reason that they might have been so disappointed to see Trump actually leave office? TIMBERG: Well, you put it well - right? - I mean, that Trump is their leader. And I think if you were to kind of make a series of circles of like, you know, Republicans and then the subset of Republicans who are Trump enthusiasts and then the subset of Republicans who are really, really diehard Trump enthusiasts, like, QAnon is in the in the dead center of those circles. Like, some of the most fervent Trump supporters in the world believe in QAnon. And so - and they regard him not merely as their president and leader, but also as essentially a messiah. And so, you know, I was seeing messages the night of January 19, when President-elect Joe Biden was presiding over a ceremony at the Lincoln Memorial, in which QAnon supporters were saying, hang on, right? Trump is still going to - he's going to stay in office. He's going to take control. All of our prophecies are going to come true. So when the when that didn't happen the next day on the inauguration, when Joe Biden actually became president, there was just huge amounts of consternation and cognitive dissonance or whatever you want to call it because they just - they had trouble making sense of it. And so there's all these new theories that are now spinning out of it. But it was a clash of reality with prophecy that was very discomforting to people. DAVIES: And the prophecy was that there would be mass arrests of these Democrats and pedophiles, right? TIMBERG: Yeah. I mean, that was part of it, that Trump was going to stay in office, that he had really won the election, that the various baseless claims of election fraud were going to be true and proven true and acted upon as though they were true, and that a bunch of Democrats were going to be rounded up and arrested and, depending on which version of this you believed, you know, shot or hung. DAVIES: All right. Let's back up a little bit and go back, you know, before the events of this January. You know, over the past year, couple of years, there was growing evidence of support among QAnon. It's always been hard to tell how many supporters it had. It's not like a membership organization. But it came to be recognized as a serious threat by law enforcement, right? TIMBERG: Indeed. Going back several years now, you know, QAnon is essentially born in October 2017 on a, you know, on a message board called 4chan. And then, you know, the conversation online, including on mainstream platforms like Facebook and Twitter and YouTube, is almost immediately terribly violent. And they're calling for firing squads and nooses and all that for people who were supposedly, you know, pedophiles, et cetera. And within, you know, a couple of years, there had been some incidents that flowed out of that online talk of violence. There was a - there's an incident at the Hoover Dam where an armed man in a truck kind of, you know, blocked off traffic for a while and got arrested. There were - there was an actual murder in New York City of a mob boss by someone who was inspired by QAnon. And so, you know, the FBI, you know, issued a warning about QAnon is a domestic terrorism threat a couple of years ago. The, you know, researchers at West Point issued a similar warning. And countless independent researchers, you know, started sending up, you know, bright red flashing warnings years ago that this was not merely something that was roiling the online world, but it was something that had the potential to spill into our world, our real world, and cause actual violence and harm to people. DAVIES: And at the same time, it was sort of gaining credibility among more mainstream Republicans, right? I mean, you had a number of Republican candidates who spoke, you know, flatteringly of QAnon. A couple have made it into Congress. That's a part of this picture, too, isn't it? TIMBERG: Yeah, absolutely. It's very hard for me as a newspaper reporter to know what percentage of the people who kind of mouth these various conspiracy theories, believe them, or find the merely convenient, right? There's always been an element of profiteering about QAnon. There's T-shirts to sell and books to sell and websites to stand up with, you know, advertising. And there's also political opportunity. And lots of politicians, you know, overwhelmingly but not exclusively Republicans, have, at a minimum, found it useful to kind of hint that they are aligned with this ideology. And indeed, you know, a couple of them are now in Congress. And the kind of footprint of QAnon among, you know, Republicans in the United States is, you know, probably larger than many of your listeners imagine. Again, there's no precise way to measure it. But at a minimum, there's a lot of kind of affinity for the ideas that QAnon traffics in among Republicans in this country. DAVIES: Right. Now, there have been - social media platforms have have imposed restrictions on Qanon and many others after the events of January. But it's easy to forget that this didn't just start then. In 2019, there were some - also sort of a crackdown on Qanon. What happened? TIMBERG: There's been a variety of crackdowns. You know, the platform Reddit a couple of years ago - you know, Reddit was the site where a previous conspiracy theory called Pizzagate, which also imagined that Democrats in Washington were trafficking in children and running a sex ring. You know, Reddit was sort of, like, you know, ground zero for Pizzagate. And so when Qanon flared up, Reddit acted pretty aggressively almost immediately in 2018 to purge that stuff from the platform. The other platforms - Twitter, Facebook, YouTube - were much, much slower. And I and others have done stories that have looked back at how violent and unhinged the conversation around Qanon was, you know, going back several years now and pointing out (laughter) that the platforms just basically didn't do much of anything for a long time. Now, they did quite a bit more in 2020. And they did, actually, to be fair, quite a bit more before this thing blossomed into the kind of consuming catastrophe it became around the election time. And so - and interestingly, this has to do with the coronavirus because, you know, as the pandemic arrived around the world and COVID disinformation became so prominent - you know, untrue things about how it spread, about masks, about vaccines - the people around those companies said, well, hang on a minute. Like, it's OK if people want to lie about politics. But it's not OK if they lie about science. And so what we saw, beginning, really, late winter last year, was a broad movement in Silicon Valley to kind of enforce the truth, which is something they'd never wanted to do before. And so that - once they kind of got the taste of it and saw the impact of enforcing truth and casting disinformation off their platforms, they became progressively more, you know, intent on doing that. And that meant that a lot of things that had never happened in previous years suddenly began happening. And so part of that was Facebook, Twitter, YouTube all crackdown on Qanon over the summer. They closed a bunch of accounts. They limited the reach of the accounts that were still there. And they kind of put everybody on notice that that wasn't really going to play on the platforms before. And what we've seen since then is a continuation of that. And the events of recent weeks, the platforms have finally really, really taken a hammer to these ideas and to the people pushing them on mainstream platforms. And it's really led to a fracturing of the whole community. DAVIES: And it was probably harder for these social media platforms to act decisively given the criticism that they're unfairly targeting conservatives all the time, right? TIMBERG: Yes. To some extent, that's certainly true. I think it's fair to ask how much harder it would have been. It certainly is the case that Facebook, in particular, and to some extent the others, were just terrified of angering President Trump and his followers. And there were two reasons for that. One is President Trump was the most powerful person in the world, you know, oversaw the Justice Department, had leverage in Congress. And if he wanted to go after the social media companies, as he ultimately did, that was a big problem for them. So yeah, that was an issue. Secondly, you know, Facebook in particular didn't want to be known as the platform for, you know, liberal America or modern America. They wanted to - you know, these are customers. They wanted to have all of America. They wanted to have all of the world. And so if this idea that Facebook or Twitter or YouTube was, you know, really just a platform for the left, that meant - that had real business stakes for all of these companies that they were deeply aware of. Now, all that said, I think the events of the past few weeks have really reinforced how, actually, easy it was for the platforms to make these decisions once they were ready to make these decisions. And it hasn't been lost on anybody that all of these companies acted on the very day that Biden's ascent to the White House became clear and that the Democrats' control of the Senate also became clear, right? So on the same day that - on January 6 - that the mobs overtake the Capitol, we'd learn that these two runoffs in Georgia have yielded two new Democrats, which meant a new party was going to be in charge in Washington. And so yes, it was politically hard for the platforms to act against a dominant Republican Party in the past few years. But it also clearly was logistically super easy and simple to just turn off some of this stuff. And there's real questions about whether they should have done that sooner. DAVIES: Right. And the fact that all the committee chairs in Congress going forward would all be Democrats probably just eased their minds a bit. TIMBERG: Indeed. DAVIES: Let me reintroduce you. We're going to take a little break here. We're speaking with Craig Timberg. He's a national technology reporter for The Washington Post. We'll continue our conversation in just a moment. This is FRESH AIR. (SOUNDBITE OF ANAT COHEN'S \"NIGHTMARE\")DAVIES: This is FRESH AIR. And we're speaking with Washington Post reporter Craig Timberg. We're talking about how President Trump's departure and social media restrictions on him and some of his more extremist supporters, including followers of the Qanon conspiracy theories, will affect events in the coming months. You wrote that before the Capitol rally on January 6, which, of course, you know, the president summoned and attracted people to and said it's going to be wild - all that stuff - that you followed the website, thedonald. win, and that you saw it was host to a really troubling interaction between online rage and real-life activity. You want to just describe some of that? TIMBERG: Yeah. Certainly. The - it wasn't just thedonald. win, it was Parler. It was Gab. It was a whole coterie of kind of new-ish, largely conservative social media platforms that were just boiling over with rage. And it wasn't the first time I had seen this. And - but it also took on a certain kind of urgency because January 6 was seen as the day - sort of their last stand, right? This was a day Congress was going to meet. They were going to certify the results of the election. And if that election was going to be overturned, it had to happen then. And so you could see both an intensity of rage, calling for the killing or arrests of Democrats. You could see calls to, you know, attack the Capitol. And you also could see logistical conversations happening about what they were going to do. It wasn't super tactical. But it was, you know, how can we bring guns to D. C. ? How are we not going to get arrested? How do we move in packs and evade the inevitable law enforcement, all we're going to run into? So it was very specific. And it was really, really troubling. DAVIES: Right. And there was a feedback loop - right? - where people would then post videos of themselves doing - what? - you know, I don't know - stacking ammo and putting on goggles and tactical gear? TIMBERG: Indeed. So there was that - there was imagery of sort of preparing for violence and unrest. And then that, of course, carried on on January 6 itself, where on these very same online forums people were talking about what they were doing, talking about what they were seeing. They were taking videos and pictures and narrating the action in a way that, you know, (laughter) everyone who wasn't, you know, part of the Qanon group or wasn't kind of - you know, didn't want to see a bunch of people storm their Capitol found really disturbing and abhorrent. And that, in a way, was - ended up - you know, the social media aspect allowed them to organize in a way that wouldn't have been possible. But it also caused them to be exposed to the world in a way that wouldn't otherwise have been possible and may have led to their, you know - maybe not their demise, but certainly their fracturing now. DAVIES: You know, when the social media restrictions were imposed on a lot of these groups, many of them found refuge in this site, Parler - P-A-R-L-E-R - which was a site which allowed much more free-flowing debate. And, you know, these groups could flourish. It has gotten the attention of congressional investigators who've expressed concern about ties to Russia. What's going on here? TIMBERG: Parler was founded in 2018 as an alternative to Twitter that had virtually no content moderation. So if you - if it was within the law to say it, you could say it on Parler. And it gained a lot of traction as Twitter and Facebook and YouTube began to crack down on things like hate speech and incitement of violence and et cetera. So it had a really kind of robust place in the market that was growing more and more for months. The reason why, you know, some congressional leaders want to investigate it is because so much of the sort of inciting to violence around the Capitol siege happened there. And there's also, you know, some sort of Russian connections that are, you know, worthy of learning more about. The CEO's wife is Russian. And I don't know if that's a problem or not. But members of Congress want to know if that's a problem. And Parler also has - is using, you know, a web services company that's based in Russia. And that has raised concerns because, you know, companies based in Russia are subject to Russian laws. And hence, data can be sucked up. And presumably, the spies can look in on that stuff, too. So those are the sources of concern more than the ownership exactly. But, yeah, the Congress - it's on the radar of Democrats in Congress. DAVIES: Has Q himself, this anonymous figure or, supposedly, a high-ranking government official, has he posted anything since the election? TIMBERG: Yes, but very little. I mean, the - you know, Q, who we presume is a man, but we don't actually know, has posted - I don't know - three or four times since the election. But it's gone largely dark. And it's not the first time that this has happened. But it sure has caught everyone's notice that at a moment when kind of Qanon ideas are traveling more widely than ever and that we're approaching this moment of reckoning that the supposed leader of the movement has been quiet. So yeah, it's been a very striking turn of events. DAVIES: Right. And the predictions - you know this stuff better than I do - but, I mean, was that there would be this apocalyptic confrontation which would result in the mass arrests of these Democrats and celebrities and pedophiles. The great awakening, the storm, that was the prediction, right (laughter)? TIMBERG: It was the prediction from the very beginning, actually. I mean, going back to October, 2017, when Qanon existed on a previous place called 4chan, the first - the very first posts talk about arrests. They talk about arresting Hillary Clinton in particular. And somehow, the fact that these predictions never came true was, you know, internalized and metabolized by Qanon believers all along. DAVIES: Let me reintroduce you. We're going to take another break here. We're speaking with Craig Timberg. He's a national technology reporter for The Washington Post. He'll be back to talk more after this short break. I'm Dave Davies. And this is FRESH AIR. (SOUNDBITE OF JOHN COLTRANE'S \"TUNJI\")DAVIES: This is FRESH AIR. I'm Dave Davies in for Terry Gross, who's off this week. We're speaking with Craig Timberg. He's a national technology reporter for The Washington Post specializing in privacy, security and disinformation. He's written recently about the followers of the QAnon conspiracy theories and other extremist groups that were involved in the assault on the U. S. Capitol on January 6. We're talking about how President Trump's departure and social media restrictions on him and many of these groups will affect them and the nation in the coming months. So let's talk about how Trump's departure and the Capitol assault affected all of this. After this happens and, you know, Trump goes to Florida, and Joe Biden is inaugurated, and Trump, you know, kind of condemns the violence, how have QAnon members reacted? TIMBERG: Different people have reacted in different ways. And I'd say there is absolutely a group that says, hold on a minute, like, what happened to the storm? Like, how is Joe Biden now president? And there is clearly consternation - in some cases, outrage - among people who feel like they were misled. DAVIES: Can we just focus on them for a moment, Craig? I mean, are they saying, hey, we've been duped - do they say this was all - we've been played? What do we hear? TIMBERG: We have heard exactly those kinds of comments, people feeling duped, people feeling played, people being angry. Yes. DAVIES: And have some of them left or taken down their sites or. . . TIMBERG: Yeah. It's hard to know exactly what the impact has been because, you know, Twitter, et cetera, have been so aggressive at knocking these forums. down. I mean, in preparation for this conversation, I sort of poked around some of my familiar places. It's actually relatively hard to get a feel for what's going on in the QAnon community now because the community has been smashed into a hundred different bits. And you can find it, but it used to be you typed QAnon into Twitter and you knew immediately what was on people's minds. It's just not true anymore. DAVIES: Clearly, some disappointment, some disillusionment. What about others who are still believers? How do they interpret these events? TIMBERG: So I would say they fall into two broad categories. There are those who believe that the great storm is still coming in some way, shape or form, even though President Biden is now in office. And I guess actually there's two iterations of this. One is that President Trump is secretly in charge and controlling events from Mara-a-Lago, I guess. The other is that there's a new date, March 4, which is - was the original inauguration date in this country, was done away with, I believe, in the '30s, and that when March 4 arrives, Donald Trump will swoop back in and say, oh, I've been president all along. I'm taking a second term. And then the mass arrests and the coming storm will happen then. So we'll have to see what happens to that group when that day comes and goes. But then there's like an even more angry kind of dead-ender group that is feeling as though the central tenets of QAnon about pedophilia and Satan worshipping, et cetera, have been true all along, that Donald Trump was not maybe the messiah they thought he was, and that they're sort of like preparing for a longer struggle. Of all the groups, that one kind of scares me because they're really doubling down on the most terrifying parts of these prophecies. DAVIES: So let's talk about what's happened on social media platforms in response to particularly the violence at the Capitol. What have these large platforms done? TIMBERG: All of the big platforms - really, all at once - acted against Donald Trump. They began seeing what we all had seen for a long time, which was that the president was a huge source of misinformation that was reverberating through our world and shaping it in all sorts of ways. And so he got, you know, de-platformed by Twitter and Facebook and such. And other online forums that were pro-Trump and also pro-QAnon also have really had a rough few weeks. So one we've written a lot about is Parler, which was founded as kind of a - what they would call a free speech alternative to Twitter. There was supposed to be essentially no rules as long as what you did was legal. You know, Parler was knocked offline. It was kicked out of the App Store by Apple and Google. Its web hosting services from Amazon were withdrawn. And they're working pretty hard to get back online, but they're really not online now. And another forum that was very prominent in all of this called thedonald. win has also disappeared. And now there's two new versions of that and it's not clear which one of those is going to emerge. So in the social media world, the mainstream platforms have cracked down on this stuff. They've closed tens of thousands of accounts finally. And in addition to that, the smaller platforms have really struggled to stay online and stay coherent. It's been a tough - it's a tough time to be a QAnon believer, believe it or not. DAVIES: Right, certainly hard for people like you to find them and presumably harder for them to find each other. TIMBERG: Yeah. I mean, I think the the conventional wisdom is, A, the Internet's such a big place that there will always be places for them to gather and talk to each other. What they lose is the ability to like, you know, talk to my uncle, might stumble upon this stuff on Facebook. Like, that has really been removed. But, B, the other place people have gone are these encrypted chat apps, Signal and Telegram, et cetera. And I love these apps. Like, I use Signal every day, all day long. And I think it's great. But the downside of it is that there's really no way to monitor what's going on on a platform where the communications are encrypted end to end, meaning from my phone to your phone. And so I think there's a lot of evidence that folks have moved off of places where they can be easily monitored, not just by researchers and journalists like me, but also by the FBI. They have moved off of these places into these darker, quieter places where they can speak in an unfettered way. And there's no real - there's very little possibility anyway to be overheard by someone they don't want to overheard by. DAVIES: Maybe you should catch some of us who are less technologically savvy up a bit on this. You said you used - what was it? - Signal? TIMBERG: I use Signal. TIMBERG: And, yeah, what is it? What do you use it for? DAVIES: Signal is a communications app that goes, you know, essentially from phone to phone or computer to computer. And so when I send a message or have a phone call on Signal, my software in my phone turns it into encryption, which is basically, you know, if it was intercepted on the way, it looks just like a jumble of code. It's just sort of gibberish, essentially. And then it lands in, say, my friend's phone and it gets unencrypted and becomes my voice or an image or a text message. And so for someone like me who, you know, does a lot of communicating and doesn't necessarily want everyone to know what I'm saying about whatever or who I'm talking to, it's a complete godsend. I mean, reporters in Washington use Signal and similar things all the time. And that's true of human rights workers. It's true of political dissidents. The ability to communicate without your government easily just tapping in is great. But as with all of these technologies, it's also something where criminals use it and, you know - and terrorists use it. And so it's a double-edged sword, ultimately. I love it, but the police don't love it - I can tell you that. DAVIES: Let me reintroduce. We're going to take another break here. We're speaking with Craig Timberg. He's a national technology reporter for The Washington Post. We'll continue our conversation after this short break. I'm Dave Davies, and this is FRESH AIR. (SOUNDBITE OF MUSIC)DAVIES: This is FRESH AIR. And we're speaking with Washington Post reporter Craig Timberg. We're talking about how President Trump's departure and social media restrictions on him and some of his more extremist supporters, including followers of the QAnon conspiracy theories, will affect events in the coming months and years. You know, apart from the crackdown on QAnon and other extremist groups on social media, probably the most far-reaching move was to take Donald Trump off of Twitter and Facebook. And you're right about this. I mean, this has impacts far beyond, you know, spreading conspiracy theories, doesn't it? This is kind of a major social change, isn't it? TIMBERG: Absolutely. And it's one that, you know, for me, it does make me uncomfortable. Like, I mean, I think that it's certainly true that Donald Trump had become a major source of misinformation in the world, right? The Washington Post, my colleagues who do the fact-checking, counted 30,000 falsehoods during Donald Trump's presidency. And let's remember - he rose to political prominence pushing another lie, which was that Barack Obama wasn't born in the United States - right? - the birther conspiracy theory. So absolutely, he had become - in the public conversation, he had become very powerful and also was pushing a lot of untruths. At the same time, it's problematic when any group of people decides who of us gets to speak and how. And now I don't - I wouldn't love it if the government took away my ability to communicate. I don't love it that social media companies are now put in this position. I'm not sure that it's the wrong choice. It may well be the right choice. But it does raise all sorts of really uncomfortable issues about who gets to talk, what they get to say and where these red lines are. And for my money - I've been covering the intersection of these issues for eight or nine years now - I've never found a really comfortable place in terms of, like, where - not only what the rules should be, but who should make the rules, right? And that debate - the removal of Donald Trump from Twitter and Facebook really brings that debate back to center stage. Who gets to decide who gets to talk and how? And while there's certainly not a First Amendment right to have a Twitter account or anything like it, to deny the power that these companies are now wielding is - seems to me to be shortsighted. DAVIES: Yeah. I mean, ideally, we would want, you know, learned judges making good-faith decisions based on a careful reading of the Constitution. Here we have these big private companies that, because of the way the Communications Act is structured, has this enormous power. And it's interesting. You know, Facebook has committed to a formal process on deciding what happens to Donald Trump's access in the future. I mean, can you describe this? Are you familiar with this? TIMBERG: I don't know all of the ins and outs of this process. But I can tell you that, as someone who's written critically about all of these companies for many years, this is one point in which I actually have more than the usual sympathy (laughter) because, you know, we just don't have laws in this country that give these private companies guidelines to follow, right? So people talk a lot about the First Amendment and the freedom to speech, but the First Amendment governs what governments do. That does not say anything about what private companies can do. And as you said, the Section 230 of the Communications Decency Act likewise gives companies a lot of latitude to monitor and kind of manage their platforms. But it doesn't say how. It doesn't say where the lines are. And so we're asking a bunch of private companies that are fundamentally about expanding their markets and making money to draw lines that we've been unwilling as a society to draw more broadly. And that strikes me as, like, not a great setup. And I applaud Facebook for trying to - you know, to set up a more formalized structure to wrestle with it. But it all comes down to who's really, really in charge, right? And you know who's really, really in charge? Mark Zuckerberg's in charge, right? (Laughter) He's the CEO of Facebook. He controls the voting shares of the stock. You know, Jack Dorsey at Twitter, he's in charge, right? And the only good part of this is that they are responsive to public opinion and market forces and when, after a lot of the unrest last year, a bunch of advertisers boycotted and were able to make some changes. So I guess one could argue that on some level the system's working. But deciding who should be making these calls is hard. And I think if as a society we got together, we probably wouldn't put all of this power in the hands of Mark Zuckerberg, would we? DAVIES: The interesting thing to note about this is that what, you know, Zuckerberg has done, apparently, is to assemble this large committee and given them quite a staff, about 30 people, and has promised to abide by their decision and given them, you know, a deadline. So it will be fascinating to see where it takes us. TIMBERG: Totally. But he promises to abide by it until he changes his mind, right? DAVIES: Still abide (laughter). TIMBERG: Just a - yeah. I mean, there's no - there's just no legal authority to it. And so what I'm saying is - we're a democracy, right? I mean, this is the job of Congress (laughter) to - or the executive branch to try to wrestle with this and lay out some kind of legal guidance or some jurisprudence or whatever. And, you know, our elected representatives ought to be making - trying to make these decisions, you know, and reflecting the will of the people, not - you know, not a handful of billionaires in California. DAVIES: How effective are bans like this? Do we know? Do we know how much disinformation changed in the United States, for example, once Trump's accounts were suspended? TIMBERG: I mean, happily we do know the answer to that question now because by a variety of metrics, you know, misinformation around the election plummeted after Trump's account was taken away by Twitter and a variety of other actions, including the closing of 70,000 Twitter accounts that were pushing QAnon. I mean, I think the number that we've quoted is 73%. Others have come up with a similar kind of measurement. And so this gets to the heart of the problem. I mean, so while we would - while we love free speech and we want free speech to be as open as possible, it's also true that my speech can drown out your speech, and my lies can drown out your truth. And so those don't seem like good outcomes to me. And so what we have in the past few weeks is kind of a science experiment. Like, what do you - what happens when you turn down or really eliminate the voice of someone who is pushing a lot of lies? It turns out that a lot - those lies have a lot less traction. They move around less often. DAVIES: So let's talk about what happens now. It seems QAnon and other extremist groups are probably finding it harder to communicate with each other, certainly harder to reach a mass audience. Is it possible that those under these restrictions might become more committed, more militant? TIMBERG: Certainly. And researchers have been saying to me for weeks that the people who stick around, the people - the QAnon believers who, you know, kind of - whose beliefs survive the inauguration of President Biden are likely to be more committed, they're likely to be more fervent and more conspiratorial and that there's also going to be active recruitment of people from the really, really hardcore haters, the neo-Nazis and the white supremacists, that they're going to sort of see disaffected QAnon folks as targets for specific kinds of recruitment. So I think that there is a real danger that what we'll see is a somewhat smaller but maybe more fervent and maybe more hateful and maybe more stealthy remnant that, you know, remains a force in our political life, you know, for years to come and maybe also, you know, engages in acts of violence. DAVIES: One of the things that's occurred to me after - in the wake of the assault on the Capitol is, you know, how it is seen by those who are, you know, very committed adherents of some of these extremist ideologies. And on the one hand, you could regard it as a crushing defeat, right? I mean, you got chased out. Biden was - his election was certified, and Trump left. You could also see it as something that would really embolden you. It was sort of an unprecedented act, the first step in many to really make a mark. I don't know. Do you have any feel for how it's playing? TIMBERG: I'd say there's two narratives that have begun to play out. One is - and this happened instantaneously - was the effort to recast what happened as somehow the work of left-wing activists - right? - that antifa and Black Lives Matter somehow got a lot of people who looked an awful lot like Trump supporters to storm the Capitol. Now, I'm laughing because on some level, it seems silly, but it's very well-trafficked. And it's - clearly, a lot of folks who weren't there believe that this was somehow a left-wing operation that was pulled off, and they've fooled the world yet again. That's the beauty of conspiratorial thinking. You can always plug a new fact in and - you know, and move it around a little bit and still kind of hold. The second piece of this is, as you suggested, that somehow this is the first step in a movement that's going to lead to more power for - you know, sort of for this hardcore group of Trump followers that - I mean, and it's not inherently crazy, right? Like, it isn't like, you know - Tiananmen Square was not - was, you know, seen correctly as a great day for the democracy movement in China, but it didn't lead directly to democracy, right? So the idea that a big public stand ends in sort of defeat in the immediate sense but somehow, you know, sets up the future in a way that is - you know, that could lead to bigger, more successful events later - like, that's - you know, that's not totally crazy. That has some historical antecedents that, if you wanted to believe it, you could turn into something that feels true. DAVIES: Craig Timberg, thanks so much for speaking with us. TIMBERG: Yeah, it's been great talking to you. Thanks for having me on the show. DAVIES: Craig Timberg is a national technology reporter for The Washington Post specializing in privacy, security and disinformation. Coming up, Maureen Corrigan reviews Chang-Rae Lee's new novel \"My Year Abroad,\" about an American college student who travels to Asia for a very unusual education. This is FRESH AIR. (SOUNDBITE OF AARON PARKS' \"SMALL PLANET\") DAVE DAVIES, HOST:   This is FRESH AIR. I'm Dave Davies in for Terry Gross, who's off this week. As Donald Trump's presidency neared its end, there was growing evidence among his followers of the influence of QAnon, a set of conspiracy theories holding that Trump was battling a cabal of deep state actors and their celebrity allies who were undermining Trump and engaging in satanic worship and pedophilia. QAnon supporters were well-represented in the deadly assault on the Capitol on January 6. But Trump's departure from the White House and Joe Biden's inauguration as president may have left many QAnon followers angry and confused, since they expected Trump to vanquish his adversaries and remain in power. After the mob stormed the Capitol, Twitter, Facebook and YouTube banned Trump, and many of those social media platforms have targeted QAnon as well. Twitter and Facebook have removed a combined total of more than a hundred thousand QAnon-linked accounts. For some insight into what these events mean for QAnon and other extremist groups in the country, we've invited Craig Timberg to join us. He's a national technology reporter for The Washington Post, specializing in privacy, security and disinformation. He's written on QAnon and related subjects in recent months. Since joining the Post in 1998, he's been a reporter, editor and foreign correspondent and co-authored the book \"Tinderbox: How The West Sparked The AIDS Epidemic And How The World Can Finally Overcome It. \" He joins us from his home in Washington, D. C. Well, Craig Timberg, welcome back to FRESH AIR. I think maybe we should start with just a little primer on what QAnon is. People may have heard the names. Some may be fuzzy on what exactly it is. Just give us the basics. CRAIG TIMBERG: Well, thanks, first of all, for having me on the show. This question you ask is harder than it sounds because we researchers and journalists debate exactly what QAnon is. In fact, our copy editors are questioning whether we should call it a conspiracy theory or an extremist ideology. Some researchers think it's a cult. Some think it's an alternative reality game. So it's a little hard to wrap your brain around. You called it a kind of collection of conspiracy theories, which kind of works for me. But the gist is that there is a person who goes by the pseudonym Q who is supposedly a top secret official in the U. S. government, who is sort of gradually dribbling out the truth about what's really happening in the world. And as you said, a lot of this truth has to do with the idea that prominent Democrats and Hollywood celebrities are pedophiles, that they traffic in children for sex - and they also eat those children on at least some occasions - and that they are working together to undermine the U. S. government and take control of essentially the whole world. And so these ideas have been dribbled out on a forum called 8kun. And people who believe in this then take those sort of cryptic messages, share it among themselves, analyze it, and then, you know, have sort of become a community of sort of, you know, fellow travelers in this stuff that seems so crazy to many of us but actually is a really animating force in a lot of people's lives and has been for years. DAVIES: Right. And they regard Trump as their champion, battling this deep state cabal. And we'll get into this a bit later. But what's the specific reason that they might have been so disappointed to see Trump actually leave office? TIMBERG: Well, you put it well - right? - I mean, that Trump is their leader. And I think if you were to kind of make a series of circles of like, you know, Republicans and then the subset of Republicans who are Trump enthusiasts and then the subset of Republicans who are really, really diehard Trump enthusiasts, like, QAnon is in the in the dead center of those circles. Like, some of the most fervent Trump supporters in the world believe in QAnon. And so - and they regard him not merely as their president and leader, but also as essentially a messiah. And so, you know, I was seeing messages the night of January 19, when President-elect Joe Biden was presiding over a ceremony at the Lincoln Memorial, in which QAnon supporters were saying, hang on, right? Trump is still going to - he's going to stay in office. He's going to take control. All of our prophecies are going to come true. So when the when that didn't happen the next day on the inauguration, when Joe Biden actually became president, there was just huge amounts of consternation and cognitive dissonance or whatever you want to call it because they just - they had trouble making sense of it. And so there's all these new theories that are now spinning out of it. But it was a clash of reality with prophecy that was very discomforting to people. DAVIES: And the prophecy was that there would be mass arrests of these Democrats and pedophiles, right? TIMBERG: Yeah. I mean, that was part of it, that Trump was going to stay in office, that he had really won the election, that the various baseless claims of election fraud were going to be true and proven true and acted upon as though they were true, and that a bunch of Democrats were going to be rounded up and arrested and, depending on which version of this you believed, you know, shot or hung. DAVIES: All right. Let's back up a little bit and go back, you know, before the events of this January. You know, over the past year, couple of years, there was growing evidence of support among QAnon. It's always been hard to tell how many supporters it had. It's not like a membership organization. But it came to be recognized as a serious threat by law enforcement, right? TIMBERG: Indeed. Going back several years now, you know, QAnon is essentially born in October 2017 on a, you know, on a message board called 4chan. And then, you know, the conversation online, including on mainstream platforms like Facebook and Twitter and YouTube, is almost immediately terribly violent. And they're calling for firing squads and nooses and all that for people who were supposedly, you know, pedophiles, et cetera. And within, you know, a couple of years, there had been some incidents that flowed out of that online talk of violence. There was a - there's an incident at the Hoover Dam where an armed man in a truck kind of, you know, blocked off traffic for a while and got arrested. There were - there was an actual murder in New York City of a mob boss by someone who was inspired by QAnon. And so, you know, the FBI, you know, issued a warning about QAnon is a domestic terrorism threat a couple of years ago. The, you know, researchers at West Point issued a similar warning. And countless independent researchers, you know, started sending up, you know, bright red flashing warnings years ago that this was not merely something that was roiling the online world, but it was something that had the potential to spill into our world, our real world, and cause actual violence and harm to people. DAVIES: And at the same time, it was sort of gaining credibility among more mainstream Republicans, right? I mean, you had a number of Republican candidates who spoke, you know, flatteringly of QAnon. A couple have made it into Congress. That's a part of this picture, too, isn't it? TIMBERG: Yeah, absolutely. It's very hard for me as a newspaper reporter to know what percentage of the people who kind of mouth these various conspiracy theories, believe them, or find the merely convenient, right? There's always been an element of profiteering about QAnon. There's T-shirts to sell and books to sell and websites to stand up with, you know, advertising. And there's also political opportunity. And lots of politicians, you know, overwhelmingly but not exclusively Republicans, have, at a minimum, found it useful to kind of hint that they are aligned with this ideology. And indeed, you know, a couple of them are now in Congress. And the kind of footprint of QAnon among, you know, Republicans in the United States is, you know, probably larger than many of your listeners imagine. Again, there's no precise way to measure it. But at a minimum, there's a lot of kind of affinity for the ideas that QAnon traffics in among Republicans in this country. DAVIES: Right. Now, there have been - social media platforms have have imposed restrictions on Qanon and many others after the events of January. But it's easy to forget that this didn't just start then. In 2019, there were some - also sort of a crackdown on Qanon. What happened? TIMBERG: There's been a variety of crackdowns. You know, the platform Reddit a couple of years ago - you know, Reddit was the site where a previous conspiracy theory called Pizzagate, which also imagined that Democrats in Washington were trafficking in children and running a sex ring. You know, Reddit was sort of, like, you know, ground zero for Pizzagate. And so when Qanon flared up, Reddit acted pretty aggressively almost immediately in 2018 to purge that stuff from the platform. The other platforms - Twitter, Facebook, YouTube - were much, much slower. And I and others have done stories that have looked back at how violent and unhinged the conversation around Qanon was, you know, going back several years now and pointing out (laughter) that the platforms just basically didn't do much of anything for a long time. Now, they did quite a bit more in 2020. And they did, actually, to be fair, quite a bit more before this thing blossomed into the kind of consuming catastrophe it became around the election time. And so - and interestingly, this has to do with the coronavirus because, you know, as the pandemic arrived around the world and COVID disinformation became so prominent - you know, untrue things about how it spread, about masks, about vaccines - the people around those companies said, well, hang on a minute. Like, it's OK if people want to lie about politics. But it's not OK if they lie about science. And so what we saw, beginning, really, late winter last year, was a broad movement in Silicon Valley to kind of enforce the truth, which is something they'd never wanted to do before. And so that - once they kind of got the taste of it and saw the impact of enforcing truth and casting disinformation off their platforms, they became progressively more, you know, intent on doing that. And that meant that a lot of things that had never happened in previous years suddenly began happening. And so part of that was Facebook, Twitter, YouTube all crackdown on Qanon over the summer. They closed a bunch of accounts. They limited the reach of the accounts that were still there. And they kind of put everybody on notice that that wasn't really going to play on the platforms before. And what we've seen since then is a continuation of that. And the events of recent weeks, the platforms have finally really, really taken a hammer to these ideas and to the people pushing them on mainstream platforms. And it's really led to a fracturing of the whole community. DAVIES: And it was probably harder for these social media platforms to act decisively given the criticism that they're unfairly targeting conservatives all the time, right? TIMBERG: Yes. To some extent, that's certainly true. I think it's fair to ask how much harder it would have been. It certainly is the case that Facebook, in particular, and to some extent the others, were just terrified of angering President Trump and his followers. And there were two reasons for that. One is President Trump was the most powerful person in the world, you know, oversaw the Justice Department, had leverage in Congress. And if he wanted to go after the social media companies, as he ultimately did, that was a big problem for them. So yeah, that was an issue. Secondly, you know, Facebook in particular didn't want to be known as the platform for, you know, liberal America or modern America. They wanted to - you know, these are customers. They wanted to have all of America. They wanted to have all of the world. And so if this idea that Facebook or Twitter or YouTube was, you know, really just a platform for the left, that meant - that had real business stakes for all of these companies that they were deeply aware of. Now, all that said, I think the events of the past few weeks have really reinforced how, actually, easy it was for the platforms to make these decisions once they were ready to make these decisions. And it hasn't been lost on anybody that all of these companies acted on the very day that Biden's ascent to the White House became clear and that the Democrats' control of the Senate also became clear, right? So on the same day that - on January 6 - that the mobs overtake the Capitol, we'd learn that these two runoffs in Georgia have yielded two new Democrats, which meant a new party was going to be in charge in Washington. And so yes, it was politically hard for the platforms to act against a dominant Republican Party in the past few years. But it also clearly was logistically super easy and simple to just turn off some of this stuff. And there's real questions about whether they should have done that sooner. DAVIES: Right. And the fact that all the committee chairs in Congress going forward would all be Democrats probably just eased their minds a bit. TIMBERG: Indeed. DAVIES: Let me reintroduce you. We're going to take a little break here. We're speaking with Craig Timberg. He's a national technology reporter for The Washington Post. We'll continue our conversation in just a moment. This is FRESH AIR. (SOUNDBITE OF ANAT COHEN'S \"NIGHTMARE\") DAVIES: This is FRESH AIR. And we're speaking with Washington Post reporter Craig Timberg. We're talking about how President Trump's departure and social media restrictions on him and some of his more extremist supporters, including followers of the Qanon conspiracy theories, will affect events in the coming months. You wrote that before the Capitol rally on January 6, which, of course, you know, the president summoned and attracted people to and said it's going to be wild - all that stuff - that you followed the website, thedonald. win, and that you saw it was host to a really troubling interaction between online rage and real-life activity. You want to just describe some of that? TIMBERG: Yeah. Certainly. The - it wasn't just thedonald. win, it was Parler. It was Gab. It was a whole coterie of kind of new-ish, largely conservative social media platforms that were just boiling over with rage. And it wasn't the first time I had seen this. And - but it also took on a certain kind of urgency because January 6 was seen as the day - sort of their last stand, right? This was a day Congress was going to meet. They were going to certify the results of the election. And if that election was going to be overturned, it had to happen then. And so you could see both an intensity of rage, calling for the killing or arrests of Democrats. You could see calls to, you know, attack the Capitol. And you also could see logistical conversations happening about what they were going to do. It wasn't super tactical. But it was, you know, how can we bring guns to D. C. ? How are we not going to get arrested? How do we move in packs and evade the inevitable law enforcement, all we're going to run into? So it was very specific. And it was really, really troubling. DAVIES: Right. And there was a feedback loop - right? - where people would then post videos of themselves doing - what? - you know, I don't know - stacking ammo and putting on goggles and tactical gear? TIMBERG: Indeed. So there was that - there was imagery of sort of preparing for violence and unrest. And then that, of course, carried on on January 6 itself, where on these very same online forums people were talking about what they were doing, talking about what they were seeing. They were taking videos and pictures and narrating the action in a way that, you know, (laughter) everyone who wasn't, you know, part of the Qanon group or wasn't kind of - you know, didn't want to see a bunch of people storm their Capitol found really disturbing and abhorrent. And that, in a way, was - ended up - you know, the social media aspect allowed them to organize in a way that wouldn't have been possible. But it also caused them to be exposed to the world in a way that wouldn't otherwise have been possible and may have led to their, you know - maybe not their demise, but certainly their fracturing now. DAVIES: You know, when the social media restrictions were imposed on a lot of these groups, many of them found refuge in this site, Parler - P-A-R-L-E-R - which was a site which allowed much more free-flowing debate. And, you know, these groups could flourish. It has gotten the attention of congressional investigators who've expressed concern about ties to Russia. What's going on here? TIMBERG: Parler was founded in 2018 as an alternative to Twitter that had virtually no content moderation. So if you - if it was within the law to say it, you could say it on Parler. And it gained a lot of traction as Twitter and Facebook and YouTube began to crack down on things like hate speech and incitement of violence and et cetera. So it had a really kind of robust place in the market that was growing more and more for months. The reason why, you know, some congressional leaders want to investigate it is because so much of the sort of inciting to violence around the Capitol siege happened there. And there's also, you know, some sort of Russian connections that are, you know, worthy of learning more about. The CEO's wife is Russian. And I don't know if that's a problem or not. But members of Congress want to know if that's a problem. And Parler also has - is using, you know, a web services company that's based in Russia. And that has raised concerns because, you know, companies based in Russia are subject to Russian laws. And hence, data can be sucked up. And presumably, the spies can look in on that stuff, too. So those are the sources of concern more than the ownership exactly. But, yeah, the Congress - it's on the radar of Democrats in Congress. DAVIES: Has Q himself, this anonymous figure or, supposedly, a high-ranking government official, has he posted anything since the election? TIMBERG: Yes, but very little. I mean, the - you know, Q, who we presume is a man, but we don't actually know, has posted - I don't know - three or four times since the election. But it's gone largely dark. And it's not the first time that this has happened. But it sure has caught everyone's notice that at a moment when kind of Qanon ideas are traveling more widely than ever and that we're approaching this moment of reckoning that the supposed leader of the movement has been quiet. So yeah, it's been a very striking turn of events. DAVIES: Right. And the predictions - you know this stuff better than I do - but, I mean, was that there would be this apocalyptic confrontation which would result in the mass arrests of these Democrats and celebrities and pedophiles. The great awakening, the storm, that was the prediction, right (laughter)? TIMBERG: It was the prediction from the very beginning, actually. I mean, going back to October, 2017, when Qanon existed on a previous place called 4chan, the first - the very first posts talk about arrests. They talk about arresting Hillary Clinton in particular. And somehow, the fact that these predictions never came true was, you know, internalized and metabolized by Qanon believers all along. DAVIES: Let me reintroduce you. We're going to take another break here. We're speaking with Craig Timberg. He's a national technology reporter for The Washington Post. He'll be back to talk more after this short break. I'm Dave Davies. And this is FRESH AIR. (SOUNDBITE OF JOHN COLTRANE'S \"TUNJI\") DAVIES: This is FRESH AIR. I'm Dave Davies in for Terry Gross, who's off this week. We're speaking with Craig Timberg. He's a national technology reporter for The Washington Post specializing in privacy, security and disinformation. He's written recently about the followers of the QAnon conspiracy theories and other extremist groups that were involved in the assault on the U. S. Capitol on January 6. We're talking about how President Trump's departure and social media restrictions on him and many of these groups will affect them and the nation in the coming months. So let's talk about how Trump's departure and the Capitol assault affected all of this. After this happens and, you know, Trump goes to Florida, and Joe Biden is inaugurated, and Trump, you know, kind of condemns the violence, how have QAnon members reacted? TIMBERG: Different people have reacted in different ways. And I'd say there is absolutely a group that says, hold on a minute, like, what happened to the storm? Like, how is Joe Biden now president? And there is clearly consternation - in some cases, outrage - among people who feel like they were misled. DAVIES: Can we just focus on them for a moment, Craig? I mean, are they saying, hey, we've been duped - do they say this was all - we've been played? What do we hear? TIMBERG: We have heard exactly those kinds of comments, people feeling duped, people feeling played, people being angry. Yes. DAVIES: And have some of them left or taken down their sites or. . . TIMBERG: Yeah. It's hard to know exactly what the impact has been because, you know, Twitter, et cetera, have been so aggressive at knocking these forums. down. I mean, in preparation for this conversation, I sort of poked around some of my familiar places. It's actually relatively hard to get a feel for what's going on in the QAnon community now because the community has been smashed into a hundred different bits. And you can find it, but it used to be you typed QAnon into Twitter and you knew immediately what was on people's minds. It's just not true anymore. DAVIES: Clearly, some disappointment, some disillusionment. What about others who are still believers? How do they interpret these events? TIMBERG: So I would say they fall into two broad categories. There are those who believe that the great storm is still coming in some way, shape or form, even though President Biden is now in office. And I guess actually there's two iterations of this. One is that President Trump is secretly in charge and controlling events from Mara-a-Lago, I guess. The other is that there's a new date, March 4, which is - was the original inauguration date in this country, was done away with, I believe, in the '30s, and that when March 4 arrives, Donald Trump will swoop back in and say, oh, I've been president all along. I'm taking a second term. And then the mass arrests and the coming storm will happen then. So we'll have to see what happens to that group when that day comes and goes. But then there's like an even more angry kind of dead-ender group that is feeling as though the central tenets of QAnon about pedophilia and Satan worshipping, et cetera, have been true all along, that Donald Trump was not maybe the messiah they thought he was, and that they're sort of like preparing for a longer struggle. Of all the groups, that one kind of scares me because they're really doubling down on the most terrifying parts of these prophecies. DAVIES: So let's talk about what's happened on social media platforms in response to particularly the violence at the Capitol. What have these large platforms done? TIMBERG: All of the big platforms - really, all at once - acted against Donald Trump. They began seeing what we all had seen for a long time, which was that the president was a huge source of misinformation that was reverberating through our world and shaping it in all sorts of ways. And so he got, you know, de-platformed by Twitter and Facebook and such. And other online forums that were pro-Trump and also pro-QAnon also have really had a rough few weeks. So one we've written a lot about is Parler, which was founded as kind of a - what they would call a free speech alternative to Twitter. There was supposed to be essentially no rules as long as what you did was legal. You know, Parler was knocked offline. It was kicked out of the App Store by Apple and Google. Its web hosting services from Amazon were withdrawn. And they're working pretty hard to get back online, but they're really not online now. And another forum that was very prominent in all of this called thedonald. win has also disappeared. And now there's two new versions of that and it's not clear which one of those is going to emerge. So in the social media world, the mainstream platforms have cracked down on this stuff. They've closed tens of thousands of accounts finally. And in addition to that, the smaller platforms have really struggled to stay online and stay coherent. It's been a tough - it's a tough time to be a QAnon believer, believe it or not. DAVIES: Right, certainly hard for people like you to find them and presumably harder for them to find each other. TIMBERG: Yeah. I mean, I think the the conventional wisdom is, A, the Internet's such a big place that there will always be places for them to gather and talk to each other. What they lose is the ability to like, you know, talk to my uncle, might stumble upon this stuff on Facebook. Like, that has really been removed. But, B, the other place people have gone are these encrypted chat apps, Signal and Telegram, et cetera. And I love these apps. Like, I use Signal every day, all day long. And I think it's great. But the downside of it is that there's really no way to monitor what's going on on a platform where the communications are encrypted end to end, meaning from my phone to your phone. And so I think there's a lot of evidence that folks have moved off of places where they can be easily monitored, not just by researchers and journalists like me, but also by the FBI. They have moved off of these places into these darker, quieter places where they can speak in an unfettered way. And there's no real - there's very little possibility anyway to be overheard by someone they don't want to overheard by. DAVIES: Maybe you should catch some of us who are less technologically savvy up a bit on this. You said you used - what was it? - Signal? TIMBERG: I use Signal. TIMBERG: And, yeah, what is it? What do you use it for? DAVIES: Signal is a communications app that goes, you know, essentially from phone to phone or computer to computer. And so when I send a message or have a phone call on Signal, my software in my phone turns it into encryption, which is basically, you know, if it was intercepted on the way, it looks just like a jumble of code. It's just sort of gibberish, essentially. And then it lands in, say, my friend's phone and it gets unencrypted and becomes my voice or an image or a text message. And so for someone like me who, you know, does a lot of communicating and doesn't necessarily want everyone to know what I'm saying about whatever or who I'm talking to, it's a complete godsend. I mean, reporters in Washington use Signal and similar things all the time. And that's true of human rights workers. It's true of political dissidents. The ability to communicate without your government easily just tapping in is great. But as with all of these technologies, it's also something where criminals use it and, you know - and terrorists use it. And so it's a double-edged sword, ultimately. I love it, but the police don't love it - I can tell you that. DAVIES: Let me reintroduce. We're going to take another break here. We're speaking with Craig Timberg. He's a national technology reporter for The Washington Post. We'll continue our conversation after this short break. I'm Dave Davies, and this is FRESH AIR. (SOUNDBITE OF MUSIC) DAVIES: This is FRESH AIR. And we're speaking with Washington Post reporter Craig Timberg. We're talking about how President Trump's departure and social media restrictions on him and some of his more extremist supporters, including followers of the QAnon conspiracy theories, will affect events in the coming months and years. You know, apart from the crackdown on QAnon and other extremist groups on social media, probably the most far-reaching move was to take Donald Trump off of Twitter and Facebook. And you're right about this. I mean, this has impacts far beyond, you know, spreading conspiracy theories, doesn't it? This is kind of a major social change, isn't it? TIMBERG: Absolutely. And it's one that, you know, for me, it does make me uncomfortable. Like, I mean, I think that it's certainly true that Donald Trump had become a major source of misinformation in the world, right? The Washington Post, my colleagues who do the fact-checking, counted 30,000 falsehoods during Donald Trump's presidency. And let's remember - he rose to political prominence pushing another lie, which was that Barack Obama wasn't born in the United States - right? - the birther conspiracy theory. So absolutely, he had become - in the public conversation, he had become very powerful and also was pushing a lot of untruths. At the same time, it's problematic when any group of people decides who of us gets to speak and how. And now I don't - I wouldn't love it if the government took away my ability to communicate. I don't love it that social media companies are now put in this position. I'm not sure that it's the wrong choice. It may well be the right choice. But it does raise all sorts of really uncomfortable issues about who gets to talk, what they get to say and where these red lines are. And for my money - I've been covering the intersection of these issues for eight or nine years now - I've never found a really comfortable place in terms of, like, where - not only what the rules should be, but who should make the rules, right? And that debate - the removal of Donald Trump from Twitter and Facebook really brings that debate back to center stage. Who gets to decide who gets to talk and how? And while there's certainly not a First Amendment right to have a Twitter account or anything like it, to deny the power that these companies are now wielding is - seems to me to be shortsighted. DAVIES: Yeah. I mean, ideally, we would want, you know, learned judges making good-faith decisions based on a careful reading of the Constitution. Here we have these big private companies that, because of the way the Communications Act is structured, has this enormous power. And it's interesting. You know, Facebook has committed to a formal process on deciding what happens to Donald Trump's access in the future. I mean, can you describe this? Are you familiar with this? TIMBERG: I don't know all of the ins and outs of this process. But I can tell you that, as someone who's written critically about all of these companies for many years, this is one point in which I actually have more than the usual sympathy (laughter) because, you know, we just don't have laws in this country that give these private companies guidelines to follow, right? So people talk a lot about the First Amendment and the freedom to speech, but the First Amendment governs what governments do. That does not say anything about what private companies can do. And as you said, the Section 230 of the Communications Decency Act likewise gives companies a lot of latitude to monitor and kind of manage their platforms. But it doesn't say how. It doesn't say where the lines are. And so we're asking a bunch of private companies that are fundamentally about expanding their markets and making money to draw lines that we've been unwilling as a society to draw more broadly. And that strikes me as, like, not a great setup. And I applaud Facebook for trying to - you know, to set up a more formalized structure to wrestle with it. But it all comes down to who's really, really in charge, right? And you know who's really, really in charge? Mark Zuckerberg's in charge, right? (Laughter) He's the CEO of Facebook. He controls the voting shares of the stock. You know, Jack Dorsey at Twitter, he's in charge, right? And the only good part of this is that they are responsive to public opinion and market forces and when, after a lot of the unrest last year, a bunch of advertisers boycotted and were able to make some changes. So I guess one could argue that on some level the system's working. But deciding who should be making these calls is hard. And I think if as a society we got together, we probably wouldn't put all of this power in the hands of Mark Zuckerberg, would we? DAVIES: The interesting thing to note about this is that what, you know, Zuckerberg has done, apparently, is to assemble this large committee and given them quite a staff, about 30 people, and has promised to abide by their decision and given them, you know, a deadline. So it will be fascinating to see where it takes us. TIMBERG: Totally. But he promises to abide by it until he changes his mind, right? DAVIES: Still abide (laughter). TIMBERG: Just a - yeah. I mean, there's no - there's just no legal authority to it. And so what I'm saying is - we're a democracy, right? I mean, this is the job of Congress (laughter) to - or the executive branch to try to wrestle with this and lay out some kind of legal guidance or some jurisprudence or whatever. And, you know, our elected representatives ought to be making - trying to make these decisions, you know, and reflecting the will of the people, not - you know, not a handful of billionaires in California. DAVIES: How effective are bans like this? Do we know? Do we know how much disinformation changed in the United States, for example, once Trump's accounts were suspended? TIMBERG: I mean, happily we do know the answer to that question now because by a variety of metrics, you know, misinformation around the election plummeted after Trump's account was taken away by Twitter and a variety of other actions, including the closing of 70,000 Twitter accounts that were pushing QAnon. I mean, I think the number that we've quoted is 73%. Others have come up with a similar kind of measurement. And so this gets to the heart of the problem. I mean, so while we would - while we love free speech and we want free speech to be as open as possible, it's also true that my speech can drown out your speech, and my lies can drown out your truth. And so those don't seem like good outcomes to me. And so what we have in the past few weeks is kind of a science experiment. Like, what do you - what happens when you turn down or really eliminate the voice of someone who is pushing a lot of lies? It turns out that a lot - those lies have a lot less traction. They move around less often. DAVIES: So let's talk about what happens now. It seems QAnon and other extremist groups are probably finding it harder to communicate with each other, certainly harder to reach a mass audience. Is it possible that those under these restrictions might become more committed, more militant? TIMBERG: Certainly. And researchers have been saying to me for weeks that the people who stick around, the people - the QAnon believers who, you know, kind of - whose beliefs survive the inauguration of President Biden are likely to be more committed, they're likely to be more fervent and more conspiratorial and that there's also going to be active recruitment of people from the really, really hardcore haters, the neo-Nazis and the white supremacists, that they're going to sort of see disaffected QAnon folks as targets for specific kinds of recruitment. So I think that there is a real danger that what we'll see is a somewhat smaller but maybe more fervent and maybe more hateful and maybe more stealthy remnant that, you know, remains a force in our political life, you know, for years to come and maybe also, you know, engages in acts of violence. DAVIES: One of the things that's occurred to me after - in the wake of the assault on the Capitol is, you know, how it is seen by those who are, you know, very committed adherents of some of these extremist ideologies. And on the one hand, you could regard it as a crushing defeat, right? I mean, you got chased out. Biden was - his election was certified, and Trump left. You could also see it as something that would really embolden you. It was sort of an unprecedented act, the first step in many to really make a mark. I don't know. Do you have any feel for how it's playing? TIMBERG: I'd say there's two narratives that have begun to play out. One is - and this happened instantaneously - was the effort to recast what happened as somehow the work of left-wing activists - right? - that antifa and Black Lives Matter somehow got a lot of people who looked an awful lot like Trump supporters to storm the Capitol. Now, I'm laughing because on some level, it seems silly, but it's very well-trafficked. And it's - clearly, a lot of folks who weren't there believe that this was somehow a left-wing operation that was pulled off, and they've fooled the world yet again. That's the beauty of conspiratorial thinking. You can always plug a new fact in and - you know, and move it around a little bit and still kind of hold. The second piece of this is, as you suggested, that somehow this is the first step in a movement that's going to lead to more power for - you know, sort of for this hardcore group of Trump followers that - I mean, and it's not inherently crazy, right? Like, it isn't like, you know - Tiananmen Square was not - was, you know, seen correctly as a great day for the democracy movement in China, but it didn't lead directly to democracy, right? So the idea that a big public stand ends in sort of defeat in the immediate sense but somehow, you know, sets up the future in a way that is - you know, that could lead to bigger, more successful events later - like, that's - you know, that's not totally crazy. That has some historical antecedents that, if you wanted to believe it, you could turn into something that feels true. DAVIES: Craig Timberg, thanks so much for speaking with us. TIMBERG: Yeah, it's been great talking to you. Thanks for having me on the show. DAVIES: Craig Timberg is a national technology reporter for The Washington Post specializing in privacy, security and disinformation. Coming up, Maureen Corrigan reviews Chang-Rae Lee's new novel \"My Year Abroad,\" about an American college student who travels to Asia for a very unusual education. This is FRESH AIR. (SOUNDBITE OF AARON PARKS' \"SMALL PLANET\")", "section": "Politics", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-01-28-961391277": {"title": "Facebook Oversight Board Rules 4 Deleted Posts Must Be Restored : NPR", "url": "https://www.npr.org/2021/01/28/961391277/facebook-supreme-court-orders-social-network-to-restore-4-posts-in-first-rulings", "author": "No author found", "published_date": "2021-01-28", "content": "AILSA CHANG, HOST:  Facebook has created its own sort of Supreme Court. It's an oversight board that has the final say on some of its hardest decisions over what users can and cannot post. Today, that board issued its first rulings. It ordered the social network to restore several posts that it had removed for breaking Facebook rules. NPR tech correspondent Shannon Bond joins us now to explain. Hey, Shannon. SHANNON BOND, BYLINE: Hey, Ailsa. CHANG: So we should first note Facebook is among NPR's financial supporters. All right. So, Shannon, tell us a little more about some of the cases this board considered. BOND: Yeah, there were five in total announced today. And in each of these, the board was reviewing posts that Facebook had taken down for violating policies against things like hate speech, nudity and harmful misinformation about COVID-19. And when you dig into the details of these rulings, you know, enforcing these rules is really complicated. And ultimately, the board overturned Facebook's decision to remove in four of these first five cases. CHANG: OK, so give us a quick example. BOND: Right. So in one case, Facebook had removed a post from a user in Myanmar who had suggested there was something wrong with Muslims. And Facebook says this broke its rules against hate speech. This is an especially fraught issue because, of course, Facebook has been criticized for its role in the genocide of the country's Muslim minority. But the board looked at this and said, you know, if you take into consideration the full context, this post was pejorative, but the board didn't think it crossed the line into hate speech. And so it said Facebook needs more justification if it's going to take down posts like this. And the board told Facebook to reinstate it. Now, Facebook has agreed to abide by these rulings, and the post is already back up. CHANG: Wait. So who is on this board exactly? BOND: It's made up of 20 international experts. They're mainly in things like law and human rights, but there's also a Nobel Peace laureate, some journalists and even the former prime minister of Denmark. It was created by Facebook last year, and it's funded by Facebook through an independent trust. CHANG: And do you think these decisions give us any clues as to how the board sees its overall role? BOND: Well, I spoke to Evelyn Douek, a Harvard Law School lecturer who's been following the board very closely. EVELYN DOUEK: These five cases, even though it's only five cases out of the thousands or millions of decisions that Facebook makes in a week, are a true shot across the bow from the oversight board to Facebook. BOND: And she says it's a shot across the bow because the board is taking aim directly at some of Facebook's policies and enforcement. You know, it warned about the extent to which the company relies on artificial intelligence. It says those systems need more human oversight. It emphasized taking context into account, and it wants Facebook to just be much more clear about its rules on policies like health misinformation or dangerous groups. And you know, Ailsa, we know Facebook has this immense power over what its billions of users can post. Now it's created this board. And from what we've seen today, the board has ambitions to be a real check on that power. You know, it's kind of flexing its muscles. CHANG: Yeah, so interesting. Well, what I did notice is we did not hear today about Facebook's decision to suspend former President Trump after the whole insurrection at the Capitol on January 6. What do we know about the board's review of that case? BOND: Right. Facebook reviewed the Trump suspension to the board last week. This is the case everyone has their eyes on, of course, right? It's a huge deal. The board is opening up for public comment tomorrow, and it has about three months to make a ruling. And ultimately, it's going to be up to the board to settle this very fraught debate over whether Trump should get his account back. So we'll stay tuned. CHANG: That is NPR's Shannon Bond. Thank you, Shannon. BOND: Thanks, Ailsa. (SOUNDBITE OF MUSIC) AILSA CHANG, HOST:   Facebook has created its own sort of Supreme Court. It's an oversight board that has the final say on some of its hardest decisions over what users can and cannot post. Today, that board issued its first rulings. It ordered the social network to restore several posts that it had removed for breaking Facebook rules. NPR tech correspondent Shannon Bond joins us now to explain. Hey, Shannon. SHANNON BOND, BYLINE: Hey, Ailsa. CHANG: So we should first note Facebook is among NPR's financial supporters. All right. So, Shannon, tell us a little more about some of the cases this board considered. BOND: Yeah, there were five in total announced today. And in each of these, the board was reviewing posts that Facebook had taken down for violating policies against things like hate speech, nudity and harmful misinformation about COVID-19. And when you dig into the details of these rulings, you know, enforcing these rules is really complicated. And ultimately, the board overturned Facebook's decision to remove in four of these first five cases. CHANG: OK, so give us a quick example. BOND: Right. So in one case, Facebook had removed a post from a user in Myanmar who had suggested there was something wrong with Muslims. And Facebook says this broke its rules against hate speech. This is an especially fraught issue because, of course, Facebook has been criticized for its role in the genocide of the country's Muslim minority. But the board looked at this and said, you know, if you take into consideration the full context, this post was pejorative, but the board didn't think it crossed the line into hate speech. And so it said Facebook needs more justification if it's going to take down posts like this. And the board told Facebook to reinstate it. Now, Facebook has agreed to abide by these rulings, and the post is already back up. CHANG: Wait. So who is on this board exactly? BOND: It's made up of 20 international experts. They're mainly in things like law and human rights, but there's also a Nobel Peace laureate, some journalists and even the former prime minister of Denmark. It was created by Facebook last year, and it's funded by Facebook through an independent trust. CHANG: And do you think these decisions give us any clues as to how the board sees its overall role? BOND: Well, I spoke to Evelyn Douek, a Harvard Law School lecturer who's been following the board very closely. EVELYN DOUEK: These five cases, even though it's only five cases out of the thousands or millions of decisions that Facebook makes in a week, are a true shot across the bow from the oversight board to Facebook. BOND: And she says it's a shot across the bow because the board is taking aim directly at some of Facebook's policies and enforcement. You know, it warned about the extent to which the company relies on artificial intelligence. It says those systems need more human oversight. It emphasized taking context into account, and it wants Facebook to just be much more clear about its rules on policies like health misinformation or dangerous groups. And you know, Ailsa, we know Facebook has this immense power over what its billions of users can post. Now it's created this board. And from what we've seen today, the board has ambitions to be a real check on that power. You know, it's kind of flexing its muscles. CHANG: Yeah, so interesting. Well, what I did notice is we did not hear today about Facebook's decision to suspend former President Trump after the whole insurrection at the Capitol on January 6. What do we know about the board's review of that case? BOND: Right. Facebook reviewed the Trump suspension to the board last week. This is the case everyone has their eyes on, of course, right? It's a huge deal. The board is opening up for public comment tomorrow, and it has about three months to make a ruling. And ultimately, it's going to be up to the board to settle this very fraught debate over whether Trump should get his account back. So we'll stay tuned. CHANG: That is NPR's Shannon Bond. Thank you, Shannon. BOND: Thanks, Ailsa. (SOUNDBITE OF MUSIC)", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-01-29-961703023": {"title": "From Elon Musk To AOC, Everybody Has A Tweet About GameStop : NPR", "url": "https://www.npr.org/2021/01/29/961703023/from-elon-musk-to-aoc-everybody-has-a-tweet-about-gamestop", "author": "No author found", "published_date": "2021-01-29", "content": "", "section": "Business", "disclaimer": ""}, "2021-01-29-962047287": {"title": "GameStop Stock Rebounds, SEC Warns Against Market Manipulation : NPR", "url": "https://www.npr.org/2021/01/29/962047287/game-back-on-gamestop-stock-rebounds-as-sec-warns-against-market-manipulation", "author": "No author found", "published_date": "2021-01-29", "content": "", "section": "Business", "disclaimer": ""}, "2021-01-29-962010211": {"title": "'Robin Hood' Groups Win New Fans, Thanks To GameStop Controversy : NPR", "url": "https://www.npr.org/2021/01/29/962010211/robin-hood-groups-win-new-fans-thanks-to-gamestop-controversy", "author": "No author found", "published_date": "2021-01-29", "content": "", "section": "Technology", "disclaimer": ""}, "2021-01-29-960810672": {"title": "NSA Warned Russia to Stay Out Of 2020 Election And Got SolarWinds Hack Instead : NPR", "url": "https://www.npr.org/2021/01/29/960810672/why-russia-may-have-stepped-up-its-hacking-game", "author": "No author found", "published_date": "2021-01-29", "content": "RACHEL MARTIN, HOST:  Joe Biden had his first official call as president this week with his Russian counterpart, Vladimir Putin. They touched on things you'd expect - arms treaties, Ukrainian sovereignty, dissidents and also the massive cyberattack on American companies and the government that was discovered last month. Dina Temple-Raston of NPR's investigations team looks at what's behind that bold new strike. DINA TEMPLE-RASTON, BYLINE: A little over a year ago, the head of the National Security Agency and Cyber Command, General Paul Nakasone, decided to do something unusual. He decided to give the American people an idea of what the U. S. military was doing in cyberspace. He went public with a new strategy he called defend forward. (SOUNDBITE OF ARCHIVED NPR BROADCAST)PAUL NAKASONE: So defend forward is a DOD strategy that looks outside of the United States. TEMPLE-RASTON: That's General Nakasone in an NPR interview about a year before the last election. (SOUNDBITE OF ARCHIVED NPR BROADCAST)NAKASONE: We're going to expand our insights of our adversaries. We're going to know our adversaries better than they knew themselves. Secondly, we're going to harden our defenses. And the third thing, we'll be poised to act. TEMPLE-RASTON: Nakasone was sending a message of deterrence to Moscow. If you meddle in the presidential elections the way you have in the past, he was saying, the U. S. is poised to respond. (SOUNDBITE OF ARCHIVED NPR BROADCAST)NAKASONE: It's a little bit different in cyberspace because you have foes that can come and go very, very quickly. They can buy infrastructure. They can develop their capabilities. They can conduct attacks. And what you have to do, from what I've learned, is you have to be persistent on them in making sure that whenever they do that type of thing, you're going to be there, and you're going to impact them. TEMPLE-RASTON: It turns out, as Nakasone was talking about being persistent on them, the U. S. believes Russian intelligence service hackers had likely already begun work on a new project - cracking into a network security company called SolarWinds. (SOUNDBITE OF MONTAGE)UNIDENTIFIED REPORTER #1: Good evening. America under virtual invasion. . . UNIDENTIFIED REPORTER #2: Security experts are scrambling to assess the damage after hackers breached sensitive government and corporate computer. . . UNIDENTIFIED REPORTER #3: Sources say the attack took advantage of the widespread use of software from a company called SolarWinds. TEMPLE-RASTON: The SolarWinds hack makes clear that something experts have been warning about for years has finally arrived - the supply chain attack. If one contractor, say, a company that does network security, falls prey to a hack, then a company is only as safe as that outside contractor. Richard Bejtlich is a former military intelligence officer who's now the principal security strategist at Corelight, a cybersecurity firm. RICHARD BEJTLICH: And if you were one of those organizations that had enough money to say, we want to have inventory management, we want to have network management, let's go with SolarWinds - well, suddenly that's opened you up to a whole new set of problems. TEMPLE-RASTON: The investigation into what actually happened has only just begun. But at this stage, what seems clear is that hackers got into the networks through a company software update. And it appears that targeting a company like SolarWinds is a very efficient way to crack into U. S. systems because intruders can slip into thousands of company and government networks all at once. And one of the questions that's come up in the wake of the attack is this - did Nakasone's discussion of defense forward inspire Russian hackers to do something spectacular just to prove they could? Kiersten Todt is the managing director of the Cyber Readiness Institute, and she says the Russians hardly needed an excuse. KIERSTEN TODT: I think the Russians are emboldened to work against us and come after us for lots of reasons, not the least of which could be us saying, hey, we're going to, you know, have a secure and safe 2020 election. That would inspire them to say, oh, no, you're not. And while you're focusing on the election, we're actually going to come into your networks. TEMPLE-RASTON: What the hackers could do next is unclear. Was this just an intelligence operation aimed at grabbing sensitive information, or are the hackers lying in wait, having created backdoors that will allow them to come and go as they please? Officials are trying to determine that now. Dina Temple-Raston, NPR News. (SOUNDBITE OF AK AND SUBLAB'S \"TRANQUIL\") RACHEL MARTIN, HOST:   Joe Biden had his first official call as president this week with his Russian counterpart, Vladimir Putin. They touched on things you'd expect - arms treaties, Ukrainian sovereignty, dissidents and also the massive cyberattack on American companies and the government that was discovered last month. Dina Temple-Raston of NPR's investigations team looks at what's behind that bold new strike. DINA TEMPLE-RASTON, BYLINE: A little over a year ago, the head of the National Security Agency and Cyber Command, General Paul Nakasone, decided to do something unusual. He decided to give the American people an idea of what the U. S. military was doing in cyberspace. He went public with a new strategy he called defend forward. (SOUNDBITE OF ARCHIVED NPR BROADCAST) PAUL NAKASONE: So defend forward is a DOD strategy that looks outside of the United States. TEMPLE-RASTON: That's General Nakasone in an NPR interview about a year before the last election. (SOUNDBITE OF ARCHIVED NPR BROADCAST) NAKASONE: We're going to expand our insights of our adversaries. We're going to know our adversaries better than they knew themselves. Secondly, we're going to harden our defenses. And the third thing, we'll be poised to act. TEMPLE-RASTON: Nakasone was sending a message of deterrence to Moscow. If you meddle in the presidential elections the way you have in the past, he was saying, the U. S. is poised to respond. (SOUNDBITE OF ARCHIVED NPR BROADCAST) NAKASONE: It's a little bit different in cyberspace because you have foes that can come and go very, very quickly. They can buy infrastructure. They can develop their capabilities. They can conduct attacks. And what you have to do, from what I've learned, is you have to be persistent on them in making sure that whenever they do that type of thing, you're going to be there, and you're going to impact them. TEMPLE-RASTON: It turns out, as Nakasone was talking about being persistent on them, the U. S. believes Russian intelligence service hackers had likely already begun work on a new project - cracking into a network security company called SolarWinds. (SOUNDBITE OF MONTAGE) UNIDENTIFIED REPORTER #1: Good evening. America under virtual invasion. . . UNIDENTIFIED REPORTER #2: Security experts are scrambling to assess the damage after hackers breached sensitive government and corporate computer. . . UNIDENTIFIED REPORTER #3: Sources say the attack took advantage of the widespread use of software from a company called SolarWinds. TEMPLE-RASTON: The SolarWinds hack makes clear that something experts have been warning about for years has finally arrived - the supply chain attack. If one contractor, say, a company that does network security, falls prey to a hack, then a company is only as safe as that outside contractor. Richard Bejtlich is a former military intelligence officer who's now the principal security strategist at Corelight, a cybersecurity firm. RICHARD BEJTLICH: And if you were one of those organizations that had enough money to say, we want to have inventory management, we want to have network management, let's go with SolarWinds - well, suddenly that's opened you up to a whole new set of problems. TEMPLE-RASTON: The investigation into what actually happened has only just begun. But at this stage, what seems clear is that hackers got into the networks through a company software update. And it appears that targeting a company like SolarWinds is a very efficient way to crack into U. S. systems because intruders can slip into thousands of company and government networks all at once. And one of the questions that's come up in the wake of the attack is this - did Nakasone's discussion of defense forward inspire Russian hackers to do something spectacular just to prove they could? Kiersten Todt is the managing director of the Cyber Readiness Institute, and she says the Russians hardly needed an excuse. KIERSTEN TODT: I think the Russians are emboldened to work against us and come after us for lots of reasons, not the least of which could be us saying, hey, we're going to, you know, have a secure and safe 2020 election. That would inspire them to say, oh, no, you're not. And while you're focusing on the election, we're actually going to come into your networks. TEMPLE-RASTON: What the hackers could do next is unclear. Was this just an intelligence operation aimed at grabbing sensitive information, or are the hackers lying in wait, having created backdoors that will allow them to come and go as they please? Officials are trying to determine that now. Dina Temple-Raston, NPR News. (SOUNDBITE OF AK AND SUBLAB'S \"TRANQUIL\")", "section": "Investigations", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-01-30-959394083": {"title": "Combatting Disinformation Requires Time And Patience, Experts Say : NPR", "url": "https://www.npr.org/2021/01/30/959394083/combating-misinformation-when-a-loved-one-is-caught-in-a-web-of-conspiracies", "author": "No author found", "published_date": "2021-01-30", "content": "MICHEL MARTIN, HOST:  Having a loved one who's convinced of things that just aren't true is frustrating and sometimes dangerous. False information can fuel violence like the attack on the U. S. Capitol by pro-Trump extremists. In his inaugural address, President Joe Biden called out the role of disinformation in stoking political tensions. (SOUNDBITE OF ARCHIVED RECORDING)PRESIDENT JOE BIDEN: Every disagreement doesn't have to be a cause for total war, and we must reject the culture in which facts themselves are manipulated and even manufactured. MARTIN: As NPR's Sarah McCammon reports, experts say dispelling manufactured information will take time. SARAH MCCAMMON, BYLINE: On January 6, Hilary Izatt was watching TV with her husband when she started to worry. HILARY IZATT: My husband and I are both political scientists. We're kind of nerdy. We watch C-SPAN a lot. And he - when we were watching C-SPAN is when the rioters started breaking into the Capitol. MCCAMMON: Izatt is a doctoral student in political science at the University of Michigan. Her dad lives in Utah, and she says he told her he was traveling to Washington, D. C. , to join the massive pro-Trump rally planned for that day. When she saw what was unfolding on the screen, it scared her. IZATT: I was mostly worried for his safety. And I texted him, and he got back to me. And he just said, don't believe everything that you're watching on TV. And that's when it was - like, so I don't believe, like, C-SPAN? Or, you know, I'm not sure what he meant by that. But it - like, it was this realization I think we're coming from two very different realities. MCCAMMON: I reached out to Izatt's dad to ask for his perspective, and he declined to comment. Izatt's pretty confident her father was not among the group that stormed the Capitol, but she's uncomfortable knowing he was there that day at all. Many people are feeling like they've lost loved ones to an alternate reality. A recent NPR/PBS NewsHour/Marist poll found that only 1 in 5 Republicans accept Biden's victory. James Hawdon, director of the Center for Peace Studies and Violence Prevention at Virginia Tech, has studied online extremism. He says the widespread acceptance of disinformation is dangerous for the country. JAMES HAWDON: We act on our beliefs. If you truly believe that the country is under attack, if this, of course, is not true, then, you know, obviously, it poses a threat. MCCAMMON: Hawdon says people often latch onto pieces of disinformation that align with their worldview and gradually begin to accept even bigger lies. HAWDON: You can get people to step - take small steps off the path of truth or reality or whatever you want to call it more easily than taking a big leap. But if - once you've gone several yards off that path, then the big leap's pretty easy to make. MCCAMMON: Those ideas can validate part of a person's belief system or identity, Hawdon says, and they're difficult to shake. Dennis, a retiree from Maryland, asks that we only use his first name for fear of his safety in the current climate. He's grown increasingly worried about his daughter's embrace of false conspiracy theories about the election. DENNIS: She's talked about the election being stolen. And I push back on that, that - you know, the standard, you know, where's your proof and how do you suppose this happened? PAULA: I will say that he actually used these terms and said that I was in la-la land. But I really don't feel that I am. MCCAMMON: That's Dennis's daughter, Paula. She lives near Baltimore and says she's been a conservative all her life. Paula told me she distrusts many elected officials and cannot believe Biden won, despite what many courts and elections officials have repeatedly confirmed and regardless of what her dad says. PAULA: I was a little bit irritated. But my response is, well, I'm there with 70 million other people then. MCCAMMON: Hawdon says one long-term solution to this growing problem could involve better education in data literacy, teaching young people how to sort through fact and fiction. In the short term, he says if a loved one is spouting misinformation, it's important to push back kindly and try to understand what led to that belief. HAWDON: I really don't believe that people started off believing that there are pedophile rings under a pizza place, (laughter) you know? Something got them down that rabbit hole, and you got to understand what that root cause is. MCCAMMON: Hawdon says just as people often take small steps toward conspiracy theories, they may need to gradually move away from them, too. Hilary Izatt says she's not sure how to talk to her dad, but she anticipates some tough conversations. IZATT: I think a lot of Americans are being forced to figure out what side they're on, you know? Are you crouching in the Capitol, hiding from rioters? Are you rioting the Capitol? And I think that means it's going to change a little bit, the dynamic with my own family. MCCAMMON: Amy Bruckman, a professor at Georgia Tech who studies social computing, says personal relationships can help squash conspiracy theories. But also important, she says, our continued cooperation from tech companies in regulating social media and leadership from elected officials. AMY BRUCKMAN: I think a lot of these crazy ideas are a product of the time. And having national leadership normalize crazy ideas makes people more likely to accept them. MCCAMMON: It will take time, Bruckman says. But she's hopeful that little by little, Americans will reject disinformation. Sarah McCammon, NPR News, Washington. MICHEL MARTIN, HOST:   Having a loved one who's convinced of things that just aren't true is frustrating and sometimes dangerous. False information can fuel violence like the attack on the U. S. Capitol by pro-Trump extremists. In his inaugural address, President Joe Biden called out the role of disinformation in stoking political tensions. (SOUNDBITE OF ARCHIVED RECORDING) PRESIDENT JOE BIDEN: Every disagreement doesn't have to be a cause for total war, and we must reject the culture in which facts themselves are manipulated and even manufactured. MARTIN: As NPR's Sarah McCammon reports, experts say dispelling manufactured information will take time. SARAH MCCAMMON, BYLINE: On January 6, Hilary Izatt was watching TV with her husband when she started to worry. HILARY IZATT: My husband and I are both political scientists. We're kind of nerdy. We watch C-SPAN a lot. And he - when we were watching C-SPAN is when the rioters started breaking into the Capitol. MCCAMMON: Izatt is a doctoral student in political science at the University of Michigan. Her dad lives in Utah, and she says he told her he was traveling to Washington, D. C. , to join the massive pro-Trump rally planned for that day. When she saw what was unfolding on the screen, it scared her. IZATT: I was mostly worried for his safety. And I texted him, and he got back to me. And he just said, don't believe everything that you're watching on TV. And that's when it was - like, so I don't believe, like, C-SPAN? Or, you know, I'm not sure what he meant by that. But it - like, it was this realization I think we're coming from two very different realities. MCCAMMON: I reached out to Izatt's dad to ask for his perspective, and he declined to comment. Izatt's pretty confident her father was not among the group that stormed the Capitol, but she's uncomfortable knowing he was there that day at all. Many people are feeling like they've lost loved ones to an alternate reality. A recent NPR/PBS NewsHour/Marist poll found that only 1 in 5 Republicans accept Biden's victory. James Hawdon, director of the Center for Peace Studies and Violence Prevention at Virginia Tech, has studied online extremism. He says the widespread acceptance of disinformation is dangerous for the country. JAMES HAWDON: We act on our beliefs. If you truly believe that the country is under attack, if this, of course, is not true, then, you know, obviously, it poses a threat. MCCAMMON: Hawdon says people often latch onto pieces of disinformation that align with their worldview and gradually begin to accept even bigger lies. HAWDON: You can get people to step - take small steps off the path of truth or reality or whatever you want to call it more easily than taking a big leap. But if - once you've gone several yards off that path, then the big leap's pretty easy to make. MCCAMMON: Those ideas can validate part of a person's belief system or identity, Hawdon says, and they're difficult to shake. Dennis, a retiree from Maryland, asks that we only use his first name for fear of his safety in the current climate. He's grown increasingly worried about his daughter's embrace of false conspiracy theories about the election. DENNIS: She's talked about the election being stolen. And I push back on that, that - you know, the standard, you know, where's your proof and how do you suppose this happened? PAULA: I will say that he actually used these terms and said that I was in la-la land. But I really don't feel that I am. MCCAMMON: That's Dennis's daughter, Paula. She lives near Baltimore and says she's been a conservative all her life. Paula told me she distrusts many elected officials and cannot believe Biden won, despite what many courts and elections officials have repeatedly confirmed and regardless of what her dad says. PAULA: I was a little bit irritated. But my response is, well, I'm there with 70 million other people then. MCCAMMON: Hawdon says one long-term solution to this growing problem could involve better education in data literacy, teaching young people how to sort through fact and fiction. In the short term, he says if a loved one is spouting misinformation, it's important to push back kindly and try to understand what led to that belief. HAWDON: I really don't believe that people started off believing that there are pedophile rings under a pizza place, (laughter) you know? Something got them down that rabbit hole, and you got to understand what that root cause is. MCCAMMON: Hawdon says just as people often take small steps toward conspiracy theories, they may need to gradually move away from them, too. Hilary Izatt says she's not sure how to talk to her dad, but she anticipates some tough conversations. IZATT: I think a lot of Americans are being forced to figure out what side they're on, you know? Are you crouching in the Capitol, hiding from rioters? Are you rioting the Capitol? And I think that means it's going to change a little bit, the dynamic with my own family. MCCAMMON: Amy Bruckman, a professor at Georgia Tech who studies social computing, says personal relationships can help squash conspiracy theories. But also important, she says, our continued cooperation from tech companies in regulating social media and leadership from elected officials. AMY BRUCKMAN: I think a lot of these crazy ideas are a product of the time. And having national leadership normalize crazy ideas makes people more likely to accept them. MCCAMMON: It will take time, Bruckman says. But she's hopeful that little by little, Americans will reject disinformation. Sarah McCammon, NPR News, Washington.", "section": "National", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-01-31-962479849": {"title": "Reddit WallStreetBets Founder: GameStop Stock Frenzy A 'Symbolic Movement' : NPR", "url": "https://www.npr.org/2021/01/31/962479849/reddit-wallstreetbets-founder-calls-gamestop-stock-frenzy-a-symbolic-movement", "author": "No author found", "published_date": "2021-01-31", "content": "", "section": "Business", "disclaimer": ""}, "2021-01-31-960819083": {"title": "Vaccines For Data: Israel's Pfizer Deal Drives Quick Rollout \u2014 And Privacy Worries : NPR", "url": "https://www.npr.org/2021/01/31/960819083/vaccines-for-data-israels-pfizer-deal-drives-quick-rollout-and-privacy-worries", "author": "No author found", "published_date": "2021-01-31", "content": "", "section": "The Coronavirus Crisis", "disclaimer": ""}, "2021-01-31-962104747": {"title": "QAnon Followers Kicked Off Facebook, Twitter Flock To Fringe Sites : NPR", "url": "https://www.npr.org/2021/01/31/962104747/unwelcome-on-facebook-twitter-qanon-followers-flock-to-fringe-sites", "author": "No author found", "published_date": "2021-01-31", "content": "", "section": "Technology", "disclaimer": ""}, "2021-02-02-963370968": {"title": "Jeff Bezos To Step Down As Amazon's CEO  : NPR", "url": "https://www.npr.org/2021/02/02/963370968/jeff-bezos-to-step-down-as-amazons-ceo", "author": "No author found", "published_date": "2021-02-02", "content": "MARY LOUISE KELLY, HOST:  Amazon's Jeff Bezos is stepping down as CEO of the company he founded almost 30 years ago. He will transition to executive chairman. He will focus on new products and early initiatives. In his time at the helm of Amazon, it has grown and grown from modest online bookseller to retailing behemoth and one of the most powerful companies in the world. I need to note that Amazon is one of NPR's financial supporters. And I want to bring in NPR's Alina Selyukh. Hey, there. ALINA SELYUKH, BYLINE: Hello, hello. KELLY: So why is he stepping aside? What does Jeff Bezos say? SELYUKH: So he's saying that he is shifting to the role of executive chairman. So it is accurate to say he's stepping down, but he's not stepping away by any means. And he has already largely stepped back from day-to-day managing work in favor of big-picture planning. And now, he, you know, he says he wants to focus more on these long-term passion projects, like his rocket company, Blue Origin, The Washington Post, which he owns, and philanthropy work. Today's timing was earnings. And so Chief Financial Officer Brian Olsavsky had to talk to reporters. And he was asked about this. And he basically said Bezos is not going anywhere, it's just a reshuffling of who's doing what. (SOUNDBITE OF ARCHIVED RECORDING)BRIAN OLSAVSKY: Jeff will continue to stay, you know, not only very involved, but very - you know, have his fingerprints on a lot of areas of product development and innovation. And of course, you know, he remains our largest individual shareholder. SELYUKH: To quote Bezos himself, he wrote to employees today, quote, \"as much as I still tap dance into the office, I am (ph) excited about this transition. \" He later said that being the CEO of Amazon is a deep responsibility and it is quite consuming. He's looking forward to expanding into all of these other projects he's got going on. KELLY: I love that image of Jeff Bezos tap dancing into (laughter) his office. . . SELYUKH: Into the office? (Laughter) Yes. KELLY: . . . At Amazon. Who will be tap dancing into the office in his place? Who's going to be the next CEO? SELYUKH: (Laughter) His name is Andy Jassy. He's the head of Amazon's cloud computing division. This is Amazon Web Services, Amazon's biggest cash cow, biggest profit center. And Jassy is the person who shaped that company. Most famously, this is the cloud business that props up the CIA. It is by far the biggest cloud company out there. Jassy is also a big investor in Amazon. He has been there a long time. He's one of Bezos' longest-serving trusted lieutenants. KELLY: Hmm. And what are going to be the biggest challenges he will face as CEO? SELYUKH: Right. The timing is interesting. Next week, Amazon faces the first major big labor battle in the U. S. On Monday, Amazon workers in Bessemer, Ala. , are starting to vote on whether to join a union, which could create Amazon's first unionized warehouse in America. So that's one big thing. Then, like all tech companies, Amazon is facing scrutiny for its scale, its power. Just today, actually, Amazon agreed to pay over $60 million to settle charges by the Federal Trade Commission, which is accusing Amazon of pocketing - essentially pocketing tips that were meant for delivery drivers. And, you know, big picture, to your point earlier, Amazon has grown and grown into all of these different aspects of our lives. It's a company now worth almost $2 trillion. KELLY: Wow. SELYUKH: It employs 1. 3 million people globally. It's growing very fast. It influences people's lives in so many ways. And how does that saying go, right? With great increasing power comes great increasing responsibility. I'm sorry about that (laughter). But the question is, you know, whether the American government or any other government might decide to hold Amazon more accountable for all its influence and power. And the new CEO is the person who will have to address that. KELLY: NPR's Alina Selyukh, I think quoting from \"Spider-Man\" there, if I'm. . . SELYUKH: Indeed. KELLY: . . . (Laughter) Not mistaken. Thank you, Alina. SELYUKH: Thank you. MARY LOUISE KELLY, HOST:   Amazon's Jeff Bezos is stepping down as CEO of the company he founded almost 30 years ago. He will transition to executive chairman. He will focus on new products and early initiatives. In his time at the helm of Amazon, it has grown and grown from modest online bookseller to retailing behemoth and one of the most powerful companies in the world. I need to note that Amazon is one of NPR's financial supporters. And I want to bring in NPR's Alina Selyukh. Hey, there. ALINA SELYUKH, BYLINE: Hello, hello. KELLY: So why is he stepping aside? What does Jeff Bezos say? SELYUKH: So he's saying that he is shifting to the role of executive chairman. So it is accurate to say he's stepping down, but he's not stepping away by any means. And he has already largely stepped back from day-to-day managing work in favor of big-picture planning. And now, he, you know, he says he wants to focus more on these long-term passion projects, like his rocket company, Blue Origin, The Washington Post, which he owns, and philanthropy work. Today's timing was earnings. And so Chief Financial Officer Brian Olsavsky had to talk to reporters. And he was asked about this. And he basically said Bezos is not going anywhere, it's just a reshuffling of who's doing what. (SOUNDBITE OF ARCHIVED RECORDING) BRIAN OLSAVSKY: Jeff will continue to stay, you know, not only very involved, but very - you know, have his fingerprints on a lot of areas of product development and innovation. And of course, you know, he remains our largest individual shareholder. SELYUKH: To quote Bezos himself, he wrote to employees today, quote, \"as much as I still tap dance into the office, I am (ph) excited about this transition. \" He later said that being the CEO of Amazon is a deep responsibility and it is quite consuming. He's looking forward to expanding into all of these other projects he's got going on. KELLY: I love that image of Jeff Bezos tap dancing into (laughter) his office. . . SELYUKH: Into the office? (Laughter) Yes. KELLY: . . . At Amazon. Who will be tap dancing into the office in his place? Who's going to be the next CEO? SELYUKH: (Laughter) His name is Andy Jassy. He's the head of Amazon's cloud computing division. This is Amazon Web Services, Amazon's biggest cash cow, biggest profit center. And Jassy is the person who shaped that company. Most famously, this is the cloud business that props up the CIA. It is by far the biggest cloud company out there. Jassy is also a big investor in Amazon. He has been there a long time. He's one of Bezos' longest-serving trusted lieutenants. KELLY: Hmm. And what are going to be the biggest challenges he will face as CEO? SELYUKH: Right. The timing is interesting. Next week, Amazon faces the first major big labor battle in the U. S. On Monday, Amazon workers in Bessemer, Ala. , are starting to vote on whether to join a union, which could create Amazon's first unionized warehouse in America. So that's one big thing. Then, like all tech companies, Amazon is facing scrutiny for its scale, its power. Just today, actually, Amazon agreed to pay over $60 million to settle charges by the Federal Trade Commission, which is accusing Amazon of pocketing - essentially pocketing tips that were meant for delivery drivers. And, you know, big picture, to your point earlier, Amazon has grown and grown into all of these different aspects of our lives. It's a company now worth almost $2 trillion. KELLY: Wow. SELYUKH: It employs 1. 3 million people globally. It's growing very fast. It influences people's lives in so many ways. And how does that saying go, right? With great increasing power comes great increasing responsibility. I'm sorry about that (laughter). But the question is, you know, whether the American government or any other government might decide to hold Amazon more accountable for all its influence and power. And the new CEO is the person who will have to address that. KELLY: NPR's Alina Selyukh, I think quoting from \"Spider-Man\" there, if I'm. . . SELYUKH: Indeed. KELLY: . . . (Laughter) Not mistaken. Thank you, Alina. SELYUKH: Thank you.", "section": "Business", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-02-03-963832594": {"title": "Parler CEO Is Fired After 'Constant Resistance' Inside The Conservative-Friendly Site : NPR", "url": "https://www.npr.org/2021/02/03/963832594/parler-ceo-is-fired-after-constant-resistance-inside-the-conservative-friendly-s", "author": "No author found", "published_date": "2021-02-03", "content": "STEVE INSKEEP, HOST:  The former CEO of Parler is discussing how he was fired. The social media site promoted itself as a forum for free speech. It quickly became a go-to site for conspiracy theorists, white supremacists and some of the people who attacked the U. S. Capitol on January 6. Parler is now offline, and its former chief executive told NPR's Bobby Allyn he's out of work. BOBBY ALLYN, BYLINE: Since 2018, 27-year-old Nevada engineer John Matze ran the social media site Parler. But here's how he now introduces himself. JOHN MATZE: John Matze, unemployed. ALLYN: Unemployed, he says, because of a disagreement over free speech. Many of the Capitol rioters turned to Parler to document property damage, vandalism and other violence. To Matze, that was a wake-up call. MATZE: To me, it was a clear indication of what could happen if we didn't change the way things were being done. ALLYN: The realization came too late for Parler since Amazon had already terminated its Web hosting contract with the company after saying it, quote, \"systemically failed to police violence. \" Matze, though, had a plan. Parler would relaunch by banning domestic terrorists and incitements of violence, including from the conspiracy theory QAnon. He took his proposal to Parler's co-founder, conservative donor Rebekah Mercer. MATZE: You know, when I presented my plan to Rebekah Mercer and one of the other reps, they were silent. So I took that as disagreement. ALLYN: We reached out to Mercer, but she did not immediately respond. (SOUNDBITE OF VIDEO)DAN BONGINO: There were two separate visions for the company. ALLYN: That's conservative talk show host Dan Bongino. He's a Parler investor. He posted a video to Facebook defending Parler's decision to fire Matze. (SOUNDBITE OF VIDEO)BONGINO: We were the ones, in fact, fighting to get Parler back up. It was some really bad decisions made by people on the inside. ALLYN: Bongino says Matze, despite being CEO, did not own Parler's mission. (SOUNDBITE OF VIDEO)BONGINO: And I don't know what John's saying in his reports out there, but this free speech vision, that was ours. ALLYN: For now, until the site is back up and running, people who share that vision will have to go somewhere other than Parler. Bobby Allyn, NPR News, San Francisco. (SOUNDBITE OF AMBINATE'S \"REMNANT\") STEVE INSKEEP, HOST:   The former CEO of Parler is discussing how he was fired. The social media site promoted itself as a forum for free speech. It quickly became a go-to site for conspiracy theorists, white supremacists and some of the people who attacked the U. S. Capitol on January 6. Parler is now offline, and its former chief executive told NPR's Bobby Allyn he's out of work. BOBBY ALLYN, BYLINE: Since 2018, 27-year-old Nevada engineer John Matze ran the social media site Parler. But here's how he now introduces himself. JOHN MATZE: John Matze, unemployed. ALLYN: Unemployed, he says, because of a disagreement over free speech. Many of the Capitol rioters turned to Parler to document property damage, vandalism and other violence. To Matze, that was a wake-up call. MATZE: To me, it was a clear indication of what could happen if we didn't change the way things were being done. ALLYN: The realization came too late for Parler since Amazon had already terminated its Web hosting contract with the company after saying it, quote, \"systemically failed to police violence. \" Matze, though, had a plan. Parler would relaunch by banning domestic terrorists and incitements of violence, including from the conspiracy theory QAnon. He took his proposal to Parler's co-founder, conservative donor Rebekah Mercer. MATZE: You know, when I presented my plan to Rebekah Mercer and one of the other reps, they were silent. So I took that as disagreement. ALLYN: We reached out to Mercer, but she did not immediately respond. (SOUNDBITE OF VIDEO) DAN BONGINO: There were two separate visions for the company. ALLYN: That's conservative talk show host Dan Bongino. He's a Parler investor. He posted a video to Facebook defending Parler's decision to fire Matze. (SOUNDBITE OF VIDEO) BONGINO: We were the ones, in fact, fighting to get Parler back up. It was some really bad decisions made by people on the inside. ALLYN: Bongino says Matze, despite being CEO, did not own Parler's mission. (SOUNDBITE OF VIDEO) BONGINO: And I don't know what John's saying in his reports out there, but this free speech vision, that was ours. ALLYN: For now, until the site is back up and running, people who share that vision will have to go somewhere other than Parler. Bobby Allyn, NPR News, San Francisco. (SOUNDBITE OF AMBINATE'S \"REMNANT\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-02-04-963861418": {"title": "Why QAnon Survives After Trump : NPR", "url": "https://www.npr.org/2021/02/04/963861418/why-qanon-survives-after-trump", "author": "No author found", "published_date": "2021-02-04", "content": "AUDIE CORNISH, HOST:  In the online QAnon universe, former President Trump is seen as the savior of humanity, someone who is destined to rescue not just the country but the entire world from darkness. That's according to our next guest, Travis View. He monitors the spread of online conspiracies. But with Trump out of office, what happens to this movement? View says it's not going anywhere. TRAVIS VIEW: Without L. Ron Hubbard, does Scientology fizzle? I mean, once a movement like this grows to a certain size and once the believers in it become dedicated enough, it becomes self-sustaining. And it doesn't need its founder or leader anymore. CORNISH: View is also the co-host of a podcast that follows the conspiracy movement. It's called \"QAnon Anonymous. \" Yes, he says, the theories are elaborate, self-contradictory and illogical. And for some adherents, that's part of the draw. VIEW: This is, I think, a big part of, like, what gets people locked in - is that it might seem impenetrable to you, but when you're inside, it feels like you're, you know, privy to some sort of secret inside information that only you and your other fellow QAnon followers are sharp enough to understand. CORNISH: What makes you think, in this case, it is self-sustaining? I mean, you - because of your - some of your branding, I understand people actually gravitate towards the podcast before they realize that you're actually not supportive of the movement. VIEW: That's true. CORNISH: And you get a lot of, like, you know, interactions and mail. So what are you hearing that, for you, says, oh, this ain't over? VIEW: Well, one thing that makes me convinced that this is not something that's just going to go away is, you know, the fact that even though sort of Q itself, the entity, has not posted whatsoever since December 8. And despite that, you know, the community itself is still very active because they sort of - the belief systems and the sort of conspiracy theories that sort of sustain the movement don't come from Trump or Q or any specific leader. It's sort of crowdsourced and self-generated. I mean, it really is about the community and sort of the feeling that they have some sort of inside information about what's going to happen. So there's really no head of the snake. There's not one sort of thing you can sort of take out to make the entire movement sort of fizzle. CORNISH: Right. I think every once in a while, you will kind of post screencaps - right? - of conversations people are having. And I notice, of course, they're very undeterred by real-world events. Like, all of a sudden, the comments - people will sort of work it out amongst themselves and say, oh, well, hey; maybe it's this. Hey; maybe it's that. It's, like, a communal experience. VIEW: Well, yeah. It's really kind of like an improvisational reality building, you know? They don't look to the outside world to try and figure out, you know, what is true and what is not and then, as a consequence, sometimes have to face harsh truths such as the, you know, electoral victory of Joe Biden. They come to their conclusion first. They decide what makes them feel best, and then they construct conspiracy theories that help them convince themselves why that's true. CORNISH: How much sympathy do you have for people who have gotten involved in this? And the reason why I ask is because it's probably not going to be unusual to hear people here and there say, oh, I was sucked in, and maybe not take personal responsibility for their actions during that time. VIEW: I actually have, I mean, a great deal of sympathy for people who fall into this, and the reason is because QAnon satisfies needs that we all have. We all need to have a feeling of significance. We all need to have a feeling of community. And we all need to have some sense of optimism for the future. And if you're not getting that in any other way, then QAnon can sort of fulfill that role for you. Now, I think in the end, it's very, very toxic. But I realize why people who are very vulnerable fall into this. CORNISH: In the end, what do you want people to understand about this movement that they don't and that the media misses - right? - because it's just so sensational in talking about it? VIEW: (Sighing). CORNISH: That's a deep sigh, man. VIEW: Yeah. See; one thing that I do want to say that people often get wrong about QAnon is this idea that everyone who believes in it is stupid or uneducated or even, like, you know, poor or something like that. And, obviously, these beliefs are delusional. But over and over again, we've seen people who are actually pretty well-educated or fairly successful get drawn into it. For example, one of the people who ran a sort of a QAnon aggregator website which kind of, like, organized Q drops for people wound up being sort of a tech executive for a major bank because, you know, again, the things that QAnon fulfilled for people is existential. Anyone can sort of fall into QAnon. CORNISH: That's interesting. Is there a kind of consequence to people dismissing it in that way or who think that this is about education or income? VIEW: Yeah. I mean, the consequence is that they wind up thinking that QAnon is sort of easily quarantined or easily fixable. That's simply not the case. CORNISH: Travis View, thank you so much for sharing your knowledge with us and for, I guess, showing us around the rabbit hole. VIEW: It's been my pleasure. Thank you so much for having me. (SOUNDBITE OF L'ECLAIR'S \"DALLAS\") AUDIE CORNISH, HOST:   In the online QAnon universe, former President Trump is seen as the savior of humanity, someone who is destined to rescue not just the country but the entire world from darkness. That's according to our next guest, Travis View. He monitors the spread of online conspiracies. But with Trump out of office, what happens to this movement? View says it's not going anywhere. TRAVIS VIEW: Without L. Ron Hubbard, does Scientology fizzle? I mean, once a movement like this grows to a certain size and once the believers in it become dedicated enough, it becomes self-sustaining. And it doesn't need its founder or leader anymore. CORNISH: View is also the co-host of a podcast that follows the conspiracy movement. It's called \"QAnon Anonymous. \" Yes, he says, the theories are elaborate, self-contradictory and illogical. And for some adherents, that's part of the draw. VIEW: This is, I think, a big part of, like, what gets people locked in - is that it might seem impenetrable to you, but when you're inside, it feels like you're, you know, privy to some sort of secret inside information that only you and your other fellow QAnon followers are sharp enough to understand. CORNISH: What makes you think, in this case, it is self-sustaining? I mean, you - because of your - some of your branding, I understand people actually gravitate towards the podcast before they realize that you're actually not supportive of the movement. VIEW: That's true. CORNISH: And you get a lot of, like, you know, interactions and mail. So what are you hearing that, for you, says, oh, this ain't over? VIEW: Well, one thing that makes me convinced that this is not something that's just going to go away is, you know, the fact that even though sort of Q itself, the entity, has not posted whatsoever since December 8. And despite that, you know, the community itself is still very active because they sort of - the belief systems and the sort of conspiracy theories that sort of sustain the movement don't come from Trump or Q or any specific leader. It's sort of crowdsourced and self-generated. I mean, it really is about the community and sort of the feeling that they have some sort of inside information about what's going to happen. So there's really no head of the snake. There's not one sort of thing you can sort of take out to make the entire movement sort of fizzle. CORNISH: Right. I think every once in a while, you will kind of post screencaps - right? - of conversations people are having. And I notice, of course, they're very undeterred by real-world events. Like, all of a sudden, the comments - people will sort of work it out amongst themselves and say, oh, well, hey; maybe it's this. Hey; maybe it's that. It's, like, a communal experience. VIEW: Well, yeah. It's really kind of like an improvisational reality building, you know? They don't look to the outside world to try and figure out, you know, what is true and what is not and then, as a consequence, sometimes have to face harsh truths such as the, you know, electoral victory of Joe Biden. They come to their conclusion first. They decide what makes them feel best, and then they construct conspiracy theories that help them convince themselves why that's true. CORNISH: How much sympathy do you have for people who have gotten involved in this? And the reason why I ask is because it's probably not going to be unusual to hear people here and there say, oh, I was sucked in, and maybe not take personal responsibility for their actions during that time. VIEW: I actually have, I mean, a great deal of sympathy for people who fall into this, and the reason is because QAnon satisfies needs that we all have. We all need to have a feeling of significance. We all need to have a feeling of community. And we all need to have some sense of optimism for the future. And if you're not getting that in any other way, then QAnon can sort of fulfill that role for you. Now, I think in the end, it's very, very toxic. But I realize why people who are very vulnerable fall into this. CORNISH: In the end, what do you want people to understand about this movement that they don't and that the media misses - right? - because it's just so sensational in talking about it? VIEW: (Sighing). CORNISH: That's a deep sigh, man. VIEW: Yeah. See; one thing that I do want to say that people often get wrong about QAnon is this idea that everyone who believes in it is stupid or uneducated or even, like, you know, poor or something like that. And, obviously, these beliefs are delusional. But over and over again, we've seen people who are actually pretty well-educated or fairly successful get drawn into it. For example, one of the people who ran a sort of a QAnon aggregator website which kind of, like, organized Q drops for people wound up being sort of a tech executive for a major bank because, you know, again, the things that QAnon fulfilled for people is existential. Anyone can sort of fall into QAnon. CORNISH: That's interesting. Is there a kind of consequence to people dismissing it in that way or who think that this is about education or income? VIEW: Yeah. I mean, the consequence is that they wind up thinking that QAnon is sort of easily quarantined or easily fixable. That's simply not the case. CORNISH: Travis View, thank you so much for sharing your knowledge with us and for, I guess, showing us around the rabbit hole. VIEW: It's been my pleasure. Thank you so much for having me. (SOUNDBITE OF L'ECLAIR'S \"DALLAS\")", "section": "National", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-02-04-963995484": {"title": "Ken Griffin: The Hedge Fund Titan In The Middle Of The Reddit Investing Revolt : NPR", "url": "https://www.npr.org/2021/02/04/963995484/ken-griffin-the-hedge-fund-titan-in-the-middle-of-the-reddit-investing-revolt", "author": "No author found", "published_date": "2021-02-04", "content": "", "section": "Business", "disclaimer": ""}, "2021-02-05-964218185": {"title": "Nagin Cox: What Does Time On Mars Teach Us About Time On Earth? : NPR", "url": "https://www.npr.org/2021/02/05/964218185/nagin-cox-what-does-time-on-mars-teach-us-about-time-on-earth", "author": "No author found", "published_date": "2021-02-05", "content": "MANOUSH ZOMORODI, HOST:  On the show today, it takes time. And earthlings, so far, we've been talking about the 24/7, 365 days a year kind of time. Get ready for something different. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED PERSON #1: Thrusters have been reenabled. We will control our attitude on chute. We are decelerating. ZOMORODI: This is Mission Control at the Jet Propulsion Laboratory, NASA's robotics headquarters. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED PERSON #2: Phase come back again with wrist mode dynamics. UNIDENTIFIED PERSON #3: Wrist mode is nominal. ZOMORODI: It's August 2012. And for the Curiosity rover that's been headed to Mars, it's landing day. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED PERSON #1: We're down to 86 meters per second at an altitude of 4 kilometers. . . ZOMORODI: Rows of engineers are stationed at computers. The landing director is pacing. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED PERSON #4: Flight, EDL, we've got some TWTA warnings. ZOMORODI: Tensions are high. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED PERSON #1: We found a nice, flat place. We're coming in ready for sky crane. ZOMORODI: They've spent years designing and programming the rover to land safely. Now they can only watch as the data come in. NAGIN COX: You have to wait. You have to wait patiently. It's very hard to wait on landing day. ZOMORODI: That's Nagin Cox. COX: And I am an engineer at NASA's Jet Propulsion Laboratory in Pasadena, Calif. , and I'm the deputy team chief of the engineering operations team for the Mars 2020 rover. ZOMORODI: In the last two decades, NASA has put three rovers on Mars. Nagin has worked on all of them. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED PERSON #3: RIMU stable. ZOMORODI: And in 2012, she's there in Mission Control, watching as the rover slowly descends. . . (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED PERSON #5: UHF is good. ZOMORODI: . . . And finally. . . (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED PERSON #1: Touchdown confirmed. We're safe on Mars. (CHEERING)ZOMORODI: But now, for Nagin and her team of engineers, the clock really starts ticking. (SOUNDBITE OF CLOCK TICKING)COX: You know, we're landing with a multibillion-dollar asset that is priceless on the surface of Mars. And we want to make use of every minute. ZOMORODI: Which means putting the rover on a very strict schedule. COX: Power is a very important resource on Mars. So the rover sleeps at night because it takes a lot of power to do anything at night. So the rover basically wakes up at about 9:30 in the morning and receives instructions from the Earth and starts working at approximately 10 a. m. and will do activities that we have told her to do. But we are not joy-sticking this rover. It's too far. Then, you know, at around 5:30 p. m. , the rover finishes her day. And basically, when she goes to sleep, we get the data, see how her day went. And now we have the information to plan her next day. ZOMORODI: Nagin can start crunching the rover's data while the rover sleeps. But don't think of it as your typical night shift because working on Mars time is a little different. COX: So a Martian day, which we call a sol, is longer than an Earth Day. Our planet rotates in 24 hours relative to the sun. Mars rotates at a different rate. So a Martian day is approximately 24 hours and 40 minutes. ZOMORODI: Nagin Cox continues from the TED stage. (SOUNDBITE OF TED TALK)COX: So in order to come to work on the Earth at the same time every day on Mars, then we have to come in to work on the Earth 40 minutes later every day in order to stay in sync with Mars. So that's like moving a time zone every day, right? So one day you come in at 8. The next day, 40 minutes later at 8:40. The next day, 40 minutes later at 9:20. The next day at 10:00. So you keep moving 40 minutes every day until, soon, you're coming to work in the middle of the night, the middle of the Earth night, right? So you can imagine how confusing that is. Hence, the Mars watch. (LAUGHTER)COX: This watch has been mechanically - the weights have been mechanically adjusted so that it runs more slowly, right? And we didn't start out - I got this watch in 2004 when Spirit and Opportunity, the rovers back then - we didn't start out thinking that we were going to need Mars watches, right? We thought, OK, we'll just have the time on our computers and on the mission control screens and that would be enough. Yeah, not so much. Because we weren't just working on Mars time, we were actually living on Mars time. And we got just instantaneously. . . ZOMORODI: I mean, it sounds like, oh, it's just a 40-minute difference, but over a 90-day mission, that can add up and, I assume, be pretty disorienting. COX: Yeah. So the minute you have to shift your sleep cycle and are moving in time, you also need to eliminate the cues of what is Earth time. So it started with shades and blinds and things to keep us from seeing the Earth daylight. Because if we had rotated to the point where it was night on Mars, but daylight on the Earth, we didn't want the daylight to come in and mess up our body clocks. And not just our body clocks, but also our mental sense of where we were. ZOMORODI: Hmm. COX: And it even started to spread into our language. I distinctly remember someone walking up to me and saying, hey, Nagin, we need to do this activity on the vehicle tomorrow. And I absolutely said, uh, which tomorrow? Tomorrow tomorrow or Mars tomorrow? ZOMORODI: (Laughter) So how do you solve for that? COX: So a lot of this was tied to how can we get our jobs done in the most efficient way? And again, that was coming up with words that would make it clear quickly, you know, what planet we were talking about. Were we talking about the Earth or Mars? And so if a day on Mars is a sol, then tomorrow becomes nextersol and yesterday becomes yestersol. (SOUNDBITE OF TED TALK)COX: So we have the watches and the language. And one of the things that we all discovered is you can get anywhere in Los Angeles at 3:00 in the morning when there's no traffic. (LAUGHTER)COX: So we would get off work, and we - instead of going - you know, we didn't want to go home and bother our families. And we were hungry, so instead of going, you know, locally to eat something, we'd go, wait, there's this great all-night deli in Long Beach, and we can get there in, like, 10 minutes. So we would drive down. It was, like, the '60s - right? - no traffic. We would drive down there, and the restaurant owners would go, who are you people? (LAUGHTER)COX: And why are you at my restaurant at 3 in the morning? So they came to realize that there were these packs of Martians. . . (LAUGHTER)COX: . . . Roaming the L. A. freeways in the middle of the night. And we did actually start calling ourselves Martians. So those of us who were on Mars time, we would refer to ourselves as Martians and everyone else as earthlings. (LAUGHTER)COX: And that's because when you're moving a time zone every day, you start to really feel separated from everyone else. You're literally in your own world. ZOMORODI: I can only imagine that that had kind of a wonderful effect on your relationships with your colleagues. Like, having worked in a newsroom, there's a lingo, right? You all speak the same language, and it - there's a shorthand, and you can move through information so much more quickly. Did it have that? Did it bring you together in some ways as a team when you started to be living on a different planet, at least in terms of what time it was and the vocabulary that you used? COX: It absolutely did in ways that we didn't expect. The isolation, the sense of separation from even your family, your friends, other colleagues who aren't working this mission sets in pretty quickly. And most of that is due to the time. You are very quickly shifted from them. Your experience becomes extremely focused on what happens on Mars. You don't have any idea what time it is on Earth because we're trying to get rid of the cues. You don't even remember what day it is on Earth. You remember what sol it is because your mind is constantly projecting you to Mars. So the people that you're sharing this experience with will always be the humans that you experience Mars time with. ZOMORODI: You know, this episode is all about topics or things that you cannot rush. They take time. That's, you know, from sloths to bridges made of roots to the amount of time that we need to sleep to be healthy human beings. And I guess I wonder, you know, for me, these conversations are making me want to slow down, to not rush things. And I wonder if there are some lessons of from when you've been on Mars time that you've taken back to when you are on Earth time. COX: Certainly, Mars time reminds you of - it makes you not take time for granted. You look at time differently because we've changed it. And when you are someplace on Mars exploring for all of humankind, it is a different rhythm. We are there to look around, to explore, to go slowly, to get our job done, which does mean we have distance to cover. But the ability to get from one location to another but then to stop and look at what we're doing - it is the rhythm of humanity-scale exploration. ZOMORODI: That's Nagin Cox. She's an operations engineer at the Jet Propulsion Laboratory and a deputy team chief for the Mars 2020 Perseverance Rover, which is set to land February 18. You can learn more about the mission at jpl. nasa. gov, and you can watch Nagin's full talk at ted. com. MANOUSH ZOMORODI, HOST:   On the show today, it takes time. And earthlings, so far, we've been talking about the 24/7, 365 days a year kind of time. Get ready for something different. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED PERSON #1: Thrusters have been reenabled. We will control our attitude on chute. We are decelerating. ZOMORODI: This is Mission Control at the Jet Propulsion Laboratory, NASA's robotics headquarters. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED PERSON #2: Phase come back again with wrist mode dynamics. UNIDENTIFIED PERSON #3: Wrist mode is nominal. ZOMORODI: It's August 2012. And for the Curiosity rover that's been headed to Mars, it's landing day. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED PERSON #1: We're down to 86 meters per second at an altitude of 4 kilometers. . . ZOMORODI: Rows of engineers are stationed at computers. The landing director is pacing. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED PERSON #4: Flight, EDL, we've got some TWTA warnings. ZOMORODI: Tensions are high. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED PERSON #1: We found a nice, flat place. We're coming in ready for sky crane. ZOMORODI: They've spent years designing and programming the rover to land safely. Now they can only watch as the data come in. NAGIN COX: You have to wait. You have to wait patiently. It's very hard to wait on landing day. ZOMORODI: That's Nagin Cox. COX: And I am an engineer at NASA's Jet Propulsion Laboratory in Pasadena, Calif. , and I'm the deputy team chief of the engineering operations team for the Mars 2020 rover. ZOMORODI: In the last two decades, NASA has put three rovers on Mars. Nagin has worked on all of them. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED PERSON #3: RIMU stable. ZOMORODI: And in 2012, she's there in Mission Control, watching as the rover slowly descends. . . (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED PERSON #5: UHF is good. ZOMORODI: . . . And finally. . . (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED PERSON #1: Touchdown confirmed. We're safe on Mars. (CHEERING) ZOMORODI: But now, for Nagin and her team of engineers, the clock really starts ticking. (SOUNDBITE OF CLOCK TICKING) COX: You know, we're landing with a multibillion-dollar asset that is priceless on the surface of Mars. And we want to make use of every minute. ZOMORODI: Which means putting the rover on a very strict schedule. COX: Power is a very important resource on Mars. So the rover sleeps at night because it takes a lot of power to do anything at night. So the rover basically wakes up at about 9:30 in the morning and receives instructions from the Earth and starts working at approximately 10 a. m. and will do activities that we have told her to do. But we are not joy-sticking this rover. It's too far. Then, you know, at around 5:30 p. m. , the rover finishes her day. And basically, when she goes to sleep, we get the data, see how her day went. And now we have the information to plan her next day. ZOMORODI: Nagin can start crunching the rover's data while the rover sleeps. But don't think of it as your typical night shift because working on Mars time is a little different. COX: So a Martian day, which we call a sol, is longer than an Earth Day. Our planet rotates in 24 hours relative to the sun. Mars rotates at a different rate. So a Martian day is approximately 24 hours and 40 minutes. ZOMORODI: Nagin Cox continues from the TED stage. (SOUNDBITE OF TED TALK) COX: So in order to come to work on the Earth at the same time every day on Mars, then we have to come in to work on the Earth 40 minutes later every day in order to stay in sync with Mars. So that's like moving a time zone every day, right? So one day you come in at 8. The next day, 40 minutes later at 8:40. The next day, 40 minutes later at 9:20. The next day at 10:00. So you keep moving 40 minutes every day until, soon, you're coming to work in the middle of the night, the middle of the Earth night, right? So you can imagine how confusing that is. Hence, the Mars watch. (LAUGHTER) COX: This watch has been mechanically - the weights have been mechanically adjusted so that it runs more slowly, right? And we didn't start out - I got this watch in 2004 when Spirit and Opportunity, the rovers back then - we didn't start out thinking that we were going to need Mars watches, right? We thought, OK, we'll just have the time on our computers and on the mission control screens and that would be enough. Yeah, not so much. Because we weren't just working on Mars time, we were actually living on Mars time. And we got just instantaneously. . . ZOMORODI: I mean, it sounds like, oh, it's just a 40-minute difference, but over a 90-day mission, that can add up and, I assume, be pretty disorienting. COX: Yeah. So the minute you have to shift your sleep cycle and are moving in time, you also need to eliminate the cues of what is Earth time. So it started with shades and blinds and things to keep us from seeing the Earth daylight. Because if we had rotated to the point where it was night on Mars, but daylight on the Earth, we didn't want the daylight to come in and mess up our body clocks. And not just our body clocks, but also our mental sense of where we were. ZOMORODI: Hmm. COX: And it even started to spread into our language. I distinctly remember someone walking up to me and saying, hey, Nagin, we need to do this activity on the vehicle tomorrow. And I absolutely said, uh, which tomorrow? Tomorrow tomorrow or Mars tomorrow? ZOMORODI: (Laughter) So how do you solve for that? COX: So a lot of this was tied to how can we get our jobs done in the most efficient way? And again, that was coming up with words that would make it clear quickly, you know, what planet we were talking about. Were we talking about the Earth or Mars? And so if a day on Mars is a sol, then tomorrow becomes nextersol and yesterday becomes yestersol. (SOUNDBITE OF TED TALK) COX: So we have the watches and the language. And one of the things that we all discovered is you can get anywhere in Los Angeles at 3:00 in the morning when there's no traffic. (LAUGHTER) COX: So we would get off work, and we - instead of going - you know, we didn't want to go home and bother our families. And we were hungry, so instead of going, you know, locally to eat something, we'd go, wait, there's this great all-night deli in Long Beach, and we can get there in, like, 10 minutes. So we would drive down. It was, like, the '60s - right? - no traffic. We would drive down there, and the restaurant owners would go, who are you people? (LAUGHTER) COX: And why are you at my restaurant at 3 in the morning? So they came to realize that there were these packs of Martians. . . (LAUGHTER) COX: . . . Roaming the L. A. freeways in the middle of the night. And we did actually start calling ourselves Martians. So those of us who were on Mars time, we would refer to ourselves as Martians and everyone else as earthlings. (LAUGHTER) COX: And that's because when you're moving a time zone every day, you start to really feel separated from everyone else. You're literally in your own world. ZOMORODI: I can only imagine that that had kind of a wonderful effect on your relationships with your colleagues. Like, having worked in a newsroom, there's a lingo, right? You all speak the same language, and it - there's a shorthand, and you can move through information so much more quickly. Did it have that? Did it bring you together in some ways as a team when you started to be living on a different planet, at least in terms of what time it was and the vocabulary that you used? COX: It absolutely did in ways that we didn't expect. The isolation, the sense of separation from even your family, your friends, other colleagues who aren't working this mission sets in pretty quickly. And most of that is due to the time. You are very quickly shifted from them. Your experience becomes extremely focused on what happens on Mars. You don't have any idea what time it is on Earth because we're trying to get rid of the cues. You don't even remember what day it is on Earth. You remember what sol it is because your mind is constantly projecting you to Mars. So the people that you're sharing this experience with will always be the humans that you experience Mars time with. ZOMORODI: You know, this episode is all about topics or things that you cannot rush. They take time. That's, you know, from sloths to bridges made of roots to the amount of time that we need to sleep to be healthy human beings. And I guess I wonder, you know, for me, these conversations are making me want to slow down, to not rush things. And I wonder if there are some lessons of from when you've been on Mars time that you've taken back to when you are on Earth time. COX: Certainly, Mars time reminds you of - it makes you not take time for granted. You look at time differently because we've changed it. And when you are someplace on Mars exploring for all of humankind, it is a different rhythm. We are there to look around, to explore, to go slowly, to get our job done, which does mean we have distance to cover. But the ability to get from one location to another but then to stop and look at what we're doing - it is the rhythm of humanity-scale exploration. ZOMORODI: That's Nagin Cox. She's an operations engineer at the Jet Propulsion Laboratory and a deputy team chief for the Mars 2020 Perseverance Rover, which is set to land February 18. You can learn more about the mission at jpl. nasa. gov, and you can watch Nagin's full talk at ted. com.", "section": "TED Radio Hour", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-02-06-964830201": {"title": "Myanmar Blocks Social Media Sites As Anti-Coup Protests Grow : NPR", "url": "https://www.npr.org/2021/02/06/964830201/myanmar-blocks-facebook-twitter-access-as-anti-government-protests-grow", "author": "No author found", "published_date": "2021-02-06", "content": "", "section": "Asia", "disclaimer": ""}, "2021-02-07-965162338": {"title": "In Alabama, Workers At Amazon Warehouse Are Poised For Union Vote : NPR", "url": "https://www.npr.org/2021/02/07/965162338/in-alabama-workers-at-amazon-warehouse-are-poised-for-union-vote", "author": "No author found", "published_date": "2021-02-07", "content": "", "section": "Business", "disclaimer": ""}, "2021-02-08-965448572": {"title": "Meet The Man Keeping Far-Right Websites Alive : NPR", "url": "https://www.npr.org/2021/02/08/965448572/meet-the-man-behind-epik-the-tech-firm-keeping-far-right-websites-alive", "author": "No author found", "published_date": "2021-02-08", "content": "", "section": "Technology", "disclaimer": ""}, "2021-02-08-965515655": {"title": "Meet Rob Monster, The Self-Described 'Lex Luthor of the Internet' : NPR", "url": "https://www.npr.org/2021/02/08/965515655/meet-rob-monster-the-self-described-lex-luther-of-the-internet", "author": "No author found", "published_date": "2021-02-08", "content": "ARI SHAPIRO, HOST:  Should websites that host hate speech and conspiracy theories have a home on the Internet? There's a tech company outside Seattle that thinks they should, and it's become one of the most controversial players in the debate over the future of online speech. NPR's Bobby Allyn traveled to Sammamish, Wash. , to talk to the man at the center of it. BOBBY ALLYN, BYLINE: He lives at the end of a cul-de-sac in this woodsy Seattle suburb and welcomes me to his lakeside home. (SOUNDBITE OF DOG BARKING)ROB MONSTER: Can I make you a coffee - cafe latte? ALLYN: Yeah, that sounds good. The man's name is Rob Monster. Yep, that's his real name. MONSTER: If you wanted to cast a villain who was going to be the Lex Luthor of the Internet, Rob Monster is about as good as it gets. ALLYN: For years, Monster has run a business called Epik. It buys and sells website names like diamond. com or 3d. com. There's big money in the world of coveted web domains. In 2018, Monster stopped being a low-key tech executive. That's when the world found out that the shooter charged with killing 11 people at the Pittsburgh synagogue had used the right-leaning social network Gab. In the fallout, Gab lost all of its Web support. MONSTER: And I looked at that and said, you know what? I don't think there was a lot of due process in terms of how the decision was taken to de-platform gab. com. ALLYN: So he reached out to Gab and helped them get back online. Now sites know if they become too radioactive for support providers, Epik will be standing by with a lifeline. Epik now supports the conspiracy theory website InfoWars, embattled conservative platform Parler, the largely unregulated YouTube alternative BitChute, the gun forum ar15. com and others. MONSTER: If somebody wants to go through a messy swamp in their search for truth, who are we to decide that they shouldn't have the opportunity to do that? ALLYN: But in the messy swamp of sites Epik does business with are conspiracy theories about the election, vaccines and mass shootings and a steady stream of bigoted content about Jews, women and people of color. Monster's libertarian approach concerns researchers who track hate groups online. Michael Edison Hayden is with the Southern Poverty Law Center. He says hate speech permeates all corners of the Internet, including major platforms Facebook and Twitter. But he says the sites Epik is keeping alive are notorious for doing almost nothing about it. MICHAEL EDISON HAYDEN: The difference is that there are people with terroristic ambitions plotting out in the open, producing propaganda that they seek to use to kind of encourage violence. And those are the type of websites Rob Monster is willing to pick up. ALLYN: Monster says he has standards. For instance, Epik dropped the neo-Nazi website The Daily Stormer and severed ties with the hate-spewing image board 8chan. On the sites Epik does support, it's easy to find some pretty ugly and hateful content. But Monster has faith in the sites regulating themselves. MONSTER: Epik is standing in the gap, trying to find that fruitful compromise that allows people to have the luxury to be able to ask questions, seek answers, while at the same time being a stakeholder in the rearchitecting of a better Internet where we can have civil conversation. ALLYN: The sites Epik backs, though, are far from civil. Experts say some have been gathering places for white supremacists and have radicalized people. And the rhetoric has led to real-world violence. Case in point - the storming of the Capitol that was largely documented on sites Monster helps maintain, like Parler. David Kay is an online speech expert at the University of California, Irvine. DAVID KAY: So he can say they're just shock jocks, but what we actually see is real-world harm coming from the platforms. And so how much is, you know, somebody who is allowing that kind of content to be hosted - how much are they operating in real good faith? ALLYN: And this really is the question. If you believe Monster, he just wants an open Internet, where the most incendiary and toxic content lives alongside everything else. Big tech playing Internet cop, he says, gives companies the levers to control what we see and don't see online. And he argues the crackdown has been overzealous. He points to Facebook and Twitter banning former President Trump. MONSTER: It's one thing to be sent to detention. It's another thing to get a suspension. It's another thing to be sent to a penal colony for the rest of your life. ALLYN: In Monster's vision for the Internet, tech companies do not interfere with who can speak or what is said. But experts say when people's lives and democracy are on the line, speech with no regulations is not always a good thing. Bobby Allyn, NPR News, Sammamish, Wash. (SOUNDBITE OF BRIGHTBLACK MORNING LIGHT SONG, \"EVERYBODY DAYLIGHT\") ARI SHAPIRO, HOST:   Should websites that host hate speech and conspiracy theories have a home on the Internet? There's a tech company outside Seattle that thinks they should, and it's become one of the most controversial players in the debate over the future of online speech. NPR's Bobby Allyn traveled to Sammamish, Wash. , to talk to the man at the center of it. BOBBY ALLYN, BYLINE: He lives at the end of a cul-de-sac in this woodsy Seattle suburb and welcomes me to his lakeside home. (SOUNDBITE OF DOG BARKING) ROB MONSTER: Can I make you a coffee - cafe latte? ALLYN: Yeah, that sounds good. The man's name is Rob Monster. Yep, that's his real name. MONSTER: If you wanted to cast a villain who was going to be the Lex Luthor of the Internet, Rob Monster is about as good as it gets. ALLYN: For years, Monster has run a business called Epik. It buys and sells website names like diamond. com or 3d. com. There's big money in the world of coveted web domains. In 2018, Monster stopped being a low-key tech executive. That's when the world found out that the shooter charged with killing 11 people at the Pittsburgh synagogue had used the right-leaning social network Gab. In the fallout, Gab lost all of its Web support. MONSTER: And I looked at that and said, you know what? I don't think there was a lot of due process in terms of how the decision was taken to de-platform gab. com. ALLYN: So he reached out to Gab and helped them get back online. Now sites know if they become too radioactive for support providers, Epik will be standing by with a lifeline. Epik now supports the conspiracy theory website InfoWars, embattled conservative platform Parler, the largely unregulated YouTube alternative BitChute, the gun forum ar15. com and others. MONSTER: If somebody wants to go through a messy swamp in their search for truth, who are we to decide that they shouldn't have the opportunity to do that? ALLYN: But in the messy swamp of sites Epik does business with are conspiracy theories about the election, vaccines and mass shootings and a steady stream of bigoted content about Jews, women and people of color. Monster's libertarian approach concerns researchers who track hate groups online. Michael Edison Hayden is with the Southern Poverty Law Center. He says hate speech permeates all corners of the Internet, including major platforms Facebook and Twitter. But he says the sites Epik is keeping alive are notorious for doing almost nothing about it. MICHAEL EDISON HAYDEN: The difference is that there are people with terroristic ambitions plotting out in the open, producing propaganda that they seek to use to kind of encourage violence. And those are the type of websites Rob Monster is willing to pick up. ALLYN: Monster says he has standards. For instance, Epik dropped the neo-Nazi website The Daily Stormer and severed ties with the hate-spewing image board 8chan. On the sites Epik does support, it's easy to find some pretty ugly and hateful content. But Monster has faith in the sites regulating themselves. MONSTER: Epik is standing in the gap, trying to find that fruitful compromise that allows people to have the luxury to be able to ask questions, seek answers, while at the same time being a stakeholder in the rearchitecting of a better Internet where we can have civil conversation. ALLYN: The sites Epik backs, though, are far from civil. Experts say some have been gathering places for white supremacists and have radicalized people. And the rhetoric has led to real-world violence. Case in point - the storming of the Capitol that was largely documented on sites Monster helps maintain, like Parler. David Kay is an online speech expert at the University of California, Irvine. DAVID KAY: So he can say they're just shock jocks, but what we actually see is real-world harm coming from the platforms. And so how much is, you know, somebody who is allowing that kind of content to be hosted - how much are they operating in real good faith? ALLYN: And this really is the question. If you believe Monster, he just wants an open Internet, where the most incendiary and toxic content lives alongside everything else. Big tech playing Internet cop, he says, gives companies the levers to control what we see and don't see online. And he argues the crackdown has been overzealous. He points to Facebook and Twitter banning former President Trump. MONSTER: It's one thing to be sent to detention. It's another thing to get a suspension. It's another thing to be sent to a penal colony for the rest of your life. ALLYN: In Monster's vision for the Internet, tech companies do not interfere with who can speak or what is said. But experts say when people's lives and democracy are on the line, speech with no regulations is not always a good thing. Bobby Allyn, NPR News, Sammamish, Wash. (SOUNDBITE OF BRIGHTBLACK MORNING LIGHT SONG, \"EVERYBODY DAYLIGHT\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-02-08-965390755": {"title": "Facebook Widens Ban On COVID-19 Vaccine Misinformation In Push To Boost Confidence : NPR", "url": "https://www.npr.org/2021/02/08/965390755/facebook-widens-ban-on-covid-19-vaccine-misinformation-in-push-to-boost-confiden", "author": "No author found", "published_date": "2021-02-08", "content": "", "section": "The Coronavirus Crisis", "disclaimer": ""}, "2021-02-09-965791252": {"title": "FBI Called In After Hacker Tries To Poison Tampa-Area City's Water With Lye : NPR", "url": "https://www.npr.org/2021/02/09/965791252/fbi-called-in-after-hacker-tries-to-poison-tampa-area-citys-water-with-lye", "author": "No author found", "published_date": "2021-02-09", "content": "", "section": "National", "disclaimer": ""}, "2021-02-09-965129433": {"title": "How The Reddit Trade Was Fueled By Fury Over The Great Recession : NPR", "url": "https://www.npr.org/2021/02/09/965129433/the-game-is-rigged-how-fury-over-the-great-recession-fueled-the-reddit-trade", "author": "No author found", "published_date": "2021-02-09", "content": "", "section": "Economy", "disclaimer": ""}, "2021-02-10-966584204": {"title": "Biden Administration Pauses Trump's TikTok Ban, Backs Off Pressure To Sell App : NPR", "url": "https://www.npr.org/2021/02/10/966584204/biden-administration-pauses-trumps-tiktok-ban-backs-off-pressure-for-tiktok-to-s", "author": "No author found", "published_date": "2021-02-10", "content": "", "section": "Technology", "disclaimer": ""}, "2021-02-10-966500963": {"title": "What To Know About The New, Controversial Audio-Only App, Clubhouse : NPR", "url": "https://www.npr.org/2021/02/10/966500963/what-to-know-about-the-new-controversial-audio-only-app-clubhouse", "author": "No author found", "published_date": "2021-02-10", "content": "ARI SHAPIRO, HOST:  Clubhouse is the new invite-only app that Silicon Valley says is the future of social media. Millions have downloaded it recently, including celebrities, famous musicians and tech CEOs. What's all the hype about? NPR's Bobby Allyn looked into it. BOBBY ALLYN, BYLINE: Oprah Winfrey, Drake, Elon Musk, Mark Zuckerberg and even the White House chief of staff have all signed up. And so have Atlanta rappers, comedians, relationship gurus and endless people with a hot take. It's starting to feel like everyone is on Clubhouse. YVETTE WOHN: People are so exhausted with Zoom. When you have a camera, there's a lot of effort that goes into self-presentation. ALLYN: Clubhouse is audio-only. That's part of the appeal, says Yvette Wohn. She's a professor at the New Jersey Institute of Technology. WOHN: But when you only have audio, you eliminate everything except for your voice. And so it provides a lot more room for imagination. ALLYN: The power of audio, something NPR learned 50 years ago. On Clubhouse, though, scroll through and you'll find people you know and strangers holding court on all kinds of conversations. Tech analyst Jeremiah Owyang was one of the first to sign up. JEREMIAH OWYANG: Just at serendipity and that pleasure of not knowing what's next. ALLYN: Sounds great, but so many of the unfiltered, unedited, hours-long chats can be mind-numbingly dull or feel like a rambling TED talk. Here are some recent discussion topics. Are you an influencer because you call yourself one? Are humans naturally good? And this one was especially riveting - focus on your mindset and manifest your future. Now, Kat Cole (ph) loves this. She's a former branding executive who now spends hours every day on Clubhouse. KAT COLE: I host a weekly room called Office Hours (ph), workshopping just tough decisions in life and business and focus really on leadership, people decisions. ALLYN: It's almost as if your LinkedIn could talk. Sound good to you? Well, it sounds good to the more than 2 million people who have downloaded the app recently. Driving the buzz is this techie country club vibe. You need an in to get on the app. And once there, there are privacy rules. You can't record or even transcribe conversations. They happen and - poof - they're gone - but not really. Surprising no one, people break rules. Here's Owyang. OWYANG: You should always own your words and assume that the bigger public could be listening. It's possible that content could be recorded in that room. ALLYN: Unlike other social media, it's easy for moderators to boot trolls or block others from joining. Controversy erupted recently when a venture capitalist blocked a journalist from coming into Elon Musk's room. The audio leaked anyway. (SOUNDBITE OF ARCHIVED RECORDING)SRIRAM KRISHNAN: I hope you had a fun time for your first time on Clubhouse. Did you have fun? ELON MUSK: Yeah, it's great. This is awesome. I didn't even know it existed a week ago. So it seems cool. KRISHNAN: Awesome. So would you come back? MUSK: Yeah. ALLYN: Musk sounds reluctant, but today he tweeted he's planning a Clubhouse with Kanye West. In China, people say the government's already blocked the app. But in the U. S. , tech companies are taking note and rushing to build Clubhouse clones. Owyang has been counting. OWYANG: Right now, there's over 25 companies and more in my inbox. I estimate there'll be over 100 social audio companies by the end of the year. ALLYN: Including Twitter and, reportedly coming soon, something from Facebook. The big question now, though, is, are these audio chatrooms a pandemic hobby, or will people want an app for spontaneous conversations when there are more things to do out in the world? Bobby Allyn, NPR News, San Francisco. ARI SHAPIRO, HOST:   Clubhouse is the new invite-only app that Silicon Valley says is the future of social media. Millions have downloaded it recently, including celebrities, famous musicians and tech CEOs. What's all the hype about? NPR's Bobby Allyn looked into it. BOBBY ALLYN, BYLINE: Oprah Winfrey, Drake, Elon Musk, Mark Zuckerberg and even the White House chief of staff have all signed up. And so have Atlanta rappers, comedians, relationship gurus and endless people with a hot take. It's starting to feel like everyone is on Clubhouse. YVETTE WOHN: People are so exhausted with Zoom. When you have a camera, there's a lot of effort that goes into self-presentation. ALLYN: Clubhouse is audio-only. That's part of the appeal, says Yvette Wohn. She's a professor at the New Jersey Institute of Technology. WOHN: But when you only have audio, you eliminate everything except for your voice. And so it provides a lot more room for imagination. ALLYN: The power of audio, something NPR learned 50 years ago. On Clubhouse, though, scroll through and you'll find people you know and strangers holding court on all kinds of conversations. Tech analyst Jeremiah Owyang was one of the first to sign up. JEREMIAH OWYANG: Just at serendipity and that pleasure of not knowing what's next. ALLYN: Sounds great, but so many of the unfiltered, unedited, hours-long chats can be mind-numbingly dull or feel like a rambling TED talk. Here are some recent discussion topics. Are you an influencer because you call yourself one? Are humans naturally good? And this one was especially riveting - focus on your mindset and manifest your future. Now, Kat Cole (ph) loves this. She's a former branding executive who now spends hours every day on Clubhouse. KAT COLE: I host a weekly room called Office Hours (ph), workshopping just tough decisions in life and business and focus really on leadership, people decisions. ALLYN: It's almost as if your LinkedIn could talk. Sound good to you? Well, it sounds good to the more than 2 million people who have downloaded the app recently. Driving the buzz is this techie country club vibe. You need an in to get on the app. And once there, there are privacy rules. You can't record or even transcribe conversations. They happen and - poof - they're gone - but not really. Surprising no one, people break rules. Here's Owyang. OWYANG: You should always own your words and assume that the bigger public could be listening. It's possible that content could be recorded in that room. ALLYN: Unlike other social media, it's easy for moderators to boot trolls or block others from joining. Controversy erupted recently when a venture capitalist blocked a journalist from coming into Elon Musk's room. The audio leaked anyway. (SOUNDBITE OF ARCHIVED RECORDING) SRIRAM KRISHNAN: I hope you had a fun time for your first time on Clubhouse. Did you have fun? ELON MUSK: Yeah, it's great. This is awesome. I didn't even know it existed a week ago. So it seems cool. KRISHNAN: Awesome. So would you come back? MUSK: Yeah. ALLYN: Musk sounds reluctant, but today he tweeted he's planning a Clubhouse with Kanye West. In China, people say the government's already blocked the app. But in the U. S. , tech companies are taking note and rushing to build Clubhouse clones. Owyang has been counting. OWYANG: Right now, there's over 25 companies and more in my inbox. I estimate there'll be over 100 social audio companies by the end of the year. ALLYN: Including Twitter and, reportedly coming soon, something from Facebook. The big question now, though, is, are these audio chatrooms a pandemic hobby, or will people want an app for spontaneous conversations when there are more things to do out in the world? Bobby Allyn, NPR News, San Francisco.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-02-10-966302055": {"title": "Forget Ride Hailing. Uber Wants To Be Your One-Stop Shop For Everything : NPR", "url": "https://www.npr.org/2021/02/10/966302055/forget-ride-hailing-uber-wants-to-be-your-one-stop-shop-for-everything", "author": "No author found", "published_date": "2021-02-10", "content": "", "section": "Technology", "disclaimer": ""}, "2021-02-10-966322717": {"title": "A Seashell Horn Is One Of The Oldest Known Musical Instruments : NPR", "url": "https://www.npr.org/2021/02/10/966322717/why-a-musician-breathed-new-life-into-a-17-000-year-old-conch-shell-horn", "author": "No author found", "published_date": "2021-02-10", "content": "MARY LOUISE KELLY, HOST:  A prehistoric musical instrument has been played for the first time in over 17,000 years. It is a trumpet-like horn made from a conch shell. And as NPR's Nell Greenfieldboyce reports, it's a unique addition to the history of music. NELL GREENFIELDBOYCE, BYLINE: Archaeologists found this big seashell in 1931. It was in a French cave that has wall paintings. Scientists speculated that the cave's Stone Age occupants had used the shell as a ceremonial cup for shared drinks. They thought that a hole in its tip was just accidental damage. But that's not so, according to a new analysis in the journal Science Advances. High-tech examinations revealed deliberate modifications. The shell's pointy end was opened up to insert a mouthpiece. Two holes were drilled inside the shell, in spots that would allow a tube to come straight down from that mouthpiece. Plus, traces of red pigment on the shell seemed to match motifs used in the cave's paintings. So scientists invited a musician to blow into it. (SOUNDBITE OF SHELL NOTES)GREENFIELDBOYCE: Hearing those notes was a profound experience for Carole Fritz. She's an expert in prehistoric art with the French National Center for Scientific Research, who led the research team. CAROLE FRITZ: For me, it was a big emotion; a big emotion and a big stress. GREENFIELDBOYCE: The stress came from the fact that the musician was forcing air through a priceless, fragile artifact. That's why he only tried a few notes and had to play the horn as it was, with no mouthpiece. Still, it's clear that the sound is very different from that of the oldest known instruments - 40,000-year-old flutes made of bird bones and animal tusks. (SOUNDBITE OF FLUTE)GREENFIELDBOYCE: That's an artist playing a reproduction of a flute found in a German cave. Nicholas Conard works at the University of Tubingen. He's convinced the seashell is a musical instrument. NICHOLAS CONARD: I'm super happy about it because it's kind of lonely having all these flutes that we've got from our sites and there's not too much to compare it to. GREENFIELDBOYCE: Because instruments made of materials like leather or wood don't last for tens of thousands of years. Daniel Adler is an archaeologist at the University of Connecticut. He says hearing music in a dark cave with echoes and dripping water and flickering lamps illuminating the brightly painted walls. . . DANIEL ADLER: That's all very, very evocative stuff that I think we can relate to as modern humans. GREENFIELDBOYCE: But what the music meant to people back then is a mystery. Nell Greenfieldboyce, NPR News. MARY LOUISE KELLY, HOST:   A prehistoric musical instrument has been played for the first time in over 17,000 years. It is a trumpet-like horn made from a conch shell. And as NPR's Nell Greenfieldboyce reports, it's a unique addition to the history of music. NELL GREENFIELDBOYCE, BYLINE: Archaeologists found this big seashell in 1931. It was in a French cave that has wall paintings. Scientists speculated that the cave's Stone Age occupants had used the shell as a ceremonial cup for shared drinks. They thought that a hole in its tip was just accidental damage. But that's not so, according to a new analysis in the journal Science Advances. High-tech examinations revealed deliberate modifications. The shell's pointy end was opened up to insert a mouthpiece. Two holes were drilled inside the shell, in spots that would allow a tube to come straight down from that mouthpiece. Plus, traces of red pigment on the shell seemed to match motifs used in the cave's paintings. So scientists invited a musician to blow into it. (SOUNDBITE OF SHELL NOTES) GREENFIELDBOYCE: Hearing those notes was a profound experience for Carole Fritz. She's an expert in prehistoric art with the French National Center for Scientific Research, who led the research team. CAROLE FRITZ: For me, it was a big emotion; a big emotion and a big stress. GREENFIELDBOYCE: The stress came from the fact that the musician was forcing air through a priceless, fragile artifact. That's why he only tried a few notes and had to play the horn as it was, with no mouthpiece. Still, it's clear that the sound is very different from that of the oldest known instruments - 40,000-year-old flutes made of bird bones and animal tusks. (SOUNDBITE OF FLUTE) GREENFIELDBOYCE: That's an artist playing a reproduction of a flute found in a German cave. Nicholas Conard works at the University of Tubingen. He's convinced the seashell is a musical instrument. NICHOLAS CONARD: I'm super happy about it because it's kind of lonely having all these flutes that we've got from our sites and there's not too much to compare it to. GREENFIELDBOYCE: Because instruments made of materials like leather or wood don't last for tens of thousands of years. Daniel Adler is an archaeologist at the University of Connecticut. He says hearing music in a dark cave with echoes and dripping water and flickering lamps illuminating the brightly painted walls. . . DANIEL ADLER: That's all very, very evocative stuff that I think we can relate to as modern humans. GREENFIELDBOYCE: But what the music meant to people back then is a mystery. Nell Greenfieldboyce, NPR News.", "section": "Science", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-02-10-966254916": {"title": "U.S. Cyber Weapons Were Leaked And Are Now Being Used Against Us, Reporter Say : NPR", "url": "https://www.npr.org/2021/02/10/966254916/u-s-cyber-weapons-were-leaked-and-are-now-being-used-against-us-reporter-says", "author": "No author found", "published_date": "2021-02-10", "content": "TERRY GROSS, HOST:  This is FRESH AIR. I'm Terry Gross. The world is on the precipice of cyber catastrophe, and everything is vulnerable, including our government, our nuclear power plants, elections, power grid, hospitals and our cellphones. How we went from having the world's strongest cyber arsenal to becoming so vulnerable to cyberattack is the subject of my guest, Nicole Perlroth's new book, \"This Is How They Tell Me the World Ends: The Cyberweapons Arms Race. \"She's a cybersecurity reporter for The New York Times who has broken many stories. Her book describes how U. S. cyberweapons were hacked and used against us in ways we were unprepared for. Lately, she's been covering the latest massive cyberbreach in which an adversary, assumed to be Russia, hacked into federal agencies, private corporations and the U. S. infrastructure. The attack was launched in 2019 and went undetected until the fall in what was described in her reporting as among the greatest intelligence failures of modern times. Nicole Perlroth, welcome to FRESH AIR. Let's start with the recent massive data breach that was discovered in the fall that is still being investigated. Describe the extent of it. NICOLE PERLROTH: Well, the biggest problem is we really don't know the extent of it. We know that it came in through software that's used by some 18,000 agencies, corporations - and that actually they did not hack all 18,000. They sort of picked and chose their targets. But in the United States so far, what we know is that this thing has hit the Department of Homeland Security, the very agency charged with keeping us safe; the Treasury; the State Department; the Justice Department; the Department of Energy; some of the nuclear labs; the Centers for Disease Control. And the problem is that they were inside these systems for so long that the chances are very likely, if not guaranteed, that they planted backdoors. And so it - right now, we're just understanding that they were inside for this long. We're still trying to figure out where those backdoors are. And that could take months, if not years to get to the bottom of. GROSS: For listeners not familiar with the term backdoors, what are they? PERLROTH: Backdoors are just code that, in this case, we assume Russian hackers planted that just allow them a foothold to come back at another time. And they can be in the network. They could be stealing an administrator's password. They could have planted code in software in another application that lets them come in at a later date. GROSS: They may have hacked Black Start, which is the program for how the U. S. plans to restore power in the event of a catastrophic blackout. So that means if they did hack that, that if Russia causes a blackout, they could also prevent us from restoring the power grid. Do I have that right? PERLROTH: Yeah. So originally when this hack was discovered, one of the bright spots was that they believed that the hackers had not made their way into classified systems. But what I kept hearing from security researchers and people who worked at these agencies was just how much vulnerable data was outside these classified systems. And one of those things was Black Start. So Black Start's just a very technical document. And it's essentially a to-do list. If we were able to have a major power failure, it says, you know, we're going to go turn on the power here first, then we're going to move over here and do this. And with that document in hand, that could be very valuable for an adversary because it would essentially give them the perfect hit list to make sure that the power stayed off. GROSS: This story that you're describing about how many places were hacked by Russia, this is very dangerous. This is - this leaves us really vulnerable. It shows how vulnerable we are. And they could have done so much more. The story has been reported. You've been reporting on it. Should we be a lot more upset and worried than we are as a nation? PERLROTH: Well, one of the things that people have said to sort of caveat the extent of this breach is, well, you know, this was designed for espionage. It really looks like they were after emails and documents; they weren't looking to exact some kind of sabotage. But the problem with that argument is they can use the same exact access they have right now for other purposes. And they have done that, again, in Ukraine. Ukraine has sort of been Russian hackers' test kitchen for a lot of these attacks. And you know, the last time they pulled off a similar attack to this, where they came in through legitimate software, they used it to pull off an attack that essentially decimated all of the data in Ukraine on government networks, but also kept people from taking money out of ATMs, kept people from going to gas stations, kept shipments from reaching their recipients, kept paychecks from getting to their recipients and even at one point got into Chernobyl, the old nuclear site's radiation monitoring systems. So we know what they are capable of with this kind of access. And that is the worst-case scenario. But just sticking with what we know, which is they got into these systems for espionage, I mean, essentially what the Biden administration just inherited was federal IT networks it cannot trust. And that is a pretty difficult predicament to be in. GROSS: What has the speculation been about what Russia's motives are? PERLROTH: Well, I think right now what we assume they were doing was getting after emails and potentially trying to get as many sensitive documents as they could - so traditional espionage. Now, I should stop here and mention that the U. S. does these exact kind of operations, which makes it very difficult to try to calibrate a response. You know, how do you respond to an adversary doing to you what we have long done to them? But the question is, where have they planted these backdoors? When could they come back? How do we ensure they don't get into more sensitive systems, into classified systems? And, you know, another major target for this that we still really have only scratched the surface of is, did they get inside our critical infrastructure, too? We know that a lot of electrical utilities used the same SolarWinds software that allowed these hackers to get into our government agencies. So right now, when you talk to these utility companies, they are just ripping out their software, trying to understand if they were compromised, too. You know, what else touches their networks? Where else are they vulnerable? So it's been a big wake-up call, not just for governments, but for critical infrastructure operators, too. GROSS: The Russians got into our system in this hack through a cybersecurity company called SolarWinds. It's an IT management company. And SolarWinds products are used by the military, the Pentagon, the State Department, the executive office of the president, some telecommunication companies, even the National Security Agency. How did Russia use SolarWinds to hack all these systems? PERLROTH: What happened was these Russian hackers got into the build process at SolarWinds. This is the process whereby SolarWinds engineers create, test and roll out their software to customers. And so customers all over the world updated their software, just as we're supposed to do, with the latest SolarWinds software. But instead of getting SolarWinds software, what they got was what we assume to be a Russian backdoor. And once they got into these systems of interest, they moved around and planted new tools that would allow them backdoor access to these systems and allowed them to crawl into things like their Microsoft email, services, et cetera. GROSS: We are all told to use complicated passwords that aren't intuitive to protect our security. My understanding is that the password for SolarWinds was solarwinds123. PERLROTH: That's right. And we're learning a lot about SolarWinds. I think SolarWinds is learning a lot about SolarWinds right now. They actually have a new CEO who just started. But what we learned was, yes, their security was just not up to snuff. We learned that they had really basic passwords. We learned that they were warned as far back as two years before this attack began that if they didn't take their security more seriously, it could be catastrophic. Now, when I started calling up some of the victims of this attack, many of them didn't even know they used SolarWinds software until it came out that the company was breached and uses this Russian conduit. So what we were looking at really was a company that didn't have very good security but that was touching some of the most sensitive systems we have. I mean, this was used inside the Pentagon. The NSA used it. We know that the Treasury used it and all the other victims that are coming out, including our utility companies. And one of the things that also struck me was, you know, most of their software build operations were not in the United States anymore even, they were in Eastern Europe. Now, that's not to say Eastern Europe is fundamentally dangerous. But it's just interesting that only now, after the fact, are we learning that we had the software in most government IT systems built elsewhere that really didn't have good security practices in place. And now we're seeing the repercussions from that play out every day. GROSS: And what does it say that this breach was discovered not by our own intelligence community, but by a private cybersecurity company called FireEye? PERLROTH: Well, I think that's what makes this one of the biggest intelligence failures of our time. You know, what happened here was FireEye discovered that it had been hacked, and to its eternal credit, it came out with that right away. And as it started unwinding this attack on its own systems, it realized that one of the conduits to getting into FireEye's networks had been SolarWinds. And so it was able to basically alert Microsoft and all of these technology companies and the government that SolarWinds had essentially been used as a backdoor for this attack. GROSS: Do you think this does not speak well of our government cybersecurity protections? PERLROTH: It does not speak well to our government cybersecurity protections. I mean, we are one of the most advanced, if not the most advanced cyber superpower in the world. But we are also its most targeted and its most vulnerable because we are so virtualized here. And we have spent way more energy on offense - and by offense, I mean hacking others - than we have on doing the really grueling and hard work to put up smart defenses. And there's never been a time that that hasn't been more glaringly clear than what we're unwinding now with the SolarWinds attack. GROSS: Let me reintroduce you here. If you're just joining us, my guest is Nicole Perlroth, a cybersecurity journalist for The New York Times. Her new book is called \"This Is How They Tell Me The World Ends: The Cyberweapons Arms Race. \" We'll be right back after a break. This is FRESH AIR. (SOUNDBITE OF MUSIC)GROSS: This is FRESH AIR. Let's get back to my interview with Nicole Perlroth, a cybersecurity journalist for The New York Times. Her new book about the cyberweapons arms race is called \"This Is How They Tell Me The World Ends. \"Do you know anything about President Biden's plans to deal with cybersecurity and to come to some kind of agreement with Russia and other adversaries that we won't attack each other and control the other country's infrastructure and power grid? PERLROTH: So we know that Biden has made cybersecurity a top priority. We know he squeezed $10 billion in additional cybersecurity funding into his COVID recovery bill. We know that he has brought this up with Putin directly and their first phone call. We know he - there are new positions that were created from the latest defense bill. And he's brought in Ann Neuberger from the NSA to essentially debrief him on just how bad the threats from cyber vulnerabilities are and to try and come up with a real working plan here. But what we also know is that the United States has been very hesitant to sign on to any cyber treaty or even any norms that would prevent the United States from hacking into the infrastructure in other countries. And part of this is just that the United States for a long time has been the most advanced player in this space. So by signing on to any kind of agreement to not hack each other's infrastructure, I think the theory was that we would be handcuffing ourselves. But right now, the problem has gotten so bad. You know, we know Russia has hacked our grid. We know that they have gotten into the switches that control the nuclear plants and power plants. We know that Russian cyber criminals have locked up our hospitals. People have not been able to get chemo treatments because of attacks on hospitals, cyberattacks on hospitals. So the problem has gotten so bad that I think there may be an opportunity here to come up with new rules of the game to say maybe, OK, we won't agree to hack each other's critical infrastructure, but you cannot attack hospitals. You cannot attack the controls at our nuclear plants without some kind of repercussions here or some kind of international repercussions. So that might be a good place to start. But I would be very surprised if we came up with or agreed to some kind of treaty that held us back. And one of the things U. S. officials will say is, sure, we could agree to a treaty. But the fact is that here, when we do our own attacks, they're done inside Cyber Command at the Pentagon. In China and Russia and Iran, they outsource that work to contractors, to cybercriminals. And so even if those countries agreed not to pull off a grid attack, for instance, there's not much keeping these sort of lower-tier contractors and cybercriminals for doing those governments' dirty work for them. GROSS: That's very worrisome. There's also been a proliferation of ransomware attacks. Over 600 towns and cities in America have been held hostage by ransomware between 2019 and 2020. Do we know who's behind that? Is that an organized effort? Is it coming from Russia? PERLROTH: So most of it is coming from cybercriminals. There is one criminal group in particular that uses an infrastructure called TrickBot. And they'll sell access to other cybercriminals who use that as a conduit to pull off their attacks. And we know that in a lot of cases, their code is designed to avoid targets in Russia. So you can assume, you know, that that means many of the people pulling off these attacks are based in Russia. But beyond that, I mean, these are, for the most part, cybercriminals. What came to be a major concern going into the election with ransomware was that there is some fuzziness and has been for a very, very long time between Russia's cybercriminals and Russia's intelligence agencies. So, for instance, when Yahoo, the technology company, was breached by Russian hackers, we learned that essentially the attack was four people, two of whom were cybercriminals and then two of whom were Russian intelligence officials. And they essentially allowed Russia's cybercriminals to mine whatever they were going to do for profit, but then they also used their access to do things like try and spy on people who worked inside the White House. So there's been sort of this tacit agreement in Russia between cybercriminals and the state. And so even though a lot of these attacks and most of them definitely are cybercriminals, we worried that cybercriminals might be used to enable some kind of state activity on our election infrastructure going into 2020. But fortunately, that never happened. GROSS: Nicole, this week we learned hackers tried to poison the water supply of a town in Florida - Oldsmar, Fla. - by dramatically increasing the level of lye in the water in a water treatment plant. Now, the hack was detected before it did any damage, before it reached the drinking supply. But as we record this on Tuesday afternoon, February 9, we don't yet know who was responsible. It could be an act of terrorism. It could be a disaffected teenager. It could be a foreign adversary. But whoever it was, should we take this as a warning about how vulnerable we are? PERLROTH: I think that's just another wake-up call of several we've had recently, but this is the targets we worry about. You know, a small town's water treatment facility is not going to have the same security in place as a PG&E, for example, and are not going to be as resourced or have the budgets to protect their systems. In this case, it's a good sign that they were able to catch it. But I think it's just a wake-up call in general that a lot of these facilities allow contractors and engineers to get in, get remote access from miles away or across the country. And I think we need to start rethinking that access. Do we really want strangers being able to get into these systems from afar? And I think right now would be a good time to ask ourselves. And I think the answer is probably no. GROSS: I think this is the first hack of its kind that got as far as it did, even though it didn't get that far. Have there been a lot of other attempts to poison the water supply by hacking the water treatment plant? PERLROTH: There's only one that I know of. And it was in Israel at the beginning of the pandemic, right when they first issued their stay-at-home order. They accused hackers in Iran of getting into a water treatment facility in Israel. And they actually responded a month later with a disruptive cyberattack on an Iranian port. But this is really dangerous. You know, they increased the amount of lye in the water from 100 parts per million to 11,000 parts per million. So had it not been caught when it was - and it just so happened that there happened to be a software engineer sitting at his computer watching his cursor move around on his screen and then later watched someone go into these functions and upped the amount of chemical. Had that not happened, then we would have been looking at an attack that would have badly sickened a lot of people. GROSS: Let me reintroduce you here. If you're just joining us, my guest is Nicole Perlroth. She's a cybersecurity journalist for The New York Times and author of the new book, \"This Is How They Tell Me The World Ends. \" It's about the cyberweapons arms race. We'll be right back after we take a short break. I'm Terry Gross, and this is FRESH AIR. (SOUNDBITE OF WAYNE HORVITZ'S \"IN FIELDS THEY LAY\")GROSS: This is FRESH AIR. I'm Terry Gross. Let's get back to my interview with Nicole Perlroth, a cybersecurity journalist for The New York Times and author of the new book \"This Is How They Tell Me the World Ends. \" It's about the underground cyber arms industry and how the National Security Agency's own cyber arsenal got into the hands of our adversaries, everything from our government to our nuclear power plants, the power grid, our elections, private companies, hospitals, our cellphones. They're all vulnerable. She's been covering the latest massive cyber breach in which an adversary - assumed to be Russia - hacked into federal agencies, private corporations and U. S. infrastructure. One of our greatest strengths, our cyber weapons, has become one of our greatest vulnerabilities because those weapons have been stolen by hackers and by government hackers and used against us. What kinds of cyber weapons were stolen from us? PERLROTH: So back in 2016, a group - we still don't know who they are, but they call themselves the Shadow Brokers - started trickling out some of the NSA's tools. Now, some of these were ways into firewalls like Cisco's firewalls that we use to protect our networks. And then later in 2017, they really dropped what were essentially the NSA's crown jewels. What they dropped was a vulnerability in Microsoft software and the NSA's code to exploit it, which essentially allowed any government with that tool in its hand to get inside enemy networks and once inside sort of supercharge their code so they didn't have to go and attack each system manually. Essentially, the code allowed them to travel and automate their attack to exact mass destruction. Now, the NSA was using that tool for counterintelligence, for espionage. But once that tool was dribbled out online by the Shadow Brokers, anyone could essentially pick it up and bolt it on to their own attack, which is exactly what happened. So North Korea first picked it up. They bolted it on to some ransomware. They sent it around the world. It locked up hospitals in the U. K. It locked up law firms and companies all over the United States and the world, universities. But they'd actually made some sloppy mistakes in their code. And a hacker was able to essentially neutralize the attack pretty quickly. And then a month later, Russia essentially used the same tool, along with others, in an attack on Ukraine. But it also hit any company or business that even had a single employee in Ukraine. And that allowed that attack to spread as far as Tasmania to chocolate Cadbury factories there, to FedEx, to Pfizer, to Merck, which essentially saw its supplies of Gardasil vaccine eviscerated in that cyberattack. And they had to tap into emergency supplies at the CDC. It was truly the most destructive attack, cyberattack, in history. It cost victims - I think it came to a total of $10 billion. And then we started to see sort of the longer tail of these tools show up in attacks that cybercriminals were conducting on American towns, cities, universities. Now, once those attacks happened, you know, anyone with a remotely capable IT administrator should have patched their systems for these holes and would have been able to mitigate these attacks. And so we've seen these tools pop up less and less, although they definitely are, you know, common tools that are tried in rudimentary cybercrime, cybercriminal attacks. But what that showed us was, you know, we were basically hoarding these holes in Microsoft software, which is some of the most widely used software in the world, for the purposes of our own cyber espionage programs without meaningful consideration for what might happen if that same hole was hacked, if it was discovered by someone else. And when that happened, we could see exactly what what the damages were, what the trade-off was from holding on to a vulnerability like that for more than five years. GROSS: So this leads to a larger controversy here in the U. S. If you're a U. S. intelligence agency, including the National Security Agency, and you find a vulnerability in Microsoft, do you inform Microsoft so they can fix that vulnerability or do you just use that vulnerability to allow U. S. national intelligence to penetrate Microsoft's clients and get into those systems? PERLROTH: So this is the big moral hazard in government today. This is the one that was the reason I wrote this book because back in the Cold War, we were all using different technology. You know, Russia would hack into our typewriters. We would hack into their systems. If we found a flaw in Russian technology, no harm, no foul to Americans. But thanks to globalization, we're all now using the same technologies. And Microsoft is a great example because, you're right, it's in our systems whether we know it or not. So when the American government discovers a major hole in Microsoft software, it has a decision to make. It can use that hole to attack Microsoft's customers all over the world. Or it can tell Microsoft, hey, you have a problem, you need to patch this and you need to roll it out to customers as quickly as possible. And what we've learned is that the United States government was making the calculation that it would actually hold on to a critical vulnerability in Microsoft software for more than five years so that it could use it to spy on terrorists and adversaries and I don't know who else. But the problem is, once that got out, we could see just how dangerous that same vulnerability is in adversaries' hands. And, you know, it really is worth just reminding people that once that vulnerability was discovered and used later by Russia, you know, they used it to eviscerate patient records. Doctors couldn't access patients' records at hospitals in the United States. You know, companies like Merck were totally sidelined and in ways are still recovering from that attack. And that was almost four years ago. So, you know, these have real, real blowback potential for Americans and for American businesses. And in that case, you know, they're basically collateral damage when we hold on to these vulnerabilities and then they get discovered or hacked by an adversary. So what we've been told is that the government has a process for this decision-making. It used to be called NOBUS at the NSA, which stood for nobody but us. If the NSA found a vulnerability that they believed only they had the sophistication to exploit, they held on to it. If it was more of the low-hanging fruit, they turned it over to the technology companies. So under George W. Bush, the government essentially formalized NOBUS into a process where they would invite representatives in from various government agencies who would have a stake in this. And when they discovered a vulnerability, let's say, in Microsoft software, representatives from these various U. S. government agencies would sit around a table and they would debate the merits of keeping the vulnerability for their own espionage programs or turning it over to Microsoft to patch it. And when I interviewed Michael Daniel, who oversaw this process under Obama, he said it's not pretty. Sometimes there's blood left on the table. And the reason for this is that, you know, they say that if they find a vulnerability in something like Huawei - OK, this is a technology that is Chinese. It's used by a lot of American adversaries. It's used in a lot of terrorist safe havens. If they find a vulnerability in Huawei, they might keep that because not a lot of American customers and businesses use Huawei software yet. But if they find a vulnerability in Microsoft, that changes the calculation. And they told me that it would bias them towards disclosure, towards giving that vulnerability to Microsoft, tipping them off to it so they could roll out a patch to their customers. And what we learned with these attacks in 2017 was that that calculation, you know, the criteria that they had long told us they used to decide whether to keep or turn over a vulnerability, clearly wasn't working in this case because what was used in those attacks was a very glaring vulnerability in Microsoft software that could easily blow back on Americans and American businesses. GROSS: Have American tech companies fought back about that? PERLROTH: They have, and the companies that really have been at the forefront of this are Microsoft, Apple and Google. Microsoft's president, Brad Smith, has been out there very publicly saying we should not be holding on to these vulnerabilities, that we need the cyber equivalent of a Geneva Convention to establish norms for who we will and won't hack and how we will and will not go about those hacks. Apple's Tim Cook was very vocal about a situation when the FBI back in 2015 wanted Apple to create a backdoor so it could get into the iPhone of one of the shooters in the San Bernardino shootings. And Tim Cook really pushed back on that. And eventually the FBI said, well, actually, we don't need Apple's help. We have found an outsider who was able to give us this backdoor anyway. We paid him or her more than a million dollars. And so Tim Cook and Apple have been pushing the government to essentially, you know, disclose that vulnerability, whatever it is. And then at Google, Google has really designated teams of its own hackers to try and go out there and pore through some of the most widely used software we rely on to find these holes that governments could exploit so that they can help get them fixed before they can be used for espionage or mayhem. GROSS: Let me reintroduce you here. If you're just joining us, my guest is Nicole Perlroth, a cybersecurity journalist for The New York Times. Her new book about the cyberwars is called \"This Is How They Tell Me The World Ends. \" We'll be right back. This is FRESH AIR. (SOUNDBITE OF JOAN JEANRENAUD'S \"AXIS\")GROSS: This is FRESH AIR. Let's get back to my interview with Nicole Perlroth, a cybersecurity reporter for The New York Times. Her new book about the cyber weapons arms race is called \"This Is How They Tell Me The World Ends. \" We've been talking about cybersecurity vulnerabilities that can be exploited either by our intelligence agencies or by criminals or foreign adversaries. These vulnerabilities are called zero days. Can you expand on what a zero-day is? PERLROTH: So a zero-day is just a hole in software that hasn't been discovered yet. And, you know, once these zero-days are discovered, they get patched and a patch gets rolled out via your software updates. If everyone's listening to this, please run your software updates. But if a government discovers this hole first, then it can be used for espionage. It can be used for cyber weapons. And so for a long time, we've recognized the sort of espionage and battlefield potential of a zero-day. And starting in the 1990s, I learned through the process of reporting out this book that the U. S. government was actually actively paying hackers and defense contractors to find these zero-days, to write them into, you know, reliable exploits that they could use to spy on our adversaries or to essentially drop a cyber weapon into their systems if we needed to one day. GROSS: Well, part of your book is about the whole underground market that has grown around selling and buying these vulnerabilities, these zero-day vulnerabilities. Can you describe a little bit the underground market that buys and sells these vulnerabilities, giving access to systems ranging from infrastructure to Microsoft and lots of other places? PERLROTH: Yeah. So, essentially, hackers can find a zero-day in a critical system like Microsoft or maybe your Apple iPhone software. And they have a decision. They can give that vulnerability to Microsoft or Apple, which, these days, will pay them small bounties for turning that over. Or they can fetch much higher rates by giving that zero day to a digital arms broker, essentially, or by selling it directly to a government, because governments recognize that these zero days have tremendous espionage potential. They're willing to pay as much as 2 million to $3 million these days for a major zero day in, let's say, your iPhone or Android phone software. And it's not just the United States. Although, the United States was the first government to, essentially, start paying hackers to turn over these zero days and then stay very quiet about them by forcing them to sign nondisclosure agreements. And later, many of these programs were classified. But over the last 10 years, this is not just a U. S. government market anymore. For a long time, our Western allies recognized the potential of a zero day as well for their own espionage operations and were paying hackers for these tools. And then, more recently, oppressive regimes like the United Arab Emirates and Saudi Arabia, who are technically allies of ours, recognized the power of a zero day to monitor the iPhone communications of their own people and of their critics all over the world. And so they started paying top dollar for these zero days. These days, it's actually not the United States. It's a broker for the United Arab Emirates and Saudi Arabia that pays top dollar for a way to get into your iPhone. So this market's really drifted outside U. S. control or even, you know, the control of our Western allies. I went down to Argentina for the book and met with people who sell zero days there to governments. And I asked a really stupid question of someone who was in the scene. I said, you know, so will you only sell these zero days to good Western governments? And he just laughed at me and said, Nicole, you know, the last time I checked, the country that bombed another country into oblivion wasn't China or Iran. We don't think of the United States as a good Western government. Someone comes here with a big bag of cash from Ghana, a big bag of cash from Russia or Iran or the United States. We just weigh the size of the bag of cash. And we'll sell our zero day to them. So - you know, we no longer have any control of this market, which makes these debates about whether to fix the vulnerabilities we are finding that much more critical today. GROSS: So one of the implications of this, I think, is that a government doesn't need to have, like, a brilliant cybersecurity agency in order to find vulnerabilities in their adversary's systems. All the government needs to do - and this includes really authoritarian governments. All they need to do is have enough cash to buy the code from the hackers who have the code. And then they could use those vulnerabilities to whatever purposes they want. PERLROTH: That's right. So they can buy their way into these capabilities. And the market has come to meet their demand. And then there's another thing here, which is they're not just paying hackers to sell these vulnerabilities. They're actually recruiting American hackers overseas to Abu Dhabi to do some of their espionage and surveillance work in some cases. And that was one of the big, eye-opening things I learned in the course of doing this book is that, you know, American contractors were luring NSA hackers out of the NSA, giving them jobs in Abu Dhabi, where originally they were told, OK, you're going to be monitoring terror cells on behalf of the UAE. But very quickly, their assignments changed to, actually, can you get into Qatar's systems? We've heard that they're funding the Muslim Brotherhood. Can you find out if that's true? And so they would - these are American, former NSA hackers who then were turned on an ally, because Qatar is technically also a close U. S. ally. And they would monitor their systems. And even though they didn't find any evidence that Qatar was funding the Muslim Brotherhood, the requests kept coming until, eventually - in one case, I learned that they were inside Qatari royals' email networks as Qataris were trying to coordinate a trip with Michelle Obama, who, while she was in office, was planning a trip to Qatar in 2015. And every last email exchange from Michelle Obama was being read by former NSA hackers stationed in Abu Dhabi. So it's not just the tools that we've lost control of, but the tradecraft, too. GROSS: If you're just joining us, my guest is Nicole Perlroth, a cybersecurity journalist for The New York Times. Her new book about the cyber weapons arms race is called \"This Is How They Tell Me The World Ends. \" We'll talk more after we take a short break. This is FRESH AIR. (SOUNDBITE OF SUSAN ALCORN QUINTET'S \"NORTHEAST RISING SUN\")GROSS: This is FRESH AIR. Let's get back to my interview with Nicole Perlroth, a cybersecurity journalist for The New York Times. Her new book about the cyber weapons arms race is called \"This Is How They Tell Me The World Ends. \"I want to read a sentence from your bio on the book jacket. It says, (reading) Perlroth lives with her family in the Bay Area but increasingly prefers life off the grid in their cabin in the woods. (Laughter) So you're speaking to us from your cabin. Obviously, you have some kind of Internet connection. How off the grid are you in your cabin in the woods? PERLROTH: So it's a family cabin of ours. And there's no smart fridges here. There's no Alexa. There's - you know, our wireless system is really poor. And there's no baby monitors here either. And that's not the case at my home in the Bay Area. And so I ended up just writing a lot of the book up here just because it was a peaceful place to get away from my 2-year-old. But also, as I started to look around, I just felt a lot more safe (laughter) here. As I was sort of just diving into the vulnerabilities of our everyday software that we rely on, I realized that I don't have a lot of software where I'm sitting right now in this cabin. And so it just started to feel a little bit more safe up here. GROSS: Yeah. You mentioned baby monitors. The new thing is - well, not so new anymore - the Internet of Things, where, you know, our refrigerators and coffeemakers and baby monitors and cameras outside our doors and other security measures, they're all connected to the Internet, which makes us so eminently hackable. PERLROTH: Right. And, you know, when I first started covering this beat, everyone was warning me, oh, you know, worry about webcams and worry about this. And, yes, I have a piece of tape over my webcam. But what has sadly happened over the last 10 years is I've covered an attack that's hit every one of these things. One of my favorites was there was an attack at the U. S. Chamber of Commerce where China had gotten into their systems. The FBI had come in, done a big sweep, figured that they had eradicated China from their systems. And next thing they knew, a couple months later, one of their printers just started printing out reams of Chinese characters. But the one that always stuck with me was there was a thermostat in their corporate apartment in D. C. And it had been acting funny. And when they did a little sleuthing, they found out that it had been communicating with a Chinese IP address. China was in the thermostat in their corporate apartment. And, you know, there's just been cases - other cases where there was one where we confirmed that a UAE contractor was spying on the baby monitor of a activist in the UAE. So these are no longer, like, hypothetical scenarios. You're not a tinfoil hat person to be suspicious of some of these devices. They have and will continue to be used for espionage and surveillance. And because I cover these things all the time, I just feel much safer in my cabin in the woods. GROSS: Well, Nicole Perlroth, thank you so much for talking with us. This has been very informative and, also, very chilling. Is part of your goal to be chilling, to say, hey, wake up, everybody, this is what's going on? PERLROTH: Yes, it is. Everything that can be intercepted here already has. You know, our intellectual property, our power grid, our nuclear plants, our hospitals have been taken hostage with ransomware. We are really in a very precarious place. But we haven't had that calamitous attack yet. And so the goal with writing this book and by putting it out now is this is my own sort of attempt at a wakeup call to say, you know, we really need to make a decision as a society and inside government to stop leaving ourselves vulnerable. You know, we have to take our own security seriously. We also have to stop leaving gaping holes in software that could be used by adversaries to pull off some of these attacks. And so if my book is chilling, it's because I'd rather people read this and be scared and really think deeply about how they're securing themselves than waiting for that big wakeup call attack to happen. GROSS: Well, thank you for your reporting. And thank you for this interview. I really appreciate it. PERLROTH: Thanks for having me, Terry. It's been an honor. GROSS: Nicole Perlroth is a cybersecurity journalist at The New York Times. Her new book is called \"This Is How They Tell Me The World Ends. \" Tomorrow on FRESH AIR, my guest will be Rashida Jones. She stars with Bill Murray in the film \"On The Rocks,\" which was just nominated for a Critic's Choice Award for Best Comedy. It was written and directed by Sofia Coppola and draws on Coppola's relationship with her famous father, Francis Ford Coppola. Jones directed a documentary about her father, Quincy Jones. I hope you'll join us. (SOUNDBITE OF QUINCY JONES SONG, \"KILLER JOE\")GROSS: FRESH AIR's executive producer is Danny Miller. Our technical director and engineer is Audrey Bentham. Our interviews and reviews are produced and edited by Amy Salit, Phyllis Myers, Sam Briger, Lauren Krenzel, Heidi Saman, Therese Madden, Ann Marie Baldonado, Thea Chaloner, Seth Kelley and Kayla Lattimore. Our associate producer of digital media is Molly Seavy-Nesper. Roberta Shorrock directs the show. I'm Terry Gross. (SOUNDBITE OF QUINCY JONES SONG, \"KILLER JOE\") TERRY GROSS, HOST:   This is FRESH AIR. I'm Terry Gross. The world is on the precipice of cyber catastrophe, and everything is vulnerable, including our government, our nuclear power plants, elections, power grid, hospitals and our cellphones. How we went from having the world's strongest cyber arsenal to becoming so vulnerable to cyberattack is the subject of my guest, Nicole Perlroth's new book, \"This Is How They Tell Me the World Ends: The Cyberweapons Arms Race. \" She's a cybersecurity reporter for The New York Times who has broken many stories. Her book describes how U. S. cyberweapons were hacked and used against us in ways we were unprepared for. Lately, she's been covering the latest massive cyberbreach in which an adversary, assumed to be Russia, hacked into federal agencies, private corporations and the U. S. infrastructure. The attack was launched in 2019 and went undetected until the fall in what was described in her reporting as among the greatest intelligence failures of modern times. Nicole Perlroth, welcome to FRESH AIR. Let's start with the recent massive data breach that was discovered in the fall that is still being investigated. Describe the extent of it. NICOLE PERLROTH: Well, the biggest problem is we really don't know the extent of it. We know that it came in through software that's used by some 18,000 agencies, corporations - and that actually they did not hack all 18,000. They sort of picked and chose their targets. But in the United States so far, what we know is that this thing has hit the Department of Homeland Security, the very agency charged with keeping us safe; the Treasury; the State Department; the Justice Department; the Department of Energy; some of the nuclear labs; the Centers for Disease Control. And the problem is that they were inside these systems for so long that the chances are very likely, if not guaranteed, that they planted backdoors. And so it - right now, we're just understanding that they were inside for this long. We're still trying to figure out where those backdoors are. And that could take months, if not years to get to the bottom of. GROSS: For listeners not familiar with the term backdoors, what are they? PERLROTH: Backdoors are just code that, in this case, we assume Russian hackers planted that just allow them a foothold to come back at another time. And they can be in the network. They could be stealing an administrator's password. They could have planted code in software in another application that lets them come in at a later date. GROSS: They may have hacked Black Start, which is the program for how the U. S. plans to restore power in the event of a catastrophic blackout. So that means if they did hack that, that if Russia causes a blackout, they could also prevent us from restoring the power grid. Do I have that right? PERLROTH: Yeah. So originally when this hack was discovered, one of the bright spots was that they believed that the hackers had not made their way into classified systems. But what I kept hearing from security researchers and people who worked at these agencies was just how much vulnerable data was outside these classified systems. And one of those things was Black Start. So Black Start's just a very technical document. And it's essentially a to-do list. If we were able to have a major power failure, it says, you know, we're going to go turn on the power here first, then we're going to move over here and do this. And with that document in hand, that could be very valuable for an adversary because it would essentially give them the perfect hit list to make sure that the power stayed off. GROSS: This story that you're describing about how many places were hacked by Russia, this is very dangerous. This is - this leaves us really vulnerable. It shows how vulnerable we are. And they could have done so much more. The story has been reported. You've been reporting on it. Should we be a lot more upset and worried than we are as a nation? PERLROTH: Well, one of the things that people have said to sort of caveat the extent of this breach is, well, you know, this was designed for espionage. It really looks like they were after emails and documents; they weren't looking to exact some kind of sabotage. But the problem with that argument is they can use the same exact access they have right now for other purposes. And they have done that, again, in Ukraine. Ukraine has sort of been Russian hackers' test kitchen for a lot of these attacks. And you know, the last time they pulled off a similar attack to this, where they came in through legitimate software, they used it to pull off an attack that essentially decimated all of the data in Ukraine on government networks, but also kept people from taking money out of ATMs, kept people from going to gas stations, kept shipments from reaching their recipients, kept paychecks from getting to their recipients and even at one point got into Chernobyl, the old nuclear site's radiation monitoring systems. So we know what they are capable of with this kind of access. And that is the worst-case scenario. But just sticking with what we know, which is they got into these systems for espionage, I mean, essentially what the Biden administration just inherited was federal IT networks it cannot trust. And that is a pretty difficult predicament to be in. GROSS: What has the speculation been about what Russia's motives are? PERLROTH: Well, I think right now what we assume they were doing was getting after emails and potentially trying to get as many sensitive documents as they could - so traditional espionage. Now, I should stop here and mention that the U. S. does these exact kind of operations, which makes it very difficult to try to calibrate a response. You know, how do you respond to an adversary doing to you what we have long done to them? But the question is, where have they planted these backdoors? When could they come back? How do we ensure they don't get into more sensitive systems, into classified systems? And, you know, another major target for this that we still really have only scratched the surface of is, did they get inside our critical infrastructure, too? We know that a lot of electrical utilities used the same SolarWinds software that allowed these hackers to get into our government agencies. So right now, when you talk to these utility companies, they are just ripping out their software, trying to understand if they were compromised, too. You know, what else touches their networks? Where else are they vulnerable? So it's been a big wake-up call, not just for governments, but for critical infrastructure operators, too. GROSS: The Russians got into our system in this hack through a cybersecurity company called SolarWinds. It's an IT management company. And SolarWinds products are used by the military, the Pentagon, the State Department, the executive office of the president, some telecommunication companies, even the National Security Agency. How did Russia use SolarWinds to hack all these systems? PERLROTH: What happened was these Russian hackers got into the build process at SolarWinds. This is the process whereby SolarWinds engineers create, test and roll out their software to customers. And so customers all over the world updated their software, just as we're supposed to do, with the latest SolarWinds software. But instead of getting SolarWinds software, what they got was what we assume to be a Russian backdoor. And once they got into these systems of interest, they moved around and planted new tools that would allow them backdoor access to these systems and allowed them to crawl into things like their Microsoft email, services, et cetera. GROSS: We are all told to use complicated passwords that aren't intuitive to protect our security. My understanding is that the password for SolarWinds was solarwinds123. PERLROTH: That's right. And we're learning a lot about SolarWinds. I think SolarWinds is learning a lot about SolarWinds right now. They actually have a new CEO who just started. But what we learned was, yes, their security was just not up to snuff. We learned that they had really basic passwords. We learned that they were warned as far back as two years before this attack began that if they didn't take their security more seriously, it could be catastrophic. Now, when I started calling up some of the victims of this attack, many of them didn't even know they used SolarWinds software until it came out that the company was breached and uses this Russian conduit. So what we were looking at really was a company that didn't have very good security but that was touching some of the most sensitive systems we have. I mean, this was used inside the Pentagon. The NSA used it. We know that the Treasury used it and all the other victims that are coming out, including our utility companies. And one of the things that also struck me was, you know, most of their software build operations were not in the United States anymore even, they were in Eastern Europe. Now, that's not to say Eastern Europe is fundamentally dangerous. But it's just interesting that only now, after the fact, are we learning that we had the software in most government IT systems built elsewhere that really didn't have good security practices in place. And now we're seeing the repercussions from that play out every day. GROSS: And what does it say that this breach was discovered not by our own intelligence community, but by a private cybersecurity company called FireEye? PERLROTH: Well, I think that's what makes this one of the biggest intelligence failures of our time. You know, what happened here was FireEye discovered that it had been hacked, and to its eternal credit, it came out with that right away. And as it started unwinding this attack on its own systems, it realized that one of the conduits to getting into FireEye's networks had been SolarWinds. And so it was able to basically alert Microsoft and all of these technology companies and the government that SolarWinds had essentially been used as a backdoor for this attack. GROSS: Do you think this does not speak well of our government cybersecurity protections? PERLROTH: It does not speak well to our government cybersecurity protections. I mean, we are one of the most advanced, if not the most advanced cyber superpower in the world. But we are also its most targeted and its most vulnerable because we are so virtualized here. And we have spent way more energy on offense - and by offense, I mean hacking others - than we have on doing the really grueling and hard work to put up smart defenses. And there's never been a time that that hasn't been more glaringly clear than what we're unwinding now with the SolarWinds attack. GROSS: Let me reintroduce you here. If you're just joining us, my guest is Nicole Perlroth, a cybersecurity journalist for The New York Times. Her new book is called \"This Is How They Tell Me The World Ends: The Cyberweapons Arms Race. \" We'll be right back after a break. This is FRESH AIR. (SOUNDBITE OF MUSIC) GROSS: This is FRESH AIR. Let's get back to my interview with Nicole Perlroth, a cybersecurity journalist for The New York Times. Her new book about the cyberweapons arms race is called \"This Is How They Tell Me The World Ends. \" Do you know anything about President Biden's plans to deal with cybersecurity and to come to some kind of agreement with Russia and other adversaries that we won't attack each other and control the other country's infrastructure and power grid? PERLROTH: So we know that Biden has made cybersecurity a top priority. We know he squeezed $10 billion in additional cybersecurity funding into his COVID recovery bill. We know that he has brought this up with Putin directly and their first phone call. We know he - there are new positions that were created from the latest defense bill. And he's brought in Ann Neuberger from the NSA to essentially debrief him on just how bad the threats from cyber vulnerabilities are and to try and come up with a real working plan here. But what we also know is that the United States has been very hesitant to sign on to any cyber treaty or even any norms that would prevent the United States from hacking into the infrastructure in other countries. And part of this is just that the United States for a long time has been the most advanced player in this space. So by signing on to any kind of agreement to not hack each other's infrastructure, I think the theory was that we would be handcuffing ourselves. But right now, the problem has gotten so bad. You know, we know Russia has hacked our grid. We know that they have gotten into the switches that control the nuclear plants and power plants. We know that Russian cyber criminals have locked up our hospitals. People have not been able to get chemo treatments because of attacks on hospitals, cyberattacks on hospitals. So the problem has gotten so bad that I think there may be an opportunity here to come up with new rules of the game to say maybe, OK, we won't agree to hack each other's critical infrastructure, but you cannot attack hospitals. You cannot attack the controls at our nuclear plants without some kind of repercussions here or some kind of international repercussions. So that might be a good place to start. But I would be very surprised if we came up with or agreed to some kind of treaty that held us back. And one of the things U. S. officials will say is, sure, we could agree to a treaty. But the fact is that here, when we do our own attacks, they're done inside Cyber Command at the Pentagon. In China and Russia and Iran, they outsource that work to contractors, to cybercriminals. And so even if those countries agreed not to pull off a grid attack, for instance, there's not much keeping these sort of lower-tier contractors and cybercriminals for doing those governments' dirty work for them. GROSS: That's very worrisome. There's also been a proliferation of ransomware attacks. Over 600 towns and cities in America have been held hostage by ransomware between 2019 and 2020. Do we know who's behind that? Is that an organized effort? Is it coming from Russia? PERLROTH: So most of it is coming from cybercriminals. There is one criminal group in particular that uses an infrastructure called TrickBot. And they'll sell access to other cybercriminals who use that as a conduit to pull off their attacks. And we know that in a lot of cases, their code is designed to avoid targets in Russia. So you can assume, you know, that that means many of the people pulling off these attacks are based in Russia. But beyond that, I mean, these are, for the most part, cybercriminals. What came to be a major concern going into the election with ransomware was that there is some fuzziness and has been for a very, very long time between Russia's cybercriminals and Russia's intelligence agencies. So, for instance, when Yahoo, the technology company, was breached by Russian hackers, we learned that essentially the attack was four people, two of whom were cybercriminals and then two of whom were Russian intelligence officials. And they essentially allowed Russia's cybercriminals to mine whatever they were going to do for profit, but then they also used their access to do things like try and spy on people who worked inside the White House. So there's been sort of this tacit agreement in Russia between cybercriminals and the state. And so even though a lot of these attacks and most of them definitely are cybercriminals, we worried that cybercriminals might be used to enable some kind of state activity on our election infrastructure going into 2020. But fortunately, that never happened. GROSS: Nicole, this week we learned hackers tried to poison the water supply of a town in Florida - Oldsmar, Fla. - by dramatically increasing the level of lye in the water in a water treatment plant. Now, the hack was detected before it did any damage, before it reached the drinking supply. But as we record this on Tuesday afternoon, February 9, we don't yet know who was responsible. It could be an act of terrorism. It could be a disaffected teenager. It could be a foreign adversary. But whoever it was, should we take this as a warning about how vulnerable we are? PERLROTH: I think that's just another wake-up call of several we've had recently, but this is the targets we worry about. You know, a small town's water treatment facility is not going to have the same security in place as a PG&E, for example, and are not going to be as resourced or have the budgets to protect their systems. In this case, it's a good sign that they were able to catch it. But I think it's just a wake-up call in general that a lot of these facilities allow contractors and engineers to get in, get remote access from miles away or across the country. And I think we need to start rethinking that access. Do we really want strangers being able to get into these systems from afar? And I think right now would be a good time to ask ourselves. And I think the answer is probably no. GROSS: I think this is the first hack of its kind that got as far as it did, even though it didn't get that far. Have there been a lot of other attempts to poison the water supply by hacking the water treatment plant? PERLROTH: There's only one that I know of. And it was in Israel at the beginning of the pandemic, right when they first issued their stay-at-home order. They accused hackers in Iran of getting into a water treatment facility in Israel. And they actually responded a month later with a disruptive cyberattack on an Iranian port. But this is really dangerous. You know, they increased the amount of lye in the water from 100 parts per million to 11,000 parts per million. So had it not been caught when it was - and it just so happened that there happened to be a software engineer sitting at his computer watching his cursor move around on his screen and then later watched someone go into these functions and upped the amount of chemical. Had that not happened, then we would have been looking at an attack that would have badly sickened a lot of people. GROSS: Let me reintroduce you here. If you're just joining us, my guest is Nicole Perlroth. She's a cybersecurity journalist for The New York Times and author of the new book, \"This Is How They Tell Me The World Ends. \" It's about the cyberweapons arms race. We'll be right back after we take a short break. I'm Terry Gross, and this is FRESH AIR. (SOUNDBITE OF WAYNE HORVITZ'S \"IN FIELDS THEY LAY\") GROSS: This is FRESH AIR. I'm Terry Gross. Let's get back to my interview with Nicole Perlroth, a cybersecurity journalist for The New York Times and author of the new book \"This Is How They Tell Me the World Ends. \" It's about the underground cyber arms industry and how the National Security Agency's own cyber arsenal got into the hands of our adversaries, everything from our government to our nuclear power plants, the power grid, our elections, private companies, hospitals, our cellphones. They're all vulnerable. She's been covering the latest massive cyber breach in which an adversary - assumed to be Russia - hacked into federal agencies, private corporations and U. S. infrastructure. One of our greatest strengths, our cyber weapons, has become one of our greatest vulnerabilities because those weapons have been stolen by hackers and by government hackers and used against us. What kinds of cyber weapons were stolen from us? PERLROTH: So back in 2016, a group - we still don't know who they are, but they call themselves the Shadow Brokers - started trickling out some of the NSA's tools. Now, some of these were ways into firewalls like Cisco's firewalls that we use to protect our networks. And then later in 2017, they really dropped what were essentially the NSA's crown jewels. What they dropped was a vulnerability in Microsoft software and the NSA's code to exploit it, which essentially allowed any government with that tool in its hand to get inside enemy networks and once inside sort of supercharge their code so they didn't have to go and attack each system manually. Essentially, the code allowed them to travel and automate their attack to exact mass destruction. Now, the NSA was using that tool for counterintelligence, for espionage. But once that tool was dribbled out online by the Shadow Brokers, anyone could essentially pick it up and bolt it on to their own attack, which is exactly what happened. So North Korea first picked it up. They bolted it on to some ransomware. They sent it around the world. It locked up hospitals in the U. K. It locked up law firms and companies all over the United States and the world, universities. But they'd actually made some sloppy mistakes in their code. And a hacker was able to essentially neutralize the attack pretty quickly. And then a month later, Russia essentially used the same tool, along with others, in an attack on Ukraine. But it also hit any company or business that even had a single employee in Ukraine. And that allowed that attack to spread as far as Tasmania to chocolate Cadbury factories there, to FedEx, to Pfizer, to Merck, which essentially saw its supplies of Gardasil vaccine eviscerated in that cyberattack. And they had to tap into emergency supplies at the CDC. It was truly the most destructive attack, cyberattack, in history. It cost victims - I think it came to a total of $10 billion. And then we started to see sort of the longer tail of these tools show up in attacks that cybercriminals were conducting on American towns, cities, universities. Now, once those attacks happened, you know, anyone with a remotely capable IT administrator should have patched their systems for these holes and would have been able to mitigate these attacks. And so we've seen these tools pop up less and less, although they definitely are, you know, common tools that are tried in rudimentary cybercrime, cybercriminal attacks. But what that showed us was, you know, we were basically hoarding these holes in Microsoft software, which is some of the most widely used software in the world, for the purposes of our own cyber espionage programs without meaningful consideration for what might happen if that same hole was hacked, if it was discovered by someone else. And when that happened, we could see exactly what what the damages were, what the trade-off was from holding on to a vulnerability like that for more than five years. GROSS: So this leads to a larger controversy here in the U. S. If you're a U. S. intelligence agency, including the National Security Agency, and you find a vulnerability in Microsoft, do you inform Microsoft so they can fix that vulnerability or do you just use that vulnerability to allow U. S. national intelligence to penetrate Microsoft's clients and get into those systems? PERLROTH: So this is the big moral hazard in government today. This is the one that was the reason I wrote this book because back in the Cold War, we were all using different technology. You know, Russia would hack into our typewriters. We would hack into their systems. If we found a flaw in Russian technology, no harm, no foul to Americans. But thanks to globalization, we're all now using the same technologies. And Microsoft is a great example because, you're right, it's in our systems whether we know it or not. So when the American government discovers a major hole in Microsoft software, it has a decision to make. It can use that hole to attack Microsoft's customers all over the world. Or it can tell Microsoft, hey, you have a problem, you need to patch this and you need to roll it out to customers as quickly as possible. And what we've learned is that the United States government was making the calculation that it would actually hold on to a critical vulnerability in Microsoft software for more than five years so that it could use it to spy on terrorists and adversaries and I don't know who else. But the problem is, once that got out, we could see just how dangerous that same vulnerability is in adversaries' hands. And, you know, it really is worth just reminding people that once that vulnerability was discovered and used later by Russia, you know, they used it to eviscerate patient records. Doctors couldn't access patients' records at hospitals in the United States. You know, companies like Merck were totally sidelined and in ways are still recovering from that attack. And that was almost four years ago. So, you know, these have real, real blowback potential for Americans and for American businesses. And in that case, you know, they're basically collateral damage when we hold on to these vulnerabilities and then they get discovered or hacked by an adversary. So what we've been told is that the government has a process for this decision-making. It used to be called NOBUS at the NSA, which stood for nobody but us. If the NSA found a vulnerability that they believed only they had the sophistication to exploit, they held on to it. If it was more of the low-hanging fruit, they turned it over to the technology companies. So under George W. Bush, the government essentially formalized NOBUS into a process where they would invite representatives in from various government agencies who would have a stake in this. And when they discovered a vulnerability, let's say, in Microsoft software, representatives from these various U. S. government agencies would sit around a table and they would debate the merits of keeping the vulnerability for their own espionage programs or turning it over to Microsoft to patch it. And when I interviewed Michael Daniel, who oversaw this process under Obama, he said it's not pretty. Sometimes there's blood left on the table. And the reason for this is that, you know, they say that if they find a vulnerability in something like Huawei - OK, this is a technology that is Chinese. It's used by a lot of American adversaries. It's used in a lot of terrorist safe havens. If they find a vulnerability in Huawei, they might keep that because not a lot of American customers and businesses use Huawei software yet. But if they find a vulnerability in Microsoft, that changes the calculation. And they told me that it would bias them towards disclosure, towards giving that vulnerability to Microsoft, tipping them off to it so they could roll out a patch to their customers. And what we learned with these attacks in 2017 was that that calculation, you know, the criteria that they had long told us they used to decide whether to keep or turn over a vulnerability, clearly wasn't working in this case because what was used in those attacks was a very glaring vulnerability in Microsoft software that could easily blow back on Americans and American businesses. GROSS: Have American tech companies fought back about that? PERLROTH: They have, and the companies that really have been at the forefront of this are Microsoft, Apple and Google. Microsoft's president, Brad Smith, has been out there very publicly saying we should not be holding on to these vulnerabilities, that we need the cyber equivalent of a Geneva Convention to establish norms for who we will and won't hack and how we will and will not go about those hacks. Apple's Tim Cook was very vocal about a situation when the FBI back in 2015 wanted Apple to create a backdoor so it could get into the iPhone of one of the shooters in the San Bernardino shootings. And Tim Cook really pushed back on that. And eventually the FBI said, well, actually, we don't need Apple's help. We have found an outsider who was able to give us this backdoor anyway. We paid him or her more than a million dollars. And so Tim Cook and Apple have been pushing the government to essentially, you know, disclose that vulnerability, whatever it is. And then at Google, Google has really designated teams of its own hackers to try and go out there and pore through some of the most widely used software we rely on to find these holes that governments could exploit so that they can help get them fixed before they can be used for espionage or mayhem. GROSS: Let me reintroduce you here. If you're just joining us, my guest is Nicole Perlroth, a cybersecurity journalist for The New York Times. Her new book about the cyberwars is called \"This Is How They Tell Me The World Ends. \" We'll be right back. This is FRESH AIR. (SOUNDBITE OF JOAN JEANRENAUD'S \"AXIS\") GROSS: This is FRESH AIR. Let's get back to my interview with Nicole Perlroth, a cybersecurity reporter for The New York Times. Her new book about the cyber weapons arms race is called \"This Is How They Tell Me The World Ends. \" We've been talking about cybersecurity vulnerabilities that can be exploited either by our intelligence agencies or by criminals or foreign adversaries. These vulnerabilities are called zero days. Can you expand on what a zero-day is? PERLROTH: So a zero-day is just a hole in software that hasn't been discovered yet. And, you know, once these zero-days are discovered, they get patched and a patch gets rolled out via your software updates. If everyone's listening to this, please run your software updates. But if a government discovers this hole first, then it can be used for espionage. It can be used for cyber weapons. And so for a long time, we've recognized the sort of espionage and battlefield potential of a zero-day. And starting in the 1990s, I learned through the process of reporting out this book that the U. S. government was actually actively paying hackers and defense contractors to find these zero-days, to write them into, you know, reliable exploits that they could use to spy on our adversaries or to essentially drop a cyber weapon into their systems if we needed to one day. GROSS: Well, part of your book is about the whole underground market that has grown around selling and buying these vulnerabilities, these zero-day vulnerabilities. Can you describe a little bit the underground market that buys and sells these vulnerabilities, giving access to systems ranging from infrastructure to Microsoft and lots of other places? PERLROTH: Yeah. So, essentially, hackers can find a zero-day in a critical system like Microsoft or maybe your Apple iPhone software. And they have a decision. They can give that vulnerability to Microsoft or Apple, which, these days, will pay them small bounties for turning that over. Or they can fetch much higher rates by giving that zero day to a digital arms broker, essentially, or by selling it directly to a government, because governments recognize that these zero days have tremendous espionage potential. They're willing to pay as much as 2 million to $3 million these days for a major zero day in, let's say, your iPhone or Android phone software. And it's not just the United States. Although, the United States was the first government to, essentially, start paying hackers to turn over these zero days and then stay very quiet about them by forcing them to sign nondisclosure agreements. And later, many of these programs were classified. But over the last 10 years, this is not just a U. S. government market anymore. For a long time, our Western allies recognized the potential of a zero day as well for their own espionage operations and were paying hackers for these tools. And then, more recently, oppressive regimes like the United Arab Emirates and Saudi Arabia, who are technically allies of ours, recognized the power of a zero day to monitor the iPhone communications of their own people and of their critics all over the world. And so they started paying top dollar for these zero days. These days, it's actually not the United States. It's a broker for the United Arab Emirates and Saudi Arabia that pays top dollar for a way to get into your iPhone. So this market's really drifted outside U. S. control or even, you know, the control of our Western allies. I went down to Argentina for the book and met with people who sell zero days there to governments. And I asked a really stupid question of someone who was in the scene. I said, you know, so will you only sell these zero days to good Western governments? And he just laughed at me and said, Nicole, you know, the last time I checked, the country that bombed another country into oblivion wasn't China or Iran. We don't think of the United States as a good Western government. Someone comes here with a big bag of cash from Ghana, a big bag of cash from Russia or Iran or the United States. We just weigh the size of the bag of cash. And we'll sell our zero day to them. So - you know, we no longer have any control of this market, which makes these debates about whether to fix the vulnerabilities we are finding that much more critical today. GROSS: So one of the implications of this, I think, is that a government doesn't need to have, like, a brilliant cybersecurity agency in order to find vulnerabilities in their adversary's systems. All the government needs to do - and this includes really authoritarian governments. All they need to do is have enough cash to buy the code from the hackers who have the code. And then they could use those vulnerabilities to whatever purposes they want. PERLROTH: That's right. So they can buy their way into these capabilities. And the market has come to meet their demand. And then there's another thing here, which is they're not just paying hackers to sell these vulnerabilities. They're actually recruiting American hackers overseas to Abu Dhabi to do some of their espionage and surveillance work in some cases. And that was one of the big, eye-opening things I learned in the course of doing this book is that, you know, American contractors were luring NSA hackers out of the NSA, giving them jobs in Abu Dhabi, where originally they were told, OK, you're going to be monitoring terror cells on behalf of the UAE. But very quickly, their assignments changed to, actually, can you get into Qatar's systems? We've heard that they're funding the Muslim Brotherhood. Can you find out if that's true? And so they would - these are American, former NSA hackers who then were turned on an ally, because Qatar is technically also a close U. S. ally. And they would monitor their systems. And even though they didn't find any evidence that Qatar was funding the Muslim Brotherhood, the requests kept coming until, eventually - in one case, I learned that they were inside Qatari royals' email networks as Qataris were trying to coordinate a trip with Michelle Obama, who, while she was in office, was planning a trip to Qatar in 2015. And every last email exchange from Michelle Obama was being read by former NSA hackers stationed in Abu Dhabi. So it's not just the tools that we've lost control of, but the tradecraft, too. GROSS: If you're just joining us, my guest is Nicole Perlroth, a cybersecurity journalist for The New York Times. Her new book about the cyber weapons arms race is called \"This Is How They Tell Me The World Ends. \" We'll talk more after we take a short break. This is FRESH AIR. (SOUNDBITE OF SUSAN ALCORN QUINTET'S \"NORTHEAST RISING SUN\") GROSS: This is FRESH AIR. Let's get back to my interview with Nicole Perlroth, a cybersecurity journalist for The New York Times. Her new book about the cyber weapons arms race is called \"This Is How They Tell Me The World Ends. \" I want to read a sentence from your bio on the book jacket. It says, (reading) Perlroth lives with her family in the Bay Area but increasingly prefers life off the grid in their cabin in the woods. (Laughter) So you're speaking to us from your cabin. Obviously, you have some kind of Internet connection. How off the grid are you in your cabin in the woods? PERLROTH: So it's a family cabin of ours. And there's no smart fridges here. There's no Alexa. There's - you know, our wireless system is really poor. And there's no baby monitors here either. And that's not the case at my home in the Bay Area. And so I ended up just writing a lot of the book up here just because it was a peaceful place to get away from my 2-year-old. But also, as I started to look around, I just felt a lot more safe (laughter) here. As I was sort of just diving into the vulnerabilities of our everyday software that we rely on, I realized that I don't have a lot of software where I'm sitting right now in this cabin. And so it just started to feel a little bit more safe up here. GROSS: Yeah. You mentioned baby monitors. The new thing is - well, not so new anymore - the Internet of Things, where, you know, our refrigerators and coffeemakers and baby monitors and cameras outside our doors and other security measures, they're all connected to the Internet, which makes us so eminently hackable. PERLROTH: Right. And, you know, when I first started covering this beat, everyone was warning me, oh, you know, worry about webcams and worry about this. And, yes, I have a piece of tape over my webcam. But what has sadly happened over the last 10 years is I've covered an attack that's hit every one of these things. One of my favorites was there was an attack at the U. S. Chamber of Commerce where China had gotten into their systems. The FBI had come in, done a big sweep, figured that they had eradicated China from their systems. And next thing they knew, a couple months later, one of their printers just started printing out reams of Chinese characters. But the one that always stuck with me was there was a thermostat in their corporate apartment in D. C. And it had been acting funny. And when they did a little sleuthing, they found out that it had been communicating with a Chinese IP address. China was in the thermostat in their corporate apartment. And, you know, there's just been cases - other cases where there was one where we confirmed that a UAE contractor was spying on the baby monitor of a activist in the UAE. So these are no longer, like, hypothetical scenarios. You're not a tinfoil hat person to be suspicious of some of these devices. They have and will continue to be used for espionage and surveillance. And because I cover these things all the time, I just feel much safer in my cabin in the woods. GROSS: Well, Nicole Perlroth, thank you so much for talking with us. This has been very informative and, also, very chilling. Is part of your goal to be chilling, to say, hey, wake up, everybody, this is what's going on? PERLROTH: Yes, it is. Everything that can be intercepted here already has. You know, our intellectual property, our power grid, our nuclear plants, our hospitals have been taken hostage with ransomware. We are really in a very precarious place. But we haven't had that calamitous attack yet. And so the goal with writing this book and by putting it out now is this is my own sort of attempt at a wakeup call to say, you know, we really need to make a decision as a society and inside government to stop leaving ourselves vulnerable. You know, we have to take our own security seriously. We also have to stop leaving gaping holes in software that could be used by adversaries to pull off some of these attacks. And so if my book is chilling, it's because I'd rather people read this and be scared and really think deeply about how they're securing themselves than waiting for that big wakeup call attack to happen. GROSS: Well, thank you for your reporting. And thank you for this interview. I really appreciate it. PERLROTH: Thanks for having me, Terry. It's been an honor. GROSS: Nicole Perlroth is a cybersecurity journalist at The New York Times. Her new book is called \"This Is How They Tell Me The World Ends. \" Tomorrow on FRESH AIR, my guest will be Rashida Jones. She stars with Bill Murray in the film \"On The Rocks,\" which was just nominated for a Critic's Choice Award for Best Comedy. It was written and directed by Sofia Coppola and draws on Coppola's relationship with her famous father, Francis Ford Coppola. Jones directed a documentary about her father, Quincy Jones. I hope you'll join us. (SOUNDBITE OF QUINCY JONES SONG, \"KILLER JOE\") GROSS: FRESH AIR's executive producer is Danny Miller. Our technical director and engineer is Audrey Bentham. Our interviews and reviews are produced and edited by Amy Salit, Phyllis Myers, Sam Briger, Lauren Krenzel, Heidi Saman, Therese Madden, Ann Marie Baldonado, Thea Chaloner, Seth Kelley and Kayla Lattimore. Our associate producer of digital media is Molly Seavy-Nesper. Roberta Shorrock directs the show. I'm Terry Gross. (SOUNDBITE OF QUINCY JONES SONG, \"KILLER JOE\")", "section": "National Security", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-02-10-965839888": {"title": "Twitter's 'Birdwatch' Aims to Crowdsource Fight Against Misinformation : NPR", "url": "https://www.npr.org/2021/02/10/965839888/twitters-birdwatch-aims-to-crowdsource-fight-against-misinformation", "author": "No author found", "published_date": "2021-02-10", "content": "", "section": "Technology", "disclaimer": ""}, "2021-02-10-966199601": {"title": "Twitter Effort To Quell Misinformation Calls On Users To Fact-Check Tweets : NPR", "url": "https://www.npr.org/2021/02/10/966199601/twitter-effort-to-quell-misinformation-calls-on-users-to-fact-check-tweets", "author": "No author found", "published_date": "2021-02-10", "content": "RACHEL MARTIN, HOST:  Twitter has tried a whole lot of things to curb misinformation. It has slapped warning labels on false claims about election fraud and the coronavirus pandemic. It's put links to credible news outlets debunking those claims. It's even banned users who break its rules. But those moves have only gone so far. So now Twitter's asking its users for help. NPR tech correspondent Shannon Bond has more. SHANNON BOND, BYLINE: The pilot project Birdwatch is an experiment to find out if people who are on Twitter all day can do something the company can't. KEITH COLEMAN: We know that not everyone trusts a single tech company or any singular institution to make the decisions about what context to add and when. BOND: Keith Coleman is Twitter's head of product. He says Birdwatch aims to use the power of the social network's 192 million daily users to fact-check each other's tweets. COLEMAN: The idea is we can allow the community together to come to a consensus on a case where that context really should be shown directly on the tweet. BOND: The way Birdwatch works is you can write a note about a tweet saying, I think this is incorrect and here's why. Then other Birdwatch users rate your note. And if a lot of people say your notes are helpful, you build up a reputation. Your notes and ratings get more weight. So think crowdsourcing combined with consensus. Coleman says eventually you'll be able to see these notes right on tweets. The hope is Birdwatch users can flag and even correct misleading information more quickly than Twitter. COLEMAN: The idea is that people would be able to come away from Twitter better informed. BOND: Birdwatch is still in its early stages, with just a thousand participants on a special site. And looking through it right now, some people are using it to fact-check, like linking to research showing masks help prevent the spread of COVID-19 on a tweet claiming otherwise. But there's also a lot of opinion, the kind of partisan bickering you can find on almost any contentious Twitter thread. Madelyn Webb is a researcher at First Draft, a nonprofit fighting misinformation. She's been digging into how people are starting to use Birdwatch. MADELYN WEBB: It's sort of just replicating what we see on Twitter - things go viral, everybody wants to talk about them, and then the rest of it sort of falls to the wayside. BOND: So how do you keep Birdwatch from recreating the problems Twitter has, like becoming another channel for misinformation? Molly White as a longtime Wikipedia editor, so she knows a lot about the power and risks of crowdsourcing. MOLLY WHITE: What if there's an accurate tweet and someone fact-checks that, they say something inaccurate? Then who fact-checks that and then who fact-checks that? You know, it's like you just keep going deeper, right? BOND: She's also wary that people could use Birdwatch for harassment and abuse. Over at Twitter, Coleman says the company worries about that, too. COLEMAN: But we believe that we can design it to work differently than Twitter in a way that can handle that. BOND: He says it's about changing the incentives. Twitter's platform rewards users who gain a lot of followers and get a lot of interactions, replies and likes. You see their tweets more. Birdwatch users are encouraged to build up reputations as being helpful and credible. Reputable users get more prominence. COLEMAN: Those dynamics around what gets elevated, you know, they're different from Twitter and we think that will create a very different result. We think that will result in genuinely helpful information being elevated. BOND: But for a Birdwatch to succeed, it will have to overcome an uncomfortable truth about Twitter and, really, all social media. Tiffany Li is a law professor at Boston University who studies technology. TIFFANY LI: People on Twitter do not agree on what truth is. They do not agree on what, you know, real news is, and that's a problem. If they don't agree on what the truth is, they're going to have different opinions on whether or not a tweet or a post is truthful. BOND: The question is, can enough Twitter users agree on anything to make the Birdwatch experiment work? Shannon Bond, NPR News. (SOUNDBITE OF MARLEY CARROLL'S \"FIREFLIES\") RACHEL MARTIN, HOST:   Twitter has tried a whole lot of things to curb misinformation. It has slapped warning labels on false claims about election fraud and the coronavirus pandemic. It's put links to credible news outlets debunking those claims. It's even banned users who break its rules. But those moves have only gone so far. So now Twitter's asking its users for help. NPR tech correspondent Shannon Bond has more. SHANNON BOND, BYLINE: The pilot project Birdwatch is an experiment to find out if people who are on Twitter all day can do something the company can't. KEITH COLEMAN: We know that not everyone trusts a single tech company or any singular institution to make the decisions about what context to add and when. BOND: Keith Coleman is Twitter's head of product. He says Birdwatch aims to use the power of the social network's 192 million daily users to fact-check each other's tweets. COLEMAN: The idea is we can allow the community together to come to a consensus on a case where that context really should be shown directly on the tweet. BOND: The way Birdwatch works is you can write a note about a tweet saying, I think this is incorrect and here's why. Then other Birdwatch users rate your note. And if a lot of people say your notes are helpful, you build up a reputation. Your notes and ratings get more weight. So think crowdsourcing combined with consensus. Coleman says eventually you'll be able to see these notes right on tweets. The hope is Birdwatch users can flag and even correct misleading information more quickly than Twitter. COLEMAN: The idea is that people would be able to come away from Twitter better informed. BOND: Birdwatch is still in its early stages, with just a thousand participants on a special site. And looking through it right now, some people are using it to fact-check, like linking to research showing masks help prevent the spread of COVID-19 on a tweet claiming otherwise. But there's also a lot of opinion, the kind of partisan bickering you can find on almost any contentious Twitter thread. Madelyn Webb is a researcher at First Draft, a nonprofit fighting misinformation. She's been digging into how people are starting to use Birdwatch. MADELYN WEBB: It's sort of just replicating what we see on Twitter - things go viral, everybody wants to talk about them, and then the rest of it sort of falls to the wayside. BOND: So how do you keep Birdwatch from recreating the problems Twitter has, like becoming another channel for misinformation? Molly White as a longtime Wikipedia editor, so she knows a lot about the power and risks of crowdsourcing. MOLLY WHITE: What if there's an accurate tweet and someone fact-checks that, they say something inaccurate? Then who fact-checks that and then who fact-checks that? You know, it's like you just keep going deeper, right? BOND: She's also wary that people could use Birdwatch for harassment and abuse. Over at Twitter, Coleman says the company worries about that, too. COLEMAN: But we believe that we can design it to work differently than Twitter in a way that can handle that. BOND: He says it's about changing the incentives. Twitter's platform rewards users who gain a lot of followers and get a lot of interactions, replies and likes. You see their tweets more. Birdwatch users are encouraged to build up reputations as being helpful and credible. Reputable users get more prominence. COLEMAN: Those dynamics around what gets elevated, you know, they're different from Twitter and we think that will create a very different result. We think that will result in genuinely helpful information being elevated. BOND: But for a Birdwatch to succeed, it will have to overcome an uncomfortable truth about Twitter and, really, all social media. Tiffany Li is a law professor at Boston University who studies technology. TIFFANY LI: People on Twitter do not agree on what truth is. They do not agree on what, you know, real news is, and that's a problem. If they don't agree on what the truth is, they're going to have different opinions on whether or not a tweet or a post is truthful. BOND: The question is, can enough Twitter users agree on anything to make the Birdwatch experiment work? Shannon Bond, NPR News. (SOUNDBITE OF MARLEY CARROLL'S \"FIREFLIES\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-02-11-966503986": {"title": "Clubhouse May Be Social Media's Future. What's All The Hype About? : NPR", "url": "https://www.npr.org/2021/02/11/966503986/clubhouse-may-be-social-medias-future-whats-all-the-hype-about", "author": "No author found", "published_date": "2021-02-11", "content": "", "section": "Technology", "disclaimer": ""}, "2021-02-12-967458767": {"title": "A Global Shortage In Computer Chips Hits Auto Industry. What Industries Are Next? : NPR", "url": "https://www.npr.org/2021/02/12/967458767/a-global-shortage-in-computer-chips-hits-auto-industry-what-industries-are-next", "author": "No author found", "published_date": "2021-02-12", "content": "ARI SHAPIRO, HOST:  Automakers around the world are being hobbled by something thinner than a piece of paper. A chip shortage is shutting down auto factories, sending workers home and halting productions on several car lines. NPR's Ryan Kailath reports on how we got here. RYAN KAILATH, BYLINE: Cars these days are basically 2-ton computers on wheels. So when auto production first shut down at the beginning of the pandemic, it meant a lot of extra computer chips sitting around. At the same time, we were all sitting around, working from home and schooling from home and attending weddings from home. KRISTIN DZICZEK: We all needed new computers. Every school kid needed a Chromebook. There's the new PlayStation 5 (laughter). KAILATH: According to Kristin Dziczek of the Center for Automotive Research, chipmakers pushed their extra supply into all our new TVs and smart speakers and Internet-connected washing machines. Whatever device you're hearing this story on probably contains a computer chip. Meanwhile, auto sales rebounded way faster than anyone predicted, says Patrick Manzi with the National Auto Dealers Association. PATRICK MANZI: Most of us did not expect this. The sales rate in April fell to the lowest on record, at least back to the '70s since we've been tracking this. KAILATH: When car carmakers suddenly needed chips again, those supply lines were spoken for. And switching them back takes time, up to six months to reallocate capacity. So now carmakers have a dire short-term need that can't be addressed in the short term. Manzi expects global production to drop by about a million cars this quarter. MANZI: It is a nontrivial amount. KAILATH: For American autoworkers at idled plants, that means up to 25% pay cuts for the duration. And the effects will trickle down through the massive cottage industry of car parts suppliers and everyone they employ. At the car lot, Manzi says. . . MANZI: There will be vehicles to buy. It just may be a little bit more difficult to find that exact specification that you're looking for. If you wanted the red one with the leather, maybe they only have the gray one with the leather, right? KAILATH: Now President Biden is stepping in, ordering a review into expanding chip manufacturing in the U. S. instead of Taiwan and Korea, treating chips as essential American goods, crucial to so many things we use every day. But new American factories would take years to bring online. In the meantime, the shortage is spreading, disrupting supplies for cellphones and laptops. Analysts say it will likely get worse before it gets better. For consumers, it's probably a good time to drive carefully and try not to drop your cellphone. Ryan Kailath, NPR News, New York. ARI SHAPIRO, HOST:   Automakers around the world are being hobbled by something thinner than a piece of paper. A chip shortage is shutting down auto factories, sending workers home and halting productions on several car lines. NPR's Ryan Kailath reports on how we got here. RYAN KAILATH, BYLINE: Cars these days are basically 2-ton computers on wheels. So when auto production first shut down at the beginning of the pandemic, it meant a lot of extra computer chips sitting around. At the same time, we were all sitting around, working from home and schooling from home and attending weddings from home. KRISTIN DZICZEK: We all needed new computers. Every school kid needed a Chromebook. There's the new PlayStation 5 (laughter). KAILATH: According to Kristin Dziczek of the Center for Automotive Research, chipmakers pushed their extra supply into all our new TVs and smart speakers and Internet-connected washing machines. Whatever device you're hearing this story on probably contains a computer chip. Meanwhile, auto sales rebounded way faster than anyone predicted, says Patrick Manzi with the National Auto Dealers Association. PATRICK MANZI: Most of us did not expect this. The sales rate in April fell to the lowest on record, at least back to the '70s since we've been tracking this. KAILATH: When car carmakers suddenly needed chips again, those supply lines were spoken for. And switching them back takes time, up to six months to reallocate capacity. So now carmakers have a dire short-term need that can't be addressed in the short term. Manzi expects global production to drop by about a million cars this quarter. MANZI: It is a nontrivial amount. KAILATH: For American autoworkers at idled plants, that means up to 25% pay cuts for the duration. And the effects will trickle down through the massive cottage industry of car parts suppliers and everyone they employ. At the car lot, Manzi says. . . MANZI: There will be vehicles to buy. It just may be a little bit more difficult to find that exact specification that you're looking for. If you wanted the red one with the leather, maybe they only have the gray one with the leather, right? KAILATH: Now President Biden is stepping in, ordering a review into expanding chip manufacturing in the U. S. instead of Taiwan and Korea, treating chips as essential American goods, crucial to so many things we use every day. But new American factories would take years to bring online. In the meantime, the shortage is spreading, disrupting supplies for cellphones and laptops. Analysts say it will likely get worse before it gets better. For consumers, it's probably a good time to drive carefully and try not to drop your cellphone. Ryan Kailath, NPR News, New York.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-02-15-968116346": {"title": "After Weeks Offline, Parler Finds A New Web Host: California Company SkySilk : NPR", "url": "https://www.npr.org/2021/02/15/968116346/after-weeks-of-being-off-line-parler-finds-a-new-web-host", "author": "No author found", "published_date": "2021-02-15", "content": "", "section": "Technology", "disclaimer": ""}, "2021-02-15-967377462": {"title": "Environmentalists Use Satellites To Detect Deforestation : NPR", "url": "https://www.npr.org/2021/02/15/967377462/pillagers-of-tropical-forests-cant-hide-behind-clouds-anymore", "author": "No author found", "published_date": "2021-02-15", "content": "STEVE INSKEEP, HOST:  The world continues to lose some of its most valuable tropical forests, millions of acres each year. Defenders of the forest are trying to halt that and preserve endangered species and slow down climate change. They just deployed a new tool in that effort. Here's NPR's Dan Charles. DAN CHARLES, BYLINE: Practically every day, Mikaela Weisse transports herself by computer to distant tropical forests. MIKAELA WEISSE: OK. So we're in the Central African Republic. That's where I'm zooming in. CHARLES: She's sharing her computer screen. We see a map of the forest created from a flood of images collected by satellites. Weisse works for the World Resources Institute, and she helps run this site called Global Forest Watch. Behind the scenes, computers sift through the images as they come in day by day. And when the software detects a change, when trees have disappeared, it issues an alert. WEISSE: If we can detect deforestation and other changes as soon as they're happening, then there's a possibility to send in law enforcement or what have you to actually stop it before it goes further. CHARLES: There's some evidence that this works, she says. According to one study, in places where people know they're being watched, there's been less forest clearing. One problem, though - when it's raining or cloudy, regular satellite sensors can't see the forest. And it rains a lot in the tropics. WEISSE: In Indonesia, my impression is it's the rainy season almost all the time (laughter). So there's, like - there's almost always cloud cover. CHARLES: So it might not be possible to see deforestation until months later when the weather clears. But last month, Weisse and her colleagues unveiled something new. Their system now collects images from an additional kind of satellite sensor, radar, which sees right through clouds. WEISSE: Essentially, the satellites are, like, sending radio waves to the Earth and collecting how they come back. CHARLES: The satellite's operated by the European Space Agency. And it delivers even sharper pictures than what Global Forest Watch had been getting. WEISSE: And so we can actually see these little patches that indicate where there's been, you know, removal of a single tree. CHARLES: At that site in Central African Republic in front of us on the computer, the map shows dark pink spots where trees disappeared just within the past few weeks. Anybody in the world can log in and see this. So local environmentalists or even big food companies that have pledged not to buy crops grown on deforested land can react more quickly. Dan Charles, NPR News. (SOUNDBITE OF EMANCIPATOR'S \"ALL IN HERE\") STEVE INSKEEP, HOST:   The world continues to lose some of its most valuable tropical forests, millions of acres each year. Defenders of the forest are trying to halt that and preserve endangered species and slow down climate change. They just deployed a new tool in that effort. Here's NPR's Dan Charles. DAN CHARLES, BYLINE: Practically every day, Mikaela Weisse transports herself by computer to distant tropical forests. MIKAELA WEISSE: OK. So we're in the Central African Republic. That's where I'm zooming in. CHARLES: She's sharing her computer screen. We see a map of the forest created from a flood of images collected by satellites. Weisse works for the World Resources Institute, and she helps run this site called Global Forest Watch. Behind the scenes, computers sift through the images as they come in day by day. And when the software detects a change, when trees have disappeared, it issues an alert. WEISSE: If we can detect deforestation and other changes as soon as they're happening, then there's a possibility to send in law enforcement or what have you to actually stop it before it goes further. CHARLES: There's some evidence that this works, she says. According to one study, in places where people know they're being watched, there's been less forest clearing. One problem, though - when it's raining or cloudy, regular satellite sensors can't see the forest. And it rains a lot in the tropics. WEISSE: In Indonesia, my impression is it's the rainy season almost all the time (laughter). So there's, like - there's almost always cloud cover. CHARLES: So it might not be possible to see deforestation until months later when the weather clears. But last month, Weisse and her colleagues unveiled something new. Their system now collects images from an additional kind of satellite sensor, radar, which sees right through clouds. WEISSE: Essentially, the satellites are, like, sending radio waves to the Earth and collecting how they come back. CHARLES: The satellite's operated by the European Space Agency. And it delivers even sharper pictures than what Global Forest Watch had been getting. WEISSE: And so we can actually see these little patches that indicate where there's been, you know, removal of a single tree. CHARLES: At that site in Central African Republic in front of us on the computer, the map shows dark pink spots where trees disappeared just within the past few weeks. Anybody in the world can log in and see this. So local environmentalists or even big food companies that have pledged not to buy crops grown on deforested land can react more quickly. Dan Charles, NPR News. (SOUNDBITE OF EMANCIPATOR'S \"ALL IN HERE\")", "section": "Environment", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-02-16-968457180": {"title": "How A Project To Get Humans To Mars Could Solve The Rural Internet Problem : NPR", "url": "https://www.npr.org/2021/02/16/968457180/how-a-project-to-get-humans-to-mars-could-solve-the-rural-internet-problem", "author": "No author found", "published_date": "2021-02-16", "content": "AILSA CHANG, HOST:  Nearly 11% of U. S. households still don't have high-speed Internet access, but a new convoy of low-flying satellites could beam broadband to hard-to-reach places across the country later this year. It's a project that actually is a fundraiser for launching humans to Mars. High Plains Public Radio's David Condos reports from Great Bend, Kan. DAVID CONDOS, BYLINE: Joey Bahr walks out to the front of his yard along a two-lane road lined with farmland. JOEY BAHR: So in the ditch that we're standing in right now, there is a fiber optic cable that runs from here all the way probably up to Albert five miles north of here. I can't access it. CONDOS: That cable running beneath his feet is owned by a neighboring Internet service provider and is just passing through on its way to a nearby town. So instead of tapping into the wired broadband that much of America takes for granted, Bahr, his wife Anita and their three sons connect their home to the Internet through a cell tower a few miles away. The family has to ration every minute they spend online to stay under their data cap of 15 gigabytes per month. BAHR: It's a beautiful place. I love it. Unfortunately, we are in kind of an Internet no man's land right now. CONDOS: But for Bahr and millions of other rural Americans, the promise of broadband might not come from below his feet but from above his head. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED PERSON: Ten, nine, eight. . . CONDOS: The richest man on the planet, SpaceX founder Elon Musk, has a plan to send humans to Mars. And almost accidentally, that plan might just open the door to getting a better YouTube feed to farms, ranches and homes across the country. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED PERSON: Ignition and liftoff. CONDOS: That's a SpaceX rocket blasting off with 60 Starlink satellites in tow. They'll orbit thousands of miles closer to the Earth than traditional satellites. That means they could bypass the crawling speeds, long lag times in spotty connections that have plagued satellite Internet users for years. SpaceX has launched about a thousand satellites so far and reaches 10,000 consumers worldwide. The company just began to offer service to its first Kansas customers earlier this month. (APPLAUSE)CONDOS: Musk views Starlink is a critical step toward funding his ambitions in the heavens like space tourism and colonizing the red planet. Jeff Bezos is looking to cash in, too. He hired a former SpaceX executive to lead Amazon's satellite Internet venture. But where other companies have failed, could these tech giants succeed? DEREK SMASHEY: First of all, I wouldn't want to bet against people like Elon Musk or Jeff Bezos. CONDOS: Derek Smashey is a portfolio manager with Scout Investments in Kansas City. He says satellite Internet could eventually serve 15 to 20% of the population. So Starlink's $99 monthly fees could cover the project's estimated $10 billion price tag. SMASHEY: It looks to us like that could be a $20 billion-plus market just in the United States alone. CONDOS: To get there, SpaceX plans to launch over 40,000 satellites, more than 10 times the number in the sky now. That worries some people who like the sky the way it is. SAMANTHA LAWLER: The thought of having to see the stars through a grid of crawling satellites - that's pretty horrifying to me. CONDOS: Samantha Lawler is an astronomy professor at the University of Regina in Canada. She fears that advancing our connection to the Internet could come at the expense of losing our connection to the stars. LAWLER: This isn't like light pollution from a city, where you can go camping in the mountains and see the stars perfectly. It will be everywhere. CONDOS: Back in Great Bend, Joey Bahr says living in a place where his sons can gaze up at the night sky was one of the reasons he and his wife moved out here. But living out here means dealing with Internet speeds that can dwindle down to about 2% of the minimum speed in the federal definition of broadband. Bahr says he recently added his name to the Starlink waiting list. For NPR News, I'm David Condos in Great Bend, Kan. (SOUNDBITE OF DELICATE STEVE'S \"TOMORROW\") AILSA CHANG, HOST:   Nearly 11% of U. S. households still don't have high-speed Internet access, but a new convoy of low-flying satellites could beam broadband to hard-to-reach places across the country later this year. It's a project that actually is a fundraiser for launching humans to Mars. High Plains Public Radio's David Condos reports from Great Bend, Kan. DAVID CONDOS, BYLINE: Joey Bahr walks out to the front of his yard along a two-lane road lined with farmland. JOEY BAHR: So in the ditch that we're standing in right now, there is a fiber optic cable that runs from here all the way probably up to Albert five miles north of here. I can't access it. CONDOS: That cable running beneath his feet is owned by a neighboring Internet service provider and is just passing through on its way to a nearby town. So instead of tapping into the wired broadband that much of America takes for granted, Bahr, his wife Anita and their three sons connect their home to the Internet through a cell tower a few miles away. The family has to ration every minute they spend online to stay under their data cap of 15 gigabytes per month. BAHR: It's a beautiful place. I love it. Unfortunately, we are in kind of an Internet no man's land right now. CONDOS: But for Bahr and millions of other rural Americans, the promise of broadband might not come from below his feet but from above his head. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED PERSON: Ten, nine, eight. . . CONDOS: The richest man on the planet, SpaceX founder Elon Musk, has a plan to send humans to Mars. And almost accidentally, that plan might just open the door to getting a better YouTube feed to farms, ranches and homes across the country. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED PERSON: Ignition and liftoff. CONDOS: That's a SpaceX rocket blasting off with 60 Starlink satellites in tow. They'll orbit thousands of miles closer to the Earth than traditional satellites. That means they could bypass the crawling speeds, long lag times in spotty connections that have plagued satellite Internet users for years. SpaceX has launched about a thousand satellites so far and reaches 10,000 consumers worldwide. The company just began to offer service to its first Kansas customers earlier this month. (APPLAUSE) CONDOS: Musk views Starlink is a critical step toward funding his ambitions in the heavens like space tourism and colonizing the red planet. Jeff Bezos is looking to cash in, too. He hired a former SpaceX executive to lead Amazon's satellite Internet venture. But where other companies have failed, could these tech giants succeed? DEREK SMASHEY: First of all, I wouldn't want to bet against people like Elon Musk or Jeff Bezos. CONDOS: Derek Smashey is a portfolio manager with Scout Investments in Kansas City. He says satellite Internet could eventually serve 15 to 20% of the population. So Starlink's $99 monthly fees could cover the project's estimated $10 billion price tag. SMASHEY: It looks to us like that could be a $20 billion-plus market just in the United States alone. CONDOS: To get there, SpaceX plans to launch over 40,000 satellites, more than 10 times the number in the sky now. That worries some people who like the sky the way it is. SAMANTHA LAWLER: The thought of having to see the stars through a grid of crawling satellites - that's pretty horrifying to me. CONDOS: Samantha Lawler is an astronomy professor at the University of Regina in Canada. She fears that advancing our connection to the Internet could come at the expense of losing our connection to the stars. LAWLER: This isn't like light pollution from a city, where you can go camping in the mountains and see the stars perfectly. It will be everywhere. CONDOS: Back in Great Bend, Joey Bahr says living in a place where his sons can gaze up at the night sky was one of the reasons he and his wife moved out here. But living out here means dealing with Internet speeds that can dwindle down to about 2% of the minimum speed in the federal definition of broadband. Bahr says he recently added his name to the Starlink waiting list. For NPR News, I'm David Condos in Great Bend, Kan. (SOUNDBITE OF DELICATE STEVE'S \"TOMORROW\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-02-17-968760724": {"title": "Behind Twitter's Tricky Balancing Act In India : NPR", "url": "https://www.npr.org/2021/02/17/968760724/behind-twitters-tricky-balancing-act-in-india", "author": "No author found", "published_date": "2021-02-17", "content": "AILSA CHANG, HOST:  All right. Well, for more on this dilemma facing Twitter in India, we're going to turn now to NPR tech correspondent Shannon Bond. Hey, Shannon. SHANNON BOND, BYLINE: Hey, Ailsa. CHANG: So it sounds like the standoff is a really complicated situation for Twitter. What exactly is the company saying about all this? BOND: Right. So Twitter is emphasizing, you know, it has complied with some of this order from the Indian government to block accounts, as Lauren reported. But Twitter also says that it won't take down other accounts of specifically journalists, activists and politicians. That's why it put back up The Caravan's account - because Twitter says that complying with the government ministry's order in those cases would actually violate Indian law and Twitter's own principles of free expression. So this is a really difficult balance, I think, that Twitter is trying to strike here. I think it's resisting being used as a tool of the government against critics. It's also worried about its employees in India, that they could face jail time. And of course, India is a huge, important market. Remember, Ailsa; many U. S. tech companies, like Twitter, Facebook, they're blocked in China. They see India as a big opportunity to get billions more people using their platforms. But they - we're just seeing how difficult it is to navigate these sort of competing pressures around the world. CHANG: What do you mean by that? What are the competing pressures? BOND: Well, I think we know - you know, we've seen over the last decade - social media is this powerful tool. It's given people who didn't have a lot of power a voice, a way to organize. But at the same time, it's also become an incredibly important platform for people in power. Think about Donald Trump, right? He had a huge Twitter following before Twitter banned him for breaking its rules against inciting violence and spreading false election fraud claims. And actually, now that Trump's banned, India's Prime Minister Narendra Modi - he's now the world leader with the most Twitter followers. CHANG: Oh. BOND: And we are increasingly seeing governments - like Modi's in India, like in Turkey - that are putting pressure on Twitter to remove speech that they don't like, that the government doesn't like. And that puts Twitter in a difficult position. You know, what happens when free speech and human rights clashes with these local laws? CHANG: Right. And we heard from Lauren Frayer that some people in India are saying Twitter is getting bullied by Modi's government but that Twitter was willing to stand up to Trump here in the U. S. And all of that raises the question, can Twitter have, like, a one-size-fits-all policy for every country? It doesn't sound like it can. BOND: That's the exact dilemma, I think, Twitter is grappling with. And that's because it's basically become - you know, whether it's wanted to or not - this gatekeeper of public conversation. I spoke with David Kay. He's a law professor at the University of California, Irvine. He was the U. N. special rapporteur on freedom of expression. Here's what he said. DAVID KAY: How do we make sense of companies that have such enormous power that they can stand up to governments and serve as a kind of protector of rights, but at the same time, they have this massive impact that can undermine democratic institutions? BOND: And what Kay says is, you know, look; a company like Twitter has so much control, sometimes it can feel like it's acting like a government. But it's not democratically elected. We don't have a lot of transparency, a good view into how it decides what to allow, what to take down. And I think whether you agree or disagree with Twitter about these decisions about Trump, about activists and journalists in India, there's a bigger question, which is, should Twitter have that kind of power at all? CHANG: Right. OK, so what happens next with Twitter in India? BOND: Well, the Indian government ministry still does want Twitter to take down these accounts. That standoff is continuing. Twitter says it's exploring its options under Indian law. There was a meeting between Twitter officials and the government last week. Didn't appear to get - make any progress. One potential outcome is maybe this could go to the Indian courts. The law professor, David Kay, I spoke with - he said that might be an appropriate way to decide whether this order is legal or if, as Twitter is arguing, it goes against Indian law. CHANG: That is NPR's Shannon Bond. Thank you, Shannon. BOND: Thank you. (SOUNDBITE OF MICHAL MENERT SONG, \"OUT OF THIS WORLD\") AILSA CHANG, HOST:   All right. Well, for more on this dilemma facing Twitter in India, we're going to turn now to NPR tech correspondent Shannon Bond. Hey, Shannon. SHANNON BOND, BYLINE: Hey, Ailsa. CHANG: So it sounds like the standoff is a really complicated situation for Twitter. What exactly is the company saying about all this? BOND: Right. So Twitter is emphasizing, you know, it has complied with some of this order from the Indian government to block accounts, as Lauren reported. But Twitter also says that it won't take down other accounts of specifically journalists, activists and politicians. That's why it put back up The Caravan's account - because Twitter says that complying with the government ministry's order in those cases would actually violate Indian law and Twitter's own principles of free expression. So this is a really difficult balance, I think, that Twitter is trying to strike here. I think it's resisting being used as a tool of the government against critics. It's also worried about its employees in India, that they could face jail time. And of course, India is a huge, important market. Remember, Ailsa; many U. S. tech companies, like Twitter, Facebook, they're blocked in China. They see India as a big opportunity to get billions more people using their platforms. But they - we're just seeing how difficult it is to navigate these sort of competing pressures around the world. CHANG: What do you mean by that? What are the competing pressures? BOND: Well, I think we know - you know, we've seen over the last decade - social media is this powerful tool. It's given people who didn't have a lot of power a voice, a way to organize. But at the same time, it's also become an incredibly important platform for people in power. Think about Donald Trump, right? He had a huge Twitter following before Twitter banned him for breaking its rules against inciting violence and spreading false election fraud claims. And actually, now that Trump's banned, India's Prime Minister Narendra Modi - he's now the world leader with the most Twitter followers. CHANG: Oh. BOND: And we are increasingly seeing governments - like Modi's in India, like in Turkey - that are putting pressure on Twitter to remove speech that they don't like, that the government doesn't like. And that puts Twitter in a difficult position. You know, what happens when free speech and human rights clashes with these local laws? CHANG: Right. And we heard from Lauren Frayer that some people in India are saying Twitter is getting bullied by Modi's government but that Twitter was willing to stand up to Trump here in the U. S. And all of that raises the question, can Twitter have, like, a one-size-fits-all policy for every country? It doesn't sound like it can. BOND: That's the exact dilemma, I think, Twitter is grappling with. And that's because it's basically become - you know, whether it's wanted to or not - this gatekeeper of public conversation. I spoke with David Kay. He's a law professor at the University of California, Irvine. He was the U. N. special rapporteur on freedom of expression. Here's what he said. DAVID KAY: How do we make sense of companies that have such enormous power that they can stand up to governments and serve as a kind of protector of rights, but at the same time, they have this massive impact that can undermine democratic institutions? BOND: And what Kay says is, you know, look; a company like Twitter has so much control, sometimes it can feel like it's acting like a government. But it's not democratically elected. We don't have a lot of transparency, a good view into how it decides what to allow, what to take down. And I think whether you agree or disagree with Twitter about these decisions about Trump, about activists and journalists in India, there's a bigger question, which is, should Twitter have that kind of power at all? CHANG: Right. OK, so what happens next with Twitter in India? BOND: Well, the Indian government ministry still does want Twitter to take down these accounts. That standoff is continuing. Twitter says it's exploring its options under Indian law. There was a meeting between Twitter officials and the government last week. Didn't appear to get - make any progress. One potential outcome is maybe this could go to the Indian courts. The law professor, David Kay, I spoke with - he said that might be an appropriate way to decide whether this order is legal or if, as Twitter is arguing, it goes against Indian law. CHANG: That is NPR's Shannon Bond. Thank you, Shannon. BOND: Thank you. (SOUNDBITE OF MICHAL MENERT SONG, \"OUT OF THIS WORLD\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-02-17-968723929": {"title": "Facebook Blocks News In Australia Over Government Plan To Force Payment To Publishers : NPR", "url": "https://www.npr.org/2021/02/17/968723929/facebook-blocks-news-in-australia-over-government-plan-to-force-payment-to-publi", "author": "No author found", "published_date": "2021-02-17", "content": "", "section": "Technology", "disclaimer": ""}, "2021-02-17-968652939": {"title": "3 North Korean Hackers Charged By Justice Department For Global Attacks : NPR", "url": "https://www.npr.org/2021/02/17/968652939/justice-department-charges-3-north-korean-hackers-for-global-cyberattacks", "author": "No author found", "published_date": "2021-02-17", "content": "", "section": "National Security", "disclaimer": ""}, "2021-02-17-968312945": {"title": "What Will Tesla's New German Gigafactory Mean For Germany's Auto Industry? : NPR", "url": "https://www.npr.org/2021/02/17/968312945/what-will-teslas-new-german-gigafactory-mean-for-germanys-auto-industry", "author": "No author found", "published_date": "2021-02-17", "content": "", "section": "World", "disclaimer": ""}, "2021-02-17-968568042": {"title": "New York Sues Amazon Over COVID-19 Workplace Safety  : NPR", "url": "https://www.npr.org/2021/02/17/968568042/new-york-sues-amazon-for-covid-19-workplace-safety-failures", "author": "No author found", "published_date": "2021-02-17", "content": "", "section": "The Coronavirus Crisis", "disclaimer": ""}, "2021-02-18-968960448": {"title": "Review: 'Super Mario 3D World/Bowser's Fury' : NPR", "url": "https://www.npr.org/2021/02/18/968960448/nintendos-super-mario-3d-world-gets-another-chance-on-the-switch", "author": "No author found", "published_date": "2021-02-18", "content": "", "section": "Games", "disclaimer": ""}, "2021-02-18-968921926": {"title": "Facebook Takes A Hard Line Against Proposed Australian Law : NPR", "url": "https://www.npr.org/2021/02/18/968921926/facebook-takes-a-hard-line-against-proposed-australian-law", "author": "No author found", "published_date": "2021-02-18", "content": "STEVE INSKEEP, HOST:  Facebook has abruptly cut off news to and from a continent. Facebook is blocking users in Australia from sharing or reading news stories. There are several parts to this. Australian publishers cannot post links to their own stories. Ordinary citizens in Australia cannot post links to any news stories. And, in fact, people anywhere in the world cannot post news stories that come out of Australia. The decision shocked Australian news outlets. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED REPORTER #1: In a huge change for social media in Australia, Facebook has blocked news content from being shared on its platform from today. . . (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED REPORTER #2: Facebook has taken the stunning step of banning Australian users and publishers from viewing or sharing news articles on its website. INSKEEP: What's going on here? We've called NPR tech correspondent Shannon Bond. And before we begin, we should note that Facebook is a financial supporter of NPR, but we cover them like any other company. Shannon, good morning. SHANNON BOND, BYLINE: Good morning, Steve. INSKEEP: What caused Facebook's move? BOND: Well, Australia is weighing this proposed law that would force tech companies like Facebook to pay big publishers for linking to their stories. This law is trying to address this long-running criticism from media companies, you know, that Facebook and Google, which is also an NPR sponsor, you know, these big tech platforms have just sucked up so much of the advertising revenue. You know, media outlets around the world have these concerns, that that's really hurt the news business. News websites just can't compete for advertising with the tech giants, which are so big, so dominant and, of course, are an important channel to readers. INSKEEP: I just want to note, you're telling me the law is not even law yet. It's something that's on its way to becoming law. And so it's almost a kind of negotiating tactic or lobbying effort that Facebook has said we're going to cut you off now. BOND: Right. I mean, this fight has been brewing for months. This proposal is expected to become law soon. And, you know, Facebook is just saying it's not going to play with the rules Australia is setting, which would require platforms to reach deals with publishers to pay for content. Facebook says this law, quote, \"fundamentally misunderstands\" its relationship with news outlets. You know, its view is that news outlets choose to post on Facebook, and ultimately publishers benefit more than Facebook does. And we should say that as this has rolled out, Facebook has acted pretty broadly in terms of blocking things. Some Australian government pages, including a fire and rescue agency, even the weather service, had their posts swiped yesterday. Even Facebook's own Facebook page was blank in Australia. Facebook says it's restoring these pages that have gotten inadvertently caught in the filters. INSKEEP: Is Facebook's response any different than other companies that might be affected by a rule requiring payment in order to post links? BOND: Well, right. So the other company sort of in the crosshairs here is Google, which has taken a very different approach. So Google had previously also threatened to shut down in Australia. It's now reached deals with several big publishers there. Most notably, it announced a three-year global deal with News Corp, which owns The Wall Street Journal, as well as several Australian papers. I say that's notable because News Corp is run by Rupert Murdoch. He is Australian. He's a powerful force in media and politics there. He's been lobbying for years for the tech companies to pay for news content, and he has thrown his considerable support behind this law. INSKEEP: Wants his companies to be paid. Any chance of a law like this in the United States? BOND: Well, I think that's the big concern here and why we're seeing Facebook act like this. You know, it doesn't want to capitulate in Australia, fearing that could set a precedent elsewhere. And we've heard from lawmakers in Canada and Europe who say they're open to this approach. You know, just last week, another U. S. tech giant, Microsoft, said it supports a version of the Australian law in the U. S. And I think there is concern that this is something that we could see here. But, you know, even if it's just in Australia, this has big consequences when it comes to misinformation. We know that's a big problem for Facebook. You know, it's talked about promoting accurate information, but now people in Australia can't post, you know, reputable news stories to counter false claims. INSKEEP: NPR tech correspondent Shannon Bond, thanks. BOND: Thanks, Steve. STEVE INSKEEP, HOST:   Facebook has abruptly cut off news to and from a continent. Facebook is blocking users in Australia from sharing or reading news stories. There are several parts to this. Australian publishers cannot post links to their own stories. Ordinary citizens in Australia cannot post links to any news stories. And, in fact, people anywhere in the world cannot post news stories that come out of Australia. The decision shocked Australian news outlets. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED REPORTER #1: In a huge change for social media in Australia, Facebook has blocked news content from being shared on its platform from today. . . (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED REPORTER #2: Facebook has taken the stunning step of banning Australian users and publishers from viewing or sharing news articles on its website. INSKEEP: What's going on here? We've called NPR tech correspondent Shannon Bond. And before we begin, we should note that Facebook is a financial supporter of NPR, but we cover them like any other company. Shannon, good morning. SHANNON BOND, BYLINE: Good morning, Steve. INSKEEP: What caused Facebook's move? BOND: Well, Australia is weighing this proposed law that would force tech companies like Facebook to pay big publishers for linking to their stories. This law is trying to address this long-running criticism from media companies, you know, that Facebook and Google, which is also an NPR sponsor, you know, these big tech platforms have just sucked up so much of the advertising revenue. You know, media outlets around the world have these concerns, that that's really hurt the news business. News websites just can't compete for advertising with the tech giants, which are so big, so dominant and, of course, are an important channel to readers. INSKEEP: I just want to note, you're telling me the law is not even law yet. It's something that's on its way to becoming law. And so it's almost a kind of negotiating tactic or lobbying effort that Facebook has said we're going to cut you off now. BOND: Right. I mean, this fight has been brewing for months. This proposal is expected to become law soon. And, you know, Facebook is just saying it's not going to play with the rules Australia is setting, which would require platforms to reach deals with publishers to pay for content. Facebook says this law, quote, \"fundamentally misunderstands\" its relationship with news outlets. You know, its view is that news outlets choose to post on Facebook, and ultimately publishers benefit more than Facebook does. And we should say that as this has rolled out, Facebook has acted pretty broadly in terms of blocking things. Some Australian government pages, including a fire and rescue agency, even the weather service, had their posts swiped yesterday. Even Facebook's own Facebook page was blank in Australia. Facebook says it's restoring these pages that have gotten inadvertently caught in the filters. INSKEEP: Is Facebook's response any different than other companies that might be affected by a rule requiring payment in order to post links? BOND: Well, right. So the other company sort of in the crosshairs here is Google, which has taken a very different approach. So Google had previously also threatened to shut down in Australia. It's now reached deals with several big publishers there. Most notably, it announced a three-year global deal with News Corp, which owns The Wall Street Journal, as well as several Australian papers. I say that's notable because News Corp is run by Rupert Murdoch. He is Australian. He's a powerful force in media and politics there. He's been lobbying for years for the tech companies to pay for news content, and he has thrown his considerable support behind this law. INSKEEP: Wants his companies to be paid. Any chance of a law like this in the United States? BOND: Well, I think that's the big concern here and why we're seeing Facebook act like this. You know, it doesn't want to capitulate in Australia, fearing that could set a precedent elsewhere. And we've heard from lawmakers in Canada and Europe who say they're open to this approach. You know, just last week, another U. S. tech giant, Microsoft, said it supports a version of the Australian law in the U. S. And I think there is concern that this is something that we could see here. But, you know, even if it's just in Australia, this has big consequences when it comes to misinformation. We know that's a big problem for Facebook. You know, it's talked about promoting accurate information, but now people in Australia can't post, you know, reputable news stories to counter false claims. INSKEEP: NPR tech correspondent Shannon Bond, thanks. BOND: Thanks, Steve.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-02-23-970300911": {"title": "Block Party Aims To Be A 'Spam Folder' For Social Media Harassment : NPR", "url": "https://www.npr.org/2021/02/23/970300911/block-party-aims-to-be-a-spam-folder-for-social-media-harassment", "author": "No author found", "published_date": "2021-02-23", "content": "", "section": "Technology", "disclaimer": ""}, "2021-02-23-970429807": {"title": "Facebook Reaches Deal Over News Content In Australia : NPR", "url": "https://www.npr.org/2021/02/23/970429807/facebook-restores-news-content-after-brokering-partial-deal-with-australian-regu", "author": "No author found", "published_date": "2021-02-23", "content": "", "section": "Technology", "disclaimer": ""}, "2021-02-25-971460327": {"title": "TikTok To Pay $92 Million To Settle Class-Action Suit Over 'Theft' Of Personal Data  : NPR", "url": "https://www.npr.org/2021/02/25/971460327/tiktok-to-pay-92-million-to-settle-class-action-suit-over-theft-of-personal-data", "author": "No author found", "published_date": "2021-02-25", "content": "", "section": "Technology", "disclaimer": ""}, "2021-02-25-971525832": {"title": "Stanford-Educated Software Engineer Develops App To Combat Online Abuse : NPR", "url": "https://www.npr.org/2021/02/25/971525832/stanford-educated-software-engineer-develops-app-to-combat-online-abuse", "author": "No author found", "published_date": "2021-02-25", "content": "ARI SHAPIRO, HOST:  Women and people of color are often the targets of harassment and abuse online, and that drives some to simply abandon platforms like Twitter and Facebook. Now, a software engineer is using her own experience of harassment to build tools that help people feel safer on social media. NPR tech correspondent Shannon Bond has more. SHANNON BOND, BYLINE: There's a saying in Silicon Valley - solve your own problems. And Tracy Chou sees plenty of problems in her social media feeds. TRACY CHOU: Everything from the casual mansplaining reply guys to really targeted persistent harassment and stalking and explicit threats that have led me to have to go to the police and file reports. Like, I've experienced a pretty wide range of this harassment. BOND: Chou is a Stanford-educated software engineer who's worked at tech companies like Pinterest and Quora. Along the way, she's become a leading advocate for diversity, pushing Silicon Valley companies to disclose how many - really, how few - women engineers they hire. And that's made her a big target of online harassment and even threats of violence, from Twitter to Facebook to Reddit. CHOU: I am so devoted to solving this problem because it is a personal one, and it's a pain that I live with literally every day. BOND: Chou's diversity work has also given her an inside understanding of why this kind of abuse is so persistent on social media. As she sees it, it's because the men - mainly white men - who founded, run and invest in most big tech companies, are less likely to experience harassment, so they fail to anticipate how these products could be misused. CHOU: They didn't prioritize safety solutions because they never needed them for themselves. BOND: And that's why Chou has created an app called Block Party. The idea is to give people more control over their experience on social media. You connect Block Party to your Twitter account, and it gives you a set of filters that you can use to decide what messages you want to see and what you don't. CHOU: So in some ways, it functions a bit like a spam folder. We don't pretend that doesn't exist. It still exists. It's there, but you can choose when to look at it. BOND: And that choice is key. Most social networks do provide tools to block, mute or report other users. Block Party makes that easier to do on users' own terms. Right now, it only works with Twitter, but Chou's ambition is to expand Block Party across social media. It's also designed to help deal with the worst abuse by letting people collect evidence of threats or stalking. That kind of documentation is really important for legal cases, like getting restraining orders, says Carrie Goldberg, a lawyer who represents people targeted by online abuse. CARRIE GOLDBERG: Any feature that collects the evidence and puts it somewhere, I am all for, especially if it means that a victim has control over when he or she looks at it. BOND: But Goldberg says she's also frustrated that Block Party needs to exist in the first place. She says the tech platforms should be on the hook for keeping their users safe. GOLDBERG: We shouldn't have to be farming that out to third party companies and putting the onus on the victim to have the software, figure out how to use it because it still is based on this premise that the abuse is inevitable. BOND: There's also the concern that a tool like this could exacerbate another problem of social media - the filter bubble, where people shut themselves off from views they disagree with. Chou says the idea of Block Party is not to filter out alternative perspectives, but to give users a break from the kind of toxic behavior that can turn them off social media entirely. CHOU: The people who often are disproportionately targeted for harassment are people that we really need to hear from. It's often women, minorities, people from marginalized backgrounds. These are the people who are being silenced, and that has pretty big consequences for all of our society. BOND: She says the biggest risk would be losing their voices from the online conversation. Shannon Bond, NPR News. (SOUNDBITE OF PSALM TREES' \"CALL WHENEVER\") ARI SHAPIRO, HOST:   Women and people of color are often the targets of harassment and abuse online, and that drives some to simply abandon platforms like Twitter and Facebook. Now, a software engineer is using her own experience of harassment to build tools that help people feel safer on social media. NPR tech correspondent Shannon Bond has more. SHANNON BOND, BYLINE: There's a saying in Silicon Valley - solve your own problems. And Tracy Chou sees plenty of problems in her social media feeds. TRACY CHOU: Everything from the casual mansplaining reply guys to really targeted persistent harassment and stalking and explicit threats that have led me to have to go to the police and file reports. Like, I've experienced a pretty wide range of this harassment. BOND: Chou is a Stanford-educated software engineer who's worked at tech companies like Pinterest and Quora. Along the way, she's become a leading advocate for diversity, pushing Silicon Valley companies to disclose how many - really, how few - women engineers they hire. And that's made her a big target of online harassment and even threats of violence, from Twitter to Facebook to Reddit. CHOU: I am so devoted to solving this problem because it is a personal one, and it's a pain that I live with literally every day. BOND: Chou's diversity work has also given her an inside understanding of why this kind of abuse is so persistent on social media. As she sees it, it's because the men - mainly white men - who founded, run and invest in most big tech companies, are less likely to experience harassment, so they fail to anticipate how these products could be misused. CHOU: They didn't prioritize safety solutions because they never needed them for themselves. BOND: And that's why Chou has created an app called Block Party. The idea is to give people more control over their experience on social media. You connect Block Party to your Twitter account, and it gives you a set of filters that you can use to decide what messages you want to see and what you don't. CHOU: So in some ways, it functions a bit like a spam folder. We don't pretend that doesn't exist. It still exists. It's there, but you can choose when to look at it. BOND: And that choice is key. Most social networks do provide tools to block, mute or report other users. Block Party makes that easier to do on users' own terms. Right now, it only works with Twitter, but Chou's ambition is to expand Block Party across social media. It's also designed to help deal with the worst abuse by letting people collect evidence of threats or stalking. That kind of documentation is really important for legal cases, like getting restraining orders, says Carrie Goldberg, a lawyer who represents people targeted by online abuse. CARRIE GOLDBERG: Any feature that collects the evidence and puts it somewhere, I am all for, especially if it means that a victim has control over when he or she looks at it. BOND: But Goldberg says she's also frustrated that Block Party needs to exist in the first place. She says the tech platforms should be on the hook for keeping their users safe. GOLDBERG: We shouldn't have to be farming that out to third party companies and putting the onus on the victim to have the software, figure out how to use it because it still is based on this premise that the abuse is inevitable. BOND: There's also the concern that a tool like this could exacerbate another problem of social media - the filter bubble, where people shut themselves off from views they disagree with. Chou says the idea of Block Party is not to filter out alternative perspectives, but to give users a break from the kind of toxic behavior that can turn them off social media entirely. CHOU: The people who often are disproportionately targeted for harassment are people that we really need to hear from. It's often women, minorities, people from marginalized backgrounds. These are the people who are being silenced, and that has pretty big consequences for all of our society. BOND: She says the biggest risk would be losing their voices from the online conversation. Shannon Bond, NPR News. (SOUNDBITE OF PSALM TREES' \"CALL WHENEVER\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-02-26-971506520": {"title": "Joy Buolamwini: How Do Biased Algorithms Damage Marginalized Communities? : NPR", "url": "https://www.npr.org/2021/02/26/971506520/joy-buolamwini-how-do-biased-algorithms-damage-marginalized-communities", "author": "No author found", "published_date": "2021-02-26", "content": "MANOUSH ZOMORODI, HOST:  It's the TED Radio Hour from NPR. I'm Manoush Zomorodi. In this hour, we have been honoring Black History Month with some of our favorite interviews from the past year, conversations about history and climate justice. And this next speaker is from our show about deception and misinformation, explaining how data and algorithms can warp our reality and discriminate, too. (SOUNDBITE OF ARCHIVED NPR BROADCAST)JOY BUOLAMWINI: We can deceive ourselves into thinking they're not doing harm, or we can fool ourselves into thinking, because it's based on numbers, that it is somehow neutral. AI is creeping into our lives. And even though the promise is that is going to be more efficient - it's going to be better - if what's happening is we're automating inequality through weapons of math destruction and we have algorithms of oppression, this promise is not actually true and certainly not true for everybody. (SOUNDBITE OF MUSIC)ZOMORODI: Weapons of math destruction, algorithms of oppression, which basically means bias and human error can be encoded into algorithms leading to inequality. To keep them in check, the Algorithmic Justice League to the rescue. BUOLAMWINI: My name is Joy Buolamwini. I'm the founder of the Algorithmic Justice League, where we use research and art to create a world with more equitable and accountable AI. You might have heard of the male gaze or the white gaze or the post-colonial gaze. To that lexicon, I add the coded gaze. And we want to make sure people are even aware of it because you can't fight the power you don't see, you don't know about. (SOUNDBITE OF MUSIC)ZOMORODI: Joy hunts down the flaws in the technology that's running every part of our lives, from deciding what we see on Instagram to how we might be sentenced for a crime. BUOLAMWINI: What happens when somebody is harmed by a system you created? You know, what happens if you're harmed? Where do you go? And we want that kind of place to be the Algorithmic Justice League, so you can seek redress for algorithmic harms. ZOMORODI: You are a lot of things. You're a poet. You're a computer scientist. You are a superhero. Like. . . (LAUGHTER)ZOMORODI: Kind of hard to put into a box. Can you just explain why you created the Algorithmic Justice League? BUOLAMWINI: Yes. So the Algorithmic Justice League is a bit of an accident. When I was in graduate school, I was working on an art project that used some computer vision technology to track my face. (SOUNDBITE OF ARCHIVED RECORDING)BUOLAMWINI: Hi, camera. I've got a face. Can you see my face? So at least that was the idea. (SOUNDBITE OF ARCHIVED RECORDING)BUOLAMWINI: You can see her face. What about my face? And when I'd try to get it to work on my face, I found that putting a white mask on my dark skin. . . (SOUNDBITE OF ARCHIVED RECORDING)BUOLAMWINI: Well, I've got a mask. . . . Is what I needed in order to have the system pick me up. And so that led to questions about, wait - are machines neutral? Why do I need to change myself to be seen by a machine? And if this is using AI techniques that are being used in other areas of our lives - whether it's health or education, transportation, the criminal justice system - what does it mean if different kinds of mistakes are being made? And also, even if these systems do work well - let's say you are able to track a face perfectly - what does that mean for surveillance? What does it mean for democracy, First Amendment rights, you know? ZOMORODI: Joy continues from the TED stage. (SOUNDBITE OF TED TALK)BUOLAMWINI: Across the U. S. , police departments are starting to use facial recognition software in their crime-fighting arsenal. Georgetown Law published a report showing that 1 in 2 adults in the U. S. - that's 117 million people - have their faces in facial recognition networks. Police departments can currently look at these networks unregulated, using algorithms that have not been audited for accuracy. Machine learning is being used for facial recognition, but it's also extending beyond the realm of computer vision. So who gets hired or fired? Do you get that loan? Do you get insurance? Are you admitted into the college that you wanted to get into? Do you and I pay the same price for the same product purchased on the same platform? Law enforcement is also starting to use machine learning for predictive policing. Some judges use machine-generated risk scores to determine how long an individual is going to spend in prison. So we really have to think about these decisions. Are they fair? And we've seen that algorithmic bias doesn't necessarily always lead to fair outcomes. When I think about algorithmic bias - and people ask me, well, what do you mean machines (laughter) are biased? It's just numbers. It's just data. I talk about machine learning. And it's a question of, well, what is the machine learning from? ZOMORODI: Well, what is the machine learning from? Like, what's the information that it's taking in? BUOLAMWINI: So an example of this - what I found was that for face detection, the ways in which systems were being trained involve collecting large data sets of images of human faces. And when you look at those data sets, I found that many of them were pale and male, right? You might have a dataset that's 75% male faces over 80% lighter-skin faces. And so what it means is the machine is learning a representation of the world that is skewed. And so what you might have thought should be a neutral process is actually reflecting the biases that it has been trained on. And sometimes what you're seeing is a skewed representation, but other times what machines are picking up on are our own societal biases that are actually treated as data. ZOMORODI: For example, Amazon was building a hiring tool. BUOLAMWINI: You need a job. Somebody in your life needs a job, right? You want to get hired. ZOMORODI: And to get hired, you upload your resume and your cover letter. BUOLAMWINI: That's the goal. It starts off well. ZOMORODI: But before a human looks at your resume, it gets vetted by algorithms written by software engineers. BUOLAMWINI: So we start off with an intent for efficiency. We have many more applications than any human could go through. Let's create a system that can do it more efficiently than we can. ZOMORODI: And how to build that better system? BUOLAMWINI: Well, we're going to gather data of resumes, and we're going to sort those resumes by the ones that represented candidates we hired or did well. Your target is who you think will be a good long-term employee. ZOMORODI: And now the system gets trained on the data. BUOLAMWINI: And the system is learning from prior data. So I like to say the past dwells within our algorithms. You don't have to have the sexist hiring manager in front of you. Now you have a black box that's serving as the gatekeeper. But what it's learning are the patterns of what success has looked like in the past. So if we're defining success by how it's looked like in the past and the past has been one where men were given opportunity, white people were given opportunity and you don't necessarily fit that profile, even though you might think you're creating this objective system, it's going through resumes - right? - this is where we run into problems. ZOMORODI: So here's what happened with Amazon's hiring tool. BUOLAMWINI: What happened was, as the model was being built and it was being tested, what they found was a gender bias where resumes that contained the word women or women's or even all-women's colleges - right? - so indication of being a woman were categorically being ranked lower than those that didn't. And try as they might, they were not able to remove that gender bias, so they ended up scratching the system. (SOUNDBITE OF RECORD SCRATCHING)ZOMORODI: They scratched the system, and that's a big win. But one win compared to thousands of platforms that use skewed algorithms - that could warp reality. BUOLAMWINI: It has not been the case that we've had universal equality or absolute equality, in the words of Frederick Douglass. And I especially worry about this when we think about techno benevolence in the space of health care, right? We're looking at, let's say, a breakthrough that comes in talking about skin cancer. Oh, we now have an AI system - right? - that can classify skin cancer as well as the top dermatologists, a study might say, a headline might read. And then when you look at it, it's like, oh, well, actually, when you look at the dataset, it was for lighter-skinned individuals. And then you might argue, well, you know, lighter-skinned people are more likely to get skin cancer. And when I was looking into this, it actually - darker-skinned people who get skin cancer, usually it's detected in stage 4 because there are all of these assumptions you're not even going to get it. . . ZOMORODI: Ah. BUOLAMWINI: . . . In the first place. So these assumptions can have meaningful consequences. ZOMORODI: Have you seen any examples of artificial intelligence being used in voting or politics? BUOLAMWINI: Yeah. So Channel 4 News just did this massive investigation showing that the 2016 Trump campaign targeted 3. 5 million African Americans in the United States, labeled them as deterrents in an attempt to actually keep people from showing up to the polls. ZOMORODI: They used targeted ads. BUOLAMWINI: Yes. And we know from Facebook's own research - right? - that you can influence voter turnout based on the kinds of posts that are put on their platform. And they did this in battleground states. And so in this way, we're seeing predictive modeling and ad targeting - right? - being used as a tool of voter suppression, which has always been the case to disenfranchise, right? You might say Black lives don't matter, but it's clear Black votes matter because of. . . ZOMORODI: Right. BUOLAMWINI: . . . So much effort used to rob people of what blood was spilt for, you know, for generations. So it should be the case - right? - that any sorts of algorithmic tools that are intended to be used, again, have to be verified for nondiscrimination before it's even adopted. ZOMORODI: So as a Black woman technologist, you know, there are not that many of you, frankly. Why not, you know, go work at Google or Amazon and make these changes to the algorithms directly? Why act as sort of a watchdog? BUOLAMWINI: Well, I think there are multiple ways to be involved in the ecosystem. But I do think this question you pose is really important because it can be an assumption that by changing who's in the room, which is important and needs to happen, we're going to then change the outcome and the outputs of these systems. So I like to remind people that most software developers, engineers, computer scientists - you don't build everything from scratch, right? You get reusable parts. And so if there's bias within those reusable parts or large-scale bias in the data sets that have become standard practice or the status quo - right? - changing the people who are involved in the system without changing the system itself is still going to reproduce algorithmic bias and algorithmic harms. ZOMORODI: So how do we build systems that are more fair? Like, if there's no data for the artificial intelligence to sort of, you know, process to start to pump out recommendations, then how do we even change that? BUOLAMWINI: Yeah. Well, it's a question of what tools do you use towards what objectives. So the first thing is seeing if this is the appropriate tool. Not every tool, not every decision, needs to be run through AI. And oftentimes, you also need to make sure you're being intentional. And so the kinds. . . ZOMORODI: Right. BUOLAMWINI: . . . Of changes you would need to make systematically for even who gets into the job pool in general - it means you do have to change society to change what AI is learning. ZOMORODI: What do you say, Joy, to people who might be listening and thinking, like, you know, let's take a step back and look at the bigger picture. We - in many ways, things are way better than they were thanks to technology because, you know, here we are in a pandemic, and anyone can work from anywhere because we have the Internet and we have Zoom and all of these platforms. Equality and access is on the whole improved. Why - let's not, like, be Debbie Downers about it. BUOLAMWINI: Yeah. I mean, I always ask who can afford to say that? Because I can tell you, the kids who are sitting in McDonald's parking lot so they can access the Internet to be able to attend school remotely, that has never been their reality. And so oftentimes, if you are able to say technology on the whole has done well, it probably means you're in a fairly privileged position. There's still a huge digital divide. Even - there are billions of people who don't have access to the Internet. I mean, I was born in Canada, moved to Ghana and then grew up in the U. S. I had very Western assumptions, you know, about what tech could do and very much excited to use the tech skills I gained as a undergrad at Georgia Tech, you know, to use tech for good, tech for the benefit of humanity. And so when I critique tech, it's really coming from a place of having been enamored with it and wanting it to live up to its promises. I don't think it's being a Debbie Downer to show ways in which we can improve so the promise of something we've created can actually be realized. I think that's even a more optimistic approach than to believe in a wishful thinking that is not true. ZOMORODI: You know, one thing that you've said that I find so - I love this idea - that you say there's a difference between potential and reality and that we must separate those two ideas. BUOLAMWINI: Yes. So it's so easy to fixate on our aspirations of what tech could be. And I think in some ways, it's this hope that we can transcend our own humanity - right? - our own failures. And so, yes, even if we haven't gotten society quite right, ideally, we can build technology that's better than we are. But we then have to look at that fact that technology reflects who we are. It doesn't transcend who we are. And so I think it's important that when we think about technology, we ask, what's the promise? What's the reality? And not only what's that gap, but who does it work for? Who does it benefit? Who does it harm and why? And also, how do we then step up and stand up to those harms? (SOUNDBITE OF MUSIC)ZOMORODI: That's Joy Buolamwini, founder of the Algorithmic Justice League. You can watch her full talk at ted. com. Thank you so much for listening to our show this week celebrating Black History Month. To learn more about the people who were on it and for more powerful stories and ideas from Black speakers, check out our Black History Month Playlist at ted. npr. org. And, of course, to see hundreds more TED talks, check out ted. com or the TED app. Our TED Radio production staff at NPR includes Jeff Rogers, Sanaz Meshkinpour, Rachel Faulkner, Diba Mohtasham, James Delahoussaye, J. C. Howard, Katie Monteleone, Maria Paz Gutierrez, Christina Cala, Matthew Cloutier and Farrah Safari, with help from Daniel Shukin. Our intern is Janet Woojeong Lee. Our theme music was written by Ramtin Arablouei. Our partners at TED are Chris Anderson, Colin Helms, Anna Phelan and Michelle Quint. I'm Manoush Zomorodi. And you've been listening to the TED Radio Hour from NPR. MANOUSH ZOMORODI, HOST:   It's the TED Radio Hour from NPR. I'm Manoush Zomorodi. In this hour, we have been honoring Black History Month with some of our favorite interviews from the past year, conversations about history and climate justice. And this next speaker is from our show about deception and misinformation, explaining how data and algorithms can warp our reality and discriminate, too. (SOUNDBITE OF ARCHIVED NPR BROADCAST) JOY BUOLAMWINI: We can deceive ourselves into thinking they're not doing harm, or we can fool ourselves into thinking, because it's based on numbers, that it is somehow neutral. AI is creeping into our lives. And even though the promise is that is going to be more efficient - it's going to be better - if what's happening is we're automating inequality through weapons of math destruction and we have algorithms of oppression, this promise is not actually true and certainly not true for everybody. (SOUNDBITE OF MUSIC) ZOMORODI: Weapons of math destruction, algorithms of oppression, which basically means bias and human error can be encoded into algorithms leading to inequality. To keep them in check, the Algorithmic Justice League to the rescue. BUOLAMWINI: My name is Joy Buolamwini. I'm the founder of the Algorithmic Justice League, where we use research and art to create a world with more equitable and accountable AI. You might have heard of the male gaze or the white gaze or the post-colonial gaze. To that lexicon, I add the coded gaze. And we want to make sure people are even aware of it because you can't fight the power you don't see, you don't know about. (SOUNDBITE OF MUSIC) ZOMORODI: Joy hunts down the flaws in the technology that's running every part of our lives, from deciding what we see on Instagram to how we might be sentenced for a crime. BUOLAMWINI: What happens when somebody is harmed by a system you created? You know, what happens if you're harmed? Where do you go? And we want that kind of place to be the Algorithmic Justice League, so you can seek redress for algorithmic harms. ZOMORODI: You are a lot of things. You're a poet. You're a computer scientist. You are a superhero. Like. . . (LAUGHTER) ZOMORODI: Kind of hard to put into a box. Can you just explain why you created the Algorithmic Justice League? BUOLAMWINI: Yes. So the Algorithmic Justice League is a bit of an accident. When I was in graduate school, I was working on an art project that used some computer vision technology to track my face. (SOUNDBITE OF ARCHIVED RECORDING) BUOLAMWINI: Hi, camera. I've got a face. Can you see my face? So at least that was the idea. (SOUNDBITE OF ARCHIVED RECORDING) BUOLAMWINI: You can see her face. What about my face? And when I'd try to get it to work on my face, I found that putting a white mask on my dark skin. . . (SOUNDBITE OF ARCHIVED RECORDING) BUOLAMWINI: Well, I've got a mask. . . . Is what I needed in order to have the system pick me up. And so that led to questions about, wait - are machines neutral? Why do I need to change myself to be seen by a machine? And if this is using AI techniques that are being used in other areas of our lives - whether it's health or education, transportation, the criminal justice system - what does it mean if different kinds of mistakes are being made? And also, even if these systems do work well - let's say you are able to track a face perfectly - what does that mean for surveillance? What does it mean for democracy, First Amendment rights, you know? ZOMORODI: Joy continues from the TED stage. (SOUNDBITE OF TED TALK) BUOLAMWINI: Across the U. S. , police departments are starting to use facial recognition software in their crime-fighting arsenal. Georgetown Law published a report showing that 1 in 2 adults in the U. S. - that's 117 million people - have their faces in facial recognition networks. Police departments can currently look at these networks unregulated, using algorithms that have not been audited for accuracy. Machine learning is being used for facial recognition, but it's also extending beyond the realm of computer vision. So who gets hired or fired? Do you get that loan? Do you get insurance? Are you admitted into the college that you wanted to get into? Do you and I pay the same price for the same product purchased on the same platform? Law enforcement is also starting to use machine learning for predictive policing. Some judges use machine-generated risk scores to determine how long an individual is going to spend in prison. So we really have to think about these decisions. Are they fair? And we've seen that algorithmic bias doesn't necessarily always lead to fair outcomes. When I think about algorithmic bias - and people ask me, well, what do you mean machines (laughter) are biased? It's just numbers. It's just data. I talk about machine learning. And it's a question of, well, what is the machine learning from? ZOMORODI: Well, what is the machine learning from? Like, what's the information that it's taking in? BUOLAMWINI: So an example of this - what I found was that for face detection, the ways in which systems were being trained involve collecting large data sets of images of human faces. And when you look at those data sets, I found that many of them were pale and male, right? You might have a dataset that's 75% male faces over 80% lighter-skin faces. And so what it means is the machine is learning a representation of the world that is skewed. And so what you might have thought should be a neutral process is actually reflecting the biases that it has been trained on. And sometimes what you're seeing is a skewed representation, but other times what machines are picking up on are our own societal biases that are actually treated as data. ZOMORODI: For example, Amazon was building a hiring tool. BUOLAMWINI: You need a job. Somebody in your life needs a job, right? You want to get hired. ZOMORODI: And to get hired, you upload your resume and your cover letter. BUOLAMWINI: That's the goal. It starts off well. ZOMORODI: But before a human looks at your resume, it gets vetted by algorithms written by software engineers. BUOLAMWINI: So we start off with an intent for efficiency. We have many more applications than any human could go through. Let's create a system that can do it more efficiently than we can. ZOMORODI: And how to build that better system? BUOLAMWINI: Well, we're going to gather data of resumes, and we're going to sort those resumes by the ones that represented candidates we hired or did well. Your target is who you think will be a good long-term employee. ZOMORODI: And now the system gets trained on the data. BUOLAMWINI: And the system is learning from prior data. So I like to say the past dwells within our algorithms. You don't have to have the sexist hiring manager in front of you. Now you have a black box that's serving as the gatekeeper. But what it's learning are the patterns of what success has looked like in the past. So if we're defining success by how it's looked like in the past and the past has been one where men were given opportunity, white people were given opportunity and you don't necessarily fit that profile, even though you might think you're creating this objective system, it's going through resumes - right? - this is where we run into problems. ZOMORODI: So here's what happened with Amazon's hiring tool. BUOLAMWINI: What happened was, as the model was being built and it was being tested, what they found was a gender bias where resumes that contained the word women or women's or even all-women's colleges - right? - so indication of being a woman were categorically being ranked lower than those that didn't. And try as they might, they were not able to remove that gender bias, so they ended up scratching the system. (SOUNDBITE OF RECORD SCRATCHING) ZOMORODI: They scratched the system, and that's a big win. But one win compared to thousands of platforms that use skewed algorithms - that could warp reality. BUOLAMWINI: It has not been the case that we've had universal equality or absolute equality, in the words of Frederick Douglass. And I especially worry about this when we think about techno benevolence in the space of health care, right? We're looking at, let's say, a breakthrough that comes in talking about skin cancer. Oh, we now have an AI system - right? - that can classify skin cancer as well as the top dermatologists, a study might say, a headline might read. And then when you look at it, it's like, oh, well, actually, when you look at the dataset, it was for lighter-skinned individuals. And then you might argue, well, you know, lighter-skinned people are more likely to get skin cancer. And when I was looking into this, it actually - darker-skinned people who get skin cancer, usually it's detected in stage 4 because there are all of these assumptions you're not even going to get it. . . ZOMORODI: Ah. BUOLAMWINI: . . . In the first place. So these assumptions can have meaningful consequences. ZOMORODI: Have you seen any examples of artificial intelligence being used in voting or politics? BUOLAMWINI: Yeah. So Channel 4 News just did this massive investigation showing that the 2016 Trump campaign targeted 3. 5 million African Americans in the United States, labeled them as deterrents in an attempt to actually keep people from showing up to the polls. ZOMORODI: They used targeted ads. BUOLAMWINI: Yes. And we know from Facebook's own research - right? - that you can influence voter turnout based on the kinds of posts that are put on their platform. And they did this in battleground states. And so in this way, we're seeing predictive modeling and ad targeting - right? - being used as a tool of voter suppression, which has always been the case to disenfranchise, right? You might say Black lives don't matter, but it's clear Black votes matter because of. . . ZOMORODI: Right. BUOLAMWINI: . . . So much effort used to rob people of what blood was spilt for, you know, for generations. So it should be the case - right? - that any sorts of algorithmic tools that are intended to be used, again, have to be verified for nondiscrimination before it's even adopted. ZOMORODI: So as a Black woman technologist, you know, there are not that many of you, frankly. Why not, you know, go work at Google or Amazon and make these changes to the algorithms directly? Why act as sort of a watchdog? BUOLAMWINI: Well, I think there are multiple ways to be involved in the ecosystem. But I do think this question you pose is really important because it can be an assumption that by changing who's in the room, which is important and needs to happen, we're going to then change the outcome and the outputs of these systems. So I like to remind people that most software developers, engineers, computer scientists - you don't build everything from scratch, right? You get reusable parts. And so if there's bias within those reusable parts or large-scale bias in the data sets that have become standard practice or the status quo - right? - changing the people who are involved in the system without changing the system itself is still going to reproduce algorithmic bias and algorithmic harms. ZOMORODI: So how do we build systems that are more fair? Like, if there's no data for the artificial intelligence to sort of, you know, process to start to pump out recommendations, then how do we even change that? BUOLAMWINI: Yeah. Well, it's a question of what tools do you use towards what objectives. So the first thing is seeing if this is the appropriate tool. Not every tool, not every decision, needs to be run through AI. And oftentimes, you also need to make sure you're being intentional. And so the kinds. . . ZOMORODI: Right. BUOLAMWINI: . . . Of changes you would need to make systematically for even who gets into the job pool in general - it means you do have to change society to change what AI is learning. ZOMORODI: What do you say, Joy, to people who might be listening and thinking, like, you know, let's take a step back and look at the bigger picture. We - in many ways, things are way better than they were thanks to technology because, you know, here we are in a pandemic, and anyone can work from anywhere because we have the Internet and we have Zoom and all of these platforms. Equality and access is on the whole improved. Why - let's not, like, be Debbie Downers about it. BUOLAMWINI: Yeah. I mean, I always ask who can afford to say that? Because I can tell you, the kids who are sitting in McDonald's parking lot so they can access the Internet to be able to attend school remotely, that has never been their reality. And so oftentimes, if you are able to say technology on the whole has done well, it probably means you're in a fairly privileged position. There's still a huge digital divide. Even - there are billions of people who don't have access to the Internet. I mean, I was born in Canada, moved to Ghana and then grew up in the U. S. I had very Western assumptions, you know, about what tech could do and very much excited to use the tech skills I gained as a undergrad at Georgia Tech, you know, to use tech for good, tech for the benefit of humanity. And so when I critique tech, it's really coming from a place of having been enamored with it and wanting it to live up to its promises. I don't think it's being a Debbie Downer to show ways in which we can improve so the promise of something we've created can actually be realized. I think that's even a more optimistic approach than to believe in a wishful thinking that is not true. ZOMORODI: You know, one thing that you've said that I find so - I love this idea - that you say there's a difference between potential and reality and that we must separate those two ideas. BUOLAMWINI: Yes. So it's so easy to fixate on our aspirations of what tech could be. And I think in some ways, it's this hope that we can transcend our own humanity - right? - our own failures. And so, yes, even if we haven't gotten society quite right, ideally, we can build technology that's better than we are. But we then have to look at that fact that technology reflects who we are. It doesn't transcend who we are. And so I think it's important that when we think about technology, we ask, what's the promise? What's the reality? And not only what's that gap, but who does it work for? Who does it benefit? Who does it harm and why? And also, how do we then step up and stand up to those harms? (SOUNDBITE OF MUSIC) ZOMORODI: That's Joy Buolamwini, founder of the Algorithmic Justice League. You can watch her full talk at ted. com. Thank you so much for listening to our show this week celebrating Black History Month. To learn more about the people who were on it and for more powerful stories and ideas from Black speakers, check out our Black History Month Playlist at ted. npr. org. And, of course, to see hundreds more TED talks, check out ted. com or the TED app. Our TED Radio production staff at NPR includes Jeff Rogers, Sanaz Meshkinpour, Rachel Faulkner, Diba Mohtasham, James Delahoussaye, J. C. Howard, Katie Monteleone, Maria Paz Gutierrez, Christina Cala, Matthew Cloutier and Farrah Safari, with help from Daniel Shukin. Our intern is Janet Woojeong Lee. Our theme music was written by Ramtin Arablouei. Our partners at TED are Chris Anderson, Colin Helms, Anna Phelan and Michelle Quint. I'm Manoush Zomorodi. And you've been listening to the TED Radio Hour from NPR.", "section": "TED Radio Hour", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-02-26-971429736": {"title": "Reading The Game: 'The Last Of Us Part 2' : NPR", "url": "https://www.npr.org/2021/02/26/971429736/reading-the-game-the-last-of-us-part-2", "author": "No author found", "published_date": "2021-02-26", "content": "", "section": "Reading The Game", "disclaimer": ""}, "2021-02-26-971681198": {"title": "Users Report 'Drunken' Roombas After Software Update : NPR", "url": "https://www.npr.org/2021/02/26/971681198/users-report-drunken-roombas-after-software-update", "author": "No author found", "published_date": "2021-02-26", "content": "RACHEL MARTIN, HOST:  Good morning. I'm Rachel Martin. Are you wandering the house aimlessly feeling like you're going in circles, barely even functioning? Well, you might be burned out, or you might be a Roomba. The robotic vacuums got a software update, and Roomba owners say the machines seem drunk. They're hitting furniture and struggling to find their charging stations. The Verge reports it could take weeks to fix. Until then, give your vacuum some time off. We all need it. Happy Friday. It's MORNING EDITION. RACHEL MARTIN, HOST:   Good morning. I'm Rachel Martin. Are you wandering the house aimlessly feeling like you're going in circles, barely even functioning? Well, you might be burned out, or you might be a Roomba. The robotic vacuums got a software update, and Roomba owners say the machines seem drunk. They're hitting furniture and struggling to find their charging stations. The Verge reports it could take weeks to fix. Until then, give your vacuum some time off. We all need it. Happy Friday. It's MORNING EDITION.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-02-26-971367875": {"title": "Why Is Facebook Going All-Out To Stop Apple's iPhone Update? : NPR", "url": "https://www.npr.org/2021/02/26/971367875/why-is-facebook-launching-an-all-out-war-on-apples-upcoming-iphone-update", "author": "No author found", "published_date": "2021-02-26", "content": "RACHEL MARTIN, HOST:  Facebook and Apple are at war. A fight between the tech giants is heating up over how our phone habits are monitored. The outcome could shape the future of online data privacy. NPR's Bobby Allyn reports. And just a note here - both companies are financial supporters of NPR. BOBBY ALLYN, BYLINE: In the coming weeks, Apple will be sending iPhone users an alert with a question. Are you OK with apps tracking what you're doing and sharing it with other companies? You can say yes, and nothing will change. Or you can opt out. At a recent tech conference, Apple CEO Tim Cook said giving people that option is out of concern for their privacy. (SOUNDBITE OF ARCHIVED RECORDING)TIM COOK: It seems no piece of information is too private or personal to be surveilled, monetized and aggregated into a 360 degree view of your life. ALLYN: Nobody knows this better than Facebook, which gets 98% percent of its revenue from advertising. Personalize ads, a big moneymaker, are driven by data tracking on phones. Facebook CEO Mark Zuckerberg has for years been defending the data instead of paying business model. Here's Zuckerberg talking in 2018 to Vox, responding to criticism back then from Apple CEO Tim Cook. (SOUNDBITE OF ARCHIVED RECORDING)MARK ZUCKERBERG: I find that argument, that if you're not paying that somehow we can't care about you, to be extremely glib and not at all aligned with the truth. ALLYN: But Cook says invasively tracking people is indefensible. It's a message that resonates with critics of Silicon Valley worried about so-called surveillance capitalism. JORDAN FISCHER: We have an application like Facebook that's really driven by collecting data and harnessing the value of that data. ALLYN: Jordan Fischer is a law professor at Drexel University. FISCHER: And then we have Apple, which is almost becoming this gatekeeper function for applications and saying, we're going to mandate a certain minimum level of privacy. And they're clashing because they don't necessarily work in the same world. ALLYN: The stakes for the digital economy are so high that Facebook has launched an all-out campaign to stop Apple. It has taken to radio and TV to say the change will hurt small businesses. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED MUSICAL ARTIST: (Rapping) But many are small businesses that simply lack the tool to find excited people who will stop and say. . . UNIDENTIFIED PERSON: That's cool. ALLYN: Facebook says this ad is about people like Monique Wilsondebriano. She owns the Charleston Gourmet Burger Company in South Carolina. When her business first started, she couldn't afford TV or radio ads but was able to drum up interest on Facebook. MONIQUE WILSONDEBRIANO: Ninety percent of our customers are finding us because of Facebook, because of those personalized ads. And so if something was to disrupt that, (laughter) you know, it's going to be a problem. ALLYN: A problem, she says, because it'll be harder to reach current and future customers. Facebook's director of privacy and public policy, Steve Satterfield, says making ads less targeted will make them less useful and generate less money. He says that could force apps to turn to subscription models, where Apple usually takes a 30% cut. STEVE SATTERFIELD: This discouragement, this is going to have a real impact on the Internet as we know it, which is increasingly going to move to a paid experience, which, again, benefits Apple's bottom line. ALLYN: Apple denies its move is driven by self-interest. The company says it is giving iPhone owners more control over the data third parties are collecting. Back at the tech conference, Cook didn't save Facebook by name. But in talking about a tech company's business model run amok, his target was clear. (SOUNDBITE OF ARCHIVED RECORDING)COOK: At a moment of rampant disinformation and conspiracy theories juiced by algorithms, we can no longer turn a blind eye to a theory of technology that says all engagement is good engagement. ALLYN: Cook was speaking just weeks after the January 6 siege on the Capitol. Many rioters organized on Facebook. Bobby Allyn, NPR News, San Francisco. (SOUNDBITE OF AMBINATE'S \"DIVIDE\") RACHEL MARTIN, HOST:   Facebook and Apple are at war. A fight between the tech giants is heating up over how our phone habits are monitored. The outcome could shape the future of online data privacy. NPR's Bobby Allyn reports. And just a note here - both companies are financial supporters of NPR. BOBBY ALLYN, BYLINE: In the coming weeks, Apple will be sending iPhone users an alert with a question. Are you OK with apps tracking what you're doing and sharing it with other companies? You can say yes, and nothing will change. Or you can opt out. At a recent tech conference, Apple CEO Tim Cook said giving people that option is out of concern for their privacy. (SOUNDBITE OF ARCHIVED RECORDING) TIM COOK: It seems no piece of information is too private or personal to be surveilled, monetized and aggregated into a 360 degree view of your life. ALLYN: Nobody knows this better than Facebook, which gets 98% percent of its revenue from advertising. Personalize ads, a big moneymaker, are driven by data tracking on phones. Facebook CEO Mark Zuckerberg has for years been defending the data instead of paying business model. Here's Zuckerberg talking in 2018 to Vox, responding to criticism back then from Apple CEO Tim Cook. (SOUNDBITE OF ARCHIVED RECORDING) MARK ZUCKERBERG: I find that argument, that if you're not paying that somehow we can't care about you, to be extremely glib and not at all aligned with the truth. ALLYN: But Cook says invasively tracking people is indefensible. It's a message that resonates with critics of Silicon Valley worried about so-called surveillance capitalism. JORDAN FISCHER: We have an application like Facebook that's really driven by collecting data and harnessing the value of that data. ALLYN: Jordan Fischer is a law professor at Drexel University. FISCHER: And then we have Apple, which is almost becoming this gatekeeper function for applications and saying, we're going to mandate a certain minimum level of privacy. And they're clashing because they don't necessarily work in the same world. ALLYN: The stakes for the digital economy are so high that Facebook has launched an all-out campaign to stop Apple. It has taken to radio and TV to say the change will hurt small businesses. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED MUSICAL ARTIST: (Rapping) But many are small businesses that simply lack the tool to find excited people who will stop and say. . . UNIDENTIFIED PERSON: That's cool. ALLYN: Facebook says this ad is about people like Monique Wilsondebriano. She owns the Charleston Gourmet Burger Company in South Carolina. When her business first started, she couldn't afford TV or radio ads but was able to drum up interest on Facebook. MONIQUE WILSONDEBRIANO: Ninety percent of our customers are finding us because of Facebook, because of those personalized ads. And so if something was to disrupt that, (laughter) you know, it's going to be a problem. ALLYN: A problem, she says, because it'll be harder to reach current and future customers. Facebook's director of privacy and public policy, Steve Satterfield, says making ads less targeted will make them less useful and generate less money. He says that could force apps to turn to subscription models, where Apple usually takes a 30% cut. STEVE SATTERFIELD: This discouragement, this is going to have a real impact on the Internet as we know it, which is increasingly going to move to a paid experience, which, again, benefits Apple's bottom line. ALLYN: Apple denies its move is driven by self-interest. The company says it is giving iPhone owners more control over the data third parties are collecting. Back at the tech conference, Cook didn't save Facebook by name. But in talking about a tech company's business model run amok, his target was clear. (SOUNDBITE OF ARCHIVED RECORDING) COOK: At a moment of rampant disinformation and conspiracy theories juiced by algorithms, we can no longer turn a blind eye to a theory of technology that says all engagement is good engagement. ALLYN: Cook was speaking just weeks after the January 6 siege on the Capitol. Many rioters organized on Facebook. Bobby Allyn, NPR News, San Francisco. (SOUNDBITE OF AMBINATE'S \"DIVIDE\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-03-01-971436680": {"title": "Disinformation Fuels Distrust At All Levels Of Government : NPR", "url": "https://www.npr.org/2021/03/01/971436680/from-the-u-s-capitol-to-local-governments-disinformation-disrupts", "author": "No author found", "published_date": "2021-03-01", "content": "", "section": "Untangling Disinformation", "disclaimer": ""}, "2021-03-02-973083119": {"title": "Former Parler CEO Matze Stripped Of All Company Shares Upon Firing, Sources Say : NPR", "url": "https://www.npr.org/2021/03/02/973083119/former-parler-ceo-matze-stripped-of-all-company-shares-upon-firing-sources-say", "author": "No author found", "published_date": "2021-03-02", "content": "", "section": "Technology", "disclaimer": ""}, "2021-03-02-972837924": {"title": "How Bellingcat's Online Sleuths Solve Global Crimes Using Open Source Info  : NPR", "url": "https://www.npr.org/2021/03/02/972837924/how-bellingcats-online-sleuths-solve-global-crimes-using-open-source-info", "author": "No author found", "published_date": "2021-03-02", "content": "TERRY GROSS, HOST:  This is FRESH AIR. I'm Terry Gross. Crowdsourcing has created a new form of online open-source investigation, as epitomized by the group Bellingcat that was founded by my guest, Eliot Higgins, in 2014. Higgins and people affiliated with Bellingcat, while at their computers, have uncovered evidence that Syrian dictator Bashar al-Assad fired chemical weapons at his own people, figured out who controlled territory during the Libyan civil war, identified the Russian intelligence agents alleged to have poisoned MI6 double agent Sergei Skripal and his daughter Yulia and found evidence that the 22-year-old woman alleged to have stolen Nancy Pelosi's laptop on January 6 was a neo-Nazi sympathizer who used coded neo-Nazi language in a video and in that video gave the Heil Hitler salute. Bellingcat has identified the perpetrators of hate crimes and how extremists use mainstream websites to divert people to extremist sites that sell neo-Nazi merchandise and ask for donations to continue doing their work. The clues used by Bellingcat come from openly available sources on the Internet, like social media posts, leaked databases and free satellite maps. Bellingcat has a core team of 18 staffers that works with scores of volunteers around the globe. The group has worked on investigations with media organizations, including The New York Times, NBC News and the BBC, as well as human rights groups. Eliot Higgins has written a new book called \"We Are Bellingcat: Global Crime, Online Sleuths, And The Bold Future Of News. \"Eliot Higgins, welcome to FRESH AIR. Let's start with a recent discovery by Bellingcat that the 22-year-old woman who allegedly stole Nancy Pelosi's laptop made a video using neo-Nazi coded words and giving the Heil Hitler salute. But in the video, the woman is disguised by a full face mask, so her face couldn't be identified. Bellingcat got a tip that this video was hers. This was a tip from an anti-fascist activist. But Bellingcat had to confirm that this really was hers. And without a face to confirm it, that was a tricky thing to do. And I should mention, if you look for this video online - the last time I saw it was last night. And as of then, the audio was unavailable because there's techno music underneath her, and the publisher - I think it's the publisher of that music had the audio removed, I think for copyright reasons, or maybe just 'cause they didn't want that music associated with a neo-Nazi. ELIOT HIGGINS: Indeed, yes. GROSS: Yes, OK. So describe how you were able to verify that the disguised woman in this video was the same woman alleged to have stolen Nancy Pelosi's computer on January 6. HIGGINS: So it was really a case of piecing together a variety of clues that were available online. There was a original video that showed her doing the salute. There was also then another photograph that was shared with us by these researchers. It shows a woman wearing a skull face mask that is identical to the one that's in the video, wearing the same dress as well. And we saw in that picture, she's wearing a pair of glasses that match exactly to the glasses that she wears in other photographs where her face is fully visible, which is one of the clues that we were using. But we started looking at other details as well. Even though her whole face is covered, there are some things that are actually visible. For example, a tattoo is visible. And that tattoo actually turns up in another video she did for a forum called Kiwi Farms, where it was adult material, basically, so it was possible to see tattoos and other parts of her body, including the one that matched. And also, to be 100% sure, there's actually a couple of features visible in that Kiwi Farms video that's visible in the video we were looking into, including, for example, very unique light fixtures and other details that allowed us to match the room she was in in the Kiwi Farms video, where she's clearly identifiable, to the room she's in in the original video, where she's making neo-Nazi-related statements. So by kind of piecing together all these really minor clues, it's actually possible to establish her identity, even though in the original video, her face is covered and her eyes are covered. GROSS: And there's several neo-Nazi symbols in this video, in addition to her giving the Heil Hitler salute. So what are some of the symbols? Like, interpret them for us. HIGGINS: In the background, there's actually a book about the SS that is displayed, clearly on purpose, to be visible on camera. She's wearing a hat as well that has a symbol that's associated with neo-Nazi groups as well. Some of the stuff she's actually purchased is from people who associate themselves with the far-right and neo-Nazis. So there's kind of a whole range of different objects in there that are identifiable beyond just what she's saying and the salute that she's giving. GROSS: And a narrator in the video says, Hammer was right all along. There is no political solution. All that is left is acceleration. HIGGINS: That's right. And the Hammer is a neo-Nazi figure who advocates followers to partake in things like things called banner drops and spraying graffiti to spread their message. So a lot of what she's kind of - the language she's using is very specific to a very specific kind of subset of the alt-right, kind of far-right and neo-Nazis. So it probably, you know, wouldn't make much context to, you know, the average person. But because our researchers have spent a lot of time in these communities understanding the kind of language of these communities, the kind of key figures in these communities and how they're spoken about, it allows us to kind of draw these conclusions about what was visible in these videos. GROSS: And doesn't acceleration also refer to accelerating the U. S. becoming a white nation? HIGGINS: Yeah. I mean, for many of the people who kind of use that terminology, that's what they're moving towards. Weirdly, there are some groups who kind of actually don't want that but still have that same idea that what they want can be achieved through another civil war. So there's kind of all these kind of weird little groups online that really would like another civil war. And, unfortunately, quite a few of them are quite keen to make that happen by, you know, having real-world activity that will lead to violence and what they hope will be even more violence. GROSS: So in the case of the 22-year-old woman who is alleged to have stolen Nancy Pelosi's computer, and now you've shown that she made a video with all kinds of coded neo-Nazi language, and she gave the Heil Hitler salute, what is the significance of unmasking her in that video? HIGGINS: Well, it shows that there's kind of more to these people, you know, who made up this group at the Capitol than, you know, just what can be discovered through kind of normal investigation. And, you know, what they, you know, are seeking in the future kind of informs their - you know, what they were doing on the ground on that day. You know, there was a whole range of different groups that made up the crowd on January 6. You know, some were fairly innocuous who were just kind of caught up in the violence. But some of them went there with long histories of political violence with the intention of targeting not only the building, but the people inside that building. And I think, you know, by looking at these individuals, it does give you a real sense of the sort of people who were involved with this. You can't just dismiss them as one big group of Trump supporters because there was a whole range of different people within those groups who were, you know, mad about, you know, one thing or another, and they had all been brought together in one space. And in many senses, this is what's happening in the online spaces as well. You're seeing these kind of very fairly disparate groups that are united under one issue. And in the case of what was happening on January 6, that was the count of the votes and, you know, Trump. But they're coming from kind of different perspectives on it, but they're kind of all coming together under these single ideas. And that's where we're starting to see more and more violence. And, unfortunately, there are politicians who don't recognize that, or if they do recognize it, they still try to use these people to build their own base of power. And until politicians stop doing that, that is going to lead to more and more violence in the U. S. and elsewhere in the world. GROSS: If you're just joining us, my guest is Eliot Higgins, founder of the online investigative group Bellingcat. His new book is called \"We Are Bellingcat. \" We'll be right back after a break. This is FRESH AIR. (SOUNDBITE OF MUSIC)GROSS: This is FRESH AIR. Let's get back to my interview with Eliot Higgins, founder of the group Bellingcat, which conducts investigative journalism, relying on open-source media on the Internet, like social media posts, leak databases and free satellite maps. Bellingcat has a team of about 18 staffers that works with scores of volunteers around the globe. He's written a new book called \"We Are Bellingcat. \"So let's talk about one of the first things that you uncovered as a digital investigator back in 2011, before you even founded Bellingcat. This was three years before you founded it. And it has to do with disputed territory during the Libyan Civil War. What was the question that you wanted to be able to answer? HIGGINS: So I think called me additional investigator. I think that's a nice title for someone who was basically just spending their time online, arguing with people on the Internet because I was just, like, your average Internet user back in 2011. But I was very interested in what was happening in the conflict in Libya. Spent my time on forums and websites like The Guardian newspaper's Middle East live blog, arguing with people about what was happening there. You know, stuff was being posted online, and some people say, no, that's fake; it can't be true. And you have people say, well, there's this that shows it's true. But there's no really kind of approach to verifying this kind of stuff, and I found that very frustrating because I was interested in what was actually happening, rather than having kind of politically biased arguments around, you know, different aspects of, you know, what was happening in the conflict. So one day, this video was shared online, and it showed rebels in Libya claiming to be in this town called Teji. And Teji was interesting because it was beyond the front-line positions that people knew they were already fighting in. So it kind of represents, you know, progression in the conflict. So there's lots of kind of arguments and debates about what had actually happened. You know, some people said, well, how do you know where this was filmed? If this isn't Teji, how do you know where this is filmed? And I had the idea of, why don't I go to satellite imagery and see if I can find Teji on the satellite image and then watch the video and look for features that might be visible. And in that video, there was a tank rolling down these two lanes of a road next to a mosque with a dome and a minaret. So I look for that on satellite imagery, and I found the road and followed it along, and there was a mosque with a dome and a minaret. And I watched the video again, and this time I looked for smaller features, like the walls and the way the pavement curved. And that was visible on the satellite imagery, too. And then I looked for utility poles, and those utility poles were there as well. And I realized I could confirm exactly where this had been filmed and then kind of share that rather smugly on the comments of the live blogs - say, ha, I found it. GROSS: (Laughter). HIGGINS: But that was kind of my first realization that you can actually look at these videos and figure out exactly where they were filmed and get a much more accurate and verifiable view on the conflict. And that really set me off doing what I now do, you know, as my career. GROSS: So it must have been remarkable to you that being at your office job in England, you were able to solve a question, to factually answer a question about what was happening in a conflict zone in Libya. HIGGINS: Yeah, and there was kind of more stuff I started noticing as well. I became very frustrated by the fact that there would be journalists on the ground in Libya and they'd go somewhere and, like, tweet about it, but they wouldn't do a story on it because it wasn't the story that they were looking to file that day. But when you started looking at, you know, those tweets and posts and bits of information from different journalists and people on the ground, you started seeing patterns. And you could start saying, OK, there's something going on in this location. You know, can I piece together what it is? And one of those cases was when the rebels in a place called Misrata, pushed south out of the town towards Gadhafi's hometown, along a coastal route. There was one town that was just off the coastal route. And the journalists who were going, you know, with the rebels back and forth to Gadhafi's hometown, hoping they'd, you know, get to interview Gadhafi, were driving past this town every day. And one of them, you know, one day would tweet, all the rebels are firing artillery into this town. It was called Tawergha. And then someone else would say, oh, Tawergha is on fire tonight. But they wouldn't write a story about it because the story was Gadhafi, not this town that was off the road they were driving by. But by kind of looking at all these individual kind of comments that were coming up, it seemed very clear something bad was happening in that town because it was a pro-Gadhafi town. And, you know, the rebels had been stuck in Misrata for a long time. And eventually, when Gadhafi was killed and journalists went to that town, they discovered that, in fact, the town had effectively been ethnically cleansed. And they had to observe that from a distance, but because they had that kind of single point of view on what was happening and this other focus, it was basically lost. And I realized then you could kind of combine all these different sources and actually start getting a real impression of what was happening in these conflict zones, along with this verified video and photographic content. GROSS: So you were basically almost like a war correspondent sitting at your computer in England. HIGGINS: That's right. And it was - it still as well was just, really, you know, about, you know, talking to people on the Internet and arguing with them and, you know, debating the facts of what was going on. But then in early 2012, I decided as a hobby to start a blog, which I called the Brown Moses Blog after a Frank Zappa song I'd been listening to when I started using that name as my kind of online pseudonym. And that was basically my style of writing about the conflict in Syria, which really started leading me into kind of becoming more professional about the kind of work I was doing. GROSS: What do you think your best scoop, so to speak, was on the Syrian Civil War? HIGGINS: There were a few, but the first really big one was - I basically couldn't speak any Arabic, so I was watching all these videos from Syria. I realized they were being shared on the same thousand or so YouTube channels every day that belonged to Syrian opposition groups, you know, media centers, those kind of things. It wasn't like an open Internet; it was, like, very restricted. But there were still lots of videos coming through of the conflict. And by doing that, I started to learn what the weapons were being used in the conflicts and writing about that. And I kind of taught myself what they were, started having arms experts approaching me, asking me questions about these videos and being part of these communities where these questions were discussed. So I was the first person, I think, to find the videos of cluster bombs being used, which I shared with Human Rights Watch, who did a piece on it. I was the first person to find, I think, a video of a barrel bomb, as they became known, these improvised explosive devices. And then in early 2013, I started seeing new weapons coming into the conflict from - I didn't recognize them. I knew all the weapons in this conflict. I just, like, every day watched videos and figured out what they were by using various online sources. But these were brand new and really weird looking. And eventually, I discovered they were from the former Yugoslavia. And by that point, I knew a journalist at The New York Times, and I kind of show this to him, and he went off and came back and said, actually, this is the Saudi's secret smuggling operation to the rebels in the south of Syria. And I had managed to discover this secret operation by watching YouTube videos intensively. And that ended up being on the front page of The New York Times, and that was kind of the first moment when I started getting, like, a really big amount of media attention. I had, like, Channel 4 News in the U. K. , Germany ARD Television, CNN - every day a different news organization would come to my house and film me (laughter). You know, this kind of - CNN said I was a stay-at-home Mr. Mom who found chemical weapons from his sofa and stuff like that. So it was a very weird experience for me, going from this kind of unknown person to suddenly someone who was on kind of CNN, talking about their work as this kind of - almost like a novelty act. But it was - it really then kind of took off from there. And then in August 2013, I did a lot of work on the chemical weapons attacks in Damascus, figured out a whole bunch of stuff about that and ended up kind of quite publicly contradicting the work of Seymour Hersh after he tried to say it was Turkey providing sarin to the rebels, when the content I found pointed to that being completely ridiculous, and that kind of then gave me another really big boost towards the eventual launch of Bellingcat in 2014. GROSS: And you found that it was the Assad regime that was responsible for the sarin gas attacks? HIGGINS: Yes, because I had been - you know, by that point, spent the last 18 months watching every video and looking at every region I could find from Syria. And there were these really weird munitions that had been turning up in some occasional attacks that seemed like chemical attacks. There was a video posted in early August where there was one of these weird tubular rocket things next to a dog that was kind of twitching and foaming from the mouth, a cat that also had been foaming from the mouth. And these same rockets turned up on August 21, loaded with sarin. And because I kind of had this knowledge of these videos, I could show videos of not only these rockets being used in previous attacks that had kind of missed the attention of the world's media, but also explosive variants of these same rockets that were very unique being used by Syrian government forces in videos posted online by pro-Syrian government accounts. So it was undeniable that these rockets were connected to the Syrian government. That kind of really put me up then at odds with reporting done by Seymour Hersh in the London Review of Books, where he claims that these were basically munitions, you know, and Turkey was involved, and it was effectively a false flag to draw the U. S. into the war. And I think a lot of journalists who had been following my work at that time saw it as a kind of case of kind of my new journalism versus Seymour Hersh's old journalism. But I've always said that it's never about one thing being versus another thing; it's about using this new form of investigation to enhance traditional sources of investigation, be they journalism or in other fields. GROSS: You know, you've said that in the past you'd used soldier selfies as part of your work and that soldier selfies had basically become a genre. How did you find them? How did you use them? And do soldiers do it anymore, or have they been warned not to in part because of people like you? HIGGINS: So this really started when I - after I launched Bellingcat in 2014. Malaysian Airlines Flight 17 was shot down just three days later, and that became, like, the first big Bellingcat investigation. And keep in mind, this was still myself, about 60,000 pounds in crowdfunding - which I think is about $80,000 - a website and some volunteers. And very quickly around that instant, there formed a group of volunteers who were looking into what happened using open-source investigation. And we started identifying soldiers who were in Russia who were part of a convoy where the missile launcher that shot down MH17 was transported in. We knew that convoy existed because a bunch of Russians along the route filmed it and posted it on social media, so we could reconstruct the route of the convoy, which led us back to their air defense base, the 53rd air defense base in Kursk, in Russia. And they had a page on VKontakte, which is, like, Russia's Facebook, where all the soldiers followed their own brigades. And we could then look at those soldiers' profiles and start finding photographs of them inside this convoy that transported this missile launcher. And we were able to basically reconstruct the entire brigade structure based off their own social media posts. And that led us to finding more and more soldiers who were involved with the conflict in Ukraine, coming from Russia and actually fighting in Ukraine, even though they were serving Russian soldiers. And that was because they were posting stuff about it on their own social media profiles. So we could find photographs of them in Ukraine, use geolocation to figure out exactly where that was and then say, this is a Russian soldier from this brigade, this unit, inside Ukraine. And that extended not just to soldiers but tanks and armored vehicles and other equipment that had been sent from Russia to Ukraine, but because of the amount of kind of video documentation, you could find the same, you know, tank in Russia and then find a photograph of it a few weeks later in Ukraine with the same markings, numbering, down to the smallest scratches and dents and prove that these were Russian tanks inside Ukraine. And this was all stuff that was just on the Internet. And as a reaction to that, the Russian government passed a law saying it was now illegal for soldiers to share those kind of images from their service online. So Russia did take notice, and they did take steps to stop us, although that was rather late by that point. GROSS: Let me reintroduce you here. If you're just joining us, my guest is Eliot Higgins, founder of the group of online investigators and crime-solvers known as Bellingcat. His new book is called \"We Are Bellingcat. \" We'll be back after we take a short break. I'm Terry Gross, and this is FRESH AIR. (SOUNDBITE OF MUSIC)GROSS: This is FRESH AIR. I'm Terry Gross. Let's get back to my interview with Eliot Higgins, founder of Bellingcat, a group of digital investigative journalists and crime solvers that relies on access to open source information and crowdsourcing to solve crimes, including war crimes, hate crimes and crimes perpetrated by extremists, and to investigate what's happening in war zones too dangerous for journalists to enter and to act as a firewall against disinformation. Higgins describes what Bellingcat does as a new field that connects journalism, human rights advocacy and criminal investigations. One of the early discoveries you made was who shot down the Malaysian Airlines Flight MH17. It was shot down over Ukraine. What are some of the tools you used from a distance sitting at your computer in England to figure out who shot down that plane? HIGGINS: So I had just launched Bellingcat in July 2014, and a few days later, MH17 was shot down. And it was, you know, the biggest news event in the world just as we had launched Bellingcat. It was still basically just me by myself working full time on the website. But very quickly, this kind of crowd of volunteers appeared online who just wanted to know as much as possible and started digging through every single link they could think of, every website, every weird Russian or Ukrainian social media platform that I'd never heard of and sharing it on Twitter and, you know, on other platforms. And around kind of Bellingcat there formed a small group of people who I recognized as being quite talented in digging through this material and analyzing it. And the first thing we did there is start looking at the videos and photographs of a Buk missile launcher traveling through eastern Ukraine on July 17 or supposedly traveling through there because, of course, these were videos and photographs on the Internet. And we had to verify they were actually where they claimed to be. So we started using this process of geolocation. And to give you a sense of the tools that we used in one example is - there was one photograph that showed this missile launcher on a back of this low loaded truck, and it was taken from a gas station. And in the background there's a shop. And it was possible to Google the name of the shop, even though it was in Russian. That gave a result. And it wasn't that many results - only covered, like, three or four towns. So we Googled the name of the shop of each of those towns, one of which gave a results that showed a - basically a legal document about a fight that had taken place in the shop, which gave the shop's full address. We then searched that, and that gave us the exact location on Google Maps but also a video or two videos, in fact. Someone had filmed from the dashboard camera of them just driving around the streets of Ukraine, including the streets that we were looking for. And we could use that video footage and match it exactly to what was visible in this photograph, confirming the precise location. And then what happened with that - for further confirmation, journalists on the ground who were reading Bellingcat's work at that point actually went to that place and spoke to the local people, who confirmed not only that this missile launch had traveled through the area at that day but the time it happened. And we were able then to cross-reference that time against social media posts made by people as the missile launcher was traveling through the area saying things like, gosh, I've just seen a big missile launcher drive past my house. So combining all those different sources allowed us to kind of verify that one moment in time when that missile launcher came by. And when you do that with multiple videos and photographs, you can actually create a route and a timeline of when this missile launcher was moving. And we could show it had moved towards what we eventually discovered to be the launch site of the missile that shot down MH17. So we could connect it to the downing of MH17 using publicly available information. GROSS: So you were able to trace the missile and the missile launcher from Russian territory into Ukrainian territory and prove that that was the missile launcher that attacked the flight that was shot down. HIGGINS: Yes, because we were not only able to track it in Ukraine, but as people online were searching for all the videos that were available, you know, digging through YouTube and Facebook and all these weird Russian sites you would have never heard of before, they found more and more videos of a convoy in Russia a few weeks earlier with the same types of Buk missile launchers. There were, you know, like, a dozen missile launchers in there and support vehicles, trucks, lots of equipment, a huge convoy. And again, we geolocated those videos. We figured out exactly where they were filmed. And it showed a very clear route from Kursk all the way down to the border with Ukraine. And within that, we found one missile launcher that had some very interesting markings on it - paint marks, damage to it, scratches that matched perfectly with the one that was in Ukraine. And we checked all the other missile launchers we could find, tried to compare all of them together. And we discovered that these matches were unique, so it had to be the same missile launcher. So we established that this missile launcher had actually come from Russia in this convoy that had gone to the Ukrainian border and, at some point, had been transported over the border and sent on to the location where MH17 was eventually shot down. GROSS: How long did that process take? HIGGINS: The initial route - I think that only took us probably about a week. It was probably before the end of 2015 where we could show that the missile launcher had come from Russia, and then we just kind of continued to build and build and build on that investigation. So by the end of 2015, we could actually name all the individuals who were in that convoy along with names, photographs, ranks because they had posted so much on social media. GROSS: The soldiers posted a lot. The soldiers posted selfies. HIGGINS: Yeah, just all these selfie soldiers posting like maniacs about their service in the Russian military. And we also discovered, as we were looking into MH17, other evidence of Russia's involvement in the conflict - you know, entire tank brigades that went over the border and were identifiable because of photographs the soldiers took in Russia and then photographs that were taken of the tanks by other people in Ukraine that we were then able to compare to each other and show they had the same markings on them. I mean, one case in Russia, they photographed themselves, after taking - painting on the tanks kind of separatist slogans, drove them over the border, had their kind of involvement in the war, drove them back, painted over the markings. But then the markings were still visible through the paint because they did a really bad job of it. So you could actually just match them to what was filmed and photographed in Ukraine showing these same tanks then turning back up in Russia again. And this happened time and time again. Russian soldiers would take photographs of themselves in Ukraine, which we geolocate and say, there's another Russian soldier in Ukraine. And Russia tried to say, oh, these were volunteers. These are people that - you know, on their holidays going over and fighting in a war. But they went there with their tanks, which - I'm pretty sure the Russian government, as lax as it may be, wouldn't allow their soldiers to go on holiday with tanks. GROSS: Got it. It's incredible work and incredibly detailed work. Let me reintroduce you here. If you're just joining us, my guest is Eliot Higgins, founder of the online investigative group Bellingcat that relies on open source information and crowdsourcing to solve war crimes and hate crimes and investigate what's happening in war zones too dangerous for journalists to enter. His new book is called \"We Are Bellingcat. \" We're going to take a short break, and then we'll be right back. This is FRESH AIR. (SOUNDBITE OF HOLT VAUGHN AND PHIL KEAGGY'S \"BITTER SUITE\")GROSS: This is FRESH AIR. I'm Terry Gross. Let's get back to my interview with Eliot Higgins, founder of the group Bellingcat, which conducts investigative journalism, relying on open source media on the Internet like social media posts, leaked databases and free satellite maps. Bellingcat has a core team of about 18 staffers that work with scores of volunteers around the globe. Higgins has written a new book called \"We Are Bellingcat. \"So in a way, you're a journalist. In a way, you're something a little different than a journalist. How would you describe your ethics in terms of what you publish and who you tell before publishing? HIGGINS: So because we're often involved in investigations where there might have been a crime committed and that there might be an ongoing police investigation, we have to be quite careful about what we publish, because when you publish open source information as part of an investigation, you're linking to the original sources. So they may be YouTube channels, Twitter accounts and other kind of links online. And often, when people get wind of what you're doing, they'll delete all that information. So by publishing something that's part of an ongoing police investigation, we can effectively destroy evidence that the police might find useful. So in the case of MH17, early on, I was contacted by the joint investigation team, who is the official criminal investigation, and interviewed as a witness. And they sat down with me for several hours as I went through kind of posts about MH17 line by line, kind of piece of evidence by piece of evidence. And they went away. And they seemed quite impressed by it. And they stayed in touch. And they asked if we found stuff that we would talk to them about it because they saw the value of, you know, preserving this evidence. So we started then - if we were finding information online and about to post an article, we would let them know that we're going to post this and that they needed to preserve anything that was interesting to them. Otherwise, it would be deleted forever. And because we kind of find ourselves in a - primarily as investigators rather than being a type of investigator, like an investigative journalist, we kind of find ourselves now more and more involved with criminal cases, especially international crimes such as, you know, war crimes and crimes against humanity, where we've kind of almost become the first line of response when stuff is shared online that shows these kind of crimes. So over the years, we've started to develop a process for investigation and archiving that allows us to preserve material, unless we're investigating it, in a way that it could be used by courts in the future, because more and more, there's this realization in bodies like the International Criminal Court, who I've worked with, that this open source evidence can be extremely valuable in locations where war crimes are happening. And they are often the only way these crimes are documented, sometimes in the moment they are being documented and they're occurring. So that's why they see more value in engaging with groups like Bellingcat and understanding how this kind of stuff is used, because when I first started doing this, I assumed, well, all these big bodies must understand what this stuff is because it's so useful. But as I've discovered over the last decade or so that these - that they - this was new to them. This was a completely new way of approaching this kind of information. And they didn't know how to use it themselves. So we've kind of ended up leading the way in the development of the use of open source evidence with bodies like the International Criminal Court. GROSS: What kind of work has Belingcat been doing about COVID? - because there's been a lot of misinformation about that and a whole campaign not to do the things that we're supposed to do to prevent the spread of COVID like wearing masks. HIGGINS: Yeah. We were involved with a project that looked into how COVID kind of conspiracy theories and misinformation were being generated. It was interesting there. You'd see Trump give his kind of nightly press conferences of - nightly for us in the U. K. , anyway - about coronavirus, these briefings. And then you'd see the kind of alt-right media kind of saying, this - actually, this is what Trump actually meant to say when he says something ridiculous or, you know, ah, but those libs have been owned by Trump being a genius again - you know, that kind of stuff. And then that would kind of get laundered through to kind of Fox News and the kind of more, you know, mainstream Republican kind of media. And then Donald Trump would watch it. And then it would create this kind of cycle of nonsense that was coming from Trump and going back to Trump and just go round and round again. And you could see this happening. You could see how the news sites would always report it in that kind of process. And it was really plain to see. And unfortunately, when you have people in positions of authority who are kind of spreading misinformation and disinformation, and you have a media system that is open to spreading that information for purely political purposes, then you're going to have a massive amount of misinformation being spread because it's happening at the very top levels of, you know, mainstream society. GROSS: Donald Trump was de-platformed from Facebook and Twitter. How have the groups that you followed that are more on the dark web, how have they been reacting to that? HIGGINS: I think, really - I mean, at the time, there was, you know, (laughter) rage. But at the same time, those Q supporters got knocked off Twitter. And, you know, it was, you know, a real massacre in many sense of all these social media accounts. And then Parler went offline. And there was kind of all these groups that were kind of splitting off. And, like, thedonald. win, which was the kind of big, pro-Trump message board that spawned off Reddit, that kind of collapsed and got relaunched. And basically, there was just a huge amount of drama with all these groups kind of, you know, reforming and collapsing again. And in a sense, I think they were so panicked about, you know, being kind of scattered to the winds that they didn't really have much more chance to think about anything else. But, you know, they're still out there. It's just they're kind of more on the obscure platforms now that most people, you know, never have heard about. But those communities are still out there. They still exist. And they're still waiting for Trump to return and for Q to post his next message. GROSS: Talk a little bit about the impact of this work on you personally because, like, when you're investigating war crimes and, you know, massacres, you end up looking at a lot of videos of victims. You've seen a lot of severed limbs. You've seen a lot of bloody bodies. You know, you write about how you try to disconnect yourself emotionally from what you're seeing, but really, that's easier said than done. So what has the impact of the work been on you emotionally? HIGGINS: I mean, the whole kind of - that period of starting the blog and, you know, going on was kind of strange for me because when I started doing this, I was someone who was, you know, very - had lots of anxiety. And, you know, I prefer to be at home. I didn't kind of like going out. But because of the work I was doing with the blog, I was kind of forced to, like, go on stage and speak in front of lots of important people. And it was terrifying. The first few times I did it, I can barely remember because I was just so out of my mind because of the anxiety about something going wrong. But it went well. I kept doing it and doing it and, over the years, built my confidence tremendously. It's had a really positive impact on me, along with the success of kind of my job at the moment, you know, with how Bellingcat's going. So at the same time, of course, I'm watching, like, really horrific conflict footage. And you can't disassociate it, you know, to a certain extent. But it still can be very difficult when you're looking at footage that's - it's not so much the horror of it. You can prepare yourself for the visceral horror of what you're seeing. But it's when you see something that gives you a kind of connection to something in your personal life. Like, I remember watching a video from Syria of a child dying from sarin, and that wasn't what was - brought me into the moment. It was that they were wearing the same nappy as I'd been using with my children. There's another time when I was looking at wreckage from MH17, looking for signs of impact from shrapnel. So I had to look at everything really close up. So I was kind of ignoring the blood and, you know, some of the bodies that were visible and focusing on the damage to the metal. But within that metal, there was this little toy rabbit doll, and it was exactly the same toy rabbit doll my sister-in-law gave my daughter when she was born. And that brings you right into that moment and what's happened there. So you have to kind of police yourself. You have to realize what those kind of trigger points are for yourself. And most important at Bellingcat is that we - you know, we talk to people about this. We engage with our staff about that. We, you know, make sure this is an environment where they can talk about those kind of, you know, moments and feelings and understand that it's not always the same for every single person. But I think myself, I was kind of - because I had that kind of weird positive development going alongside what was happening with my work, I think that may have offered me some kind of, you know, protection from it. But now, you know, I really dislike watching things like horror films now because I've seen injuries for real that - you know, when you see it in a horror film, it just, like, reminds you of seeing that stuff. And it's just - I don't get any enjoyment from, you know, being scared like that anymore. GROSS: Eliot Higgins, thank you so much for your work, and thank you so much for doing this interview. HIGGINS: Thanks for having me on. GROSS: Eliot Higgins is the founder of Bellingcat and author of the new book \"We Are Bellingcat. \" After we take a short break, our TV critic David Bianculli will tell us why he recommends the new Netflix miniseries \"Behind Her Eyes. \" This is FRESH AIR. (SOUNDBITE OF KEVIN EUBANKS AND STANLEY JORDAN'S \"OLD SCHOOL JAM\") TERRY GROSS, HOST:   This is FRESH AIR. I'm Terry Gross. Crowdsourcing has created a new form of online open-source investigation, as epitomized by the group Bellingcat that was founded by my guest, Eliot Higgins, in 2014. Higgins and people affiliated with Bellingcat, while at their computers, have uncovered evidence that Syrian dictator Bashar al-Assad fired chemical weapons at his own people, figured out who controlled territory during the Libyan civil war, identified the Russian intelligence agents alleged to have poisoned MI6 double agent Sergei Skripal and his daughter Yulia and found evidence that the 22-year-old woman alleged to have stolen Nancy Pelosi's laptop on January 6 was a neo-Nazi sympathizer who used coded neo-Nazi language in a video and in that video gave the Heil Hitler salute. Bellingcat has identified the perpetrators of hate crimes and how extremists use mainstream websites to divert people to extremist sites that sell neo-Nazi merchandise and ask for donations to continue doing their work. The clues used by Bellingcat come from openly available sources on the Internet, like social media posts, leaked databases and free satellite maps. Bellingcat has a core team of 18 staffers that works with scores of volunteers around the globe. The group has worked on investigations with media organizations, including The New York Times, NBC News and the BBC, as well as human rights groups. Eliot Higgins has written a new book called \"We Are Bellingcat: Global Crime, Online Sleuths, And The Bold Future Of News. \" Eliot Higgins, welcome to FRESH AIR. Let's start with a recent discovery by Bellingcat that the 22-year-old woman who allegedly stole Nancy Pelosi's laptop made a video using neo-Nazi coded words and giving the Heil Hitler salute. But in the video, the woman is disguised by a full face mask, so her face couldn't be identified. Bellingcat got a tip that this video was hers. This was a tip from an anti-fascist activist. But Bellingcat had to confirm that this really was hers. And without a face to confirm it, that was a tricky thing to do. And I should mention, if you look for this video online - the last time I saw it was last night. And as of then, the audio was unavailable because there's techno music underneath her, and the publisher - I think it's the publisher of that music had the audio removed, I think for copyright reasons, or maybe just 'cause they didn't want that music associated with a neo-Nazi. ELIOT HIGGINS: Indeed, yes. GROSS: Yes, OK. So describe how you were able to verify that the disguised woman in this video was the same woman alleged to have stolen Nancy Pelosi's computer on January 6. HIGGINS: So it was really a case of piecing together a variety of clues that were available online. There was a original video that showed her doing the salute. There was also then another photograph that was shared with us by these researchers. It shows a woman wearing a skull face mask that is identical to the one that's in the video, wearing the same dress as well. And we saw in that picture, she's wearing a pair of glasses that match exactly to the glasses that she wears in other photographs where her face is fully visible, which is one of the clues that we were using. But we started looking at other details as well. Even though her whole face is covered, there are some things that are actually visible. For example, a tattoo is visible. And that tattoo actually turns up in another video she did for a forum called Kiwi Farms, where it was adult material, basically, so it was possible to see tattoos and other parts of her body, including the one that matched. And also, to be 100% sure, there's actually a couple of features visible in that Kiwi Farms video that's visible in the video we were looking into, including, for example, very unique light fixtures and other details that allowed us to match the room she was in in the Kiwi Farms video, where she's clearly identifiable, to the room she's in in the original video, where she's making neo-Nazi-related statements. So by kind of piecing together all these really minor clues, it's actually possible to establish her identity, even though in the original video, her face is covered and her eyes are covered. GROSS: And there's several neo-Nazi symbols in this video, in addition to her giving the Heil Hitler salute. So what are some of the symbols? Like, interpret them for us. HIGGINS: In the background, there's actually a book about the SS that is displayed, clearly on purpose, to be visible on camera. She's wearing a hat as well that has a symbol that's associated with neo-Nazi groups as well. Some of the stuff she's actually purchased is from people who associate themselves with the far-right and neo-Nazis. So there's kind of a whole range of different objects in there that are identifiable beyond just what she's saying and the salute that she's giving. GROSS: And a narrator in the video says, Hammer was right all along. There is no political solution. All that is left is acceleration. HIGGINS: That's right. And the Hammer is a neo-Nazi figure who advocates followers to partake in things like things called banner drops and spraying graffiti to spread their message. So a lot of what she's kind of - the language she's using is very specific to a very specific kind of subset of the alt-right, kind of far-right and neo-Nazis. So it probably, you know, wouldn't make much context to, you know, the average person. But because our researchers have spent a lot of time in these communities understanding the kind of language of these communities, the kind of key figures in these communities and how they're spoken about, it allows us to kind of draw these conclusions about what was visible in these videos. GROSS: And doesn't acceleration also refer to accelerating the U. S. becoming a white nation? HIGGINS: Yeah. I mean, for many of the people who kind of use that terminology, that's what they're moving towards. Weirdly, there are some groups who kind of actually don't want that but still have that same idea that what they want can be achieved through another civil war. So there's kind of all these kind of weird little groups online that really would like another civil war. And, unfortunately, quite a few of them are quite keen to make that happen by, you know, having real-world activity that will lead to violence and what they hope will be even more violence. GROSS: So in the case of the 22-year-old woman who is alleged to have stolen Nancy Pelosi's computer, and now you've shown that she made a video with all kinds of coded neo-Nazi language, and she gave the Heil Hitler salute, what is the significance of unmasking her in that video? HIGGINS: Well, it shows that there's kind of more to these people, you know, who made up this group at the Capitol than, you know, just what can be discovered through kind of normal investigation. And, you know, what they, you know, are seeking in the future kind of informs their - you know, what they were doing on the ground on that day. You know, there was a whole range of different groups that made up the crowd on January 6. You know, some were fairly innocuous who were just kind of caught up in the violence. But some of them went there with long histories of political violence with the intention of targeting not only the building, but the people inside that building. And I think, you know, by looking at these individuals, it does give you a real sense of the sort of people who were involved with this. You can't just dismiss them as one big group of Trump supporters because there was a whole range of different people within those groups who were, you know, mad about, you know, one thing or another, and they had all been brought together in one space. And in many senses, this is what's happening in the online spaces as well. You're seeing these kind of very fairly disparate groups that are united under one issue. And in the case of what was happening on January 6, that was the count of the votes and, you know, Trump. But they're coming from kind of different perspectives on it, but they're kind of all coming together under these single ideas. And that's where we're starting to see more and more violence. And, unfortunately, there are politicians who don't recognize that, or if they do recognize it, they still try to use these people to build their own base of power. And until politicians stop doing that, that is going to lead to more and more violence in the U. S. and elsewhere in the world. GROSS: If you're just joining us, my guest is Eliot Higgins, founder of the online investigative group Bellingcat. His new book is called \"We Are Bellingcat. \" We'll be right back after a break. This is FRESH AIR. (SOUNDBITE OF MUSIC) GROSS: This is FRESH AIR. Let's get back to my interview with Eliot Higgins, founder of the group Bellingcat, which conducts investigative journalism, relying on open-source media on the Internet, like social media posts, leak databases and free satellite maps. Bellingcat has a team of about 18 staffers that works with scores of volunteers around the globe. He's written a new book called \"We Are Bellingcat. \" So let's talk about one of the first things that you uncovered as a digital investigator back in 2011, before you even founded Bellingcat. This was three years before you founded it. And it has to do with disputed territory during the Libyan Civil War. What was the question that you wanted to be able to answer? HIGGINS: So I think called me additional investigator. I think that's a nice title for someone who was basically just spending their time online, arguing with people on the Internet because I was just, like, your average Internet user back in 2011. But I was very interested in what was happening in the conflict in Libya. Spent my time on forums and websites like The Guardian newspaper's Middle East live blog, arguing with people about what was happening there. You know, stuff was being posted online, and some people say, no, that's fake; it can't be true. And you have people say, well, there's this that shows it's true. But there's no really kind of approach to verifying this kind of stuff, and I found that very frustrating because I was interested in what was actually happening, rather than having kind of politically biased arguments around, you know, different aspects of, you know, what was happening in the conflict. So one day, this video was shared online, and it showed rebels in Libya claiming to be in this town called Teji. And Teji was interesting because it was beyond the front-line positions that people knew they were already fighting in. So it kind of represents, you know, progression in the conflict. So there's lots of kind of arguments and debates about what had actually happened. You know, some people said, well, how do you know where this was filmed? If this isn't Teji, how do you know where this is filmed? And I had the idea of, why don't I go to satellite imagery and see if I can find Teji on the satellite image and then watch the video and look for features that might be visible. And in that video, there was a tank rolling down these two lanes of a road next to a mosque with a dome and a minaret. So I look for that on satellite imagery, and I found the road and followed it along, and there was a mosque with a dome and a minaret. And I watched the video again, and this time I looked for smaller features, like the walls and the way the pavement curved. And that was visible on the satellite imagery, too. And then I looked for utility poles, and those utility poles were there as well. And I realized I could confirm exactly where this had been filmed and then kind of share that rather smugly on the comments of the live blogs - say, ha, I found it. GROSS: (Laughter). HIGGINS: But that was kind of my first realization that you can actually look at these videos and figure out exactly where they were filmed and get a much more accurate and verifiable view on the conflict. And that really set me off doing what I now do, you know, as my career. GROSS: So it must have been remarkable to you that being at your office job in England, you were able to solve a question, to factually answer a question about what was happening in a conflict zone in Libya. HIGGINS: Yeah, and there was kind of more stuff I started noticing as well. I became very frustrated by the fact that there would be journalists on the ground in Libya and they'd go somewhere and, like, tweet about it, but they wouldn't do a story on it because it wasn't the story that they were looking to file that day. But when you started looking at, you know, those tweets and posts and bits of information from different journalists and people on the ground, you started seeing patterns. And you could start saying, OK, there's something going on in this location. You know, can I piece together what it is? And one of those cases was when the rebels in a place called Misrata, pushed south out of the town towards Gadhafi's hometown, along a coastal route. There was one town that was just off the coastal route. And the journalists who were going, you know, with the rebels back and forth to Gadhafi's hometown, hoping they'd, you know, get to interview Gadhafi, were driving past this town every day. And one of them, you know, one day would tweet, all the rebels are firing artillery into this town. It was called Tawergha. And then someone else would say, oh, Tawergha is on fire tonight. But they wouldn't write a story about it because the story was Gadhafi, not this town that was off the road they were driving by. But by kind of looking at all these individual kind of comments that were coming up, it seemed very clear something bad was happening in that town because it was a pro-Gadhafi town. And, you know, the rebels had been stuck in Misrata for a long time. And eventually, when Gadhafi was killed and journalists went to that town, they discovered that, in fact, the town had effectively been ethnically cleansed. And they had to observe that from a distance, but because they had that kind of single point of view on what was happening and this other focus, it was basically lost. And I realized then you could kind of combine all these different sources and actually start getting a real impression of what was happening in these conflict zones, along with this verified video and photographic content. GROSS: So you were basically almost like a war correspondent sitting at your computer in England. HIGGINS: That's right. And it was - it still as well was just, really, you know, about, you know, talking to people on the Internet and arguing with them and, you know, debating the facts of what was going on. But then in early 2012, I decided as a hobby to start a blog, which I called the Brown Moses Blog after a Frank Zappa song I'd been listening to when I started using that name as my kind of online pseudonym. And that was basically my style of writing about the conflict in Syria, which really started leading me into kind of becoming more professional about the kind of work I was doing. GROSS: What do you think your best scoop, so to speak, was on the Syrian Civil War? HIGGINS: There were a few, but the first really big one was - I basically couldn't speak any Arabic, so I was watching all these videos from Syria. I realized they were being shared on the same thousand or so YouTube channels every day that belonged to Syrian opposition groups, you know, media centers, those kind of things. It wasn't like an open Internet; it was, like, very restricted. But there were still lots of videos coming through of the conflict. And by doing that, I started to learn what the weapons were being used in the conflicts and writing about that. And I kind of taught myself what they were, started having arms experts approaching me, asking me questions about these videos and being part of these communities where these questions were discussed. So I was the first person, I think, to find the videos of cluster bombs being used, which I shared with Human Rights Watch, who did a piece on it. I was the first person to find, I think, a video of a barrel bomb, as they became known, these improvised explosive devices. And then in early 2013, I started seeing new weapons coming into the conflict from - I didn't recognize them. I knew all the weapons in this conflict. I just, like, every day watched videos and figured out what they were by using various online sources. But these were brand new and really weird looking. And eventually, I discovered they were from the former Yugoslavia. And by that point, I knew a journalist at The New York Times, and I kind of show this to him, and he went off and came back and said, actually, this is the Saudi's secret smuggling operation to the rebels in the south of Syria. And I had managed to discover this secret operation by watching YouTube videos intensively. And that ended up being on the front page of The New York Times, and that was kind of the first moment when I started getting, like, a really big amount of media attention. I had, like, Channel 4 News in the U. K. , Germany ARD Television, CNN - every day a different news organization would come to my house and film me (laughter). You know, this kind of - CNN said I was a stay-at-home Mr. Mom who found chemical weapons from his sofa and stuff like that. So it was a very weird experience for me, going from this kind of unknown person to suddenly someone who was on kind of CNN, talking about their work as this kind of - almost like a novelty act. But it was - it really then kind of took off from there. And then in August 2013, I did a lot of work on the chemical weapons attacks in Damascus, figured out a whole bunch of stuff about that and ended up kind of quite publicly contradicting the work of Seymour Hersh after he tried to say it was Turkey providing sarin to the rebels, when the content I found pointed to that being completely ridiculous, and that kind of then gave me another really big boost towards the eventual launch of Bellingcat in 2014. GROSS: And you found that it was the Assad regime that was responsible for the sarin gas attacks? HIGGINS: Yes, because I had been - you know, by that point, spent the last 18 months watching every video and looking at every region I could find from Syria. And there were these really weird munitions that had been turning up in some occasional attacks that seemed like chemical attacks. There was a video posted in early August where there was one of these weird tubular rocket things next to a dog that was kind of twitching and foaming from the mouth, a cat that also had been foaming from the mouth. And these same rockets turned up on August 21, loaded with sarin. And because I kind of had this knowledge of these videos, I could show videos of not only these rockets being used in previous attacks that had kind of missed the attention of the world's media, but also explosive variants of these same rockets that were very unique being used by Syrian government forces in videos posted online by pro-Syrian government accounts. So it was undeniable that these rockets were connected to the Syrian government. That kind of really put me up then at odds with reporting done by Seymour Hersh in the London Review of Books, where he claims that these were basically munitions, you know, and Turkey was involved, and it was effectively a false flag to draw the U. S. into the war. And I think a lot of journalists who had been following my work at that time saw it as a kind of case of kind of my new journalism versus Seymour Hersh's old journalism. But I've always said that it's never about one thing being versus another thing; it's about using this new form of investigation to enhance traditional sources of investigation, be they journalism or in other fields. GROSS: You know, you've said that in the past you'd used soldier selfies as part of your work and that soldier selfies had basically become a genre. How did you find them? How did you use them? And do soldiers do it anymore, or have they been warned not to in part because of people like you? HIGGINS: So this really started when I - after I launched Bellingcat in 2014. Malaysian Airlines Flight 17 was shot down just three days later, and that became, like, the first big Bellingcat investigation. And keep in mind, this was still myself, about 60,000 pounds in crowdfunding - which I think is about $80,000 - a website and some volunteers. And very quickly around that instant, there formed a group of volunteers who were looking into what happened using open-source investigation. And we started identifying soldiers who were in Russia who were part of a convoy where the missile launcher that shot down MH17 was transported in. We knew that convoy existed because a bunch of Russians along the route filmed it and posted it on social media, so we could reconstruct the route of the convoy, which led us back to their air defense base, the 53rd air defense base in Kursk, in Russia. And they had a page on VKontakte, which is, like, Russia's Facebook, where all the soldiers followed their own brigades. And we could then look at those soldiers' profiles and start finding photographs of them inside this convoy that transported this missile launcher. And we were able to basically reconstruct the entire brigade structure based off their own social media posts. And that led us to finding more and more soldiers who were involved with the conflict in Ukraine, coming from Russia and actually fighting in Ukraine, even though they were serving Russian soldiers. And that was because they were posting stuff about it on their own social media profiles. So we could find photographs of them in Ukraine, use geolocation to figure out exactly where that was and then say, this is a Russian soldier from this brigade, this unit, inside Ukraine. And that extended not just to soldiers but tanks and armored vehicles and other equipment that had been sent from Russia to Ukraine, but because of the amount of kind of video documentation, you could find the same, you know, tank in Russia and then find a photograph of it a few weeks later in Ukraine with the same markings, numbering, down to the smallest scratches and dents and prove that these were Russian tanks inside Ukraine. And this was all stuff that was just on the Internet. And as a reaction to that, the Russian government passed a law saying it was now illegal for soldiers to share those kind of images from their service online. So Russia did take notice, and they did take steps to stop us, although that was rather late by that point. GROSS: Let me reintroduce you here. If you're just joining us, my guest is Eliot Higgins, founder of the group of online investigators and crime-solvers known as Bellingcat. His new book is called \"We Are Bellingcat. \" We'll be back after we take a short break. I'm Terry Gross, and this is FRESH AIR. (SOUNDBITE OF MUSIC) GROSS: This is FRESH AIR. I'm Terry Gross. Let's get back to my interview with Eliot Higgins, founder of Bellingcat, a group of digital investigative journalists and crime solvers that relies on access to open source information and crowdsourcing to solve crimes, including war crimes, hate crimes and crimes perpetrated by extremists, and to investigate what's happening in war zones too dangerous for journalists to enter and to act as a firewall against disinformation. Higgins describes what Bellingcat does as a new field that connects journalism, human rights advocacy and criminal investigations. One of the early discoveries you made was who shot down the Malaysian Airlines Flight MH17. It was shot down over Ukraine. What are some of the tools you used from a distance sitting at your computer in England to figure out who shot down that plane? HIGGINS: So I had just launched Bellingcat in July 2014, and a few days later, MH17 was shot down. And it was, you know, the biggest news event in the world just as we had launched Bellingcat. It was still basically just me by myself working full time on the website. But very quickly, this kind of crowd of volunteers appeared online who just wanted to know as much as possible and started digging through every single link they could think of, every website, every weird Russian or Ukrainian social media platform that I'd never heard of and sharing it on Twitter and, you know, on other platforms. And around kind of Bellingcat there formed a small group of people who I recognized as being quite talented in digging through this material and analyzing it. And the first thing we did there is start looking at the videos and photographs of a Buk missile launcher traveling through eastern Ukraine on July 17 or supposedly traveling through there because, of course, these were videos and photographs on the Internet. And we had to verify they were actually where they claimed to be. So we started using this process of geolocation. And to give you a sense of the tools that we used in one example is - there was one photograph that showed this missile launcher on a back of this low loaded truck, and it was taken from a gas station. And in the background there's a shop. And it was possible to Google the name of the shop, even though it was in Russian. That gave a result. And it wasn't that many results - only covered, like, three or four towns. So we Googled the name of the shop of each of those towns, one of which gave a results that showed a - basically a legal document about a fight that had taken place in the shop, which gave the shop's full address. We then searched that, and that gave us the exact location on Google Maps but also a video or two videos, in fact. Someone had filmed from the dashboard camera of them just driving around the streets of Ukraine, including the streets that we were looking for. And we could use that video footage and match it exactly to what was visible in this photograph, confirming the precise location. And then what happened with that - for further confirmation, journalists on the ground who were reading Bellingcat's work at that point actually went to that place and spoke to the local people, who confirmed not only that this missile launch had traveled through the area at that day but the time it happened. And we were able then to cross-reference that time against social media posts made by people as the missile launcher was traveling through the area saying things like, gosh, I've just seen a big missile launcher drive past my house. So combining all those different sources allowed us to kind of verify that one moment in time when that missile launcher came by. And when you do that with multiple videos and photographs, you can actually create a route and a timeline of when this missile launcher was moving. And we could show it had moved towards what we eventually discovered to be the launch site of the missile that shot down MH17. So we could connect it to the downing of MH17 using publicly available information. GROSS: So you were able to trace the missile and the missile launcher from Russian territory into Ukrainian territory and prove that that was the missile launcher that attacked the flight that was shot down. HIGGINS: Yes, because we were not only able to track it in Ukraine, but as people online were searching for all the videos that were available, you know, digging through YouTube and Facebook and all these weird Russian sites you would have never heard of before, they found more and more videos of a convoy in Russia a few weeks earlier with the same types of Buk missile launchers. There were, you know, like, a dozen missile launchers in there and support vehicles, trucks, lots of equipment, a huge convoy. And again, we geolocated those videos. We figured out exactly where they were filmed. And it showed a very clear route from Kursk all the way down to the border with Ukraine. And within that, we found one missile launcher that had some very interesting markings on it - paint marks, damage to it, scratches that matched perfectly with the one that was in Ukraine. And we checked all the other missile launchers we could find, tried to compare all of them together. And we discovered that these matches were unique, so it had to be the same missile launcher. So we established that this missile launcher had actually come from Russia in this convoy that had gone to the Ukrainian border and, at some point, had been transported over the border and sent on to the location where MH17 was eventually shot down. GROSS: How long did that process take? HIGGINS: The initial route - I think that only took us probably about a week. It was probably before the end of 2015 where we could show that the missile launcher had come from Russia, and then we just kind of continued to build and build and build on that investigation. So by the end of 2015, we could actually name all the individuals who were in that convoy along with names, photographs, ranks because they had posted so much on social media. GROSS: The soldiers posted a lot. The soldiers posted selfies. HIGGINS: Yeah, just all these selfie soldiers posting like maniacs about their service in the Russian military. And we also discovered, as we were looking into MH17, other evidence of Russia's involvement in the conflict - you know, entire tank brigades that went over the border and were identifiable because of photographs the soldiers took in Russia and then photographs that were taken of the tanks by other people in Ukraine that we were then able to compare to each other and show they had the same markings on them. I mean, one case in Russia, they photographed themselves, after taking - painting on the tanks kind of separatist slogans, drove them over the border, had their kind of involvement in the war, drove them back, painted over the markings. But then the markings were still visible through the paint because they did a really bad job of it. So you could actually just match them to what was filmed and photographed in Ukraine showing these same tanks then turning back up in Russia again. And this happened time and time again. Russian soldiers would take photographs of themselves in Ukraine, which we geolocate and say, there's another Russian soldier in Ukraine. And Russia tried to say, oh, these were volunteers. These are people that - you know, on their holidays going over and fighting in a war. But they went there with their tanks, which - I'm pretty sure the Russian government, as lax as it may be, wouldn't allow their soldiers to go on holiday with tanks. GROSS: Got it. It's incredible work and incredibly detailed work. Let me reintroduce you here. If you're just joining us, my guest is Eliot Higgins, founder of the online investigative group Bellingcat that relies on open source information and crowdsourcing to solve war crimes and hate crimes and investigate what's happening in war zones too dangerous for journalists to enter. His new book is called \"We Are Bellingcat. \" We're going to take a short break, and then we'll be right back. This is FRESH AIR. (SOUNDBITE OF HOLT VAUGHN AND PHIL KEAGGY'S \"BITTER SUITE\") GROSS: This is FRESH AIR. I'm Terry Gross. Let's get back to my interview with Eliot Higgins, founder of the group Bellingcat, which conducts investigative journalism, relying on open source media on the Internet like social media posts, leaked databases and free satellite maps. Bellingcat has a core team of about 18 staffers that work with scores of volunteers around the globe. Higgins has written a new book called \"We Are Bellingcat. \" So in a way, you're a journalist. In a way, you're something a little different than a journalist. How would you describe your ethics in terms of what you publish and who you tell before publishing? HIGGINS: So because we're often involved in investigations where there might have been a crime committed and that there might be an ongoing police investigation, we have to be quite careful about what we publish, because when you publish open source information as part of an investigation, you're linking to the original sources. So they may be YouTube channels, Twitter accounts and other kind of links online. And often, when people get wind of what you're doing, they'll delete all that information. So by publishing something that's part of an ongoing police investigation, we can effectively destroy evidence that the police might find useful. So in the case of MH17, early on, I was contacted by the joint investigation team, who is the official criminal investigation, and interviewed as a witness. And they sat down with me for several hours as I went through kind of posts about MH17 line by line, kind of piece of evidence by piece of evidence. And they went away. And they seemed quite impressed by it. And they stayed in touch. And they asked if we found stuff that we would talk to them about it because they saw the value of, you know, preserving this evidence. So we started then - if we were finding information online and about to post an article, we would let them know that we're going to post this and that they needed to preserve anything that was interesting to them. Otherwise, it would be deleted forever. And because we kind of find ourselves in a - primarily as investigators rather than being a type of investigator, like an investigative journalist, we kind of find ourselves now more and more involved with criminal cases, especially international crimes such as, you know, war crimes and crimes against humanity, where we've kind of almost become the first line of response when stuff is shared online that shows these kind of crimes. So over the years, we've started to develop a process for investigation and archiving that allows us to preserve material, unless we're investigating it, in a way that it could be used by courts in the future, because more and more, there's this realization in bodies like the International Criminal Court, who I've worked with, that this open source evidence can be extremely valuable in locations where war crimes are happening. And they are often the only way these crimes are documented, sometimes in the moment they are being documented and they're occurring. So that's why they see more value in engaging with groups like Bellingcat and understanding how this kind of stuff is used, because when I first started doing this, I assumed, well, all these big bodies must understand what this stuff is because it's so useful. But as I've discovered over the last decade or so that these - that they - this was new to them. This was a completely new way of approaching this kind of information. And they didn't know how to use it themselves. So we've kind of ended up leading the way in the development of the use of open source evidence with bodies like the International Criminal Court. GROSS: What kind of work has Belingcat been doing about COVID? - because there's been a lot of misinformation about that and a whole campaign not to do the things that we're supposed to do to prevent the spread of COVID like wearing masks. HIGGINS: Yeah. We were involved with a project that looked into how COVID kind of conspiracy theories and misinformation were being generated. It was interesting there. You'd see Trump give his kind of nightly press conferences of - nightly for us in the U. K. , anyway - about coronavirus, these briefings. And then you'd see the kind of alt-right media kind of saying, this - actually, this is what Trump actually meant to say when he says something ridiculous or, you know, ah, but those libs have been owned by Trump being a genius again - you know, that kind of stuff. And then that would kind of get laundered through to kind of Fox News and the kind of more, you know, mainstream Republican kind of media. And then Donald Trump would watch it. And then it would create this kind of cycle of nonsense that was coming from Trump and going back to Trump and just go round and round again. And you could see this happening. You could see how the news sites would always report it in that kind of process. And it was really plain to see. And unfortunately, when you have people in positions of authority who are kind of spreading misinformation and disinformation, and you have a media system that is open to spreading that information for purely political purposes, then you're going to have a massive amount of misinformation being spread because it's happening at the very top levels of, you know, mainstream society. GROSS: Donald Trump was de-platformed from Facebook and Twitter. How have the groups that you followed that are more on the dark web, how have they been reacting to that? HIGGINS: I think, really - I mean, at the time, there was, you know, (laughter) rage. But at the same time, those Q supporters got knocked off Twitter. And, you know, it was, you know, a real massacre in many sense of all these social media accounts. And then Parler went offline. And there was kind of all these groups that were kind of splitting off. And, like, thedonald. win, which was the kind of big, pro-Trump message board that spawned off Reddit, that kind of collapsed and got relaunched. And basically, there was just a huge amount of drama with all these groups kind of, you know, reforming and collapsing again. And in a sense, I think they were so panicked about, you know, being kind of scattered to the winds that they didn't really have much more chance to think about anything else. But, you know, they're still out there. It's just they're kind of more on the obscure platforms now that most people, you know, never have heard about. But those communities are still out there. They still exist. And they're still waiting for Trump to return and for Q to post his next message. GROSS: Talk a little bit about the impact of this work on you personally because, like, when you're investigating war crimes and, you know, massacres, you end up looking at a lot of videos of victims. You've seen a lot of severed limbs. You've seen a lot of bloody bodies. You know, you write about how you try to disconnect yourself emotionally from what you're seeing, but really, that's easier said than done. So what has the impact of the work been on you emotionally? HIGGINS: I mean, the whole kind of - that period of starting the blog and, you know, going on was kind of strange for me because when I started doing this, I was someone who was, you know, very - had lots of anxiety. And, you know, I prefer to be at home. I didn't kind of like going out. But because of the work I was doing with the blog, I was kind of forced to, like, go on stage and speak in front of lots of important people. And it was terrifying. The first few times I did it, I can barely remember because I was just so out of my mind because of the anxiety about something going wrong. But it went well. I kept doing it and doing it and, over the years, built my confidence tremendously. It's had a really positive impact on me, along with the success of kind of my job at the moment, you know, with how Bellingcat's going. So at the same time, of course, I'm watching, like, really horrific conflict footage. And you can't disassociate it, you know, to a certain extent. But it still can be very difficult when you're looking at footage that's - it's not so much the horror of it. You can prepare yourself for the visceral horror of what you're seeing. But it's when you see something that gives you a kind of connection to something in your personal life. Like, I remember watching a video from Syria of a child dying from sarin, and that wasn't what was - brought me into the moment. It was that they were wearing the same nappy as I'd been using with my children. There's another time when I was looking at wreckage from MH17, looking for signs of impact from shrapnel. So I had to look at everything really close up. So I was kind of ignoring the blood and, you know, some of the bodies that were visible and focusing on the damage to the metal. But within that metal, there was this little toy rabbit doll, and it was exactly the same toy rabbit doll my sister-in-law gave my daughter when she was born. And that brings you right into that moment and what's happened there. So you have to kind of police yourself. You have to realize what those kind of trigger points are for yourself. And most important at Bellingcat is that we - you know, we talk to people about this. We engage with our staff about that. We, you know, make sure this is an environment where they can talk about those kind of, you know, moments and feelings and understand that it's not always the same for every single person. But I think myself, I was kind of - because I had that kind of weird positive development going alongside what was happening with my work, I think that may have offered me some kind of, you know, protection from it. But now, you know, I really dislike watching things like horror films now because I've seen injuries for real that - you know, when you see it in a horror film, it just, like, reminds you of seeing that stuff. And it's just - I don't get any enjoyment from, you know, being scared like that anymore. GROSS: Eliot Higgins, thank you so much for your work, and thank you so much for doing this interview. HIGGINS: Thanks for having me on. GROSS: Eliot Higgins is the founder of Bellingcat and author of the new book \"We Are Bellingcat. \" After we take a short break, our TV critic David Bianculli will tell us why he recommends the new Netflix miniseries \"Behind Her Eyes. \" This is FRESH AIR. (SOUNDBITE OF KEVIN EUBANKS AND STANLEY JORDAN'S \"OLD SCHOOL JAM\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-03-02-971745290": {"title": "What Is Bitcoin: Mother Of All Bubbles Or Revolutionary Breakthrough : NPR", "url": "https://www.npr.org/2021/03/02/971745290/bitcoin-revolutionary-breakthrough-or-mother-of-all-bubbles", "author": "No author found", "published_date": "2021-03-02", "content": "MARY LOUISE KELLY, HOST:  If you think America's politics are polarizing, consider Bitcoin. The price of a single bitcoin today is nearly $50,000. Ten years ago, in its infancy, it was around a buck. The digital currency's meteoric rise has minted millionaires. It has energized true believers around the world, which has only convinced skeptics that Bitcoin is the mother of all bubbles. NPR's Uri Berliner wades in. URI BERLINER, BYLINE: Nikki Beesetti was an engineering student at Purdue University facing money pressure and teaching a bit on the side. NIKKI BEESETTI: And I was getting paid about, I think, like, $10 an hour. It was just enough money for me to buy food and coffee and just get ramen. BERLINER: This was back in 2017. And being an engineering major, she was curious about Bitcoin - about its technology, its innovative design and maybe, just maybe, as an investment. So she did a lot of research and spent $2,000 dollars on a single bitcoin. And then. . . BEESETTI: I sold at the end of the year, when it was about $19,000. I got a email from my bursar's office telling me, this is how much you owe for the next semester. BERLINER: That single bitcoin she bought covered her tuition, books and lab fees, and in a way, it changed her life. She's still buying Bitcoin, still excited by its promise. BEESETTI: I think sometimes when you're very young, a new technology can really excite you, and it can really shape your future and the way you look at the world. And I think that was the case for me and Bitcoin. It's definitely made me more optimistic. It's definitely given me, like, a lot of things to look forward to, especially in a time when things can seem so lonely and dreary. BERLINER: There's a phrase for people who are all in on Bitcoin not just to get rich but as a force for good. They're called Bitcoin maximalists. George Mekhail is one of them. GEORGE MEKHAIL: I found something that I believe in. I found something that seems like it's - it has a benevolent mission to sort of help humanity. And so I stuck around. BERLINER: Mekhail is a mortgage professional in his day job and the co-author of a book called \"Thank God For Bitcoin\" on the moral case for the cryptocurrency. He started buying Bitcoin in 2017 and has continued buying and holding ever since. MEKHAIL: It's not like - we're not becoming astronomically wealthy yet. But if this thing does what we think it's going to do, we will be, and that will be a part of it. But I think it's important to note that that's not the motivation. That's a byproduct of being here. BERLINER: Here's the maximalist case for Bitcoin. The cryptocurrency is beyond politics at a time when many people mistrust government. It's not controlled by central banks or leaders craving popular approval. Mekhail calls Bitcoin money for the people. MEKHAIL: There's no CEO. There's no headquarters. So that's unique. BERLINER: Bitcoin is borderless. Bitcoin can't be counterfeited. And here's what might be the biggest argument of all on behalf of Bitcoin. The way it's designed, only 21 million bitcoins will ever exist. So it's like gold - finite and a hedge against inflation. In contrast, governments can print endless amounts of money. So, the argument goes, scarcity will keep Bitcoin valuable. There's only so much of it. That's the all-in maximalist case. Here's the more expedient one. (SOUNDBITE OF MONTAGE)REBECCA QUICK: Bitcoin rising this morning following news that Tesla has bought about $1. 5 billion in the cryptocurrency. UNIDENTIFIED REPORTER #1: Massachusetts Mutual Life Insurance buying $100 million worth of Bitcoin. SCOTT WAPNER: Let's talk rocket ships - first, Bitcoin. That falls into that category because that's what that is. BERLINER: Companies have been snapping up Bitcoin recently. So are ordinary people on apps like Robinhood, often buying a fraction of a Bitcoin at a time, all sending the price skyrocketing even higher. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED REPORTER #2: Check this out. Bitcoin - it broke through the $50,000 level just a short time ago. It's now up more than 70% since January 1. BERLINER: It's fallen a bit since then, but the phrase you hear about Bitcoin this year is FOMO. Given all this buzz, it's probably a good time to ask, what is Bitcoin? JAMES LEDBETTER: It is essentially a currency that's based on nothing except mathematics. BERLINER: James Ledbetter is the publisher of Fin, a financial technology newsletter. LEDBETTER: It doesn't correspond to anything that exists in the real world. BERLINER: But it does exist in the digital world. Each transaction is kept on a ledger. And who's keeping tabs on those transactions? They're called Bitcoin miners, digital miners. Anyone can be one. What they do is make sure that everything on the ledger is legitimate. LEDBETTER: It's verifying the transactions so that everybody can have faith that the system is clean and transparent. BERLINER: The system does have its drawbacks. Verifying those transactions takes a lot of computer power and uses a lot of energy. Cybercriminals have stolen Bitcoin and other cryptocurrencies from exchanges where they're traded. And bitcoin doesn't always go up. Its price has crashed several times before. So is Bitcoin an innovation that will improve the world, as true believers contend? Is it something more modest, a savvy financial hedge? Or is it a mirage? (SOUNDBITE OF TV SHOW, \"SQUAWK BOX\")WARREN BUFFETT: The asset itself is creating nothing. BERLINER: That's the legendary investor Warren Buffett on CNBC. He says Bitcoin doesn't lead to anything productive. He's even called it rat poison. A number of Nobel Prize-winning economists have warned against Bitcoin, saying it's a speculative bubble. One of them, Oliver Hart, wrote me in an email, like many economists, I don't understand why its price isn't zero. Bitcoin isn't used that much for actual buying and selling. It can be cumbersome. There are fees. Many economists say it's just way too volatile to be used as everyday currency. And they say Bitcoin is a solution for a problem that doesn't really exist. ROBERT SHILLER: We already have money. BERLINER: That's Robert Shiller of Yale University. SHILLER: What's special about Bitcoin? Well, it's special in our imagination. BERLINER: Shiller says Bitcoin is certainly fascinating. SHILLER: I have to say it's a great story - secret codes, computers that write codes that can't be broken. So there's a narrative about this particular invention that sounds like it belongs in a movie. BERLINER: Shiller is a Nobel Prize-winning economist known for his work on bubbles. And he says bubbles ride on a crest of enthusiasm, and there's plenty of enthusiasm about Bitcoin. One place he sees it is in his classroom at Yale. SHILLER: I teach a course, financial markets, and sometimes they seem to be falling asleep. I just bring up Bitcoin, and they suddenly perk up. BERLINER: Remember Nikki Beesetti, the former Purdue student who paid off her semester's tuition with Bitcoin? She thinks the enthusiasm is justified, that Bitcoin and its technology will have uses that are hard to imagine today. BEESETTI: When the Internet was just starting out 20 years ago, a lot of people didn't think that the Internet was going to become the next big thing. They didn't see a value in it. They didn't see the point in sharing all this information to everybody in the world. BERLINER: The next Internet, digital fool's gold or something else? The story of Bitcoin is evolving. So for now, it can be whatever you believe it to be. Uri Berliner, NPR News. MARY LOUISE KELLY, HOST:   If you think America's politics are polarizing, consider Bitcoin. The price of a single bitcoin today is nearly $50,000. Ten years ago, in its infancy, it was around a buck. The digital currency's meteoric rise has minted millionaires. It has energized true believers around the world, which has only convinced skeptics that Bitcoin is the mother of all bubbles. NPR's Uri Berliner wades in. URI BERLINER, BYLINE: Nikki Beesetti was an engineering student at Purdue University facing money pressure and teaching a bit on the side. NIKKI BEESETTI: And I was getting paid about, I think, like, $10 an hour. It was just enough money for me to buy food and coffee and just get ramen. BERLINER: This was back in 2017. And being an engineering major, she was curious about Bitcoin - about its technology, its innovative design and maybe, just maybe, as an investment. So she did a lot of research and spent $2,000 dollars on a single bitcoin. And then. . . BEESETTI: I sold at the end of the year, when it was about $19,000. I got a email from my bursar's office telling me, this is how much you owe for the next semester. BERLINER: That single bitcoin she bought covered her tuition, books and lab fees, and in a way, it changed her life. She's still buying Bitcoin, still excited by its promise. BEESETTI: I think sometimes when you're very young, a new technology can really excite you, and it can really shape your future and the way you look at the world. And I think that was the case for me and Bitcoin. It's definitely made me more optimistic. It's definitely given me, like, a lot of things to look forward to, especially in a time when things can seem so lonely and dreary. BERLINER: There's a phrase for people who are all in on Bitcoin not just to get rich but as a force for good. They're called Bitcoin maximalists. George Mekhail is one of them. GEORGE MEKHAIL: I found something that I believe in. I found something that seems like it's - it has a benevolent mission to sort of help humanity. And so I stuck around. BERLINER: Mekhail is a mortgage professional in his day job and the co-author of a book called \"Thank God For Bitcoin\" on the moral case for the cryptocurrency. He started buying Bitcoin in 2017 and has continued buying and holding ever since. MEKHAIL: It's not like - we're not becoming astronomically wealthy yet. But if this thing does what we think it's going to do, we will be, and that will be a part of it. But I think it's important to note that that's not the motivation. That's a byproduct of being here. BERLINER: Here's the maximalist case for Bitcoin. The cryptocurrency is beyond politics at a time when many people mistrust government. It's not controlled by central banks or leaders craving popular approval. Mekhail calls Bitcoin money for the people. MEKHAIL: There's no CEO. There's no headquarters. So that's unique. BERLINER: Bitcoin is borderless. Bitcoin can't be counterfeited. And here's what might be the biggest argument of all on behalf of Bitcoin. The way it's designed, only 21 million bitcoins will ever exist. So it's like gold - finite and a hedge against inflation. In contrast, governments can print endless amounts of money. So, the argument goes, scarcity will keep Bitcoin valuable. There's only so much of it. That's the all-in maximalist case. Here's the more expedient one. (SOUNDBITE OF MONTAGE) REBECCA QUICK: Bitcoin rising this morning following news that Tesla has bought about $1. 5 billion in the cryptocurrency. UNIDENTIFIED REPORTER #1: Massachusetts Mutual Life Insurance buying $100 million worth of Bitcoin. SCOTT WAPNER: Let's talk rocket ships - first, Bitcoin. That falls into that category because that's what that is. BERLINER: Companies have been snapping up Bitcoin recently. So are ordinary people on apps like Robinhood, often buying a fraction of a Bitcoin at a time, all sending the price skyrocketing even higher. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED REPORTER #2: Check this out. Bitcoin - it broke through the $50,000 level just a short time ago. It's now up more than 70% since January 1. BERLINER: It's fallen a bit since then, but the phrase you hear about Bitcoin this year is FOMO. Given all this buzz, it's probably a good time to ask, what is Bitcoin? JAMES LEDBETTER: It is essentially a currency that's based on nothing except mathematics. BERLINER: James Ledbetter is the publisher of Fin, a financial technology newsletter. LEDBETTER: It doesn't correspond to anything that exists in the real world. BERLINER: But it does exist in the digital world. Each transaction is kept on a ledger. And who's keeping tabs on those transactions? They're called Bitcoin miners, digital miners. Anyone can be one. What they do is make sure that everything on the ledger is legitimate. LEDBETTER: It's verifying the transactions so that everybody can have faith that the system is clean and transparent. BERLINER: The system does have its drawbacks. Verifying those transactions takes a lot of computer power and uses a lot of energy. Cybercriminals have stolen Bitcoin and other cryptocurrencies from exchanges where they're traded. And bitcoin doesn't always go up. Its price has crashed several times before. So is Bitcoin an innovation that will improve the world, as true believers contend? Is it something more modest, a savvy financial hedge? Or is it a mirage? (SOUNDBITE OF TV SHOW, \"SQUAWK BOX\") WARREN BUFFETT: The asset itself is creating nothing. BERLINER: That's the legendary investor Warren Buffett on CNBC. He says Bitcoin doesn't lead to anything productive. He's even called it rat poison. A number of Nobel Prize-winning economists have warned against Bitcoin, saying it's a speculative bubble. One of them, Oliver Hart, wrote me in an email, like many economists, I don't understand why its price isn't zero. Bitcoin isn't used that much for actual buying and selling. It can be cumbersome. There are fees. Many economists say it's just way too volatile to be used as everyday currency. And they say Bitcoin is a solution for a problem that doesn't really exist. ROBERT SHILLER: We already have money. BERLINER: That's Robert Shiller of Yale University. SHILLER: What's special about Bitcoin? Well, it's special in our imagination. BERLINER: Shiller says Bitcoin is certainly fascinating. SHILLER: I have to say it's a great story - secret codes, computers that write codes that can't be broken. So there's a narrative about this particular invention that sounds like it belongs in a movie. BERLINER: Shiller is a Nobel Prize-winning economist known for his work on bubbles. And he says bubbles ride on a crest of enthusiasm, and there's plenty of enthusiasm about Bitcoin. One place he sees it is in his classroom at Yale. SHILLER: I teach a course, financial markets, and sometimes they seem to be falling asleep. I just bring up Bitcoin, and they suddenly perk up. BERLINER: Remember Nikki Beesetti, the former Purdue student who paid off her semester's tuition with Bitcoin? She thinks the enthusiasm is justified, that Bitcoin and its technology will have uses that are hard to imagine today. BEESETTI: When the Internet was just starting out 20 years ago, a lot of people didn't think that the Internet was going to become the next big thing. They didn't see a value in it. They didn't see the point in sharing all this information to everybody in the world. BERLINER: The next Internet, digital fool's gold or something else? The story of Bitcoin is evolving. So for now, it can be whatever you believe it to be. Uri Berliner, NPR News.", "section": "Your Money", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-03-02-971289977": {"title": "Conspiracy Theories Spread Rapidly Because Of Trump, Social Media, Experts Say : NPR", "url": "https://www.npr.org/2021/03/02/971289977/through-the-looking-glass-conspiracy-theories-spread-faster-and-wider-than-ever", "author": "No author found", "published_date": "2021-03-02", "content": "", "section": "Untangling Disinformation", "disclaimer": ""}, "2021-03-03-971457702": {"title": "Disinformation And Conspiracy Theories: Experts Work To Deprogram Americans  : NPR", "url": "https://www.npr.org/2021/03/03/971457702/exit-counselors-strain-to-pull-americans-out-of-a-web-of-false-conspiracies", "author": "No author found", "published_date": "2021-03-03", "content": "", "section": "Untangling Disinformation", "disclaimer": ""}, "2021-03-04-973791982": {"title": "A Small Choral Group Is Betting Big On Tokenizing Their Art With Blockchain : NPR", "url": "https://www.npr.org/2021/03/04/973791982/a-small-choral-group-is-betting-big-on-tokenizing-their-art-with-blockchain", "author": "No author found", "published_date": "2021-03-04", "content": "ARI SHAPIRO, HOST:  Blockchain has taken the art world by storm. That is the technology that powers cryptocurrencies like Bitcoin. These digital art pieces - paintings, gifts and videos - are fetching tens of thousands, even millions of dollars online. Some big names in music have started offering fans crypto collectibles. Christie's has even started auctioning crypto art pieces. And a small choral group in Dallas thinks their new piece could also draw big bucks using this technology. Miguel Perez with member station KERA sat in on a recording session with Verdigris Ensemble to find out more. UNIDENTIFIED SINGERS: (Singing). ANTHONY MAGLIONE: Can we stop? Sorry to be a pain. MIGUEL PEREZ, BYLINE: Producer Anthony Maglione is shuffling through sheet music inside a recording studio in Dallas. It's almost 10 p. m. , the end of a five-hour session for the singers on the other side of the glass. UNIDENTIFIED SINGERS: (Vocalizing). MAGLIONE: Yeah. All right. Yeah. That was a much better take. Well done. PEREZ: Sam Brukhman, the founder of Verdigris Ensemble, is sitting next to Maglione. They're in the middle of recording a piece called \"Betty's Notebook,\" which composer Nicholas Reeves based on the story of Betty Klenck, who claimed to have her distress signals from Amelia Earhart on her radio. SAM BRUKHMAN: It's like we're putting the audience in front of a really old 1930s radio. But there's all of this sort of, like, white noise and jazz standards and other things that block us from clearly hearing what Amelia Earhart was saying on that day. PEREZ: Now, the group has performed \"Betty's Notebook\" live before, but this time, they're working with a digital art platform called Async Art to transform this new recording into a one-of-a-kind sound installation using blockchain technology. And Brukhman wants to sell the piece to the highest bidder. BRUKHMAN: We've gotten very positive feedback from several museums and galleries across the world. Whether that's actually going to happen, I just don't know. PEREZ: The choral group has poured a lot of money into this, hiring a production team and buying valuable studio time. It's a huge risk. BRUKHMAN: But I wouldn't do it if I didn't, like, really, truly see the vision and how it could be successful. And I see it so clearly. PEREZ: The use of blockchain in the digital art world has been gaining steam for several years now. So how does it work? Let's say you create a digital painting, and you share it on Twitter. It goes viral, and it's copied and pasted all over the Internet. You don't get a cent from that, and no one even knows that you made it. But what if you had created a piece of code, a unique digital token attached to the work that helps solve the problem? BLAKE FINUCANE: You can prove that you're the original owner of something that exists online - an image that exists online, a video that exists online - in ways that have never been possible before. PEREZ: Blake Finucane wrote one of the first academic papers on tokenized art. These digital works are known as NFTs, non-fungible tokens. And that means they're not interchangeable. Each one is special and identifiable. It's that non-fungibility that helps keep track of things like provenance and authenticity. Finucane says that, in turn, creates scarcity for digital art. Elena Zavelev has spent a lot of time explaining NFTs to art professionals as the founder of New Art Academy in New York. ELENA ZAVELEV: The clearest value potentially is actually artists getting paid sort of like a royalty on the resale of their works. PEREZ: Musicians can write their own royalty terms into an NFT - for example, guaranteeing a 10% cut every time the piece is resold. Music and technology writer Cherie Hu says this kind of system could be a game-changer in music, where artists get paid fractions of a penny per stream. CHERIE HU: All signs seem to be pointing to, like, a race to the bottom on pricing. Royalty rates have actually not been increasing. They've only been decreasing kind of as these streaming services scale, and that's definitely worrying to a lot of artists and to the music industry. So anything that can kind of help reverse that course is appealing to them. PEREZ: Instead of chasing streams by the millions, Hu says musicians could sell a single NFT - say, to a superfan or a gallery - for a similar price tag. Now, that's not the same as buying the definitive, sole copy of a song, though. The artist hasn't handed over the copyright or the distribution rights to the music. HU: Something I often say that's, like - makes more sense to the music industry, it's like a digital piece of rare merch. PEREZ: Like a unique gift paired with an unreleased demo. That's what Canadian pop artist Grimes just auctioned off. One of her debut NFTs sold for more than $380,000. And Sam Brukhman with Verdigris is banking on a similar outcome for his choral group. He set the bidding to start at $150,000. BRUKHMAN: We could very well at the end of this entire process sell \"Betty's Notebook\" and actually, like, make a profit and be able to support and give a fair wage not just to our producer or our sound engineer or the composer, but also to the singers. PEREZ: Certain corners of the music world are well-versed in crypto art, like electronic artists. But an NFT from a choral group is pretty much unheard of. Whether crypto art is a passing fad or the future of art collecting, right now, Verdigris is hoping it'll pay off. I'm Miguel Perez in Dallas. (SOUNDBITE OF SUNSQUABI'S \"ANYTIME\") ARI SHAPIRO, HOST:   Blockchain has taken the art world by storm. That is the technology that powers cryptocurrencies like Bitcoin. These digital art pieces - paintings, gifts and videos - are fetching tens of thousands, even millions of dollars online. Some big names in music have started offering fans crypto collectibles. Christie's has even started auctioning crypto art pieces. And a small choral group in Dallas thinks their new piece could also draw big bucks using this technology. Miguel Perez with member station KERA sat in on a recording session with Verdigris Ensemble to find out more. UNIDENTIFIED SINGERS: (Singing). ANTHONY MAGLIONE: Can we stop? Sorry to be a pain. MIGUEL PEREZ, BYLINE: Producer Anthony Maglione is shuffling through sheet music inside a recording studio in Dallas. It's almost 10 p. m. , the end of a five-hour session for the singers on the other side of the glass. UNIDENTIFIED SINGERS: (Vocalizing). MAGLIONE: Yeah. All right. Yeah. That was a much better take. Well done. PEREZ: Sam Brukhman, the founder of Verdigris Ensemble, is sitting next to Maglione. They're in the middle of recording a piece called \"Betty's Notebook,\" which composer Nicholas Reeves based on the story of Betty Klenck, who claimed to have her distress signals from Amelia Earhart on her radio. SAM BRUKHMAN: It's like we're putting the audience in front of a really old 1930s radio. But there's all of this sort of, like, white noise and jazz standards and other things that block us from clearly hearing what Amelia Earhart was saying on that day. PEREZ: Now, the group has performed \"Betty's Notebook\" live before, but this time, they're working with a digital art platform called Async Art to transform this new recording into a one-of-a-kind sound installation using blockchain technology. And Brukhman wants to sell the piece to the highest bidder. BRUKHMAN: We've gotten very positive feedback from several museums and galleries across the world. Whether that's actually going to happen, I just don't know. PEREZ: The choral group has poured a lot of money into this, hiring a production team and buying valuable studio time. It's a huge risk. BRUKHMAN: But I wouldn't do it if I didn't, like, really, truly see the vision and how it could be successful. And I see it so clearly. PEREZ: The use of blockchain in the digital art world has been gaining steam for several years now. So how does it work? Let's say you create a digital painting, and you share it on Twitter. It goes viral, and it's copied and pasted all over the Internet. You don't get a cent from that, and no one even knows that you made it. But what if you had created a piece of code, a unique digital token attached to the work that helps solve the problem? BLAKE FINUCANE: You can prove that you're the original owner of something that exists online - an image that exists online, a video that exists online - in ways that have never been possible before. PEREZ: Blake Finucane wrote one of the first academic papers on tokenized art. These digital works are known as NFTs, non-fungible tokens. And that means they're not interchangeable. Each one is special and identifiable. It's that non-fungibility that helps keep track of things like provenance and authenticity. Finucane says that, in turn, creates scarcity for digital art. Elena Zavelev has spent a lot of time explaining NFTs to art professionals as the founder of New Art Academy in New York. ELENA ZAVELEV: The clearest value potentially is actually artists getting paid sort of like a royalty on the resale of their works. PEREZ: Musicians can write their own royalty terms into an NFT - for example, guaranteeing a 10% cut every time the piece is resold. Music and technology writer Cherie Hu says this kind of system could be a game-changer in music, where artists get paid fractions of a penny per stream. CHERIE HU: All signs seem to be pointing to, like, a race to the bottom on pricing. Royalty rates have actually not been increasing. They've only been decreasing kind of as these streaming services scale, and that's definitely worrying to a lot of artists and to the music industry. So anything that can kind of help reverse that course is appealing to them. PEREZ: Instead of chasing streams by the millions, Hu says musicians could sell a single NFT - say, to a superfan or a gallery - for a similar price tag. Now, that's not the same as buying the definitive, sole copy of a song, though. The artist hasn't handed over the copyright or the distribution rights to the music. HU: Something I often say that's, like - makes more sense to the music industry, it's like a digital piece of rare merch. PEREZ: Like a unique gift paired with an unreleased demo. That's what Canadian pop artist Grimes just auctioned off. One of her debut NFTs sold for more than $380,000. And Sam Brukhman with Verdigris is banking on a similar outcome for his choral group. He set the bidding to start at $150,000. BRUKHMAN: We could very well at the end of this entire process sell \"Betty's Notebook\" and actually, like, make a profit and be able to support and give a fair wage not just to our producer or our sound engineer or the composer, but also to the singers. PEREZ: Certain corners of the music world are well-versed in crypto art, like electronic artists. But an NFT from a choral group is pretty much unheard of. Whether crypto art is a passing fad or the future of art collecting, right now, Verdigris is hoping it'll pay off. I'm Miguel Perez in Dallas. (SOUNDBITE OF SUNSQUABI'S \"ANYTIME\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-03-04-973610866": {"title": "Insect-Size Flying Robots Could Help On Rescue Missions, MIT Scientist Says : NPR", "url": "https://www.npr.org/2021/03/04/973610866/dont-swat-this-bug-it-might-be-a-robot-on-a-rescue-mission", "author": "No author found", "published_date": "2021-03-04", "content": "", "section": "Technology", "disclaimer": ""}, "2021-03-05-974089381": {"title": "What's An NFT? And Why Are People Paying Millions To Buy Them? : NPR", "url": "https://www.npr.org/2021/03/05/974089381/whats-an-nft-and-why-are-people-paying-millions-to-buy-them", "author": "No author found", "published_date": "2021-03-05", "content": "", "section": "Pop Culture", "disclaimer": ""}, "2021-03-05-974173496": {"title": "Twitter Tests New Products And Experiments Like 'Super Follows' : NPR", "url": "https://www.npr.org/2021/03/05/974173496/twitter-tests-new-products-and-experiments-like-super-follows", "author": "No author found", "published_date": "2021-03-05", "content": "MARY LOUISE KELLY, HOST:  In Silicon Valley, things change pretty quickly. But not at Twitter. The social network has long been the exception to the rule innovate or die. Now Twitter is racing to catch up with a whole bunch of new products and experiments, things like subscriptions, groups and something called super follows. NPR tech correspondent Shannon Bond is here to tell us more. Hey, Shannon. SHANNON BOND, BYLINE: Hey, Mary Louise. KELLY: So super follows - what is this? BOND: Well, this is an idea that a Twitter user could set a price, say, $1 or $5 a month and let others subscribe to basically a premium version of their Twitter feed. And, you know, you might be wondering, why would anyone pay to read tweets? KELLY: Yeah (laughter). BOND: The idea is that people could sell - right (laughter). But the idea is people could sell bonus content, right? So an exclusive newsletter or membership in a group. Maybe a musician could give their super followers bonus tracks. A filmmaker could give an early sneak peek of a movie trailer. And maybe those things would be worth some money, or at least that's what Twitter is hoping. We don't know a lot of the details or when this will start to roll out, other than, Twitter says, sometime this year. KELLY: It's interesting because, as we noted, Twitter is not known for innovation. This seems like a departure for them. BOND: Yeah, I mean, one of the last big changes Twitter made was doubling the length of a tweet. That was back in 2017. KELLY: Yeah. BOND: And now it's making a lot of changes. It's more than just super follows. Twitter bought a newsletter company. It's experimenting with audio chatrooms and disappearing posts. It plans to introduce groups around particular interests or topics, like a sports team. Many of these things are efforts to bring in more users and more money. You know, they could boost its core advertising business and also bring in new revenue sources like this kind of subscription income. KELLY: Disappearing posts - I don't know if that sounds terrifying or great. Why now? Why is Twitter thinking about doing all this now? BOND: Well, let's actually go back to a year ago when Twitter was targeted by a hedge fund that tried to oust CEO Jack Dorsey. And this hedge fund said, you know, he wasn't focused enough on Twitter, on making it better by really - which, ultimately, they mean, you know, making more money for shareholders. So last week, in this presentation to Wall Street analysts and investors unveiling a lot of these new ideas, Dorsey made this kind of surprising acknowledgment about Twitter's weaknesses. (SOUNDBITE OF ARCHIVED RECORDING)JACK DORSEY: Why don't we start with why folks don't believe in us? It comes down to three critiques - we're slow, we're not innovative, and we're not trusted. BOND: I mean, and look - you know, Twitter is much smaller than Facebook. It hasn't grown as quickly as Snapchat and TikTok. But now we see this company - you know, Dorsey's really pushing it to put a big emphasis on these new products and experiments. He has these two ambitious goals he wants to reach by the end of 2023. One is to get a lot more users - to get to 315 million daily users from, you know, under 200 million right now - and to more than double annual sales. And to reach both of these goals, it really comes down to getting people to use Twitter more and use it for more things. KELLY: Do we know what the feedback to these changes has been so far from Twitter users? BOND: Well, you know, we focus on super follows - you know, I think there have been a lot of jokes about this. You know, exactly why would you pay for tweets? I mean, this is a website where the recurring punch line you see on Twitter all the time - this website is free. KELLY: Is free, yeah. (LAUGHTER)BOND: Right. And look - I don't think most people are going to charge for their tweets. This is an idea that's very much targeted at people with big followings, high profiles, like musicians, like influencers, who might release exclusive content for their super followers. You know, that's the kind of content people are going to pay for. That's not what most people are using Twitter for. But more broadly, you know, it's not just investors that complain Twitter has been slow to improve. Users do, too. But when users talk about it, they're worried about keeping people safe from harassment and abuse, curbing bogus claims. That's what users think Twitter should be focusing on. KELLY: That is NPR tech correspondent and Twitter user Shannon Bond. Thanks, Shannon. BOND: Thanks, Mary Louise. MARY LOUISE KELLY, HOST:   In Silicon Valley, things change pretty quickly. But not at Twitter. The social network has long been the exception to the rule innovate or die. Now Twitter is racing to catch up with a whole bunch of new products and experiments, things like subscriptions, groups and something called super follows. NPR tech correspondent Shannon Bond is here to tell us more. Hey, Shannon. SHANNON BOND, BYLINE: Hey, Mary Louise. KELLY: So super follows - what is this? BOND: Well, this is an idea that a Twitter user could set a price, say, $1 or $5 a month and let others subscribe to basically a premium version of their Twitter feed. And, you know, you might be wondering, why would anyone pay to read tweets? KELLY: Yeah (laughter). BOND: The idea is that people could sell - right (laughter). But the idea is people could sell bonus content, right? So an exclusive newsletter or membership in a group. Maybe a musician could give their super followers bonus tracks. A filmmaker could give an early sneak peek of a movie trailer. And maybe those things would be worth some money, or at least that's what Twitter is hoping. We don't know a lot of the details or when this will start to roll out, other than, Twitter says, sometime this year. KELLY: It's interesting because, as we noted, Twitter is not known for innovation. This seems like a departure for them. BOND: Yeah, I mean, one of the last big changes Twitter made was doubling the length of a tweet. That was back in 2017. KELLY: Yeah. BOND: And now it's making a lot of changes. It's more than just super follows. Twitter bought a newsletter company. It's experimenting with audio chatrooms and disappearing posts. It plans to introduce groups around particular interests or topics, like a sports team. Many of these things are efforts to bring in more users and more money. You know, they could boost its core advertising business and also bring in new revenue sources like this kind of subscription income. KELLY: Disappearing posts - I don't know if that sounds terrifying or great. Why now? Why is Twitter thinking about doing all this now? BOND: Well, let's actually go back to a year ago when Twitter was targeted by a hedge fund that tried to oust CEO Jack Dorsey. And this hedge fund said, you know, he wasn't focused enough on Twitter, on making it better by really - which, ultimately, they mean, you know, making more money for shareholders. So last week, in this presentation to Wall Street analysts and investors unveiling a lot of these new ideas, Dorsey made this kind of surprising acknowledgment about Twitter's weaknesses. (SOUNDBITE OF ARCHIVED RECORDING) JACK DORSEY: Why don't we start with why folks don't believe in us? It comes down to three critiques - we're slow, we're not innovative, and we're not trusted. BOND: I mean, and look - you know, Twitter is much smaller than Facebook. It hasn't grown as quickly as Snapchat and TikTok. But now we see this company - you know, Dorsey's really pushing it to put a big emphasis on these new products and experiments. He has these two ambitious goals he wants to reach by the end of 2023. One is to get a lot more users - to get to 315 million daily users from, you know, under 200 million right now - and to more than double annual sales. And to reach both of these goals, it really comes down to getting people to use Twitter more and use it for more things. KELLY: Do we know what the feedback to these changes has been so far from Twitter users? BOND: Well, you know, we focus on super follows - you know, I think there have been a lot of jokes about this. You know, exactly why would you pay for tweets? I mean, this is a website where the recurring punch line you see on Twitter all the time - this website is free. KELLY: Is free, yeah. (LAUGHTER) BOND: Right. And look - I don't think most people are going to charge for their tweets. This is an idea that's very much targeted at people with big followings, high profiles, like musicians, like influencers, who might release exclusive content for their super followers. You know, that's the kind of content people are going to pay for. That's not what most people are using Twitter for. But more broadly, you know, it's not just investors that complain Twitter has been slow to improve. Users do, too. But when users talk about it, they're worried about keeping people safe from harassment and abuse, curbing bogus claims. That's what users think Twitter should be focusing on. KELLY: That is NPR tech correspondent and Twitter user Shannon Bond. Thanks, Shannon. BOND: Thanks, Mary Louise.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-03-05-971767967": {"title": "How Online Disinformation Will Keep Expanding In 2021 : NPR", "url": "https://www.npr.org/2021/03/05/971767967/trump-is-no-longer-tweeting-but-online-disinformation-isnt-going-away", "author": "No author found", "published_date": "2021-03-05", "content": "", "section": "Untangling Disinformation", "disclaimer": ""}, "2021-03-05-973929514": {"title": "What's A Non-Fungible Token? Why Some Collectors Are Spending Millions On Them : NPR", "url": "https://www.npr.org/2021/03/05/973929514/whats-a-non-fungible-token-why-some-collectors-are-spending-millions-them", "author": "No author found", "published_date": "2021-03-05", "content": "NOEL KING, HOST:  The latest Internet hype is about a thing that doesn't really exist. Some collectors are spending millions of dollars on digital items called NFTs, and here's the thing - anyone can make one of these. NPR's Bobby Allyn explains. BOBBY ALLYN, BYLINE: A meme of an animated cat with a Pop-Tart body, a video clip of Kobe Bryant dunking, an image of an oil painting of Batman - all have sold for hundreds of thousands of dollars apiece in recent weeks. KATIE HAUN: Remember those days where people would line up for the newest, you know, Nike Air Jordan sneakers at the physical store? This is the new digital equivalent. ALLYN: Katie Haun is a general partner at the venture capital firm Andreessen Horowitz. They are plunging big bucks into NFTs. That's short for a nonfungible token. In plain English, that means a collector's item that lives on the Internet. HAUN: It's everything that brings together culture, and it's also a bet on the future of e-commerce. ALLYN: The artist Grimes recently made nearly $6 million selling NFTs like a piece of art featuring a baby floating in space. The NBA has seen more than $200 million in NFT sales from clips of game moments. OK, OK, but what exactly are people buying? I asked NFT expert Donna Redel. DONNA REDEL: So what you get is a very interesting question. ALLYN: So anything on the Internet can be downloaded and copied and shared infinitely, right? An NFT is trying to bring order to that chaos. It's a unique barcode, a certificate of authenticity that says, this thing on the Internet is mine, and nobody else can have it. Here's how NFT enthusiast Jake Bruckman puts it. JAKE BRUCKMAN: These are the property rights to digital content. ALLYN: Bruckman runs an NFT art gallery. He says the new craze is tapping into a couple things. First, people have always like to collect - comic books, Beanie Babies, baseball cards - and now it's NFTs. Then he says the NFT movement has something in common with the WallStreetBets group on Reddit who sent the price of GameStop soaring. BRUCKMAN: This is all, like, part of the same process that we're seeing. People, especially young people, they're finding it more natural, more easier than ever to coordinate on the Internet in the form of digital communities. ALLYN: He says in these communities of people hanging out together online, an NFT gives you clout. Its cachet, whether it's a pixelated alien face there are only nine of or a photo of Lindsay Lohan. Now, this is the Internet, so not shocking that some are taking NFTs to absurd places. Some have turned tweets into NFTs. Bruckman has seen it all. BRUCKMAN: I saw a project the other day which was selling colors (laughter) - off-white and (laughter) like, dark orange. ALLYN: You still might be asking yourself, what? Why? So I thought I'd give it a shot. I went online to an NFT marketplace where you bid on items, in cryptocurrency, of course. I stumbled on something that caught my eye, a stop-motion animation of a box of French fries where the fries move like a jellyfish. OK, I'll say it's worth three bucks. Prices on these things can be pretty volatile. I tracked down the artist, a guy named Javier Perez Estrella in Ecuador. I was asking him some questions about the art, but then he said, wait, wait, which NFT are you talking about now? JAVIER PEREZ ESTRELLA: Yeah - because I have a lot of animations with French fries, and I want to be sure. ALLYN: He confirmed, yes, we are talking about the same French fry animation. Last I checked, someone outbid me with a $77 bet. Bobby Allyn, NPR News, San Francisco. (SOUNDBITE OF PENSEES' \"FACELESS ARTIST\") NOEL KING, HOST:   The latest Internet hype is about a thing that doesn't really exist. Some collectors are spending millions of dollars on digital items called NFTs, and here's the thing - anyone can make one of these. NPR's Bobby Allyn explains. BOBBY ALLYN, BYLINE: A meme of an animated cat with a Pop-Tart body, a video clip of Kobe Bryant dunking, an image of an oil painting of Batman - all have sold for hundreds of thousands of dollars apiece in recent weeks. KATIE HAUN: Remember those days where people would line up for the newest, you know, Nike Air Jordan sneakers at the physical store? This is the new digital equivalent. ALLYN: Katie Haun is a general partner at the venture capital firm Andreessen Horowitz. They are plunging big bucks into NFTs. That's short for a nonfungible token. In plain English, that means a collector's item that lives on the Internet. HAUN: It's everything that brings together culture, and it's also a bet on the future of e-commerce. ALLYN: The artist Grimes recently made nearly $6 million selling NFTs like a piece of art featuring a baby floating in space. The NBA has seen more than $200 million in NFT sales from clips of game moments. OK, OK, but what exactly are people buying? I asked NFT expert Donna Redel. DONNA REDEL: So what you get is a very interesting question. ALLYN: So anything on the Internet can be downloaded and copied and shared infinitely, right? An NFT is trying to bring order to that chaos. It's a unique barcode, a certificate of authenticity that says, this thing on the Internet is mine, and nobody else can have it. Here's how NFT enthusiast Jake Bruckman puts it. JAKE BRUCKMAN: These are the property rights to digital content. ALLYN: Bruckman runs an NFT art gallery. He says the new craze is tapping into a couple things. First, people have always like to collect - comic books, Beanie Babies, baseball cards - and now it's NFTs. Then he says the NFT movement has something in common with the WallStreetBets group on Reddit who sent the price of GameStop soaring. BRUCKMAN: This is all, like, part of the same process that we're seeing. People, especially young people, they're finding it more natural, more easier than ever to coordinate on the Internet in the form of digital communities. ALLYN: He says in these communities of people hanging out together online, an NFT gives you clout. Its cachet, whether it's a pixelated alien face there are only nine of or a photo of Lindsay Lohan. Now, this is the Internet, so not shocking that some are taking NFTs to absurd places. Some have turned tweets into NFTs. Bruckman has seen it all. BRUCKMAN: I saw a project the other day which was selling colors (laughter) - off-white and (laughter) like, dark orange. ALLYN: You still might be asking yourself, what? Why? So I thought I'd give it a shot. I went online to an NFT marketplace where you bid on items, in cryptocurrency, of course. I stumbled on something that caught my eye, a stop-motion animation of a box of French fries where the fries move like a jellyfish. OK, I'll say it's worth three bucks. Prices on these things can be pretty volatile. I tracked down the artist, a guy named Javier Perez Estrella in Ecuador. I was asking him some questions about the art, but then he said, wait, wait, which NFT are you talking about now? JAVIER PEREZ ESTRELLA: Yeah - because I have a lot of animations with French fries, and I want to be sure. ALLYN: He confirmed, yes, we are talking about the same French fry animation. Last I checked, someone outbid me with a $77 bet. Bobby Allyn, NPR News, San Francisco. (SOUNDBITE OF PENSEES' \"FACELESS ARTIST\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-03-05-973373489": {"title": "NPR Poll Tracks Parents' Views On Remote Learning And The Pandemic : NPR", "url": "https://www.npr.org/2021/03/05/973373489/npr-ipsos-poll-nearly-one-third-of-parents-may-stick-with-remote-learning", "author": "No author found", "published_date": "2021-03-05", "content": "NOEL KING, HOST:  We are a year into the pandemic, a year of school closures. But an NPR/Ipsos poll of parents in the U. S. finds some optimism about academic and social development. More than 4 out of 5 parents would like extra services to help their kids catch up. Just over half are in favor of summer school. Anya Kamenetz from NPR's education team helped design this poll. Good morning, Anya. ANYA KAMENETZ, BYLINE: Good morning, Noel. KING: What were you polling to find out? KAMENETZ: We felt like the way that the school reopening debate has sometimes been covered, we're generally hearing only the loudest, most disgruntled voices, or else we're trying to focus on the families who are really vulnerable and being left out. So we wanted to get a more representative national view on how parents are feeling about this school year and also what they'd like to see happen next. KING: OK. And what'd you find? KAMENETZ: So obviously, this has not been a seamless school year for most people. Many schools have opened for in-person learning, gone from virtual to hybrid, closed, gone back again. Almost half of parents told us they were, quote, \"worried that my child will be behind when the pandemic is over. \"KING: When they say falling behind, what do they mean? KAMENETZ: Well, this was puzzling because when we tried to drill down, large majorities of parents actually judge their kids to be on track or even ahead of schedule in math and science, in reading and writing, in mental health, emotional well-being - even the socialization and communication skills and time management. KING: OK. So it sounds like they're worried their kids are behind, but they can't actually really say how. KAMENETZ: Exactly. And also - yeah. And also, parents are giving pretty high marks to their kids' schools. Four out of 5 said, my child's school has handled the pandemic well. And about the same number said their schools had clearly communicated during the year. And that's kind of different from how, you know, sometimes the conflicts over school reopening had been portrayed. KING: Yeah, 4 out of 5 is telling. What are parents thinking about next school year? KAMENETZ: You know, most parents expect things to go back to quote-unquote, \"normal. \" Exactly 3 out of 4 of the parents we polled expect their children's schools to open full time in person next fall. And even sooner than that, about half of those attending hybrid and/or remote right now expect schools to open full time in person just as soon as the teachers are all vaccinated. And, you know, President Biden just put a move on that. He recently directed all states to prioritize educators for their shots as soon as this month. However, when you think about, you know, schools opening five days a week in person, teachers getting vaccinated is not the only concern. Currently, CDC guidelines recommend 6 feet of distance between students, and most schools have only been able to achieve that by having a hybrid or part-time schedule. KING: So full time still might not happen in the fall in some schools. KAMENETZ: I mean, that is a big story that we're going to continue to cover. But, you know, we should also point out that there are kids who are thriving with online learning. So Joshua Jessep in Discovery Bay in Northern California told us. . . JOSHUA JESSEP: My son actually sits with me here in my office as I work. You can see he's busy over there. And so I'm able to keep a really close track of, you know, daily assignments, make sure he's not goofing off. KAMENETZ: So with his son as his co-worker, his grades are now straight A's. And, overall, fully 29% of parents said they were either somewhat or very likely to choose remote learning indefinitely. KING: My eyes just fell out of my head. Almost one-third of parents say we'd like to keep our kids learning at home? That would be massive. KAMENETZ: Yeah. And many districts are already setting up district-wide virtual learning programs. This is a change that could have ripples far beyond the pandemic. KING: President Biden's American Rescue Plan has set aside some funds to address learning loss. Did you ask parents what they're looking for in there? KAMENETZ: Yes, and all of these recovery proposals are very popular. More than 4 in 5 parents want some kind of customized service to help their kids with those catch-up worries that they have. KING: NPR education correspondent Anya Kamenetz. Thanks, Anya. KAMENETZ: Thanks, Noel. NOEL KING, HOST:   We are a year into the pandemic, a year of school closures. But an NPR/Ipsos poll of parents in the U. S. finds some optimism about academic and social development. More than 4 out of 5 parents would like extra services to help their kids catch up. Just over half are in favor of summer school. Anya Kamenetz from NPR's education team helped design this poll. Good morning, Anya. ANYA KAMENETZ, BYLINE: Good morning, Noel. KING: What were you polling to find out? KAMENETZ: We felt like the way that the school reopening debate has sometimes been covered, we're generally hearing only the loudest, most disgruntled voices, or else we're trying to focus on the families who are really vulnerable and being left out. So we wanted to get a more representative national view on how parents are feeling about this school year and also what they'd like to see happen next. KING: OK. And what'd you find? KAMENETZ: So obviously, this has not been a seamless school year for most people. Many schools have opened for in-person learning, gone from virtual to hybrid, closed, gone back again. Almost half of parents told us they were, quote, \"worried that my child will be behind when the pandemic is over. \" KING: When they say falling behind, what do they mean? KAMENETZ: Well, this was puzzling because when we tried to drill down, large majorities of parents actually judge their kids to be on track or even ahead of schedule in math and science, in reading and writing, in mental health, emotional well-being - even the socialization and communication skills and time management. KING: OK. So it sounds like they're worried their kids are behind, but they can't actually really say how. KAMENETZ: Exactly. And also - yeah. And also, parents are giving pretty high marks to their kids' schools. Four out of 5 said, my child's school has handled the pandemic well. And about the same number said their schools had clearly communicated during the year. And that's kind of different from how, you know, sometimes the conflicts over school reopening had been portrayed. KING: Yeah, 4 out of 5 is telling. What are parents thinking about next school year? KAMENETZ: You know, most parents expect things to go back to quote-unquote, \"normal. \" Exactly 3 out of 4 of the parents we polled expect their children's schools to open full time in person next fall. And even sooner than that, about half of those attending hybrid and/or remote right now expect schools to open full time in person just as soon as the teachers are all vaccinated. And, you know, President Biden just put a move on that. He recently directed all states to prioritize educators for their shots as soon as this month. However, when you think about, you know, schools opening five days a week in person, teachers getting vaccinated is not the only concern. Currently, CDC guidelines recommend 6 feet of distance between students, and most schools have only been able to achieve that by having a hybrid or part-time schedule. KING: So full time still might not happen in the fall in some schools. KAMENETZ: I mean, that is a big story that we're going to continue to cover. But, you know, we should also point out that there are kids who are thriving with online learning. So Joshua Jessep in Discovery Bay in Northern California told us. . . JOSHUA JESSEP: My son actually sits with me here in my office as I work. You can see he's busy over there. And so I'm able to keep a really close track of, you know, daily assignments, make sure he's not goofing off. KAMENETZ: So with his son as his co-worker, his grades are now straight A's. And, overall, fully 29% of parents said they were either somewhat or very likely to choose remote learning indefinitely. KING: My eyes just fell out of my head. Almost one-third of parents say we'd like to keep our kids learning at home? That would be massive. KAMENETZ: Yeah. And many districts are already setting up district-wide virtual learning programs. This is a change that could have ripples far beyond the pandemic. KING: President Biden's American Rescue Plan has set aside some funds to address learning loss. Did you ask parents what they're looking for in there? KAMENETZ: Yes, and all of these recovery proposals are very popular. More than 4 in 5 parents want some kind of customized service to help their kids with those catch-up worries that they have. KING: NPR education correspondent Anya Kamenetz. Thanks, Anya. KAMENETZ: Thanks, Noel.", "section": "The Coronavirus Crisis", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-03-06-974394783": {"title": "Far-Right Misinformation Drives Facebook Engagement : NPR", "url": "https://www.npr.org/2021/03/06/974394783/far-right-misinformation-is-thriving-on-facebook-a-new-study-shows-just-how-much", "author": "No author found", "published_date": "2021-03-06", "content": "MICHEL MARTIN, HOST:  We've talked a lot in recent years about misinformation and about how it spreads online, but we have new information about that. You might remember that Facebook has promised repeatedly in recent years to address the spread of conspiracy theories and misinformation on its site. But a new study from researchers at New York University shows that far-right accounts known for spreading misinformation are not only thriving on Facebook - they are actually more successful than other kinds of accounts aimed at getting likes, shares and other forms of user engagement. Laura Edelson helped lead that research. She is part of Cybersecurity for Democracy, a group based at NYU that's studying online misinformation. And she's with us now. Laura Edelson, thank you so much for being with us. LAURA EDELSON: Great to be here. MARTIN: And I do want to note that Facebook is among NPR's financial supporters. With that being said, could you walk us through these findings in nonexpert terms? As briefly as you can, what question was your research team looking at, and what did you find? EDELSON: Absolutely. So after the events of the last few months, we really wanted to understand how different types of news media engaged with their audiences on Facebook. So we got third-party evaluations of news quality and partisanship, and we combined that with Facebook data about engagement. And what we found is that overall, far-right news sources have much more engagement with their audiences than other partisan categories. But most of that edge comes from sources with a reputation for spreading misinformation. So on the far-right, misinformation sources outperformed more reputable sources by quite a bit. But for all other partisan categories, including slightly right, the reverse was true. Sources with a reputation for spreading misinformation performed worse, and usually significantly so. And we call that effect a misinformation penalty. MARTIN: So when you talk about a far-right news source, do you feel comfortable giving us an example that we might recognize? I know what I certainly think of, but what are you thinking of? EDELSON: So some of the top-performing far-right news sources in our data set were things like Newsmax, Breitbart - that kind of media source. MARTIN: And you and your colleagues say that far-right content is the only partisan leaning in which misinformation actually drives more engagement. And there is no what you call misinformation penalty. Could you just talk a little bit more about that? So a misinformation penalty is what? Is that if you are demonstrated to be inaccurate or false, then what? People who are on the left side of the ledger would give you less credibility. Is that it? EDELSON: So we can't say exactly why it's happening. But what we see is that for left-leaning sources, for center sources, and even slightly right, the sources that have a reputation for spreading misinformation just don't engage as well. There could be a variety of reasons for that. But certainly, the simplest explanation would be that users don't find them as credible and don't want to engage with them. MARTIN: But you're saying that misinformation actually drives more engagement with far-right content, which is remarkable. EDELSON: Yeah. The effect was quite striking because it's not a small edge, either. It's almost twice as much engagement, you know, per follower among the sources that have a reputation for spreading misinformation. So clearly, that portion of the news ecosystem is just behaving very differently. MARTIN: And it's my understanding that Facebook responded by saying engagement isn't the same as how many people actually see a piece of content. So perhaps you could talk a little bit more about that. Like, what do we know about how Facebook promotes content? And what do you make of their response? MARTIN: Well, we really don't know that much about how Facebook promotes content. We know that engagement is part of what drives Facebook's algorithm for promoting content, but they really don't make a lot of information about that available. Frankly, I would love for Facebook to make the data available that backs this assertion, but they don't make it public. And this is where I just think Facebook can't have it both ways. They can't say that their data leads to a different conclusion but then not make that data public. MARTIN: I recognize that the purpose of the study is to analyze what is as opposed to, say, what should be. But does your team have recommendations? Because it sounds like - I mean, and I understand exactly what you're saying - there is not sort of publicly available data from Facebook that would help us understand why far-right misinformation drives more engagement. But it sounds from what you're telling us that people seek this stuff out and believe it because they want to. They want to seek it out, and they want to engage with it. So if that's the case, do you have recommendations about that? EDELSON: I think what's very clear is that Facebook has a misinformation problem. I think any system that attempts to promote the most engaging content, from what we can tell, will wind up promoting misinformation. And just to pull out one portion of our data that I know I was really concerned about when I saw it is, you know, of course, we saw a spike of engagement with news content on January 6. That's to be expected. The thing was that most of that spike was concentrated among the partisan extremes and misinformation providers. And when I really sit back and think about that, I think the idea that on a day like that, which was so scary and so uncertain, that the most extreme and least reputable sources were the ones that Facebook users were engaging with is pretty troubling. And I think those are the kinds of circumstances where especially Facebook has a responsibility to its users and to the wider public to do a better job of stopping misinformation from spreading. And I think, you know, that's true every day. MARTIN: That was Laura Edelson. She's a Ph. D. candidate at New York University and a researcher with Cybersecurity for Democracy. Laura Edelson, thank you so much for being with us and sharing this work with us. EDELSON: Thanks for having me. (SOUNDBITE OF MISTY SAPPHIRE'S \"BLAZO\") MICHEL MARTIN, HOST:   We've talked a lot in recent years about misinformation and about how it spreads online, but we have new information about that. You might remember that Facebook has promised repeatedly in recent years to address the spread of conspiracy theories and misinformation on its site. But a new study from researchers at New York University shows that far-right accounts known for spreading misinformation are not only thriving on Facebook - they are actually more successful than other kinds of accounts aimed at getting likes, shares and other forms of user engagement. Laura Edelson helped lead that research. She is part of Cybersecurity for Democracy, a group based at NYU that's studying online misinformation. And she's with us now. Laura Edelson, thank you so much for being with us. LAURA EDELSON: Great to be here. MARTIN: And I do want to note that Facebook is among NPR's financial supporters. With that being said, could you walk us through these findings in nonexpert terms? As briefly as you can, what question was your research team looking at, and what did you find? EDELSON: Absolutely. So after the events of the last few months, we really wanted to understand how different types of news media engaged with their audiences on Facebook. So we got third-party evaluations of news quality and partisanship, and we combined that with Facebook data about engagement. And what we found is that overall, far-right news sources have much more engagement with their audiences than other partisan categories. But most of that edge comes from sources with a reputation for spreading misinformation. So on the far-right, misinformation sources outperformed more reputable sources by quite a bit. But for all other partisan categories, including slightly right, the reverse was true. Sources with a reputation for spreading misinformation performed worse, and usually significantly so. And we call that effect a misinformation penalty. MARTIN: So when you talk about a far-right news source, do you feel comfortable giving us an example that we might recognize? I know what I certainly think of, but what are you thinking of? EDELSON: So some of the top-performing far-right news sources in our data set were things like Newsmax, Breitbart - that kind of media source. MARTIN: And you and your colleagues say that far-right content is the only partisan leaning in which misinformation actually drives more engagement. And there is no what you call misinformation penalty. Could you just talk a little bit more about that? So a misinformation penalty is what? Is that if you are demonstrated to be inaccurate or false, then what? People who are on the left side of the ledger would give you less credibility. Is that it? EDELSON: So we can't say exactly why it's happening. But what we see is that for left-leaning sources, for center sources, and even slightly right, the sources that have a reputation for spreading misinformation just don't engage as well. There could be a variety of reasons for that. But certainly, the simplest explanation would be that users don't find them as credible and don't want to engage with them. MARTIN: But you're saying that misinformation actually drives more engagement with far-right content, which is remarkable. EDELSON: Yeah. The effect was quite striking because it's not a small edge, either. It's almost twice as much engagement, you know, per follower among the sources that have a reputation for spreading misinformation. So clearly, that portion of the news ecosystem is just behaving very differently. MARTIN: And it's my understanding that Facebook responded by saying engagement isn't the same as how many people actually see a piece of content. So perhaps you could talk a little bit more about that. Like, what do we know about how Facebook promotes content? And what do you make of their response? MARTIN: Well, we really don't know that much about how Facebook promotes content. We know that engagement is part of what drives Facebook's algorithm for promoting content, but they really don't make a lot of information about that available. Frankly, I would love for Facebook to make the data available that backs this assertion, but they don't make it public. And this is where I just think Facebook can't have it both ways. They can't say that their data leads to a different conclusion but then not make that data public. MARTIN: I recognize that the purpose of the study is to analyze what is as opposed to, say, what should be. But does your team have recommendations? Because it sounds like - I mean, and I understand exactly what you're saying - there is not sort of publicly available data from Facebook that would help us understand why far-right misinformation drives more engagement. But it sounds from what you're telling us that people seek this stuff out and believe it because they want to. They want to seek it out, and they want to engage with it. So if that's the case, do you have recommendations about that? EDELSON: I think what's very clear is that Facebook has a misinformation problem. I think any system that attempts to promote the most engaging content, from what we can tell, will wind up promoting misinformation. And just to pull out one portion of our data that I know I was really concerned about when I saw it is, you know, of course, we saw a spike of engagement with news content on January 6. That's to be expected. The thing was that most of that spike was concentrated among the partisan extremes and misinformation providers. And when I really sit back and think about that, I think the idea that on a day like that, which was so scary and so uncertain, that the most extreme and least reputable sources were the ones that Facebook users were engaging with is pretty troubling. And I think those are the kinds of circumstances where especially Facebook has a responsibility to its users and to the wider public to do a better job of stopping misinformation from spreading. And I think, you know, that's true every day. MARTIN: That was Laura Edelson. She's a Ph. D. candidate at New York University and a researcher with Cybersecurity for Democracy. Laura Edelson, thank you so much for being with us and sharing this work with us. EDELSON: Thanks for having me. (SOUNDBITE OF MISTY SAPPHIRE'S \"BLAZO\")", "section": "Politics", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-03-06-974056831": {"title": "Pok\u00e9mon Legends: Arceus Will Feature Open World Design : NPR", "url": "https://www.npr.org/2021/03/06/974056831/new-pokemon-game-goes-off-the-beaten-path", "author": "No author found", "published_date": "2021-03-06", "content": "", "section": "Games", "disclaimer": ""}, "2021-03-06-973439404": {"title": "California Bill Targets NDAs That Block Talk of Workplace Discrimination : NPR", "url": "https://www.npr.org/2021/03/06/973439404/it-really-is-a-gag-order-california-may-limit-nondisclosure-agreements", "author": "No author found", "published_date": "2021-03-06", "content": "SCOTT SIMON, HOST:  If you work at a big company in America, you may have had to sign a nondisclosure agreement. NDAs keep workers from speaking out about what happens at the office, including discrimination and harassment. They're as broad as they are common, and as member station KQED's Rachael Myrow reports, now they're being challenged in California. RACHAEL MYROW, BYLINE: NDAs scare most people away from speaking publicly about their employers for nearly any reason about almost anything, especially in Silicon Valley. IFEOMA OZOMA: They're multibillion-dollar corporations. If Pinterest decided to sue me, I would be bankrupted. MYROW: That's Ifeoma Ozoma, who used to have a high-profile position at the social media company, Pinterest. She left a couple of years ago after complaining about racial discrimination among other things. She stayed silent about it because she'd signed an NDA. But then last summer, Pinterest joined thousands of American companies voicing support for the Black Lives Matter movement. Put off by what she saw as performative hypocrisy, Ozoma decided to break her NDA and go public. OZOMA: I wasn't being paid fairly, and - according to the company's own chart, while I was still the public face of all of the work that was being used to prop the company up as a responsible tech company in a sea of irresponsible ones. MYROW: Pinterest first insisted Ozoma was treated fairly, then acknowledged parts of its culture were broken and praised unnamed employees for the, quote, \"courage to share your experiences honestly and openly. \" Today, Ozoma agrees it did take courage, courage she exercised only after consulting with a lawyer. OZOMA: The agreements are written so broadly, you can't even legally speak to your spouse about what happened. It really is a gag order. And it compounds the harm because you've already experienced the discrimination or harassment. You've been pushed out of your job, and now you can't even explain to people why you left. CONNIE LEYVA: You can't fix a problem if you don't know there's a problem. MYROW: State Senator Connie Leyva, a Democrat from Southern California, has written a bill that would help workers like Ozoma. While California law protects employees who speak out about sex or gender-related harassment, this new bill would do more. It would also protect speech about race, ethnicity, age, disability and religion. Leyva says the #MeToo Movement and Black Lives Matter have exposed the way NDAs serve as corporate cover for illegal behavior. LEYVA: Sure, if you're Coca-Cola, and you don't want somebody giving away the secret ingredients of Coke, no problem. We understand that. But people should always have the right to be able to speak out against any form of discrimination that they've had at the job place. MYROW: Typically, companies in California leave it to trade groups and chambers of commerce that represent business to come out publicly against bills they don't like. But this time, they are all silent. That speaks volumes to labor law professor Veena Dubal at the University of California, Hastings. VEENA DUBAL: I don't imagine that any of these very sophisticated PR representatives at these companies would come out and say, no, we're against this bill, even though it may very well do real damage to companies' reputations where there are cultures of harassment and discrimination. MYROW: Even though this bill, if it passes, would only apply in California, Ozoma says she hopes it will bring an end to a long-standing form of corporate overreach at some of the world's largest companies. OZOMA: What I'm hoping it does is shift the court of public opinion, along with the legislation such that companies think twice before going after employees who do decide to break NDAs. MYROW: As for her, after working for Google and Facebook as well as Pinterest, she's done being anyone's employee. Ozoma has launched her own consulting business, focusing on tech accountability issues. For NPR News, I'm Rachael Myrow. (SOUNDBITE OF MENAHAN STREET BAND'S \"QUEENS HIGHWAY\") SCOTT SIMON, HOST:   If you work at a big company in America, you may have had to sign a nondisclosure agreement. NDAs keep workers from speaking out about what happens at the office, including discrimination and harassment. They're as broad as they are common, and as member station KQED's Rachael Myrow reports, now they're being challenged in California. RACHAEL MYROW, BYLINE: NDAs scare most people away from speaking publicly about their employers for nearly any reason about almost anything, especially in Silicon Valley. IFEOMA OZOMA: They're multibillion-dollar corporations. If Pinterest decided to sue me, I would be bankrupted. MYROW: That's Ifeoma Ozoma, who used to have a high-profile position at the social media company, Pinterest. She left a couple of years ago after complaining about racial discrimination among other things. She stayed silent about it because she'd signed an NDA. But then last summer, Pinterest joined thousands of American companies voicing support for the Black Lives Matter movement. Put off by what she saw as performative hypocrisy, Ozoma decided to break her NDA and go public. OZOMA: I wasn't being paid fairly, and - according to the company's own chart, while I was still the public face of all of the work that was being used to prop the company up as a responsible tech company in a sea of irresponsible ones. MYROW: Pinterest first insisted Ozoma was treated fairly, then acknowledged parts of its culture were broken and praised unnamed employees for the, quote, \"courage to share your experiences honestly and openly. \" Today, Ozoma agrees it did take courage, courage she exercised only after consulting with a lawyer. OZOMA: The agreements are written so broadly, you can't even legally speak to your spouse about what happened. It really is a gag order. And it compounds the harm because you've already experienced the discrimination or harassment. You've been pushed out of your job, and now you can't even explain to people why you left. CONNIE LEYVA: You can't fix a problem if you don't know there's a problem. MYROW: State Senator Connie Leyva, a Democrat from Southern California, has written a bill that would help workers like Ozoma. While California law protects employees who speak out about sex or gender-related harassment, this new bill would do more. It would also protect speech about race, ethnicity, age, disability and religion. Leyva says the #MeToo Movement and Black Lives Matter have exposed the way NDAs serve as corporate cover for illegal behavior. LEYVA: Sure, if you're Coca-Cola, and you don't want somebody giving away the secret ingredients of Coke, no problem. We understand that. But people should always have the right to be able to speak out against any form of discrimination that they've had at the job place. MYROW: Typically, companies in California leave it to trade groups and chambers of commerce that represent business to come out publicly against bills they don't like. But this time, they are all silent. That speaks volumes to labor law professor Veena Dubal at the University of California, Hastings. VEENA DUBAL: I don't imagine that any of these very sophisticated PR representatives at these companies would come out and say, no, we're against this bill, even though it may very well do real damage to companies' reputations where there are cultures of harassment and discrimination. MYROW: Even though this bill, if it passes, would only apply in California, Ozoma says she hopes it will bring an end to a long-standing form of corporate overreach at some of the world's largest companies. OZOMA: What I'm hoping it does is shift the court of public opinion, along with the legislation such that companies think twice before going after employees who do decide to break NDAs. MYROW: As for her, after working for Google and Facebook as well as Pinterest, she's done being anyone's employee. Ozoma has launched her own consulting business, focusing on tech accountability issues. For NPR News, I'm Rachael Myrow. (SOUNDBITE OF MENAHAN STREET BAND'S \"QUEENS HIGHWAY\")", "section": "Business", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-03-07-974495259": {"title": "Officials Frustrated Over Vaccine Management Tech : NPR", "url": "https://www.npr.org/2021/03/07/974495259/officials-frustrated-over-vaccine-management-tech", "author": "No author found", "published_date": "2021-03-07", "content": "LULU GARCIA-NAVARRO, HOST:  Software - it's actually at the heart of the vaccination program. But glitches, bugs and website fiascos have led to frustration among vaccine-seekers and clinic managers. Twenty-seven states paid hundreds of thousands of dollars to one nonprofit for a vaccine management program that did not work. Reporter Angus Chen comes to us with the story of how this program came to be and a look at how it fell short in one state. ANGUS CHEN, BYLINE: Vaccine eligibility finally came to Tracey Lowenstein's group - people in Massachusetts 65 or older and those with two preexisting conditions. So she grabbed her laptop and her phone and prepared to pounce on a spot. TRACEY LOWENSTEIN: You know, I'm sitting on my couch with my whole little, like, command station going, full of excitement and hope. CHEN: Lowenstein went to the state vaccine website, where she hoped to book an appointment. The software she had to use is called PrepMod. Massachusetts bought it to streamline the coronavirus vaccine rollout. But Lowenstein found herself filling out the same online form over and over as the website crashed on her repeatedly. She'd get an error message that PrepMod had stopped working or that too many people were on the site. So she'd try again. She'd click, click and crash. This went on for hours. LOWENSTEIN: This was infuriating. It was really and truly eight hours just in this constant cycle. I was cursing. I won't tell you on the radio, but oh, yeah. CHEN: At the end of those eight hours, she was one of the few who got a spot. But she's hardly the only person seething over PrepMod. California and Virginia switched to PrepMod after struggling with their free program provided by the Centers for Disease Control and Prevention. But then, like many of the 27 states that purchased it, they had issues with the software. Overbooked clinics and duplicate data entries are two problems health officials reported. Shaun McAuliffe, a local board of health director in Massachusetts, says the program just crashes on him when trying to manage patient information. SHAUN MCAULIFFE: I'd enter the data. I'd get my error message, and I'm like, my God, I still can't get it right. CHEN: McAuliffe says sometimes PrepMod works well, but a lot of time, it's just hard to use. And whenever he runs a clinic now, he worries the system will fail once again. MCAULIFFE: I'm taking a risk running a clinic tomorrow because I don't know if I'm going to be able to use PrepMod. CHEN: A nonprofit called the Maryland Partnership for Prevention created PrepMod. For decades, this nonprofit improved flu vaccinations in public schools. And it created a small software program to make that easier. When the pandemic came around, Tiffany Tate, the nonprofit's executive director, realized her program could be repurposed. TIFFANY TATE: When the pandemic came along is when we said, well, let's evolve it and add a few more features and then make it available to everyone. CHEN: Massachusetts paid over $400,000 for the program in total. Tate says part of the problem in that state was a million people became eligible for the vaccine at once and rushed the PrepMod website. The page wasn't prepared for that kind of traffic. TATE: And that's something that we've been working on since the moment that it happened. So this is an opportunity to apologize and to do better. CHEN: Part of the issue might be that PrepMod wasn't built from the ground up to be pandemic software. It's a flu vaccine program adapted for the coronavirus. Olivia Adams is a software developer who created her own vaccine website while on maternity leave to help people find appointments in Massachusetts. OLIVIA ADAMS: When you're thinking about the flu vaccine every year, you don't have a line of 3,000 people outside of Target at 6 a. m. trying to get their flu vaccine the first day it's available. CHEN: The people who are used to creating medical software aren't the same that are dealing with things like concert ticket sales, Adams says. So they might not have the experience to get everything right. Even so, she says the PrepMod developers and Massachusetts could have predicted these issues and stopped them from happening in the first place. ADAMS: I think that this was very foreseeable, and I'm surprised that we didn't see it coming and do more about it. CHEN: For now, PrepMod is all her state has. She only hopes its developers will use the feedback and continue to improve the program so it doesn't hold the vaccine rollout back anymore. For NPR News, I'm Angus Chen. LULU GARCIA-NAVARRO, HOST:   Software - it's actually at the heart of the vaccination program. But glitches, bugs and website fiascos have led to frustration among vaccine-seekers and clinic managers. Twenty-seven states paid hundreds of thousands of dollars to one nonprofit for a vaccine management program that did not work. Reporter Angus Chen comes to us with the story of how this program came to be and a look at how it fell short in one state. ANGUS CHEN, BYLINE: Vaccine eligibility finally came to Tracey Lowenstein's group - people in Massachusetts 65 or older and those with two preexisting conditions. So she grabbed her laptop and her phone and prepared to pounce on a spot. TRACEY LOWENSTEIN: You know, I'm sitting on my couch with my whole little, like, command station going, full of excitement and hope. CHEN: Lowenstein went to the state vaccine website, where she hoped to book an appointment. The software she had to use is called PrepMod. Massachusetts bought it to streamline the coronavirus vaccine rollout. But Lowenstein found herself filling out the same online form over and over as the website crashed on her repeatedly. She'd get an error message that PrepMod had stopped working or that too many people were on the site. So she'd try again. She'd click, click and crash. This went on for hours. LOWENSTEIN: This was infuriating. It was really and truly eight hours just in this constant cycle. I was cursing. I won't tell you on the radio, but oh, yeah. CHEN: At the end of those eight hours, she was one of the few who got a spot. But she's hardly the only person seething over PrepMod. California and Virginia switched to PrepMod after struggling with their free program provided by the Centers for Disease Control and Prevention. But then, like many of the 27 states that purchased it, they had issues with the software. Overbooked clinics and duplicate data entries are two problems health officials reported. Shaun McAuliffe, a local board of health director in Massachusetts, says the program just crashes on him when trying to manage patient information. SHAUN MCAULIFFE: I'd enter the data. I'd get my error message, and I'm like, my God, I still can't get it right. CHEN: McAuliffe says sometimes PrepMod works well, but a lot of time, it's just hard to use. And whenever he runs a clinic now, he worries the system will fail once again. MCAULIFFE: I'm taking a risk running a clinic tomorrow because I don't know if I'm going to be able to use PrepMod. CHEN: A nonprofit called the Maryland Partnership for Prevention created PrepMod. For decades, this nonprofit improved flu vaccinations in public schools. And it created a small software program to make that easier. When the pandemic came around, Tiffany Tate, the nonprofit's executive director, realized her program could be repurposed. TIFFANY TATE: When the pandemic came along is when we said, well, let's evolve it and add a few more features and then make it available to everyone. CHEN: Massachusetts paid over $400,000 for the program in total. Tate says part of the problem in that state was a million people became eligible for the vaccine at once and rushed the PrepMod website. The page wasn't prepared for that kind of traffic. TATE: And that's something that we've been working on since the moment that it happened. So this is an opportunity to apologize and to do better. CHEN: Part of the issue might be that PrepMod wasn't built from the ground up to be pandemic software. It's a flu vaccine program adapted for the coronavirus. Olivia Adams is a software developer who created her own vaccine website while on maternity leave to help people find appointments in Massachusetts. OLIVIA ADAMS: When you're thinking about the flu vaccine every year, you don't have a line of 3,000 people outside of Target at 6 a. m. trying to get their flu vaccine the first day it's available. CHEN: The people who are used to creating medical software aren't the same that are dealing with things like concert ticket sales, Adams says. So they might not have the experience to get everything right. Even so, she says the PrepMod developers and Massachusetts could have predicted these issues and stopped them from happening in the first place. ADAMS: I think that this was very foreseeable, and I'm surprised that we didn't see it coming and do more about it. CHEN: For now, PrepMod is all her state has. She only hopes its developers will use the feedback and continue to improve the program so it doesn't hold the vaccine rollout back anymore. For NPR News, I'm Angus Chen.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-03-08-972764825": {"title": "Walter Isaacson's 'Code Breaker' Spotlights The Woman At The Forefront Of CRISPR : NPR", "url": "https://www.npr.org/2021/03/08/972764825/walter-isaacsons-code-breaker-spotlights-the-woman-at-the-forefront-of-crispr", "author": "No author found", "published_date": "2021-03-08", "content": "", "section": "Book Reviews", "disclaimer": ""}, "2021-03-09-974893374": {"title": "Roblox Gaming Platform Has IPO : NPR", "url": "https://www.npr.org/2021/03/09/974893374/roblox-goes-public-whats-roblox-ask-anyone-with-kids", "author": "No author found", "published_date": "2021-03-09", "content": "MARY LOUISE KELLY, HOST:  If you have a child, know a child - maybe you are a child - you may be familiar with Roblox. The online gaming platform's popularity has exploded in the pandemic. With more than 32. 6 million people playing daily, the company plans to go public tomorrow. So what is Roblox? NPR's Mandalit del Barco reports. MANDALIT DEL BARCO, BYLINE: During lockdown, my 9-year-old daughter Amaya has been playing Roblox with her friends nonstop. AMAYA: Guys, look. There's a roller coaster. UNIDENTIFIED CHILD: I want to go on the roller coaster. DEL BARCO: They can't be with each other in person, but they can enjoy virtual amusement parks together. They can pretend to go to school together and play dress-up. AMAYA: Do you want to be twins and freak the people out again? UNIDENTIFIED CHILD: Oh, yes. AMAYA: Oh, OK. DEL BARCO: Mostly, they follow each other around different virtual environments. UNIDENTIFIED CHILD: Ooh, that was close. AMAYA: I. . . UNIDENTIFIED CHILD: Ah. AMAYA: (Laughter) I almost squished you. PJ MCNEALY: Roblox is a bit of a substitute babysitter when parents need a break at home. DEL BARCO: P. J. McNealy is the CEO of Digital World Research. He says Roblox has benefited during COVID by having a captive audience. He describes the platform this way. MCNEALY: Minecraft meets Nintendo, which meets Lego. And mobile phones enables a whole bunch of it. They're starting with certainly the younger demographic and building their way up. DEL BARCO: McNealy says going public will allow Roblox to build a digital empire beyond gaming. MCNEALY: This money will either give them an opportunity to build more content for the platform or to go to adjacent platforms, like music or partnering with Spotify or a movie service. That's where this is going to go. DEL BARCO: The company's CEO David Baszucki, known as Builder Man, co-founded Roblox in 2004. He estimates three-quarters of American children age 9 through 12 hang out on Roblox every month. DAVID BASZUCKI: We're crushing it right now. And in the midst of COVID, we've seen an explosion of older players on the platform. So how do we make it possible for Roblox to connect everyone in the world? DEL BARCO: During a conference for its game developers last summer, Baszucki laid out his dreams for the company. That includes making movies with Roblox content and creating a universal translator for people around the globe to gather in a collective virtual space. BASZUCKI: This is ultimately the dream of so many of us for so many years way back to the science fiction community. We have our own personal vision of the metaverse. DEL BARCO: Last year, Roblox presented an online experience tied to the recent \"Wonder Woman\" film, and the platform hosted several virtual concerts. (CHEERING)DEL BARCO: In November, players put their avatars in the audience to sing and dance alongside Lil Nas X's avatar as he performed for them. (SOUNDBITE OF SONG, \"HOLIDAY\")LIL NAS X: (Rapping) I can't even stay away from the game that I play. They gon' (ph) know us today. DEL BARCO: In January, Roblox announced it had already raised $535 million for what it calls its human experience platform. It hosts games created by the players themselves. Alex Hicks was just 13 when he went from playing Roblox games to designing them. Now 24, he has his own nearly $2 million game development studio with 10 employees. They created the games Robloxian High School and World Zero. ALEX HICKS: With other games, if you get bored of that game, you'd stop playing it. But with Roblox, there's just a constant stream of titles to play. And you can just see what your friends are up to, go hang out with them. It makes you realize that this is probably the future of social engagement. If you can watch it with other people at the same time, it's just that much more engaging. And I think that's what Roblox really gets - is the social aspect. DEL BARCO: Twenty-year-old Zoe Basil lives with roommates she first met on Roblox. She's a computer programmer who works on the platform's popular game Adopt Me! She likes that anyone can publish a game on the platform. ZOE BASIL: When you're just, like, a 13-year-old making a game in your bedroom, you don't really have all these internalized rules, and you kind of just make whatever you want. It's kind of like outsider art, and I think that's awesome. DEL BARCO: Megan Letter is a Roblox superstar with her virtual pet unicorn, Honey. She has more than 3 million subscribers for her daily YouTube channel Megan Plays. (SOUNDBITE OF ARCHIVED RECORDING)MEGAN LETTER: Hey. What's up, you guys? It's Megan. Welcome back to my channel, peachy squad. Today I thought it would be really fun to dress up as a pet and see if we can catch any scammers in Roblox Adopt Me! Let's get into it. DEL BARCO: The 25-year-old influencer from Dallas has other YouTube channels and a merchandise line. She and her husband Zach also run their own studio, where they develop the game Overlook Bay. LETTER: My husband and I are really, really excited for Roblox to go public. And I know personally we're planning to invest because Roblox is only getting bigger and bigger. We live and breathe Roblox, so to hear it's going to go public, it's going to be massive. DEL BARCO: She and so many others are eager to see what's next for Roblox after it files a direct listing of its stock. Mandalit del Barco, NPR News. (SOUNDBITE OF METRONOMY SONG, \"THE LOOK\") MARY LOUISE KELLY, HOST:   If you have a child, know a child - maybe you are a child - you may be familiar with Roblox. The online gaming platform's popularity has exploded in the pandemic. With more than 32. 6 million people playing daily, the company plans to go public tomorrow. So what is Roblox? NPR's Mandalit del Barco reports. MANDALIT DEL BARCO, BYLINE: During lockdown, my 9-year-old daughter Amaya has been playing Roblox with her friends nonstop. AMAYA: Guys, look. There's a roller coaster. UNIDENTIFIED CHILD: I want to go on the roller coaster. DEL BARCO: They can't be with each other in person, but they can enjoy virtual amusement parks together. They can pretend to go to school together and play dress-up. AMAYA: Do you want to be twins and freak the people out again? UNIDENTIFIED CHILD: Oh, yes. AMAYA: Oh, OK. DEL BARCO: Mostly, they follow each other around different virtual environments. UNIDENTIFIED CHILD: Ooh, that was close. AMAYA: I. . . UNIDENTIFIED CHILD: Ah. AMAYA: (Laughter) I almost squished you. PJ MCNEALY: Roblox is a bit of a substitute babysitter when parents need a break at home. DEL BARCO: P. J. McNealy is the CEO of Digital World Research. He says Roblox has benefited during COVID by having a captive audience. He describes the platform this way. MCNEALY: Minecraft meets Nintendo, which meets Lego. And mobile phones enables a whole bunch of it. They're starting with certainly the younger demographic and building their way up. DEL BARCO: McNealy says going public will allow Roblox to build a digital empire beyond gaming. MCNEALY: This money will either give them an opportunity to build more content for the platform or to go to adjacent platforms, like music or partnering with Spotify or a movie service. That's where this is going to go. DEL BARCO: The company's CEO David Baszucki, known as Builder Man, co-founded Roblox in 2004. He estimates three-quarters of American children age 9 through 12 hang out on Roblox every month. DAVID BASZUCKI: We're crushing it right now. And in the midst of COVID, we've seen an explosion of older players on the platform. So how do we make it possible for Roblox to connect everyone in the world? DEL BARCO: During a conference for its game developers last summer, Baszucki laid out his dreams for the company. That includes making movies with Roblox content and creating a universal translator for people around the globe to gather in a collective virtual space. BASZUCKI: This is ultimately the dream of so many of us for so many years way back to the science fiction community. We have our own personal vision of the metaverse. DEL BARCO: Last year, Roblox presented an online experience tied to the recent \"Wonder Woman\" film, and the platform hosted several virtual concerts. (CHEERING) DEL BARCO: In November, players put their avatars in the audience to sing and dance alongside Lil Nas X's avatar as he performed for them. (SOUNDBITE OF SONG, \"HOLIDAY\") LIL NAS X: (Rapping) I can't even stay away from the game that I play. They gon' (ph) know us today. DEL BARCO: In January, Roblox announced it had already raised $535 million for what it calls its human experience platform. It hosts games created by the players themselves. Alex Hicks was just 13 when he went from playing Roblox games to designing them. Now 24, he has his own nearly $2 million game development studio with 10 employees. They created the games Robloxian High School and World Zero. ALEX HICKS: With other games, if you get bored of that game, you'd stop playing it. But with Roblox, there's just a constant stream of titles to play. And you can just see what your friends are up to, go hang out with them. It makes you realize that this is probably the future of social engagement. If you can watch it with other people at the same time, it's just that much more engaging. And I think that's what Roblox really gets - is the social aspect. DEL BARCO: Twenty-year-old Zoe Basil lives with roommates she first met on Roblox. She's a computer programmer who works on the platform's popular game Adopt Me! She likes that anyone can publish a game on the platform. ZOE BASIL: When you're just, like, a 13-year-old making a game in your bedroom, you don't really have all these internalized rules, and you kind of just make whatever you want. It's kind of like outsider art, and I think that's awesome. DEL BARCO: Megan Letter is a Roblox superstar with her virtual pet unicorn, Honey. She has more than 3 million subscribers for her daily YouTube channel Megan Plays. (SOUNDBITE OF ARCHIVED RECORDING) MEGAN LETTER: Hey. What's up, you guys? It's Megan. Welcome back to my channel, peachy squad. Today I thought it would be really fun to dress up as a pet and see if we can catch any scammers in Roblox Adopt Me! Let's get into it. DEL BARCO: The 25-year-old influencer from Dallas has other YouTube channels and a merchandise line. She and her husband Zach also run their own studio, where they develop the game Overlook Bay. LETTER: My husband and I are really, really excited for Roblox to go public. And I know personally we're planning to invest because Roblox is only getting bigger and bigger. We live and breathe Roblox, so to hear it's going to go public, it's going to be massive. DEL BARCO: She and so many others are eager to see what's next for Roblox after it files a direct listing of its stock. Mandalit del Barco, NPR News. (SOUNDBITE OF METRONOMY SONG, \"THE LOOK\")", "section": "Games", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-03-09-975032249": {"title": "Instagram Algorithms Serve Up COVID-19 Misinformation, Study Finds : NPR", "url": "https://www.npr.org/2021/03/09/975032249/instagram-suggested-posts-to-users-it-served-up-covid-19-falsehoods-study-finds", "author": "No author found", "published_date": "2021-03-09", "content": "", "section": "Untangling Disinformation", "disclaimer": ""}, "2021-03-10-975598869": {"title": "The Man Who Invented The Cassette Tape Has Died; Lou Ottens Was 94 : NPR", "url": "https://www.npr.org/2021/03/10/975598869/lou-ottens-inventor-of-the-cassette-tape-has-died", "author": "No author found", "published_date": "2021-03-10", "content": "", "section": "Music", "disclaimer": ""}, "2021-03-10-975648007": {"title": "Russia Slows And Threatens To Block Twitter : NPR", "url": "https://www.npr.org/2021/03/10/975648007/russia-slows-twitter-in-blunt-warning-to-u-s-based-social-media-platforms", "author": "No author found", "published_date": "2021-03-10", "content": "", "section": "Technology", "disclaimer": ""}, "2021-03-10-975545509": {"title": "Biden Administration Gears Up For A Showdown With Big Tech : NPR", "url": "https://www.npr.org/2021/03/10/975545509/biden-administration-gears-up-for-a-showdown-with-big-tech", "author": "No author found", "published_date": "2021-03-10", "content": "RACHEL MARTIN, HOST:  President Biden is gearing up for a showdown with Big Tech. He's reportedly hiring two of the most outspoken critics of Amazon, Facebook and Google for influential roles in his administration. These critics have pushed for the government to get much more aggressive at reigning in tech giants, even break some of them up. NPR's tech correspondent Shannon Bond is with us this morning. Hi, Shannon. SHANNON BOND, BYLINE: Hi, Rachel. MARTIN: The tech critics in question are Lina Khan and Tim Wu. Tell us about them and the jobs they might take. BOND: Yeah, so they're both Columbia Law professors. And in Lina Khan's case, Biden is reportedly getting ready to nominate her to the Federal Trade Commission, which is, of course, one of the main antitrust regulators. And Tim Wu has been tapped as a tech policy adviser at the National Economic Council. And, Rachel, it's kind of hard to overstate just how big a deal these names are in tech policy circles. You know, they both have very progressive views about how the government should regulate monopoly power, and now we're potentially seeing them moving into these influential roles, as the government is investigating and in some cases even suing these tech giants. Wu worked on tech policy in the Obama administration. He's actually known for coining the term net neutrality. He now says the tech giants have helped create a new Gilded Age, much like the robber barons did in the industrial era with, you know, the railroad and oil monopolies. And Wu has advocated for breaking up Facebook. Khan has been described as a legal prodigy. She's just 32. She became famous when she was still in law school for writing a groundbreaking paper about Amazon. And she's become the face of this approach that's sometimes jokingly called hipster antitrust. MARTIN: That demands more explanation. BOND: (Laughter) Right. So her argument is that the current way that the government deals with monopoly power has really fallen short, especially when it comes to the tech giants. So these rules, they're really focused on when consumers like you and me get hurt - so, you know, maybe we have fewer choices, we have to pay more for products or services. Khan says that way of thinking doesn't address concerns about a company like Amazon. Those concerns focus on the harms to other people affected, like, say, the independent sellers who rely on the platform to make money. You know, she says Amazon should not be able to both control the marketplace and sell as a competitor in that marketplace. Here's what she told my colleague Alina Selyukh back in 2018 about the bind that Amazon is putting sellers in. (SOUNDBITE OF ARCHIVED NPR BROADCAST)LINA KHAN: That dependence means that Amazon gets to often call all of the shots. And I think that is oftentimes quite harmful because it means Amazon can extract more and more from these sellers, and that can affect quality. BOND: And Khan has already had these, you know, influential views. They've already been influential in Washington. She advised a House panel last year that conducted this big investigation into Apple, Amazon, Facebook and Google. It found they were all monopolies with unfair power. And we should note, all four of those companies are NPR supporters. MARTIN: OK, I think we're going to have to do a separate conversation about what is hipster about that theory. BOND: (Laughter). MARTIN: But that's beside the point. So this is a big shift from how the Obama administration dealt with the tech industry, isn't it? BOND: It is. I mean, I think the Obama administration, people sort of see it as having a much cozier relationship with Silicon Valley. And it wasn't that long ago these companies were celebrated as innovators. But, you know, we've seen that really has been changing. The Trump administration, of course, was hugely critical of these companies. It sued Google and Facebook for antitrust concerns. And the Biden administration is expected to continue those lawsuits. You know, and we've just seen growing criticism of tech from both sides of the aisle. Of course, there are some people from the tech world who are taking positions with the Biden administration, as they did under Obama. But I think the choice of people like Lina Khan, Tim Wu in these roles, these high-profile roles, does signal a tougher stance toward Silicon Valley and signals that the era of scrutiny and skepticism - what we sometimes call the tech-lash (ph) - is not over. MARTIN: (Laughter) Shannon. NPR's tech correspondent Shannon Bond. Thank you. BOND: Thank you. RACHEL MARTIN, HOST:   President Biden is gearing up for a showdown with Big Tech. He's reportedly hiring two of the most outspoken critics of Amazon, Facebook and Google for influential roles in his administration. These critics have pushed for the government to get much more aggressive at reigning in tech giants, even break some of them up. NPR's tech correspondent Shannon Bond is with us this morning. Hi, Shannon. SHANNON BOND, BYLINE: Hi, Rachel. MARTIN: The tech critics in question are Lina Khan and Tim Wu. Tell us about them and the jobs they might take. BOND: Yeah, so they're both Columbia Law professors. And in Lina Khan's case, Biden is reportedly getting ready to nominate her to the Federal Trade Commission, which is, of course, one of the main antitrust regulators. And Tim Wu has been tapped as a tech policy adviser at the National Economic Council. And, Rachel, it's kind of hard to overstate just how big a deal these names are in tech policy circles. You know, they both have very progressive views about how the government should regulate monopoly power, and now we're potentially seeing them moving into these influential roles, as the government is investigating and in some cases even suing these tech giants. Wu worked on tech policy in the Obama administration. He's actually known for coining the term net neutrality. He now says the tech giants have helped create a new Gilded Age, much like the robber barons did in the industrial era with, you know, the railroad and oil monopolies. And Wu has advocated for breaking up Facebook. Khan has been described as a legal prodigy. She's just 32. She became famous when she was still in law school for writing a groundbreaking paper about Amazon. And she's become the face of this approach that's sometimes jokingly called hipster antitrust. MARTIN: That demands more explanation. BOND: (Laughter) Right. So her argument is that the current way that the government deals with monopoly power has really fallen short, especially when it comes to the tech giants. So these rules, they're really focused on when consumers like you and me get hurt - so, you know, maybe we have fewer choices, we have to pay more for products or services. Khan says that way of thinking doesn't address concerns about a company like Amazon. Those concerns focus on the harms to other people affected, like, say, the independent sellers who rely on the platform to make money. You know, she says Amazon should not be able to both control the marketplace and sell as a competitor in that marketplace. Here's what she told my colleague Alina Selyukh back in 2018 about the bind that Amazon is putting sellers in. (SOUNDBITE OF ARCHIVED NPR BROADCAST) LINA KHAN: That dependence means that Amazon gets to often call all of the shots. And I think that is oftentimes quite harmful because it means Amazon can extract more and more from these sellers, and that can affect quality. BOND: And Khan has already had these, you know, influential views. They've already been influential in Washington. She advised a House panel last year that conducted this big investigation into Apple, Amazon, Facebook and Google. It found they were all monopolies with unfair power. And we should note, all four of those companies are NPR supporters. MARTIN: OK, I think we're going to have to do a separate conversation about what is hipster about that theory. BOND: (Laughter). MARTIN: But that's beside the point. So this is a big shift from how the Obama administration dealt with the tech industry, isn't it? BOND: It is. I mean, I think the Obama administration, people sort of see it as having a much cozier relationship with Silicon Valley. And it wasn't that long ago these companies were celebrated as innovators. But, you know, we've seen that really has been changing. The Trump administration, of course, was hugely critical of these companies. It sued Google and Facebook for antitrust concerns. And the Biden administration is expected to continue those lawsuits. You know, and we've just seen growing criticism of tech from both sides of the aisle. Of course, there are some people from the tech world who are taking positions with the Biden administration, as they did under Obama. But I think the choice of people like Lina Khan, Tim Wu in these roles, these high-profile roles, does signal a tougher stance toward Silicon Valley and signals that the era of scrutiny and skepticism - what we sometimes call the tech-lash (ph) - is not over. MARTIN: (Laughter) Shannon. NPR's tech correspondent Shannon Bond. Thank you. BOND: Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-03-11-975849508": {"title": "Slick Tom Cruise Deepfakes Signal That Near Flawless Forgeries May Be Here  : NPR", "url": "https://www.npr.org/2021/03/11/975849508/slick-tom-cruise-deepfakes-signal-that-near-flawless-forgeries-may-be-here", "author": "No author found", "published_date": "2021-03-11", "content": "MARY LOUISE KELLY, HOST:  Perhaps you have seen the viral TikTok where Tom Cruise purportedly performs a magic trick with a coin. (SOUNDBITE OF TIKTOK VIDEO)MILES FISHER: (As Tom Cruise) I'm going to show you some magic. It's the real thing (laughter). KELLY: That laugh - unmistakably Tom Cruise, right? And it sure looks like Tom Cruise when you watch the video. It is not, though. This video is a deepfake, an image altered with artificial intelligence in a way that makes it difficult - really difficult - to tell that it is not real. Well, here to tell us how it works is University of California, Berkeley professor Hany Farid. Welcome. HANY FARID: It's good to be here. KELLY: What did you make of this Tom Cruise deepfake? The voice, the mannerisms, they are perfect. Did it fool you? FARID: It's exceedingly well done. And it's been - it was interesting to see because part of the evolution of what we've been seeing since 2017, where every three to four months a video hits TikTok, YouTube, whatever, and it's just, wow, this is much, much better than before. And this is clearly a new category of deepfake that we have not seen before. KELLY: Just explain, what are we actually seeing? Is this real video of Cruise, but it's been manipulated? Is this an actor? What's happening? FARID: What you're seeing in these videos is not Tom Cruise. It is an actor who looks a little bit like Tom Cruise, clearly sounds like Tom Cruise. But on every frame of the video, at somewhere between 24 and 30 frames per second, the actor's frame was replaced with Tom Cruise's face. And that process is done digitally and with advances in machine learning and big data. And almost certainly, there was some post-production in this to sort of clean it up and get it really polished and high quality. And if you can replace somebody's face on every frame of a video, you can make it look like it's Tom Cruise or you or me or anybody else. KELLY: Is this legal? I was looking - the account in question here is @deeptomcruise. That's the account posting this. Does TikTok have an obligation to take that account down once it has been established that this isn't real, that this is a deepfake? FARID: Man, that's a great question. So I'm not the lawyer to ask this question to, but there is a really interesting question here around identity. So for example, many states have passed laws banning nonconsensual pornography, where one person's likeness is inserted into sexually explicit material. And you can see clearly why you would do that. It is harmful to that individual. This one's a little bit different. It's not clear that it's harmful to Tom Cruise. Now, he may say, look, this is a copyright infringement because you're using my face and my likeness, at which point TikTok or YouTube or whomever would be obligated to take down the material. But I think we are starting to tread into some interesting legal and ethical territory is, who owns that identity? And if that person is a person in sort of the public sphere - a president, an actor - do they have different rights than, say, a private individual like me or you? I don't think we've fully figured out how we're going to navigate that space. KELLY: Yeah. And when you talk about the dangers of this, I'm thinking there's such a range. There's, you know, you touched on pornography, nonconsensual pornography - you know, a woman's photo being linked to something that she is not doing. I also read where you have talked about the potential of deepfakes to pose a national security risk. How so? FARID: So here's a couple of scenarios you can imagine. Somebody creates a video of President Biden saying, I've launched nuclear weapons against Iran, and that goes viral online. How long does it take before somebody panics and pushes the button in return? And that's the danger here, is first of all, it's not just the content, but it's that we can deliver it online en masse to millions of people around the world, have it go viral and before anybody gets around to figuring out that it's fake, we have a global nuclear meltdown. Here's another scenario. I create a video of Jeff Bezos quietly saying that Amazon's profits are down 20%. That video goes viral. How long does it take me to move the market to the tune of billions of dollars? Now, are either of those scenarios highly likely? No. But are they possible? Yes. And the consequences should give us pause because we know that things can spread online incredibly fast. And before anybody circles around to figuring out what's what, you can imagine some very, very bad consequences from that material. And frankly, that is outside of the deepfake phenomena. Why we have the misinformation apocalypse that is upon us now is because it's so easy to spread misinformation, and people are so willing and eager to spread it. And deepfakes is now throwing jet fuel onto that already burning fire. KELLY: Professor Hany Farid of the University of California, Berkeley. Professor Farid, thanks. FARID: It's very good to be with you. Thanks for talking. (SOUNDBITE OF MUSIC) MARY LOUISE KELLY, HOST:   Perhaps you have seen the viral TikTok where Tom Cruise purportedly performs a magic trick with a coin. (SOUNDBITE OF TIKTOK VIDEO) MILES FISHER: (As Tom Cruise) I'm going to show you some magic. It's the real thing (laughter). KELLY: That laugh - unmistakably Tom Cruise, right? And it sure looks like Tom Cruise when you watch the video. It is not, though. This video is a deepfake, an image altered with artificial intelligence in a way that makes it difficult - really difficult - to tell that it is not real. Well, here to tell us how it works is University of California, Berkeley professor Hany Farid. Welcome. HANY FARID: It's good to be here. KELLY: What did you make of this Tom Cruise deepfake? The voice, the mannerisms, they are perfect. Did it fool you? FARID: It's exceedingly well done. And it's been - it was interesting to see because part of the evolution of what we've been seeing since 2017, where every three to four months a video hits TikTok, YouTube, whatever, and it's just, wow, this is much, much better than before. And this is clearly a new category of deepfake that we have not seen before. KELLY: Just explain, what are we actually seeing? Is this real video of Cruise, but it's been manipulated? Is this an actor? What's happening? FARID: What you're seeing in these videos is not Tom Cruise. It is an actor who looks a little bit like Tom Cruise, clearly sounds like Tom Cruise. But on every frame of the video, at somewhere between 24 and 30 frames per second, the actor's frame was replaced with Tom Cruise's face. And that process is done digitally and with advances in machine learning and big data. And almost certainly, there was some post-production in this to sort of clean it up and get it really polished and high quality. And if you can replace somebody's face on every frame of a video, you can make it look like it's Tom Cruise or you or me or anybody else. KELLY: Is this legal? I was looking - the account in question here is @deeptomcruise. That's the account posting this. Does TikTok have an obligation to take that account down once it has been established that this isn't real, that this is a deepfake? FARID: Man, that's a great question. So I'm not the lawyer to ask this question to, but there is a really interesting question here around identity. So for example, many states have passed laws banning nonconsensual pornography, where one person's likeness is inserted into sexually explicit material. And you can see clearly why you would do that. It is harmful to that individual. This one's a little bit different. It's not clear that it's harmful to Tom Cruise. Now, he may say, look, this is a copyright infringement because you're using my face and my likeness, at which point TikTok or YouTube or whomever would be obligated to take down the material. But I think we are starting to tread into some interesting legal and ethical territory is, who owns that identity? And if that person is a person in sort of the public sphere - a president, an actor - do they have different rights than, say, a private individual like me or you? I don't think we've fully figured out how we're going to navigate that space. KELLY: Yeah. And when you talk about the dangers of this, I'm thinking there's such a range. There's, you know, you touched on pornography, nonconsensual pornography - you know, a woman's photo being linked to something that she is not doing. I also read where you have talked about the potential of deepfakes to pose a national security risk. How so? FARID: So here's a couple of scenarios you can imagine. Somebody creates a video of President Biden saying, I've launched nuclear weapons against Iran, and that goes viral online. How long does it take before somebody panics and pushes the button in return? And that's the danger here, is first of all, it's not just the content, but it's that we can deliver it online en masse to millions of people around the world, have it go viral and before anybody gets around to figuring out that it's fake, we have a global nuclear meltdown. Here's another scenario. I create a video of Jeff Bezos quietly saying that Amazon's profits are down 20%. That video goes viral. How long does it take me to move the market to the tune of billions of dollars? Now, are either of those scenarios highly likely? No. But are they possible? Yes. And the consequences should give us pause because we know that things can spread online incredibly fast. And before anybody circles around to figuring out what's what, you can imagine some very, very bad consequences from that material. And frankly, that is outside of the deepfake phenomena. Why we have the misinformation apocalypse that is upon us now is because it's so easy to spread misinformation, and people are so willing and eager to spread it. And deepfakes is now throwing jet fuel onto that already burning fire. KELLY: Professor Hany Farid of the University of California, Berkeley. Professor Farid, thanks. FARID: It's very good to be with you. Thanks for talking. (SOUNDBITE OF MUSIC)", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-03-11-976141522": {"title": "Beeple JPEG Sells For $69 Million : NPR", "url": "https://www.npr.org/2021/03/11/976141522/beeple-jpg-file-sells-for-69-million-setting-crypto-art-record", "author": "No author found", "published_date": "2021-03-11", "content": "", "section": "Technology", "disclaimer": ""}, "2021-03-11-975765363": {"title": "Microtransactions Are Great For Game Companies, Less So For Players : NPR", "url": "https://www.npr.org/2021/03/11/975765363/microtransactions-are-great-for-game-companies-less-fun-for-players", "author": "No author found", "published_date": "2021-03-11", "content": "", "section": "Gaming", "disclaimer": ""}, "2021-03-11-975746051": {"title": "Arizona GOP Wants To Ban Private Funds Used For Elections : NPR", "url": "https://www.npr.org/2021/03/11/975746051/private-donations-helped-pay-for-2020-elections-arizona-republicans-say-no-more", "author": "No author found", "published_date": "2021-03-11", "content": "", "section": "Politics", "disclaimer": ""}, "2021-03-12-976513031": {"title": "Who is Beeple, the artist behind Christie's NFT auction? We talk with him.  : Planet Money : NPR", "url": "https://www.npr.org/2021/03/12/976513031/the-69-million-jpeg", "author": "No author found", "published_date": "2021-03-12", "content": "SYLVIE DOUGLIS, BYLINE: This is PLANET MONEY from NPR. (SOUNDBITE OF COIN SPINNING)MARY CHILDS, HOST:  Mike Winkelmann is a digital artist living in the suburbs of Charleston, S. C. ALEXI HOROWITZ-GHAZI, HOST:  Among many other things, he makes a hot new kind of art investment object you may have heard of - NFTs, nonfungible tokens. And we'll get into the details about those a bit later. CHILDS: Yeah, don't sweat it. We will unpack that. And Mike is pretty famous at this point for making these weird, dystopian Internet art things under the name Beeple. And he makes a lot of those. HOROWITZ-GHAZI: Would you describe what the \"Beyond Meat\" image is? MIKE WINKELMANN: Honestly, I don't even remember what that is, to be quite honest. HOROWITZ-GHAZI: Sure. WINKELMANN: You're actually going to have to describe it to me a little bit (laughter). HOROWITZ-GHAZI: It looks like a kind of Martian lunarscape, and it looks like they're kind of farming synthetic meat pigs with the head of Elon Musk. WINKELMANN: Oh, with Elon heads. I mean, to be quite honest, some of it is just kind of like I have no idea what this even is. HOROWITZ-GHAZI: And even though his work is super well-known, Mike, aka Beeple, had a problem that's common to all artists who make digital work. It is super hard to sell. Beeple wasn't really able to participate in the traditional art market. But a few months ago, Mike got a call from a guy named Noah Davis, who works at the esteemed auction house Christie's of London. And Noah specializes in postwar and contemporary art, but he's also kind of Christie's Internet guy. He was running their online auctions. And being the Internet guy is how he started seeing Mike's work basically everywhere, just JPEGs floating all around the Internet. And we talked to Mike. He asked him, if we wanted to sell one of your works to our global clientele of billionaires and scions and heiresses, is there a piece of yours that springs to mind? And Mike was like, oh, yeah, definitely. Noah of Christie's told us what Mike had sent over. NOAH DAVIS: Basically, it's a self-portrait of Mike as a child doodling in his notebook. And then hovering behind him are some of the grotesque characters that reappear in his work all the time, notably naked Buzz Lightyear. . . (LAUGHTER)DAVIS: . . . And Kim Jong Un with breasts. HOROWITZ-GHAZI: And when you saw that, how did you think it would play with the Christie's crowd? DAVIS: Well, I knew it wouldn't. I just knew it wouldn't. CHILDS: Christie's' usual fare is generally a little less provocative - you know, like rare antiquities, precious collectibles, ancient Greek sculptures of almost-naked men. DAVIS: And so I said to him, you know, this is amazing, Mike. You're hilarious. Your brain is terrifying. HOROWITZ-GHAZI: (Laughter). DAVIS: But we need to find an image that's a little more brand appropriate for Christie's. HOROWITZ-GHAZI: So they had to decide which piece might work for the brand. And it wasn't like they were lacking for material. Mike had actually become famous for this thing he calls his \"Everydays\" project. Since 2007, he'd created an original piece of art, usually on a computer, and posted it online every single day for over 5,000 days. CHILDS: So Noah of Christie's asked Mike to dig back into that vast archive to find one that would work. And Mike was like, well, what about all of it? WINKELMANN: What we're going to do is I'm going to take and make a mosaic of all 5,000 pictures, and that's what we'll use. CHILDS: He takes it to Noah, the Christie's guy. DAVIS: And he came back to us with this mosaic collage. And that kind of hit me in the forehead. Like, it - or punched me in the gut, really, because not only was this thing just beautiful from an aesthetic perspective, but the idea that you could zoom in and see every single image in the series so close and explore it, they all become unique digital worlds - that illustrated the capability of NFTs to do something that traditional art can't. HOROWITZ-GHAZI: And two weeks ago, Christie's put this mosaic up for auction as a new kind of digital art product. And they set the opening bid at $100. Like, why not? Whatever. We'll just see what happens. CHILDS: Noah says he and many of his colleagues thought of the auction as kind of a test case for how NFTs and also all digital art could do in the high-rolling international art market. This was sort of the debut for digital art. And the scale of the response surprised everyone, including Noah, the Christie's guy. DAVIS: I could've never told you that in the first 10 minutes of bidding, we would get from $100 for our starting bid to more than a million dollars. We had 20-plus bidders from seven countries. And of those 20-plus people that got us from $100 to a million, only three of them were existing Christie's clients. HOROWITZ-GHAZI: And on Thursday, Mike Winkelmann's little digital mosaic, a picture on a screen, ended up selling for $69 million. That is the third-highest amount anyone has ever paid for a piece of art by a living artist. He catapulted past Jasper Johns, Ai Weiwei, Yayoi Kusama. He's trailing only Jeff Koons and David Hockney. CHILDS: For that price, you could've filled your shopping cart with a Frida Kahlo, an Alice Neel and a small Picasso, Blue Period. HOROWITZ-GHAZI: You could've gotten a hot dog at the Christie's cafeteria. CHILDS: Damn, that sounds good. I'm very hungry. (SOUNDBITE OF MUSIC)CHILDS: Hello, and welcome to PLANET MONEY. I'm Mary Childs. HOROWITZ-GHAZI: And I'm Alexi Horowitz-Ghazi. Today on the show, why would anyone pay so much money for something they could just copy and paste off the Internet? CHILDS: Alexi, you and our colleagues at The Indicator have been doing stuff on the explosion of NFTs all week. HOROWITZ-GHAZI: Yeah, it's been kind of a wild roller coaster of a story. Just a couple days ago, the Beeple auction was at a mere $13 million. And over the course of, like, a day, it jumped to close at $69 million. It went from this kind of, you know, funny little Internet thing to a historic moment in the art market. CHILDS: Which raises all sorts of fascinating economic questions, like does this mean the art market is broken? HOROWITZ-GHAZI: Or is it brilliant? (SOUNDBITE OF MUSIC)HOROWITZ-GHAZI: Mike Winkelmann, aka Beeple, who just sold a digital art piece for 69 million real dollars, says that people are often confused when they meet him for the first time. (SOUNDBITE OF ARCHIVED NPR BROADCAST)WINKELMANN: They're like, you're not what I expected at all, 'cause I'm very, like, dorky-looking. I look - a lot of people compare me to Bill Gates. CHILDS: And with his heavy-framed glasses, his sweater-collared-shirt combo, Mike does kind of cosplay as Bill Gates every day. WINKELMANN: So they're not wrong. They're - actually, it is pretty, pretty accurate, if I'm being totally honest. HOROWITZ-GHAZI: But his day-to-day life has generally been more, you know, Bill Gates without the billions. WINKELMANN: I have two kids. My wife is - you know, stays home with the kids. Like, I am at the computer an ungodly amount. It's quite a boring suburban lifestyle, I would say is quite accurate. CHILDS: But on the Internet, he is known to his 1. 9 million Instagram followers and many others as Beeple, an art name he explains that he borrowed from a 1980s toy for kids. WINKELMANN: It's like an Ewok-looking toy that sort of, like, lights up and makes some noise. I think I've got one around here. It kind of - if you cover its eyes, it makes this. . . (SOUNDBITE OF BEEPING)WINKELMANN: There. HOROWITZ-GHAZI: (Laughter). WINKELMANN: You can hear it there, so. . . HOROWITZ-GHAZI: That is the titular Beeple. WINKELMANN: Yeah, that's a Beeple. HOROWITZ-GHAZI: Over the last several years, Mike has been almost religious about his \"Everydays\" project - creating something each day, no matter what. WINKELMANN: Like, today I have literally no idea what I'm going to make. It's 3 o'clock right now. Between now and midnight, I have 8 1/2 hours. I will come up with something. My expectations per day are to put a JPEG on the Internet, not to make a masterpiece. CHILDS: Some of these are other-worldly spacescapes. More recently, they've been kind of disturbingly realistic, often gross sci-fi scenes inspired by things in the news. He sees himself as, like, a gonzo political cartoonist for the digital age. HOROWITZ-GHAZI: So when Jeff Bezos announced he'd be stepping down as the CEO of Amazon last month, for example, Beeple made a picture called \"Release The Bezos. \"(SOUNDBITE OF ARCHIVED NPR BROADCAST)WINKELMANN: Kind of like release the kraken, this sort of, you know. . . HOROWITZ-GHAZI: (Laughter). WINKELMANN: . . . Giant squid thing. And so it's a giant Jeff Bezos head sort of in the ocean with tentacles sort of wreaking havoc. And they - he's holding up, like, shipping containers and stuff. And there's helicopters flying around him. CHILDS: Or during the whole GameStop-WallStreetBets saga, he made a \"Lord Of The Rings\" mash-up with the Reddit logo as the flaming eye of Sauron. There are a lot of mature themes, so many naked Buzz Lightyears. Things get a little weird. WINKELMANN: I'm very self-aware of this, like, to the point where, you know, pre-COVID, I'm, like, in the airport and stuff, and it's like, OK, like, I don't want somebody to even look over and, like, look at me looking at my own work. They're going to think I'm, like, looking at, like, some weird porn or something. Like - it's, like, embarrassing. CHILDS: Mike has mostly made his money elsewhere, for the first few years after college as a Web designer. And then more recently, he's worked as a freelance digital artist for performers like Lady Gaga and Justin Bieber. HOROWITZ-GHAZI: His own personal art, pasted all over the Internet though it is, hasn't made him much money. The whole category of digital art, which is basically infinitely reproducible by definition, hasn't really been able to find purchase in the broader art market. Mike says it's basically been ignored by fancy art galleries and auction houses. (SOUNDBITE OF ARCHIVED NPR BROADCAST)WINKELMANN: And they have ignored it for quite a good reason, actually. There was no way to collect it. Like, there was truly no technology available to collect my art in sort of a natively digital form. CHILDS: Or so he thought until about four months ago, when his friends started telling him about this new kind of technology that's been ripping through the digital economy - nonfungible tokens, NFTs - nifties (ph). People do say that, apparently, I just learned. HOROWITZ-GHAZI: OK, we have arrived at the NFT explanation section. Buckle up. Let's just take it letter by letter here. NFTs - nonfungible tokens. So the T in NFT, token - we all kind of know what we mean by that. It's like a little piece or a unit within a system. You can think of this as like a unit of currency. Now, the F in NFT, fungible - that basically means, like, interchangeable, replaceable. The standard example of something fungible is cash. Cash is all the same. If you and I trade $50 bills, Mary, so. . . CHILDS: That's right. I don't care. It's the same $50 bills. My dollar is your dollar. Every dollar is the same. So nonfungible, the NF in NFT, means that it's the only one ever - entirely unique. WINKELMANN: I look at it as just nothing more than a proof of ownership backed by the blockchain. HOROWITZ-GHAZI: The blockchain - this is the technology that underlies different cryptocurrencies, like, you know, Bitcoin, Dogecoin, Ethereum. It's an open-ledger system where every transaction of every token is clearly recorded for all to see. So any buyer is assured of the token's authenticity. Everyone can see the provenance, to borrow a fancy art term. CHILDS: And you can attach NFTs to all sorts of digital things. Over the last few months, we've seen NFTs attached to images, video clips, cat GIFs, songs, tweets. HOROWITZ-GHAZI: The NBA, for example, has created a type of NFT and corresponding platform called Top Shots. These are video clips of NBA players doing NBA things - you know, dunking, alley-ooping. . . CHILDS: Playing with a basketball. . . HOROWITZ-GHAZI: . . . Dribbling. . . CHILDS: Yup. Passing. . . HOROWITZ-GHAZI: . . . Maybe traveling. (LAUGHTER)HOROWITZ-GHAZI: And each of these clips has an NFT attached to it and can be bought and sold on the platform by individual collectors. CHILDS: But here's the kind of mind-bending thing about NFTs. When you buy an NFT, the asset that that number refers to - the, you know, epic LeBron James dunking clip or whatever - that is technically infinitely replicable. It has, hypothetically, unlimited supply. Anyone can sit there and just, like, watch it over and over and over. HOROWITZ-GHAZI: But the tokens, the nonfungible tokens, NFTs - those are not unlimited. Whether it's, you know, basketball videos or cat GIFs, the platforms that create and manage these NFTs spend a lot of time thinking very carefully about how many will ever be made because the key to an NFT's value is that they are part of a limited set. They are finite by design. That scarcity is essential. CHILDS: And what all this is leading to is basically that NFTs are a kind of cryptocurrency, a number that you trade. They are nonfungible, as opposed to something like Bitcoin, which is closer to cash. One Bitcoin equals one Bitcoin. HOROWITZ-GHAZI: But NFTs, like many cryptocurrencies, have costs that we're still figuring out, externalities, like the environmental impact from all the electricity needed to create and run these platforms. And like Bitcoin, all of this may seem ridiculous to a lot of people. Like, why are you paying to own something that I can just go look at for free? CHILDS: There are a few reasons. There's collector culture. Why does anyone buy anything, like Beanie Babies or baseball cards? There's patronage. You might want to support an artist like Beeple. And it's also that thing where people want somehow to get, like, a little bit of that beautiful Beeple dust on them. This is a way to reach out and touch a beloved public figure. But to me, the most compelling one is the literal benefit of what you get out of the thing kind of doesn't matter. The utility is knowing that you own it and, to some extent, everyone else knowing that you own it. It's sort of like how your name could be on a little plaque at MoMA under some beautiful, important piece of art that you lent to the museum, except thanks to the blockchain, thanks to the ledger, that plaque at MoMA can now be visible to the entire world. HOROWITZ-GHAZI: But NFT sales are very real. Across the different arenas, people are spending hundreds of millions of dollars on these things. WINKELMANN: And then it clicked for me. And it was sort of like, OK, this is crazy. People are paying, like, ridiculous amounts of money for something I didn't even think you could charge any money for. HOROWITZ-GHAZI: (Laughter. )WINKELMANN: And I recognized, like, a lot of the people in the space. And it was sort of like, well, I mean, to be quite honest, I'm actually, you know, more popular than a lot (laughter) of these people. Like, if they're making that much money, like, I feel like I can make some money here. HOROWITZ-GHAZI: After the break, Mike Winkelmann dips his toes into the NFT art market and pretty quickly gets totally soaked in money. UNIDENTIFIED REPORTER, BYLINE: I'm going to go to shop. npr. org/planetmoney. What we've got for sale here is a T-shirt, a sticker, the patch from when we sent a satellite to space - a bunch of PLANET MONEY stuff for sale at shop. npr. org/planetmoney for all of the PLANET MONEY lovers in your life. HOROWITZ-GHAZI: So Mike decided to get into NFTs last October. And he set up an initial auction on one of these platforms, a marketplace called Nifty Gateway. CHILDS: And in addition to a couple of individual NFTs Mike put up for auction, he set up a kind of price experiment to give his fans a cheap way into NFT ownership while also testing out the market. He decided to create a limited set of 100 identical NFTs and sell them for a dollar each. (SOUNDBITE OF ARCHIVED NPR BROADCAST)WINKELMANN: I knew they were worth more than a dollar, but I thought they were maybe worth, like, maybe $50 or $100. And so these instantly sold out, obviously. And pretty immediately, people started trading them because the thing with NFTs is you can immediately sort of resell them through the different platforms. HOROWITZ-GHAZI: Right. There's a built-in secondary market. WINKELMANN: Built-in in secondary market's right there. There's much less friction than sort of, you know, traditional art, where you buy a painting and then it's like, OK, if you want to resell the painting, well, that's quite a bit of work. HOROWITZ-GHAZI: And NFTs offer another nice kind of bonus. If you were to sell a piece of art, like, in a gallery, it would just be gone. People can resell it without him. He gets none of those dollars. But because NFT transactions are conducted on the blockchain and governed by so-called smart contracts, he can get a commission every time his piece of art is sold. CHILDS: And the platforms like Nifty Gateway want artists like him to sell work in their ecosystems. So, for example, Nifty Gateway's able to offer a 10% cut to people like Beeple every time one of his NFTs is sold as a condition of selling the work there in the first place. This was basically unimaginable in the traditional art market. HOROWITZ-GHAZI: And Mike says within hours, people were flipping those $1 tokens for thousands of dollars. (SOUNDBITE OF ARCHIVED NPR BROADCAST)WINKELMANN: So fast-forward to today, those $1 additions recently this week sold for $300,000. You know, when it resells, 10% just automatically goes into my wallet. HOROWITZ-GHAZI: For the art establishment, all of this feels like kind of a radical departure. They finally have to take the world of digital art seriously. But in a lot of ways, it's kind of a perfect match. Like, for example, the, you know, openly visible documentation of ownership, this is, like, half of what the art establishment spends its time on because in their market, the only art that has value is art that has been meticulously accounted for. CHILDS: There is no better place than the art world to express how totally abstract and arbitrary the concepts of price and value can be. Like, when you're bidding in that mahogany-paneled room on a beautiful painting of haystacks, what do you think you're going to do with that painting? You can't live in it. You could eat it, but it is toxic. Someone else can print a high-res version of it at home and frame that up real nice. And yet, art is like a $70 billion market. HOROWITZ-GHAZI: And Mike Winkelmann, Beeple, says the thing that for a long time seemed like digital art's greatest weakness when it came to making a market, the fact that you can infinitely screengrab and share any individual art piece, has actually turned into an advantage in this nonfungible world. WINKELMANN: OK, look at the \"Mona Lisa. \" If you go into the Louvre and take a picture of the \"Mona Lisa,\" do you think you just devalued it? No, I literally think quite the opposite. Because everybody knows about it, that makes it more popular. And so I think it's really this ironic - it feels like it shouldn't be like this, that we get to kind of have our cake and eat it, too, that you can have this proliferation of copies, but then you can also prove that one person owns that thing. CHILDS: Mike thinks NFTs are a lot like the early Internet, a new, exciting technology that inevitably will have a lot of failures and weirdness but that has a real use. (SOUNDBITE OF ARCHIVED NPR BROADCAST)HOROWITZ-GHAZI: Does any part of you worry that this is a bubble or a flash in the pan of some sort? WINKELMANN: I actually believe it is a bubble, to be quite honest. I think you're going to see a mad rush of people come to this space. And a lot of the stuff that people are making into NFTs is junk. And that stuff will not hold its value. When the bubble bursts, it's not going to wipe out this technology. It's just going to wipe out the junk. CHILDS: This week, to a buyer who goes by the pseudonym Metakovan, Beeple's piece at Christie's had $69 million worth of value. HOROWITZ-GHAZI: Christie's of London will get a 15% cut of that, around $10 million. Not bad for their first foray into the crypto art market. The lion's share then goes to the Beeple, Mike Winkelmann, along with a cut of whatever it sells for next time if the new owner ever decides to trade it. (SOUNDBITE OF MUSIC)CHILDS: Huge thank-you this week to The Indicator, whose great episode was the foundation for this piece. The Indicator is a daily 10-minute-or-less podcast. And they have yet another NFT episode that is a great companion to this one. It's all about the NBA Top Shot stuff. That's The Indicator from Planet Money. If you like absurd economic art for free, check out our TikTok - @planetmoney. One day, we, too, will be at Christie's. I'm sure of it. HOROWITZ-GHAZI: We're also on all the other social media channels - Facebook, Twitter, Instagram - @planetmoney. CHILDS: You can also email us at planetmoney@npr. org. HOROWITZ-GHAZI: Today's show was produced by Darian Woods and James Sneed, with engineering help from Gilly Moon. Alex Goldmark is our supervising producer. Bryant Urstadt edits the show. I'm Alexi Horowitz-Ghazi. CHILDS: I'm Mary Childs. This is NPR. Thanks for listening. SYLVIE DOUGLIS, BYLINE: This is PLANET MONEY from NPR. (SOUNDBITE OF COIN SPINNING) MARY CHILDS, HOST:   Mike Winkelmann is a digital artist living in the suburbs of Charleston, S. C. ALEXI HOROWITZ-GHAZI, HOST:   Among many other things, he makes a hot new kind of art investment object you may have heard of - NFTs, nonfungible tokens. And we'll get into the details about those a bit later. CHILDS: Yeah, don't sweat it. We will unpack that. And Mike is pretty famous at this point for making these weird, dystopian Internet art things under the name Beeple. And he makes a lot of those. HOROWITZ-GHAZI: Would you describe what the \"Beyond Meat\" image is? MIKE WINKELMANN: Honestly, I don't even remember what that is, to be quite honest. HOROWITZ-GHAZI: Sure. WINKELMANN: You're actually going to have to describe it to me a little bit (laughter). HOROWITZ-GHAZI: It looks like a kind of Martian lunarscape, and it looks like they're kind of farming synthetic meat pigs with the head of Elon Musk. WINKELMANN: Oh, with Elon heads. I mean, to be quite honest, some of it is just kind of like I have no idea what this even is. HOROWITZ-GHAZI: And even though his work is super well-known, Mike, aka Beeple, had a problem that's common to all artists who make digital work. It is super hard to sell. Beeple wasn't really able to participate in the traditional art market. But a few months ago, Mike got a call from a guy named Noah Davis, who works at the esteemed auction house Christie's of London. And Noah specializes in postwar and contemporary art, but he's also kind of Christie's Internet guy. He was running their online auctions. And being the Internet guy is how he started seeing Mike's work basically everywhere, just JPEGs floating all around the Internet. And we talked to Mike. He asked him, if we wanted to sell one of your works to our global clientele of billionaires and scions and heiresses, is there a piece of yours that springs to mind? And Mike was like, oh, yeah, definitely. Noah of Christie's told us what Mike had sent over. NOAH DAVIS: Basically, it's a self-portrait of Mike as a child doodling in his notebook. And then hovering behind him are some of the grotesque characters that reappear in his work all the time, notably naked Buzz Lightyear. . . (LAUGHTER) DAVIS: . . . And Kim Jong Un with breasts. HOROWITZ-GHAZI: And when you saw that, how did you think it would play with the Christie's crowd? DAVIS: Well, I knew it wouldn't. I just knew it wouldn't. CHILDS: Christie's' usual fare is generally a little less provocative - you know, like rare antiquities, precious collectibles, ancient Greek sculptures of almost-naked men. DAVIS: And so I said to him, you know, this is amazing, Mike. You're hilarious. Your brain is terrifying. HOROWITZ-GHAZI: (Laughter). DAVIS: But we need to find an image that's a little more brand appropriate for Christie's. HOROWITZ-GHAZI: So they had to decide which piece might work for the brand. And it wasn't like they were lacking for material. Mike had actually become famous for this thing he calls his \"Everydays\" project. Since 2007, he'd created an original piece of art, usually on a computer, and posted it online every single day for over 5,000 days. CHILDS: So Noah of Christie's asked Mike to dig back into that vast archive to find one that would work. And Mike was like, well, what about all of it? WINKELMANN: What we're going to do is I'm going to take and make a mosaic of all 5,000 pictures, and that's what we'll use. CHILDS: He takes it to Noah, the Christie's guy. DAVIS: And he came back to us with this mosaic collage. And that kind of hit me in the forehead. Like, it - or punched me in the gut, really, because not only was this thing just beautiful from an aesthetic perspective, but the idea that you could zoom in and see every single image in the series so close and explore it, they all become unique digital worlds - that illustrated the capability of NFTs to do something that traditional art can't. HOROWITZ-GHAZI: And two weeks ago, Christie's put this mosaic up for auction as a new kind of digital art product. And they set the opening bid at $100. Like, why not? Whatever. We'll just see what happens. CHILDS: Noah says he and many of his colleagues thought of the auction as kind of a test case for how NFTs and also all digital art could do in the high-rolling international art market. This was sort of the debut for digital art. And the scale of the response surprised everyone, including Noah, the Christie's guy. DAVIS: I could've never told you that in the first 10 minutes of bidding, we would get from $100 for our starting bid to more than a million dollars. We had 20-plus bidders from seven countries. And of those 20-plus people that got us from $100 to a million, only three of them were existing Christie's clients. HOROWITZ-GHAZI: And on Thursday, Mike Winkelmann's little digital mosaic, a picture on a screen, ended up selling for $69 million. That is the third-highest amount anyone has ever paid for a piece of art by a living artist. He catapulted past Jasper Johns, Ai Weiwei, Yayoi Kusama. He's trailing only Jeff Koons and David Hockney. CHILDS: For that price, you could've filled your shopping cart with a Frida Kahlo, an Alice Neel and a small Picasso, Blue Period. HOROWITZ-GHAZI: You could've gotten a hot dog at the Christie's cafeteria. CHILDS: Damn, that sounds good. I'm very hungry. (SOUNDBITE OF MUSIC) CHILDS: Hello, and welcome to PLANET MONEY. I'm Mary Childs. HOROWITZ-GHAZI: And I'm Alexi Horowitz-Ghazi. Today on the show, why would anyone pay so much money for something they could just copy and paste off the Internet? CHILDS: Alexi, you and our colleagues at The Indicator have been doing stuff on the explosion of NFTs all week. HOROWITZ-GHAZI: Yeah, it's been kind of a wild roller coaster of a story. Just a couple days ago, the Beeple auction was at a mere $13 million. And over the course of, like, a day, it jumped to close at $69 million. It went from this kind of, you know, funny little Internet thing to a historic moment in the art market. CHILDS: Which raises all sorts of fascinating economic questions, like does this mean the art market is broken? HOROWITZ-GHAZI: Or is it brilliant? (SOUNDBITE OF MUSIC) HOROWITZ-GHAZI: Mike Winkelmann, aka Beeple, who just sold a digital art piece for 69 million real dollars, says that people are often confused when they meet him for the first time. (SOUNDBITE OF ARCHIVED NPR BROADCAST) WINKELMANN: They're like, you're not what I expected at all, 'cause I'm very, like, dorky-looking. I look - a lot of people compare me to Bill Gates. CHILDS: And with his heavy-framed glasses, his sweater-collared-shirt combo, Mike does kind of cosplay as Bill Gates every day. WINKELMANN: So they're not wrong. They're - actually, it is pretty, pretty accurate, if I'm being totally honest. HOROWITZ-GHAZI: But his day-to-day life has generally been more, you know, Bill Gates without the billions. WINKELMANN: I have two kids. My wife is - you know, stays home with the kids. Like, I am at the computer an ungodly amount. It's quite a boring suburban lifestyle, I would say is quite accurate. CHILDS: But on the Internet, he is known to his 1. 9 million Instagram followers and many others as Beeple, an art name he explains that he borrowed from a 1980s toy for kids. WINKELMANN: It's like an Ewok-looking toy that sort of, like, lights up and makes some noise. I think I've got one around here. It kind of - if you cover its eyes, it makes this. . . (SOUNDBITE OF BEEPING) WINKELMANN: There. HOROWITZ-GHAZI: (Laughter). WINKELMANN: You can hear it there, so. . . HOROWITZ-GHAZI: That is the titular Beeple. WINKELMANN: Yeah, that's a Beeple. HOROWITZ-GHAZI: Over the last several years, Mike has been almost religious about his \"Everydays\" project - creating something each day, no matter what. WINKELMANN: Like, today I have literally no idea what I'm going to make. It's 3 o'clock right now. Between now and midnight, I have 8 1/2 hours. I will come up with something. My expectations per day are to put a JPEG on the Internet, not to make a masterpiece. CHILDS: Some of these are other-worldly spacescapes. More recently, they've been kind of disturbingly realistic, often gross sci-fi scenes inspired by things in the news. He sees himself as, like, a gonzo political cartoonist for the digital age. HOROWITZ-GHAZI: So when Jeff Bezos announced he'd be stepping down as the CEO of Amazon last month, for example, Beeple made a picture called \"Release The Bezos. \" (SOUNDBITE OF ARCHIVED NPR BROADCAST) WINKELMANN: Kind of like release the kraken, this sort of, you know. . . HOROWITZ-GHAZI: (Laughter). WINKELMANN: . . . Giant squid thing. And so it's a giant Jeff Bezos head sort of in the ocean with tentacles sort of wreaking havoc. And they - he's holding up, like, shipping containers and stuff. And there's helicopters flying around him. CHILDS: Or during the whole GameStop-WallStreetBets saga, he made a \"Lord Of The Rings\" mash-up with the Reddit logo as the flaming eye of Sauron. There are a lot of mature themes, so many naked Buzz Lightyears. Things get a little weird. WINKELMANN: I'm very self-aware of this, like, to the point where, you know, pre-COVID, I'm, like, in the airport and stuff, and it's like, OK, like, I don't want somebody to even look over and, like, look at me looking at my own work. They're going to think I'm, like, looking at, like, some weird porn or something. Like - it's, like, embarrassing. CHILDS: Mike has mostly made his money elsewhere, for the first few years after college as a Web designer. And then more recently, he's worked as a freelance digital artist for performers like Lady Gaga and Justin Bieber. HOROWITZ-GHAZI: His own personal art, pasted all over the Internet though it is, hasn't made him much money. The whole category of digital art, which is basically infinitely reproducible by definition, hasn't really been able to find purchase in the broader art market. Mike says it's basically been ignored by fancy art galleries and auction houses. (SOUNDBITE OF ARCHIVED NPR BROADCAST) WINKELMANN: And they have ignored it for quite a good reason, actually. There was no way to collect it. Like, there was truly no technology available to collect my art in sort of a natively digital form. CHILDS: Or so he thought until about four months ago, when his friends started telling him about this new kind of technology that's been ripping through the digital economy - nonfungible tokens, NFTs - nifties (ph). People do say that, apparently, I just learned. HOROWITZ-GHAZI: OK, we have arrived at the NFT explanation section. Buckle up. Let's just take it letter by letter here. NFTs - nonfungible tokens. So the T in NFT, token - we all kind of know what we mean by that. It's like a little piece or a unit within a system. You can think of this as like a unit of currency. Now, the F in NFT, fungible - that basically means, like, interchangeable, replaceable. The standard example of something fungible is cash. Cash is all the same. If you and I trade $50 bills, Mary, so. . . CHILDS: That's right. I don't care. It's the same $50 bills. My dollar is your dollar. Every dollar is the same. So nonfungible, the NF in NFT, means that it's the only one ever - entirely unique. WINKELMANN: I look at it as just nothing more than a proof of ownership backed by the blockchain. HOROWITZ-GHAZI: The blockchain - this is the technology that underlies different cryptocurrencies, like, you know, Bitcoin, Dogecoin, Ethereum. It's an open-ledger system where every transaction of every token is clearly recorded for all to see. So any buyer is assured of the token's authenticity. Everyone can see the provenance, to borrow a fancy art term. CHILDS: And you can attach NFTs to all sorts of digital things. Over the last few months, we've seen NFTs attached to images, video clips, cat GIFs, songs, tweets. HOROWITZ-GHAZI: The NBA, for example, has created a type of NFT and corresponding platform called Top Shots. These are video clips of NBA players doing NBA things - you know, dunking, alley-ooping. . . CHILDS: Playing with a basketball. . . HOROWITZ-GHAZI: . . . Dribbling. . . CHILDS: Yup. Passing. . . HOROWITZ-GHAZI: . . . Maybe traveling. (LAUGHTER) HOROWITZ-GHAZI: And each of these clips has an NFT attached to it and can be bought and sold on the platform by individual collectors. CHILDS: But here's the kind of mind-bending thing about NFTs. When you buy an NFT, the asset that that number refers to - the, you know, epic LeBron James dunking clip or whatever - that is technically infinitely replicable. It has, hypothetically, unlimited supply. Anyone can sit there and just, like, watch it over and over and over. HOROWITZ-GHAZI: But the tokens, the nonfungible tokens, NFTs - those are not unlimited. Whether it's, you know, basketball videos or cat GIFs, the platforms that create and manage these NFTs spend a lot of time thinking very carefully about how many will ever be made because the key to an NFT's value is that they are part of a limited set. They are finite by design. That scarcity is essential. CHILDS: And what all this is leading to is basically that NFTs are a kind of cryptocurrency, a number that you trade. They are nonfungible, as opposed to something like Bitcoin, which is closer to cash. One Bitcoin equals one Bitcoin. HOROWITZ-GHAZI: But NFTs, like many cryptocurrencies, have costs that we're still figuring out, externalities, like the environmental impact from all the electricity needed to create and run these platforms. And like Bitcoin, all of this may seem ridiculous to a lot of people. Like, why are you paying to own something that I can just go look at for free? CHILDS: There are a few reasons. There's collector culture. Why does anyone buy anything, like Beanie Babies or baseball cards? There's patronage. You might want to support an artist like Beeple. And it's also that thing where people want somehow to get, like, a little bit of that beautiful Beeple dust on them. This is a way to reach out and touch a beloved public figure. But to me, the most compelling one is the literal benefit of what you get out of the thing kind of doesn't matter. The utility is knowing that you own it and, to some extent, everyone else knowing that you own it. It's sort of like how your name could be on a little plaque at MoMA under some beautiful, important piece of art that you lent to the museum, except thanks to the blockchain, thanks to the ledger, that plaque at MoMA can now be visible to the entire world. HOROWITZ-GHAZI: But NFT sales are very real. Across the different arenas, people are spending hundreds of millions of dollars on these things. WINKELMANN: And then it clicked for me. And it was sort of like, OK, this is crazy. People are paying, like, ridiculous amounts of money for something I didn't even think you could charge any money for. HOROWITZ-GHAZI: (Laughter. ) WINKELMANN: And I recognized, like, a lot of the people in the space. And it was sort of like, well, I mean, to be quite honest, I'm actually, you know, more popular than a lot (laughter) of these people. Like, if they're making that much money, like, I feel like I can make some money here. HOROWITZ-GHAZI: After the break, Mike Winkelmann dips his toes into the NFT art market and pretty quickly gets totally soaked in money. UNIDENTIFIED REPORTER, BYLINE: I'm going to go to shop. npr. org/planetmoney. What we've got for sale here is a T-shirt, a sticker, the patch from when we sent a satellite to space - a bunch of PLANET MONEY stuff for sale at shop. npr. org/planetmoney for all of the PLANET MONEY lovers in your life. HOROWITZ-GHAZI: So Mike decided to get into NFTs last October. And he set up an initial auction on one of these platforms, a marketplace called Nifty Gateway. CHILDS: And in addition to a couple of individual NFTs Mike put up for auction, he set up a kind of price experiment to give his fans a cheap way into NFT ownership while also testing out the market. He decided to create a limited set of 100 identical NFTs and sell them for a dollar each. (SOUNDBITE OF ARCHIVED NPR BROADCAST) WINKELMANN: I knew they were worth more than a dollar, but I thought they were maybe worth, like, maybe $50 or $100. And so these instantly sold out, obviously. And pretty immediately, people started trading them because the thing with NFTs is you can immediately sort of resell them through the different platforms. HOROWITZ-GHAZI: Right. There's a built-in secondary market. WINKELMANN: Built-in in secondary market's right there. There's much less friction than sort of, you know, traditional art, where you buy a painting and then it's like, OK, if you want to resell the painting, well, that's quite a bit of work. HOROWITZ-GHAZI: And NFTs offer another nice kind of bonus. If you were to sell a piece of art, like, in a gallery, it would just be gone. People can resell it without him. He gets none of those dollars. But because NFT transactions are conducted on the blockchain and governed by so-called smart contracts, he can get a commission every time his piece of art is sold. CHILDS: And the platforms like Nifty Gateway want artists like him to sell work in their ecosystems. So, for example, Nifty Gateway's able to offer a 10% cut to people like Beeple every time one of his NFTs is sold as a condition of selling the work there in the first place. This was basically unimaginable in the traditional art market. HOROWITZ-GHAZI: And Mike says within hours, people were flipping those $1 tokens for thousands of dollars. (SOUNDBITE OF ARCHIVED NPR BROADCAST) WINKELMANN: So fast-forward to today, those $1 additions recently this week sold for $300,000. You know, when it resells, 10% just automatically goes into my wallet. HOROWITZ-GHAZI: For the art establishment, all of this feels like kind of a radical departure. They finally have to take the world of digital art seriously. But in a lot of ways, it's kind of a perfect match. Like, for example, the, you know, openly visible documentation of ownership, this is, like, half of what the art establishment spends its time on because in their market, the only art that has value is art that has been meticulously accounted for. CHILDS: There is no better place than the art world to express how totally abstract and arbitrary the concepts of price and value can be. Like, when you're bidding in that mahogany-paneled room on a beautiful painting of haystacks, what do you think you're going to do with that painting? You can't live in it. You could eat it, but it is toxic. Someone else can print a high-res version of it at home and frame that up real nice. And yet, art is like a $70 billion market. HOROWITZ-GHAZI: And Mike Winkelmann, Beeple, says the thing that for a long time seemed like digital art's greatest weakness when it came to making a market, the fact that you can infinitely screengrab and share any individual art piece, has actually turned into an advantage in this nonfungible world. WINKELMANN: OK, look at the \"Mona Lisa. \" If you go into the Louvre and take a picture of the \"Mona Lisa,\" do you think you just devalued it? No, I literally think quite the opposite. Because everybody knows about it, that makes it more popular. And so I think it's really this ironic - it feels like it shouldn't be like this, that we get to kind of have our cake and eat it, too, that you can have this proliferation of copies, but then you can also prove that one person owns that thing. CHILDS: Mike thinks NFTs are a lot like the early Internet, a new, exciting technology that inevitably will have a lot of failures and weirdness but that has a real use. (SOUNDBITE OF ARCHIVED NPR BROADCAST) HOROWITZ-GHAZI: Does any part of you worry that this is a bubble or a flash in the pan of some sort? WINKELMANN: I actually believe it is a bubble, to be quite honest. I think you're going to see a mad rush of people come to this space. And a lot of the stuff that people are making into NFTs is junk. And that stuff will not hold its value. When the bubble bursts, it's not going to wipe out this technology. It's just going to wipe out the junk. CHILDS: This week, to a buyer who goes by the pseudonym Metakovan, Beeple's piece at Christie's had $69 million worth of value. HOROWITZ-GHAZI: Christie's of London will get a 15% cut of that, around $10 million. Not bad for their first foray into the crypto art market. The lion's share then goes to the Beeple, Mike Winkelmann, along with a cut of whatever it sells for next time if the new owner ever decides to trade it. (SOUNDBITE OF MUSIC) CHILDS: Huge thank-you this week to The Indicator, whose great episode was the foundation for this piece. The Indicator is a daily 10-minute-or-less podcast. And they have yet another NFT episode that is a great companion to this one. It's all about the NBA Top Shot stuff. That's The Indicator from Planet Money. If you like absurd economic art for free, check out our TikTok - @planetmoney. One day, we, too, will be at Christie's. I'm sure of it. HOROWITZ-GHAZI: We're also on all the other social media channels - Facebook, Twitter, Instagram - @planetmoney. CHILDS: You can also email us at planetmoney@npr. org. HOROWITZ-GHAZI: Today's show was produced by Darian Woods and James Sneed, with engineering help from Gilly Moon. Alex Goldmark is our supervising producer. Bryant Urstadt edits the show. I'm Alexi Horowitz-Ghazi. CHILDS: I'm Mary Childs. This is NPR. Thanks for listening.", "section": "The $69 Million JPEG", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-03-12-976141488": {"title": "Amazon Union Fight Heats Up At Bessemer Warehouse In Alabama : NPR", "url": "https://www.npr.org/2021/03/12/976141488/high-stakes-at-a-warehouse-amazon-fights-against-alabama-union-drive", "author": "No author found", "published_date": "2021-03-12", "content": "", "section": "Business", "disclaimer": ""}, "2021-03-12-957054009": {"title": "New Copyright Small Claims Court Could Be A Game Changer For The Internet : NPR", "url": "https://www.npr.org/2021/03/12/957054009/will-posting-memes-or-pro-wedding-pics-land-you-in-copyright-small-claims-court", "author": "No author found", "published_date": "2021-03-12", "content": "", "section": "Culture", "disclaimer": ""}, "2021-03-12-976383147": {"title": "Robot Ump: Minor League Baseball To Experiment With Rule Changes : NPR", "url": "https://www.npr.org/2021/03/12/976383147/minor-league-baseball-to-experiment-with-robotic-umpires", "author": "No author found", "published_date": "2021-03-12", "content": "", "section": "Sports", "disclaimer": ""}, "2021-03-16-972519460": {"title": "As Big Tech Deplatforms, Extremists Find New 'Alt-Tech' Ways To Talk Online : NPR", "url": "https://www.npr.org/2021/03/16/972519460/across-the-internet-a-game-of-whac-a-mole-is-underway-to-root-out-extremism", "author": "No author found", "published_date": "2021-03-16", "content": "AILSA CHANG, HOST:  Following the January 6 insurrection at the U. S. Capitol, Big Tech companies accelerated deplatforming. That is the process of permanently removing extremists from their sites. But those extremists are quickly adjusting to this clampdown. NPR investigative correspondent Tim Mak has more on the so-called alt-tech and how young extremists are adapting to this new era. And just a note for our listeners - this story does contain details that some will find offensive. TIM MAK, BYLINE: Alt-tech is a term used to describe the sort of clone technology that is being used by extremists to get around deplatforming. The techniques are not particularly sophisticated but show a resourcefulness among those who have been marginalized by mainstream companies. A prime example of this transition is the story of Nick Fuentes, one of the most prominent young far-right extremists in America today. HEIDI BEIRICH: I think Nick Fuentes, with his youth and his tech savvy, is emblematic of a whole new generation of white supremacists who have sprung up really from the online space. MAK: That's Heidi Beirich, the co-founder of the Global Project Against Hate and Extremism. BEIRICH: So we have a whole new generation of extremists that we didn't have before, and we know there are a lot of young people online in white supremacist networks. They talk about their age and so on. MAK: Fuentes livestreams a pro-Trump online show called \"America First,\" and his segments have included racist comments like what you're about to hear. (SOUNDBITE OF PODCAST, \"AMERICA FIRST\")NICK FUENTES: You know, if Blacks have a grievance against America, I get it. But then go somewhere else. Or better yet, if you have a grievance against America, then why is it offensive when I don't consider you a full American? Why is that hateful? MAK: His ideas are important to hear because they did help drive some of the actions during the Capitol riots. One of the young people arrested after the events on January 6 had founded a student group at UCLA inspired by Fuentes. Fuentes originally used livestreaming site Twitch, but he was banned from that, so he moved on. After the insurrection, Fuentes was kicked off of DLive, a livestreaming video service that was already considered a very permissive platform. So Fuentes developed a new platform for himself, a novel solution held together by duct tape and alligator clips. Megan Squire is a professor of computer science at Elon University studying online extremism. MEGAN SQUIRE: Well, I looked at the source code. Long story short, he had rigged up a system where he was secretly streaming on YouTube. So he had this website that looked like it was his. That's why the quality looks so good. MAK: Fuentes was forced offline for a few days after his jerry-rigged YouTube system was halted. Then he came back online with a solution. Here he is streaming again this month on his own platform. (SOUNDBITE OF ARCHIVED RECORDING)FUENTES: Well, initially, it was a struggle even to get back on a livestream because, you know, to be honest, I've been working on a streaming alternative for about a year. MAK: And last week, he nodded to how important this new technology is to his survival and his movement. (SOUNDBITE OF ARCHIVED RECORDING)FUENTES: The sky is falling, right? And we're hanging on for dear life. And we're going to survive off the platforms. We're entering a totally new chapter in the movement and on the Internet as a whole. MAK: But it's not just about the movement. It's also about the money. DLive was one of the key places where people like Fuentes could raise funds. Squire did a deep dive into fundraising by alt-right personalities and found that over a nine-month period, Fuentes managed to raise $113,000 through daily streaming sessions. A user by the name of Baked Alaska who livestreamed the Capitol attack raised close to $20,000 during the same period. SQUIRE: It's mostly small donations, but there are megadonors in this community. There are guys that just give thousands and thousands of dollars. MAK: Fuentes was banned from PayPal, then his source of fundraising at DLive. But with his new platform, he's already raising funds from donations and selling merchandise. So is deplatforming just a hopeless, endless game of whack-a-mole in the broader spread of domestic extremism? Here's Deen Freelon, a professor at UNC Chapel Hill who studies digital media and politics. DEEN FREELON: Deplatforming works excessively well, especially if you consider that one of the main purposes of the alt-right and other far-right individuals on social media is to attract new members. So if you remove somebody from a major social networking site where they can recruit people, that actually in a significant way reduces their capacity to do that. MAK: But that may not be enough to fully halt the momentum of extremists like Nick Fuentes. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED GROUP: (Chanting) We want Nick. We want Nick. MAK: Fuentes and his supporters recently held an in-person conference in Florida. . . (SOUNDBITE OF ARCHIVED RECORDING)FUENTES: This is a truly special event. MAK: . . . Promoted heavily online, bringing what started in the virtual world into real-world networking. Arizona Congressman Paul Gosar was the keynote speaker. This merging of new tech and old-school techniques to build a movement poses new challenges for all those seeking to counter his ideas. Tim Mak, NPR News. AILSA CHANG, HOST:   Following the January 6 insurrection at the U. S. Capitol, Big Tech companies accelerated deplatforming. That is the process of permanently removing extremists from their sites. But those extremists are quickly adjusting to this clampdown. NPR investigative correspondent Tim Mak has more on the so-called alt-tech and how young extremists are adapting to this new era. And just a note for our listeners - this story does contain details that some will find offensive. TIM MAK, BYLINE: Alt-tech is a term used to describe the sort of clone technology that is being used by extremists to get around deplatforming. The techniques are not particularly sophisticated but show a resourcefulness among those who have been marginalized by mainstream companies. A prime example of this transition is the story of Nick Fuentes, one of the most prominent young far-right extremists in America today. HEIDI BEIRICH: I think Nick Fuentes, with his youth and his tech savvy, is emblematic of a whole new generation of white supremacists who have sprung up really from the online space. MAK: That's Heidi Beirich, the co-founder of the Global Project Against Hate and Extremism. BEIRICH: So we have a whole new generation of extremists that we didn't have before, and we know there are a lot of young people online in white supremacist networks. They talk about their age and so on. MAK: Fuentes livestreams a pro-Trump online show called \"America First,\" and his segments have included racist comments like what you're about to hear. (SOUNDBITE OF PODCAST, \"AMERICA FIRST\") NICK FUENTES: You know, if Blacks have a grievance against America, I get it. But then go somewhere else. Or better yet, if you have a grievance against America, then why is it offensive when I don't consider you a full American? Why is that hateful? MAK: His ideas are important to hear because they did help drive some of the actions during the Capitol riots. One of the young people arrested after the events on January 6 had founded a student group at UCLA inspired by Fuentes. Fuentes originally used livestreaming site Twitch, but he was banned from that, so he moved on. After the insurrection, Fuentes was kicked off of DLive, a livestreaming video service that was already considered a very permissive platform. So Fuentes developed a new platform for himself, a novel solution held together by duct tape and alligator clips. Megan Squire is a professor of computer science at Elon University studying online extremism. MEGAN SQUIRE: Well, I looked at the source code. Long story short, he had rigged up a system where he was secretly streaming on YouTube. So he had this website that looked like it was his. That's why the quality looks so good. MAK: Fuentes was forced offline for a few days after his jerry-rigged YouTube system was halted. Then he came back online with a solution. Here he is streaming again this month on his own platform. (SOUNDBITE OF ARCHIVED RECORDING) FUENTES: Well, initially, it was a struggle even to get back on a livestream because, you know, to be honest, I've been working on a streaming alternative for about a year. MAK: And last week, he nodded to how important this new technology is to his survival and his movement. (SOUNDBITE OF ARCHIVED RECORDING) FUENTES: The sky is falling, right? And we're hanging on for dear life. And we're going to survive off the platforms. We're entering a totally new chapter in the movement and on the Internet as a whole. MAK: But it's not just about the movement. It's also about the money. DLive was one of the key places where people like Fuentes could raise funds. Squire did a deep dive into fundraising by alt-right personalities and found that over a nine-month period, Fuentes managed to raise $113,000 through daily streaming sessions. A user by the name of Baked Alaska who livestreamed the Capitol attack raised close to $20,000 during the same period. SQUIRE: It's mostly small donations, but there are megadonors in this community. There are guys that just give thousands and thousands of dollars. MAK: Fuentes was banned from PayPal, then his source of fundraising at DLive. But with his new platform, he's already raising funds from donations and selling merchandise. So is deplatforming just a hopeless, endless game of whack-a-mole in the broader spread of domestic extremism? Here's Deen Freelon, a professor at UNC Chapel Hill who studies digital media and politics. DEEN FREELON: Deplatforming works excessively well, especially if you consider that one of the main purposes of the alt-right and other far-right individuals on social media is to attract new members. So if you remove somebody from a major social networking site where they can recruit people, that actually in a significant way reduces their capacity to do that. MAK: But that may not be enough to fully halt the momentum of extremists like Nick Fuentes. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED GROUP: (Chanting) We want Nick. We want Nick. MAK: Fuentes and his supporters recently held an in-person conference in Florida. . . (SOUNDBITE OF ARCHIVED RECORDING) FUENTES: This is a truly special event. MAK: . . . Promoted heavily online, bringing what started in the virtual world into real-world networking. Arizona Congressman Paul Gosar was the keynote speaker. This merging of new tech and old-school techniques to build a movement poses new challenges for all those seeking to counter his ideas. Tim Mak, NPR News.", "section": "Investigations", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-03-16-977613561": {"title": "'Ya Basta Facebook' Says Company Must Curb Misinformation In Spanish : NPR", "url": "https://www.npr.org/2021/03/16/977613561/ya-basta-facebook-says-company-must-curb-misinformation-in-spanish", "author": "No author found", "published_date": "2021-03-16", "content": "", "section": "Technology", "disclaimer": ""}, "2021-03-16-977769873": {"title": "Kevin Roose's 'Futureproof' Offers Rules To Thrive In The Age Of Automation  : NPR", "url": "https://www.npr.org/2021/03/16/977769873/the-age-of-automation-is-now-heres-how-to-futureproof-yourself", "author": "No author found", "published_date": "2021-03-16", "content": "DAVE DAVIES, HOST:  This is FRESH AIR. I'm Dave Davies, in today for Terry Gross. When you go to the grocery store these days, do you opt for that self-checkout lane? It's convenient, saves you some time, probably, but you're also doing work store employees used to do and probably cutting their hours. Our guest, New York Times tech columnist Kevin Roose, says those self-service lanes are among the countless ways that companies and governments are employing automation and artificial intelligence to cut costs, transform workplaces, eliminate jobs and influence our buying habits and lifestyle choices. In a new book, Roose examines the approaches and motivations of those pushing artificial intelligence, and he offers some ideas for protecting yourself from being automated out of a job and some thoughts on how we as a society should responsibly manage technological innovation. Kevin Roose also writes frequently about social media disinformation and cybersecurity. He's the author of two previous books, \"The Unlikely Disciple,\" about his semester at Liberty University, the evangelical school founded by Jerry Falwell, and \"Young Money,\" which looked at the lives of eight Wall Street bankers after the 2008 financial crisis. He's also the host of \"Rabbit Hole,\" an eight-part podcast series about how the Internet affects our lives. He joins us from his home in Oakland to talk about his new book, \"Futureproof: 9 Rules For Humans In The Age Of Automation. \"Well, Kevin Roose, welcome to FRESH AIR. KEVIN ROOSE: Such a pleasure to be here. DAVIES: You write about automation and using artificial intelligence and the extent to which it eliminates jobs. And you say that there's a lot people misunderstand about how this works. It's not that, you know, somebody is literally replaced one day by a robot. What's the more typical way that automation cuts jobs? ROOSE: Well, there are a few ways. I mean, that kind of one-for-one substitution, it still does happen sometimes. There still are jobs - you know, like, cleaning people at big-box retailers, for example - who are sort of being replaced by robots. But much of the work that can be automated that way has already been automated in factories and manufacturing facilities. So there are some other ways that automation can replace jobs, too. And one of them is by allowing companies to do the same amount of work with many fewer people - new companies, that is. So one example of this is in China, one of the biggest lenders is a company called MYbank, and their signature loan product is referred to as 310 because it takes three minutes to apply online for a loan, it takes one second for an algorithm to approve it, and zero humans are involved in the process. And so that firm has been able to issue billions and billions of dollars in loans with very few employees relative to their competitors. So you might have a bank that has 10,000 loan officers, but if this company, MYbank, can outperform you with a couple hundred employees, that results in a net loss of jobs if that firm takes over. So that's a more common way. But there are other ways, too, including giving us new behaviors that replace old behaviors. So one example of that would be what's been happening with photos. Kodak used to be a major American company with many, many thousands of employees. But we don't hear much about them anymore because now we get photos on our phones, and we distribute them through Instagram and Facebook and on Twitter. And so the distribution has changed. The behavior has changed. And the companies that are sort of doing that new behavior - Instagram and Twitter - those have fewer employees than Kodak used to have because they're much more automated. DAVIES: And there are cases where one company will do something which allows it to operate smarter and leaner, and it causes a loss in jobs somewhere else, like software that allows people to better maintain aircraft, for example. That's one you give. ROOSE: Exactly, yeah. So there are lots of ways in which AI and automation are being implemented to make processes more efficient, which, you know, we think of as generally a good thing. And it is. But it can also result in a loss of jobs. So yeah, if there is a company that's making an algorithm that, you know, tells airlines when to replace parts in their planes, maybe they end up buying fewer parts and maintaining them more. There are many, many examples of this happening throughout the economy. And it doesn't all replace jobs, but there are jobs being lost as a result. DAVIES: Right, so one company just finds they're getting fewer orders. And way down the line, somebody somewhere doesn't need to order stuff because they are taking better care of what they have. You know, there is this growing industry of people who develop artificial intelligence programs. Sometimes it's software; sometimes it's hardware. And they sell to companies. Do they pitch it as, hey, this is going to save you money by cutting jobs? ROOSE: It depends who's listening. And this is one of the big things that made me interested in this topic, was, you know, I live out in Silicon Valley, and I talk to a lot of people in the tech industry. And most of the time, they will tell you, you know, AI is going to be great for people. It's going to free them from mundane and repetitive tasks. It's going to make their lives better. These algorithms are going to personalize everything for them and make it easy for them to get around in the world. But then there's this other story that I started hearing snippets of a few years ago when I decided to write this book, and that story was much more cynical and much more pessimistic. And it basically was these executives who were talking about automation and AI as purely a way to get rid of human workers, to cut their costs and to automate their workforces. And so the clearest example I have of this in the book is I was at a party a few years ago in San Francisco, and I started talking to a guy who was telling me about his startup, as most conversations at parties tend to go in the Bay Area. And he told me that his company had developed a piece of software that he was calling the boomer remover. And I sort of - I was confused by that. I said, what do you mean, the boomer remover? And he told me, well, this is a piece of software that allows companies with factories to use artificial intelligence to streamline the decision about what to produce on which machines on which days. This is called production planning, and humans have done that job for hundreds of years. But this AI program that he had developed was allowing factories and companies to replace the supervisors of those factories - who he referred to as boomers because they were generally older and better paid - with an algorithm. And he was very proud of this. And so there are snippets of this more honest automation conversation that you occasionally hear. And that part was really disturbing to me because he was not concerned about the people who were going to lose their jobs to this technology. In fact, he was almost glad to be able to replace them. DAVIES: You know, defenders of this say, look, this has been happening throughout history - the Industrial Revolution, successive waves of new technology when, you know, factories began to run on electricity. That changed things in big ways - and that, yes, jobs were eliminated, but new ones emerged. Should we be reassured by that argument? ROOSE: Well, I believed in that argument for a long time. I mean, I am a tech writer. I'm not a Luddite. I love technology. I, you know, grew up with computers and on the Internet. And I was very optimistic about this technology because of that argument that you made that, you know, automation and artificial intelligence will destroy some jobs. But they will create other jobs. And those jobs will replace the lost ones. But as I started looking more into the present of AI and also the past of automation, I learned that it's not always that smooth. During the Industrial Revolution, for example, there were people who didn't find work for a long time. There were - you know, wages for workers didn't catch up to corporate profits for something like 50 years. So a lot of the people who went through those technological transformations didn't have a good time. They weren't necessarily happier or living better lives or wealthier as a result of this new technology. But there's also a difference today, which is that artificial intelligence is not just replacing sort of repetitive manual labor. It's also replacing repetitive cognitive labor. It's able to do higher value tasks, not just moving data around on a spreadsheet or moving car parts around in a factory. It's able to do the work of white-collar workers in fields that are generally - require college educations and specialized training. And that's one difference. And then the other difference is there's been some new research out about the effect that automation has been having in the economy. And it's shown that while for much of the 20th century, automation was creating new jobs faster than it was destroying old jobs, for the last few decades, the opposite has been true. New jobs have been disappearing - or old jobs have been disappearing faster than new jobs have been created. DAVIES: After rolling over these arguments a bit in the book, you say that, well, if you were going to rate your view of this on a one to 10 scale, one being no worries, this is all going to work out to 10 being artificial intelligence will destroy everything we hold dear, where are you on the scale? ROOSE: Well, the answer is - I have two answers for that. One is about the technology itself. And on the technology itself, I am much more optimistic. I really think that AI and automation could produce amazing things for us. It could help us cure rare diseases. It could help us fix the climate crisis. It could do any number of amazing things that we really, really need. I am much more worried, on the other hand, about the humans who are in charge of the AI and automation and what their motivations are. I mean, it's the people like the startup founder who told me about the boomer remover. But it's also the executives at large companies who are using automation to replace workers without transforming their companies, without developing new products. They're not trying to innovate and transform their businesses. They're purely trying to do the same amount of work with fewer people. DAVIES: We need to take a break here. Let me reintroduce you. We're speaking with Kevin Roose. He is a technology columnist for The New York Times. His new book is \"Futureproof: 9 Rules For Humans In An Age Of Automation. \" We'll continue our conversation in just a moment. This is FRESH AIR. (SOUNDBITE OF THE ROOTS SONG, \"SACRIFICE\")DAVIES: This is FRESH AIR. And we're speaking with New York Times technology columnist Kevin Roose. He has a new book about the impact of automation and artificial intelligence. It's called \"Futureproof: 9 Rules For Humans In An Age Of Automation. \"You know, it's interesting that a lot of this automation and artificial intelligence doesn't even involve a physical intervention in a workplace, necessarily. A lot of it is simply algorithms, which guide the workplace - the work process through software. And you say, one thing to beware of are bureaucratic bots. That is to say, algorithms which governments and institutions use to determine, you know, who qualifies for unemployment compensation or, in a private company, how the benefits are managed. Do you want to explain what this is and what its impact is? ROOSE: Yeah. The category I call bureaucratic bots is sort of made up of these algorithms that make decisions that affect people's lives in really dramatic and important ways. So I don't think people fully appreciate the extent to which things like benefits, who qualifies for nutrition assistance, who qualifies for public housing are determined by algorithms now. And sometimes that works fine. And some other times, it doesn't work so great. There was a case a few years ago in Michigan where an algorithm that the state was using to determine benefits eligibility misfired. And it kicked a lot of people off their benefits wrongly. And that affected people's lives in real, tangible ways. There are other kinds of bots and automation being used by governments in the criminal justice system, for example, to predict whether a given defendant is likely to reoffend if you put them out on parole. And these algorithms are generally not open and inspectable by the public. They're sort of black boxes. And we don't really know how they work. And there's not a lot of accountability for them. And so as a result, we end up with these kind of mysterious machines making these decisions that affect millions, billions of people's lives. And we don't really understand what they're doing. DAVIES: And I guess when a process like that, who qualifies for what, is highly automated, even if there is an outrageous screw up that clearly affects a lot of people and becomes known, it's hard to unwind and fix quickly, isn't it? ROOSE: Exactly. And it requires humans to intervene and to undo a lot of the work that the machine has screwed up. And I think that's a real issue. And I think there's been some great writing on this. There's a book called Automating Inequality by a scholar named Virginia Eubanks. And she goes into a lot of examples of how this technology, this automation and AI technology is harming people and is disproportionately harming people who don't have a lot of money, who are, you know, dependent on state benefits, people of color, marginalized communities. They suffer when these systems don't work as they're supposed to. And it often takes a long time to clean up the mess. DAVIES: You looked in particular at YouTube and the way it recommended videos to regular YouTube watchers. YouTube is, of course, owned by Google. This is something that you wrote about in the Times. And it's also in your podcast, \"Rabbit Hole. \" You want to explain what you learned about the algorithm that was recommending videos to YouTube and its impact? ROOSE: Well, one thing I didn't fully appreciate is how sophisticated the AI that powers YouTube is. YouTube is owned by Google. And Google has the best AI research team in America. And they produce the most award-winning papers. They have the best Ph. D. s. They - you know, they're at the vanguard of artificial intelligence. And a lot of that research and expertise for the last decade has been going into honing this YouTube algorithm with these techniques that are brand-new and that are making it much more effective. And something like 70% of all the time that people spend on YouTube is directly related to recommendations that come from this algorithm. And so one thing that I learned when I started looking into this is that this algorithm has changed a lot over the years. And it's become much more savvy about what will keep people on YouTube. Maximizing watch time is the No. 1 goal of this algorithm. And so some of the ways that it's learned that it can keep people on YouTube for a long time are by introducing them to new ideas, maybe to conspiracy theories, maybe to more extreme versions of something that they already believe, things that will sort of lead them down these rabbit holes. And so this has had an effect on politics. This has had an effect on our culture. And it's resulted in some cases where people have been radicalized because the algorithm thought that radicalizing them would be a good way to keep them watching YouTube. DAVIES: Wow. So the algorithm sees them have a certain political orientation. And rather than, you know, popping up some videos which might give me another way of looking at it, it takes me a step further into my own beliefs and can result in extremist views of all kinds, right? ROOSE: Yeah. I mean, these algorithms have no idea what they're recommending. That's one thing that I learned is it's not like there's an algorithm sitting inside YouTube's, you know, headquarters that's saying, you know, I want to radicalize this person. So I'm going to show them a conspiracy theory about Qanon or something like that. But it does learn what we enjoy. And it learns what we're attracted to. And it learns what will keep our attention. And often, lies and conspiracy theories and extremist views are just more engaging than the truth. It's much more engaging to think that there is a conspiracy, you know, where people are, you know, being microchipped by Bill Gates every time they get a COVID vaccine than the truth, which is that these vaccines are effective. And they work. And there are no Bill Gates microchips inside of them. And so when you give that job to an algorithm and tell it to learn what people will respond to and don't give it any sort of parameters for that, it learns some intriguing and, sometimes, scary things. DAVIES: What do Google and YouTube officials say when you've done these stories and you've contacted them for comment? ROOSE: Well, they say that, you know, their algorithms are effective and that they're not, you know, radicalizing large numbers of people. They dispute this idea that there's this kind of extremism effect that their algorithms have. But they've also sort of tacitly acknowledged that this is happening because they've changed their algorithm a lot. They've, you know, kicked off a lot of the white supremacists and neo-Nazis who were, you know, major figures on YouTube. They've started monitoring what kind of content their algorithm is recommending to people and sort of reducing what they call borderline content, which is sort of content that's - almost breaks their rules but doesn't quite. So they have changed a lot in response to, you know, criticism and awareness of what is going on there. DAVIES: We need to take another break here. Let me reintroduce you. We are speaking with Kevin Roose. He's a technology columnist for The New York Times. His new book is \"Futureproof: 9 Rules For Humans In An Age Of Automation. \" He'll be back to talk more after a short break. I'm Dave Davies. And this is FRESH AIR. (SOUNDBITE OF FRANK ZAPPA'S \"UNCLE MEAT: MAIN TITLE THEME\")DAVIES: This is FRESH AIR. I'm Dave Davies, in today for Terry Gross. We're speaking with New York Times technology columnist Kevin Roose. His new book is about the expanding use of artificial intelligence and automation to cut costs, transform workplaces and influence our buying habits and lifestyle choices. The book is called \"Futureproof: 9 Rules For Humans In An Age Of Automation. \"So if somebody is worried about this, somebody who has a job in a warehouse or somebody who drives a truck or any of the millions of jobs out in in the economy, how do they evaluate its vulnerability to automation? And what do they do? ROOSE: Well, the conventional way is by looking at it and sort of a job-to-job basis. So there - you know, there are studies showing that, you know, tax preparers have this chance of being automated or truck drivers have this chance. But I think that's the wrong framework because what matters and what we've seen over history is that certain occupations don't just disappear one day. Instead, they sort of change. People who, you know, are doing work that is more rote and repetitive become automated first. And then, you know, the sort of automation works its way up. And sometimes it hits a wall. And it can't sort of do any more of the jobs in that field. And so the version of that today that we're seeing is that, you know, some people within professions like journalism are, you know, very susceptible to automation. The people who write, you know, recaps of sports games or, you know, reports about the stock market or the kinds of corporate earning reports that I used to write - those jobs are much more susceptible than jobs like, frankly, the ones we're doing right now, which are more about human connection and expression of complex ideas. So I think there's a sort of way of looking at this that is not so much about what you do. It's about how you do it and how human you are in performing that work. DAVIES: Yeah. It's interesting, you know, because I think the advice for a lot of people in an increasingly technically sophisticated age is, you know, learn math, learn computer science, you know, forget about all this humanities stuff. It sounds like you're saying that that's - the humanities are really important if you're going to live in this world. ROOSE: Yeah. That was one of the fascinating things I learned while I was researching this book. The more AI experts and computer scientists I talked to, the more sure I became that we have been preparing people for the future in exactly the wrong way. We've been telling them, you know, develop these kind of technical skills in fields like computer science and engineering. We've been telling people to become as productive as possible to optimize their lives, to squeeze out all the inefficiency and spend their time as effectively as possible, in essence, to become more like machines. And really, what we should be teaching people is to be more like humans, to do the things that machines can't do. And so in the book, I go over a couple types of activities that I learned in researching this book were very hard for machines to accomplish as effectively as humans. There are three categories of work that I think is unlikely to be automated in the near future. One is surprising work. So this is work that involves complex rules, changing environments, unexpected variables. AI and automation really like regularity. They like concrete rules, sort of bounded environments and repetitive action. So this is why, like, AI can beat a human in chess. But if you asked an algorithm to teach a kindergarten class, it would fail miserably because that's a very irregular environment with lots of surprises going on. So those surprising jobs are the first jobs I think are relatively safe. The second category is what I call social jobs, jobs that involve making people feel things rather than making things. So these would be the jobs in social services and health care, nursing, therapists, ministers, but also people who perform sort of emotional labor as part of their jobs - people like flight attendants and baristas, you know, people we don't typically think of as being sort of social workers. But their jobs do involve an element of making people feel things. And the third category of work that I think is safe is what I call scarce work. And this is work that involves sort of high-stakes situations, rare combinations of skills or just people who are sort of experts in their fields. And this would include jobs that we have decided are unacceptable to automate. So you know, we could replace all of the human 911 operators with robots. That technology exists. But if you call 911 today, you will get a human because we want humans to be doing that job. When we're in trouble, we want a human to pick up the phone and help us to deal with our problems. DAVIES: You know, some of the ideas that you present to deal with this rule of automation involve individual choices. But some of them are really at the level of society, large institutions, the government. What should elected officials and policy analysts be focused on as we confront these issues? ROOSE: Well, I think we need to prepare for the possibility that a lot of people are going to fall through the cracks of this technological transformation. It's happened during every technological transformation we've ever had, and it's going to happen this time. And in fact, it already is happening. And so - you know, there have been various solutions proposed. You know, universal basic income is the kind of Andrew Yang solution to this. And I think that's probably a good idea. We're seeing now during the pandemic with these stimulus checks that actually giving people money is a really good way to get people out of poverty and to sustain them through periods of hardship. So something like that, like universal basic income, could help. Something like \"Medicare for All\" could also help by not - by sort of detaching health care from our work. You know, a big part of the reason people don't quit their jobs, even if they know they're about to be automated, is because they don't want to go without health care. But there are also solutions that we could put in place that already exist in other countries. So in Sweden, for example, there are these job councils that are basically sort of public-private partnerships that essentially catch workers who are displaced by automation and layoffs. And they help retrain them. They sustain them while they're looking for work, and they find them other work. And that works very effectively in that country. In Japan, there's a similar practice. And so I think we need to take this really seriously. And I think we - you know, we can do a lot more than we're currently doing. DAVIES: We need to take another break here. Let me reintroduce you. We're speaking with Kevin Roose. He's a technology columnist for The New York Times. His new book is \"Futureproof: 9 Rules For Humans In An Age Of Automation. \" We'll continue our conversation after this short break. This is FRESH AIR. (SOUNDBITE OF JULIAN LAGE'S \"IOWA TAKEN\")DAVIES: This is FRESH AIR, and we're speaking with New York Times technology columnist Kevin Roose. His new book is about the expanding use of artificial intelligence and automation in our lives. The book is \"Futureproof: 9 Rules For Humans In An Age Of Automation. \"You don't just report on automation for the Times, and you've spent a fair amount of time reporting on online extremism. And for, you know, a recent episode of The New York Times radio program and podcast \"The Daily,\" you described watching the reaction of followers of the QAnon conspiracy theory to the events on Inauguration Day, January 20, when Joe Biden was sworn in. I thought we - I wanted to play a clip of this because you captured some of these reactions. You want to just first tell us what you were doing on Inauguration Day and what you wanted to see? ROOSE: Yeah. Well, I have two computer monitors in my office side by side. And on one of them, I was watching the inauguration. You know, I had a stream going, and I was watching Joe Biden get sworn into office. And on the other screen, I was looking at this kind of QAnon reality. There were these predictions that people who believe in this conspiracy theory had made that Joe Biden would not actually be inaugurated, that Donald Trump would implement martial law and stop the proceedings and announce the mass arrests of elite pedophiles and satanic criminals and that there would be this kind of day of reckoning during the inauguration that would result in Donald Trump taking a second term in office. And so I was watching those people, the people who believed in that theory, respond to the events of the actual inauguration that was happening on my other screen. DAVIES: All right, so we're going to listen to a bit of this. This is from the podcast \"The Daily. \" And what we'll hear is a QAnon follower anticipating Trump seizing power before Biden can be sworn into office. And then we hear some of you describing this and then some other followers. So let's just listen. (SOUNDBITE OF PODCAST, \"THE DAILY\")UNIDENTIFIED PERSON #1: It would be hilarious if Trump did the emergency broadcast in the middle of the inauguration. That would be hilarious. ROOSE: As inauguration started, politicians, you know, walk in, take their seats. These people that they believe are members of this global cabal of criminals - Hillary Clinton, George W. Bush, Barack Obama - they're all in one place. UNIDENTIFIED PERSON #2: I got the popcorn ready. UNIDENTIFIED PERSON #3: I'm optimistic. UNIDENTIFIED PERSON #4: Almost like it's the moment of truth. ROOSE: One person on a QAnon message board writes, the next 48 hours will be like the entire Revolutionary War and the fall of Berlin compressed into two days. I have called off work so I can witness history in the making. What a time to be alive. DAVIES: And that's our guest Kevin Roose on an episode of the podcast \"The Daily\" in which he's watching QAnon followers in real time as they anticipate Trump taking power on Inauguration Day, January 20. That obviously didn't happen. And I know, Kevin Roose, that you've maintained contact with a number of QAnon followers. You know, others hope that on March 4 - I think that was the date which was traditionally the Inauguration Day historically. That was another opportunity for Trump to make his move. Nothing happened. Life goes on. We have a new president. I'm wondering how those that you are in contact with are reacting to this collision with reality. ROOSE: Well, it varies. So some of them have gotten disillusioned with QAnon. They've said, you know, maybe we've been lied to. Maybe this whole thing, you know, was made up, and maybe I'm going to go find some other way to spend my time or some other conspiracy theory to attach myself to. But then there are people who just move the goalposts. They say, OK, well, it's not that Q, the sort of mysterious, anonymous figure at the center of the QAnon movement - it's not that Q is wrong. It's just that we misinterpreted Q. So the real date of this great awakening, they call it, will be sometime in the future. It'll be, you know, in the 2024 election maybe or maybe even before then. And so there's this sort of reluctance to accept reality that I don't think is unique to QAnon. I mean, we've seen, you know, religious groups that predict that the world is going to end on a certain day. You know, that day comes and goes. And they don't lose their faith. They just sort of shift their expectations. DAVIES: A lot of people have talked about the need to address this, you know, increasing, you know, embrace of deluded thinking in a lot of these conspiracy theories. And, you know, social media institutions have responded in some ways. But, you know, it seemed like this was potentially an inflection point where such, you know, a clearly predicted and anticipated event just didn't happen. The underlying - you know, reality undermines the thinking. Is it an opportunity to intervene in some way? If it is, who should do it? I'm wondering if you've thought about that, how you begin to - I don't know - weaken the hold of some of this thinking on its followers. ROOSE: I think it is a moment for potential intervention. I get emails every day from people who say, you know, my mom or my brother or my neighbor or my colleague has gotten really into Internet conspiracy theories. How do I get them out of it? And it's a really hard question. That is not something we know the answer to. But I think it does work better in moments where there is sort of uncertainty and people are sort of grappling with what they believe and whether or not it's true. So I think, yeah, this is a moment where some people may not change their thinking at all and they may still be resistant to being sort of reintroduced to reality, but for other people, there might be a kind of break in the clouds and a chance to bring them back. DAVIES: You're a technology writer. I'm wondering, just looking ahead, are there new technologies, new trends that you think are important for you to follow up on? I mean, what questions do you think you'll be examining in the next year? ROOSE: Well, AI is fascinating. I - you know, we've talked a lot about the potential negatives of it, but there are a lot of potential positives, too. I mean, one area I'm looking at right now is the use of AI in medicine and health care, not just to sort of make things more efficient, but to discover new drugs, you know, to allow doctors to do kind of better analysis and diagnosis of patients. I think that's really promising, so I'm looking at that. And I'm also excited about just the stuff that is in our, you know, homes and lives just getting - continuing to get better. You know, I don't remember if you - or I don't know if you remember, but, like, when, you know, something like Siri first came out, like, it wasn't very good (laughter). Like, you would ask, you know, Siri, what time is it? And she would respond, thyme is an herb used in cooking, you know? DAVIES: Right. ROOSE: It's something like that. And those models, those AIs have gotten much more accurate in the past few years. And I think that's something to be excited about and also to monitor very closely because it's not always good. DAVIES: Yeah, one of your nine rules is demote your devices, right (laughter)? ROOSE: Yeah. We need to be in control of our technology. There's a way in which we use our tools, and there's a way in which our tools use us. And so I think restoring authority over the technology in our lives so that we are in the driver's seat, we are controlling our own human experience, I think that's really important. DAVIES: Well, Kevin Roose, thank you so much for speaking with us. ROOSE: Thanks so much for having me. DAVIES: Kevin Roose is a technology columnist for the New York Times and host of \"Rabbit Hole,\" an eight-part podcast about how the Internet is affecting us. His new book is \"Futureproof: 9 Rules For Humans In The Age Of Automation. \"(SOUNDBITE OF ALLISON MILLER'S \"VALLEY OF THE GIANTS\")DAVIES: Coming up, Justin Chang reviews \"Quo Vadis, Aida? \", the Oscar-nominated film about the massacre of Muslims in the town of Srebrenica near the end of the Bosnian war. This is FRESH AIR. (SOUNDBITE OF JASON MORAN'S \"BIG STUFF\") DAVE DAVIES, HOST:   This is FRESH AIR. I'm Dave Davies, in today for Terry Gross. When you go to the grocery store these days, do you opt for that self-checkout lane? It's convenient, saves you some time, probably, but you're also doing work store employees used to do and probably cutting their hours. Our guest, New York Times tech columnist Kevin Roose, says those self-service lanes are among the countless ways that companies and governments are employing automation and artificial intelligence to cut costs, transform workplaces, eliminate jobs and influence our buying habits and lifestyle choices. In a new book, Roose examines the approaches and motivations of those pushing artificial intelligence, and he offers some ideas for protecting yourself from being automated out of a job and some thoughts on how we as a society should responsibly manage technological innovation. Kevin Roose also writes frequently about social media disinformation and cybersecurity. He's the author of two previous books, \"The Unlikely Disciple,\" about his semester at Liberty University, the evangelical school founded by Jerry Falwell, and \"Young Money,\" which looked at the lives of eight Wall Street bankers after the 2008 financial crisis. He's also the host of \"Rabbit Hole,\" an eight-part podcast series about how the Internet affects our lives. He joins us from his home in Oakland to talk about his new book, \"Futureproof: 9 Rules For Humans In The Age Of Automation. \" Well, Kevin Roose, welcome to FRESH AIR. KEVIN ROOSE: Such a pleasure to be here. DAVIES: You write about automation and using artificial intelligence and the extent to which it eliminates jobs. And you say that there's a lot people misunderstand about how this works. It's not that, you know, somebody is literally replaced one day by a robot. What's the more typical way that automation cuts jobs? ROOSE: Well, there are a few ways. I mean, that kind of one-for-one substitution, it still does happen sometimes. There still are jobs - you know, like, cleaning people at big-box retailers, for example - who are sort of being replaced by robots. But much of the work that can be automated that way has already been automated in factories and manufacturing facilities. So there are some other ways that automation can replace jobs, too. And one of them is by allowing companies to do the same amount of work with many fewer people - new companies, that is. So one example of this is in China, one of the biggest lenders is a company called MYbank, and their signature loan product is referred to as 310 because it takes three minutes to apply online for a loan, it takes one second for an algorithm to approve it, and zero humans are involved in the process. And so that firm has been able to issue billions and billions of dollars in loans with very few employees relative to their competitors. So you might have a bank that has 10,000 loan officers, but if this company, MYbank, can outperform you with a couple hundred employees, that results in a net loss of jobs if that firm takes over. So that's a more common way. But there are other ways, too, including giving us new behaviors that replace old behaviors. So one example of that would be what's been happening with photos. Kodak used to be a major American company with many, many thousands of employees. But we don't hear much about them anymore because now we get photos on our phones, and we distribute them through Instagram and Facebook and on Twitter. And so the distribution has changed. The behavior has changed. And the companies that are sort of doing that new behavior - Instagram and Twitter - those have fewer employees than Kodak used to have because they're much more automated. DAVIES: And there are cases where one company will do something which allows it to operate smarter and leaner, and it causes a loss in jobs somewhere else, like software that allows people to better maintain aircraft, for example. That's one you give. ROOSE: Exactly, yeah. So there are lots of ways in which AI and automation are being implemented to make processes more efficient, which, you know, we think of as generally a good thing. And it is. But it can also result in a loss of jobs. So yeah, if there is a company that's making an algorithm that, you know, tells airlines when to replace parts in their planes, maybe they end up buying fewer parts and maintaining them more. There are many, many examples of this happening throughout the economy. And it doesn't all replace jobs, but there are jobs being lost as a result. DAVIES: Right, so one company just finds they're getting fewer orders. And way down the line, somebody somewhere doesn't need to order stuff because they are taking better care of what they have. You know, there is this growing industry of people who develop artificial intelligence programs. Sometimes it's software; sometimes it's hardware. And they sell to companies. Do they pitch it as, hey, this is going to save you money by cutting jobs? ROOSE: It depends who's listening. And this is one of the big things that made me interested in this topic, was, you know, I live out in Silicon Valley, and I talk to a lot of people in the tech industry. And most of the time, they will tell you, you know, AI is going to be great for people. It's going to free them from mundane and repetitive tasks. It's going to make their lives better. These algorithms are going to personalize everything for them and make it easy for them to get around in the world. But then there's this other story that I started hearing snippets of a few years ago when I decided to write this book, and that story was much more cynical and much more pessimistic. And it basically was these executives who were talking about automation and AI as purely a way to get rid of human workers, to cut their costs and to automate their workforces. And so the clearest example I have of this in the book is I was at a party a few years ago in San Francisco, and I started talking to a guy who was telling me about his startup, as most conversations at parties tend to go in the Bay Area. And he told me that his company had developed a piece of software that he was calling the boomer remover. And I sort of - I was confused by that. I said, what do you mean, the boomer remover? And he told me, well, this is a piece of software that allows companies with factories to use artificial intelligence to streamline the decision about what to produce on which machines on which days. This is called production planning, and humans have done that job for hundreds of years. But this AI program that he had developed was allowing factories and companies to replace the supervisors of those factories - who he referred to as boomers because they were generally older and better paid - with an algorithm. And he was very proud of this. And so there are snippets of this more honest automation conversation that you occasionally hear. And that part was really disturbing to me because he was not concerned about the people who were going to lose their jobs to this technology. In fact, he was almost glad to be able to replace them. DAVIES: You know, defenders of this say, look, this has been happening throughout history - the Industrial Revolution, successive waves of new technology when, you know, factories began to run on electricity. That changed things in big ways - and that, yes, jobs were eliminated, but new ones emerged. Should we be reassured by that argument? ROOSE: Well, I believed in that argument for a long time. I mean, I am a tech writer. I'm not a Luddite. I love technology. I, you know, grew up with computers and on the Internet. And I was very optimistic about this technology because of that argument that you made that, you know, automation and artificial intelligence will destroy some jobs. But they will create other jobs. And those jobs will replace the lost ones. But as I started looking more into the present of AI and also the past of automation, I learned that it's not always that smooth. During the Industrial Revolution, for example, there were people who didn't find work for a long time. There were - you know, wages for workers didn't catch up to corporate profits for something like 50 years. So a lot of the people who went through those technological transformations didn't have a good time. They weren't necessarily happier or living better lives or wealthier as a result of this new technology. But there's also a difference today, which is that artificial intelligence is not just replacing sort of repetitive manual labor. It's also replacing repetitive cognitive labor. It's able to do higher value tasks, not just moving data around on a spreadsheet or moving car parts around in a factory. It's able to do the work of white-collar workers in fields that are generally - require college educations and specialized training. And that's one difference. And then the other difference is there's been some new research out about the effect that automation has been having in the economy. And it's shown that while for much of the 20th century, automation was creating new jobs faster than it was destroying old jobs, for the last few decades, the opposite has been true. New jobs have been disappearing - or old jobs have been disappearing faster than new jobs have been created. DAVIES: After rolling over these arguments a bit in the book, you say that, well, if you were going to rate your view of this on a one to 10 scale, one being no worries, this is all going to work out to 10 being artificial intelligence will destroy everything we hold dear, where are you on the scale? ROOSE: Well, the answer is - I have two answers for that. One is about the technology itself. And on the technology itself, I am much more optimistic. I really think that AI and automation could produce amazing things for us. It could help us cure rare diseases. It could help us fix the climate crisis. It could do any number of amazing things that we really, really need. I am much more worried, on the other hand, about the humans who are in charge of the AI and automation and what their motivations are. I mean, it's the people like the startup founder who told me about the boomer remover. But it's also the executives at large companies who are using automation to replace workers without transforming their companies, without developing new products. They're not trying to innovate and transform their businesses. They're purely trying to do the same amount of work with fewer people. DAVIES: We need to take a break here. Let me reintroduce you. We're speaking with Kevin Roose. He is a technology columnist for The New York Times. His new book is \"Futureproof: 9 Rules For Humans In An Age Of Automation. \" We'll continue our conversation in just a moment. This is FRESH AIR. (SOUNDBITE OF THE ROOTS SONG, \"SACRIFICE\") DAVIES: This is FRESH AIR. And we're speaking with New York Times technology columnist Kevin Roose. He has a new book about the impact of automation and artificial intelligence. It's called \"Futureproof: 9 Rules For Humans In An Age Of Automation. \" You know, it's interesting that a lot of this automation and artificial intelligence doesn't even involve a physical intervention in a workplace, necessarily. A lot of it is simply algorithms, which guide the workplace - the work process through software. And you say, one thing to beware of are bureaucratic bots. That is to say, algorithms which governments and institutions use to determine, you know, who qualifies for unemployment compensation or, in a private company, how the benefits are managed. Do you want to explain what this is and what its impact is? ROOSE: Yeah. The category I call bureaucratic bots is sort of made up of these algorithms that make decisions that affect people's lives in really dramatic and important ways. So I don't think people fully appreciate the extent to which things like benefits, who qualifies for nutrition assistance, who qualifies for public housing are determined by algorithms now. And sometimes that works fine. And some other times, it doesn't work so great. There was a case a few years ago in Michigan where an algorithm that the state was using to determine benefits eligibility misfired. And it kicked a lot of people off their benefits wrongly. And that affected people's lives in real, tangible ways. There are other kinds of bots and automation being used by governments in the criminal justice system, for example, to predict whether a given defendant is likely to reoffend if you put them out on parole. And these algorithms are generally not open and inspectable by the public. They're sort of black boxes. And we don't really know how they work. And there's not a lot of accountability for them. And so as a result, we end up with these kind of mysterious machines making these decisions that affect millions, billions of people's lives. And we don't really understand what they're doing. DAVIES: And I guess when a process like that, who qualifies for what, is highly automated, even if there is an outrageous screw up that clearly affects a lot of people and becomes known, it's hard to unwind and fix quickly, isn't it? ROOSE: Exactly. And it requires humans to intervene and to undo a lot of the work that the machine has screwed up. And I think that's a real issue. And I think there's been some great writing on this. There's a book called Automating Inequality by a scholar named Virginia Eubanks. And she goes into a lot of examples of how this technology, this automation and AI technology is harming people and is disproportionately harming people who don't have a lot of money, who are, you know, dependent on state benefits, people of color, marginalized communities. They suffer when these systems don't work as they're supposed to. And it often takes a long time to clean up the mess. DAVIES: You looked in particular at YouTube and the way it recommended videos to regular YouTube watchers. YouTube is, of course, owned by Google. This is something that you wrote about in the Times. And it's also in your podcast, \"Rabbit Hole. \" You want to explain what you learned about the algorithm that was recommending videos to YouTube and its impact? ROOSE: Well, one thing I didn't fully appreciate is how sophisticated the AI that powers YouTube is. YouTube is owned by Google. And Google has the best AI research team in America. And they produce the most award-winning papers. They have the best Ph. D. s. They - you know, they're at the vanguard of artificial intelligence. And a lot of that research and expertise for the last decade has been going into honing this YouTube algorithm with these techniques that are brand-new and that are making it much more effective. And something like 70% of all the time that people spend on YouTube is directly related to recommendations that come from this algorithm. And so one thing that I learned when I started looking into this is that this algorithm has changed a lot over the years. And it's become much more savvy about what will keep people on YouTube. Maximizing watch time is the No. 1 goal of this algorithm. And so some of the ways that it's learned that it can keep people on YouTube for a long time are by introducing them to new ideas, maybe to conspiracy theories, maybe to more extreme versions of something that they already believe, things that will sort of lead them down these rabbit holes. And so this has had an effect on politics. This has had an effect on our culture. And it's resulted in some cases where people have been radicalized because the algorithm thought that radicalizing them would be a good way to keep them watching YouTube. DAVIES: Wow. So the algorithm sees them have a certain political orientation. And rather than, you know, popping up some videos which might give me another way of looking at it, it takes me a step further into my own beliefs and can result in extremist views of all kinds, right? ROOSE: Yeah. I mean, these algorithms have no idea what they're recommending. That's one thing that I learned is it's not like there's an algorithm sitting inside YouTube's, you know, headquarters that's saying, you know, I want to radicalize this person. So I'm going to show them a conspiracy theory about Qanon or something like that. But it does learn what we enjoy. And it learns what we're attracted to. And it learns what will keep our attention. And often, lies and conspiracy theories and extremist views are just more engaging than the truth. It's much more engaging to think that there is a conspiracy, you know, where people are, you know, being microchipped by Bill Gates every time they get a COVID vaccine than the truth, which is that these vaccines are effective. And they work. And there are no Bill Gates microchips inside of them. And so when you give that job to an algorithm and tell it to learn what people will respond to and don't give it any sort of parameters for that, it learns some intriguing and, sometimes, scary things. DAVIES: What do Google and YouTube officials say when you've done these stories and you've contacted them for comment? ROOSE: Well, they say that, you know, their algorithms are effective and that they're not, you know, radicalizing large numbers of people. They dispute this idea that there's this kind of extremism effect that their algorithms have. But they've also sort of tacitly acknowledged that this is happening because they've changed their algorithm a lot. They've, you know, kicked off a lot of the white supremacists and neo-Nazis who were, you know, major figures on YouTube. They've started monitoring what kind of content their algorithm is recommending to people and sort of reducing what they call borderline content, which is sort of content that's - almost breaks their rules but doesn't quite. So they have changed a lot in response to, you know, criticism and awareness of what is going on there. DAVIES: We need to take another break here. Let me reintroduce you. We are speaking with Kevin Roose. He's a technology columnist for The New York Times. His new book is \"Futureproof: 9 Rules For Humans In An Age Of Automation. \" He'll be back to talk more after a short break. I'm Dave Davies. And this is FRESH AIR. (SOUNDBITE OF FRANK ZAPPA'S \"UNCLE MEAT: MAIN TITLE THEME\") DAVIES: This is FRESH AIR. I'm Dave Davies, in today for Terry Gross. We're speaking with New York Times technology columnist Kevin Roose. His new book is about the expanding use of artificial intelligence and automation to cut costs, transform workplaces and influence our buying habits and lifestyle choices. The book is called \"Futureproof: 9 Rules For Humans In An Age Of Automation. \" So if somebody is worried about this, somebody who has a job in a warehouse or somebody who drives a truck or any of the millions of jobs out in in the economy, how do they evaluate its vulnerability to automation? And what do they do? ROOSE: Well, the conventional way is by looking at it and sort of a job-to-job basis. So there - you know, there are studies showing that, you know, tax preparers have this chance of being automated or truck drivers have this chance. But I think that's the wrong framework because what matters and what we've seen over history is that certain occupations don't just disappear one day. Instead, they sort of change. People who, you know, are doing work that is more rote and repetitive become automated first. And then, you know, the sort of automation works its way up. And sometimes it hits a wall. And it can't sort of do any more of the jobs in that field. And so the version of that today that we're seeing is that, you know, some people within professions like journalism are, you know, very susceptible to automation. The people who write, you know, recaps of sports games or, you know, reports about the stock market or the kinds of corporate earning reports that I used to write - those jobs are much more susceptible than jobs like, frankly, the ones we're doing right now, which are more about human connection and expression of complex ideas. So I think there's a sort of way of looking at this that is not so much about what you do. It's about how you do it and how human you are in performing that work. DAVIES: Yeah. It's interesting, you know, because I think the advice for a lot of people in an increasingly technically sophisticated age is, you know, learn math, learn computer science, you know, forget about all this humanities stuff. It sounds like you're saying that that's - the humanities are really important if you're going to live in this world. ROOSE: Yeah. That was one of the fascinating things I learned while I was researching this book. The more AI experts and computer scientists I talked to, the more sure I became that we have been preparing people for the future in exactly the wrong way. We've been telling them, you know, develop these kind of technical skills in fields like computer science and engineering. We've been telling people to become as productive as possible to optimize their lives, to squeeze out all the inefficiency and spend their time as effectively as possible, in essence, to become more like machines. And really, what we should be teaching people is to be more like humans, to do the things that machines can't do. And so in the book, I go over a couple types of activities that I learned in researching this book were very hard for machines to accomplish as effectively as humans. There are three categories of work that I think is unlikely to be automated in the near future. One is surprising work. So this is work that involves complex rules, changing environments, unexpected variables. AI and automation really like regularity. They like concrete rules, sort of bounded environments and repetitive action. So this is why, like, AI can beat a human in chess. But if you asked an algorithm to teach a kindergarten class, it would fail miserably because that's a very irregular environment with lots of surprises going on. So those surprising jobs are the first jobs I think are relatively safe. The second category is what I call social jobs, jobs that involve making people feel things rather than making things. So these would be the jobs in social services and health care, nursing, therapists, ministers, but also people who perform sort of emotional labor as part of their jobs - people like flight attendants and baristas, you know, people we don't typically think of as being sort of social workers. But their jobs do involve an element of making people feel things. And the third category of work that I think is safe is what I call scarce work. And this is work that involves sort of high-stakes situations, rare combinations of skills or just people who are sort of experts in their fields. And this would include jobs that we have decided are unacceptable to automate. So you know, we could replace all of the human 911 operators with robots. That technology exists. But if you call 911 today, you will get a human because we want humans to be doing that job. When we're in trouble, we want a human to pick up the phone and help us to deal with our problems. DAVIES: You know, some of the ideas that you present to deal with this rule of automation involve individual choices. But some of them are really at the level of society, large institutions, the government. What should elected officials and policy analysts be focused on as we confront these issues? ROOSE: Well, I think we need to prepare for the possibility that a lot of people are going to fall through the cracks of this technological transformation. It's happened during every technological transformation we've ever had, and it's going to happen this time. And in fact, it already is happening. And so - you know, there have been various solutions proposed. You know, universal basic income is the kind of Andrew Yang solution to this. And I think that's probably a good idea. We're seeing now during the pandemic with these stimulus checks that actually giving people money is a really good way to get people out of poverty and to sustain them through periods of hardship. So something like that, like universal basic income, could help. Something like \"Medicare for All\" could also help by not - by sort of detaching health care from our work. You know, a big part of the reason people don't quit their jobs, even if they know they're about to be automated, is because they don't want to go without health care. But there are also solutions that we could put in place that already exist in other countries. So in Sweden, for example, there are these job councils that are basically sort of public-private partnerships that essentially catch workers who are displaced by automation and layoffs. And they help retrain them. They sustain them while they're looking for work, and they find them other work. And that works very effectively in that country. In Japan, there's a similar practice. And so I think we need to take this really seriously. And I think we - you know, we can do a lot more than we're currently doing. DAVIES: We need to take another break here. Let me reintroduce you. We're speaking with Kevin Roose. He's a technology columnist for The New York Times. His new book is \"Futureproof: 9 Rules For Humans In An Age Of Automation. \" We'll continue our conversation after this short break. This is FRESH AIR. (SOUNDBITE OF JULIAN LAGE'S \"IOWA TAKEN\") DAVIES: This is FRESH AIR, and we're speaking with New York Times technology columnist Kevin Roose. His new book is about the expanding use of artificial intelligence and automation in our lives. The book is \"Futureproof: 9 Rules For Humans In An Age Of Automation. \" You don't just report on automation for the Times, and you've spent a fair amount of time reporting on online extremism. And for, you know, a recent episode of The New York Times radio program and podcast \"The Daily,\" you described watching the reaction of followers of the QAnon conspiracy theory to the events on Inauguration Day, January 20, when Joe Biden was sworn in. I thought we - I wanted to play a clip of this because you captured some of these reactions. You want to just first tell us what you were doing on Inauguration Day and what you wanted to see? ROOSE: Yeah. Well, I have two computer monitors in my office side by side. And on one of them, I was watching the inauguration. You know, I had a stream going, and I was watching Joe Biden get sworn into office. And on the other screen, I was looking at this kind of QAnon reality. There were these predictions that people who believe in this conspiracy theory had made that Joe Biden would not actually be inaugurated, that Donald Trump would implement martial law and stop the proceedings and announce the mass arrests of elite pedophiles and satanic criminals and that there would be this kind of day of reckoning during the inauguration that would result in Donald Trump taking a second term in office. And so I was watching those people, the people who believed in that theory, respond to the events of the actual inauguration that was happening on my other screen. DAVIES: All right, so we're going to listen to a bit of this. This is from the podcast \"The Daily. \" And what we'll hear is a QAnon follower anticipating Trump seizing power before Biden can be sworn into office. And then we hear some of you describing this and then some other followers. So let's just listen. (SOUNDBITE OF PODCAST, \"THE DAILY\") UNIDENTIFIED PERSON #1: It would be hilarious if Trump did the emergency broadcast in the middle of the inauguration. That would be hilarious. ROOSE: As inauguration started, politicians, you know, walk in, take their seats. These people that they believe are members of this global cabal of criminals - Hillary Clinton, George W. Bush, Barack Obama - they're all in one place. UNIDENTIFIED PERSON #2: I got the popcorn ready. UNIDENTIFIED PERSON #3: I'm optimistic. UNIDENTIFIED PERSON #4: Almost like it's the moment of truth. ROOSE: One person on a QAnon message board writes, the next 48 hours will be like the entire Revolutionary War and the fall of Berlin compressed into two days. I have called off work so I can witness history in the making. What a time to be alive. DAVIES: And that's our guest Kevin Roose on an episode of the podcast \"The Daily\" in which he's watching QAnon followers in real time as they anticipate Trump taking power on Inauguration Day, January 20. That obviously didn't happen. And I know, Kevin Roose, that you've maintained contact with a number of QAnon followers. You know, others hope that on March 4 - I think that was the date which was traditionally the Inauguration Day historically. That was another opportunity for Trump to make his move. Nothing happened. Life goes on. We have a new president. I'm wondering how those that you are in contact with are reacting to this collision with reality. ROOSE: Well, it varies. So some of them have gotten disillusioned with QAnon. They've said, you know, maybe we've been lied to. Maybe this whole thing, you know, was made up, and maybe I'm going to go find some other way to spend my time or some other conspiracy theory to attach myself to. But then there are people who just move the goalposts. They say, OK, well, it's not that Q, the sort of mysterious, anonymous figure at the center of the QAnon movement - it's not that Q is wrong. It's just that we misinterpreted Q. So the real date of this great awakening, they call it, will be sometime in the future. It'll be, you know, in the 2024 election maybe or maybe even before then. And so there's this sort of reluctance to accept reality that I don't think is unique to QAnon. I mean, we've seen, you know, religious groups that predict that the world is going to end on a certain day. You know, that day comes and goes. And they don't lose their faith. They just sort of shift their expectations. DAVIES: A lot of people have talked about the need to address this, you know, increasing, you know, embrace of deluded thinking in a lot of these conspiracy theories. And, you know, social media institutions have responded in some ways. But, you know, it seemed like this was potentially an inflection point where such, you know, a clearly predicted and anticipated event just didn't happen. The underlying - you know, reality undermines the thinking. Is it an opportunity to intervene in some way? If it is, who should do it? I'm wondering if you've thought about that, how you begin to - I don't know - weaken the hold of some of this thinking on its followers. ROOSE: I think it is a moment for potential intervention. I get emails every day from people who say, you know, my mom or my brother or my neighbor or my colleague has gotten really into Internet conspiracy theories. How do I get them out of it? And it's a really hard question. That is not something we know the answer to. But I think it does work better in moments where there is sort of uncertainty and people are sort of grappling with what they believe and whether or not it's true. So I think, yeah, this is a moment where some people may not change their thinking at all and they may still be resistant to being sort of reintroduced to reality, but for other people, there might be a kind of break in the clouds and a chance to bring them back. DAVIES: You're a technology writer. I'm wondering, just looking ahead, are there new technologies, new trends that you think are important for you to follow up on? I mean, what questions do you think you'll be examining in the next year? ROOSE: Well, AI is fascinating. I - you know, we've talked a lot about the potential negatives of it, but there are a lot of potential positives, too. I mean, one area I'm looking at right now is the use of AI in medicine and health care, not just to sort of make things more efficient, but to discover new drugs, you know, to allow doctors to do kind of better analysis and diagnosis of patients. I think that's really promising, so I'm looking at that. And I'm also excited about just the stuff that is in our, you know, homes and lives just getting - continuing to get better. You know, I don't remember if you - or I don't know if you remember, but, like, when, you know, something like Siri first came out, like, it wasn't very good (laughter). Like, you would ask, you know, Siri, what time is it? And she would respond, thyme is an herb used in cooking, you know? DAVIES: Right. ROOSE: It's something like that. And those models, those AIs have gotten much more accurate in the past few years. And I think that's something to be excited about and also to monitor very closely because it's not always good. DAVIES: Yeah, one of your nine rules is demote your devices, right (laughter)? ROOSE: Yeah. We need to be in control of our technology. There's a way in which we use our tools, and there's a way in which our tools use us. And so I think restoring authority over the technology in our lives so that we are in the driver's seat, we are controlling our own human experience, I think that's really important. DAVIES: Well, Kevin Roose, thank you so much for speaking with us. ROOSE: Thanks so much for having me. DAVIES: Kevin Roose is a technology columnist for the New York Times and host of \"Rabbit Hole,\" an eight-part podcast about how the Internet is affecting us. His new book is \"Futureproof: 9 Rules For Humans In The Age Of Automation. \" (SOUNDBITE OF ALLISON MILLER'S \"VALLEY OF THE GIANTS\") DAVIES: Coming up, Justin Chang reviews \"Quo Vadis, Aida? \", the Oscar-nominated film about the massacre of Muslims in the town of Srebrenica near the end of the Bosnian war. This is FRESH AIR. (SOUNDBITE OF JASON MORAN'S \"BIG STUFF\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-03-17-978163949": {"title": "NASA Unlikely To Send People To The Moon In 2024, But Is Proceeding With Tests : NPR", "url": "https://www.npr.org/2021/03/17/978163949/nasa-to-test-rocket-in-the-next-step-toward-returning-to-the-moon", "author": "No author found", "published_date": "2021-03-17", "content": "", "section": "Science", "disclaimer": ""}, "2021-03-17-976152350": {"title": "From Amazon To FedEx, The Delivery Truck Is Going Electric : NPR", "url": "https://www.npr.org/2021/03/17/976152350/from-amazon-to-fedex-the-delivery-truck-is-going-electric", "author": "No author found", "published_date": "2021-03-17", "content": "", "section": "Business", "disclaimer": ""}, "2021-03-19-978210584": {"title": "Why SkySilk Came Out of Nowhere To Save Parler After Capitol Riot : NPR", "url": "https://www.npr.org/2021/03/19/978210584/why-skysilk-came-out-of-nowhere-to-save-parler-after-capitol-riot", "author": "No author found", "published_date": "2021-03-19", "content": "LULU GARCIA-NAVARRO, HOST:  Rioters who stormed the Capitol back in January documented the attack on the conservative social media platform called Parler. Amazon, which was hosting the site, feared additional violence and knocked it offline. That was almost the end, but then an obscure company came out of nowhere to save it. NPR's Bobby Allyn went to Los Angeles to talk to the man in charge of the company, and he joins us now. Welcome to the program. BOBBY ALLYN, BYLINE: Hello. GARCIA-NAVARRO: Hi, Bobby. What can you tell us about the company that brought Parler back online? ALLYN: Yeah. It's a company called SkySilk. It's an IT firm that hasn't been around very long. And they do things like keep websites running, and they offer cloud storage. It's honestly an operation that has flown under the radar, even here - out here in Silicon Valley in tech circles. Kind of no one's ever heard of them. And I interviewed some of its former employees who said the firm is, quote, \"sketchy\". . . GARCIA-NAVARRO: (Laughter). ALLYN: . . . That the office was eerily empty. There were, like, surveillance cameras everywhere, and people would go into work every day and weren't even sure what their jobs were exactly. Now, the CEO of the company says SkySilk is not a shell company. He told me that specifically. But at any rate, the only reason we're talking about this company is because it agreed to do what no other web hosting company was willing to, and that's strike a deal with Parler. And for those who don't know, Parler is kind of a conservative spin on Twitter. GARCIA-NAVARRO: Tell us why no other company was willing to work with Parler after Amazon kicked it offline. ALLYN: Yeah. So Amazon said goodbye, and then six other Web hosts said the same thing. No, thanks. We're not interested in doing business with you. And that's because it really became a pariah in the tech world. It was seen as a platform that was growing fast but just could not manage itself at all. I mean, it let loads and loads of problematic content thrive - white nationalist groups, disinformation, hate speech and harassment. And Web hosts saw that as a real liability. Now, Facebook, Lulu, we should note, you know, was a major organizing tool for what led to the Capitol riots, but Parler has gotten so much of our attention because of it's anything-goes approach to content on the site. GARCIA-NAVARRO: So why did this little IT firm that nobody really ever heard of that was called sketchy by its, you know, own employees decide to do this? ALLYN: Yeah. So I went to Burbank to try to figure that out. I talked to SkySilk's CEO. It's this guy named Kevin Matossian. He's a film producer who's only been leading the company for a couple of months. And he told me he's doing business with Parler as a way of sticking it to Big Tech companies like Amazon. KEVIN MATOSSIAN: It scares us and concerns us that big technology can turn you on and turn you off. We used to joke about this. Write them off. You can make you disappear. Well, now big technologies can make you digitally disappear. ALLYN: So I said to Matossian, OK, OK. But what about all the hate speech and disinformation and the really violent and ugly stuff that flies around Parler? Are you endorsing that? And he said no, but he thinks the answer to bad speech is not censorship but rather more speech, no matter how vile it is. GARCIA-NAVARRO: So Parler is now back online. Is it as permissive with what people can share, including violent threats as before? ALLYN: I mean, the short answer is yes. I mean, right now, the only kind of content that they actually are banning is content that is illegal, content that breaks the law. Other than that, anything goes. And so, you know, Parler remains a place that is popular for really two kinds of people, Lulu. One group are people who are fed up with Big Tech and say deplatforming anyone is an abuse of power, and a second group of people who see policing online speech as, you know, a step too far. And Parler's value add (laughter) is that they promise to do as little of it as possible. Now, experts who study extremism and disinformation have some obvious concerns with this laissez-faire approach. I mean, unfettered speech online might sound great to some. But as we have seen, it can lead to some really scary real world consequences. GARCIA-NAVARRO: Indeed. That's NPR's Bobby Allyn. Thank you very much. ALLYN: Thank you. LULU GARCIA-NAVARRO, HOST:   Rioters who stormed the Capitol back in January documented the attack on the conservative social media platform called Parler. Amazon, which was hosting the site, feared additional violence and knocked it offline. That was almost the end, but then an obscure company came out of nowhere to save it. NPR's Bobby Allyn went to Los Angeles to talk to the man in charge of the company, and he joins us now. Welcome to the program. BOBBY ALLYN, BYLINE: Hello. GARCIA-NAVARRO: Hi, Bobby. What can you tell us about the company that brought Parler back online? ALLYN: Yeah. It's a company called SkySilk. It's an IT firm that hasn't been around very long. And they do things like keep websites running, and they offer cloud storage. It's honestly an operation that has flown under the radar, even here - out here in Silicon Valley in tech circles. Kind of no one's ever heard of them. And I interviewed some of its former employees who said the firm is, quote, \"sketchy\". . . GARCIA-NAVARRO: (Laughter). ALLYN: . . . That the office was eerily empty. There were, like, surveillance cameras everywhere, and people would go into work every day and weren't even sure what their jobs were exactly. Now, the CEO of the company says SkySilk is not a shell company. He told me that specifically. But at any rate, the only reason we're talking about this company is because it agreed to do what no other web hosting company was willing to, and that's strike a deal with Parler. And for those who don't know, Parler is kind of a conservative spin on Twitter. GARCIA-NAVARRO: Tell us why no other company was willing to work with Parler after Amazon kicked it offline. ALLYN: Yeah. So Amazon said goodbye, and then six other Web hosts said the same thing. No, thanks. We're not interested in doing business with you. And that's because it really became a pariah in the tech world. It was seen as a platform that was growing fast but just could not manage itself at all. I mean, it let loads and loads of problematic content thrive - white nationalist groups, disinformation, hate speech and harassment. And Web hosts saw that as a real liability. Now, Facebook, Lulu, we should note, you know, was a major organizing tool for what led to the Capitol riots, but Parler has gotten so much of our attention because of it's anything-goes approach to content on the site. GARCIA-NAVARRO: So why did this little IT firm that nobody really ever heard of that was called sketchy by its, you know, own employees decide to do this? ALLYN: Yeah. So I went to Burbank to try to figure that out. I talked to SkySilk's CEO. It's this guy named Kevin Matossian. He's a film producer who's only been leading the company for a couple of months. And he told me he's doing business with Parler as a way of sticking it to Big Tech companies like Amazon. KEVIN MATOSSIAN: It scares us and concerns us that big technology can turn you on and turn you off. We used to joke about this. Write them off. You can make you disappear. Well, now big technologies can make you digitally disappear. ALLYN: So I said to Matossian, OK, OK. But what about all the hate speech and disinformation and the really violent and ugly stuff that flies around Parler? Are you endorsing that? And he said no, but he thinks the answer to bad speech is not censorship but rather more speech, no matter how vile it is. GARCIA-NAVARRO: So Parler is now back online. Is it as permissive with what people can share, including violent threats as before? ALLYN: I mean, the short answer is yes. I mean, right now, the only kind of content that they actually are banning is content that is illegal, content that breaks the law. Other than that, anything goes. And so, you know, Parler remains a place that is popular for really two kinds of people, Lulu. One group are people who are fed up with Big Tech and say deplatforming anyone is an abuse of power, and a second group of people who see policing online speech as, you know, a step too far. And Parler's value add (laughter) is that they promise to do as little of it as possible. Now, experts who study extremism and disinformation have some obvious concerns with this laissez-faire approach. I mean, unfettered speech online might sound great to some. But as we have seen, it can lead to some really scary real world consequences. GARCIA-NAVARRO: Indeed. That's NPR's Bobby Allyn. Thank you very much. ALLYN: Thank you.", "section": "Untangling Disinformation", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-03-19-978393310": {"title": "How Zoom Beat Tech Giants To Dominate Video Chat In The Pandemic : NPR", "url": "https://www.npr.org/2021/03/19/978393310/a-pandemic-winner-how-zoom-beat-tech-giants-to-dominate-video-chat", "author": "No author found", "published_date": "2021-03-19", "content": "STEVE INSKEEP, HOST:  Roughly one year ago, I heard colleagues refer to a meeting on Zoom. It was one of those passing references, you know, where people assume you already know what they mean. But I didn't. I'd literally never heard of the brand. Within a few days, of course, I knew, as did millions of others who likely had not known before. Zoom is by no means the only way for a video meeting, but the company has come out ahead during the pandemic. Zoom is among NPR's financial supporters, and we cover it like any other company. NPR's Shannon Bond has the company's pandemic story. SHANNON BOND, BYLINE: Zoom's chief financial officer, Kelly Steckelberg, vividly remembers one specific date last spring. KELLY STECKELBERG: March 15 last year was the day when everything changed. It's like we woke up, and almost overnight, the demand grew exponentially. BOND: Demand from companies trying to keep running after sending everybody home, schools setting up virtual classrooms - then the floodgates opened. Here at NPR, we did stories about fitness classes moving to Zoom. (SOUNDBITE OF ARCHIVED NPR BROADCAST)KATIE GOULD: You're going to need a broom and a towel. BOND: Happy hours, complete with drinking games. (SOUNDBITE OF ARCHIVED NPR BROADCAST)DJ HADDAD: We figured out rules for virtual beer pong. BOND: One of our producers watched her sister get married over Zoom. (SOUNDBITE OF ARCHIVED NPR BROADCAST)UNIDENTIFIED PERSON: You may now seal your vows with a kiss. (CHEERING)BOND: By April, Zoom meetings were attracting 300 million participants a day, 30 times the amount just a few months before. Zoom was an upstart, and it was going up against products from giants like Google and Microsoft, which are both NPR supporters. So how did Zoom beat these heavyweights? JASON FRIED: The real reason is, it was just simply way easier. BOND: Jason Fried is CEO of Basecamp, a company that makes remote work software. He told me, over his preferred app, Skype, he's been working remotely for two decades. He says Zoom made sending a meeting link as easy as sharing a YouTube video. FRIED: You open a room. You get a URL. You send the URL around to people. That's it. BOND: Unlike other video meetings, the people you invite to Zoom don't have to log in or download software. Fried says that simplicity meant, even though the app was intended for companies, it was really easy for everyone else to use, too. But Zoom was so popular and convenient, it had a downside. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED NEWS ANCHOR: The FBI is warning about Zoom bombing. BOND: Intruders had started crashing Zoom meetings because security was so lax. Town halls, school classes, AA meetings were all targets. Dennis Johnson knows all about this. Last March, he was defending his doctoral dissertation on Zoom in front of family and friends when an unknown attacker scrawled racial slurs and genitalia on the screen. A year later, Johnson still avoids Zoom when he can. DENNIS JOHNSON: Every time somebody calls me a doctor, I think of that moment. So it's just like - it's just a nasty taste in my mouth. BOND: Researchers uncovered other security and privacy flaws. Zoom told users meetings were fully encrypted when they weren't. The company admitted it shut down the accounts of activists in China after pressure from the government. Zoom went into damage control mode. It put everything except privacy and security on pause for three months, and it reached settlements with federal and state regulators investigating the issues. Steckelberg, Zoom's CFO, says the episode was a wake-up call. STECKELBERG: It was a humbling experience for all of us, but we learned a lot through it. And we have come out on the other side a stronger - a better company with a stronger and more secure platform. BOND: Now, after a year of daily life and major milestones conducted over Zoom, what happens when people get vaccinated and can go back to seeing each other face to face? Daniel Ives is an analyst at Wedbush Securities. DANIEL IVES: There could definitely be a Roaring '20s-type feel post-COVID where people are just going to want to get out and just almost a pent-up demand. BOND: But, he says, Zoom has made such inroads into our lives in the past year, it's here to stay. So there's still time to learn how to use the mute button. Shannon Bond, NPR News. (SOUNDBITE OF MARLEY CARROLL'S \"FIREFLIES\") STEVE INSKEEP, HOST:   Roughly one year ago, I heard colleagues refer to a meeting on Zoom. It was one of those passing references, you know, where people assume you already know what they mean. But I didn't. I'd literally never heard of the brand. Within a few days, of course, I knew, as did millions of others who likely had not known before. Zoom is by no means the only way for a video meeting, but the company has come out ahead during the pandemic. Zoom is among NPR's financial supporters, and we cover it like any other company. NPR's Shannon Bond has the company's pandemic story. SHANNON BOND, BYLINE: Zoom's chief financial officer, Kelly Steckelberg, vividly remembers one specific date last spring. KELLY STECKELBERG: March 15 last year was the day when everything changed. It's like we woke up, and almost overnight, the demand grew exponentially. BOND: Demand from companies trying to keep running after sending everybody home, schools setting up virtual classrooms - then the floodgates opened. Here at NPR, we did stories about fitness classes moving to Zoom. (SOUNDBITE OF ARCHIVED NPR BROADCAST) KATIE GOULD: You're going to need a broom and a towel. BOND: Happy hours, complete with drinking games. (SOUNDBITE OF ARCHIVED NPR BROADCAST) DJ HADDAD: We figured out rules for virtual beer pong. BOND: One of our producers watched her sister get married over Zoom. (SOUNDBITE OF ARCHIVED NPR BROADCAST) UNIDENTIFIED PERSON: You may now seal your vows with a kiss. (CHEERING) BOND: By April, Zoom meetings were attracting 300 million participants a day, 30 times the amount just a few months before. Zoom was an upstart, and it was going up against products from giants like Google and Microsoft, which are both NPR supporters. So how did Zoom beat these heavyweights? JASON FRIED: The real reason is, it was just simply way easier. BOND: Jason Fried is CEO of Basecamp, a company that makes remote work software. He told me, over his preferred app, Skype, he's been working remotely for two decades. He says Zoom made sending a meeting link as easy as sharing a YouTube video. FRIED: You open a room. You get a URL. You send the URL around to people. That's it. BOND: Unlike other video meetings, the people you invite to Zoom don't have to log in or download software. Fried says that simplicity meant, even though the app was intended for companies, it was really easy for everyone else to use, too. But Zoom was so popular and convenient, it had a downside. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED NEWS ANCHOR: The FBI is warning about Zoom bombing. BOND: Intruders had started crashing Zoom meetings because security was so lax. Town halls, school classes, AA meetings were all targets. Dennis Johnson knows all about this. Last March, he was defending his doctoral dissertation on Zoom in front of family and friends when an unknown attacker scrawled racial slurs and genitalia on the screen. A year later, Johnson still avoids Zoom when he can. DENNIS JOHNSON: Every time somebody calls me a doctor, I think of that moment. So it's just like - it's just a nasty taste in my mouth. BOND: Researchers uncovered other security and privacy flaws. Zoom told users meetings were fully encrypted when they weren't. The company admitted it shut down the accounts of activists in China after pressure from the government. Zoom went into damage control mode. It put everything except privacy and security on pause for three months, and it reached settlements with federal and state regulators investigating the issues. Steckelberg, Zoom's CFO, says the episode was a wake-up call. STECKELBERG: It was a humbling experience for all of us, but we learned a lot through it. And we have come out on the other side a stronger - a better company with a stronger and more secure platform. BOND: Now, after a year of daily life and major milestones conducted over Zoom, what happens when people get vaccinated and can go back to seeing each other face to face? Daniel Ives is an analyst at Wedbush Securities. DANIEL IVES: There could definitely be a Roaring '20s-type feel post-COVID where people are just going to want to get out and just almost a pent-up demand. BOND: But, he says, Zoom has made such inroads into our lives in the past year, it's here to stay. So there's still time to learn how to use the mute button. Shannon Bond, NPR News. (SOUNDBITE OF MARLEY CARROLL'S \"FIREFLIES\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-03-22-975220122": {"title": "Lina Khan, nominated to the FTC, is an outspoken critic of Big Tech's power : NPR", "url": "https://www.npr.org/2021/03/22/975220122/big-tech-showdown-looms-as-biden-taps-top-critics-lina-khan-tim-wu", "author": "No author found", "published_date": "2021-03-22", "content": "", "section": "Technology", "disclaimer": ""}, "2021-03-22-979886135": {"title": "Tech Giants Cut Commissions It Charges App Developers  : NPR", "url": "https://www.npr.org/2021/03/22/979886135/tech-giants-cut-commissions-it-charges-app-developers", "author": "No author found", "published_date": "2021-03-22", "content": "STEVE INSKEEP, HOST:  Two big tech companies made a rare concession to developers that do business with them. Operators of mobile phone apps have to pay to get their products seen by customers of Apple and Google. Critics say those big tech companies are so powerful, they are like nation states. And the charges for mobile phone apps were like a tax. Now comes a tax cut. Apple and Google are financial supporters of NPR, which we cover like any companies. And here, Bobby Allyn reports. BOBBY ALLYN, BYLINE: Video game developer Derrick Morton, who runs a company called FlowPlay, says it's daunting to sell his video games for mobile phones because Apple and Google's app stores take a big cut. DERRICK MORTON: In a market where there's a 30% fee for just for the platform, this breaks down the pie to the extent where there's almost nothing left for developers. ALLYN: If you have a smartphone, chances are you have to use an app store controlled by Apple or Google to download stuff. The companies say they need to collect a commission on what you buy to support the privacy and security of apps. Apple and Google have defended these fees for more than a decade. But now the companies have caved and slashed them. RANDY NELSON: You have sort of the reality of this. And then you have the optics of this. ALLYN: What Randy Nelson of the analytics firm Sensor Tower means is, yes, this is a victory for small app developers who are set to benefit the most. NELSON: But for Apple at the end of the day or for Google at the end of the day, what this is actually meaning to their bottom lines is not that substantial. ALLYN: But this was never just about money. These changes are coming right in the midst of some serious legal jeopardy for Apple and Google. State and federal investigators are probing whether the companies broke the law by allegedly making it hard for rivals to compete with them. Apple CEO Tim Cook is even scheduled to testify about these fees in a trial next month. So the timing of the fee cuts, that is interesting, says Chris Sagers. He's a law professor at Cleveland State University who studies antitrust issues. CHRIS SAGERS: I think it probably reflects the sense of the two companies that they're in significant trouble. ALLYN: Trouble, Sagers says, that extending an olive branch to developers right now is not going to do much about. SAGERS: Two firms made an agreement to lower their prices only when they're under immense legal pressure - doesn't make me think that this market has become competitive or that everything is fine. ALLYN: Morton at the 62-person video game company FlowPlay says, we'll take it. MORTON: I would say the really small guys are ecstatic. ALLYN: So much so that Morton says he's going to make some new moves into mobile video game apps. Bobby Allyn, NPR News, San Francisco. (SOUNDBITE OF MOKHOV'S \"SPRING EVENING\") STEVE INSKEEP, HOST:   Two big tech companies made a rare concession to developers that do business with them. Operators of mobile phone apps have to pay to get their products seen by customers of Apple and Google. Critics say those big tech companies are so powerful, they are like nation states. And the charges for mobile phone apps were like a tax. Now comes a tax cut. Apple and Google are financial supporters of NPR, which we cover like any companies. And here, Bobby Allyn reports. BOBBY ALLYN, BYLINE: Video game developer Derrick Morton, who runs a company called FlowPlay, says it's daunting to sell his video games for mobile phones because Apple and Google's app stores take a big cut. DERRICK MORTON: In a market where there's a 30% fee for just for the platform, this breaks down the pie to the extent where there's almost nothing left for developers. ALLYN: If you have a smartphone, chances are you have to use an app store controlled by Apple or Google to download stuff. The companies say they need to collect a commission on what you buy to support the privacy and security of apps. Apple and Google have defended these fees for more than a decade. But now the companies have caved and slashed them. RANDY NELSON: You have sort of the reality of this. And then you have the optics of this. ALLYN: What Randy Nelson of the analytics firm Sensor Tower means is, yes, this is a victory for small app developers who are set to benefit the most. NELSON: But for Apple at the end of the day or for Google at the end of the day, what this is actually meaning to their bottom lines is not that substantial. ALLYN: But this was never just about money. These changes are coming right in the midst of some serious legal jeopardy for Apple and Google. State and federal investigators are probing whether the companies broke the law by allegedly making it hard for rivals to compete with them. Apple CEO Tim Cook is even scheduled to testify about these fees in a trial next month. So the timing of the fee cuts, that is interesting, says Chris Sagers. He's a law professor at Cleveland State University who studies antitrust issues. CHRIS SAGERS: I think it probably reflects the sense of the two companies that they're in significant trouble. ALLYN: Trouble, Sagers says, that extending an olive branch to developers right now is not going to do much about. SAGERS: Two firms made an agreement to lower their prices only when they're under immense legal pressure - doesn't make me think that this market has become competitive or that everything is fine. ALLYN: Morton at the 62-person video game company FlowPlay says, we'll take it. MORTON: I would say the really small guys are ecstatic. ALLYN: So much so that Morton says he's going to make some new moves into mobile video game apps. Bobby Allyn, NPR News, San Francisco. (SOUNDBITE OF MOKHOV'S \"SPRING EVENING\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-03-23-980341703": {"title": "Ex-CEO John Matze Sues Parler Over 'Arrogant Theft,' Claims Site Was 'Hijacked' : NPR", "url": "https://www.npr.org/2021/03/23/980341703/ex-ceo-sues-parler-over-arrogant-theft-claims-site-was-hijacked", "author": "No author found", "published_date": "2021-03-23", "content": "", "section": "Technology", "disclaimer": ""}, "2021-03-24-981021257": {"title": "Chinese Hackers Made Fake Facebook Profiles, Apps To Spy On Uyghur Activists : NPR", "url": "https://www.npr.org/2021/03/24/981021257/chinese-hackers-made-fake-facebook-profiles-apps-to-spy-on-uyghur-activists", "author": "No author found", "published_date": "2021-03-24", "content": "", "section": "Asia", "disclaimer": ""}, "2021-03-24-980436658": {"title": "Trump Social Media Platform: There's Reason For Skepticism : NPR", "url": "https://www.npr.org/2021/03/24/980436658/trump-teases-starting-his-own-social-media-platform-heres-why-itd-be-tough", "author": "No author found", "published_date": "2021-03-24", "content": "", "section": "Politics", "disclaimer": ""}, "2021-03-25-981203566": {"title": "5 Takeaways From Big Tech's Misinformation Hearing : NPR", "url": "https://www.npr.org/2021/03/25/981203566/5-takeaways-from-big-techs-misinformation-hearing", "author": "No author found", "published_date": "2021-03-25", "content": "", "section": "Untangling Disinformation", "disclaimer": ""}, "2021-03-25-981309882": {"title": "Congress Pressed Tech CEOs About The Falsehoods Spread On Their Platforms : NPR", "url": "https://www.npr.org/2021/03/25/981309882/congress-pressed-tech-ceos-about-the-falsehoods-spread-on-their-platforms", "author": "No author found", "published_date": "2021-03-25", "content": "ARI SHAPIRO, HOST:  Hoaxes and violent messages online can lead to real-world harm, like the January 6 attack on the U. S. Capitol, which was largely planned and documented on platforms including Facebook, Twitter and YouTube. So should social media companies be responsible for that? That's essentially what Pennsylvania Congressman Mike Doyle, a Democrat, asked Facebook CEO Mark Zuckerberg at a hearing today. (SOUNDBITE OF ARCHIVED RECORDING)MIKE DOYLE: Yes or no. Do you bear some responsibility for what happened? MARK ZUCKERBERG: Congressman, our responsibility is to make sure that we build effective systems to help. . . DOYLE: OK, the gentleman chooses not to answer the question. SHAPIRO: The heads of Google and Twitter also testified at that hearing. These companies are among NPR's financial supporters. And NPR tech correspondent Shannon Bond is here to fill us in on the hearing. Hi, Shannon. SHANNON BOND, BYLINE: Hi, Ari. SHAPIRO: Many members of the committee were there when this pro-Trump mob breached the Capitol back in January. At today's hearing, how much did they blame the tech companies for that? BOND: Well, like we heard from Mike Doyle, they were certainly asking them to answer for their role. But what we heard from the companies, you know, is what Zuckerberg told Doyle. It was not Facebook that attacked the Capitol, he said. It was the rioters spurred on by former President Trump. And, Ari, that distinction between what is shared online and then what people do in real life, that's this core tension between these powerful companies' point of view and their critics, including in government. So today we heard the CEOs - Zuckerberg, as well as Jack Dorsey of Twitter and Sundar Pichai of Google. They really focused on talking up their policies, talking about how much they've cracked down on misinformation, especially during the pandemic and around the election. SHAPIRO: Did they acknowledge any room for improvement, or was it just pure kind of, like, defensiveness and happy talk from the tech companies? BOND: They didn't give a lot of ground. I mean, the one who came closest to acknowledging some kind of responsibility was Jack Dorsey of Twitter. He said, yes, social media did play a role in January 6. But he also said that can't be pinned solely on tech companies. And throughout the day, lawmakers were very frustrated with the answers they were getting. You could hear that frustration here from Democrat Frank Pallone of New Jersey. (SOUNDBITE OF ARCHIVED RECORDING)FRANK PALLONE: You're not bystanders. You're encouraging this stuff. SHAPIRO: So what are lawmakers proposing, Shannon? BOND: Well, there is a bunch of bills that are being introduced. Many are focused on holding the companies more responsible for exactly these - this kind of harm. Today, you know, there were questions. They pushed the CEOs a lot on how their platforms work, about how their business models - you know, these business models of getting people to spend a lot of time online so that these companies can sell ads - how that might actually be rewarding the most inflammatory content because we know that often gets the most engagement, and then how that's contributed to the spread of lies about election fraud, doubt about vaccines. You know, and on the Republican side, interestingly, you know, at other recent hearings with these tech CEOs, we've heard a lot of complaints about anti-conservative bias. They say people like former President Trump have been unfairly muzzled. We heard less of that today. Many Republicans zeroed in on the effects of social media on kids, on their mental health and wellbeing. Here's Cathy McMorris Rodgers of Washington. (SOUNDBITE OF ARCHIVED RECORDING)CATHY MCMORRIS RODGERS: Your platforms are my biggest fear as a parent. BOND: And so some Democrats also mentioned these fears, and I think that might be a sign you will see more bipartisan efforts to take on these companies through new laws. SHAPIRO: Interesting. What are the companies saying specifically about the proposed regulations that lawmakers are talking about? BOND: Well, look, Ari; they know change is coming, and now you're starting to see these companies really trying to get ahead of those changes, shape those changes, especially Facebook. It's been running a lot of ads recently calling for updated rules for the Internet, saying, you know, it's time. Zuckerberg today laid out more of a vision for those new rules. You know, he talked about requiring big platforms to be more transparent, to have systems in place to deal with content that breaks the law. You know, a lot of these things are things Facebook itself is already doing, so that could potentially benefit them. And, you know, Google and Twitter, on the other hand, they've been warning a bit about if these changes are done the wrong way, that could actually backfire. Ultimately, you know, these big companies, like Facebook and Google, they have a lot of money. They have the legal power to comply with regulation, especially if they can shape it. So the question, Ari, is, how might these rules we see getting changed affect everybody else in the tech world, not just the big guys? SHAPIRO: That's NPR's tech correspondent Shannon Bond. Thanks, Shannon. BOND: Thanks, Ari. (SOUNDBITE OF MUSIC) ARI SHAPIRO, HOST:   Hoaxes and violent messages online can lead to real-world harm, like the January 6 attack on the U. S. Capitol, which was largely planned and documented on platforms including Facebook, Twitter and YouTube. So should social media companies be responsible for that? That's essentially what Pennsylvania Congressman Mike Doyle, a Democrat, asked Facebook CEO Mark Zuckerberg at a hearing today. (SOUNDBITE OF ARCHIVED RECORDING) MIKE DOYLE: Yes or no. Do you bear some responsibility for what happened? MARK ZUCKERBERG: Congressman, our responsibility is to make sure that we build effective systems to help. . . DOYLE: OK, the gentleman chooses not to answer the question. SHAPIRO: The heads of Google and Twitter also testified at that hearing. These companies are among NPR's financial supporters. And NPR tech correspondent Shannon Bond is here to fill us in on the hearing. Hi, Shannon. SHANNON BOND, BYLINE: Hi, Ari. SHAPIRO: Many members of the committee were there when this pro-Trump mob breached the Capitol back in January. At today's hearing, how much did they blame the tech companies for that? BOND: Well, like we heard from Mike Doyle, they were certainly asking them to answer for their role. But what we heard from the companies, you know, is what Zuckerberg told Doyle. It was not Facebook that attacked the Capitol, he said. It was the rioters spurred on by former President Trump. And, Ari, that distinction between what is shared online and then what people do in real life, that's this core tension between these powerful companies' point of view and their critics, including in government. So today we heard the CEOs - Zuckerberg, as well as Jack Dorsey of Twitter and Sundar Pichai of Google. They really focused on talking up their policies, talking about how much they've cracked down on misinformation, especially during the pandemic and around the election. SHAPIRO: Did they acknowledge any room for improvement, or was it just pure kind of, like, defensiveness and happy talk from the tech companies? BOND: They didn't give a lot of ground. I mean, the one who came closest to acknowledging some kind of responsibility was Jack Dorsey of Twitter. He said, yes, social media did play a role in January 6. But he also said that can't be pinned solely on tech companies. And throughout the day, lawmakers were very frustrated with the answers they were getting. You could hear that frustration here from Democrat Frank Pallone of New Jersey. (SOUNDBITE OF ARCHIVED RECORDING) FRANK PALLONE: You're not bystanders. You're encouraging this stuff. SHAPIRO: So what are lawmakers proposing, Shannon? BOND: Well, there is a bunch of bills that are being introduced. Many are focused on holding the companies more responsible for exactly these - this kind of harm. Today, you know, there were questions. They pushed the CEOs a lot on how their platforms work, about how their business models - you know, these business models of getting people to spend a lot of time online so that these companies can sell ads - how that might actually be rewarding the most inflammatory content because we know that often gets the most engagement, and then how that's contributed to the spread of lies about election fraud, doubt about vaccines. You know, and on the Republican side, interestingly, you know, at other recent hearings with these tech CEOs, we've heard a lot of complaints about anti-conservative bias. They say people like former President Trump have been unfairly muzzled. We heard less of that today. Many Republicans zeroed in on the effects of social media on kids, on their mental health and wellbeing. Here's Cathy McMorris Rodgers of Washington. (SOUNDBITE OF ARCHIVED RECORDING) CATHY MCMORRIS RODGERS: Your platforms are my biggest fear as a parent. BOND: And so some Democrats also mentioned these fears, and I think that might be a sign you will see more bipartisan efforts to take on these companies through new laws. SHAPIRO: Interesting. What are the companies saying specifically about the proposed regulations that lawmakers are talking about? BOND: Well, look, Ari; they know change is coming, and now you're starting to see these companies really trying to get ahead of those changes, shape those changes, especially Facebook. It's been running a lot of ads recently calling for updated rules for the Internet, saying, you know, it's time. Zuckerberg today laid out more of a vision for those new rules. You know, he talked about requiring big platforms to be more transparent, to have systems in place to deal with content that breaks the law. You know, a lot of these things are things Facebook itself is already doing, so that could potentially benefit them. And, you know, Google and Twitter, on the other hand, they've been warning a bit about if these changes are done the wrong way, that could actually backfire. Ultimately, you know, these big companies, like Facebook and Google, they have a lot of money. They have the legal power to comply with regulation, especially if they can shape it. So the question, Ari, is, how might these rules we see getting changed affect everybody else in the tech world, not just the big guys? SHAPIRO: That's NPR's tech correspondent Shannon Bond. Thanks, Shannon. BOND: Thanks, Ari. (SOUNDBITE OF MUSIC)", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-03-25-981242121": {"title": "Alan Turing Honored As The Face Of The U.K.'s New 50-Pound Bank Note : NPR", "url": "https://www.npr.org/2021/03/25/981242121/new-u-k-currency-honors-alan-turing-pioneering-computer-scientist-and-code-break", "author": "No author found", "published_date": "2021-03-25", "content": "", "section": "Europe", "disclaimer": ""}, "2021-03-25-980815611": {"title": "'Howard The Printer' Makes An Impression On TikTok With Mini History Lessons : NPR", "url": "https://www.npr.org/2021/03/25/980815611/howard-the-printer-makes-an-impression-on-tiktok-with-mini-history-lessons", "author": "No author found", "published_date": "2021-03-25", "content": "", "section": "History", "disclaimer": ""}, "2021-03-25-980305760": {"title": "A Cautionary Tale For China's Ambitious Chipmakers : NPR", "url": "https://www.npr.org/2021/03/25/980305760/a-cautionary-tale-for-chinas-ambitious-chipmakers", "author": "No author found", "published_date": "2021-03-25", "content": "", "section": "Asia", "disclaimer": ""}, "2021-03-25-980035707": {"title": "Misleading Facts Fuel COVID-19 Misinformation, Evade Social Media Moderation : NPR", "url": "https://www.npr.org/2021/03/25/980035707/lying-through-truth-misleading-facts-fuel-vaccine-misinformation", "author": "No author found", "published_date": "2021-03-25", "content": "", "section": "Untangling Disinformation", "disclaimer": ""}, "2021-03-25-980510388": {"title": "Facebook, Twitter, Google CEOs Testify Before Congress: 4 Things To Know  : NPR", "url": "https://www.npr.org/2021/03/25/980510388/facebook-twitter-google-ceos-testify-before-congress-4-things-to-know", "author": "No author found", "published_date": "2021-03-25", "content": "", "section": "Untangling Disinformation", "disclaimer": ""}, "2021-03-26-981210663": {"title": "Review: 'Story Of Seasons: Pioneers Of Olive Town' & 'Harvest Moon: One World' : NPR", "url": "https://www.npr.org/2021/03/26/981210663/the-latest-chapters-in-gamings-favorite-farm-story-wither-on-the-vine", "author": "No author found", "published_date": "2021-03-26", "content": "", "section": "Games", "disclaimer": ""}, "2021-03-27-981959930": {"title": "How Animators Are Using Artificial Intelligence For 'The Simpsons' : NPR", "url": "https://www.npr.org/2021/03/27/981959930/how-animators-are-using-artificial-intelligence-for-the-simpsons", "author": "No author found", "published_date": "2021-03-27", "content": "(SOUNDBITE OF SONG, \"THE SIMPSONS THEME\")UNIDENTIFIED SINGERS: (Singing) The Simpsons. MICHEL MARTIN, HOST:  The longest-running cartoon in TV history, \"The Simpsons,\" aired its 700th episode last weekend. It debuted in 1989, and since then, not one character has aged. Even the voice actors have stuck around for decades. But a few weeks ago, \"The Simpsons\" included a voice not heard in years. (SOUNDBITE OF TV SHOW, \"THE SIMPSONS\")UNIDENTIFIED SINGERS: (As Edna Krabappel) Remember, if you can teach one kid one thing, then today will be a success. MARTIN:  You may recognize that voice. It's Bart's teacher, Edna Krabappel, voiced by Marcia Wallace for 25 seasons. But there is a twist. AMIT KATWALA: Now, Marcia Wallace, who's the voice actor who plays Edna Krabappel, died a few years ago. But they wanted to bring her back for a one-off episode, and to do it, they used recordings from previous episodes, which they spliced together. MARTIN: That's Amit Katwala, a senior editor at Wired UK. He recently wrote about how animators are using technology to voice characters. KATWALA: And I was wondering whether they might be able to train an AI to do this kind of thing. Could they, if Dan Castellaneta, who plays Homer, decided to leave the show, replace him with an AI model trained on recordings of his own voice? One of the first things I came across was this YouTube channel called Speaking of AI, which is run by a British guy who's based in Canada called Tim McSmythurs. And he's built a generic model that he's trained on kind of hundreds of hours of data. And then he can tune the model to mimic a particular person's voice,MARTIN: Like, say, a famous actor. McSmythurs has a model of the voice, and he types up a script about good hygiene. (SOUNDBITE OF ARCHIVED RECORDING)COMPUTER-GENERATED VOICE #2: Hi, kids. My name is Adam Driver. And today, we're going to sing a special song. This is the way we wash our hands, wash our hands, wash our hands. KATWALA: So what he's done on YouTube as he's slotted \"Simpsons\" voice characters into famous movies. So there's one scene where he takes a clip from \"Notting Hill,\" and he puts Homer into the Julia Roberts role. (SOUNDBITE OF FILM, \"NOTTING HILL\")HUGH GRANT: (As William Thacker) Everyone in the world knows who you are. My mother has trouble remembering my nameKATWALA: Homer's on the doorstep, begging Hugh Grant to take him back. (SOUNDBITE OF ARCHIVED RECORDING)COMPUTER-GENERATED VOICE #3: (As Homer Simpson) But don't forget, I'm also just a boy standing in front of another boy asking him if this is a donut shop. KATWALA: He also does it the other way round. He takes politicians like Donald Trump or Joe Biden and slots them into scenes from \"The Simpsons. \" So you've got Donald Trump reading something that was originally said by Ralph Wiggum. (SOUNDBITE OF ARCHIVED RECORDING)COMPUTER-GENERATED VOICE #4: (As Ralph Wiggum) Hi, Lisa. Hi, Supernintendo (ph) Chalmers. (SOUNDBITE OF CAT MEOWING)COMPUTER-GENERATED VOICE #3: (As Ralph Wiggum) I'm learning. MARTIN: These manufactured voices are called deepfakes. You may have heard about them in terms of disinformation as a way to deceive people through manipulated images. Now animators can use this technology to voice characters. But don't expect it to replace your favorite characters just yet. There are a bunch of legal issues that come up with technology like this, and Katwala says there are other limits. KATWALA: So I can say something like, this is deepfake Amit. MARTIN: And out comes an eerie but familiar voice. COMPUTER-GENERATED VOICE #5: This is deepfake Amit. You can tell this is not the real me because the intonation is very flat and unemotional. KATWALA: When we speak, we're drawing on, you know, years of experience of how to make our voice change to portray a particular emotion or stress a particular point. And the AI model of Homer doesn't know how to do that because it's only been fed on a very, very small subset of the things that Homer Simpson says. MARTIN: Katwala says that is good news for voice actors. KATWALA: It's much, much easier to just get an actor to do it or even hire a soundalike if Homer leaves. There's, you know, thousands of people that can do a Homer Simpson-esque voice rather than training a deepfake to do it. MARTIN: That was Amit Katwala, senior editor at Wired UK, talking about \"The Simpsons\" and deepfake technology. (SOUNDBITE OF UYAMA HIROTO'S \"81 AUTUMNS\")MARTIN: This is NPR News, and it really is me. (SOUNDBITE OF SONG, \"THE SIMPSONS THEME\") UNIDENTIFIED SINGERS: (Singing) The Simpsons. MICHEL MARTIN, HOST:   The longest-running cartoon in TV history, \"The Simpsons,\" aired its 700th episode last weekend. It debuted in 1989, and since then, not one character has aged. Even the voice actors have stuck around for decades. But a few weeks ago, \"The Simpsons\" included a voice not heard in years. (SOUNDBITE OF TV SHOW, \"THE SIMPSONS\") UNIDENTIFIED SINGERS: (As Edna Krabappel) Remember, if you can teach one kid one thing, then today will be a success. MARTIN:   You may recognize that voice. It's Bart's teacher, Edna Krabappel, voiced by Marcia Wallace for 25 seasons. But there is a twist. AMIT KATWALA: Now, Marcia Wallace, who's the voice actor who plays Edna Krabappel, died a few years ago. But they wanted to bring her back for a one-off episode, and to do it, they used recordings from previous episodes, which they spliced together. MARTIN: That's Amit Katwala, a senior editor at Wired UK. He recently wrote about how animators are using technology to voice characters. KATWALA: And I was wondering whether they might be able to train an AI to do this kind of thing. Could they, if Dan Castellaneta, who plays Homer, decided to leave the show, replace him with an AI model trained on recordings of his own voice? One of the first things I came across was this YouTube channel called Speaking of AI, which is run by a British guy who's based in Canada called Tim McSmythurs. And he's built a generic model that he's trained on kind of hundreds of hours of data. And then he can tune the model to mimic a particular person's voice, MARTIN: Like, say, a famous actor. McSmythurs has a model of the voice, and he types up a script about good hygiene. (SOUNDBITE OF ARCHIVED RECORDING) COMPUTER-GENERATED VOICE #2: Hi, kids. My name is Adam Driver. And today, we're going to sing a special song. This is the way we wash our hands, wash our hands, wash our hands. KATWALA: So what he's done on YouTube as he's slotted \"Simpsons\" voice characters into famous movies. So there's one scene where he takes a clip from \"Notting Hill,\" and he puts Homer into the Julia Roberts role. (SOUNDBITE OF FILM, \"NOTTING HILL\") HUGH GRANT: (As William Thacker) Everyone in the world knows who you are. My mother has trouble remembering my name KATWALA: Homer's on the doorstep, begging Hugh Grant to take him back. (SOUNDBITE OF ARCHIVED RECORDING) COMPUTER-GENERATED VOICE #3: (As Homer Simpson) But don't forget, I'm also just a boy standing in front of another boy asking him if this is a donut shop. KATWALA: He also does it the other way round. He takes politicians like Donald Trump or Joe Biden and slots them into scenes from \"The Simpsons. \" So you've got Donald Trump reading something that was originally said by Ralph Wiggum. (SOUNDBITE OF ARCHIVED RECORDING) COMPUTER-GENERATED VOICE #4: (As Ralph Wiggum) Hi, Lisa. Hi, Supernintendo (ph) Chalmers. (SOUNDBITE OF CAT MEOWING) COMPUTER-GENERATED VOICE #3: (As Ralph Wiggum) I'm learning. MARTIN: These manufactured voices are called deepfakes. You may have heard about them in terms of disinformation as a way to deceive people through manipulated images. Now animators can use this technology to voice characters. But don't expect it to replace your favorite characters just yet. There are a bunch of legal issues that come up with technology like this, and Katwala says there are other limits. KATWALA: So I can say something like, this is deepfake Amit. MARTIN: And out comes an eerie but familiar voice. COMPUTER-GENERATED VOICE #5: This is deepfake Amit. You can tell this is not the real me because the intonation is very flat and unemotional. KATWALA: When we speak, we're drawing on, you know, years of experience of how to make our voice change to portray a particular emotion or stress a particular point. And the AI model of Homer doesn't know how to do that because it's only been fed on a very, very small subset of the things that Homer Simpson says. MARTIN: Katwala says that is good news for voice actors. KATWALA: It's much, much easier to just get an actor to do it or even hire a soundalike if Homer leaves. There's, you know, thousands of people that can do a Homer Simpson-esque voice rather than training a deepfake to do it. MARTIN: That was Amit Katwala, senior editor at Wired UK, talking about \"The Simpsons\" and deepfake technology. (SOUNDBITE OF UYAMA HIROTO'S \"81 AUTUMNS\") MARTIN: This is NPR News, and it really is me.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-03-27-981875147": {"title": "New York Launches Vaccine Status Mobile Phone App : NPR", "url": "https://www.npr.org/2021/03/27/981875147/new-york-launches-vaccine-status-mobile-phone-app", "author": "No author found", "published_date": "2021-03-27", "content": "SCOTT SIMON, HOST:  New York state is launching a new phone app that will allow people to quickly show their coronavirus testing or vaccination status. Officials say the Excelsior Pass will give people quicker access to gatherings, including sports arenas and large weddings, where the state's public health rules are still in effect. NPR's Brian Mann reports. BRIAN MANN, BYLINE: When Governor Andrew Cuomo gave a briefing this week, he talked a lot about reopening businesses and venues, getting the economy going again. But he also gave a warning. (SOUNDBITE OF ARCHIVED RECORDING)ANDREW CUOMO: We have made tremendous progress. But anyone who says it's over, they're wrong. Seventy-one people passed away. CUOMO: There are still thousands of new coronavirus cases confirmed in New York every day and dozens of deaths. The challenge, says Mark Dorr with the New York State Hospitality and Tourism Association, is reopening more places like sports arenas and Broadway theaters when the coronavirus is still lurking. MARK DORR: I think confidence is the biggest dilemma, I guess, to overcome as we head into the busy season - confidence in getting people out to travel. MANN: So New York state partnered with IBM to create a smart device app that includes a scannable barcode similar to the one used in airline boarding passes. They say it's voluntary. It's free to download. It keeps most of your personal information private. Dorr says business venues can check customers' barcodes to find out if they've been vaccinated or tested negative for the coronavirus within the last three days. DORR: The business will be able to really quickly recognize that the proper protocols have been followed in order to have a safe entry into the business. MANN: From the start of the pandemic, smart devices have been used for contact-tracing and public health alerts. But this appears to be the first app in the U. S. that shows this kind of personal coronavirus status, though officials in Hawaii are working on a similar vaccine passport. Melissa Fleischut, who heads the New York State Restaurant Association, doesn't think smaller venues like restaurants and bars are likely to use the app. But she points out many businesses that host larger crowds, including caterers and wedding organizers, are still required to follow strict public health rules. That includes making sure people are vaccinated or have recent negative tests. Until now, she says, checking people's status was super-inefficient. MELISSA FLEISCHUT: Paper, for example, or an Excel spreadsheet or something like that. MANN: She thinks this app will help, and she agrees it might give people a little more confidence when venturing back into venues with really big crowds. FLEISCHUT: You know, if you knew that everybody in that area near you had either tested negative or had received the vaccine, you know, I think you could feel pretty good about going to those events and feeling comfortable even when the numbers got really high like that. MANN: Some large sports and concert arenas, including Madison Square Garden, have already started using the app. New York state's caterers and wedding planners can start using it with their customers April 2. Brian Mann, NPR News. SCOTT SIMON, HOST:   New York state is launching a new phone app that will allow people to quickly show their coronavirus testing or vaccination status. Officials say the Excelsior Pass will give people quicker access to gatherings, including sports arenas and large weddings, where the state's public health rules are still in effect. NPR's Brian Mann reports. BRIAN MANN, BYLINE: When Governor Andrew Cuomo gave a briefing this week, he talked a lot about reopening businesses and venues, getting the economy going again. But he also gave a warning. (SOUNDBITE OF ARCHIVED RECORDING) ANDREW CUOMO: We have made tremendous progress. But anyone who says it's over, they're wrong. Seventy-one people passed away. CUOMO: There are still thousands of new coronavirus cases confirmed in New York every day and dozens of deaths. The challenge, says Mark Dorr with the New York State Hospitality and Tourism Association, is reopening more places like sports arenas and Broadway theaters when the coronavirus is still lurking. MARK DORR: I think confidence is the biggest dilemma, I guess, to overcome as we head into the busy season - confidence in getting people out to travel. MANN: So New York state partnered with IBM to create a smart device app that includes a scannable barcode similar to the one used in airline boarding passes. They say it's voluntary. It's free to download. It keeps most of your personal information private. Dorr says business venues can check customers' barcodes to find out if they've been vaccinated or tested negative for the coronavirus within the last three days. DORR: The business will be able to really quickly recognize that the proper protocols have been followed in order to have a safe entry into the business. MANN: From the start of the pandemic, smart devices have been used for contact-tracing and public health alerts. But this appears to be the first app in the U. S. that shows this kind of personal coronavirus status, though officials in Hawaii are working on a similar vaccine passport. Melissa Fleischut, who heads the New York State Restaurant Association, doesn't think smaller venues like restaurants and bars are likely to use the app. But she points out many businesses that host larger crowds, including caterers and wedding organizers, are still required to follow strict public health rules. That includes making sure people are vaccinated or have recent negative tests. Until now, she says, checking people's status was super-inefficient. MELISSA FLEISCHUT: Paper, for example, or an Excel spreadsheet or something like that. MANN: She thinks this app will help, and she agrees it might give people a little more confidence when venturing back into venues with really big crowds. FLEISCHUT: You know, if you knew that everybody in that area near you had either tested negative or had received the vaccine, you know, I think you could feel pretty good about going to those events and feeling comfortable even when the numbers got really high like that. MANN: Some large sports and concert arenas, including Madison Square Garden, have already started using the app. New York state's caterers and wedding planners can start using it with their customers April 2. Brian Mann, NPR News.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-03-27-981683224": {"title": "Election Lawsuits Are A New Tactic To Fight Disinformation : NPR", "url": "https://www.npr.org/2021/03/27/981683224/election-defamation-lawsuits-open-new-front-in-fight-against-disinformation", "author": "No author found", "published_date": "2021-03-27", "content": "", "section": "Untangling Disinformation", "disclaimer": ""}, "2021-03-29-981573228": {"title": "Amazon Union Vote Count At Alabama Warehouse Begins This Week : NPR", "url": "https://www.npr.org/2021/03/29/981573228/historic-amazon-union-vote-count-begins-this-week-for-alabama-warehouse", "author": "No author found", "published_date": "2021-03-29", "content": "NOEL KING, HOST:  Around 5,800 Amazon employees in Bessemer, Ala. , have now had a chance to vote on whether to unionize. The vote count starts today. If it's a yes, Bessemer would become Amazon's first unionized warehouse in this country, and it could juice the movement for organized labor. Amazon is one of NPR's financial supporters, but we cover them like we cover any other company. With me now, NPR business correspondent Alina Selyukh, who's been following this. Hi, Alina. ALINA SELYUKH, BYLINE: Good morning. KING: When will we know how they voted? SELYUKH: Well, so what's happening today is the tally begins, which is actually giving me a bit of a throwback to the time a few months ago when, you know, the whole country watched a live feed of the Pennsylvania vote count in the presidential election. . . KING: Sure. SELYUKH: . . . Because we're expecting to have this Web stream where federal officials are going to be counting, by hand, the ballots that Amazon workers from Bessemer have been mailing in. And first, they'll have to sort out whether the union or the company wants to challenge each voter's eligibility. So long answer short, this count could take a few days. KING: It is only one warehouse. That said, there's a lot at stake here. SELYUKH: Yes, it's a really big moment, both for Amazon and for the American labor movement. Union membership has been declining for a while now. And this is Amazon. It's a big one, the second-largest private employer in the U. S. Its warehouse workforce seems to balloon every year. For years, Amazon has fought off labor organizing around the country, so unionizing nearly 6,000 employees in this one warehouse could be a catalyst. This has pro-union workers at Bessemer really feeling the pressure. Here's Darryl Richardson, who helped organize the vote. DARRYL RICHARDSON: Very, very nervous. I think - I ain't going to say if - when we win, I believe I'll just drop down to my knees and cry. SELYUKH: Some experts think that even if the union loses by a small margin, it would send a similar message. Union leaders say already the vote by itself has prompted hundreds of new inquiries from other facilities elsewhere. Of course, a big loss for the union would only solidify Amazon's success in evading labor organizing efforts around the U. S. KING: You've been following this story for a while. SELYUKH: Indeed. KING: Do you have a sense of whether they'll vote yes or no? SELYUKH: Not really. For its part, the union points out the fact that more than half of the warehouse workers in Bessemer had signed cards saying they wanted a union shop, you know, when they petitioned for this union election in the first place. But historically, unions have been a tough sell in the Southern states. And Amazon staged a big campaign. It's been touting the pay and benefits that it offers, arguing that the union just wanted workers' dues money. I talked to Bessemer worker LaVonette Stokes who voted against unionizing. LAVONETTE STOKES: Most of the people who are complaining about it are people who are not compliant. It's an unskilled job, easy to attain. There are a gallimaufry of people who never have a issue. SELYUKH: And she says she didn't think the union would give workers anything Amazon doesn't already offer. KING: So what happens once a vote is announced? SELYUKH: Well, first, it will probably get a ton of really high-profile reactions. KING: Sure. SELYUKH: You know, the union push has gotten a ton of attention, including endorsements from celebrities, from politicians, even President Biden. But it will not be the end of the story for the Bessemer warehouse. Whatever the outcome, either Amazon or the Retail, Wholesale and Department Store Union, which is the union vying to represent workers here - one of them would probably pursue a legal challenge to the vote. And then if the vote succeeds, workers likely face a difficult and protracted negotiation over their first collective bargaining contract with Amazon. KING: OK. So either way, it takes time. NPR's Alina Selyukh. Thanks, Alina. SELYUKH: Thank you. NOEL KING, HOST:   Around 5,800 Amazon employees in Bessemer, Ala. , have now had a chance to vote on whether to unionize. The vote count starts today. If it's a yes, Bessemer would become Amazon's first unionized warehouse in this country, and it could juice the movement for organized labor. Amazon is one of NPR's financial supporters, but we cover them like we cover any other company. With me now, NPR business correspondent Alina Selyukh, who's been following this. Hi, Alina. ALINA SELYUKH, BYLINE: Good morning. KING: When will we know how they voted? SELYUKH: Well, so what's happening today is the tally begins, which is actually giving me a bit of a throwback to the time a few months ago when, you know, the whole country watched a live feed of the Pennsylvania vote count in the presidential election. . . KING: Sure. SELYUKH: . . . Because we're expecting to have this Web stream where federal officials are going to be counting, by hand, the ballots that Amazon workers from Bessemer have been mailing in. And first, they'll have to sort out whether the union or the company wants to challenge each voter's eligibility. So long answer short, this count could take a few days. KING: It is only one warehouse. That said, there's a lot at stake here. SELYUKH: Yes, it's a really big moment, both for Amazon and for the American labor movement. Union membership has been declining for a while now. And this is Amazon. It's a big one, the second-largest private employer in the U. S. Its warehouse workforce seems to balloon every year. For years, Amazon has fought off labor organizing around the country, so unionizing nearly 6,000 employees in this one warehouse could be a catalyst. This has pro-union workers at Bessemer really feeling the pressure. Here's Darryl Richardson, who helped organize the vote. DARRYL RICHARDSON: Very, very nervous. I think - I ain't going to say if - when we win, I believe I'll just drop down to my knees and cry. SELYUKH: Some experts think that even if the union loses by a small margin, it would send a similar message. Union leaders say already the vote by itself has prompted hundreds of new inquiries from other facilities elsewhere. Of course, a big loss for the union would only solidify Amazon's success in evading labor organizing efforts around the U. S. KING: You've been following this story for a while. SELYUKH: Indeed. KING: Do you have a sense of whether they'll vote yes or no? SELYUKH: Not really. For its part, the union points out the fact that more than half of the warehouse workers in Bessemer had signed cards saying they wanted a union shop, you know, when they petitioned for this union election in the first place. But historically, unions have been a tough sell in the Southern states. And Amazon staged a big campaign. It's been touting the pay and benefits that it offers, arguing that the union just wanted workers' dues money. I talked to Bessemer worker LaVonette Stokes who voted against unionizing. LAVONETTE STOKES: Most of the people who are complaining about it are people who are not compliant. It's an unskilled job, easy to attain. There are a gallimaufry of people who never have a issue. SELYUKH: And she says she didn't think the union would give workers anything Amazon doesn't already offer. KING: So what happens once a vote is announced? SELYUKH: Well, first, it will probably get a ton of really high-profile reactions. KING: Sure. SELYUKH: You know, the union push has gotten a ton of attention, including endorsements from celebrities, from politicians, even President Biden. But it will not be the end of the story for the Bessemer warehouse. Whatever the outcome, either Amazon or the Retail, Wholesale and Department Store Union, which is the union vying to represent workers here - one of them would probably pursue a legal challenge to the vote. And then if the vote succeeds, workers likely face a difficult and protracted negotiation over their first collective bargaining contract with Amazon. KING: OK. So either way, it takes time. NPR's Alina Selyukh. Thanks, Alina. SELYUKH: Thank you.", "section": "Business", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-03-30-982798460": {"title": "U.K., U.S. Working Closely On Countering 'Almost Gangsterish' Russia, U.K. Envoy Says : NPR", "url": "https://www.npr.org/2021/03/30/982798460/u-k-ambassador-karen-pierce-on-the-u-k-s-foreign-policy-future", "author": "No author found", "published_date": "2021-03-30", "content": "", "section": "World", "disclaimer": ""}, "2021-03-30-982449551": {"title": "Remote Work Is Leading To More Gender And Racial Harassment, Say Tech Workers : NPR", "url": "https://www.npr.org/2021/03/30/982449551/remote-work-is-leading-to-more-gender-and-racial-harassment-say-tech-workers", "author": "No author found", "published_date": "2021-03-30", "content": "", "section": "Technology", "disclaimer": ""}, "2021-03-31-983097569": {"title": "Virtual Reality Office Work Rising Due to Covid Pandemic : The Indicator from Planet Money : NPR", "url": "https://www.npr.org/2021/03/31/983097569/the-virtual-office", "author": "No author found", "published_date": "2021-03-31", "content": "SYLVIE DOUGLIS, BYLINE: NPR. (SOUNDBITE OF DROP ELECTRIC'S \"WAKING UP TO THE FIRE\")CARDIFF GARCIA, HOST:  Hey, everyone. This is THE INDICATOR FROM PLANET MONEY. I'm Cardiff Garcia. STACEY VANEK SMITH, HOST:  And I'm Stacey Vanek Smith. It has been more than a year since we at THE INDICATOR started working from home. GARCIA: Yeah, and it's brought some perks for sure, like wearing sweatpants all day or taking the occasional mid-day nap. SMITH: Interview. It's an interview. GARCIA: Yeah. But also, it's not quite the same as being in the office. SMITH: Yeah. You know, we were talking about this. Like, back when we were at the office, we would just bounce ideas off each other all the time. Like, you know, someone on our team would say, like, hey, did you see this news story? Someone else would jump in with like an economic concept that applied. GARCIA: Yeah. So these ideas would get better as we discussed them, and our shows would get smarter in this kind of amazing organic way. There's a word for this that everyone hates - synergy. SMITH: Yeah. Well, I mean, I - it's true, though, right? Staring at a bunch of little squares on Zoom, it's not the same. I actually - I miss the synergy. GARCIA: So recently we decided to try something - to meet up together in an actual meeting room. SMITH: Someone else is here. There's Cardiff. GARCIA: I'm here. I'm here. I'm here. SMITH: Hi. Woo. GARCIA: And it was a beautiful space, you know, high ceilings, spiral staircase, huge windows, very like mod furniture, a lot of plants. SMITH: A nice room, right? What do you think? ALEXI HOROWITZ-GHAZI, BYLINE: Yeah, I think I have this pillow. I don't know. Looks like an IKEA classic. UNIDENTIFIED PERSON #2, BYLINE: Where are our lower bodies? GARCIA: This was a weird meeting. (LAUGHTER)SMITH: Yes. We should clarify that this room was not in the physical world. We met in a virtual reality world where, by the way, everyone was just a torso, a floating torso. And meeting in a place like this in a virtual reality conference room is a pretty new thing. But the pandemic has just supercharged interest and investment in virtual reality. VR is now worth nearly $16 billion, and that is expected to almost double in just the next five years. And recently, a bunch of VR startups have cropped up that cater to companies and universities. They help people meet up and learn and have meetings in virtual spaces. Bhushan Sethi works for PWC. It's a consulting firm. And they've done a bunch of studies on virtual reality. BHUSHAN SETHI: This will be not just the workplace of the future, but the education of the future. GARCIA: Bhushan is a true believer. He actually organized a meeting in virtual reality. There was a kind of big international-type meeting that would have normally taken months to put together. SETHI: It was incredibly immersive. We had breakouts. We had some fun. We had some yoga in there. We imagined ourselves on. . . SMITH: You did virtual reality yoga? SETHI: We did. We actually led the team through a couple of stretches because it's a long period of time. SMITH: (Laughter). SETHI: It's not as good as the, you know, breaking bread and having a glass of wine in continental Europe, but it's the next best thing. SMITH: We've never done yoga at a meeting once at THE INDICATOR. . . GARCIA: No, certainly not. SMITH: . . . Or, incidentally, broken bread and had a glass of wine in continental Europe. How have we missed these things? GARCIA: Well, I mean, so we thought, let's give this a try - not the yoga thing, I mean the VR meeting thing - so that maybe we can try to get back a little of what we've been missing by working from home. SMITH: Yeah. So I looked around, and I found an app for us that we could all use. They had a little roster of meeting rooms, so I picked the one that I liked the best. I sent out a link to THE INDICATOR team and then also got everyone to order these, like, really cheap VR goggles on Amazon. They're like 10 bucks. You could just stick your phone in to them. And lo and behold, we all showed up to our meeting in virtual reality. GARCIA: Or at least our avatar torsos showed up. SMITH: Our avatar torsos showed up. GARCIA: Yeah. To create an avatar, you upload a picture of yourself, and the app turns it into this animated face. And your mouth even moves a little when you talk. SMITH: Yeah. And we all, like, met in this virtual room and gathered around a virtual little round conference table. GARCIA: We're like the Knights of the Round Table here. HOROWITZ-GHAZI: Oh, wow. Look. We're at our meeting. SMITH: It's great. UNIDENTIFIED PERSON #3, BYLINE: This is great. I'm already sitting in a chair. SMITH: Yeah. I feel like this is a small victory. So we're all here. We're gathered. GARCIA: Oh, Stacey, you declared victory. That was a bad idea. SMITH: I know. I jinxed stuff because very shortly after that, things got really weird. UNIDENTIFIED PERSON #2: Sam just disappeared into the carpet. (SOUNDBITE OF MUSIC)JOLIE MYERS, BYLINE: So, Cardiff, last week, Team Indicator jumped into the world of virtual reality, and we tried to actually do work there. We tried to have an actual meeting run by our editor, Jolie Myers, who was determined to just have a normal, productive meeting. MYERS: OK. I'm going to start this meeting. GARCIA: Oh, no. SMITH: Cardiff just vaporized. It's like rapture or something. UNIDENTIFIED PERSON #2: Wait. Wait. Guys, did I show up? I can't even tell if I'm actually here. MYERS: OK. So I'm going to (unintelligible) the meeting. And those of you that hear things, great. Those of you that don't. . . GARCIA: Such an inauspicious start. SMITH: There's some early roadblocks. GARCIA: So to explain what's happening here, when you're in these meetings, the view is all first-person. Like, you can't see your own avatar. But these avatars presented some challenges. Are you sitting down? Will it let me sit down? I wonder if it'll let me sit down. SMITH: Oh, sorry. I think I just walked through you, Alexi. HOROWITZ-GHAZI: That's OK. That's OK. GARCIA: Oh, my God. It just gave me a close-up of Stacey. Oh, my God. It's freaky. Everybody in speaker view looks like the guy in \"Indiana Jones\" who drank from the wrong chalice and then his face melted off. SMITH: This was a horror show. We spent basically 15 minutes freaking out over how deranged everybody looked and just like howling with laughter. Like, nothing got done. GARCIA: And, I mean, it was funny and delightful. SMITH: Yes. But then things took a turn for the sinister. UNIDENTIFIED PERSON #2: Guys, is Sam OK? GARCIA: Yeah. So out of nowhere, our intern, Sam Cai's avatar was just hanging in the air above us all with his head all the way over to the side. SMITH: It was like demonic. (SOUNDBITE OF MUSIC)SMITH: Why is he hanging in the air like that? HOROWITZ-GHAZI: Yeah. Sam, how are you doing that? SMITH: Did you just turn into a shadow? I think Sam's avatar is possessed. GARCIA: And it went even more downhill from there. UNIDENTIFIED PERSON #2: Jamila's head is falling off her body. HOROWITZ-GHAZI: Yeah. Jamila, how do you keep moving your head back? It's like \"Exorcist\" style. Some freaky, wild stuff going. GARCIA: So weird looking. UNIDENTIFIED PERSON #2: Sam just disappeared into the carpet. GARCIA: And just like that, our orderly 15-minute meeting devolved into a chaotic hellscape. Who's writing things? HOROWITZ-GHAZI: How are you doing that? SMITH: Oh, my God. Who wrote red rum? I did not write that. GARCIA: What's happening? SMITH: Alexi, your hair's turned gray. HOROWITZ-GHAZI: I know. It's so stressful. UNIDENTIFIED PERSON #2: I just took a screenshot of me looking over Stacey's shoulder, and I am certain I'm about to kill her. SMITH: Are we all going to be visited by, like, a curse tonight? GARCIA: Well, I definitely had a stress nightmare about this because it was about as far from an idyllic, productive meeting with yoga breaks or whatever as you could possibly imagine. SMITH: And I brought this up in a pretty muted way with Bhushan Sethi of PWC. I didn't give him the whole, like, demonic picture of everything that had happened. I just told him, you know, the technology was pretty challenging, that we kept getting derailed. GARCIA: And Bhushan responded that technology is always glitchy at first. You just got to hang in there. And he says, better to make your peace with VR now because the old-school way of flying all over the world and booking a fancy hotel for company meetings and business conferences, that has changed forever. SMITH: And Bhushan says, for him and his, like, super-sophisticated yoga break meeting that did not devolve into like a satanic ritual, the VR did achieve what it promised to, which was an immersive experience. He didn't feel, like, the barrier that he typically feels looking at people through a screen. SETHI: Us being able to quickly put ourselves in kind of experiences and kind of immersive experiences together, that builds a connection which you cannot do by a two-dimensional video conference or by a conference call and definitely not by an email - wouldn't give up on it. You know, take it as a learning experience. SMITH: A learning experience. What we did learn was that our 15-minute meeting took 38 minutes. And we were all exhausted and, like, a little traumatized at the end, I would say, Cardiff. GARCIA: (Laughter). SMITH: And in the end, we made the totally unanimous decision to go back to our screens. GARCIA: When we talk after the meeting, not on the platform. UNIDENTIFIED PERSON #2: No. This is horrible. I hate this. GARCIA: Does anybody know how to leave? This episode of THE INDICATOR was produced by Dave Blanchard and fact-checked by Sam Cai. It was edited by Jolie Myers. And THE INDICATOR is a production of NPR. SYLVIE DOUGLIS, BYLINE: NPR. (SOUNDBITE OF DROP ELECTRIC'S \"WAKING UP TO THE FIRE\") CARDIFF GARCIA, HOST:   Hey, everyone. This is THE INDICATOR FROM PLANET MONEY. I'm Cardiff Garcia. STACEY VANEK SMITH, HOST:   And I'm Stacey Vanek Smith. It has been more than a year since we at THE INDICATOR started working from home. GARCIA: Yeah, and it's brought some perks for sure, like wearing sweatpants all day or taking the occasional mid-day nap. SMITH: Interview. It's an interview. GARCIA: Yeah. But also, it's not quite the same as being in the office. SMITH: Yeah. You know, we were talking about this. Like, back when we were at the office, we would just bounce ideas off each other all the time. Like, you know, someone on our team would say, like, hey, did you see this news story? Someone else would jump in with like an economic concept that applied. GARCIA: Yeah. So these ideas would get better as we discussed them, and our shows would get smarter in this kind of amazing organic way. There's a word for this that everyone hates - synergy. SMITH: Yeah. Well, I mean, I - it's true, though, right? Staring at a bunch of little squares on Zoom, it's not the same. I actually - I miss the synergy. GARCIA: So recently we decided to try something - to meet up together in an actual meeting room. SMITH: Someone else is here. There's Cardiff. GARCIA: I'm here. I'm here. I'm here. SMITH: Hi. Woo. GARCIA: And it was a beautiful space, you know, high ceilings, spiral staircase, huge windows, very like mod furniture, a lot of plants. SMITH: A nice room, right? What do you think? ALEXI HOROWITZ-GHAZI, BYLINE: Yeah, I think I have this pillow. I don't know. Looks like an IKEA classic. UNIDENTIFIED PERSON #2, BYLINE: Where are our lower bodies? GARCIA: This was a weird meeting. (LAUGHTER) SMITH: Yes. We should clarify that this room was not in the physical world. We met in a virtual reality world where, by the way, everyone was just a torso, a floating torso. And meeting in a place like this in a virtual reality conference room is a pretty new thing. But the pandemic has just supercharged interest and investment in virtual reality. VR is now worth nearly $16 billion, and that is expected to almost double in just the next five years. And recently, a bunch of VR startups have cropped up that cater to companies and universities. They help people meet up and learn and have meetings in virtual spaces. Bhushan Sethi works for PWC. It's a consulting firm. And they've done a bunch of studies on virtual reality. BHUSHAN SETHI: This will be not just the workplace of the future, but the education of the future. GARCIA: Bhushan is a true believer. He actually organized a meeting in virtual reality. There was a kind of big international-type meeting that would have normally taken months to put together. SETHI: It was incredibly immersive. We had breakouts. We had some fun. We had some yoga in there. We imagined ourselves on. . . SMITH: You did virtual reality yoga? SETHI: We did. We actually led the team through a couple of stretches because it's a long period of time. SMITH: (Laughter). SETHI: It's not as good as the, you know, breaking bread and having a glass of wine in continental Europe, but it's the next best thing. SMITH: We've never done yoga at a meeting once at THE INDICATOR. . . GARCIA: No, certainly not. SMITH: . . . Or, incidentally, broken bread and had a glass of wine in continental Europe. How have we missed these things? GARCIA: Well, I mean, so we thought, let's give this a try - not the yoga thing, I mean the VR meeting thing - so that maybe we can try to get back a little of what we've been missing by working from home. SMITH: Yeah. So I looked around, and I found an app for us that we could all use. They had a little roster of meeting rooms, so I picked the one that I liked the best. I sent out a link to THE INDICATOR team and then also got everyone to order these, like, really cheap VR goggles on Amazon. They're like 10 bucks. You could just stick your phone in to them. And lo and behold, we all showed up to our meeting in virtual reality. GARCIA: Or at least our avatar torsos showed up. SMITH: Our avatar torsos showed up. GARCIA: Yeah. To create an avatar, you upload a picture of yourself, and the app turns it into this animated face. And your mouth even moves a little when you talk. SMITH: Yeah. And we all, like, met in this virtual room and gathered around a virtual little round conference table. GARCIA: We're like the Knights of the Round Table here. HOROWITZ-GHAZI: Oh, wow. Look. We're at our meeting. SMITH: It's great. UNIDENTIFIED PERSON #3, BYLINE: This is great. I'm already sitting in a chair. SMITH: Yeah. I feel like this is a small victory. So we're all here. We're gathered. GARCIA: Oh, Stacey, you declared victory. That was a bad idea. SMITH: I know. I jinxed stuff because very shortly after that, things got really weird. UNIDENTIFIED PERSON #2: Sam just disappeared into the carpet. (SOUNDBITE OF MUSIC) JOLIE MYERS, BYLINE: So, Cardiff, last week, Team Indicator jumped into the world of virtual reality, and we tried to actually do work there. We tried to have an actual meeting run by our editor, Jolie Myers, who was determined to just have a normal, productive meeting. MYERS: OK. I'm going to start this meeting. GARCIA: Oh, no. SMITH: Cardiff just vaporized. It's like rapture or something. UNIDENTIFIED PERSON #2: Wait. Wait. Guys, did I show up? I can't even tell if I'm actually here. MYERS: OK. So I'm going to (unintelligible) the meeting. And those of you that hear things, great. Those of you that don't. . . GARCIA: Such an inauspicious start. SMITH: There's some early roadblocks. GARCIA: So to explain what's happening here, when you're in these meetings, the view is all first-person. Like, you can't see your own avatar. But these avatars presented some challenges. Are you sitting down? Will it let me sit down? I wonder if it'll let me sit down. SMITH: Oh, sorry. I think I just walked through you, Alexi. HOROWITZ-GHAZI: That's OK. That's OK. GARCIA: Oh, my God. It just gave me a close-up of Stacey. Oh, my God. It's freaky. Everybody in speaker view looks like the guy in \"Indiana Jones\" who drank from the wrong chalice and then his face melted off. SMITH: This was a horror show. We spent basically 15 minutes freaking out over how deranged everybody looked and just like howling with laughter. Like, nothing got done. GARCIA: And, I mean, it was funny and delightful. SMITH: Yes. But then things took a turn for the sinister. UNIDENTIFIED PERSON #2: Guys, is Sam OK? GARCIA: Yeah. So out of nowhere, our intern, Sam Cai's avatar was just hanging in the air above us all with his head all the way over to the side. SMITH: It was like demonic. (SOUNDBITE OF MUSIC) SMITH: Why is he hanging in the air like that? HOROWITZ-GHAZI: Yeah. Sam, how are you doing that? SMITH: Did you just turn into a shadow? I think Sam's avatar is possessed. GARCIA: And it went even more downhill from there. UNIDENTIFIED PERSON #2: Jamila's head is falling off her body. HOROWITZ-GHAZI: Yeah. Jamila, how do you keep moving your head back? It's like \"Exorcist\" style. Some freaky, wild stuff going. GARCIA: So weird looking. UNIDENTIFIED PERSON #2: Sam just disappeared into the carpet. GARCIA: And just like that, our orderly 15-minute meeting devolved into a chaotic hellscape. Who's writing things? HOROWITZ-GHAZI: How are you doing that? SMITH: Oh, my God. Who wrote red rum? I did not write that. GARCIA: What's happening? SMITH: Alexi, your hair's turned gray. HOROWITZ-GHAZI: I know. It's so stressful. UNIDENTIFIED PERSON #2: I just took a screenshot of me looking over Stacey's shoulder, and I am certain I'm about to kill her. SMITH: Are we all going to be visited by, like, a curse tonight? GARCIA: Well, I definitely had a stress nightmare about this because it was about as far from an idyllic, productive meeting with yoga breaks or whatever as you could possibly imagine. SMITH: And I brought this up in a pretty muted way with Bhushan Sethi of PWC. I didn't give him the whole, like, demonic picture of everything that had happened. I just told him, you know, the technology was pretty challenging, that we kept getting derailed. GARCIA: And Bhushan responded that technology is always glitchy at first. You just got to hang in there. And he says, better to make your peace with VR now because the old-school way of flying all over the world and booking a fancy hotel for company meetings and business conferences, that has changed forever. SMITH: And Bhushan says, for him and his, like, super-sophisticated yoga break meeting that did not devolve into like a satanic ritual, the VR did achieve what it promised to, which was an immersive experience. He didn't feel, like, the barrier that he typically feels looking at people through a screen. SETHI: Us being able to quickly put ourselves in kind of experiences and kind of immersive experiences together, that builds a connection which you cannot do by a two-dimensional video conference or by a conference call and definitely not by an email - wouldn't give up on it. You know, take it as a learning experience. SMITH: A learning experience. What we did learn was that our 15-minute meeting took 38 minutes. And we were all exhausted and, like, a little traumatized at the end, I would say, Cardiff. GARCIA: (Laughter). SMITH: And in the end, we made the totally unanimous decision to go back to our screens. GARCIA: When we talk after the meeting, not on the platform. UNIDENTIFIED PERSON #2: No. This is horrible. I hate this. GARCIA: Does anybody know how to leave? This episode of THE INDICATOR was produced by Dave Blanchard and fact-checked by Sam Cai. It was edited by Jolie Myers. And THE INDICATOR is a production of NPR.", "section": "The Virtual Office", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-03-31-983157378": {"title": "Group-Chatting Platform Discord Might Change Social Media With Its Business Model : NPR", "url": "https://www.npr.org/2021/03/31/983157378/group-chatting-platform-discord-might-change-social-media-with-their-business-mo", "author": "No author found", "published_date": "2021-03-31", "content": "AILSA CHANG, HOST:  Microsoft is reportedly in talks to acquire the social media platform Discord for $10 billion. Discord started as a gaming community, but now it's much more than that. It's a place for conferences, concerts, book clubs and homework help. NPR's Bobby Allyn reports. BOBBY ALLYN, BYLINE: Max Roquettes (ph) is an 18-year-old in the Chicago area who spent much of the last year hanging out on Discord. It started as a place to be with friends while playing video games. You can talk over text, audio or video. MAX ROQUETTES: You can see when they're typing. It's a live conversation. It's really like a mix of, like, Reddit and a group chat. ALLYN: And like Reddit, people on Discord chat under anonymous usernames, and many use anime characters and animal memes as their avatars. Some of the most popular communities are what you might expect - gaming, tech topics, cryptocurrency - but Roquettes says increasingly it doesn't just feel like a bubble for nerdy people who spend too much time on the Internet. ROQUETTES: With the pandemic, a lot of my non-techy (ph) friends have kind of come on to Discord recently just to get help with their homework and interact with, like, new communities and, honestly, just because they have more time spent alone at home. ALLYN: Roquettes, who is in high school, knows about homework help on Discord because he started a community that connects tutors with students. It's grown to nearly 7,000 people in recent months. He even uses it himself when his homework assignments stump him. ROQUETTES: Having Discord for learning gives, like, another resource for me to kind of reinforce what my teachers are showing me. ALLYN: In other homework communities, people stream live videos of themselves silently completing their assignments. In an interview with NPR, Discord CEO Jason Citron says he's seen it all on the platform. The social network has doubled its size in the pandemic to nearly 150 million users. JASON CITRON: Our growth last year was pretty wild. ALLYN: Karaoke, sneaker trading, Wall Street analysis - it's all going down on Discord. Citron says small private chats of fewer than 30 users is the most common way people are using it. CITRON: So it's like friends of friends. You can almost think of it like an online potluck where you know some of the people but not all the people. ALLYN: It's an intimate space where people don't worry about being snooped on. That's what has really drawn people to Discord. Its business model is almost like the anti-Facebook. S SHYAM SUNDAR: But what is different about Discord is it doesn't track us or sell us to advertisers. ALLYN: S. Shyam Sundar studies social media at Penn State University. Discord makes money through subscriptions for perks like better streaming quality and sillier emojis. Sundar says building a social network free of ads is tapping into deep worries right now over tech companies knowing so much about our lives. SUNDAR: They've reached a kind of a tipping point in terms of our tolerance for advertising, even though it's relevant and even though it's tailored for us. ALLYN: Just ask 18-year-old Discord user Janine Guzman (ph). He prefers Discord over other social media, specifically because what he says and does on the site is not being data mined by advertisers. JANINE GUZMAN: I think that's really important that you don't want to, you know, target them with ads that will sucker them into buying something to make these companies that you're selling their information to happy. ALLYN: Like on every corner of the Internet, chats on Discord can turn nasty. Discord says last year, it had to ban more than 250,000 users for things like harassment. Citron, the Discord CEO, says it has community guidelines against violent threats and extremism. CITRON: If we discover that people are doing this based around a topic that violates our guidelines, we shut it down. ALLYN: But most of the policing on the platform happens by volunteer moderators who set their own norms. Bobby Allyn, NPR News, San Francisco. AILSA CHANG, HOST:   Microsoft is reportedly in talks to acquire the social media platform Discord for $10 billion. Discord started as a gaming community, but now it's much more than that. It's a place for conferences, concerts, book clubs and homework help. NPR's Bobby Allyn reports. BOBBY ALLYN, BYLINE: Max Roquettes (ph) is an 18-year-old in the Chicago area who spent much of the last year hanging out on Discord. It started as a place to be with friends while playing video games. You can talk over text, audio or video. MAX ROQUETTES: You can see when they're typing. It's a live conversation. It's really like a mix of, like, Reddit and a group chat. ALLYN: And like Reddit, people on Discord chat under anonymous usernames, and many use anime characters and animal memes as their avatars. Some of the most popular communities are what you might expect - gaming, tech topics, cryptocurrency - but Roquettes says increasingly it doesn't just feel like a bubble for nerdy people who spend too much time on the Internet. ROQUETTES: With the pandemic, a lot of my non-techy (ph) friends have kind of come on to Discord recently just to get help with their homework and interact with, like, new communities and, honestly, just because they have more time spent alone at home. ALLYN: Roquettes, who is in high school, knows about homework help on Discord because he started a community that connects tutors with students. It's grown to nearly 7,000 people in recent months. He even uses it himself when his homework assignments stump him. ROQUETTES: Having Discord for learning gives, like, another resource for me to kind of reinforce what my teachers are showing me. ALLYN: In other homework communities, people stream live videos of themselves silently completing their assignments. In an interview with NPR, Discord CEO Jason Citron says he's seen it all on the platform. The social network has doubled its size in the pandemic to nearly 150 million users. JASON CITRON: Our growth last year was pretty wild. ALLYN: Karaoke, sneaker trading, Wall Street analysis - it's all going down on Discord. Citron says small private chats of fewer than 30 users is the most common way people are using it. CITRON: So it's like friends of friends. You can almost think of it like an online potluck where you know some of the people but not all the people. ALLYN: It's an intimate space where people don't worry about being snooped on. That's what has really drawn people to Discord. Its business model is almost like the anti-Facebook. S SHYAM SUNDAR: But what is different about Discord is it doesn't track us or sell us to advertisers. ALLYN: S. Shyam Sundar studies social media at Penn State University. Discord makes money through subscriptions for perks like better streaming quality and sillier emojis. Sundar says building a social network free of ads is tapping into deep worries right now over tech companies knowing so much about our lives. SUNDAR: They've reached a kind of a tipping point in terms of our tolerance for advertising, even though it's relevant and even though it's tailored for us. ALLYN: Just ask 18-year-old Discord user Janine Guzman (ph). He prefers Discord over other social media, specifically because what he says and does on the site is not being data mined by advertisers. JANINE GUZMAN: I think that's really important that you don't want to, you know, target them with ads that will sucker them into buying something to make these companies that you're selling their information to happy. ALLYN: Like on every corner of the Internet, chats on Discord can turn nasty. Discord says last year, it had to ban more than 250,000 users for things like harassment. Citron, the Discord CEO, says it has community guidelines against violent threats and extremism. CITRON: If we discover that people are doing this based around a topic that violates our guidelines, we shut it down. ALLYN: But most of the policing on the platform happens by volunteer moderators who set their own norms. Bobby Allyn, NPR News, San Francisco.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-03-31-982750146": {"title": "'Fulfillment' Author Alec MacGillis On The Pitfalls Of An Amazon-Driven Economy : NPR", "url": "https://www.npr.org/2021/03/31/982750146/journalist-investigates-amazon-warehouse-life-and-the-pitfalls-of-one-click-amer", "author": "No author found", "published_date": "2021-03-31", "content": "DAVE DAVIES, HOST:  This is FRESH AIR. I'm Dave Davies, in for Terry Gross, who's off this week. Ballots are being counted this week in what could be a watershed election in Bessemer, Ala. , but it's not for a political office. The vote will determine whether nearly 6,000 employees of the Amazon warehouse in Bessemer will be represented by a union, something Amazon has forcefully resisted in its workplaces across the country. Our guest today, veteran reporter Alec MacGillis, has a new book which explores Amazon's impact on American life. But it isn't just about Amazon. MacGillis looks at the growing disparities in wealth and prosperity, not just among American households, but among the regions where Americans live, places that are technology hubs, mainly on the east and west coasts, are seeing growth and jobs and income that spawns soaring housing prices and plenty of high-end restaurants while other regions stagnate, leaving once-prosperous families struggling, alienated and angry. We should note that Amazon is a financial supporter of NPR. Alec MacGillis is a senior reporter for ProPublica and the recipient of a George Polk Award, among other honors. He worked previously at the Washington Post, The Baltimore Sun and The New Republic. He was last on FRESH AIR to talk about his book \"The Cynic,\" a biography of Senator Mitch McConnell. The title of his new book borrows the term Amazon uses for its warehouses - fulfillment centers. The book is \"Fulfillment: Winning And Losing In One-Click America. \" Alec MacGillis joins us from his home in Baltimore. Alec MacGillis, welcome back to FRESH AIR. Let's start for a moment talking about this union vote at the Amazon warehouse in Bessemer, Ala. It's gotten a lot of attention - you know, a video message from President Biden. Why is it such a big deal? ALEC MACGILLIS: The stakes are just enormous here. I mean, this is really the first time that any union has gotten this far in trying to organize an Amazon warehouse. No warehouse has ever gotten to hold a full vote like this. And if you step back a little bit, I mean, this really is - this could help decide the question of what work is going to look like, what life is going to look like for the working class in America in years to come. The Amazon warehouses have spread so much in the country, have become so huge, so ubiquitous, especially over this past year, when we all started buying so much more online that working in an Amazon warehouse has really kind of become the - a sort of mass labor option for Americans the way that going to work in the factory or at the mall used to be. Now, if you're sort of looking for work in a given place, you can go to the Amazon warehouse and get a job there. But those jobs are really difficult, really challenging with incredibly high pressure, high demand expectations inside these warehouses. And they're paid not that much. DAVIES: Right. And we should note that this vote takes place in Alabama, which is not a union-friendly state. And Amazon says it pays $15 an hour, which is, I think, twice Alabama's minimum wage. There are health benefits. And yet this effort has managed to get some real momentum. Just help us understand why you think. MACGILLIS: It's for a couple of reasons. One is that when we talk about the wage, it's important to think about what we're comparing it to. It's true that it's twice the minimum wage in Alabama. And it's more than one might make that, say, a fast-food job. But it's also less than what many other warehouse jobs have paid in the past, warehouse jobs that tend to be more kind of stable, longer tenure kind of warehouse jobs. You know, working at the local, you know, beer warehouse or mattress warehouse is something that a lot of places would actually still pay more than the Amazon job does. The Amazon job also does pay quite a bit less than the manufacturing jobs of yore that sustained so much of the American working class, working middle class, despite the fact that the jobs in these warehouses are often nearly as strenuous or physically taxing as those manufacturing jobs were. The jobs in these warehouses are just incredibly physically strenuous often, very repetitive, very isolating. They're hard jobs to do, which is one reason why these warehouses have such an enormous turnover. DAVIES: Tell us a bit about the conditions of working in the Amazon warehouses. MACGILLIS: It is such demanding work. And it's not only demanding, but it's incredibly repetitive. You know, I think a lot of us kind of hoped that as work got more automated in warehouses like this and you got more and more robots into there, that it would kind of free up people to do more sort of autonomous, kind of fulfilling kind of work. In fact, the opposite has happened. Bringing the robots in has actually made the work more repetitive and more essentially robotic. One main example of this is that you used to have to - the pickers - one of the main jobs in the warehouse are the pickers. And they used to have to roam the corridors looking for items. So you'd have to go up and down looking for X or Y item on your scanner. And there's a lot of walking involved in that, but there's also a little bit of autonomy. You were out there on your own looking for things. Now, most warehouses, the robots bring the items to you. They're these - they have these tall stacks of shelves on them. The robots are like these little ottomans sort of that have these tall stacks of shelves on them. They zoom around, and they bring these - a robot will zoom a bunch of shelves over to you so that you can take out a given item that you need to fulfill an order. And so just standing there all day, just pulling the items out of the shelves as they come to you in the exact same spot in. And essentially, your work has not yet been replaced by robot only because they're having a hard time teaching robots how to grab things. That's one of the tougher things that robots do - to grab things at different shapes and sizes. So much of the work at the warehouse has now become even more kind of rudimentary and essentially robotic-like. And it's also just so isolating. The work is so - that isolating quality of the work has gotten even worse during the pandemic because there's been an effort to separate people out more on the floor, so they don't give each other the virus. So work that used to be done maybe by two or three people in a given part of the floor is now done by just one person, which not only makes the jobs tougher, but also makes them more isolating. The loss of community in these in these jobs is, you know, is one of the big parts of what's changed, the fact that you used to know all the people you worked with. You were maybe related to some of them. After you left work at the steel mill on Sparrows Point, you would often, of course, roll out of your shift and go to the bar, go to the diner, whatever it might be with your - the people you worked with. Now you go and you do your shift, your 10-hour shift. It's very grueling, repetitive, demanding. And then you get the heck out of there. A former mill worker who lives nearby says that you can just see every shift change as people come screaming out of the warehouse is now driving at such high speeds that they've had to put speed bumps in because people are just desperate to get out of there. DAVIES: There have been other organizing attempts at Amazon warehouses, and the company has resisted them. There have been some National Labor Relations Board complaints about deaths. There was a settlement in which the company agreed to post certain messages in one of its plants. Has the company been more constrained in its efforts to fight the union here in Bessemer? MACGILLIS: They may have been somewhat more constrained because there was so much scrutiny on this particular election. They know that there are a lot of eyes on them. But they've still been quite aggressive in trying to head off the union. Just constant messages, you know, anti-union messages coming to the workers. They've, you know, as usual, hired firms - law firms that specialize in fending off unions. There's just been a very strong sense of just how displeased they would be if workers were to vote to organize to the point where there's some concern that Amazon might actually shut down this entire warehouse if there were, in fact, a vote to organize. So, you know, they've been very, very aggressive while being somewhat more aware of just the fact that the eyes of the country are on them in this case. DAVIES: We'll see what happens. We should note that if the union wins this vote and they are the recognized bargaining agent for the factory, that doesn't mean they have a contract. Negotiating a contract is the next step, and that's a big one, right? MACGILLIS: It is. And it's also worth noting that because Alabama is a so-called right-to-work state, that even if the union were to win this election and if there were then, you know, successful contract negotiations, workers would still have the right to opt out of paying dues for this union since the right-to-work states give workers that choice. DAVIES: All right. Let's take a break here. I'm going to reintroduce you. We are speaking with Alec MacGillis. He is a senior reporter for ProPublica. His new book is \"Fulfillment: Winning And Losing in One-Click America. \" We'll be back to talk more in just a moment. This is FRESH AIR. (SOUNDBITE OF ULTRALUST'S \"MISSING YOU\")DAVIES: This is FRESH AIR, and we're speaking with ProPublica senior reporter Alec MacGillis. He has a new book about Amazon and the impact of giant tech companies on the growing inequality and wealth and prosperity among regions in the United States. The book is \"Fulfillment: Winning And Losing In One-Click America. \"You write that, you know, if you go back a few decades, that the cities that had among the highest median incomes included places like Cleveland and Detroit. And it's very different now. Well, first of all, let's just take some of the areas that are really getting the lion's share of growth like Seattle, like San Francisco. Part of that is the tech industry. What is it about tech companies and their needs that tend to cause many of them to cluster in a particular location, even competitors? Why do they end up ganging up in places like Seattle and the San Francisco area? MACGILLIS: One is the natural tendency of the tech economy to agglomerate. That's sort of the fancy word for it, that with tech, you want to be around the other people who are innovating and coming up with advances. It kind of harkens back to the role that cities have played throughout history, where they've become fonts of innovation, you know, Renaissance Florence or Glasgow in the 19th century, when you have people together who are bouncing ideas off each other, coming up with innovations in proximity with one another and also, of course, in proximity with capital, with the venture capitalists who can fund their ideas and help launch their companies. It helps to be in the same place to make that pitch at the cocktail party or in the elevator. This differs from the way that the manufacturing economy used to work, where once you came up with an advance like, say, the steel-making process that fueled the Industrial Revolution, the Bessemer steel-making process, once you came up with something like that, you could take that process and set up a factory or plant anywhere where you had the basic manpower and natural resources and transportation to get your product to market so that you could just sort of go out around the country and set up a steel mill anywhere where it made sense. With tech, we instead see this kind of agglomeration where it's all about the human capital. So once you come up with a big software innovation - say the cost of producing that thing, whatever it might be, is negligible - all the value lies in that initial innovation. It's all about getting that human capital together to make those advances. And so you have that agglomerating effect in a handful of winner-take-all cities. DAVIES: So as you were writing about these great disparities in the United States among regions and tech companies' role in it, you thought Amazon would be a good lens for examining all this. Let's just start with, how big was Amazon before the pandemic? How big is it now? MACGILLIS: I think it's really kind of hard for us to even comprehend just how big it's gotten. It was huge already before the pandemic, with several hundred thousand workers around the country, more than a hundred fulfillment centers as they call their primary warehouses, about, you know, 40% of the e-commerce market in the country was controlled by Amazon, just a huge share of it. The company, of course, has also been growing incredibly rapidly in a whole other realm, namely the so-called cloud, the world of online tech infrastructure that other companies rent - essentially rent from Amazon in all these data centers that have also sprung up around the country. That's a whole other part of Amazon that's been incredibly lucrative for them. So they were already very large before the pandemic. But what has happened in this past year is really kind of hard to grasp. In the span of just a single year, they hired more than 400,000 additional employees. And that does not include all the delivery drivers that we see all around our cities that are actually not technically employed by Amazon, even though they wear Amazon jerseys and drive Amazon vans. The company has added roughly 50% more warehouse space in just the past year. Its sales have gone up about 40% year over year. Its stock price went up more than 80%. Jeff Bezos' personal wealth went up about $58 billion over the past year. Perhaps because we're right in the middle of it, we can't really grasp just how much how it's gotten. We may be averting our eyes from the scale of the growth, partly because we all feel somewhat complicit in it. The fact is that the company grew so much over the past year because Americans, in much greater numbers than before, really embraced the sort of one-click approach to our daily life. And now we just see it. We see it everywhere around us. I mean, you see the vans just coming up and down your streets constantly. If you're out on the highway, the number of, you know - on tractor trailers is just stunning and almost kind of eerie when you start to count them over just a short stretch of highway. It's just an incredible growth in reach and in size and penetration in our economy and in our daily life. DAVIES: Right. Now, of course, Amazon has been building, you know, scores of new warehouses and distribution centers, many of them in regions where, you know, good-paying manufacturing jobs had disappeared, you know, due to competition and automation. So when the company considers where to locate one of its facilities which will create a lot of jobs, they can bargain with the host community for financial incentives. There's nothing new about this. Companies have been doing this for decades. Does Amazon play the game differently from other firms? MACGILLIS: Amazon is especially aggressive at this game. I mean, one of the things that really just astonished me was what I found in all my reporting and digging into these communications between the towns and cities and the company - I did a lot of public information requests and got a lot of the emails that went back and forth between them - and just to see the aggressiveness on Amazon's part, the obsequiousness on the part of the local officials who are willing to offer these tax subsidies and incentives and also the pledges of secrecy, that was one of the key things. Amazon is especially insistent on secrecy to the point of even giving a lot of its projects code names so that when they go into a given town, a lot of people won't even know who the company is that's trying to build the data center on the edge of town. It'll have some kind of code name that does not include the name Amazon. DAVIES: Let me just explore that for a moment. When you say secrecy, I mean, a lot of these - in some cases, they're - you know, a government subsidy is a public contract. And there are rules of transparency. There are right to know laws that allow citizens and journalists to get information. What kind of secrecy can the company impose that affects that? MACGILLIS: The company can impose or has managed to impose requirements that local governments not give up the identity of the company seeking to build this data center warehouse until the last possible moment. They also urged local officials not to take questions from the press. DAVIES: Right. Right. Now, of course, we're dealing with often local officials who are desperate to develop some economic growth for their citizens who are sorely in need of it. When a deal is done, eventually the public subsidies do become public. What kind of deals does Amazon get? And what's its impact on those communities? MACGILLIS: Typically, it's some form of a tax subsidy where the company will not have to pay all the taxes that would normally be due both on the property itself of the warehouse or the data center or payroll taxes on the workers that will be employed at them; so essentially just a great reduction in its tax bill in the community where it's setting up shop. And the effect of this is, of course, to erode the local tax base and to greatly reduce the amount of money that's coming into local coffers, to support local services, to support the roads and the police and fire and schools. And one reason this is a special problem is that Amazon, when it comes into a community, of course, brings much greater demands for public services. There's all the - just the wear and tear on the roads that come with the incredible increased traffic of cars and trucks, delivery trucks. There are the frequent calls for emergency assistance at the warehouses. The Amazon warehouses tend to have their own in-house medical teams that are called AmCare, but they're not always on duty or they can't sometimes handle the severity of a given case, including some of the fatal accidents that I wrote about in the book. And so you have police and fire and EMS in the local community having to respond to the warehouses for lots of calls when Amazon is itself not supporting those services through the tax dollars that it has essentially been able to avoid paying. DAVIES: Did you find communities that regretted making these deals? MACGILLIS: They - absolutely. They see it as very much of a mixed bag. But in a lot of cases, they feel like they have no choice. You have communities that have been just really hollowed out by the loss of manufacturing jobs. Places that I focus on in the book, you know, in Ohio, especially southwest Ohio, that it was just crushed by the loss of auto manufacturing jobs and other manufacturing jobs in the first couple of decades - the last couple decades or places like Baltimore, another big focus in the book, where you had the largest steel mill in the world, 30,000 jobs that completely vanished in the last two decades and left this entire peninsula outside Baltimore just wiped clean of the massive employment base that used to be on offer there and left local officials just desperate to get anything in there. And so there they were a few years ago handing out subsidies to bring in an Amazon warehouse where jobs were then paying $13 or $14 an hour when at that very same location, you had a steel mill where jobs were paying $35 more an hour not so long ago. DAVIES: We need to take another break here. Let me introduce you. We are speaking with Alec MacGillis. He is a senior reporter for ProPublica. His new book is \"Fulfillment: Winning And Losing In One-Click America. \" He'll be back to talk more after this short break. I'm Dave Davies, and this is FRESH AIR. (SOUNDBITE OF BRUCE HORNSBY'S \"BACKHAND\")DAVIES: This is FRESH AIR. I'm Dave Davies, in for Terry Gross, who's off this week. We're speaking with ProPublica senior reporter Alec MacGillis. He has a new book about Amazon and the impact of giant tech companies on the growing inequality IN wealth and prosperity among metropolitan regions in the United States. The book is \"Fulfillment: Winning And Losing In One-Click America. \"Amazon has obviously had an impact on brick-and-mortar businesses that have to compete with online shopping. And this is not just Amazon. This is a phenomenon that we're seeing around the country where department stores and malls have closed. But you look at another aspect of this that was really interesting. Some companies like, you know, business supplies companies, office supplies companies, in El Paso, they were trying to supply their products to the local school districts and local governments and had to deal with competition from Amazon. What did you discover? This is interesting. MACGILLIS: This is such a big part of Amazon's massive growth in recent years. And I think a lot of people probably aren't aware of this, that it used to be that Amazon mostly, you know, sold goods on the website that it had purchased wholesale from the manufacturer and then sold them on their site just the way that the company would sell goods in a store. But more and more of Amazon's - the goods that are available on the site and the company's profits come from, quote, what they call \"third-party sellers. \" So these are companies that have goods that they want to sell. And instead of just setting up their storefront wherever they might be or selling their items online directly through e-commerce, they now put them on the Amazon website, what's called the marketplace. You sell your goods on the marketplace and it's good for you as a third-party seller in the sense that you have this enormous customer base that now goes to Amazon, all these people who go to Amazon to find whatever they want to buy. And so you want to be in that marketplace. But the problem with that approach for a third-party seller is that Amazon extracts a very large cut of its own and, you know, basic commission and advertising fees and the fees for fulfilling the order and holding the item in the warehouse, all sorts of costs that can get up close to 25%, 30% in some cases. But more and more, a seller feels like they have no real option but to go to the marketplace because that's where everything now is happening. DAVIES: And you describe a fascinating moment where one of these businesses is dealing with the fact that - I believe it was the school district that has, you know, talked to Amazon and they're going to offer this terrific program where you'll get Amazon products and they'll offer third - you know, other companies' products on their website. And then one of these local companies did some research about prices and about products and went to talk to the school district and said there are some things you should know. Tell us about that. MACGILLIS: Yeah. So he was this very charismatic, kind of feisty office supply company owner called Sandy Grodin (ph). And while he was getting this sort of pressuring call from some very young Amazon salespeople urging him to come to the marketplace - you know, basically you better do this or else because everyone's doing it and this is where the world is heading - while he was actually on the phone with them, he had one of his employees check the prices of some basic office supply products on Amazon. And he was stunned to see just how low the price was, a price that he would never be able to make any money from. And he looked into it and discovered that, in fact, that product was a counterfeit product. This is a big problem on Amazon. A lot of products are that are offered at seemingly, you know, bargain prices are, in fact, counterfeits. DAVIES: And it's a brand name. It presents itself to be a certain brand name, right? And it isn't. MACGILLIS: It isn't. And what you're going to get in the mail, if you get it at all, is not what you were - what you thought you had bought. DAVIES: Did Amazon say anything about the counterfeit products? MACGILLIS: Amazon has acknowledged for a while now that this is a problem and that they are, you know, trying to deal with the counterfeit problem. But it just remains and it's become a huge issue for the website, just the growth of counterfeit products and also all the tricks that various third-party sellers use to try to hurt each other, in a sense. There's not only the sale of counterfeit products on the site, but then there's also the false claims lodged against other companies for having offered shoddy goods or otherwise broken the rules that then gets them kicked off of the website. It's just a real - it can be a real nightmare for a lot of companies trying to sell through Amazon, but they feel like they have no choice. And it's now - that now makes up a - the vast majority of Amazon sales on the website are from third-party sellers, not from the company itself. And it's one reason that the company is doing so well because they get a much larger cut of those third-party sales than they would of their own kind of direct selling of goods on the website. DAVIES: Wow. So you have so many players that those who choose to exploit the rules can, you know, use Amazon's own rules, file complaints, create problems and chaos. MACGILLIS: Right. It's a real morass. DAVIES: You know, when Amazon has all of these third-party suppliers on their website and they can sell their goods, it gathers an enormous amount of information about consumer preferences for those products. And there have been accusations - and this was explored in one congressional hearing that you wrote about - accusations that Amazon can use that information to then tweak its own products and get a competitive edge over some of the more successful third-party suppliers. What have we learned about this? MACGILLIS: Yes, this is one of the main complaints against Amazon and actually one of the main drivers of discussions in Washington now about somehow trying to break up the company's hold on so much of our economy. But what's been happening is that the company is able to collect so much data about what kind of products are doing well. And it then in many cases - and this is - there's no real dispute about this - it has then managed to come up with products of its own where it's actually selling products under its own labels. So it'll go out and get some manufacturer to make a given product that strongly resembles the one that was doing well on the site from some other seller and sell it under one of its own private label names. Amazon says this is hardly any different than retail companies that for years now have offered their goods under their own labels. You go into the grocery store and you see, you know, all manner of goods that that grocery store or other retailers selling under their own label. The difference is that - is the data that Amazon has been able to collect and the way it's been able to use the data it's collecting on sales on the site to inform its own decisions to go after a particular product. And there's just been all sorts of examples of it being able to essentially just knock out a product that was doing well on the site and then sell it under its own name. DAVIES: We are speaking with Alec MacGillis. He's a senior reporter for ProPublica. His new book is \"Fulfillment: Winning And Losing In One-Click America. \" We will continue our conversation in just a moment. This is FRESH AIR. (SOUNDBITE OF MUSIC)DAVIES: This is FRESH AIR. We're speaking with ProPublica senior reporter Alec MacGillis, whose book is about the impact of Amazon and giant tech companies on the growing inequality of wealth and prosperity in different regions of the country. It's called \"Fulfillment: Winning And Losing In One-Click America. \" When we left off, MacGillis was talking about reporting that Amazon uses the data it collects from the sales of products from other companies on its website to create similar products which Amazon can then sell under its own label. Critics say this data collection gives Amazon a huge competitive edge. You know, competition is a part of capitalism. It's a part of sales. And it benefits consumers if the competition is fair, right? I mean, but if somebody has the power to knock somebody else out and then raise prices, that's considered anti-competitive. And there are antitrust laws that deal with this kind of thing. Have Congress or regulators shown any interest in dealing with this in the case of Amazon? MACGILLIS: This is the big question that's before us now in Washington. For decades now, we've allowed some of these companies to get so big and so powerful because we've taken a very lax approach to antitrust enforcement in this country. Back in the early 20th century, we worried a lot about monopoly. And there were all these efforts to rein in and break up various big companies. As the 20th century went on, there was an adoption of a much softer approach to antitrust where the basic argument was there's nothing to worry about as long as prices remain low. As long as the consumer is still paying low prices, it's OK if a company gets really big or if a company controls a huge share of a given market. It was called the consumer welfare test. That was the main test for whether we should go after a monopoly. And so, you know, you could look at a company like Amazon, where there all these goods for sale at seemingly low prices and say, well, what's the problem with having a company that's so incredibly powerful and dominant if we, the American consumers, can still buy all sorts of stuff fairly cheap? And it's only been in recent years that a group of people of sort of thinkers have now come to identify the problem with this kind of approach, that there's all sorts of distorting effects that a company can have on the market and anti-competitive effects that it can have, even if it's seemingly keeping prices low for the moment. And now we're heading into this moment in Washington where there's going to be a very interesting fight over whether we're going to try to do something about this. DAVIES: Yeah. We have a new president. Are there any signs that he's going to take a different approach? I mean, there are government regulators that affect all this - right? - the Federal Trade Commission and others. What are you seeing? MACGILLIS: There are signs that we're actually going to - that we could actually have a new approach here. The Biden administration has brought in some very high-profile people who have been outspoken opponents of this softer approach to antitrust. One of them is a woman by the name of Lina Khan, who as a Yale law student not long ago wrote a really kind of groundbreaking piece explaining how Amazon was, in fact, having a distorting monopoly-like effect on the economy, even if it was seemingly still keeping prices low. The Biden administration has appointed her to the Federal Trade Commission and brought another very outspoken critic of the tech giants by the name of Tim Wu into the White House as an adviser. And on top of that, we have lots of people in Congress who actually have been - Democrats in Congress who've been getting quite aggressive on this front and even some signs that Republicans are willing to consider taking this on as well. Republicans have their own reasons and motivations for being wary of the tech giants. But it really seems like this is one area where there is some potential for some kind of bipartisan consensus that we need to do something about the extraordinary dominance that this handful of companies have come to hold on our economy and our daily life. DAVIES: Yeah. And I guess we should just note that Amazon and the other tech giants have some serious ammunition to battle, you know, in Congress and regulatory agencies. MACGILLIS: Absolutely. They've vastly increased their spending on lobbying in recent years. They're now some of the very biggest spenders on the influence industry in Washington. Many people who used to be in government have now sort of cycled through the revolving door into these companies. The Obama administration, which was strikingly lax in its approach to the growth of the giants, sent a lot of people, you know, into these companies. So there are very strong ties between government and the companies. And then in the case of Amazon, there's even more kind of direct ammunition, namely the company's really remarkable growth in Washington itself. The company has - clearly has set out to grow its presence and raise his profile in Washington, which will only help it in these fights to come. The company - of course, Jeff Bezos bought The Washington Post. He bought the largest mansion in town, which he spent about $35 million on to sort of turn it into a great kind of salon for having, you know, local gatherings of the power elite. They're spending a lot more on lobbying. They're getting all sorts of large contracts from the government for their cloud services. And then finally, they decided to put their second national headquarters just outside Washington - 25,000 high-paid jobs, billions in investment. So the company has greatly increased its profile in Washington, which makes sense if you think that for a company like Amazon, the main threat right now comes not from other corporate rivals, but really from the possibility of government intervention. DAVIES: Yeah. You know, I found the Bezos house in Washington fascinating. I mean, you know, he was a Seattle guy. I think you report that this was his fourth additional home. What was the - what's the scale of this thing? MACGILLIS: Oh, it's extraordinary. It's the former textile museum in Washington. It's two - actually two separate buildings, two very large adjacent gorgeous buildings, which is, you know, countless rooms and. MACGILLIS: bathrooms. I think there are maybe - if I recall right two dozen bathrooms between the two - these two structures, vast ballroom. It's clearly the whole goal of this building, which is in the Kalorama neighborhood that's, you know, near where the Obamas live and all sorts of other sort of high-profile elite in town. The goal is to turn this building into something really kind of like what would Katharine Graham, the legendary owner of The Washington Post, used to have, a real sort of salon where everyone, you know, will gather and sort of hobnob. And it's not hard to see how having a kind of power center of that sort will help Bezos and Amazon in the years to come in Washington. DAVIES: Right. And it's worth noting that he has interests not just in government policy about antitrust issues and issues of size, but he competes for an awful lot of government contracts. You know, you mentioned that he bought The Washington Post. And I think many, many people are - a lot of people there are excited at the resources that have been put into good, hard-nosed reporting by The Washington Post. Have they been as hard nosed in reporting on Amazon like the competition for the second headquarters? MACGILLIS: The Washington Post has benefited greatly from the investment by Bezos, and I'm very happy for my former colleagues there who simply have more resources now to do their jobs. There is a fundamental awkwardness that comes with one of the richest men in the world, the founder of this enormous, powerful company owning the newspaper. The newspaper has done quite a good job of, you know, covering various aspects of Amazon. There's - they have a very good reporter based in Seattle who covers the company. They occasionally do, you know, tough stories about various aspects of the company, whether it's the counterfeit goods on the site or other things. What the newspaper has been in an awkward position to cover is the whole scale of the takeover of Washington by Amazon. That is a huge story that has not yet really been covered by the paper. One can't help but think that if a different company had acquired as much influence and scale and presence in Washington that the local newspaper would have been writing about this in a big sort of way. That you haven't really seen yet in The Post. Of all my colleagues - former colleagues there assure me that there's no calls coming from Seattle telling them not to do this or that story. And I believe them. It's a more existential problem than that. It's just - it's really tricky for the paper to tell in a big way what is happening with the Amazon takeover of Washington. DAVIES: You know, a lot of people will listen to this and think of all of the times that they have used Amazon in its many forms - I mean, online and, you know, videos and whatever. Should we feel guilty about our collaboration here? MACGILLIS: It's a tough question. And I think a lot of people, you know, even friends of mine asked me about this. You know, do you use the Amazon? How should we approach this? There's no question that in the last year, a lot of the compunction that we used to feel about using Amazon kind of went out the window. We felt like we had permission and approval from the authorities to sort of go all-in on the kind of one-click approach to our daily life. And now that we're coming out of this moment of the pandemic, it does seem important for us to re-engage with sort of the physical world in all its forms in the places we live, whether it's local businesses and, you know, local theater, all these places that make our towns and neighborhoods places that we want to be in, places that have character. I am not an absolutist on this. I use Amazon when I have to if there's no other option. So this is not about cold turkey approach. It's just about thinking about our purchases, thinking about the way we live and really thinking about what lies behind that one click. DAVIES: Alec MacGillis, let me also thank you so much for speaking with us again. MACGILLIS: Well, thank you for having me. DAVIES: Alec MacGillis is a senior reporter for ProPublica. His new book is \"Fulfillment: Winning And Losing In One-Click America. \" We should note that Amazon is a financial supporter of NPR. Coming up, jazz critic Kevin Whitehead tells us about a very old-school jam session recorded with Chicago piano player Erwin Helfer. This is FRESH AIR. (SOUNDBITE OF MUSIC) DAVE DAVIES, HOST:   This is FRESH AIR. I'm Dave Davies, in for Terry Gross, who's off this week. Ballots are being counted this week in what could be a watershed election in Bessemer, Ala. , but it's not for a political office. The vote will determine whether nearly 6,000 employees of the Amazon warehouse in Bessemer will be represented by a union, something Amazon has forcefully resisted in its workplaces across the country. Our guest today, veteran reporter Alec MacGillis, has a new book which explores Amazon's impact on American life. But it isn't just about Amazon. MacGillis looks at the growing disparities in wealth and prosperity, not just among American households, but among the regions where Americans live, places that are technology hubs, mainly on the east and west coasts, are seeing growth and jobs and income that spawns soaring housing prices and plenty of high-end restaurants while other regions stagnate, leaving once-prosperous families struggling, alienated and angry. We should note that Amazon is a financial supporter of NPR. Alec MacGillis is a senior reporter for ProPublica and the recipient of a George Polk Award, among other honors. He worked previously at the Washington Post, The Baltimore Sun and The New Republic. He was last on FRESH AIR to talk about his book \"The Cynic,\" a biography of Senator Mitch McConnell. The title of his new book borrows the term Amazon uses for its warehouses - fulfillment centers. The book is \"Fulfillment: Winning And Losing In One-Click America. \" Alec MacGillis joins us from his home in Baltimore. Alec MacGillis, welcome back to FRESH AIR. Let's start for a moment talking about this union vote at the Amazon warehouse in Bessemer, Ala. It's gotten a lot of attention - you know, a video message from President Biden. Why is it such a big deal? ALEC MACGILLIS: The stakes are just enormous here. I mean, this is really the first time that any union has gotten this far in trying to organize an Amazon warehouse. No warehouse has ever gotten to hold a full vote like this. And if you step back a little bit, I mean, this really is - this could help decide the question of what work is going to look like, what life is going to look like for the working class in America in years to come. The Amazon warehouses have spread so much in the country, have become so huge, so ubiquitous, especially over this past year, when we all started buying so much more online that working in an Amazon warehouse has really kind of become the - a sort of mass labor option for Americans the way that going to work in the factory or at the mall used to be. Now, if you're sort of looking for work in a given place, you can go to the Amazon warehouse and get a job there. But those jobs are really difficult, really challenging with incredibly high pressure, high demand expectations inside these warehouses. And they're paid not that much. DAVIES: Right. And we should note that this vote takes place in Alabama, which is not a union-friendly state. And Amazon says it pays $15 an hour, which is, I think, twice Alabama's minimum wage. There are health benefits. And yet this effort has managed to get some real momentum. Just help us understand why you think. MACGILLIS: It's for a couple of reasons. One is that when we talk about the wage, it's important to think about what we're comparing it to. It's true that it's twice the minimum wage in Alabama. And it's more than one might make that, say, a fast-food job. But it's also less than what many other warehouse jobs have paid in the past, warehouse jobs that tend to be more kind of stable, longer tenure kind of warehouse jobs. You know, working at the local, you know, beer warehouse or mattress warehouse is something that a lot of places would actually still pay more than the Amazon job does. The Amazon job also does pay quite a bit less than the manufacturing jobs of yore that sustained so much of the American working class, working middle class, despite the fact that the jobs in these warehouses are often nearly as strenuous or physically taxing as those manufacturing jobs were. The jobs in these warehouses are just incredibly physically strenuous often, very repetitive, very isolating. They're hard jobs to do, which is one reason why these warehouses have such an enormous turnover. DAVIES: Tell us a bit about the conditions of working in the Amazon warehouses. MACGILLIS: It is such demanding work. And it's not only demanding, but it's incredibly repetitive. You know, I think a lot of us kind of hoped that as work got more automated in warehouses like this and you got more and more robots into there, that it would kind of free up people to do more sort of autonomous, kind of fulfilling kind of work. In fact, the opposite has happened. Bringing the robots in has actually made the work more repetitive and more essentially robotic. One main example of this is that you used to have to - the pickers - one of the main jobs in the warehouse are the pickers. And they used to have to roam the corridors looking for items. So you'd have to go up and down looking for X or Y item on your scanner. And there's a lot of walking involved in that, but there's also a little bit of autonomy. You were out there on your own looking for things. Now, most warehouses, the robots bring the items to you. They're these - they have these tall stacks of shelves on them. The robots are like these little ottomans sort of that have these tall stacks of shelves on them. They zoom around, and they bring these - a robot will zoom a bunch of shelves over to you so that you can take out a given item that you need to fulfill an order. And so just standing there all day, just pulling the items out of the shelves as they come to you in the exact same spot in. And essentially, your work has not yet been replaced by robot only because they're having a hard time teaching robots how to grab things. That's one of the tougher things that robots do - to grab things at different shapes and sizes. So much of the work at the warehouse has now become even more kind of rudimentary and essentially robotic-like. And it's also just so isolating. The work is so - that isolating quality of the work has gotten even worse during the pandemic because there's been an effort to separate people out more on the floor, so they don't give each other the virus. So work that used to be done maybe by two or three people in a given part of the floor is now done by just one person, which not only makes the jobs tougher, but also makes them more isolating. The loss of community in these in these jobs is, you know, is one of the big parts of what's changed, the fact that you used to know all the people you worked with. You were maybe related to some of them. After you left work at the steel mill on Sparrows Point, you would often, of course, roll out of your shift and go to the bar, go to the diner, whatever it might be with your - the people you worked with. Now you go and you do your shift, your 10-hour shift. It's very grueling, repetitive, demanding. And then you get the heck out of there. A former mill worker who lives nearby says that you can just see every shift change as people come screaming out of the warehouse is now driving at such high speeds that they've had to put speed bumps in because people are just desperate to get out of there. DAVIES: There have been other organizing attempts at Amazon warehouses, and the company has resisted them. There have been some National Labor Relations Board complaints about deaths. There was a settlement in which the company agreed to post certain messages in one of its plants. Has the company been more constrained in its efforts to fight the union here in Bessemer? MACGILLIS: They may have been somewhat more constrained because there was so much scrutiny on this particular election. They know that there are a lot of eyes on them. But they've still been quite aggressive in trying to head off the union. Just constant messages, you know, anti-union messages coming to the workers. They've, you know, as usual, hired firms - law firms that specialize in fending off unions. There's just been a very strong sense of just how displeased they would be if workers were to vote to organize to the point where there's some concern that Amazon might actually shut down this entire warehouse if there were, in fact, a vote to organize. So, you know, they've been very, very aggressive while being somewhat more aware of just the fact that the eyes of the country are on them in this case. DAVIES: We'll see what happens. We should note that if the union wins this vote and they are the recognized bargaining agent for the factory, that doesn't mean they have a contract. Negotiating a contract is the next step, and that's a big one, right? MACGILLIS: It is. And it's also worth noting that because Alabama is a so-called right-to-work state, that even if the union were to win this election and if there were then, you know, successful contract negotiations, workers would still have the right to opt out of paying dues for this union since the right-to-work states give workers that choice. DAVIES: All right. Let's take a break here. I'm going to reintroduce you. We are speaking with Alec MacGillis. He is a senior reporter for ProPublica. His new book is \"Fulfillment: Winning And Losing in One-Click America. \" We'll be back to talk more in just a moment. This is FRESH AIR. (SOUNDBITE OF ULTRALUST'S \"MISSING YOU\") DAVIES: This is FRESH AIR, and we're speaking with ProPublica senior reporter Alec MacGillis. He has a new book about Amazon and the impact of giant tech companies on the growing inequality and wealth and prosperity among regions in the United States. The book is \"Fulfillment: Winning And Losing In One-Click America. \" You write that, you know, if you go back a few decades, that the cities that had among the highest median incomes included places like Cleveland and Detroit. And it's very different now. Well, first of all, let's just take some of the areas that are really getting the lion's share of growth like Seattle, like San Francisco. Part of that is the tech industry. What is it about tech companies and their needs that tend to cause many of them to cluster in a particular location, even competitors? Why do they end up ganging up in places like Seattle and the San Francisco area? MACGILLIS: One is the natural tendency of the tech economy to agglomerate. That's sort of the fancy word for it, that with tech, you want to be around the other people who are innovating and coming up with advances. It kind of harkens back to the role that cities have played throughout history, where they've become fonts of innovation, you know, Renaissance Florence or Glasgow in the 19th century, when you have people together who are bouncing ideas off each other, coming up with innovations in proximity with one another and also, of course, in proximity with capital, with the venture capitalists who can fund their ideas and help launch their companies. It helps to be in the same place to make that pitch at the cocktail party or in the elevator. This differs from the way that the manufacturing economy used to work, where once you came up with an advance like, say, the steel-making process that fueled the Industrial Revolution, the Bessemer steel-making process, once you came up with something like that, you could take that process and set up a factory or plant anywhere where you had the basic manpower and natural resources and transportation to get your product to market so that you could just sort of go out around the country and set up a steel mill anywhere where it made sense. With tech, we instead see this kind of agglomeration where it's all about the human capital. So once you come up with a big software innovation - say the cost of producing that thing, whatever it might be, is negligible - all the value lies in that initial innovation. It's all about getting that human capital together to make those advances. And so you have that agglomerating effect in a handful of winner-take-all cities. DAVIES: So as you were writing about these great disparities in the United States among regions and tech companies' role in it, you thought Amazon would be a good lens for examining all this. Let's just start with, how big was Amazon before the pandemic? How big is it now? MACGILLIS: I think it's really kind of hard for us to even comprehend just how big it's gotten. It was huge already before the pandemic, with several hundred thousand workers around the country, more than a hundred fulfillment centers as they call their primary warehouses, about, you know, 40% of the e-commerce market in the country was controlled by Amazon, just a huge share of it. The company, of course, has also been growing incredibly rapidly in a whole other realm, namely the so-called cloud, the world of online tech infrastructure that other companies rent - essentially rent from Amazon in all these data centers that have also sprung up around the country. That's a whole other part of Amazon that's been incredibly lucrative for them. So they were already very large before the pandemic. But what has happened in this past year is really kind of hard to grasp. In the span of just a single year, they hired more than 400,000 additional employees. And that does not include all the delivery drivers that we see all around our cities that are actually not technically employed by Amazon, even though they wear Amazon jerseys and drive Amazon vans. The company has added roughly 50% more warehouse space in just the past year. Its sales have gone up about 40% year over year. Its stock price went up more than 80%. Jeff Bezos' personal wealth went up about $58 billion over the past year. Perhaps because we're right in the middle of it, we can't really grasp just how much how it's gotten. We may be averting our eyes from the scale of the growth, partly because we all feel somewhat complicit in it. The fact is that the company grew so much over the past year because Americans, in much greater numbers than before, really embraced the sort of one-click approach to our daily life. And now we just see it. We see it everywhere around us. I mean, you see the vans just coming up and down your streets constantly. If you're out on the highway, the number of, you know - on tractor trailers is just stunning and almost kind of eerie when you start to count them over just a short stretch of highway. It's just an incredible growth in reach and in size and penetration in our economy and in our daily life. DAVIES: Right. Now, of course, Amazon has been building, you know, scores of new warehouses and distribution centers, many of them in regions where, you know, good-paying manufacturing jobs had disappeared, you know, due to competition and automation. So when the company considers where to locate one of its facilities which will create a lot of jobs, they can bargain with the host community for financial incentives. There's nothing new about this. Companies have been doing this for decades. Does Amazon play the game differently from other firms? MACGILLIS: Amazon is especially aggressive at this game. I mean, one of the things that really just astonished me was what I found in all my reporting and digging into these communications between the towns and cities and the company - I did a lot of public information requests and got a lot of the emails that went back and forth between them - and just to see the aggressiveness on Amazon's part, the obsequiousness on the part of the local officials who are willing to offer these tax subsidies and incentives and also the pledges of secrecy, that was one of the key things. Amazon is especially insistent on secrecy to the point of even giving a lot of its projects code names so that when they go into a given town, a lot of people won't even know who the company is that's trying to build the data center on the edge of town. It'll have some kind of code name that does not include the name Amazon. DAVIES: Let me just explore that for a moment. When you say secrecy, I mean, a lot of these - in some cases, they're - you know, a government subsidy is a public contract. And there are rules of transparency. There are right to know laws that allow citizens and journalists to get information. What kind of secrecy can the company impose that affects that? MACGILLIS: The company can impose or has managed to impose requirements that local governments not give up the identity of the company seeking to build this data center warehouse until the last possible moment. They also urged local officials not to take questions from the press. DAVIES: Right. Right. Now, of course, we're dealing with often local officials who are desperate to develop some economic growth for their citizens who are sorely in need of it. When a deal is done, eventually the public subsidies do become public. What kind of deals does Amazon get? And what's its impact on those communities? MACGILLIS: Typically, it's some form of a tax subsidy where the company will not have to pay all the taxes that would normally be due both on the property itself of the warehouse or the data center or payroll taxes on the workers that will be employed at them; so essentially just a great reduction in its tax bill in the community where it's setting up shop. And the effect of this is, of course, to erode the local tax base and to greatly reduce the amount of money that's coming into local coffers, to support local services, to support the roads and the police and fire and schools. And one reason this is a special problem is that Amazon, when it comes into a community, of course, brings much greater demands for public services. There's all the - just the wear and tear on the roads that come with the incredible increased traffic of cars and trucks, delivery trucks. There are the frequent calls for emergency assistance at the warehouses. The Amazon warehouses tend to have their own in-house medical teams that are called AmCare, but they're not always on duty or they can't sometimes handle the severity of a given case, including some of the fatal accidents that I wrote about in the book. And so you have police and fire and EMS in the local community having to respond to the warehouses for lots of calls when Amazon is itself not supporting those services through the tax dollars that it has essentially been able to avoid paying. DAVIES: Did you find communities that regretted making these deals? MACGILLIS: They - absolutely. They see it as very much of a mixed bag. But in a lot of cases, they feel like they have no choice. You have communities that have been just really hollowed out by the loss of manufacturing jobs. Places that I focus on in the book, you know, in Ohio, especially southwest Ohio, that it was just crushed by the loss of auto manufacturing jobs and other manufacturing jobs in the first couple of decades - the last couple decades or places like Baltimore, another big focus in the book, where you had the largest steel mill in the world, 30,000 jobs that completely vanished in the last two decades and left this entire peninsula outside Baltimore just wiped clean of the massive employment base that used to be on offer there and left local officials just desperate to get anything in there. And so there they were a few years ago handing out subsidies to bring in an Amazon warehouse where jobs were then paying $13 or $14 an hour when at that very same location, you had a steel mill where jobs were paying $35 more an hour not so long ago. DAVIES: We need to take another break here. Let me introduce you. We are speaking with Alec MacGillis. He is a senior reporter for ProPublica. His new book is \"Fulfillment: Winning And Losing In One-Click America. \" He'll be back to talk more after this short break. I'm Dave Davies, and this is FRESH AIR. (SOUNDBITE OF BRUCE HORNSBY'S \"BACKHAND\") DAVIES: This is FRESH AIR. I'm Dave Davies, in for Terry Gross, who's off this week. We're speaking with ProPublica senior reporter Alec MacGillis. He has a new book about Amazon and the impact of giant tech companies on the growing inequality IN wealth and prosperity among metropolitan regions in the United States. The book is \"Fulfillment: Winning And Losing In One-Click America. \" Amazon has obviously had an impact on brick-and-mortar businesses that have to compete with online shopping. And this is not just Amazon. This is a phenomenon that we're seeing around the country where department stores and malls have closed. But you look at another aspect of this that was really interesting. Some companies like, you know, business supplies companies, office supplies companies, in El Paso, they were trying to supply their products to the local school districts and local governments and had to deal with competition from Amazon. What did you discover? This is interesting. MACGILLIS: This is such a big part of Amazon's massive growth in recent years. And I think a lot of people probably aren't aware of this, that it used to be that Amazon mostly, you know, sold goods on the website that it had purchased wholesale from the manufacturer and then sold them on their site just the way that the company would sell goods in a store. But more and more of Amazon's - the goods that are available on the site and the company's profits come from, quote, what they call \"third-party sellers. \" So these are companies that have goods that they want to sell. And instead of just setting up their storefront wherever they might be or selling their items online directly through e-commerce, they now put them on the Amazon website, what's called the marketplace. You sell your goods on the marketplace and it's good for you as a third-party seller in the sense that you have this enormous customer base that now goes to Amazon, all these people who go to Amazon to find whatever they want to buy. And so you want to be in that marketplace. But the problem with that approach for a third-party seller is that Amazon extracts a very large cut of its own and, you know, basic commission and advertising fees and the fees for fulfilling the order and holding the item in the warehouse, all sorts of costs that can get up close to 25%, 30% in some cases. But more and more, a seller feels like they have no real option but to go to the marketplace because that's where everything now is happening. DAVIES: And you describe a fascinating moment where one of these businesses is dealing with the fact that - I believe it was the school district that has, you know, talked to Amazon and they're going to offer this terrific program where you'll get Amazon products and they'll offer third - you know, other companies' products on their website. And then one of these local companies did some research about prices and about products and went to talk to the school district and said there are some things you should know. Tell us about that. MACGILLIS: Yeah. So he was this very charismatic, kind of feisty office supply company owner called Sandy Grodin (ph). And while he was getting this sort of pressuring call from some very young Amazon salespeople urging him to come to the marketplace - you know, basically you better do this or else because everyone's doing it and this is where the world is heading - while he was actually on the phone with them, he had one of his employees check the prices of some basic office supply products on Amazon. And he was stunned to see just how low the price was, a price that he would never be able to make any money from. And he looked into it and discovered that, in fact, that product was a counterfeit product. This is a big problem on Amazon. A lot of products are that are offered at seemingly, you know, bargain prices are, in fact, counterfeits. DAVIES: And it's a brand name. It presents itself to be a certain brand name, right? And it isn't. MACGILLIS: It isn't. And what you're going to get in the mail, if you get it at all, is not what you were - what you thought you had bought. DAVIES: Did Amazon say anything about the counterfeit products? MACGILLIS: Amazon has acknowledged for a while now that this is a problem and that they are, you know, trying to deal with the counterfeit problem. But it just remains and it's become a huge issue for the website, just the growth of counterfeit products and also all the tricks that various third-party sellers use to try to hurt each other, in a sense. There's not only the sale of counterfeit products on the site, but then there's also the false claims lodged against other companies for having offered shoddy goods or otherwise broken the rules that then gets them kicked off of the website. It's just a real - it can be a real nightmare for a lot of companies trying to sell through Amazon, but they feel like they have no choice. And it's now - that now makes up a - the vast majority of Amazon sales on the website are from third-party sellers, not from the company itself. And it's one reason that the company is doing so well because they get a much larger cut of those third-party sales than they would of their own kind of direct selling of goods on the website. DAVIES: Wow. So you have so many players that those who choose to exploit the rules can, you know, use Amazon's own rules, file complaints, create problems and chaos. MACGILLIS: Right. It's a real morass. DAVIES: You know, when Amazon has all of these third-party suppliers on their website and they can sell their goods, it gathers an enormous amount of information about consumer preferences for those products. And there have been accusations - and this was explored in one congressional hearing that you wrote about - accusations that Amazon can use that information to then tweak its own products and get a competitive edge over some of the more successful third-party suppliers. What have we learned about this? MACGILLIS: Yes, this is one of the main complaints against Amazon and actually one of the main drivers of discussions in Washington now about somehow trying to break up the company's hold on so much of our economy. But what's been happening is that the company is able to collect so much data about what kind of products are doing well. And it then in many cases - and this is - there's no real dispute about this - it has then managed to come up with products of its own where it's actually selling products under its own labels. So it'll go out and get some manufacturer to make a given product that strongly resembles the one that was doing well on the site from some other seller and sell it under one of its own private label names. Amazon says this is hardly any different than retail companies that for years now have offered their goods under their own labels. You go into the grocery store and you see, you know, all manner of goods that that grocery store or other retailers selling under their own label. The difference is that - is the data that Amazon has been able to collect and the way it's been able to use the data it's collecting on sales on the site to inform its own decisions to go after a particular product. And there's just been all sorts of examples of it being able to essentially just knock out a product that was doing well on the site and then sell it under its own name. DAVIES: We are speaking with Alec MacGillis. He's a senior reporter for ProPublica. His new book is \"Fulfillment: Winning And Losing In One-Click America. \" We will continue our conversation in just a moment. This is FRESH AIR. (SOUNDBITE OF MUSIC) DAVIES: This is FRESH AIR. We're speaking with ProPublica senior reporter Alec MacGillis, whose book is about the impact of Amazon and giant tech companies on the growing inequality of wealth and prosperity in different regions of the country. It's called \"Fulfillment: Winning And Losing In One-Click America. \" When we left off, MacGillis was talking about reporting that Amazon uses the data it collects from the sales of products from other companies on its website to create similar products which Amazon can then sell under its own label. Critics say this data collection gives Amazon a huge competitive edge. You know, competition is a part of capitalism. It's a part of sales. And it benefits consumers if the competition is fair, right? I mean, but if somebody has the power to knock somebody else out and then raise prices, that's considered anti-competitive. And there are antitrust laws that deal with this kind of thing. Have Congress or regulators shown any interest in dealing with this in the case of Amazon? MACGILLIS: This is the big question that's before us now in Washington. For decades now, we've allowed some of these companies to get so big and so powerful because we've taken a very lax approach to antitrust enforcement in this country. Back in the early 20th century, we worried a lot about monopoly. And there were all these efforts to rein in and break up various big companies. As the 20th century went on, there was an adoption of a much softer approach to antitrust where the basic argument was there's nothing to worry about as long as prices remain low. As long as the consumer is still paying low prices, it's OK if a company gets really big or if a company controls a huge share of a given market. It was called the consumer welfare test. That was the main test for whether we should go after a monopoly. And so, you know, you could look at a company like Amazon, where there all these goods for sale at seemingly low prices and say, well, what's the problem with having a company that's so incredibly powerful and dominant if we, the American consumers, can still buy all sorts of stuff fairly cheap? And it's only been in recent years that a group of people of sort of thinkers have now come to identify the problem with this kind of approach, that there's all sorts of distorting effects that a company can have on the market and anti-competitive effects that it can have, even if it's seemingly keeping prices low for the moment. And now we're heading into this moment in Washington where there's going to be a very interesting fight over whether we're going to try to do something about this. DAVIES: Yeah. We have a new president. Are there any signs that he's going to take a different approach? I mean, there are government regulators that affect all this - right? - the Federal Trade Commission and others. What are you seeing? MACGILLIS: There are signs that we're actually going to - that we could actually have a new approach here. The Biden administration has brought in some very high-profile people who have been outspoken opponents of this softer approach to antitrust. One of them is a woman by the name of Lina Khan, who as a Yale law student not long ago wrote a really kind of groundbreaking piece explaining how Amazon was, in fact, having a distorting monopoly-like effect on the economy, even if it was seemingly still keeping prices low. The Biden administration has appointed her to the Federal Trade Commission and brought another very outspoken critic of the tech giants by the name of Tim Wu into the White House as an adviser. And on top of that, we have lots of people in Congress who actually have been - Democrats in Congress who've been getting quite aggressive on this front and even some signs that Republicans are willing to consider taking this on as well. Republicans have their own reasons and motivations for being wary of the tech giants. But it really seems like this is one area where there is some potential for some kind of bipartisan consensus that we need to do something about the extraordinary dominance that this handful of companies have come to hold on our economy and our daily life. DAVIES: Yeah. And I guess we should just note that Amazon and the other tech giants have some serious ammunition to battle, you know, in Congress and regulatory agencies. MACGILLIS: Absolutely. They've vastly increased their spending on lobbying in recent years. They're now some of the very biggest spenders on the influence industry in Washington. Many people who used to be in government have now sort of cycled through the revolving door into these companies. The Obama administration, which was strikingly lax in its approach to the growth of the giants, sent a lot of people, you know, into these companies. So there are very strong ties between government and the companies. And then in the case of Amazon, there's even more kind of direct ammunition, namely the company's really remarkable growth in Washington itself. The company has - clearly has set out to grow its presence and raise his profile in Washington, which will only help it in these fights to come. The company - of course, Jeff Bezos bought The Washington Post. He bought the largest mansion in town, which he spent about $35 million on to sort of turn it into a great kind of salon for having, you know, local gatherings of the power elite. They're spending a lot more on lobbying. They're getting all sorts of large contracts from the government for their cloud services. And then finally, they decided to put their second national headquarters just outside Washington - 25,000 high-paid jobs, billions in investment. So the company has greatly increased its profile in Washington, which makes sense if you think that for a company like Amazon, the main threat right now comes not from other corporate rivals, but really from the possibility of government intervention. DAVIES: Yeah. You know, I found the Bezos house in Washington fascinating. I mean, you know, he was a Seattle guy. I think you report that this was his fourth additional home. What was the - what's the scale of this thing? MACGILLIS: Oh, it's extraordinary. It's the former textile museum in Washington. It's two - actually two separate buildings, two very large adjacent gorgeous buildings, which is, you know, countless rooms and. MACGILLIS: bathrooms. I think there are maybe - if I recall right two dozen bathrooms between the two - these two structures, vast ballroom. It's clearly the whole goal of this building, which is in the Kalorama neighborhood that's, you know, near where the Obamas live and all sorts of other sort of high-profile elite in town. The goal is to turn this building into something really kind of like what would Katharine Graham, the legendary owner of The Washington Post, used to have, a real sort of salon where everyone, you know, will gather and sort of hobnob. And it's not hard to see how having a kind of power center of that sort will help Bezos and Amazon in the years to come in Washington. DAVIES: Right. And it's worth noting that he has interests not just in government policy about antitrust issues and issues of size, but he competes for an awful lot of government contracts. You know, you mentioned that he bought The Washington Post. And I think many, many people are - a lot of people there are excited at the resources that have been put into good, hard-nosed reporting by The Washington Post. Have they been as hard nosed in reporting on Amazon like the competition for the second headquarters? MACGILLIS: The Washington Post has benefited greatly from the investment by Bezos, and I'm very happy for my former colleagues there who simply have more resources now to do their jobs. There is a fundamental awkwardness that comes with one of the richest men in the world, the founder of this enormous, powerful company owning the newspaper. The newspaper has done quite a good job of, you know, covering various aspects of Amazon. There's - they have a very good reporter based in Seattle who covers the company. They occasionally do, you know, tough stories about various aspects of the company, whether it's the counterfeit goods on the site or other things. What the newspaper has been in an awkward position to cover is the whole scale of the takeover of Washington by Amazon. That is a huge story that has not yet really been covered by the paper. One can't help but think that if a different company had acquired as much influence and scale and presence in Washington that the local newspaper would have been writing about this in a big sort of way. That you haven't really seen yet in The Post. Of all my colleagues - former colleagues there assure me that there's no calls coming from Seattle telling them not to do this or that story. And I believe them. It's a more existential problem than that. It's just - it's really tricky for the paper to tell in a big way what is happening with the Amazon takeover of Washington. DAVIES: You know, a lot of people will listen to this and think of all of the times that they have used Amazon in its many forms - I mean, online and, you know, videos and whatever. Should we feel guilty about our collaboration here? MACGILLIS: It's a tough question. And I think a lot of people, you know, even friends of mine asked me about this. You know, do you use the Amazon? How should we approach this? There's no question that in the last year, a lot of the compunction that we used to feel about using Amazon kind of went out the window. We felt like we had permission and approval from the authorities to sort of go all-in on the kind of one-click approach to our daily life. And now that we're coming out of this moment of the pandemic, it does seem important for us to re-engage with sort of the physical world in all its forms in the places we live, whether it's local businesses and, you know, local theater, all these places that make our towns and neighborhoods places that we want to be in, places that have character. I am not an absolutist on this. I use Amazon when I have to if there's no other option. So this is not about cold turkey approach. It's just about thinking about our purchases, thinking about the way we live and really thinking about what lies behind that one click. DAVIES: Alec MacGillis, let me also thank you so much for speaking with us again. MACGILLIS: Well, thank you for having me. DAVIES: Alec MacGillis is a senior reporter for ProPublica. His new book is \"Fulfillment: Winning And Losing In One-Click America. \" We should note that Amazon is a financial supporter of NPR. Coming up, jazz critic Kevin Whitehead tells us about a very old-school jam session recorded with Chicago piano player Erwin Helfer. This is FRESH AIR. (SOUNDBITE OF MUSIC)", "section": "Business", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-03-31-982339371": {"title": "Attorney-Client Privilege Rights In Federal Bureau Of Prisons Come Under Fire : NPR", "url": "https://www.npr.org/2021/03/31/982339371/when-it-comes-to-email-some-prisoners-say-attorney-client-privilege-has-been-era", "author": "No author found", "published_date": "2021-03-31", "content": "RACHEL MARTIN, HOST:  All right. Communications between defendants and their lawyers are protected by the attorney-client privilege. Anyone who's ever watched an episode of any crime show knows this. But it's a bit more complicated in practice, especially when it comes to email correspondence between federal prisoners and their attorneys. NPR's Carrie Johnson reports. CARRIE JOHNSON, BYLINE: The Federal Bureau of Prisons offers email to the 150,000 people locked up in the system, but defense attorneys say there's a big catch. Jumana Musa works at the National Association of Criminal Defense Lawyers. JUMANA MUSA: The whole system is completely coercive because there's only one email system that you can possibly use. And if you want to use it, you have to sign a waiver. JOHNSON: That waiver allows authorities to monitor messages even between clients and their lawyers. Musa says there is a way for the prisons to filter out those attorney-client emails, but it's not clear how often the Justice Department actually does that. Defendants only find out if those messages get used against them in court. That happened to a client of a Pennsylvania lawyer Peter Goldberger. PETER GOLDBERGER: I will say the client did in one message criticize the jury that had convicted him for being stupid, I think was the word he used. And that was very offensive to the judge. JOHNSON: A spokesman for the Bureau of Prisons says lawyers who worry about the surveillance can schedule a phone call or make a visit to the prison. But California defense lawyer Ken White says it's not that easy. KEN WHITE: It's extremely time-consuming and burdensome to visit somebody in jail. It's often a multi-hour prospect just to go see someone, even if it's for five minutes. JOHNSON: Things only got worse during the coronaviruses pandemic, which ravaged prisons and sometimes put a stop to visits altogether. Catherine Crump runs a legal clinic at the Berkeley law school. CATHERINE CRUMP: BOP reading inmates' emails was concerning even before the pandemic. But now email is one of the few ways attorneys can reliably communicate with their clients when they're in custody. JOHNSON: The issue has attracted attention in Congress. Last month, the House of Representatives overwhelmingly voted to give prisoner emails with their attorneys more legal protection. Congressman Hakeem Jeffries, a Democrat from New York, sponsored the bill. (SOUNDBITE OF ARCHIVED RECORDING)HAKEEM JEFFRIES: The time has arrived for us to address this egregious practice, lift up the presumption of innocence, facilitate due process and allow fundamental fairness to permeate all aspects of our judicial system. JOHNSON: The Senate needs to act before the bill could become law. Carrie Johnson, NPR News, Washington. (SOUNDBITE OF LIAM THOMAS' \"BITTER FEELING\") RACHEL MARTIN, HOST:   All right. Communications between defendants and their lawyers are protected by the attorney-client privilege. Anyone who's ever watched an episode of any crime show knows this. But it's a bit more complicated in practice, especially when it comes to email correspondence between federal prisoners and their attorneys. NPR's Carrie Johnson reports. CARRIE JOHNSON, BYLINE: The Federal Bureau of Prisons offers email to the 150,000 people locked up in the system, but defense attorneys say there's a big catch. Jumana Musa works at the National Association of Criminal Defense Lawyers. JUMANA MUSA: The whole system is completely coercive because there's only one email system that you can possibly use. And if you want to use it, you have to sign a waiver. JOHNSON: That waiver allows authorities to monitor messages even between clients and their lawyers. Musa says there is a way for the prisons to filter out those attorney-client emails, but it's not clear how often the Justice Department actually does that. Defendants only find out if those messages get used against them in court. That happened to a client of a Pennsylvania lawyer Peter Goldberger. PETER GOLDBERGER: I will say the client did in one message criticize the jury that had convicted him for being stupid, I think was the word he used. And that was very offensive to the judge. JOHNSON: A spokesman for the Bureau of Prisons says lawyers who worry about the surveillance can schedule a phone call or make a visit to the prison. But California defense lawyer Ken White says it's not that easy. KEN WHITE: It's extremely time-consuming and burdensome to visit somebody in jail. It's often a multi-hour prospect just to go see someone, even if it's for five minutes. JOHNSON: Things only got worse during the coronaviruses pandemic, which ravaged prisons and sometimes put a stop to visits altogether. Catherine Crump runs a legal clinic at the Berkeley law school. CATHERINE CRUMP: BOP reading inmates' emails was concerning even before the pandemic. But now email is one of the few ways attorneys can reliably communicate with their clients when they're in custody. JOHNSON: The issue has attracted attention in Congress. Last month, the House of Representatives overwhelmingly voted to give prisoner emails with their attorneys more legal protection. Congressman Hakeem Jeffries, a Democrat from New York, sponsored the bill. (SOUNDBITE OF ARCHIVED RECORDING) HAKEEM JEFFRIES: The time has arrived for us to address this egregious practice, lift up the presumption of innocence, facilitate due process and allow fundamental fairness to permeate all aspects of our judicial system. JOHNSON: The Senate needs to act before the bill could become law. Carrie Johnson, NPR News, Washington. (SOUNDBITE OF LIAM THOMAS' \"BITTER FEELING\")", "section": "Law", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-04-01-983159051": {"title": "Why Does Discord Not Use Ads? The Questions We Asked Discord's CEO : NPR", "url": "https://www.npr.org/2021/04/01/983159051/why-does-discord-not-use-ads-and-why-is-microsoft-interested-we-asked-discords-c", "author": "No author found", "published_date": "2021-04-01", "content": "", "section": "Technology", "disclaimer": ""}, "2021-04-01-983155583": {"title": "Facebook Disputes Claims It Fuels Political Polarization And Extremism : NPR", "url": "https://www.npr.org/2021/04/01/983155583/facebook-disputes-claims-it-fuels-political-polarization-and-extremism", "author": "No author found", "published_date": "2021-04-01", "content": "NOEL KING, HOST:  One line of criticism against Facebook is this. The platform captures and holds our attention while its algorithms dictate what we see. And so the company just has too much influence on the national conversation. Those critics say Facebook has to take some responsibility for the polarized times that we're living in. Nick Clegg is Facebook's vice president of global affairs and communications. Yesterday on Medium, he posted a 5,000-word essay addressing critics. We called him on Zoom to talk about it. And full disclosure, Facebook is one of NPR's financial supporters. NICK CLEGG: This essay tries to deal with some of those wider concerns about social media, concerns about social media and the impact on polarization in society and so on, but also and more specifically, focuses on this fundamental issue. Who's in the driving seat? Is it us, you know, human beings? Or is it the machines? Is it the algorithms? And what I seek to explain is that, certainly, as far as Facebook is concerned, people are often, if you like, much more in control or much more in charge than they sometimes feel like they are. And what I announced in this article is some additional controls which give people real transparency in how the systems work and allows people to pull levers. So for instance, in a new feature, which I announced today, you'll be able to, in effect, override the algorithm and curate your own news feed composed of posts and groups and people who are your favorites. And so it's all about, in a sense, enhancing the control that users have as they use these sophisticated, new social media communication tools. KING: I understand how that might help in some senses. But what if I'm the user who wants a bunch of posts about how to overthrow the U. S. government? CLEGG: Well, if you are invoking violence, then of course that will be removed. And you won't be able to post that altogether. And we remove a significant amounts of content all the time where it breaks the company's own rules. For instance, just on COVID, we remove misinformation which could lead to imminent physical harm since March of last year. So over the last year, for instance, we've removed more than 12 million pieces of content on Facebook and Instagram where we feel that the information or the post would, you know, promote fake preventative measures or exaggerated cures, which would harm people. So if that's what you want, well, you can't do that on Facebook and Instagram. If you want to discuss politics, of course, you know, we live in a free society, thankfully. And you're free to do so, you know, on social media, just as much as you're free to do so sitting around your kitchen table. KING: Toward the end of your essay, you warn against blaming Facebook's algorithm for divisiveness and for hatred. You write, quote, \"we need to look at ourselves in the mirror and not wrap ourselves in the false comfort that we've simply been manipulated by machines all along. \" In your view, how much of the solution and how much of the blame lies with individual users? CLEGG: This really isn't about apportioning blame. The point I was trying to make was that there are very, very popular ways of communicating, you know, messaging apps - iMessage, Telegram, Signal, WhatsApp and so on - where, you know, millions, billions of people use that, you know, every second of the day to communicate with others. And yet there's no algorithm involved in those. And yet they're also, of course, a route by which people say unpleasant and hateful things as well as beautiful and uplifting things. And so the point I was just trying to make was that it's just foolish to say it's all the user's fault, but equally to say it's all somehow a faceless machine's fault. It's the interaction between the two. And the research, which I cite in the piece, you know, suggests that the reasons, for instance, for polarization in the U. S. , you know, precede - polarization was developing decades before social media was even invented. And I guess what I'm trying to do, which is difficult because sometimes, quite understandably, people want, you know, simple answers to what are complex issues - I'm sort of urging us nonetheless to try and grapple with the complexity of this and not try and all reduce it to some faceless machine that we blame for things that sometimes lie deep within society itself. KING: Nick Clegg is vice president for global affairs and communications at Facebook. Mr. Clegg, thank you for your time. CLEGG: Thank you. NOEL KING, HOST:   One line of criticism against Facebook is this. The platform captures and holds our attention while its algorithms dictate what we see. And so the company just has too much influence on the national conversation. Those critics say Facebook has to take some responsibility for the polarized times that we're living in. Nick Clegg is Facebook's vice president of global affairs and communications. Yesterday on Medium, he posted a 5,000-word essay addressing critics. We called him on Zoom to talk about it. And full disclosure, Facebook is one of NPR's financial supporters. NICK CLEGG: This essay tries to deal with some of those wider concerns about social media, concerns about social media and the impact on polarization in society and so on, but also and more specifically, focuses on this fundamental issue. Who's in the driving seat? Is it us, you know, human beings? Or is it the machines? Is it the algorithms? And what I seek to explain is that, certainly, as far as Facebook is concerned, people are often, if you like, much more in control or much more in charge than they sometimes feel like they are. And what I announced in this article is some additional controls which give people real transparency in how the systems work and allows people to pull levers. So for instance, in a new feature, which I announced today, you'll be able to, in effect, override the algorithm and curate your own news feed composed of posts and groups and people who are your favorites. And so it's all about, in a sense, enhancing the control that users have as they use these sophisticated, new social media communication tools. KING: I understand how that might help in some senses. But what if I'm the user who wants a bunch of posts about how to overthrow the U. S. government? CLEGG: Well, if you are invoking violence, then of course that will be removed. And you won't be able to post that altogether. And we remove a significant amounts of content all the time where it breaks the company's own rules. For instance, just on COVID, we remove misinformation which could lead to imminent physical harm since March of last year. So over the last year, for instance, we've removed more than 12 million pieces of content on Facebook and Instagram where we feel that the information or the post would, you know, promote fake preventative measures or exaggerated cures, which would harm people. So if that's what you want, well, you can't do that on Facebook and Instagram. If you want to discuss politics, of course, you know, we live in a free society, thankfully. And you're free to do so, you know, on social media, just as much as you're free to do so sitting around your kitchen table. KING: Toward the end of your essay, you warn against blaming Facebook's algorithm for divisiveness and for hatred. You write, quote, \"we need to look at ourselves in the mirror and not wrap ourselves in the false comfort that we've simply been manipulated by machines all along. \" In your view, how much of the solution and how much of the blame lies with individual users? CLEGG: This really isn't about apportioning blame. The point I was trying to make was that there are very, very popular ways of communicating, you know, messaging apps - iMessage, Telegram, Signal, WhatsApp and so on - where, you know, millions, billions of people use that, you know, every second of the day to communicate with others. And yet there's no algorithm involved in those. And yet they're also, of course, a route by which people say unpleasant and hateful things as well as beautiful and uplifting things. And so the point I was just trying to make was that it's just foolish to say it's all the user's fault, but equally to say it's all somehow a faceless machine's fault. It's the interaction between the two. And the research, which I cite in the piece, you know, suggests that the reasons, for instance, for polarization in the U. S. , you know, precede - polarization was developing decades before social media was even invented. And I guess what I'm trying to do, which is difficult because sometimes, quite understandably, people want, you know, simple answers to what are complex issues - I'm sort of urging us nonetheless to try and grapple with the complexity of this and not try and all reduce it to some faceless machine that we blame for things that sometimes lie deep within society itself. KING: Nick Clegg is vice president for global affairs and communications at Facebook. Mr. Clegg, thank you for your time. CLEGG: Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-04-02-983211972": {"title": "This News Publisher Quit Facebook And Readership Went Up : NPR", "url": "https://www.npr.org/2021/04/02/983211972/this-news-publisher-quit-facebook-readership-went-up", "author": "No author found", "published_date": "2021-04-02", "content": "NOEL KING, HOST:  The relationship between Facebook and news publishers is very complicated. Many news outlets think they need to be on Facebook in order to reach people, but they've also lost a lot of advertising dollars that now go to Facebook. NPR's Shannon Bond has the story of a publisher that decided to go it alone. And I should note that Facebook is one of NPR's financial supporters. SHANNON BOND, BYLINE: Sinead Boucher is CEO of New Zealand's largest news publisher. And last year during the pandemic, she bought the company for $1. And why a dollar? SINEAD BOUCHER: Well, it was just a nominal fee. Like, I knew that they, you know, in the context of what was happening, would potentially just decide to wind us up. So it was just a punt. BOND: The publisher is called Stuff. It owns the most popular news website in New Zealand and around 50 newspapers. And when the pandemic brought the economy to a halt, Stuff was at risk of shutting down. For Boucher, this was a big moment. BOUCHER: People sometimes said to me, it must be so stressful now owning the company and blah, blah. But it's actually, in a lot of ways, it's been liberating because there is a freedom in being able to make your own decisions for better or worse. BOND: And one of the first decisions she made was to break up with Facebook. Stuff was already wary of the social network, especially after a terrible mass shooting in New Zealand that was livestreamed on Facebook in 2019. So in July 2020, Stuff's newspapers and magazines all hit pause on Facebook. BOUCHER: You know, we still felt uneasy with a lot of the decisions Facebook has made or a lot of the things it turned a blind eye to. BOND: Things like hate speech and misinformation. But this decision was also risky for Stuff. Almost a quarter of its traffic came from social media - mainly Facebook. In fact, Facebook has become such a dominant force in how people get information, some governments are trying to force the social network to pay media outlets for news stories. Boucher says Stuff was bracing for the worst. BOUCHER: We were expecting that it would bring a significant drop in our traffic. That didn't happen. BOND: Traffic from social media did drop, but overall traffic went up in part because 2020 was such a big news year. BOUCHER: If we had remained on Facebook, we might have had another, I don't know, 5% growth. But even if we throttled our growth, it's brought us a lot of positives as well. BOND: Positives like more donations from readers who want to support Stuff. The Facebook pause was supposed to last a few weeks. It's now been more than eight months. But Boucher says it's still an experiment because there are people who rely on Facebook for news, and there's a lot of bad information on there. BOUCHER: And we wonder about the risk of withdrawing journalism from Facebook and what that leaves behind for people to sort of be exposed to, particularly around things like COVID vaccine. BOND: She worries. Does Stuff have an obligation to be on Facebook? Still, she's confident she made the right decision. She knows Stuff is just one publisher in a small country. BOUCHER: But taking that step and deciding to just give it a go taught us so much and made us think that all our fears that without these platforms, we would just collapse, that was, you know, baseless. BOND: So she thinks it might be time for other media outlets to reconsider their relationship status with Facebook. Shannon Bond, NPR News. NOEL KING, HOST:   The relationship between Facebook and news publishers is very complicated. Many news outlets think they need to be on Facebook in order to reach people, but they've also lost a lot of advertising dollars that now go to Facebook. NPR's Shannon Bond has the story of a publisher that decided to go it alone. And I should note that Facebook is one of NPR's financial supporters. SHANNON BOND, BYLINE: Sinead Boucher is CEO of New Zealand's largest news publisher. And last year during the pandemic, she bought the company for $1. And why a dollar? SINEAD BOUCHER: Well, it was just a nominal fee. Like, I knew that they, you know, in the context of what was happening, would potentially just decide to wind us up. So it was just a punt. BOND: The publisher is called Stuff. It owns the most popular news website in New Zealand and around 50 newspapers. And when the pandemic brought the economy to a halt, Stuff was at risk of shutting down. For Boucher, this was a big moment. BOUCHER: People sometimes said to me, it must be so stressful now owning the company and blah, blah. But it's actually, in a lot of ways, it's been liberating because there is a freedom in being able to make your own decisions for better or worse. BOND: And one of the first decisions she made was to break up with Facebook. Stuff was already wary of the social network, especially after a terrible mass shooting in New Zealand that was livestreamed on Facebook in 2019. So in July 2020, Stuff's newspapers and magazines all hit pause on Facebook. BOUCHER: You know, we still felt uneasy with a lot of the decisions Facebook has made or a lot of the things it turned a blind eye to. BOND: Things like hate speech and misinformation. But this decision was also risky for Stuff. Almost a quarter of its traffic came from social media - mainly Facebook. In fact, Facebook has become such a dominant force in how people get information, some governments are trying to force the social network to pay media outlets for news stories. Boucher says Stuff was bracing for the worst. BOUCHER: We were expecting that it would bring a significant drop in our traffic. That didn't happen. BOND: Traffic from social media did drop, but overall traffic went up in part because 2020 was such a big news year. BOUCHER: If we had remained on Facebook, we might have had another, I don't know, 5% growth. But even if we throttled our growth, it's brought us a lot of positives as well. BOND: Positives like more donations from readers who want to support Stuff. The Facebook pause was supposed to last a few weeks. It's now been more than eight months. But Boucher says it's still an experiment because there are people who rely on Facebook for news, and there's a lot of bad information on there. BOUCHER: And we wonder about the risk of withdrawing journalism from Facebook and what that leaves behind for people to sort of be exposed to, particularly around things like COVID vaccine. BOND: She worries. Does Stuff have an obligation to be on Facebook? Still, she's confident she made the right decision. She knows Stuff is just one publisher in a small country. BOUCHER: But taking that step and deciding to just give it a go taught us so much and made us think that all our fears that without these platforms, we would just collapse, that was, you know, baseless. BOND: So she thinks it might be time for other media outlets to reconsider their relationship status with Facebook. Shannon Bond, NPR News.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-04-04-983895036": {"title": "Seniors Talk About Their New Life On Zoom : NPR", "url": "https://www.npr.org/2021/04/04/983895036/so-deep-and-so-rich-seniors-talk-about-their-new-life-on-zoom", "author": "No author found", "published_date": "2021-04-04", "content": "LULU GARCIA-NAVARRO, HOST:  At this point in the pandemic, many of us are suffering - and how - from Zoom fatigue - many, not all. WNYC's Gwynne Hogan checked in with a group of senior citizens who switch their weekly gathering to Zoom at the start of the pandemic, and now they say they're closer than ever. GWYNNE HOGAN, BYLINE: Last March, I visited a senior center in Manhattan. At that point in a pandemic, we were flying blind. We were elbow-bumping instead of shaking hands but not wearing masks. I rode my bike to the DOROT Center with a lump in my throat, fearing maybe I was an unknowing vector of the virus. UNIDENTIFIED PERSON #1: (Singing) To reach. Guys, we're going to sing. . . HOGAN: But I got there, and there was a crowd of coughing college kids on tour with their a cappella group, performing to the small crowd of seniors. UNIDENTIFIED STUDENTS: (Singing) To reach the unreachable star. HOGAN: I popped in to a memoir writing class. (SOUNDBITE OF KNOCKING)HOGAN: It was a group of about a dozen women. They'd been meeting weekly for a couple of years at that point. I arrived right as the director of the center, Mark Meridy, broke the news. The center was closing. It was March 11, 2020. MARK MERIDY: We need to suspend our on-site programming here at DOROT for a period of time. UNIDENTIFIED PERSON #2: Starting when? MERIDY: Starting today. HOGAN: The news was a blow for the group, especially for Yvonne Rossetti. YVONNE ROSSETTI: I think depression is a killer. UNIDENTIFIED PEOPLE: Yes. ROSSETTI: And certainly, many of us are here because maybe we battle depression, or this place is a lifeboat. UNIDENTIFIED PERSON #3: It is a lifeboat. UNIDENTIFIED PEOPLE: Yes. HOGAN: Over the course of the pandemic, I wondered how these women were doing - if they got sick, if they got better, if they were experiencing that loneliness they'd spoken so fearfully of when I met them that day. I reached back out, and they invited me to their weekly class on Zoom. Hello, everyone. UNIDENTIFIED PEOPLE: Hi. HOGAN: Adellar Greenhill told me about her recollection of that day. ADELLAR GREENHILL: Before we knew about Zoom and what was going to happen, it was like one of those feelings in the pit of your stomach. HOGAN: The women got some coaching on how to log in to Zoom, and the group started reconvening regularly online. GREENHILL: There's an intimacy to Zoom that we never would have anticipated, I don't think. HOGAN: Christine Graf says they were already used to sharing personal details in their writing. CHRISTINE GRAF: And then to meet again in our own homes, it felt good. HOGAN: Many of them did get COVID, and they all survived. But Marsha Cohen says one member of the memoir group got sick with cancer. MARSHA COHEN: She said, I need help finishing my memoir. I'm getting this memoir published. HOGAN: She did get it published right before her death. The group was able to celebrate her life over Zoom. COHEN: We're making that connection every single week, which is great because a lot of us live alone. And, you know, otherwise, we don't connect. SIPRA ROY: We are not disconnected by social distance - rather, I will say, more connected. HOGAN: That was Sipra Roy. I particularly wanted to know what Yvonne Rossetti felt a year into this technological experiment. She says she's on board, too. ROSSETTI: Zoom created a paradigm shift for loneliness. It was like life is normal with this and so deep and so rich with this. HOGAN: Before I left the session, Wendy Handler, who works for the senior center, wanted to add something too. WENDY HANDLER: This group was supposed to end many times along the way. (LAUGHTER)HANDLER: We're so thrilled that you're still here and that this group means as much to you today, if not more, than it did when we met in person. HOGAN: They say they're hoping to convene in the real world someday soon, hopefully in Central Park on a sunny day. For NPR News, I'm Gwynne Hogan in New York. LULU GARCIA-NAVARRO, HOST:   At this point in the pandemic, many of us are suffering - and how - from Zoom fatigue - many, not all. WNYC's Gwynne Hogan checked in with a group of senior citizens who switch their weekly gathering to Zoom at the start of the pandemic, and now they say they're closer than ever. GWYNNE HOGAN, BYLINE: Last March, I visited a senior center in Manhattan. At that point in a pandemic, we were flying blind. We were elbow-bumping instead of shaking hands but not wearing masks. I rode my bike to the DOROT Center with a lump in my throat, fearing maybe I was an unknowing vector of the virus. UNIDENTIFIED PERSON #1: (Singing) To reach. Guys, we're going to sing. . . HOGAN: But I got there, and there was a crowd of coughing college kids on tour with their a cappella group, performing to the small crowd of seniors. UNIDENTIFIED STUDENTS: (Singing) To reach the unreachable star. HOGAN: I popped in to a memoir writing class. (SOUNDBITE OF KNOCKING) HOGAN: It was a group of about a dozen women. They'd been meeting weekly for a couple of years at that point. I arrived right as the director of the center, Mark Meridy, broke the news. The center was closing. It was March 11, 2020. MARK MERIDY: We need to suspend our on-site programming here at DOROT for a period of time. UNIDENTIFIED PERSON #2: Starting when? MERIDY: Starting today. HOGAN: The news was a blow for the group, especially for Yvonne Rossetti. YVONNE ROSSETTI: I think depression is a killer. UNIDENTIFIED PEOPLE: Yes. ROSSETTI: And certainly, many of us are here because maybe we battle depression, or this place is a lifeboat. UNIDENTIFIED PERSON #3: It is a lifeboat. UNIDENTIFIED PEOPLE: Yes. HOGAN: Over the course of the pandemic, I wondered how these women were doing - if they got sick, if they got better, if they were experiencing that loneliness they'd spoken so fearfully of when I met them that day. I reached back out, and they invited me to their weekly class on Zoom. Hello, everyone. UNIDENTIFIED PEOPLE: Hi. HOGAN: Adellar Greenhill told me about her recollection of that day. ADELLAR GREENHILL: Before we knew about Zoom and what was going to happen, it was like one of those feelings in the pit of your stomach. HOGAN: The women got some coaching on how to log in to Zoom, and the group started reconvening regularly online. GREENHILL: There's an intimacy to Zoom that we never would have anticipated, I don't think. HOGAN: Christine Graf says they were already used to sharing personal details in their writing. CHRISTINE GRAF: And then to meet again in our own homes, it felt good. HOGAN: Many of them did get COVID, and they all survived. But Marsha Cohen says one member of the memoir group got sick with cancer. MARSHA COHEN: She said, I need help finishing my memoir. I'm getting this memoir published. HOGAN: She did get it published right before her death. The group was able to celebrate her life over Zoom. COHEN: We're making that connection every single week, which is great because a lot of us live alone. And, you know, otherwise, we don't connect. SIPRA ROY: We are not disconnected by social distance - rather, I will say, more connected. HOGAN: That was Sipra Roy. I particularly wanted to know what Yvonne Rossetti felt a year into this technological experiment. She says she's on board, too. ROSSETTI: Zoom created a paradigm shift for loneliness. It was like life is normal with this and so deep and so rich with this. HOGAN: Before I left the session, Wendy Handler, who works for the senior center, wanted to add something too. WENDY HANDLER: This group was supposed to end many times along the way. (LAUGHTER) HANDLER: We're so thrilled that you're still here and that this group means as much to you today, if not more, than it did when we met in person. HOGAN: They say they're hoping to convene in the real world someday soon, hopefully in Central Park on a sunny day. For NPR News, I'm Gwynne Hogan in New York.", "section": "The Coronavirus Crisis", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-04-05-984527969": {"title": "A Broadband Expansion Brought Fiber To His Driveway In Idaho \u2014 Then The Money Ran Out : NPR", "url": "https://www.npr.org/2021/04/05/984527969/a-broadband-expansion-brought-fiber-to-his-driveway-in-idaho-then-the-money-ran", "author": "No author found", "published_date": "2021-04-05", "content": "AILSA CHANG, HOST:  The pandemic has brought an unexpected boom to parts of rural America that have been struggling for years. Suddenly, people are fleeing cities for quieter, smaller towns because they can work from basically anywhere. Now rural leaders are trying to figure out how this Zoom boom could bring permanent economic benefits. NPR's Kirk Siegler reports. KIRK SIEGLER, BYLINE: The pandemic accelerated a plan Matthew Stoehr had been dreaming of for years - relocating from his crowded Southern California neighborhood to a home he bought in the Idaho mountains. MATTHEW STOEHR: For me, it was a change of lifestyle, pace of life. I still work just as hard up here as I ever did down there. But, you know, now I can walk outside and sit with the turkeys or watch the deer. SIEGLER: In jeans and pullover sweater, Stoehr just wrapped a conference call in his yard. His home office is up a winding mountain road past some shuttered sawmills near the old timber town of Orofino, Idaho. He's the chief technology officer for a large real estate company in California. STOEHR: I went back once. I had an apartment down there, and I moved out. I think it was last September I did that. SIEGLER: And he's not alone. STOEHR: Might not be able to hear it on the microphone, but we can hear the heavy machinery logging over there. That means that somebody is clearing trees to build a house. SIEGLER: Small towns that were built on extractive industries and farming have been steadily losing population, in part due to automation. Pre-pandemic, rural America tried for years to lure new people like Stoehr to relocate businesses or just work remotely because the Internet is finally better. Idaho's Governor Brad Little started thinking big after a recent visit to Orofino promoting broadband expansion. (SOUNDBITE OF ARCHIVED RECORDING)BRAD LITTLE: Obviously, one of the things we need to do is have more smart growth in housing in the right areas. SIEGLER: Speaking at the virtual Idaho Press Club, Little suggested that one fix for the housing crisis in cities is to encourage more Americans to move out to small towns like Orofino. (SOUNDBITE OF ARCHIVED RECORDING)LITTLE: As we work on our quest for more broadband and better roads, that means that that growth can be dispersed out into areas, particularly areas that have had a dislocation, that have lost a major employer. SIEGLER: Just a few years ago, Orofino lost two timber mills. The town's boosters have worked to diversify, attracting new firearms and outdoor sports manufacturers while touting the world-class trout fishing here on the Clearwater River. (SOUNDBITE OF WATER RUSHING)SIEGLER: It's paid off during the pandemic, maybe too much. CHRIS ST GERMAINE: Oh, gosh, it's been crazy here. We've seen more different kinds of license plates in Clearwater County over the last year than in the last 31 years of living here. SIEGLER: Chris St. Germaine runs Clearwater County's one-person economic development office. She says there are now bidding wars for homes, and locals are getting priced out. ST GERMAINE: We're an aging or graying community, and the influx of younger families and younger people is something we should all celebrate. SIEGLER: But she says in order for the governor's idea to work, towns like this will also have to offer more amenities and services so newcomers stay and spend their money locally. St. Germaine works exhaustively to get federal money to expand broadband. Now, it can still be a battle to get online when you're just outside of town, which is where most people want to move. ST GERMAINE: People think that they can telecommute from rural places, and they buy property without really investigating what the Internet capacity is at that place. And then they come to me and say, is there a space in town I can rent from? Can I use your connectivity for this very important meeting? SIEGLER: A recent federal grant expanded fibers several miles up the canyon from Orofino toward Matthew Stoehr's place, actually almost to his driveway. Then the money ran out. STOEHR: And then there's our phone box that it would connect to. So you're looking at 50 feet. SIEGLER: So Stoehr still uses satellite Internet, which is spotty. But it's a trade-off, though he's not sure everyone is as committed to staying in rural America as he is. STOEHR: Everybody is leaving because, oh, my gosh, it was horrible with the pandemic in the cities and everything. And then they're going to move out here, and then they're going to say, well, this isn't - you know, I can't go down the street to Trader Joe's, or I can't - you know, there's no Starbucks in our town. SIEGLER: Stoehr has considered buying some real estate down in town to help the local economy grow. Boosters see opportunity for a craft brewery or maybe new bistro to keep newcomers here after the pandemic ends. Kirk Siegler, NPR News, Orofino, Idaho. (SOUNDBITE OF ST. VINCENT SONG, \"HUEY NEWTON\") AILSA CHANG, HOST:   The pandemic has brought an unexpected boom to parts of rural America that have been struggling for years. Suddenly, people are fleeing cities for quieter, smaller towns because they can work from basically anywhere. Now rural leaders are trying to figure out how this Zoom boom could bring permanent economic benefits. NPR's Kirk Siegler reports. KIRK SIEGLER, BYLINE: The pandemic accelerated a plan Matthew Stoehr had been dreaming of for years - relocating from his crowded Southern California neighborhood to a home he bought in the Idaho mountains. MATTHEW STOEHR: For me, it was a change of lifestyle, pace of life. I still work just as hard up here as I ever did down there. But, you know, now I can walk outside and sit with the turkeys or watch the deer. SIEGLER: In jeans and pullover sweater, Stoehr just wrapped a conference call in his yard. His home office is up a winding mountain road past some shuttered sawmills near the old timber town of Orofino, Idaho. He's the chief technology officer for a large real estate company in California. STOEHR: I went back once. I had an apartment down there, and I moved out. I think it was last September I did that. SIEGLER: And he's not alone. STOEHR: Might not be able to hear it on the microphone, but we can hear the heavy machinery logging over there. That means that somebody is clearing trees to build a house. SIEGLER: Small towns that were built on extractive industries and farming have been steadily losing population, in part due to automation. Pre-pandemic, rural America tried for years to lure new people like Stoehr to relocate businesses or just work remotely because the Internet is finally better. Idaho's Governor Brad Little started thinking big after a recent visit to Orofino promoting broadband expansion. (SOUNDBITE OF ARCHIVED RECORDING) BRAD LITTLE: Obviously, one of the things we need to do is have more smart growth in housing in the right areas. SIEGLER: Speaking at the virtual Idaho Press Club, Little suggested that one fix for the housing crisis in cities is to encourage more Americans to move out to small towns like Orofino. (SOUNDBITE OF ARCHIVED RECORDING) LITTLE: As we work on our quest for more broadband and better roads, that means that that growth can be dispersed out into areas, particularly areas that have had a dislocation, that have lost a major employer. SIEGLER: Just a few years ago, Orofino lost two timber mills. The town's boosters have worked to diversify, attracting new firearms and outdoor sports manufacturers while touting the world-class trout fishing here on the Clearwater River. (SOUNDBITE OF WATER RUSHING) SIEGLER: It's paid off during the pandemic, maybe too much. CHRIS ST GERMAINE: Oh, gosh, it's been crazy here. We've seen more different kinds of license plates in Clearwater County over the last year than in the last 31 years of living here. SIEGLER: Chris St. Germaine runs Clearwater County's one-person economic development office. She says there are now bidding wars for homes, and locals are getting priced out. ST GERMAINE: We're an aging or graying community, and the influx of younger families and younger people is something we should all celebrate. SIEGLER: But she says in order for the governor's idea to work, towns like this will also have to offer more amenities and services so newcomers stay and spend their money locally. St. Germaine works exhaustively to get federal money to expand broadband. Now, it can still be a battle to get online when you're just outside of town, which is where most people want to move. ST GERMAINE: People think that they can telecommute from rural places, and they buy property without really investigating what the Internet capacity is at that place. And then they come to me and say, is there a space in town I can rent from? Can I use your connectivity for this very important meeting? SIEGLER: A recent federal grant expanded fibers several miles up the canyon from Orofino toward Matthew Stoehr's place, actually almost to his driveway. Then the money ran out. STOEHR: And then there's our phone box that it would connect to. So you're looking at 50 feet. SIEGLER: So Stoehr still uses satellite Internet, which is spotty. But it's a trade-off, though he's not sure everyone is as committed to staying in rural America as he is. STOEHR: Everybody is leaving because, oh, my gosh, it was horrible with the pandemic in the cities and everything. And then they're going to move out here, and then they're going to say, well, this isn't - you know, I can't go down the street to Trader Joe's, or I can't - you know, there's no Starbucks in our town. SIEGLER: Stoehr has considered buying some real estate down in town to help the local economy grow. Boosters see opportunity for a craft brewery or maybe new bistro to keep newcomers here after the pandemic ends. Kirk Siegler, NPR News, Orofino, Idaho. (SOUNDBITE OF ST. VINCENT SONG, \"HUEY NEWTON\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-04-05-984442325": {"title": "Supreme Court Hands Google A Win Over Oracle In Multibillion-Dollar Case : NPR", "url": "https://www.npr.org/2021/04/05/984442325/supreme-court-hands-google-a-win-over-oracle-in-multibillion-dollar-case", "author": "No author found", "published_date": "2021-04-05", "content": "", "section": "Law", "disclaimer": ""}, "2021-04-05-983855753": {"title": "Discord Says It Banned More Than 2,000 Extremist Communities  : NPR", "url": "https://www.npr.org/2021/04/05/983855753/group-chat-app-discord-says-it-banned-more-than-2-000-extremist-communities", "author": "No author found", "published_date": "2021-04-05", "content": "", "section": "Technology", "disclaimer": ""}, "2021-04-05-984440891": {"title": "Justice Clarence Thomas Takes Aim At Tech And Its Power 'To Cut Off Speech' : NPR", "url": "https://www.npr.org/2021/04/05/984440891/justice-clarence-thomas-takes-aims-at-tech-and-its-power-to-cut-off-speech", "author": "No author found", "published_date": "2021-04-05", "content": "NOEL KING, HOST:  Congress has lately been weighing how much power tech companies should have. A member of the Supreme Court has now spoken. Justice Clarence Thomas yesterday criticized Twitter for banning former President Donald Trump, and he wrote that social media companies should lose decades-old legal protections. Here's NPR's Bobby Allyn. BOBBY ALLYN, BYLINE: Justice Clarence Thomas' words are ricocheting around Silicon Valley. He wrote that the ability to, quote, \"cut off speech\" lies most powerfully in the hands of digital platforms. Tech companies' power is a, quote, \"glaring concern,\" he wrote. He says the dominance of companies like Google and Facebook make them more similar to a telephone or railroad company, like a public utility. It shows that at least one Supreme Court justice is open to taking away the tech industry's legal protections. JEFF KOSSEFF: It is an invitation for plaintiffs' lawyers to bring cases challenging Section 230. ALLYN: That's legal scholar Jeff Kosseff. He wrote a book called \"The Twenty-Six Words That Created The Internet. \" It's about the tech law Thomas is attacking known as Section 230. KOSSEFF: I would not be surprised if we would start seeing more states passing laws that attempt to regulate content moderation. ALLYN: Section 230 is part of a 1996 law that does two things. First, it shields the tech industry from being sued over what people post on the Internet. And secondly, it allows the companies to patrol their own sites. KOSSEFF: They get rid of a lot of garbage. I mean, there's a lot of stuff we don't see and we're happy that we don't see when we go online. ALLYN: Kosseff says if social media companies lost that power, the Internet would be overwhelmed with even more garbage than what exists there now. Some lawmakers in Washington want to completely rewrite this law. Thomas' comments were striking because it came in a case that had nothing to do with Section 230. Instead, a lower court found it unconstitutional for former President Trump to block his critics on Twitter. Since Trump is no longer in office and banned on Twitter, the Supreme Court ruled the case is dead (ph). The Knight First Amendment Institute at Columbia University brought the case. Jameel Jaffer with the institute says politicians can still be sued for blocking critics on social media. JAMEEL JAFFER: So, you know, I think public officials are and should be on notice that if they block people from their social media accounts on the basis of viewpoint, they're violating the First Amendment. ALLYN: Jaffer says Section 230 is clearly on Thomas' mind. But he also noted that Thomas' opinion was not cosigned by any other conservative justice. Bobby Allyn, NPR News, San Francisco. (SOUNDBITE OF NEIL COWLEY'S \"BEAT INFINITUM\") NOEL KING, HOST:   Congress has lately been weighing how much power tech companies should have. A member of the Supreme Court has now spoken. Justice Clarence Thomas yesterday criticized Twitter for banning former President Donald Trump, and he wrote that social media companies should lose decades-old legal protections. Here's NPR's Bobby Allyn. BOBBY ALLYN, BYLINE: Justice Clarence Thomas' words are ricocheting around Silicon Valley. He wrote that the ability to, quote, \"cut off speech\" lies most powerfully in the hands of digital platforms. Tech companies' power is a, quote, \"glaring concern,\" he wrote. He says the dominance of companies like Google and Facebook make them more similar to a telephone or railroad company, like a public utility. It shows that at least one Supreme Court justice is open to taking away the tech industry's legal protections. JEFF KOSSEFF: It is an invitation for plaintiffs' lawyers to bring cases challenging Section 230. ALLYN: That's legal scholar Jeff Kosseff. He wrote a book called \"The Twenty-Six Words That Created The Internet. \" It's about the tech law Thomas is attacking known as Section 230. KOSSEFF: I would not be surprised if we would start seeing more states passing laws that attempt to regulate content moderation. ALLYN: Section 230 is part of a 1996 law that does two things. First, it shields the tech industry from being sued over what people post on the Internet. And secondly, it allows the companies to patrol their own sites. KOSSEFF: They get rid of a lot of garbage. I mean, there's a lot of stuff we don't see and we're happy that we don't see when we go online. ALLYN: Kosseff says if social media companies lost that power, the Internet would be overwhelmed with even more garbage than what exists there now. Some lawmakers in Washington want to completely rewrite this law. Thomas' comments were striking because it came in a case that had nothing to do with Section 230. Instead, a lower court found it unconstitutional for former President Trump to block his critics on Twitter. Since Trump is no longer in office and banned on Twitter, the Supreme Court ruled the case is dead (ph). The Knight First Amendment Institute at Columbia University brought the case. Jameel Jaffer with the institute says politicians can still be sued for blocking critics on social media. JAMEEL JAFFER: So, you know, I think public officials are and should be on notice that if they block people from their social media accounts on the basis of viewpoint, they're violating the First Amendment. ALLYN: Jaffer says Section 230 is clearly on Thomas' mind. But he also noted that Thomas' opinion was not cosigned by any other conservative justice. Bobby Allyn, NPR News, San Francisco. (SOUNDBITE OF NEIL COWLEY'S \"BEAT INFINITUM\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-04-06-983872116": {"title": "After A Major Hack, U.S. Looks To Fix A Cyber 'Blind Spot'  : NPR", "url": "https://www.npr.org/2021/04/06/983872116/after-a-major-hack-u-s-looks-to-fix-a-cyber-blind-spot", "author": "No author found", "published_date": "2021-04-06", "content": "STEVE INSKEEP, HOST:  U. S. intelligence agencies operate under two sets of laws. One set of U. S. laws covers how they can monitor people overseas; another set sharply limits what they can do inside the United States and also how they monitor U. S. persons - that's U. S. citizens and other residents, wherever they may be in the world. This division is meant to protect Americans' rights, but the Internet has a way of fudging borders. And cyber experts say Russian hackers exploit the different U. S. laws when they disguise where a hack is coming from. NPR's Greg Myre explains. GREG MYRE, BYLINE: The National Security Agency considers itself the world's most formidable cyber power. But there's a catch. By law, the NSA collects intelligence abroad and not inside the U. S. U. S. rivals like Russia know this and take advantage of it. The head of the NSA, General Paul Nakasone, laid it out recently to a Senate committee. (SOUNDBITE OF ARCHIVED RECORDING)PAUL NAKASONE: We may see what is occurring outside of the United States, but when it comes into the United States, our adversaries are moving very quickly. They understand the laws. And so they are utilizing our own infrastructure, our own Internet service providers, to create these intrusions. MYRE: Last year, hackers stealthily placed malware on a software update produced by the Texas company SolarWinds. No one had reason to be suspicious or the legal authority to monitor as that software went from SolarWinds to 18,000 organizations, including U. S. government agencies. General Nakasone explains. (SOUNDBITE OF ARCHIVED RECORDING)NAKASONE: It's not the fact that we can't connect the dots; we can't see all of the dots. MYRE: Glenn Gerstell was the NSA's top lawyer until he stepped down a year ago. He says the hackers, widely believed to be Russia's foreign intelligence service, further covered their tracks by deceiving another U. S. company. GLENN GERSTELL: The Russians rented a computer server capability on a network-hosting company called GoDaddy. Just like I can go buy a website on GoDaddy, so too can the Russians. MYRE: This meant that even if U. S. cybersecurity teams suspected something amiss, the breadcrumbs weren't leading back to Russia. GERSTELL: Someone looking at their computer in the United States to see whether it was doing anything funny, all they would see is traffic communications to and from a point from their computer to another computer in the United States on GoDaddy, which doesn't look particularly suspicious. MYRE: The hackers rummaged through computer networks for months. It was purely by chance that they were finally detected in December by yet another U. S. company hit in the attack - the California cybersecurity firm FireEye. Kevin Mandia is the CEO. KEVIN MANDIA: We recognized right away. FireEye was one of many victims. MYRE: Here's the larger issue. The Constitution's Fourth Amendment bars the government from domestic surveillance unless a crime is suspected. But in the digital age, these U. S. privacy protections have an unintended consequence - they help hide foreign intelligence agencies conducting cyber espionage inside the U. S. This is fueling a debate on how the U. S. government and private companies can protect computer networks and civil liberties. Again, Kevin Mandia. MANDIA: Regardless of the agency chartered with doing it, you will have to have a clearinghouse for intel that's a single point. You just do. I don't care what you call it, but it's got to be private and public-sector thing. MYRE: Glenn Gerstell, the former NSA lawyer, has a similar proposal. GERSTELL: What we can do is create some kind of fusion center whereby the FBI, together with the NSA and Homeland Security, can all pull together their resources, their computers and work together in real time with the private sector. MYRE: But Senator Ron Wyden, an Oregon Democrat, is a skeptic. (SOUNDBITE OF ARCHIVED RECORDING)RON WYDEN: My view is that message leads to privacy-violating laws and billions of more taxpayer funds for cybersecurity. MYRE: He spoke during a recent hearing of the Senate Intelligence Committee. (SOUNDBITE OF ARCHIVED RECORDING)WYDEN: There are concrete ways for the government to improve its ability to identify hackers without resorting to warrantless monitoring of the domestic Internet. MYRE: The Biden administration says it's working on ways for the government and the tech industry to better share critical information. The White House stresses it's not currently seeking increased legal authority for domestic digital surveillance. Greg Myre, NPR News, Washington. STEVE INSKEEP, HOST:   U. S. intelligence agencies operate under two sets of laws. One set of U. S. laws covers how they can monitor people overseas; another set sharply limits what they can do inside the United States and also how they monitor U. S. persons - that's U. S. citizens and other residents, wherever they may be in the world. This division is meant to protect Americans' rights, but the Internet has a way of fudging borders. And cyber experts say Russian hackers exploit the different U. S. laws when they disguise where a hack is coming from. NPR's Greg Myre explains. GREG MYRE, BYLINE: The National Security Agency considers itself the world's most formidable cyber power. But there's a catch. By law, the NSA collects intelligence abroad and not inside the U. S. U. S. rivals like Russia know this and take advantage of it. The head of the NSA, General Paul Nakasone, laid it out recently to a Senate committee. (SOUNDBITE OF ARCHIVED RECORDING) PAUL NAKASONE: We may see what is occurring outside of the United States, but when it comes into the United States, our adversaries are moving very quickly. They understand the laws. And so they are utilizing our own infrastructure, our own Internet service providers, to create these intrusions. MYRE: Last year, hackers stealthily placed malware on a software update produced by the Texas company SolarWinds. No one had reason to be suspicious or the legal authority to monitor as that software went from SolarWinds to 18,000 organizations, including U. S. government agencies. General Nakasone explains. (SOUNDBITE OF ARCHIVED RECORDING) NAKASONE: It's not the fact that we can't connect the dots; we can't see all of the dots. MYRE: Glenn Gerstell was the NSA's top lawyer until he stepped down a year ago. He says the hackers, widely believed to be Russia's foreign intelligence service, further covered their tracks by deceiving another U. S. company. GLENN GERSTELL: The Russians rented a computer server capability on a network-hosting company called GoDaddy. Just like I can go buy a website on GoDaddy, so too can the Russians. MYRE: This meant that even if U. S. cybersecurity teams suspected something amiss, the breadcrumbs weren't leading back to Russia. GERSTELL: Someone looking at their computer in the United States to see whether it was doing anything funny, all they would see is traffic communications to and from a point from their computer to another computer in the United States on GoDaddy, which doesn't look particularly suspicious. MYRE: The hackers rummaged through computer networks for months. It was purely by chance that they were finally detected in December by yet another U. S. company hit in the attack - the California cybersecurity firm FireEye. Kevin Mandia is the CEO. KEVIN MANDIA: We recognized right away. FireEye was one of many victims. MYRE: Here's the larger issue. The Constitution's Fourth Amendment bars the government from domestic surveillance unless a crime is suspected. But in the digital age, these U. S. privacy protections have an unintended consequence - they help hide foreign intelligence agencies conducting cyber espionage inside the U. S. This is fueling a debate on how the U. S. government and private companies can protect computer networks and civil liberties. Again, Kevin Mandia. MANDIA: Regardless of the agency chartered with doing it, you will have to have a clearinghouse for intel that's a single point. You just do. I don't care what you call it, but it's got to be private and public-sector thing. MYRE: Glenn Gerstell, the former NSA lawyer, has a similar proposal. GERSTELL: What we can do is create some kind of fusion center whereby the FBI, together with the NSA and Homeland Security, can all pull together their resources, their computers and work together in real time with the private sector. MYRE: But Senator Ron Wyden, an Oregon Democrat, is a skeptic. (SOUNDBITE OF ARCHIVED RECORDING) RON WYDEN: My view is that message leads to privacy-violating laws and billions of more taxpayer funds for cybersecurity. MYRE: He spoke during a recent hearing of the Senate Intelligence Committee. (SOUNDBITE OF ARCHIVED RECORDING) WYDEN: There are concrete ways for the government to improve its ability to identify hackers without resorting to warrantless monitoring of the domestic Internet. MYRE: The Biden administration says it's working on ways for the government and the tech industry to better share critical information. The White House stresses it's not currently seeking increased legal authority for domestic digital surveillance. Greg Myre, NPR News, Washington.", "section": "National Security", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-04-07-984537466": {"title": "Game Review: 'Disco Elysium: The Final Cut ' : NPR", "url": "https://www.npr.org/2021/04/07/984537466/disco-elysium-the-final-cut-is-a-grimly-gorgeous-genre-bender", "author": "No author found", "published_date": "2021-04-07", "content": "", "section": "Gaming", "disclaimer": ""}, "2021-04-08-985498425": {"title": "Amazon Union Vote Count: What We Know So Far : NPR", "url": "https://www.npr.org/2021/04/08/985498425/amazon-union-election-no-votes-outnumber-yes-votes-at-end-of-1st-day-of-counting", "author": "No author found", "published_date": "2021-04-08", "content": "", "section": "Business", "disclaimer": ""}, "2021-04-08-985400141": {"title": "What Is A Vaccine 'Passport,' And What Are These Credentials Used For? : NPR", "url": "https://www.npr.org/2021/04/08/985400141/faq-what-is-a-vaccine-passport-and-what-are-these-credentials-used-for", "author": "No author found", "published_date": "2021-04-08", "content": "", "section": "The Coronavirus Crisis", "disclaimer": ""}, "2021-04-08-985306190": {"title": "Amazon Union Vote Count In Alabama: Why Is It Taking So Long? : NPR", "url": "https://www.npr.org/2021/04/08/985306190/why-is-the-amazon-union-vote-count-taking-so-long", "author": "No author found", "published_date": "2021-04-08", "content": "", "section": "Business", "disclaimer": ""}, "2021-04-08-985143101": {"title": "'Stop Lying': Muslim Rights Group Sues Facebook Over Claims It Removes Hate Groups : NPR", "url": "https://www.npr.org/2021/04/08/985143101/stop-lying-muslim-rights-group-sues-facebook-over-claims-it-removes-hate-groups", "author": "No author found", "published_date": "2021-04-08", "content": "", "section": "Technology", "disclaimer": ""}, "2021-04-09-986005820": {"title": "After Data Breach Exposes 530 Million, Facebook Says It Will Not Notify Users : NPR", "url": "https://www.npr.org/2021/04/09/986005820/after-data-breach-exposes-530-million-facebook-says-it-will-not-notify-users", "author": "No author found", "published_date": "2021-04-09", "content": "", "section": "Technology", "disclaimer": ""}, "2021-04-09-982139494": {"title": "No Amazon Union: Alabama Warehouse Workers Vote Against Unionizing : NPR", "url": "https://www.npr.org/2021/04/09/982139494/its-a-no-amazon-warehouse-workers-vote-against-unionizing-in-historic-election", "author": "No author found", "published_date": "2021-04-09", "content": "STEVE INSKEEP, HOST:  Workers at an Amazon warehouse in Alabama will not be negotiating their work terms through a union. In a historic election, the workers voted heavily against unionizing. The vote tally ended just minutes ago, and NPR's Alina Selyukh has been covering this story. Hey there, Alina. ALINA SELYUKH, BYLINE: Hello, hello. INSKEEP: First, I want to understand why the union vote at a single warehouse in Alabama would be considered historic at all. What kind of warehouse is this? SELYUKH: Right. So this warehouse is one of many, many, many warehouses of this kind that Amazon has around the country and around the world. It's really large, extraordinarily large. A total of 5,800, a little over 5,800, people work at this warehouse. INSKEEP: Wow. SELYUKH: And it's, you know, where all of that packing and repacking and opening of boxes happens. Trucks pull in at all hours of day and night, and workers hustle to get your packages ready to ship them to you. And the reason this warehouse was so highly watched is because this is the first union vote in - at Amazon in years, and this was potentially looking to be the first unionized warehouse for Amazon in the country, which didn't go that way. INSKEEP: Wow. And - yeah, and you can see why - thousands of people at this one facility and, if it were to succeed, it might spread to other facilities. So what was the vote tally? SELYUKH: The vote tally, totally, was almost 1,800 votes against unionizing versus a bit over 700 votes in favor of a union. So it was a pretty decisive election. The majority of Amazon's workers in this warehouse in Bessemer, Ala. , voted against joining the Retail, Wholesale and Department Store Union, which means, to reiterate, Amazon has once again withstood a union push. And this was the largest union push among its U. S. workers. And it has avoided the prospect of its first unionized warehouse in the country. INSKEEP: It seems to me that this was greeted nationally with so much interest and excitement among proponents of labor unions that I get the impression that the union movement thought they had a better chance than this. SELYUKH: Well, there were hundreds of workers who had expressed interest in a union. And this unionization effort came together extremely fast. The drive started with a few workers who reached out to a union last summer, and in a matter of months, they had enough cards signed by workers to show enough support for federal labor officials to schedule this election. And, in fact, union leaders said that the vote itself had prompted a massive new wave of interest in labor organizing. They were saying that they were hearing from warehouses across the country, in other facilities and other companies of workers saying, well, Bessemer is voting on this potential Amazon union; what can we do? And so there was this sense of potential watershed moment, and it was a really major labor battle. And it continues - I should say, it continues to be a major labor battle. INSKEEP: Yeah, there'll be the question of whether people try union votes at other places. But is the vote in Bessemer, Ala. , final? Is it over there? SELYUKH: Well, the tally is final. But, of course, now, as I was sort of alluding to it, the union is - the retail union is pursuing legal challenges to this election. They are planning to file charges of unfair labor practices against Amazon. They're requesting a hearing to question some of the actions that Amazon has done during the vote count. They're essentially saying that Amazon had created an atmosphere of confusion, coercion and fear that may have tainted this vote. And so we will be watching how that legal challenge plays out. INSKEEP: Alina, thanks for the update. SELYUKH: Thank you. INSKEEP: NPR's Alina Selyukh. (SOUNDBITE OF MUSIC) STEVE INSKEEP, HOST:   Workers at an Amazon warehouse in Alabama will not be negotiating their work terms through a union. In a historic election, the workers voted heavily against unionizing. The vote tally ended just minutes ago, and NPR's Alina Selyukh has been covering this story. Hey there, Alina. ALINA SELYUKH, BYLINE: Hello, hello. INSKEEP: First, I want to understand why the union vote at a single warehouse in Alabama would be considered historic at all. What kind of warehouse is this? SELYUKH: Right. So this warehouse is one of many, many, many warehouses of this kind that Amazon has around the country and around the world. It's really large, extraordinarily large. A total of 5,800, a little over 5,800, people work at this warehouse. INSKEEP: Wow. SELYUKH: And it's, you know, where all of that packing and repacking and opening of boxes happens. Trucks pull in at all hours of day and night, and workers hustle to get your packages ready to ship them to you. And the reason this warehouse was so highly watched is because this is the first union vote in - at Amazon in years, and this was potentially looking to be the first unionized warehouse for Amazon in the country, which didn't go that way. INSKEEP: Wow. And - yeah, and you can see why - thousands of people at this one facility and, if it were to succeed, it might spread to other facilities. So what was the vote tally? SELYUKH: The vote tally, totally, was almost 1,800 votes against unionizing versus a bit over 700 votes in favor of a union. So it was a pretty decisive election. The majority of Amazon's workers in this warehouse in Bessemer, Ala. , voted against joining the Retail, Wholesale and Department Store Union, which means, to reiterate, Amazon has once again withstood a union push. And this was the largest union push among its U. S. workers. And it has avoided the prospect of its first unionized warehouse in the country. INSKEEP: It seems to me that this was greeted nationally with so much interest and excitement among proponents of labor unions that I get the impression that the union movement thought they had a better chance than this. SELYUKH: Well, there were hundreds of workers who had expressed interest in a union. And this unionization effort came together extremely fast. The drive started with a few workers who reached out to a union last summer, and in a matter of months, they had enough cards signed by workers to show enough support for federal labor officials to schedule this election. And, in fact, union leaders said that the vote itself had prompted a massive new wave of interest in labor organizing. They were saying that they were hearing from warehouses across the country, in other facilities and other companies of workers saying, well, Bessemer is voting on this potential Amazon union; what can we do? And so there was this sense of potential watershed moment, and it was a really major labor battle. And it continues - I should say, it continues to be a major labor battle. INSKEEP: Yeah, there'll be the question of whether people try union votes at other places. But is the vote in Bessemer, Ala. , final? Is it over there? SELYUKH: Well, the tally is final. But, of course, now, as I was sort of alluding to it, the union is - the retail union is pursuing legal challenges to this election. They are planning to file charges of unfair labor practices against Amazon. They're requesting a hearing to question some of the actions that Amazon has done during the vote count. They're essentially saying that Amazon had created an atmosphere of confusion, coercion and fear that may have tainted this vote. And so we will be watching how that legal challenge plays out. INSKEEP: Alina, thanks for the update. SELYUKH: Thank you. INSKEEP: NPR's Alina Selyukh. (SOUNDBITE OF MUSIC)", "section": "Business", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-04-09-984789341": {"title": "Why So Many Asian Americans Are Learning Remotely : NPR", "url": "https://www.npr.org/2021/04/09/984789341/why-so-many-asian-americans-are-learning-remotely", "author": "No author found", "published_date": "2021-04-09", "content": "", "section": "Asian American And Pacific Islander Heritage Month", "disclaimer": ""}, "2021-04-09-985625902": {"title": "Andrew Pelling: How Can Plants Help Rebuild The Human Body? : NPR", "url": "https://www.npr.org/2021/04/09/985625902/andrew-pelling-how-can-plants-help-rebuild-the-human-body", "author": "No author found", "published_date": "2021-04-09", "content": "MANOUSH ZOMORODI, HOST:  On the show today - ideas about revitalizing and rebuilding. And what if all we need to revitalize parts of our bodies is the right tool? ANDREW PELLING: Could we think about biology kind of like hardware? Could I take the pieces I'm interested in and sort of rewire them and put them together physically in different ways? ZOMORODI: This is Andrew Pelling. He's a biophysicist at the University of Ottawa. PELLING: And I run a research lab that creates augmented living biological systems. ZOMORODI: OK, augmented living biological systems - what the heck is that? Can you explain, please? PELLING: (Laughter) So we're really kind of interested in creating living tissues that might not normally be found in nature. We've also discovered ways to heal and regenerate living tissues in the human body. And what my lab has become very well-known for is creating an apple ear. And it's essentially an apple that we carved into the shape of a human ear. We processed it, decellularized it, pulled out all the plant cells and then repopulated it with human cells. ZOMORODI: OK. Wait a minute. Hold up. I just want you to say that one more time. You made an ear that has human cells out of an apple. PELLING: Mmm hmm. ZOMORODI: Can you just back up and explain this to me? PELLING: Yeah. It's a long story. But a lot of us have heard of approaches to biomedicine right now that might involve something called CRISPR or DNA technologies that you might engineer or change our DNA. And that's all really fascinating and very hard work. But my response to that type of effort has always been like, well, can we actually control our cells and tissues without even touching the DNA? So what we needed was a sort of scaffold, sort of a three-dimensional architecture we could grow our cells into. And we had found a way to take plant tissues we find in the grocery store. We can strip out all the plant cells. And all you're left with is this fibrous material, the stuff that gets stuck in your teeth when you're eating a salad or whatever. And that material, cellulose, was the three-dimensional scaffolding we were looking for. And it was really cheap. We could get it in the grocery store, and our cells could grow inside of it. ZOMORODI: OK. Wait, though. So you get an apple, but then how do you make an ear out of it? PELLING: So what we did (laughter) - we had been doing a lot of work with apples. And if you've ever cut an apple in half and looked at it, it does kind of look like two ears side by side, at least to me. And the only person in our orbit that we knew who could carve anything was actually my wife. She's a violin maker. And so I asked her, you know, could you carve me an ear from this piece of apple? And. . . ZOMORODI: So great. PELLING: I have a very loving and patient wife and. . . ZOMORODI: Yes. PELLING: She's kind of used to me at this point, so. . . ZOMORODI: Sure, honey. PELLING: . . . She got to it. I was modeling, and she carved us several ears. And I took them back to the lab. And so now I've got this, like, Tupperware container full of these pieces of apple that look like human ears. And what we do with them is we essentially put them into a large beaker. And inside of the beaker is the solution that we used to pull out all the plant cells. It's like a soap or detergent. And it slowly sort of shakes and spins over several days. It's a slow process to remove all of the cells. But at the end, what you get is - it's almost completely white, and it still holds its shape. It looks like an ear. And this scaffold or this implant, we can then put in a petri dish. We can put cells onto it, and we let them grow. And over time, they'll start to invade inside of the scaffold and fill it up with - as they replicate, and what you end up with is a really nice proof of concept of a plant-based human implant. (SOUNDBITE OF MUSIC)ZOMORODI: What kind of cells do you put into the scaffolding? PELLING: So we can actually put all sorts of cells. We've done work with muscle cells and sort of vascular cells and neurons, and you name it. Over the years, it's become fairly straightforward. You can grow almost anything in there. That's how generalizable it is. ZOMORODI: So you said it's a proof of concept. So tell me what you learned from being able to grow cells like this and why it's not being used to help people yet. PELLING: Well, I hope it will be helping people soon, and that's what we're working on now. That ear was the first proof of concept. It really convinced me and the whole team that what we had wasn't just some goofy, funny discovery but was something that could actually be quite impactful in terms of human health and well-being. And so what has happened since that time is now translating these materials into the clinical space. And we've actually, since that year, been able to demonstrate that not only can we make three-dimensional structural objects but, at least in the case of spinal cord, actually repair spinal cords in small animals. And this is really, really exciting and potentially revolutionary. ZOMORODI: And that brings us to what you're working on right now - right? - to repair spinal cord tissue using not an apple, but another food. PELLING: Yeah. We - it's funny. I was - in the early days, literally, we would go to the grocery store, just buy everything you could see. The lab would look like a farmer's market - like, just bags and bags of produce, and we just - decellularizing everything and throwing cells on them. And in the midst of all this, one day I was at home, and I was cooking asparagus for dinner. I had cut the ends of the asparagus off, and I was sort of looking at the sort of stalk and noticing all of those long capillaries, those little tubes inside the stalk. I started to wonder, you know, could we actually use those conduits as a way to guide neurons back together in the case of spinal cord injury? ZOMORODI: In a minute, more from Andrew Pelling on the extraordinary possibilities of rebuilding the body with produce. On the show today - ideas about revitalization. I'm Manoush Zomorodi, and you're listening to the TED Radio Hour from NPR. It's the TED Radio Hour from NPR. I'm Manoush Zomorodi. On the show today, ideas about revitalization. And before the break, we were talking to Andrew Pelling about his mind-boggling experiments, including a new idea to rebuild human spinal cords with asparagus. PELLING: And this wasn't a totally original idea or anything like that. There's been plenty of work on synthetic materials with tunnels and conduits and all that sort of thing. But again, I was wondering, you know, could it be this simple? Could I just go to the grocery store and find my scaffolding there? And the interesting thing about plant-based biomaterials is they don't break down. They're actually quite stable, long-lasting. So we, again, stripped out all the cells and made some asparagus scaffolds. And then I thought, well, I got to talk to an expert at this point because I'm so far out of my sort of comfort zone at this stage. So I looked around. And one of the top neurosurgeons in Canada happened to be right here in my own city, in Ottawa, and we brought her some scaffolds. And she spent time thinking about this and looking at them. And her first question to me was, can I take these today and use them in a patient? ZOMORODI: What? PELLING: (Laughter) Yeah. I was like, you neuro people are crazier than me, man. Like, this is. . . ZOMORODI: Wow. Yeah. PELLING: One of the problems that she had seen and experienced was that scaffolding that she had used previously had always broken down. And this is what really excited her about what we were proposing, was a scaffold that was long-lasting and stable. And so thankfully, she was willing to collaborate and helped us sort of design some preliminary animal studies to first look at, you know, the efficacy of this scaffold in repairing a severe spinal cord injury. ZOMORODI: And so you basically started a study where you put this asparagus implant in some animals with spinal cord injuries, right? And what happened? PELLING: One of the most fascinating things I've ever witnessed in my life started to happen a few weeks after this, about two weeks. The animals that received the implants, they started - they looked like they were having sort of pins and needles in their legs. They were sort of scratching at their rear legs and biting at them. It was like they were gaining some feeling back. And over the course of the next - over the course of about 12 weeks, we watched these animals go from being paralyzed from the waist down to starting to move their legs - so left, right, left, right - and then starting to lift themselves up on their back legs and lift their bellies off the ground. This is a really important step in recovery. And this is also showing that those core muscles are getting activated, the legs are getting activated, healthy cells migrate inside of the scaffold and it really just becomes a living tissue within the body. It becomes something that's kept alive by the heart. And by no means were the animals perfectly walking or anything like that, but this for us was an incredible moment because what seemed like such a far-fetched, you know, idea appeared to actually have legs to it and potentially could impact tens of thousands, if not millions of lives on the planet. And I've never, never expected as a scientist to be involved in something that important. And late last year, we announced that this technology was just designated a breakthrough medical device by the FDA. This is going to dramatically speed up the timeline between when - you know, from going from the bench to eventually to the patient. ZOMORODI: So how do you get to the point where asparagus can actually be a potentially viable therapy for someone who has a spinal cord injury? Like what - walk - like, what does that look like? Is - are we talking five years, 50 years? PELLING: That is a good question. I mean, you know, it's interesting. As I've met and spoken with many people who live with spinal cord injury, you know, walking, of course, is sort of held out as that holy grail. But there are these really just - these things that we take for granted that you lose - you know, the ability to control your bladder, you know, sexual function, scratching an itch, feeling an itch, you know? There are these dramatic - these things that seem small but can have dramatic impacts on human life. Now, the timeline, that's - I think it's difficult for me to give you an answer on that. I mean, we've heard timelines before and been disappointed. So I think we need to be realistic here. But those human trials are about two years down the road from now, but we've got - we still have to meet certain milestones and prove to the FDA that we're ready for that. And that's part of what we're working on every single day now, and it's what keeps me up pretty much all the time, so (laughter). . . ZOMORODI: That's biophysicist Andrew Pelling. You can check out his talks at ted. com. (SOUNDBITE OF MUSIC) MANOUSH ZOMORODI, HOST:   On the show today - ideas about revitalizing and rebuilding. And what if all we need to revitalize parts of our bodies is the right tool? ANDREW PELLING: Could we think about biology kind of like hardware? Could I take the pieces I'm interested in and sort of rewire them and put them together physically in different ways? ZOMORODI: This is Andrew Pelling. He's a biophysicist at the University of Ottawa. PELLING: And I run a research lab that creates augmented living biological systems. ZOMORODI: OK, augmented living biological systems - what the heck is that? Can you explain, please? PELLING: (Laughter) So we're really kind of interested in creating living tissues that might not normally be found in nature. We've also discovered ways to heal and regenerate living tissues in the human body. And what my lab has become very well-known for is creating an apple ear. And it's essentially an apple that we carved into the shape of a human ear. We processed it, decellularized it, pulled out all the plant cells and then repopulated it with human cells. ZOMORODI: OK. Wait a minute. Hold up. I just want you to say that one more time. You made an ear that has human cells out of an apple. PELLING: Mmm hmm. ZOMORODI: Can you just back up and explain this to me? PELLING: Yeah. It's a long story. But a lot of us have heard of approaches to biomedicine right now that might involve something called CRISPR or DNA technologies that you might engineer or change our DNA. And that's all really fascinating and very hard work. But my response to that type of effort has always been like, well, can we actually control our cells and tissues without even touching the DNA? So what we needed was a sort of scaffold, sort of a three-dimensional architecture we could grow our cells into. And we had found a way to take plant tissues we find in the grocery store. We can strip out all the plant cells. And all you're left with is this fibrous material, the stuff that gets stuck in your teeth when you're eating a salad or whatever. And that material, cellulose, was the three-dimensional scaffolding we were looking for. And it was really cheap. We could get it in the grocery store, and our cells could grow inside of it. ZOMORODI: OK. Wait, though. So you get an apple, but then how do you make an ear out of it? PELLING: So what we did (laughter) - we had been doing a lot of work with apples. And if you've ever cut an apple in half and looked at it, it does kind of look like two ears side by side, at least to me. And the only person in our orbit that we knew who could carve anything was actually my wife. She's a violin maker. And so I asked her, you know, could you carve me an ear from this piece of apple? And. . . ZOMORODI: So great. PELLING: I have a very loving and patient wife and. . . ZOMORODI: Yes. PELLING: She's kind of used to me at this point, so. . . ZOMORODI: Sure, honey. PELLING: . . . She got to it. I was modeling, and she carved us several ears. And I took them back to the lab. And so now I've got this, like, Tupperware container full of these pieces of apple that look like human ears. And what we do with them is we essentially put them into a large beaker. And inside of the beaker is the solution that we used to pull out all the plant cells. It's like a soap or detergent. And it slowly sort of shakes and spins over several days. It's a slow process to remove all of the cells. But at the end, what you get is - it's almost completely white, and it still holds its shape. It looks like an ear. And this scaffold or this implant, we can then put in a petri dish. We can put cells onto it, and we let them grow. And over time, they'll start to invade inside of the scaffold and fill it up with - as they replicate, and what you end up with is a really nice proof of concept of a plant-based human implant. (SOUNDBITE OF MUSIC) ZOMORODI: What kind of cells do you put into the scaffolding? PELLING: So we can actually put all sorts of cells. We've done work with muscle cells and sort of vascular cells and neurons, and you name it. Over the years, it's become fairly straightforward. You can grow almost anything in there. That's how generalizable it is. ZOMORODI: So you said it's a proof of concept. So tell me what you learned from being able to grow cells like this and why it's not being used to help people yet. PELLING: Well, I hope it will be helping people soon, and that's what we're working on now. That ear was the first proof of concept. It really convinced me and the whole team that what we had wasn't just some goofy, funny discovery but was something that could actually be quite impactful in terms of human health and well-being. And so what has happened since that time is now translating these materials into the clinical space. And we've actually, since that year, been able to demonstrate that not only can we make three-dimensional structural objects but, at least in the case of spinal cord, actually repair spinal cords in small animals. And this is really, really exciting and potentially revolutionary. ZOMORODI: And that brings us to what you're working on right now - right? - to repair spinal cord tissue using not an apple, but another food. PELLING: Yeah. We - it's funny. I was - in the early days, literally, we would go to the grocery store, just buy everything you could see. The lab would look like a farmer's market - like, just bags and bags of produce, and we just - decellularizing everything and throwing cells on them. And in the midst of all this, one day I was at home, and I was cooking asparagus for dinner. I had cut the ends of the asparagus off, and I was sort of looking at the sort of stalk and noticing all of those long capillaries, those little tubes inside the stalk. I started to wonder, you know, could we actually use those conduits as a way to guide neurons back together in the case of spinal cord injury? ZOMORODI: In a minute, more from Andrew Pelling on the extraordinary possibilities of rebuilding the body with produce. On the show today - ideas about revitalization. I'm Manoush Zomorodi, and you're listening to the TED Radio Hour from NPR. It's the TED Radio Hour from NPR. I'm Manoush Zomorodi. On the show today, ideas about revitalization. And before the break, we were talking to Andrew Pelling about his mind-boggling experiments, including a new idea to rebuild human spinal cords with asparagus. PELLING: And this wasn't a totally original idea or anything like that. There's been plenty of work on synthetic materials with tunnels and conduits and all that sort of thing. But again, I was wondering, you know, could it be this simple? Could I just go to the grocery store and find my scaffolding there? And the interesting thing about plant-based biomaterials is they don't break down. They're actually quite stable, long-lasting. So we, again, stripped out all the cells and made some asparagus scaffolds. And then I thought, well, I got to talk to an expert at this point because I'm so far out of my sort of comfort zone at this stage. So I looked around. And one of the top neurosurgeons in Canada happened to be right here in my own city, in Ottawa, and we brought her some scaffolds. And she spent time thinking about this and looking at them. And her first question to me was, can I take these today and use them in a patient? ZOMORODI: What? PELLING: (Laughter) Yeah. I was like, you neuro people are crazier than me, man. Like, this is. . . ZOMORODI: Wow. Yeah. PELLING: One of the problems that she had seen and experienced was that scaffolding that she had used previously had always broken down. And this is what really excited her about what we were proposing, was a scaffold that was long-lasting and stable. And so thankfully, she was willing to collaborate and helped us sort of design some preliminary animal studies to first look at, you know, the efficacy of this scaffold in repairing a severe spinal cord injury. ZOMORODI: And so you basically started a study where you put this asparagus implant in some animals with spinal cord injuries, right? And what happened? PELLING: One of the most fascinating things I've ever witnessed in my life started to happen a few weeks after this, about two weeks. The animals that received the implants, they started - they looked like they were having sort of pins and needles in their legs. They were sort of scratching at their rear legs and biting at them. It was like they were gaining some feeling back. And over the course of the next - over the course of about 12 weeks, we watched these animals go from being paralyzed from the waist down to starting to move their legs - so left, right, left, right - and then starting to lift themselves up on their back legs and lift their bellies off the ground. This is a really important step in recovery. And this is also showing that those core muscles are getting activated, the legs are getting activated, healthy cells migrate inside of the scaffold and it really just becomes a living tissue within the body. It becomes something that's kept alive by the heart. And by no means were the animals perfectly walking or anything like that, but this for us was an incredible moment because what seemed like such a far-fetched, you know, idea appeared to actually have legs to it and potentially could impact tens of thousands, if not millions of lives on the planet. And I've never, never expected as a scientist to be involved in something that important. And late last year, we announced that this technology was just designated a breakthrough medical device by the FDA. This is going to dramatically speed up the timeline between when - you know, from going from the bench to eventually to the patient. ZOMORODI: So how do you get to the point where asparagus can actually be a potentially viable therapy for someone who has a spinal cord injury? Like what - walk - like, what does that look like? Is - are we talking five years, 50 years? PELLING: That is a good question. I mean, you know, it's interesting. As I've met and spoken with many people who live with spinal cord injury, you know, walking, of course, is sort of held out as that holy grail. But there are these really just - these things that we take for granted that you lose - you know, the ability to control your bladder, you know, sexual function, scratching an itch, feeling an itch, you know? There are these dramatic - these things that seem small but can have dramatic impacts on human life. Now, the timeline, that's - I think it's difficult for me to give you an answer on that. I mean, we've heard timelines before and been disappointed. So I think we need to be realistic here. But those human trials are about two years down the road from now, but we've got - we still have to meet certain milestones and prove to the FDA that we're ready for that. And that's part of what we're working on every single day now, and it's what keeps me up pretty much all the time, so (laughter). . . ZOMORODI: That's biophysicist Andrew Pelling. You can check out his talks at ted. com. (SOUNDBITE OF MUSIC)", "section": "TED Radio Hour", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-04-09-982776102": {"title": "'Can You Hear Me?' The Annoyances That Lead To Zoom Burnout : NPR", "url": "https://www.npr.org/2021/04/09/982776102/zoom-burnout-is-real-how-to-escape-the-rut", "author": "No author found", "published_date": "2021-04-09", "content": "", "section": "Technology", "disclaimer": ""}, "2021-04-11-986203233": {"title": "How Yahoo! Answers Shaped The Internet : NPR", "url": "https://www.npr.org/2021/04/11/986203233/how-yahoo-answers-shaped-the-internet", "author": "No author found", "published_date": "2021-04-11", "content": "LULU GARCIA-NAVARRO, HOST:  An online corner for curious thinkers, a relic of a bygone Internet, Yahoo says it is shutting down its Q&A forum, Yahoo Answers. JAISHREE KUMAR: Can you boil your earphones? Can you fall in love with a potato? How is baby formed? That was another one. GARCIA-NAVARRO: That's journalist Jaishree Kumar reading some of the site's most popular questions wistfully because Yahoo Answers was a crucial resource for her growing up. KUMAR: There were some questions like, I swallowed a watermelon seed. Am I going to get pregnant? Maybe they were just joking around. But at the age of 11, you probably think that, like, hey, can that happen? Can I end up growing a watermelon baby accidentally? GARCIA-NAVARRO: During her childhood in India, Yahoo Answers was there for Jaishree Kumar when no one else was. KUMAR: To be honest, I think the lack of sex education I had in my own country in my own social settings is sort of tied up with this because I was going to Yahoo Answers to look for like, you know, what would constitute as basic sex education. GARCIA-NAVARRO: News that the website will stop allowing new posts on April 20 and will disappear entirely on May 4 has many former users looking back over these past 16 years for their Yahoo Answers greatest hits. JACQUI LEVITAN: When I was in fifth grade, we had an explorers project, and every person in my class got assigned an explorer. GARCIA-NAVARRO: That's Jacqui Levitan of San Francisco. LEVITAN: I was Juan Rodriguez Cabrillo. And there was another boy in my class who also was Juan Rodriguez Cabrillo, and so I kind of was feeling a little competitive. And I decided I wanted to prank him a little. And so I kept trying to convince him that Cabrillo's favorite color was pink. And he wasn't believing me, and so then I took to Yahoo Answers and posted a question from one account saying, what was Juan Rodriguez Cabrillo's favorite color? - and then went in and answered it with a different account. GARCIA-NAVARRO: She looked it all up. LEVITAN: Answered February 13, 2009. According to most of my research, Cabrillo's favorite color was pink. My name is Catalina Rodriguez, and I am distantly related to Juna Cabrillo. I have done a lot of research about this topic, and it is quite true. GARCIA-NAVARRO: Levitan remembers her poor classmate dressing in pink for his presentation. No word on if points got deducted. MICHAEL DUGAN: The first time I used Yahoo Answers, arguably, was in high school when we had take-home tests that I could copy and paste the test question into Yahoo. GARCIA-NAVARRO: That's Michael Dugan of Atlanta. DUGAN: Funny enough, it was pretty much anything. Like, I'm a chemist now, and I know I definitely used it on some chemistry tests in high school and even college. GARCIA-NAVARRO: Tan Tran says he also relied on Yahoo Answers with a dash of hope. TAN TRAN: The funny thing about Yahoo Answers is you can rank up responses. The highest rated, I pray, is usually the correct one. GARCIA-NAVARRO: Dugan says he saw warning signs, though. DUGAN: Like, when I searched an answer to cheat for a test, you know, you would dive down a rabbit hole, and you'd see some dumb response to a pretty easy question. And you'd always laugh that. LUKE WINKIE: Will my laptop get heavier if I put more files on it? GARCIA-NAVARRO: That's writer Luke Winkie reading an example. He called Yahoo Answers the most earnest place on the Internet. WINKIE: You read it, and you're not sure if it's someone kind of just making a joke, or if it's someone who is genuinely curious about this. GARCIA-NAVARRO: Which is precisely why people like Sophie Armstrong are sad to see it go. SOPHIE ARMSTRONG: I was really hurt when I heard Yahoo Answers was going to close because it has had a incredible cultural impact on the Internet. GARCIA-NAVARRO: Shane Conerty (ph), who runs a meme account called Sad Yahoos, is dedicating the next few weeks to preserving the site's content. SHANE CONERTY: So after May 4, there will be a Yahoo Answers home, I guess, dedicated to the ridiculousness of Yahoo Answers. GARCIA-NAVARRO: And its incredible cultural impact. RIP Yahoo Answers. LULU GARCIA-NAVARRO, HOST:   An online corner for curious thinkers, a relic of a bygone Internet, Yahoo says it is shutting down its Q&A forum, Yahoo Answers. JAISHREE KUMAR: Can you boil your earphones? Can you fall in love with a potato? How is baby formed? That was another one. GARCIA-NAVARRO: That's journalist Jaishree Kumar reading some of the site's most popular questions wistfully because Yahoo Answers was a crucial resource for her growing up. KUMAR: There were some questions like, I swallowed a watermelon seed. Am I going to get pregnant? Maybe they were just joking around. But at the age of 11, you probably think that, like, hey, can that happen? Can I end up growing a watermelon baby accidentally? GARCIA-NAVARRO: During her childhood in India, Yahoo Answers was there for Jaishree Kumar when no one else was. KUMAR: To be honest, I think the lack of sex education I had in my own country in my own social settings is sort of tied up with this because I was going to Yahoo Answers to look for like, you know, what would constitute as basic sex education. GARCIA-NAVARRO: News that the website will stop allowing new posts on April 20 and will disappear entirely on May 4 has many former users looking back over these past 16 years for their Yahoo Answers greatest hits. JACQUI LEVITAN: When I was in fifth grade, we had an explorers project, and every person in my class got assigned an explorer. GARCIA-NAVARRO: That's Jacqui Levitan of San Francisco. LEVITAN: I was Juan Rodriguez Cabrillo. And there was another boy in my class who also was Juan Rodriguez Cabrillo, and so I kind of was feeling a little competitive. And I decided I wanted to prank him a little. And so I kept trying to convince him that Cabrillo's favorite color was pink. And he wasn't believing me, and so then I took to Yahoo Answers and posted a question from one account saying, what was Juan Rodriguez Cabrillo's favorite color? - and then went in and answered it with a different account. GARCIA-NAVARRO: She looked it all up. LEVITAN: Answered February 13, 2009. According to most of my research, Cabrillo's favorite color was pink. My name is Catalina Rodriguez, and I am distantly related to Juna Cabrillo. I have done a lot of research about this topic, and it is quite true. GARCIA-NAVARRO: Levitan remembers her poor classmate dressing in pink for his presentation. No word on if points got deducted. MICHAEL DUGAN: The first time I used Yahoo Answers, arguably, was in high school when we had take-home tests that I could copy and paste the test question into Yahoo. GARCIA-NAVARRO: That's Michael Dugan of Atlanta. DUGAN: Funny enough, it was pretty much anything. Like, I'm a chemist now, and I know I definitely used it on some chemistry tests in high school and even college. GARCIA-NAVARRO: Tan Tran says he also relied on Yahoo Answers with a dash of hope. TAN TRAN: The funny thing about Yahoo Answers is you can rank up responses. The highest rated, I pray, is usually the correct one. GARCIA-NAVARRO: Dugan says he saw warning signs, though. DUGAN: Like, when I searched an answer to cheat for a test, you know, you would dive down a rabbit hole, and you'd see some dumb response to a pretty easy question. And you'd always laugh that. LUKE WINKIE: Will my laptop get heavier if I put more files on it? GARCIA-NAVARRO: That's writer Luke Winkie reading an example. He called Yahoo Answers the most earnest place on the Internet. WINKIE: You read it, and you're not sure if it's someone kind of just making a joke, or if it's someone who is genuinely curious about this. GARCIA-NAVARRO: Which is precisely why people like Sophie Armstrong are sad to see it go. SOPHIE ARMSTRONG: I was really hurt when I heard Yahoo Answers was going to close because it has had a incredible cultural impact on the Internet. GARCIA-NAVARRO: Shane Conerty (ph), who runs a meme account called Sad Yahoos, is dedicating the next few weeks to preserving the site's content. SHANE CONERTY: So after May 4, there will be a Yahoo Answers home, I guess, dedicated to the ridiculousness of Yahoo Answers. GARCIA-NAVARRO: And its incredible cultural impact. RIP Yahoo Answers.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-04-12-986266208": {"title": "Semiconductor Summit Held At White House Amid Shortages : NPR", "url": "https://www.npr.org/2021/04/12/986266208/white-house-convenes-summit-to-address-supply-shortage-crippling-auto-plants", "author": "No author found", "published_date": "2021-04-12", "content": "NOEL KING, HOST:  The auto industry is dealing with a shortage of semiconductors. Those are small computer chips that power your car, your phone, a lot of other stuff you use. Most of them are manufactured in Asia. And because of the shortage, some car factories have stopped producing. The White House is holding a meeting today with executives from dozens of companies. And NPR White House correspondent Scott Detrow is following. Good morning, Scott. SCOTT DETROW, BYLINE: Good morning. KING: So car factories stopping production in some cases. How serious is this? DETROW: Yeah, this is affecting a lot of industries but car - the auto industry the most. Cars are just becoming more and more computerized, like everything else, and demand for cars is really surging right now. There's this huge supply shortage and just not enough semiconductors to go around to make cars. So two more General Motors plants just announced temporary shutdowns because they don't have the materials they need. GM has now paused more than a half-dozen plants. Four Ford plants are temporarily shut down as well, among other automakers. KING: OK, so real impacts. And then the White House is holding this call with industry leaders. What does the White House want to do about it? DETROW: President Biden has already ordered a review looking at what the federal government can do to make sure more semiconductors are manufactured in the U. S. and that the supply chain is more steady because there is the supply issue but also a sustained environment of trade wars and more economic nationalism with China in particular. So today, the White House - officials there are meeting with people from 19 different companies across a wide range of industries to talk about the problem. I interviewed Daleep Singh about this. He's a deputy national security adviser in the administration, also the deputy director of the National Economic Council. And he says the White House knows this is a serious economic problem. And when you look at how many other industries rely on semiconductors, particularly the most high-capacity ones, it's a national security problem, too. DALEEP SINGH: Pharmaceuticals, space but also weapons systems and satellites. So here's the problem - today, 100% - all of the most advanced semiconductors are produced in East Asia. That's a critical vulnerability. DETROW: The administration wants to spend $50 billion to boost domestic manufacturing of semiconductors. And in the president's infrastructure plan, there's a proposal to spend the same amount of money creating a new Commerce Department office to oversee all of this. KING: So is this phone call today about the Biden administration selling the Biden administration's infrastructure plan? DETROW: That is certainly a big part of it. And from the messages we've heard, the White House also seems to be making it clear to these companies that it is ready to intervene. President Biden and his top advisers have centered a lot of policy around the need to make economic interests of middle-class Americans central to both foreign and domestic policy and, just as importantly, to let voters know that they're doing this. And the administration is also taking an active, expansive view of how to use the power of the federal government and making it clear it's comfortable redirecting private industry when they think it's in the national interest. In this case, that would be making sure more semiconductors are manufactured here in the U. S. Singh was really blunt about this in our interview. SINGH: The reality is that at home or abroad, we don't believe - I don't believe the private sector by itself is going to solve the biggest problems we have in our society - and whether it's extreme levels of inequality and social disparity, whether it's an existential climate crisis or people dropping out of the workforce or stagnant wages. DETROW: So that's the mindset the administration is taking to so many issues right now. And you could see it at play in this $2 trillion infrastructure proposal, a lot of areas where it would seek to reshape a lot of different industries. KING: NPR White House correspondent Scott Detrow. Thanks, Scott. DETROW: Thank you. (SOUNDBITE OF MENISCUS' \"FLUX\") NOEL KING, HOST:   The auto industry is dealing with a shortage of semiconductors. Those are small computer chips that power your car, your phone, a lot of other stuff you use. Most of them are manufactured in Asia. And because of the shortage, some car factories have stopped producing. The White House is holding a meeting today with executives from dozens of companies. And NPR White House correspondent Scott Detrow is following. Good morning, Scott. SCOTT DETROW, BYLINE: Good morning. KING: So car factories stopping production in some cases. How serious is this? DETROW: Yeah, this is affecting a lot of industries but car - the auto industry the most. Cars are just becoming more and more computerized, like everything else, and demand for cars is really surging right now. There's this huge supply shortage and just not enough semiconductors to go around to make cars. So two more General Motors plants just announced temporary shutdowns because they don't have the materials they need. GM has now paused more than a half-dozen plants. Four Ford plants are temporarily shut down as well, among other automakers. KING: OK, so real impacts. And then the White House is holding this call with industry leaders. What does the White House want to do about it? DETROW: President Biden has already ordered a review looking at what the federal government can do to make sure more semiconductors are manufactured in the U. S. and that the supply chain is more steady because there is the supply issue but also a sustained environment of trade wars and more economic nationalism with China in particular. So today, the White House - officials there are meeting with people from 19 different companies across a wide range of industries to talk about the problem. I interviewed Daleep Singh about this. He's a deputy national security adviser in the administration, also the deputy director of the National Economic Council. And he says the White House knows this is a serious economic problem. And when you look at how many other industries rely on semiconductors, particularly the most high-capacity ones, it's a national security problem, too. DALEEP SINGH: Pharmaceuticals, space but also weapons systems and satellites. So here's the problem - today, 100% - all of the most advanced semiconductors are produced in East Asia. That's a critical vulnerability. DETROW: The administration wants to spend $50 billion to boost domestic manufacturing of semiconductors. And in the president's infrastructure plan, there's a proposal to spend the same amount of money creating a new Commerce Department office to oversee all of this. KING: So is this phone call today about the Biden administration selling the Biden administration's infrastructure plan? DETROW: That is certainly a big part of it. And from the messages we've heard, the White House also seems to be making it clear to these companies that it is ready to intervene. President Biden and his top advisers have centered a lot of policy around the need to make economic interests of middle-class Americans central to both foreign and domestic policy and, just as importantly, to let voters know that they're doing this. And the administration is also taking an active, expansive view of how to use the power of the federal government and making it clear it's comfortable redirecting private industry when they think it's in the national interest. In this case, that would be making sure more semiconductors are manufactured here in the U. S. Singh was really blunt about this in our interview. SINGH: The reality is that at home or abroad, we don't believe - I don't believe the private sector by itself is going to solve the biggest problems we have in our society - and whether it's extreme levels of inequality and social disparity, whether it's an existential climate crisis or people dropping out of the workforce or stagnant wages. DETROW: So that's the mindset the administration is taking to so many issues right now. And you could see it at play in this $2 trillion infrastructure proposal, a lot of areas where it would seek to reshape a lot of different industries. KING: NPR White House correspondent Scott Detrow. Thanks, Scott. DETROW: Thank you. (SOUNDBITE OF MENISCUS' \"FLUX\")", "section": "Politics", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-04-14-987380900": {"title": "Coinbase, A Bitcoin Startup, Goes Public. Is Crypto Really The 'Future Of Finance'? : NPR", "url": "https://www.npr.org/2021/04/14/987380900/coinbase-a-bitcoin-startup-goes-public-is-crypto-really-the-future-of-finance", "author": "No author found", "published_date": "2021-04-14", "content": "", "section": "Technology", "disclaimer": ""}, "2021-04-14-986982387": {"title": "Falun Gong, Steve Bannon And The Battle Over Internet Freedom Under Trump : NPR", "url": "https://www.npr.org/2021/04/14/986982387/falun-gong-steve-bannon-and-the-trump-era-battle-over-internet-freedom", "author": "No author found", "published_date": "2021-04-14", "content": "", "section": "Investigations", "disclaimer": ""}, "2021-04-15-987182241": {"title": "J&J Vaccine Pause Creates 'Perfect Storm' For Misinformation : NPR", "url": "https://www.npr.org/2021/04/15/987182241/the-most-popular-j-j-vaccine-story-on-facebook-a-conspiracy-theorist-posted-it", "author": "No author found", "published_date": "2021-04-15", "content": "STEVE INSKEEP, HOST:  The Johnson & Johnson COVID vaccine has a very rare side effect. Officials paused the use of the vaccine to study news of blood clots that appeared in fewer out of one out of a million cases. The pause has had a very widespread side effect. It's an occasion for people to spread misinformation and conspiracy theories about vaccines. NPR's Miles Parks is covering that part of the story. Miles, good morning. MILES PARKS, BYLINE: Hey, Steve. INSKEEP: How widespread is this false information? PARKS: I mean, just to set the stage for you a little bit, the most popular link posted about the Johnson & Johnson News on Facebook this week in terms of engagement was not from The New York Times or Fox News or ABC News. All of those news outlets were in the top five. But the top post was from a conspiracy theorist with 1. 5 million Facebook followers who says the pandemic is basically just cover for government control. INSKEEP: Wow. And I guess we're going to get more of that. PARKS: Yeah. Exactly. I mean, it's clear that there is an active network centered around vaccine hesitancy trying to drive this hesitancy. And those people are clearly picking up on this story. I talked to Jennifer Granston, who's head of insights at a media intelligence firm called Zignal Labs. Zignal has seen a number of vaccine misinformation narratives spike in mentions in recent days. JENNIFER GRANSTON: That vaccine conversation is so polarizing. And there's so many eyes on it. And there's so many components of it. This is kind of the perfect storm. PARKS: On Tuesday, Johnson & Johnson was getting as many mentions online per hour as the company was getting mentioned in entire weeks prior to this news. INSKEEP: What makes this particular news story such an appealing moment for conspiracy grifters? PARKS: The biggest thing is that there's what experts call an information deficit right now. The CDC basically said, you know, we're investigating these few reports of blood clots. We're going to talk to doctors about how to deal with these extremely rare cases. And we'll get back to you, you being the public. And that's transparent. And that's true. But it also means there are a lot of open questions that people can exploit to basically say, you want answers right now. We have them. And there isn't good information yet to fill that void. So the longer this sort of waiting period goes on, the more people can jump in and exploit that void. INSKEEP: I just want to note, this information can get people killed. False information about vaccines can literally get people killed. So does any of it break the rules of Facebook or Twitter or any laws? PARKS: Oh, it's a really tough problem because in a lot of cases, this is actually people sharing credible news sources, articles from CNN or The Washington Post or The New York Times. They're just using those factual articles as evidence of a broader, false premise, you know, the idea that the vaccines are inherently unsafe or dangerous. This is a tactic that's emerged over the past year as social media companies have gotten stricter about taking down blatantly false information. The other thing to note here is that these sorts of events would not be such a problem if the country wasn't so polarized by COVID in general. I talked to Sarah Roberts, who's an information studies professor at UCLA. And she put a lot of blame on that on former President Trump. Now, basically, she says any time there's any sort of vaccine hiccup or problem, the government is fighting against all of this really ingrained skepticism and division. SARAH ROBERTS: To call that an uphill battle - I mean, it's like a Mount Everest-sized battle. It's just - uphill is - well, it seems like an understatement. INSKEEP: Is this likely to be eased once the CDC comes up with some kind of answer about J&J? PARKS: It's really going to depend on how effective the government is at cutting through all this noise. One in four Americans still say they don't want to be vaccinated. It's doubtful this news helped. And so that's true even if this news doesn't actually affect the actual safety of the vaccines. INSKEEP: NPR's Miles Parks. Thanks so much. PARKS: Thanks, Steve. STEVE INSKEEP, HOST:   The Johnson & Johnson COVID vaccine has a very rare side effect. Officials paused the use of the vaccine to study news of blood clots that appeared in fewer out of one out of a million cases. The pause has had a very widespread side effect. It's an occasion for people to spread misinformation and conspiracy theories about vaccines. NPR's Miles Parks is covering that part of the story. Miles, good morning. MILES PARKS, BYLINE: Hey, Steve. INSKEEP: How widespread is this false information? PARKS: I mean, just to set the stage for you a little bit, the most popular link posted about the Johnson & Johnson News on Facebook this week in terms of engagement was not from The New York Times or Fox News or ABC News. All of those news outlets were in the top five. But the top post was from a conspiracy theorist with 1. 5 million Facebook followers who says the pandemic is basically just cover for government control. INSKEEP: Wow. And I guess we're going to get more of that. PARKS: Yeah. Exactly. I mean, it's clear that there is an active network centered around vaccine hesitancy trying to drive this hesitancy. And those people are clearly picking up on this story. I talked to Jennifer Granston, who's head of insights at a media intelligence firm called Zignal Labs. Zignal has seen a number of vaccine misinformation narratives spike in mentions in recent days. JENNIFER GRANSTON: That vaccine conversation is so polarizing. And there's so many eyes on it. And there's so many components of it. This is kind of the perfect storm. PARKS: On Tuesday, Johnson & Johnson was getting as many mentions online per hour as the company was getting mentioned in entire weeks prior to this news. INSKEEP: What makes this particular news story such an appealing moment for conspiracy grifters? PARKS: The biggest thing is that there's what experts call an information deficit right now. The CDC basically said, you know, we're investigating these few reports of blood clots. We're going to talk to doctors about how to deal with these extremely rare cases. And we'll get back to you, you being the public. And that's transparent. And that's true. But it also means there are a lot of open questions that people can exploit to basically say, you want answers right now. We have them. And there isn't good information yet to fill that void. So the longer this sort of waiting period goes on, the more people can jump in and exploit that void. INSKEEP: I just want to note, this information can get people killed. False information about vaccines can literally get people killed. So does any of it break the rules of Facebook or Twitter or any laws? PARKS: Oh, it's a really tough problem because in a lot of cases, this is actually people sharing credible news sources, articles from CNN or The Washington Post or The New York Times. They're just using those factual articles as evidence of a broader, false premise, you know, the idea that the vaccines are inherently unsafe or dangerous. This is a tactic that's emerged over the past year as social media companies have gotten stricter about taking down blatantly false information. The other thing to note here is that these sorts of events would not be such a problem if the country wasn't so polarized by COVID in general. I talked to Sarah Roberts, who's an information studies professor at UCLA. And she put a lot of blame on that on former President Trump. Now, basically, she says any time there's any sort of vaccine hiccup or problem, the government is fighting against all of this really ingrained skepticism and division. SARAH ROBERTS: To call that an uphill battle - I mean, it's like a Mount Everest-sized battle. It's just - uphill is - well, it seems like an understatement. INSKEEP: Is this likely to be eased once the CDC comes up with some kind of answer about J&J? PARKS: It's really going to depend on how effective the government is at cutting through all this noise. One in four Americans still say they don't want to be vaccinated. It's doubtful this news helped. And so that's true even if this news doesn't actually affect the actual safety of the vaccines. INSKEEP: NPR's Miles Parks. Thanks so much. PARKS: Thanks, Steve.", "section": "Untangling Disinformation", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-04-16-988200892": {"title": "Here's What 'All Things Considered' Sounds Like \u2014 In Blackbird Song : NPR", "url": "https://www.npr.org/2021/04/16/988200892/heres-what-all-things-considered-sounds-like-in-blackbird-song", "author": "No author found", "published_date": "2021-04-16", "content": "AILSA CHANG, HOST:  While none of us will communicate with birds as well as singer Bobby Day with his \"Rockin' Robin,\" this project just might get you close. Oona Raisanen is a Finnish programmer who built a speech-to-birdsong convertor, and it all started with a dream of a blackbird. OONA RAISANEN: And he was talking in a human voice. And then I slowly woke up, and it was 5 am in the morning. And there was still a blackbird outside, but now it wasn't talking anymore, it was singing. MARY LOUISE KELLY, HOST:  And listening to that song, she perceived an inflection somewhat like human speech. RAISANEN: I think it kind of had a sort of sentence structure in its song. KELLY: As a signal-processing geek, she thought, why not write some computer code to transform speech into birdsong? RAISANEN: Human voice is built up of these simpler tones that are put on top of each other to make vowels and consonants. CHANG: But the tune of many songbirds, while still complicated to produce, often consists of a single harmonic tone rather than layers of harmonics like the human voice. RAISANEN: So if I remove all of those tones from the human voice except for the one, it should become blackbird song. And it did. CHANG: Here's how that sounded with Oona voice. (SOUNDBITE OF ARCHIVED RECORDING)RAISANEN: At the tone, 16 hours, zero minutes. (SOUNDBITE OF BIRDSONG)RAISANEN: I don't think there's any use for it, per se - some silly ideas that I had. Maybe it could be used as a children's toy or - oh, yeah - you could entertain your cats. KELLY: Well, in case you're wondering, no, it does not work the other way around. The tool cannot convert birdsong into human speech, so apologies to all you bird scientists out there. CHANG: Darn. But there is one more application for this technology. We could convert the daily ALL THINGS CONSIDERED broadcast into birdsong. So if I say, hi, I'm Ailsa Chang, and I host ALL THINGS CONSIDERED, this is what that would sound like in birdsong. (SOUNDBITE OF BIRDSONG)CHANG: (Laughter). KELLY: (Laughter) I like it. OK, I'll try. If I say, I'm Mary Louise Kelly, and I also host ALL THINGS CONSIDERED, it would sound like. . . (SOUNDBITE OF BIRDSONG)KELLY: Charming, but it might make it maybe a little too hard to parse the daily news. CHANG: (Laughter). (SOUNDBITE OF SONG, \"ROCKIN' ROBIN\")BOBBY DAY: (Singing) Tweedle-lee-dee-dee. Tweet. Tweet. Tweet. Tweet. He rocks in the tree tops all day long, boppin' and a-boppin' and a-singing his song. All the little birds on Jaybird Street love to hear the robin go tweet tweet tweet. AILSA CHANG, HOST:   While none of us will communicate with birds as well as singer Bobby Day with his \"Rockin' Robin,\" this project just might get you close. Oona Raisanen is a Finnish programmer who built a speech-to-birdsong convertor, and it all started with a dream of a blackbird. OONA RAISANEN: And he was talking in a human voice. And then I slowly woke up, and it was 5 am in the morning. And there was still a blackbird outside, but now it wasn't talking anymore, it was singing. MARY LOUISE KELLY, HOST:   And listening to that song, she perceived an inflection somewhat like human speech. RAISANEN: I think it kind of had a sort of sentence structure in its song. KELLY: As a signal-processing geek, she thought, why not write some computer code to transform speech into birdsong? RAISANEN: Human voice is built up of these simpler tones that are put on top of each other to make vowels and consonants. CHANG: But the tune of many songbirds, while still complicated to produce, often consists of a single harmonic tone rather than layers of harmonics like the human voice. RAISANEN: So if I remove all of those tones from the human voice except for the one, it should become blackbird song. And it did. CHANG: Here's how that sounded with Oona voice. (SOUNDBITE OF ARCHIVED RECORDING) RAISANEN: At the tone, 16 hours, zero minutes. (SOUNDBITE OF BIRDSONG) RAISANEN: I don't think there's any use for it, per se - some silly ideas that I had. Maybe it could be used as a children's toy or - oh, yeah - you could entertain your cats. KELLY: Well, in case you're wondering, no, it does not work the other way around. The tool cannot convert birdsong into human speech, so apologies to all you bird scientists out there. CHANG: Darn. But there is one more application for this technology. We could convert the daily ALL THINGS CONSIDERED broadcast into birdsong. So if I say, hi, I'm Ailsa Chang, and I host ALL THINGS CONSIDERED, this is what that would sound like in birdsong. (SOUNDBITE OF BIRDSONG) CHANG: (Laughter). KELLY: (Laughter) I like it. OK, I'll try. If I say, I'm Mary Louise Kelly, and I also host ALL THINGS CONSIDERED, it would sound like. . . (SOUNDBITE OF BIRDSONG) KELLY: Charming, but it might make it maybe a little too hard to parse the daily news. CHANG: (Laughter). (SOUNDBITE OF SONG, \"ROCKIN' ROBIN\") BOBBY DAY: (Singing) Tweedle-lee-dee-dee. Tweet. Tweet. Tweet. Tweet. He rocks in the tree tops all day long, boppin' and a-boppin' and a-singing his song. All the little birds on Jaybird Street love to hear the robin go tweet tweet tweet.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-04-16-985439655": {"title": "How Russia Used SolarWinds To Hack Microsoft, Intel, Pentagon, Other Networks : NPR", "url": "https://www.npr.org/2021/04/16/985439655/a-worst-nightmare-cyberattack-the-untold-story-of-the-solarwinds-hack", "author": "No author found", "published_date": "2021-04-16", "content": "MARY LOUISE KELLY, HOST:  Late last year, a long-simmering cyber conflict between the United States and Russia broke out into the open. (SOUNDBITE OF MONTAGE)UNIDENTIFIED REPORTER #1: Authorities say the Russians targeted some of America's most sensitive and important computer systems. UNIDENTIFIED REPORTER #2: Hackers breached SolarWinds to infect at least seven U. S. government agencies. UNIDENTIFIED REPORTER #3: Government agencies were caught off guard by an unprecedented attack. KELLY: That's right. Hackers targeted SolarWinds, a Texas software company you'd probably never heard of. But they make a piece of software that is indispensable to thousands of IT departments, including many of the nation's biggest companies and U. S. government institutions. ARI SHAPIRO, HOST:  Russian hackers were able to sneak malicious code into this widely used software, which gave them a vast list of potential targets. NPR investigative correspondent Dina Temple-Raston got an exclusive look inside the sophisticated attack. Here's how it unfolded. DINA TEMPLE-RASTON, BYLINE: The routine software update may be one of the most familiar and least understood parts of our digital lives, but this last spring it became the vehicle to launch an epic cyberattack. Hackers used a software update to slip into some of this country's most sensitive computer networks, which allowed them to take aim not just at the economy but at our national security, too. ALEX STAMOS: I mean, it's one of the most impressive and effective cyberespionage campaigns of all time. TEMPLE-RASTON: Alex Stamos is the director of the Internet Observatory at Stanford University and the former head of security at Facebook. STAMOS: They were able to get access to some very sensitive companies and government organizations without getting caught for quite a while. TEMPLE-RASTON: And when he says quite a while, he means almost a year. And for all that time, the hackers roamed around the networks of companies like Microsoft, Intel and Cisco and government agencies like the Treasury, the Department of Energy and the Pentagon. And the hackers might have kept skulking around those networks were it not for the vigilance of one company - FireEye, which happened to be one of SolarWinds' customers. STAMOS: That's right. I mean, this is - we only know about any of this because they made the mistake of attacking FireEye, which is, like, a professional incident response company. KEVIN MANDIA: You know, us doing investigations is kind of like The Beatles entering a battle of the bands. They're going to do really well in a battle of the bands. We're going to do well investigating. TEMPLE-RASTON: That's Kevin Mandia, FireEye CEO. You're former Air Force intelligence. Is that right? MANDIA: No, I was in what's called the Air Force Office of Special Investigations. I spent from 1996 1998 responding to what I would equate to as the Russian Foreign Intelligence Service. TEMPLE-RASTON: So late last year, when he saw some suspicious activity in his company's network, it felt familiar. The first clue that something was wrong came when the FireEye security team noticed something unusual - someone trying to register a second phone onto the company's network. So they called. MANDIA: And the gentleman said, no, I did not register that phone. So who did? TEMPLE-RASTON: Whoever it was, they were roaming around the network, looking like an employee. MANDIA: It just felt like the breach that I was always worried about. TEMPLE-RASTON: The FireEye security team started tearing apart their servers, looking for the intruder, and it took them weeks to trace the problem back to that SolarWinds software update. And once they were certain that's what it was, they wrote a report and sent it to the head of cybersecurity at SolarWinds, Tim Brown. TIM BROWN: And the report was detailed. The report said, we decompiled your code. We see this malicious code here. We see proof that, yes, we had shipped things that had malicious content inside of it. TEMPLE-RASTON: And what was going through your head? BROWN: You know, it's kind of a nightmare idea for any security person. You know, we deal with little, tiny incidents often. But this had the potential to affect thousands of customers, right? This had the potential to do a great deal of damage. TEMPLE-RASTON: Brown went home, packed a bag and was prepared to stay at the office for the rest of the week. BROWN: I would say Sunday, Monday, we knew that the attack itself and the code that was inserted itself was pretty purposeful. So we quickly understood that the attacker was on a mission. TEMPLE-RASTON: This wasn't just a hacker in a hoodie. This looked like a nation-state. So they brought in someone who knew how to deal with these kinds of attacks. ADAM MEYERS: Hi - Adam Meyers, and I run intel at CrowdStrike. TEMPLE-RASTON: CrowdStrike is a cyber investigation company, and Meyers has helped them unwind some famous hacks - Sony in 2015, the Democratic National Committee a year later. So he knew a nation-state attack when he saw one, and this looked like one of those. MEYERS: I started rolling up my sleeves and started actually looking at the code. And the backdoor itself was 3,500 lines. TEMPLE-RASTON: A backdoor is a little portal into the software. MEYERS: And, you know, there was quite a bit of things that it did. And the tradecraft of this threat actor was phenomenal. TEMPLE-RASTON: That little blob of code was the tiny, beating part of the attack buried deep inside the SolarWinds software. MEYERS: We're hoping it's going to have, you know, variable names or maybe some comments in Cyrillic or Mandarin, give us some clue that - who wrote this thing. TEMPLE-RASTON: But as the CrowdStrike program kept chewing its way through the code, Meyers' heart began to sink. The crime scene was a bust. MEYERS: They washed the code. They cleaned it of any human artifact or tool mark. And that was kind of mind-blowing that this threat actor had the wherewithal to just hide anything that a human might have inadvertently left behind as a clue. TEMPLE-RASTON: Experts like Meyers can often find gossamer connections inside the code. Some hackers have little tics. Others copy and paste from previous hacks. It's like a nerdy calling card. And nation-states typically have teams whose whole job is to try to break into other countries' systems. This happens so much, there's actually a convention to name them. MEYERS: So if I say it's bear, it's Russia. If I say it's panda, it's China. North Korea is Chollima. You know, we always kind of use the official state animal. And I think when we looked, that was the official state animal of North Korea, which was just what we were hoping for - an imaginary flying horse. TEMPLE-RASTON: To Meyers, SolarWinds felt like a bear operation, but he wasn't sure. He started looking for hints in the hack itself, which it turns out started earlier than anyone thought - all the way back to September 2019. That's when the hackers tried to insert a little snippet of code into the SolarWinds update to see if it would end up in finished software. It worked. MEYERS: They modified the product. And so at this point, they know that they can pull off a supply chain attack. They know that they have that capability. TEMPLE-RASTON: After that initial success, the hackers did something they never do. They disappeared for five months. They returned in February 2020, armed with code that allowed them to build their own SolarWinds update. But their version had a little addition - code that gave them that backdoor, that secret portal into SolarWinds' customer networks. Then came the trick. At the last second, they swapped their version in. MEYERS: Right. Like, I - when I was growing up, you used to have to check your Halloween candy because somebody might have put a razor blade in your Reese's peanut butter cup, right? But imagine those Reese's peanut butter cups going into the package, and just before the machine comes down and seals the package, some other thing comes in and slides a razor blade into your Reese's peanut butter cup. TEMPLE-RASTON: The package gets sealed. It's put in a box and goes out to the store and into plastic pumpkins everywhere. It wasn't complicated so much as crafty. Here's what really worried Meyers, though. This bait and switch could have worked on anyone. MEYERS: It could have been reconfigured for any number of software products. We realize that this could be elsewhere. TEMPLE-RASTON: To this day, no one knows where the hackers have been or exactly what they have done except, of course, for the hackers themselves. SolarWinds is still investigating. Typically, no one talks about a hack. But the CEO of SolarWinds, a man named Sudhakar Ramakrishna, thought he needed to. Why have you been so open about all of this? It's very unusual for a company to be this open. SUDHAKAR RAMAKRISHNA: You forget about competition and competitors. And in that context, the right thing to do is to report. The right thing to do is to give them the ability to fix those issues and protect their customers, right? And we can compete on value. We can compete on price. We can compete on other factors. But you don't compete on that. TEMPLE-RASTON: Ramakrishna wasn't running SolarWinds when the hack happened. He was hired just before the breach was discovered and stepped into the top job just as the full extent of the attack became clear. So when he published a blog post laying out an 11-point security plan, it was seen in two ways. IAN THORNTON-TRUMP: One interpretation of that could be, we learned a valuable lesson from what the hack was. The other interpretation could be is that there were at least 11 material deficiencies in the actual security we had. TEMPLE-RASTON: Right. THORNTON-TRUMP: I see the 11-point plan as actually an admission that things were not good in the security house. TEMPLE-RASTON: Ian Thornton-Trump used to work at SolarWinds. He was on the company's security team until 2017. He says he left because SolarWinds refused to spend enough money on its own security. Now he's chief of cybersecurity at a threat intelligence company, Cyjax, and he says he wished he'd done more to convince people at SolarWinds that a big hack was coming. THORNTON-TRUMP: There's an emotional component of me that is just super-sad about this. Something bad was going to happen. And, you know, we always say in cybersecurity, it's when, not if, right? It's when you're going to get data breached, not if you're going to get data breached. And this was a whopper. TEMPLE-RASTON: But you have to wonder, of all the software companies to target with this huge, complicated attack, why did the hackers choose SolarWinds? RAMAKRISHNA: I've thought about this quite a bit as to why us. Why not some somebody else? TEMPLE-RASTON: And Ramakrishna has come to the conclusion that the hackers chose SolarWinds because they thought they would be able to cast a wide net and possibly hack 18,000 customers with just one sophisticated attack. This wasn't just a hack, though. This was really about espionage. The White House thinks Russia was behind this and specifically that it was a group linked to Russian intelligence - APT29, known as Cozy Bear. Alex Stamos of Stanford says this was a high-end job. The hackers did their homework. They spent a lot of time studying the adversary. STAMOS: They demonstrated not just technical acumen, but the way they did this demonstrated that they understand how tech companies operate, how software companies operate. TEMPLE-RASTON: And that's the other thing that makes this hack different. The attack on SolarWinds was a bit of a bank shot. A nation-state wanted intelligence about the U. S. and hacked a private company to get it. FireEye's Kevin Mandia says that's what's new. MANDIA: We would have landed at this day sooner or later. But to see it happen, that's where, you know, you have a little bit of shock and surprise. OK, it's here now. TEMPLE-RASTON: And since it is here, new ideas may be required. For example, some people are suggesting there be a more formal way to investigate big cyberattacks. Stanford's Stamos likes the idea of starting something like the National Transportation Safety Board but for cyber instead. He thinks we should be looking at cyberattacks as carefully as we look at plane crashes. STAMOS: When the Boeing 737 Maxes started crashing, there was a government agency whose entire job it was to gather up the facts of all of those different crashes and then to come up with a theory of what needed to be fixed and then oversaw the fixes that went into that. TEMPLE-RASTON: And Adam Meyers, the man who found that little blob of code inside the SolarWinds software - he's busy as ever fending off other attacks. MEYERS: This was an intelligence collection operation meant to steal information. And it's not the last time that's going to happen, right? This is going to happen every day. And, you know, I can't tell you how many investigations I've worked on since. It gives you a sense that this is continuing to happen. And I think there's a lot that we all need to do to work together to stop this from happening. TEMPLE-RASTON: Dina Temple-Raston, NPR News. (SOUNDBITE OF DECEPTIKON'S \"THE WAY OF THE SAMURAI\") MARY LOUISE KELLY, HOST:   Late last year, a long-simmering cyber conflict between the United States and Russia broke out into the open. (SOUNDBITE OF MONTAGE) UNIDENTIFIED REPORTER #1: Authorities say the Russians targeted some of America's most sensitive and important computer systems. UNIDENTIFIED REPORTER #2: Hackers breached SolarWinds to infect at least seven U. S. government agencies. UNIDENTIFIED REPORTER #3: Government agencies were caught off guard by an unprecedented attack. KELLY: That's right. Hackers targeted SolarWinds, a Texas software company you'd probably never heard of. But they make a piece of software that is indispensable to thousands of IT departments, including many of the nation's biggest companies and U. S. government institutions. ARI SHAPIRO, HOST:   Russian hackers were able to sneak malicious code into this widely used software, which gave them a vast list of potential targets. NPR investigative correspondent Dina Temple-Raston got an exclusive look inside the sophisticated attack. Here's how it unfolded. DINA TEMPLE-RASTON, BYLINE: The routine software update may be one of the most familiar and least understood parts of our digital lives, but this last spring it became the vehicle to launch an epic cyberattack. Hackers used a software update to slip into some of this country's most sensitive computer networks, which allowed them to take aim not just at the economy but at our national security, too. ALEX STAMOS: I mean, it's one of the most impressive and effective cyberespionage campaigns of all time. TEMPLE-RASTON: Alex Stamos is the director of the Internet Observatory at Stanford University and the former head of security at Facebook. STAMOS: They were able to get access to some very sensitive companies and government organizations without getting caught for quite a while. TEMPLE-RASTON: And when he says quite a while, he means almost a year. And for all that time, the hackers roamed around the networks of companies like Microsoft, Intel and Cisco and government agencies like the Treasury, the Department of Energy and the Pentagon. And the hackers might have kept skulking around those networks were it not for the vigilance of one company - FireEye, which happened to be one of SolarWinds' customers. STAMOS: That's right. I mean, this is - we only know about any of this because they made the mistake of attacking FireEye, which is, like, a professional incident response company. KEVIN MANDIA: You know, us doing investigations is kind of like The Beatles entering a battle of the bands. They're going to do really well in a battle of the bands. We're going to do well investigating. TEMPLE-RASTON: That's Kevin Mandia, FireEye CEO. You're former Air Force intelligence. Is that right? MANDIA: No, I was in what's called the Air Force Office of Special Investigations. I spent from 1996 1998 responding to what I would equate to as the Russian Foreign Intelligence Service. TEMPLE-RASTON: So late last year, when he saw some suspicious activity in his company's network, it felt familiar. The first clue that something was wrong came when the FireEye security team noticed something unusual - someone trying to register a second phone onto the company's network. So they called. MANDIA: And the gentleman said, no, I did not register that phone. So who did? TEMPLE-RASTON: Whoever it was, they were roaming around the network, looking like an employee. MANDIA: It just felt like the breach that I was always worried about. TEMPLE-RASTON: The FireEye security team started tearing apart their servers, looking for the intruder, and it took them weeks to trace the problem back to that SolarWinds software update. And once they were certain that's what it was, they wrote a report and sent it to the head of cybersecurity at SolarWinds, Tim Brown. TIM BROWN: And the report was detailed. The report said, we decompiled your code. We see this malicious code here. We see proof that, yes, we had shipped things that had malicious content inside of it. TEMPLE-RASTON: And what was going through your head? BROWN: You know, it's kind of a nightmare idea for any security person. You know, we deal with little, tiny incidents often. But this had the potential to affect thousands of customers, right? This had the potential to do a great deal of damage. TEMPLE-RASTON: Brown went home, packed a bag and was prepared to stay at the office for the rest of the week. BROWN: I would say Sunday, Monday, we knew that the attack itself and the code that was inserted itself was pretty purposeful. So we quickly understood that the attacker was on a mission. TEMPLE-RASTON: This wasn't just a hacker in a hoodie. This looked like a nation-state. So they brought in someone who knew how to deal with these kinds of attacks. ADAM MEYERS: Hi - Adam Meyers, and I run intel at CrowdStrike. TEMPLE-RASTON: CrowdStrike is a cyber investigation company, and Meyers has helped them unwind some famous hacks - Sony in 2015, the Democratic National Committee a year later. So he knew a nation-state attack when he saw one, and this looked like one of those. MEYERS: I started rolling up my sleeves and started actually looking at the code. And the backdoor itself was 3,500 lines. TEMPLE-RASTON: A backdoor is a little portal into the software. MEYERS: And, you know, there was quite a bit of things that it did. And the tradecraft of this threat actor was phenomenal. TEMPLE-RASTON: That little blob of code was the tiny, beating part of the attack buried deep inside the SolarWinds software. MEYERS: We're hoping it's going to have, you know, variable names or maybe some comments in Cyrillic or Mandarin, give us some clue that - who wrote this thing. TEMPLE-RASTON: But as the CrowdStrike program kept chewing its way through the code, Meyers' heart began to sink. The crime scene was a bust. MEYERS: They washed the code. They cleaned it of any human artifact or tool mark. And that was kind of mind-blowing that this threat actor had the wherewithal to just hide anything that a human might have inadvertently left behind as a clue. TEMPLE-RASTON: Experts like Meyers can often find gossamer connections inside the code. Some hackers have little tics. Others copy and paste from previous hacks. It's like a nerdy calling card. And nation-states typically have teams whose whole job is to try to break into other countries' systems. This happens so much, there's actually a convention to name them. MEYERS: So if I say it's bear, it's Russia. If I say it's panda, it's China. North Korea is Chollima. You know, we always kind of use the official state animal. And I think when we looked, that was the official state animal of North Korea, which was just what we were hoping for - an imaginary flying horse. TEMPLE-RASTON: To Meyers, SolarWinds felt like a bear operation, but he wasn't sure. He started looking for hints in the hack itself, which it turns out started earlier than anyone thought - all the way back to September 2019. That's when the hackers tried to insert a little snippet of code into the SolarWinds update to see if it would end up in finished software. It worked. MEYERS: They modified the product. And so at this point, they know that they can pull off a supply chain attack. They know that they have that capability. TEMPLE-RASTON: After that initial success, the hackers did something they never do. They disappeared for five months. They returned in February 2020, armed with code that allowed them to build their own SolarWinds update. But their version had a little addition - code that gave them that backdoor, that secret portal into SolarWinds' customer networks. Then came the trick. At the last second, they swapped their version in. MEYERS: Right. Like, I - when I was growing up, you used to have to check your Halloween candy because somebody might have put a razor blade in your Reese's peanut butter cup, right? But imagine those Reese's peanut butter cups going into the package, and just before the machine comes down and seals the package, some other thing comes in and slides a razor blade into your Reese's peanut butter cup. TEMPLE-RASTON: The package gets sealed. It's put in a box and goes out to the store and into plastic pumpkins everywhere. It wasn't complicated so much as crafty. Here's what really worried Meyers, though. This bait and switch could have worked on anyone. MEYERS: It could have been reconfigured for any number of software products. We realize that this could be elsewhere. TEMPLE-RASTON: To this day, no one knows where the hackers have been or exactly what they have done except, of course, for the hackers themselves. SolarWinds is still investigating. Typically, no one talks about a hack. But the CEO of SolarWinds, a man named Sudhakar Ramakrishna, thought he needed to. Why have you been so open about all of this? It's very unusual for a company to be this open. SUDHAKAR RAMAKRISHNA: You forget about competition and competitors. And in that context, the right thing to do is to report. The right thing to do is to give them the ability to fix those issues and protect their customers, right? And we can compete on value. We can compete on price. We can compete on other factors. But you don't compete on that. TEMPLE-RASTON: Ramakrishna wasn't running SolarWinds when the hack happened. He was hired just before the breach was discovered and stepped into the top job just as the full extent of the attack became clear. So when he published a blog post laying out an 11-point security plan, it was seen in two ways. IAN THORNTON-TRUMP: One interpretation of that could be, we learned a valuable lesson from what the hack was. The other interpretation could be is that there were at least 11 material deficiencies in the actual security we had. TEMPLE-RASTON: Right. THORNTON-TRUMP: I see the 11-point plan as actually an admission that things were not good in the security house. TEMPLE-RASTON: Ian Thornton-Trump used to work at SolarWinds. He was on the company's security team until 2017. He says he left because SolarWinds refused to spend enough money on its own security. Now he's chief of cybersecurity at a threat intelligence company, Cyjax, and he says he wished he'd done more to convince people at SolarWinds that a big hack was coming. THORNTON-TRUMP: There's an emotional component of me that is just super-sad about this. Something bad was going to happen. And, you know, we always say in cybersecurity, it's when, not if, right? It's when you're going to get data breached, not if you're going to get data breached. And this was a whopper. TEMPLE-RASTON: But you have to wonder, of all the software companies to target with this huge, complicated attack, why did the hackers choose SolarWinds? RAMAKRISHNA: I've thought about this quite a bit as to why us. Why not some somebody else? TEMPLE-RASTON: And Ramakrishna has come to the conclusion that the hackers chose SolarWinds because they thought they would be able to cast a wide net and possibly hack 18,000 customers with just one sophisticated attack. This wasn't just a hack, though. This was really about espionage. The White House thinks Russia was behind this and specifically that it was a group linked to Russian intelligence - APT29, known as Cozy Bear. Alex Stamos of Stanford says this was a high-end job. The hackers did their homework. They spent a lot of time studying the adversary. STAMOS: They demonstrated not just technical acumen, but the way they did this demonstrated that they understand how tech companies operate, how software companies operate. TEMPLE-RASTON: And that's the other thing that makes this hack different. The attack on SolarWinds was a bit of a bank shot. A nation-state wanted intelligence about the U. S. and hacked a private company to get it. FireEye's Kevin Mandia says that's what's new. MANDIA: We would have landed at this day sooner or later. But to see it happen, that's where, you know, you have a little bit of shock and surprise. OK, it's here now. TEMPLE-RASTON: And since it is here, new ideas may be required. For example, some people are suggesting there be a more formal way to investigate big cyberattacks. Stanford's Stamos likes the idea of starting something like the National Transportation Safety Board but for cyber instead. He thinks we should be looking at cyberattacks as carefully as we look at plane crashes. STAMOS: When the Boeing 737 Maxes started crashing, there was a government agency whose entire job it was to gather up the facts of all of those different crashes and then to come up with a theory of what needed to be fixed and then oversaw the fixes that went into that. TEMPLE-RASTON: And Adam Meyers, the man who found that little blob of code inside the SolarWinds software - he's busy as ever fending off other attacks. MEYERS: This was an intelligence collection operation meant to steal information. And it's not the last time that's going to happen, right? This is going to happen every day. And, you know, I can't tell you how many investigations I've worked on since. It gives you a sense that this is continuing to happen. And I think there's a lot that we all need to do to work together to stop this from happening. TEMPLE-RASTON: Dina Temple-Raston, NPR News. (SOUNDBITE OF DECEPTIKON'S \"THE WAY OF THE SAMURAI\")", "section": "Untangling Disinformation", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-04-18-984023155": {"title": "Tufting On TikTok, 'Renegade' Rug Makers Create Community : NPR", "url": "https://www.npr.org/2021/04/18/984023155/renegade-rug-makers-create-community-tufting-on-tiktok", "author": "No author found", "published_date": "2021-04-18", "content": "MICHEL MARTIN, HOST:  Over the past year, some crafters have gotten extreme. They are making their own rugs with hand-held industrial equipment. NPR's Fiona Geiran introduces us to a few artists on TikTok who are remixing rug making. FIONA GEIRAN, BYLINE: Of course it's on TikTok. (SOUNDBITE OF TIKTOK VIDEO)UNIDENTIFIED PERSON #1: Rug check. GEIRAN: In this TikTok video, the artist shows off the rugs that he made with his tufting gun. Tufters use both hands to draw with their electric tufting guns, shooting out yarn in bright puddles of color. TRISH ANDERSEN: It's just like a paintbrush. GEIRAN: Trish Andersen says tufters are making everything from Pokemon characters to abstract original art. Andersen uses her tufting gun to create lines of color that come alive and run over each other like water. Tufting is unconventional, Andersen says. ANDERSEN: It's not like knitting, where you can go and, like, just buy a book and then you learn the stitches, you know? It's still a little bit renegade at this point. GEIRAN: Andersen's got carpeting in her roots. ANDERSEN: I'm from Dalton, Ga. , which is the carpet capital of the world. GEIRAN: Dalton is where tufting machinery was invented in the 1930s. It still produces the most wall-to-wall carpeting in America, the kind designed to blend in with neutral colors, straight lines and sensible patterns. Andersen first learned to tuft using rug company manuals, but tufting for her means so much more than a mechanical process. ANDERSEN: The first stitch that I lined that I got to make it work, I just cried because I hadn't felt so alive, you know? GEIRAN: Andersen is not alone in her passion. Sales at the website tuftinggun. com have gone up by more than 600% last quarter compared to the year before, thanks in large part to tufting videos like this. (SOUNDBITE OF MUSIC)GEIRAN: 19-year-old Justin Clarke had never heard of tufting until he saw a tufter's video on TikTok last summer. He had not expected to use rugs as a way of making portraits. JUSTIN CLARKE: When I started taking tufting a little bit more seriously, it dealt a lot with, like my own self-image of, like, my body and Afrocentric facial features that, like, I didn't see them as, like, beautiful yet. GEIRAN: Clarke's art examines the human body up close. Some of his rugs show teeth or torsos in bright blocks of yellows, reds and pinks. CLARKE: When I don't, like, find myself beautiful or if I don't see the beauty in myself, it takes a toll on myself. And when you don't have self-value, people could walk all over you, you know, like a rug. GEIRAN: Tufting is a solitary process. But with online spaces, tufters build community, trade techniques and show that art should be everywhere - on your walls, on your TikTok feed and on your floors. Fiona Geiran, NPR News. MARTIN: And if you are looking for another way to have fun on TikTok, submit an original poem for our annual Poetry Month celebration. Stay tuned because later this hour, we will be speaking with a youth poet about the original poems that caught their eye. In the meantime, here are a couple of your submissions. (SOUNDBITE OF TIKTOK VIDEO)CORDELIA HAMILTON VA: Life-ku (ph) by me. Faking It. You are my client. I have to be nice to you. Doesn't mean I like it. MARTIN: That was from user @dearcordelia - very funny. And here's one from Debra Shigley. (SOUNDBITE OF TIKTOK VIDEO)DEBRA SHIGLEY: I saw the kids from the window masked up, marching down the hill and up the stairs onto the school bus. Grins hidden, all steely will, and eyes bright with purpose into the murky trenches of letters, long division and recess. Socially distanced on playground benches, they sparkle, climb and carry on. Not kvetching, rarely fuss, these magical little creatures are heroes among us. MARTIN: Stay with us for much more. (SOUNDBITE OF MUSIC) MICHEL MARTIN, HOST:   Over the past year, some crafters have gotten extreme. They are making their own rugs with hand-held industrial equipment. NPR's Fiona Geiran introduces us to a few artists on TikTok who are remixing rug making. FIONA GEIRAN, BYLINE: Of course it's on TikTok. (SOUNDBITE OF TIKTOK VIDEO) UNIDENTIFIED PERSON #1: Rug check. GEIRAN: In this TikTok video, the artist shows off the rugs that he made with his tufting gun. Tufters use both hands to draw with their electric tufting guns, shooting out yarn in bright puddles of color. TRISH ANDERSEN: It's just like a paintbrush. GEIRAN: Trish Andersen says tufters are making everything from Pokemon characters to abstract original art. Andersen uses her tufting gun to create lines of color that come alive and run over each other like water. Tufting is unconventional, Andersen says. ANDERSEN: It's not like knitting, where you can go and, like, just buy a book and then you learn the stitches, you know? It's still a little bit renegade at this point. GEIRAN: Andersen's got carpeting in her roots. ANDERSEN: I'm from Dalton, Ga. , which is the carpet capital of the world. GEIRAN: Dalton is where tufting machinery was invented in the 1930s. It still produces the most wall-to-wall carpeting in America, the kind designed to blend in with neutral colors, straight lines and sensible patterns. Andersen first learned to tuft using rug company manuals, but tufting for her means so much more than a mechanical process. ANDERSEN: The first stitch that I lined that I got to make it work, I just cried because I hadn't felt so alive, you know? GEIRAN: Andersen is not alone in her passion. Sales at the website tuftinggun. com have gone up by more than 600% last quarter compared to the year before, thanks in large part to tufting videos like this. (SOUNDBITE OF MUSIC) GEIRAN: 19-year-old Justin Clarke had never heard of tufting until he saw a tufter's video on TikTok last summer. He had not expected to use rugs as a way of making portraits. JUSTIN CLARKE: When I started taking tufting a little bit more seriously, it dealt a lot with, like my own self-image of, like, my body and Afrocentric facial features that, like, I didn't see them as, like, beautiful yet. GEIRAN: Clarke's art examines the human body up close. Some of his rugs show teeth or torsos in bright blocks of yellows, reds and pinks. CLARKE: When I don't, like, find myself beautiful or if I don't see the beauty in myself, it takes a toll on myself. And when you don't have self-value, people could walk all over you, you know, like a rug. GEIRAN: Tufting is a solitary process. But with online spaces, tufters build community, trade techniques and show that art should be everywhere - on your walls, on your TikTok feed and on your floors. Fiona Geiran, NPR News. MARTIN: And if you are looking for another way to have fun on TikTok, submit an original poem for our annual Poetry Month celebration. Stay tuned because later this hour, we will be speaking with a youth poet about the original poems that caught their eye. In the meantime, here are a couple of your submissions. (SOUNDBITE OF TIKTOK VIDEO) CORDELIA HAMILTON VA: Life-ku (ph) by me. Faking It. You are my client. I have to be nice to you. Doesn't mean I like it. MARTIN: That was from user @dearcordelia - very funny. And here's one from Debra Shigley. (SOUNDBITE OF TIKTOK VIDEO) DEBRA SHIGLEY: I saw the kids from the window masked up, marching down the hill and up the stairs onto the school bus. Grins hidden, all steely will, and eyes bright with purpose into the murky trenches of letters, long division and recess. Socially distanced on playground benches, they sparkle, climb and carry on. Not kvetching, rarely fuss, these magical little creatures are heroes among us. MARTIN: Stay with us for much more. (SOUNDBITE OF MUSIC)", "section": "Fine Art", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-04-18-988572593": {"title": "What Would A 'Feminist Internet' Look Like? : NPR", "url": "https://www.npr.org/2021/04/18/988572593/what-would-a-feminist-internet-look-like", "author": "No author found", "published_date": "2021-04-18", "content": "MICHEL MARTIN, HOST:  When computer scientists were creating the World Wide Web, the entire project was steeped in optimism. Early Internet pioneers predicted a techno-utopia. You can hear it in this 1996 \"Declaration Of The Independence Of Cyberspace. \"(SOUNDBITE OF ARCHIVED RECORDING)JOHN PERRY BARLOW: We are creating a world that all may enter without privilege or prejudice accorded by race, economic power, military force or station of birth. MARTIN: That was John Perry Barlow, a co-founder of the Electronic Frontier Foundation, reading the declaration. But did you notice what was missing from that list? Charlotte Jee, a reporter with MIT Technology Review, did notice something missing - gender. Decades later, social media platforms have become havens for abuse, misogyny and harassment. In a new piece for MIT's Technology Review, Charlotte Jee asks, what would a feminist Internet look like? And Charlotte Jee is with us now to tell us more. Hello. Welcome. Thank you so much for joining us. CHARLOTTE JEE: Thank you for having me. MARTIN: Well, first of all - and I hate to start this way, but I do have to start this way - set the problem up for us. You know, why is the Internet so toxic, especially for public-facing women? There have been many, many surveys that have shown that women in general and women of color in particular receive an excessive portion of the online abuse, which isn't to say that other people don't, but women are particularly targeted. So why is the Internet so toxic for women? JEE: Yeah. I mean, it's a really good question. A lot of the problem, to be honest with you, is around women who have a platform and sexists who see that and then get enraged or frustrated by this. And as I say in the piece, you know, it's the same message, which is, a woman is saying something that I'm finding uncomfortable, and so I'm going to get her to shut up. And the way that this is done is through trolling campaigns, through people that kind of ask repetitive questions to people - just people that are making, you know, life a bit more uncomfortable for women. So it's not a nice place to hang out. MARTIN: Well, so - there are so many factors you write about in the piece that seem to contribute to an overwhelming Internet culture - I mean, the fact that venture capital money goes overwhelmingly to men. Women make up less than 20% of U. S. tech employees. But you also write that there's a - sort of a misogyny that seeps into the online experience. You bring up a concept of algorithmic discrimination. Could you just give an example of what that looks like? JEE: Yeah, absolutely. I mean, as I say in the piece, you know, if you look at Google Images, and you search schoolboy and you search schoolgirl, the first one is pretty innocuous. But for girls, it's all kind of sexualized imagery. And that's partly kind of image recognition algorithms. That's bias creeping into that process. You know, I call it, like, a self-reinforcing misogyny machine. We're taking the existing bias that exists in society, we're embedding it, and then we're kind of amplifying it. And part of that has also to do with prioritizing engagement because you know who engages a lot online? Trolls. So, you know, we're kind of almost encouraging this sort of behavior with the way that the Internet functions. MARTIN: So let's wheel it around. We've sort of framed the problem. Let's talk about the solution. And how did you conceive of this idea of a feminist Internet? And before we get into the specifics, tell me what you mean by feminist Internet. And how did you arrive at some of these ideas? JEE: I mean, the interesting thing about the feminist Internet movement is that it's pretty diverse. And mostly, it's just a loose collection of activists who are working on trying to redress the balance, the sort of power imbalance that's going on here. It's about pushing things away from big tech and towards individuals. So, for example, making this a more consensual relationship - which data do you want to share? Are you comfortable with certain security settings? And, you know, we do also desperately need better privacy protection, so there's also a role for politicians and regulators here. MARTIN: Part of the piece - part of the argument of the piece is that a more feminist Internet benefits everybody and not just women. And you bring up the fitness tracking company Strava. So what happened with Strava, and what lessons might other companies take from that? JEE: Yeah. So - yeah, it allows you to track your runs, you know, for the people that like posting their running routes online. And for a long time, you know, feminist activists and just women generally pointed out, actually, this could be used to stalk people. And they wouldn't even necessarily have to be posting this online. It's just if someone could look at their account on Strava, they could see where they're running and what times. Strava didn't really pay much attention to this. And to be honest, that, by the way, is a theme that runs through this - activists raising issues and then basically being ignored. And then a few years later, it turned out that security researchers had discovered that you can discover where different U. S. bases are overseas by looking at the running routes of the military personnel who are stationed at those bases. So basically, they discovered something that had concerned these women was, in fact, a national security threat for the U. S. That is just, like, a microcosm and a really small example of how failing to listen to women also hurts men and society more generally. MARTIN: You know, we're having this very calm civil conversation, as, of course, we should be. But what you're describing is infuriating. You know, how is it that - this is half the population. Why is it that the concerns of half the population are so uninteresting to these companies. . . JEE: Yeah. MARTIN: . . . That play such an important role in all of our lives? Why is it that women are being inundated not just with mean words, but with threats to rape them and eviscerate them simply because they may have a role in public life is not taken more seriously? Why is that? JEE: Yeah. I mean, one of the activists that I spoke to - she was, like, you know, part of the problem is that these companies are founded by and run by relatively privileged men who really can't imagine what it's like to be on the receiving end of this. Also, there's been this traditional debate around free speech, when in reality it's, like, well, whose free speech? Because you're protecting the free speech of men to abuse women, but what about those women's free speech that are being chased offline? MARTIN: What would make a difference? JEE: Yeah. This is the question. I mean, I look in the piece at sort of the different activists who are working on different tools to try to address this. But it is a bit piecemeal. I look at stuff like there's some women who are building an app called Heard, which is, like, a completely different social network that's meant to be - designed to be a much more pleasant experience inherently, basically. I look at the app called Block Party, which helps women to better deal with harassment on Twitter. I think, you know, we do need better regulations. I know that we can't necessarily expect those to be explicitly feminist regulations, but I do think that if we gave consumers in the U. S. better privacy protections, I think that that would be of huge benefit to women and to men, too, but also the tech companies themselves. You know, if they wanted to, they could decide that harassment is not something they're willing to tolerate because, you know, they are able to work together on issues like terrorism, child sexual abuse. And right now, it feels like they've decided that women being harassed and receiving rape threats - that kind of thing - is just, like, a cost of doing business that they're willing to pay. When it comes to threats to women's well-being, direct threats, I really do think that they can and should be doing a lot more about that. MARTIN: That was Charlotte Jee. She is a reporter with MIT Technology Review. Her piece is titled, \"A Feminist Internet Would Be Better For Everyone. \" Charlotte Jee, thank you so much for sharing your time and expertise with us. JEE: Thank you for having me. (SOUNDBITE OF JUSTICE DER SONG, \"BLEACH\") MICHEL MARTIN, HOST:   When computer scientists were creating the World Wide Web, the entire project was steeped in optimism. Early Internet pioneers predicted a techno-utopia. You can hear it in this 1996 \"Declaration Of The Independence Of Cyberspace. \" (SOUNDBITE OF ARCHIVED RECORDING) JOHN PERRY BARLOW: We are creating a world that all may enter without privilege or prejudice accorded by race, economic power, military force or station of birth. MARTIN: That was John Perry Barlow, a co-founder of the Electronic Frontier Foundation, reading the declaration. But did you notice what was missing from that list? Charlotte Jee, a reporter with MIT Technology Review, did notice something missing - gender. Decades later, social media platforms have become havens for abuse, misogyny and harassment. In a new piece for MIT's Technology Review, Charlotte Jee asks, what would a feminist Internet look like? And Charlotte Jee is with us now to tell us more. Hello. Welcome. Thank you so much for joining us. CHARLOTTE JEE: Thank you for having me. MARTIN: Well, first of all - and I hate to start this way, but I do have to start this way - set the problem up for us. You know, why is the Internet so toxic, especially for public-facing women? There have been many, many surveys that have shown that women in general and women of color in particular receive an excessive portion of the online abuse, which isn't to say that other people don't, but women are particularly targeted. So why is the Internet so toxic for women? JEE: Yeah. I mean, it's a really good question. A lot of the problem, to be honest with you, is around women who have a platform and sexists who see that and then get enraged or frustrated by this. And as I say in the piece, you know, it's the same message, which is, a woman is saying something that I'm finding uncomfortable, and so I'm going to get her to shut up. And the way that this is done is through trolling campaigns, through people that kind of ask repetitive questions to people - just people that are making, you know, life a bit more uncomfortable for women. So it's not a nice place to hang out. MARTIN: Well, so - there are so many factors you write about in the piece that seem to contribute to an overwhelming Internet culture - I mean, the fact that venture capital money goes overwhelmingly to men. Women make up less than 20% of U. S. tech employees. But you also write that there's a - sort of a misogyny that seeps into the online experience. You bring up a concept of algorithmic discrimination. Could you just give an example of what that looks like? JEE: Yeah, absolutely. I mean, as I say in the piece, you know, if you look at Google Images, and you search schoolboy and you search schoolgirl, the first one is pretty innocuous. But for girls, it's all kind of sexualized imagery. And that's partly kind of image recognition algorithms. That's bias creeping into that process. You know, I call it, like, a self-reinforcing misogyny machine. We're taking the existing bias that exists in society, we're embedding it, and then we're kind of amplifying it. And part of that has also to do with prioritizing engagement because you know who engages a lot online? Trolls. So, you know, we're kind of almost encouraging this sort of behavior with the way that the Internet functions. MARTIN: So let's wheel it around. We've sort of framed the problem. Let's talk about the solution. And how did you conceive of this idea of a feminist Internet? And before we get into the specifics, tell me what you mean by feminist Internet. And how did you arrive at some of these ideas? JEE: I mean, the interesting thing about the feminist Internet movement is that it's pretty diverse. And mostly, it's just a loose collection of activists who are working on trying to redress the balance, the sort of power imbalance that's going on here. It's about pushing things away from big tech and towards individuals. So, for example, making this a more consensual relationship - which data do you want to share? Are you comfortable with certain security settings? And, you know, we do also desperately need better privacy protection, so there's also a role for politicians and regulators here. MARTIN: Part of the piece - part of the argument of the piece is that a more feminist Internet benefits everybody and not just women. And you bring up the fitness tracking company Strava. So what happened with Strava, and what lessons might other companies take from that? JEE: Yeah. So - yeah, it allows you to track your runs, you know, for the people that like posting their running routes online. And for a long time, you know, feminist activists and just women generally pointed out, actually, this could be used to stalk people. And they wouldn't even necessarily have to be posting this online. It's just if someone could look at their account on Strava, they could see where they're running and what times. Strava didn't really pay much attention to this. And to be honest, that, by the way, is a theme that runs through this - activists raising issues and then basically being ignored. And then a few years later, it turned out that security researchers had discovered that you can discover where different U. S. bases are overseas by looking at the running routes of the military personnel who are stationed at those bases. So basically, they discovered something that had concerned these women was, in fact, a national security threat for the U. S. That is just, like, a microcosm and a really small example of how failing to listen to women also hurts men and society more generally. MARTIN: You know, we're having this very calm civil conversation, as, of course, we should be. But what you're describing is infuriating. You know, how is it that - this is half the population. Why is it that the concerns of half the population are so uninteresting to these companies. . . JEE: Yeah. MARTIN: . . . That play such an important role in all of our lives? Why is it that women are being inundated not just with mean words, but with threats to rape them and eviscerate them simply because they may have a role in public life is not taken more seriously? Why is that? JEE: Yeah. I mean, one of the activists that I spoke to - she was, like, you know, part of the problem is that these companies are founded by and run by relatively privileged men who really can't imagine what it's like to be on the receiving end of this. Also, there's been this traditional debate around free speech, when in reality it's, like, well, whose free speech? Because you're protecting the free speech of men to abuse women, but what about those women's free speech that are being chased offline? MARTIN: What would make a difference? JEE: Yeah. This is the question. I mean, I look in the piece at sort of the different activists who are working on different tools to try to address this. But it is a bit piecemeal. I look at stuff like there's some women who are building an app called Heard, which is, like, a completely different social network that's meant to be - designed to be a much more pleasant experience inherently, basically. I look at the app called Block Party, which helps women to better deal with harassment on Twitter. I think, you know, we do need better regulations. I know that we can't necessarily expect those to be explicitly feminist regulations, but I do think that if we gave consumers in the U. S. better privacy protections, I think that that would be of huge benefit to women and to men, too, but also the tech companies themselves. You know, if they wanted to, they could decide that harassment is not something they're willing to tolerate because, you know, they are able to work together on issues like terrorism, child sexual abuse. And right now, it feels like they've decided that women being harassed and receiving rape threats - that kind of thing - is just, like, a cost of doing business that they're willing to pay. When it comes to threats to women's well-being, direct threats, I really do think that they can and should be doing a lot more about that. MARTIN: That was Charlotte Jee. She is a reporter with MIT Technology Review. Her piece is titled, \"A Feminist Internet Would Be Better For Everyone. \" Charlotte Jee, thank you so much for sharing your time and expertise with us. JEE: Thank you for having me. (SOUNDBITE OF JUSTICE DER SONG, \"BLEACH\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-04-19-988837540": {"title": "Apple Is Rolling Out Big Privacy Changes : NPR", "url": "https://www.npr.org/2021/04/19/988837540/apple-is-rolling-out-big-privacy-changes", "author": "No author found", "published_date": "2021-04-19", "content": "MARY LOUISE KELLY, HOST:  Are you an iPhone user? If yes, then you should expect to see messages in the coming weeks from the apps on your phone. This is because Apple has told app developers that they must send iPhone users pop-up messages to alert them that their personal information is being tracked. Well, NPR's tech correspondent Shannon Bond is tracking this story, and she's here to explain. Hey, Shannon. SHANNON BOND, BYLINE: Hey, Mary Louise. KELLY: All right. I need to note that Apple is among NPR's financial supporters. So tell us; what kind of messages are we going to see, and why. . . BOND: Yeah. KELLY: . . . Should we pay attention to them? BOND: Some people may already be seeing these, actually, from certain apps, and it's a message that gives you a choice. Do you want to let this app track you across other apps and websites or not? And Apple is soon going to require all apps to send these messages. So if you're like me, you have lots of apps on your phone. You're going to get a lot of these pop-ups. KELLY: Why is Apple doing this? BOND: Well, remember, Mary Louise; most apps are free, right? We don't pay anything to download them. So these apps make money by selling ads. Many of these ads are personalized with data from all of the different things you do on your phone - you know, the workouts you're doing in one app, the things that you're buying, the posts that you're liking on Instagram. KELLY: Sure. BOND: Many apps share this information. For example of how this works, say you downloaded a recipe app. That recipe app - it knows who you are. It can go to Facebook or some other app and say, I want to show Mary Louise ads to tell her that she should upgrade to a subscription for this recipe app. Now, Apple thinks that that decision, that power should be in the hands of people. They should have to give permission before these apps can share that kind of information. For Apple, it's all about privacy. KELLY: What if I don't want all the recipe apps tracking me? What if I get these pop-up messages, and I say, no, thank you? Then what happens? BOND: Well, just obviously, if you say yes, you know, that's - nothing changes. But if you say no, the app will work in the same way. Apple actually says, you know, apps can't make, you know, the app working contingent on people saying yes to this kind of tracking. What it does mean is you won't get the kind of personalized apps that are following you kind of across your phone from app to app based on all this collected information about what you do online. You will see - still see apps - you will still see ads in these apps. But the key thing here is that they can't share that data they have about you with all the other companies that are looking at your phone. KELLY: Which I imagine is not a pleasing prospect to the app companies. What are they saying about this? BOND: Yeah. I mean, this is a really big change. As we said, this is sort of the basis of how many of these apps make money - most apps make money. And most people are expected to say no when given this choice. The most outspoken opponent here is Facebook, which is also an NPR supporter. And of course, Mary Louise, Facebook is in the advertising business. Apple is not. Apple makes money in other ways. So what Facebook says is Apple is trying to push developers to make more apps that charge their users money, like a meditation or a fitness app where you pay for that kind of monthly subscription because Apple takes a cut of those subscriptions, right? That's Apple's business model. You know, Facebook and Apple have been at odds for a long time. These companies and their CEOs have fundamentally very different ideas about how tech companies make money, how they use people's personal information. This is a longstanding battle. But in this particular fight between these two tech giants, you know, Apple has the upper hand. It gets to set the rules for its phones. And, you know, Facebook can complain that it doesn't have a lot of choice. KELLY: NPR tech correspondent Shannon Bond, thanks for your reporting. BOND: Thank you. (SOUNDBITE OF EXMAG'S \"ZAN\") MARY LOUISE KELLY, HOST:   Are you an iPhone user? If yes, then you should expect to see messages in the coming weeks from the apps on your phone. This is because Apple has told app developers that they must send iPhone users pop-up messages to alert them that their personal information is being tracked. Well, NPR's tech correspondent Shannon Bond is tracking this story, and she's here to explain. Hey, Shannon. SHANNON BOND, BYLINE: Hey, Mary Louise. KELLY: All right. I need to note that Apple is among NPR's financial supporters. So tell us; what kind of messages are we going to see, and why. . . BOND: Yeah. KELLY: . . . Should we pay attention to them? BOND: Some people may already be seeing these, actually, from certain apps, and it's a message that gives you a choice. Do you want to let this app track you across other apps and websites or not? And Apple is soon going to require all apps to send these messages. So if you're like me, you have lots of apps on your phone. You're going to get a lot of these pop-ups. KELLY: Why is Apple doing this? BOND: Well, remember, Mary Louise; most apps are free, right? We don't pay anything to download them. So these apps make money by selling ads. Many of these ads are personalized with data from all of the different things you do on your phone - you know, the workouts you're doing in one app, the things that you're buying, the posts that you're liking on Instagram. KELLY: Sure. BOND: Many apps share this information. For example of how this works, say you downloaded a recipe app. That recipe app - it knows who you are. It can go to Facebook or some other app and say, I want to show Mary Louise ads to tell her that she should upgrade to a subscription for this recipe app. Now, Apple thinks that that decision, that power should be in the hands of people. They should have to give permission before these apps can share that kind of information. For Apple, it's all about privacy. KELLY: What if I don't want all the recipe apps tracking me? What if I get these pop-up messages, and I say, no, thank you? Then what happens? BOND: Well, just obviously, if you say yes, you know, that's - nothing changes. But if you say no, the app will work in the same way. Apple actually says, you know, apps can't make, you know, the app working contingent on people saying yes to this kind of tracking. What it does mean is you won't get the kind of personalized apps that are following you kind of across your phone from app to app based on all this collected information about what you do online. You will see - still see apps - you will still see ads in these apps. But the key thing here is that they can't share that data they have about you with all the other companies that are looking at your phone. KELLY: Which I imagine is not a pleasing prospect to the app companies. What are they saying about this? BOND: Yeah. I mean, this is a really big change. As we said, this is sort of the basis of how many of these apps make money - most apps make money. And most people are expected to say no when given this choice. The most outspoken opponent here is Facebook, which is also an NPR supporter. And of course, Mary Louise, Facebook is in the advertising business. Apple is not. Apple makes money in other ways. So what Facebook says is Apple is trying to push developers to make more apps that charge their users money, like a meditation or a fitness app where you pay for that kind of monthly subscription because Apple takes a cut of those subscriptions, right? That's Apple's business model. You know, Facebook and Apple have been at odds for a long time. These companies and their CEOs have fundamentally very different ideas about how tech companies make money, how they use people's personal information. This is a longstanding battle. But in this particular fight between these two tech giants, you know, Apple has the upper hand. It gets to set the rules for its phones. And, you know, Facebook can complain that it doesn't have a lot of choice. KELLY: NPR tech correspondent Shannon Bond, thanks for your reporting. BOND: Thank you. (SOUNDBITE OF EXMAG'S \"ZAN\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-04-20-989115774": {"title": "Apple Will Reinstate Parler In App Store Next Week : NPR", "url": "https://www.npr.org/2021/04/20/989115774/far-right-friendly-platform-parler-expected-to-return-to-app-store-next-week", "author": "No author found", "published_date": "2021-04-20", "content": "", "section": "Technology", "disclaimer": ""}, "2021-04-22-989862270": {"title": "Zeran v. AOL Section 230 Legal Fight Led To Big Tech : The Indicator from Planet Money : NPR", "url": "https://www.npr.org/2021/04/22/989862270/the-26-words-that-made-the-internet-what-it-is", "author": "No author found", "published_date": "2021-04-22", "content": "SYLVIE DOUGLIS, BYLINE: NPR. (SOUNDBITE OF DROP ELECTRIC SONG, \"WAKING UP TO THE FIRE\")BOBBY ALLYN, HOST:  Hey, everyone. This is THE INDICATOR FROM PLANET MONEY. I'm Bobby Allyn. SHANNON BOND, HOST:  And I'm Shannon Bond. Stacey Vanek Smith is back next week. So Bobby and I are here from NPR's business desk, where we cover tech. And something we've been talking about a lot is this 26-word sentence. It's this one confusing paragraph in an old law that made the Internet what it is, for better and for worse. ALLYN: Facebook, Twitter, YouTube - they all say they're able to exist because of these 26 very ambiguous and confusing words. And fair warning here, they're very boring. But it's also just 26 words, so let's just get them out of the way. No provider or user of any interactive computer service shall be treated as the publisher or speaker of any information provided by another information content provider. What? BOND: I mean, interactive computer service. . . ALLYN: Whatever that means. BOND: . . . Information content provider. Like, what is this? Clearly, these words are not how we talk about the Internet today, and that's because they were written when Mark Zuckerberg was just 11 years old, before Google even existed. The year was 1996, back when most people got on to the World Wide Web by using a dial-up connection, back when they fired up their modems to get on America Online or CompuServe or Prodigy. ALLYN: What these words say, in a nutshell, is a website is not legally responsible for what its users post. These words are why we have social media, but also Yelp, Wikipedia, Amazon reviews. They're the reason why any website that lets people post stuff can exist as they do now. And many people argue these words also enabled the most toxic parts of the Internet - the bullying, the harassment, the spread of disinformation. BOND: Today on the show, the 26 words at the heart of Section 230 of the Communications Decency Act of 1996. ALLYN: We'll tell you the story of one man's legal fight and how it turned those 26 words into a shield big tech companies hide behind to this day. (SOUNDBITE OF MUSIC)ALLYN: In April 1995, Ken Zeran's phone started ringing and ringing some more. It just wouldn't stop. KEN ZERAN: Lots of calls. It wasn't like every second, but it was just lots of calls. ALLYN: Ken had no idea what was going on. He ran a real estate magazine in Seattle, but these calls had nothing to do with that. These callers were angry. This was the era of landline phones, no caller ID. So he'd answer. And it would just be people screaming and cursing. Often, they'd hang up before he could even figure out why they were so mad. BOND: He'd eventually learn that it had to do with a post online on the Internet service AOL or America Online. And AOL at that time was filled with lots of message boards. And someone else had posted this message under the screen name KenZZ03 with Ken's real phone number. This early Internet troll was purporting to sell great Oklahoma T-shirts. And this was just days after a domestic terrorist bombing in Oklahoma City killed more than 160 people. These shirts, they were just awful. They had slogans making light of the bombing and saying tasteless things about the victims. And the ads infuriated people. ZERAN: How could you do this? What a loser you are. I mean, I'm just paraphrasing all of it now. You could use your own sense and think of what they might be saying, given what had just happened in Oklahoma City. ALLYN: In the post, one troll wrote, quote, \"ask for Ken. Due to high demand, please call back if busy. \" But not only did Ken nothing about this ad, he didn't even use AOL. So he called AOL. ZERAN: And basically, I told him, you know, my phone's ringing off the hook. And I can't get anything done. And it's all these people upset about something that they saw on AOL. BOND: AOL took the post down, but another popped up, then another and another, a familiar cat-and-mouse game. ALLYN: He tried AOL's legal department, the FBI, the Secret Service. He called everyone he could to get these ads taken down. But his phone kept ringing and ringing, dozens of calls a day. Ken started to get freaked out. ZERAN: I didn't want the thing to go any further and have some. . . ALLYN: Yeah. ZERAN: . . . You know, nitwit show up with a shotgun. The problem was AOL would not post something on their server telling their audience that this is a bunch of baloney, a hoax or whatever. And so the calls kept coming. ALLYN: OK. So Ken thought AOL had a big part to play in this. He said they didn't take the post seriously, even though he told them again and again that this post was causing him so much grief. ZERAN: And then it became - the whole focus of it became, well, AOL, what are you going to do about it? ALLYN: So he sued AOL. And he didn't know it at the time, but this lawsuit would eventually form the legal foundation for the Internet we know and don't exactly love today. BOND: Because Ken lost. As the Fourth Circuit Court of Appeals saw it, being able to sue AOL for what someone posted could be disastrous for the Internet. And the court, it had to make a tough decision. Does it protect Ken and let him go after damages from AOL? And then maybe AOL just shuts down whole message boards because they're too risky. Or does the court protect the Internet as an idea and let these new up-and-coming companies grow without worrying about getting sued over every single thing someone posts? ALLYN: It can be hard to show just how significant a moment this was, so we called up Jeff Kosseff. He wrote the book - literally - on Section 230. And he says the way the court interpreted the law, it was a big change from how courts treated newspapers and TV and radio. The Internet became an exception. JEFF KOSSEFF: That's what's really remarkable was that they took this really exceptionalist view by saying, you know, Congress wanted to treat the Internet differently than other media. BOND: So what he's saying here is if someone had run these same ads about these T-shirts in the classifieds section of a newspaper, Ken could have sued the newspaper. He might not have won that lawsuit, but he could have had his day in court. But what this ruling in Ken's case means is he doesn't even get to argue the merits of his case. He simply cannot sue AOL over these posts, period. ALLYN: To this day, the Zeran case is the law of the land. It's been cited in opinions 350 times, which every legal expert we talked to said, technically speaking, is a whole lot of citations for a case. KOSSEFF: What the Zeran case did was it provided the flexibility to these online services to develop their business models around user content and develop their own policies and practices for moderation. BOND: Which is to say, tech companies can set their own rules about what you can and can't post. But if someone posts something about you on Facebook that you think is abusive or harmful or defamatory, you can't take Facebook to court. Kosseff and many other scholars of the Internet say this decision allowed social media companies and other online sites to grow and grow without worry about the risk of getting sued for what people post. ALLYN: Yeah. And it also means that if companies like Facebook or YouTube want to get better at patrolling the dangerous stuff on their websites, that's completely up to them. There's no government penalty for being too slow or doing nothing at all. BOND: Take the Capitol insurrection on January 6. It was planned and documented on social media. And now we're seeing charges, even a guilty plea among the rioters. But who's not getting charged? The social media sites - Facebook, Twitter, Parler - because of how Ken's case interpreted Section 230. So to change the way the Internet works, that means changing the underlying law the case is based on, those 26 words. ALLYN: And now in Washington, there's a big push to rewrite Section 230 to say, for example, the Internet platforms need to do more to earn this legal shield, like by showing that they have proactive systems in place to remove illegal posts. BOND: There are a lot of proposals in Congress, and it's not clear what will win out. But change does feel inevitable because getting tough on big tech is one of the few areas these days where there's real bipartisan energy. ALLYN: And Ken - who, by the way, never found who was behind the trolling - he says he's happy that a fix might be on the way, even though for him it's 26 years too late. ZERAN: And there's no putting the genie back in of what we have now. But this is what we have, and it's not working well. BOND: Today's episode of THE INDICATOR was produced by Emma Peaslee and Dave Blanchard. It was fact-checked by Sam Caiand edited by Alex Goldmark. And if you have suggestions for the show or ideas of what you want THE INDICATOR to cover, email us at indicator@npr. org. THE INDICATOR is a production of NPR. SYLVIE DOUGLIS, BYLINE: NPR. (SOUNDBITE OF DROP ELECTRIC SONG, \"WAKING UP TO THE FIRE\") BOBBY ALLYN, HOST:   Hey, everyone. This is THE INDICATOR FROM PLANET MONEY. I'm Bobby Allyn. SHANNON BOND, HOST:   And I'm Shannon Bond. Stacey Vanek Smith is back next week. So Bobby and I are here from NPR's business desk, where we cover tech. And something we've been talking about a lot is this 26-word sentence. It's this one confusing paragraph in an old law that made the Internet what it is, for better and for worse. ALLYN: Facebook, Twitter, YouTube - they all say they're able to exist because of these 26 very ambiguous and confusing words. And fair warning here, they're very boring. But it's also just 26 words, so let's just get them out of the way. No provider or user of any interactive computer service shall be treated as the publisher or speaker of any information provided by another information content provider. What? BOND: I mean, interactive computer service. . . ALLYN: Whatever that means. BOND: . . . Information content provider. Like, what is this? Clearly, these words are not how we talk about the Internet today, and that's because they were written when Mark Zuckerberg was just 11 years old, before Google even existed. The year was 1996, back when most people got on to the World Wide Web by using a dial-up connection, back when they fired up their modems to get on America Online or CompuServe or Prodigy. ALLYN: What these words say, in a nutshell, is a website is not legally responsible for what its users post. These words are why we have social media, but also Yelp, Wikipedia, Amazon reviews. They're the reason why any website that lets people post stuff can exist as they do now. And many people argue these words also enabled the most toxic parts of the Internet - the bullying, the harassment, the spread of disinformation. BOND: Today on the show, the 26 words at the heart of Section 230 of the Communications Decency Act of 1996. ALLYN: We'll tell you the story of one man's legal fight and how it turned those 26 words into a shield big tech companies hide behind to this day. (SOUNDBITE OF MUSIC) ALLYN: In April 1995, Ken Zeran's phone started ringing and ringing some more. It just wouldn't stop. KEN ZERAN: Lots of calls. It wasn't like every second, but it was just lots of calls. ALLYN: Ken had no idea what was going on. He ran a real estate magazine in Seattle, but these calls had nothing to do with that. These callers were angry. This was the era of landline phones, no caller ID. So he'd answer. And it would just be people screaming and cursing. Often, they'd hang up before he could even figure out why they were so mad. BOND: He'd eventually learn that it had to do with a post online on the Internet service AOL or America Online. And AOL at that time was filled with lots of message boards. And someone else had posted this message under the screen name KenZZ03 with Ken's real phone number. This early Internet troll was purporting to sell great Oklahoma T-shirts. And this was just days after a domestic terrorist bombing in Oklahoma City killed more than 160 people. These shirts, they were just awful. They had slogans making light of the bombing and saying tasteless things about the victims. And the ads infuriated people. ZERAN: How could you do this? What a loser you are. I mean, I'm just paraphrasing all of it now. You could use your own sense and think of what they might be saying, given what had just happened in Oklahoma City. ALLYN: In the post, one troll wrote, quote, \"ask for Ken. Due to high demand, please call back if busy. \" But not only did Ken nothing about this ad, he didn't even use AOL. So he called AOL. ZERAN: And basically, I told him, you know, my phone's ringing off the hook. And I can't get anything done. And it's all these people upset about something that they saw on AOL. BOND: AOL took the post down, but another popped up, then another and another, a familiar cat-and-mouse game. ALLYN: He tried AOL's legal department, the FBI, the Secret Service. He called everyone he could to get these ads taken down. But his phone kept ringing and ringing, dozens of calls a day. Ken started to get freaked out. ZERAN: I didn't want the thing to go any further and have some. . . ALLYN: Yeah. ZERAN: . . . You know, nitwit show up with a shotgun. The problem was AOL would not post something on their server telling their audience that this is a bunch of baloney, a hoax or whatever. And so the calls kept coming. ALLYN: OK. So Ken thought AOL had a big part to play in this. He said they didn't take the post seriously, even though he told them again and again that this post was causing him so much grief. ZERAN: And then it became - the whole focus of it became, well, AOL, what are you going to do about it? ALLYN: So he sued AOL. And he didn't know it at the time, but this lawsuit would eventually form the legal foundation for the Internet we know and don't exactly love today. BOND: Because Ken lost. As the Fourth Circuit Court of Appeals saw it, being able to sue AOL for what someone posted could be disastrous for the Internet. And the court, it had to make a tough decision. Does it protect Ken and let him go after damages from AOL? And then maybe AOL just shuts down whole message boards because they're too risky. Or does the court protect the Internet as an idea and let these new up-and-coming companies grow without worrying about getting sued over every single thing someone posts? ALLYN: It can be hard to show just how significant a moment this was, so we called up Jeff Kosseff. He wrote the book - literally - on Section 230. And he says the way the court interpreted the law, it was a big change from how courts treated newspapers and TV and radio. The Internet became an exception. JEFF KOSSEFF: That's what's really remarkable was that they took this really exceptionalist view by saying, you know, Congress wanted to treat the Internet differently than other media. BOND: So what he's saying here is if someone had run these same ads about these T-shirts in the classifieds section of a newspaper, Ken could have sued the newspaper. He might not have won that lawsuit, but he could have had his day in court. But what this ruling in Ken's case means is he doesn't even get to argue the merits of his case. He simply cannot sue AOL over these posts, period. ALLYN: To this day, the Zeran case is the law of the land. It's been cited in opinions 350 times, which every legal expert we talked to said, technically speaking, is a whole lot of citations for a case. KOSSEFF: What the Zeran case did was it provided the flexibility to these online services to develop their business models around user content and develop their own policies and practices for moderation. BOND: Which is to say, tech companies can set their own rules about what you can and can't post. But if someone posts something about you on Facebook that you think is abusive or harmful or defamatory, you can't take Facebook to court. Kosseff and many other scholars of the Internet say this decision allowed social media companies and other online sites to grow and grow without worry about the risk of getting sued for what people post. ALLYN: Yeah. And it also means that if companies like Facebook or YouTube want to get better at patrolling the dangerous stuff on their websites, that's completely up to them. There's no government penalty for being too slow or doing nothing at all. BOND: Take the Capitol insurrection on January 6. It was planned and documented on social media. And now we're seeing charges, even a guilty plea among the rioters. But who's not getting charged? The social media sites - Facebook, Twitter, Parler - because of how Ken's case interpreted Section 230. So to change the way the Internet works, that means changing the underlying law the case is based on, those 26 words. ALLYN: And now in Washington, there's a big push to rewrite Section 230 to say, for example, the Internet platforms need to do more to earn this legal shield, like by showing that they have proactive systems in place to remove illegal posts. BOND: There are a lot of proposals in Congress, and it's not clear what will win out. But change does feel inevitable because getting tough on big tech is one of the few areas these days where there's real bipartisan energy. ALLYN: And Ken - who, by the way, never found who was behind the trolling - he says he's happy that a fix might be on the way, even though for him it's 26 years too late. ZERAN: And there's no putting the genie back in of what we have now. But this is what we have, and it's not working well. BOND: Today's episode of THE INDICATOR was produced by Emma Peaslee and Dave Blanchard. It was fact-checked by Sam Caiand edited by Alex Goldmark. And if you have suggestions for the show or ideas of what you want THE INDICATOR to cover, email us at indicator@npr. org. THE INDICATOR is a production of NPR.", "section": "The 26 Words That Made The Internet What It Is", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-04-23-988816176": {"title": "In Iran, Clubhouse Means Unfiltered Chats, Even With Top Officials. But For How Long? : NPR", "url": "https://www.npr.org/2021/04/23/988816176/in-iran-clubhouse-means-unfiltered-chats-even-with-top-officials-but-for-how-lon", "author": "No author found", "published_date": "2021-04-23", "content": "MARY LOUISE KELLY, HOST:  Iranians have been using the app Clubhouse, which hosts people joining discussions on lots of topics, your choice. At first, it seemed like Iranian officials were surprisingly open to the conversations. They joined in themselves. But as NPR's Peter Kenyon reports, after a controversy involving the country's top diplomat, some are calling for Clubhouse to be restricted or banned. PETER KENYON, BYLINE: Haniyeh, a language teacher in Tehran, likes to join conversations on Clubhouse about poetry, literature and education. Reached via WhatsApp, she asked that her family name not be used for fear of retribution for speaking with an American media outlet. What makes Clubhouse popular? Haniyeh has some ideas about that. HANIYEH: (Through interpreter) Well, Iranians have always liked social apps. The reason might be that building relationships and connections in the outside world is harder. Some people are shy. But in cyber-world, people can talk more freely. And I think if this app is not filtered in the future, it has a really high potential for all people to express their ideas freely. KENYON: Haniyeh says she stays out of the political conversations, but she's noticed that the invitation-only app became a virtual soapbox for some, including Iranian officials. HANIYEH: (Through interpreter) The presence of Iranian politicians on Clubhouse has been very interesting. I've heard from my own friends who participated in Mr. Zarif's room, for example, about the China deal. KENYON: That's Zarif as in Iranian Foreign Minister Mohammad Javad Zarif. On March 31, officials were on Clubhouse taking questions about a new agreement between Iran and China when Zarif himself popped into the conversation. Amir Rashidi, a New York-based digital rights and Internet security researcher, says the conversation turned from the China deal to politics. Rashidi says Zarif exploded in anger at a recent TV series in Iran called \"Gando,\" reportedly produced with the aid of Iran's Revolutionary Guard Corps, that portrays the Iranian government and the foreign minister in particular as corrupt and incompetent. AMIR RASHIDI: Well, he was really mad, yelling because of - you know, he was really outrageous about that TV series. Basically, his argument was, we are trying to do our best. I want to go back to the university and, you know, teaching and things like that. KENYON: Rashidi and others say those kind of direct conversations don't normally happen in Iran. But let's make clear that Clubhouse is not a huge phenomenon in Iran, perhaps being used by tens of thousands of Iranians. And while Zarif and Iranian officials have used Clubhouse, pressure to restrict it in Iran could mount as the June election nears. Rashidi cites the example of another app, Telegram, which Iranian reformers successfully used in 2016 to mobilize support for their parliamentary candidates. RASHIDI: But a month after that, the Iranian authority arrested 12 admin of reformists Telegram channels. And basically two months after the election, they blocked Telegram. KENYON: Rashidi says the fate of Clubhouse in Iran may depend on what kind of presidential election the authorities want this June - a lively race with high voter turnout or a tightly controlled process that improves the odds for their preferred candidate. If it's the latter, Clubhouse could face official scrutiny. The hardline Kayhan news outlet has already begun calling on the government to impose, quote, \"authoritarian filtering\" on such platforms. Peter Kenyon, NPR News, Istanbul. (SOUNDBITE OF ODDISEE'S \"SOCIAL INSECURITY\") MARY LOUISE KELLY, HOST:   Iranians have been using the app Clubhouse, which hosts people joining discussions on lots of topics, your choice. At first, it seemed like Iranian officials were surprisingly open to the conversations. They joined in themselves. But as NPR's Peter Kenyon reports, after a controversy involving the country's top diplomat, some are calling for Clubhouse to be restricted or banned. PETER KENYON, BYLINE: Haniyeh, a language teacher in Tehran, likes to join conversations on Clubhouse about poetry, literature and education. Reached via WhatsApp, she asked that her family name not be used for fear of retribution for speaking with an American media outlet. What makes Clubhouse popular? Haniyeh has some ideas about that. HANIYEH: (Through interpreter) Well, Iranians have always liked social apps. The reason might be that building relationships and connections in the outside world is harder. Some people are shy. But in cyber-world, people can talk more freely. And I think if this app is not filtered in the future, it has a really high potential for all people to express their ideas freely. KENYON: Haniyeh says she stays out of the political conversations, but she's noticed that the invitation-only app became a virtual soapbox for some, including Iranian officials. HANIYEH: (Through interpreter) The presence of Iranian politicians on Clubhouse has been very interesting. I've heard from my own friends who participated in Mr. Zarif's room, for example, about the China deal. KENYON: That's Zarif as in Iranian Foreign Minister Mohammad Javad Zarif. On March 31, officials were on Clubhouse taking questions about a new agreement between Iran and China when Zarif himself popped into the conversation. Amir Rashidi, a New York-based digital rights and Internet security researcher, says the conversation turned from the China deal to politics. Rashidi says Zarif exploded in anger at a recent TV series in Iran called \"Gando,\" reportedly produced with the aid of Iran's Revolutionary Guard Corps, that portrays the Iranian government and the foreign minister in particular as corrupt and incompetent. AMIR RASHIDI: Well, he was really mad, yelling because of - you know, he was really outrageous about that TV series. Basically, his argument was, we are trying to do our best. I want to go back to the university and, you know, teaching and things like that. KENYON: Rashidi and others say those kind of direct conversations don't normally happen in Iran. But let's make clear that Clubhouse is not a huge phenomenon in Iran, perhaps being used by tens of thousands of Iranians. And while Zarif and Iranian officials have used Clubhouse, pressure to restrict it in Iran could mount as the June election nears. Rashidi cites the example of another app, Telegram, which Iranian reformers successfully used in 2016 to mobilize support for their parliamentary candidates. RASHIDI: But a month after that, the Iranian authority arrested 12 admin of reformists Telegram channels. And basically two months after the election, they blocked Telegram. KENYON: Rashidi says the fate of Clubhouse in Iran may depend on what kind of presidential election the authorities want this June - a lively race with high voter turnout or a tightly controlled process that improves the odds for their preferred candidate. If it's the latter, Clubhouse could face official scrutiny. The hardline Kayhan news outlet has already begun calling on the government to impose, quote, \"authoritarian filtering\" on such platforms. Peter Kenyon, NPR News, Istanbul. (SOUNDBITE OF ODDISEE'S \"SOCIAL INSECURITY\")", "section": "World", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-04-25-990603441": {"title": "Elon Musk To Host 'Saturday Night Live' On May 8 : NPR", "url": "https://www.npr.org/2021/04/25/990603441/elon-musk-to-host-saturday-night-live", "author": "No author found", "published_date": "2021-04-25", "content": "", "section": "Television", "disclaimer": ""}, "2021-04-25-988860971": {"title": "Father And Daughter, Divided By Disinformation On YouTube  : NPR", "url": "https://www.npr.org/2021/04/25/988860971/full-of-hatred-and-fear-disinformation-on-youtube-divided-a-dad-and-daughter", "author": "No author found", "published_date": "2021-04-25", "content": "", "section": "Technology", "disclaimer": ""}, "2021-04-26-990943261": {"title": "Apple Launches Major New Privacy Protections For iPhones And iPads : NPR", "url": "https://www.npr.org/2021/04/26/990943261/apple-rolls-out-major-new-privacy-protections-for-iphones-and-ipads", "author": "No author found", "published_date": "2021-04-26", "content": "", "section": "Technology", "disclaimer": ""}, "2021-04-26-990792665": {"title": "Parler's New iPhone App Will Block Posts That Apple Prohibits : NPR", "url": "https://www.npr.org/2021/04/26/990792665/parlers-new-iphone-app-will-block-posts-that-apple-prohibits", "author": "No author found", "published_date": "2021-04-26", "content": "NOEL KING, HOST:  The social media network Parler calls itself a platform for free speech. Apple and Google banned the app from their stores after the insurrection at the Capitol on January 6. They said Parler allowed violent and offensive posts. But now it is coming back, and NPR's Shannon Bond asked, what has changed? I should note, Apple and Google are among NPR's financial supporters. SHANNON BOND, BYLINE: When pro-Trump rioters breached the Capitol, many of them documented it in videos posted on Parler. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED RIOTER #1: Here we go. Here's the next rush. BOND: Breaking doors, shattering windows, milling around the rotunda. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED RIOTER #2: Inside the Capitol building. BOND: Parler was already known as a hotbed for baseless conspiracy theories and election fraud claims. But for the big tech companies, January 6 was the last straw. Apple and Google kicked Parler out of their app stores, basically cutting it off from smartphones. Amazon refused to host the site anymore, effectively booting it off the Internet altogether. The tech companies all said Parler was violating their rules against harmful content, and that really hurt Parler. Its website eventually got back online, but it was buggy and really hard to use. JARED HOLT: You know, some people - maybe the most devout free speech absolutists or whatnot - will take those extra steps to get to Parler, but it's a numbers game, you know? Most people will not. BOND: Jared Holt studies online extremism at the Atlantic Council's Digital Forensic Research Lab. So overnight, Parler went from one of the most downloaded apps - claiming 20 million users, fueled by Trump loyalists and conservative influencers who say Facebook and Twitter censor them - to nearly impossible for most people to find and use. Now, more than three months later, Parler says it's made changes to satisfy Apple, but it's still sticking to its free speech mantra. Holt says the company didn't have much choice. HOLT: It is such an advantage to them that they are willing to compromise a bit on their original vision for this platform. BOND: Apple demanded Parler do more to keep offensive and discriminatory posts off its platform, so Parler says its new iPhone app will block posts that Apple prohibits. But those same posts will still be on Parler's website and its Android app, which, unlike the iPhone version, can be downloaded outside of Google's app store. To be clear, Parler says it does not allow illegal content, and it's put new safeguards in place to detect it. Shannon McGregor studies social media at the University of North Carolina at Chapel Hill. She says Parler's trying to walk a fine line, following Apple's rules while satisfying people who were attracted by its anything goes philosophy. SHANNON MCGREGOR: If the appeal of Parler was some unfettered free speech zone, then will they want to be on an app where the most extreme views, the most hateful and violent views, are not going to be allowed any longer? BOND: And if those motivations conflict, which version of Parler will win? Even if Parler is no longer as popular as it once was, it's still a potent political symbol as Congress looks to crack down on Silicon Valley. To many Republicans, it's a prime example of how tech giants abuse their power. Here's Senator Mike Lee of Utah at a hearing last week. (SOUNDBITE OF ARCHIVED RECORDING)MIKE LEE: If Big Tech is going to take a side in the culture wars or in political conversations, Big Tech should be prepared for the greater scrutiny that will come with that unfortunate choice. BOND: And that means Parler will continue to play a role, no matter how many people actually use it. Shannon Bond, NPR News. (SOUNDBITE OF SUBLAB AND AZALEH'S \"VIDURA\") NOEL KING, HOST:   The social media network Parler calls itself a platform for free speech. Apple and Google banned the app from their stores after the insurrection at the Capitol on January 6. They said Parler allowed violent and offensive posts. But now it is coming back, and NPR's Shannon Bond asked, what has changed? I should note, Apple and Google are among NPR's financial supporters. SHANNON BOND, BYLINE: When pro-Trump rioters breached the Capitol, many of them documented it in videos posted on Parler. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED RIOTER #1: Here we go. Here's the next rush. BOND: Breaking doors, shattering windows, milling around the rotunda. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED RIOTER #2: Inside the Capitol building. BOND: Parler was already known as a hotbed for baseless conspiracy theories and election fraud claims. But for the big tech companies, January 6 was the last straw. Apple and Google kicked Parler out of their app stores, basically cutting it off from smartphones. Amazon refused to host the site anymore, effectively booting it off the Internet altogether. The tech companies all said Parler was violating their rules against harmful content, and that really hurt Parler. Its website eventually got back online, but it was buggy and really hard to use. JARED HOLT: You know, some people - maybe the most devout free speech absolutists or whatnot - will take those extra steps to get to Parler, but it's a numbers game, you know? Most people will not. BOND: Jared Holt studies online extremism at the Atlantic Council's Digital Forensic Research Lab. So overnight, Parler went from one of the most downloaded apps - claiming 20 million users, fueled by Trump loyalists and conservative influencers who say Facebook and Twitter censor them - to nearly impossible for most people to find and use. Now, more than three months later, Parler says it's made changes to satisfy Apple, but it's still sticking to its free speech mantra. Holt says the company didn't have much choice. HOLT: It is such an advantage to them that they are willing to compromise a bit on their original vision for this platform. BOND: Apple demanded Parler do more to keep offensive and discriminatory posts off its platform, so Parler says its new iPhone app will block posts that Apple prohibits. But those same posts will still be on Parler's website and its Android app, which, unlike the iPhone version, can be downloaded outside of Google's app store. To be clear, Parler says it does not allow illegal content, and it's put new safeguards in place to detect it. Shannon McGregor studies social media at the University of North Carolina at Chapel Hill. She says Parler's trying to walk a fine line, following Apple's rules while satisfying people who were attracted by its anything goes philosophy. SHANNON MCGREGOR: If the appeal of Parler was some unfettered free speech zone, then will they want to be on an app where the most extreme views, the most hateful and violent views, are not going to be allowed any longer? BOND: And if those motivations conflict, which version of Parler will win? Even if Parler is no longer as popular as it once was, it's still a potent political symbol as Congress looks to crack down on Silicon Valley. To many Republicans, it's a prime example of how tech giants abuse their power. Here's Senator Mike Lee of Utah at a hearing last week. (SOUNDBITE OF ARCHIVED RECORDING) MIKE LEE: If Big Tech is going to take a side in the culture wars or in political conversations, Big Tech should be prepared for the greater scrutiny that will come with that unfortunate choice. BOND: And that means Parler will continue to play a role, no matter how many people actually use it. Shannon Bond, NPR News. (SOUNDBITE OF SUBLAB AND AZALEH'S \"VIDURA\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-04-27-991343032": {"title": "India's Government Is Telling Facebook, Twitter To Remove Critical Posts : NPR", "url": "https://www.npr.org/2021/04/27/991343032/indias-government-is-telling-facebook-twitter-to-remove-critical-posts", "author": "No author found", "published_date": "2021-04-27", "content": "AUDIE CORNISH, HOST:  India is grappling with a devastating surge in COVID cases, sending its health system to the verge of collapse. Now the Indian government has ordered Facebook and Twitter to take down posts, many of which show just how dire things really are, and the social companies are complying. NPR tech correspondent Shannon Bond is here to explain why. And, Shannon, we're going to start, of course, by noting Facebook is among NPR's financial supporters. Help us understand how the Indian government has made this approach to social media companies. SHANNON BOND, BYLINE: Right. The government says it's ordered Twitter, Facebook and Instagram to take down about a hundred posts. And according to local media reports, the government says these were cases where it said people were misusing social media to create panic during the pandemic. And so sources familiar with the companies tell me that Twitter and Facebook have complied in some of these cases but not all of them. And what that means is for some of these posts, they are blocking them from appearing on their services in India, although we can still see them outside of India. CORNISH: Can you give an example of the kind of post that might have been taken down? BOND: Yeah. So many were critical of Prime Minister Narendra Modi's management of this crisis. They've been sharing pictures of the devastation in India, pictures of bodies lying on the ground. Some were showing burning funeral pyres side by side with these big political rallies that were held in recent months. And some of these were from really high-profile users. So these were people like journalists and even political opponents of Modi. And now, of course, Audie, India is the world's largest democracy, but this is an escalating pattern that we have seen from Modi's government of stifling dissent. CORNISH: I want to come back to that. But first, these companies are always talking about freedom of expression - right? - talking about it like a core value. Why are they saying they're complying with this request? BOND: Right. I think they're in a pretty difficult situation here. You know, if they want to operate in a country like India, they have to follow local laws. So, you know, Twitter said in a statement it's complying with Indian law. That's its policy. So even if a post does not break Twitter's rules, if it breaks local law, Twitter will block the post in that country. And, you know, these - there are real consequences here. Just a few months ago, India threatened to throw Twitter employees in jail when Twitter refused to block some of Modi's critics on the platform. Now, Facebook declined to comment on this, and it's a little hard to know much more about what's happening inside the companies. Indian law limits what the companies can say about these government orders, so we don't know exactly how many of these posts actually have been blocked out of, you know, the total number of takedown notices the government has issued. But clearly, this is a case where this order is in conflict with the values these companies say they were founded on, like free speech - this idea that, you know, they provide a platform for anyone. CORNISH: Is it fair to say it's also, like, a major profit market, right? BOND: Yeah. I mean, India is a huge market - hundreds of millions of users. Facebook, its WhatsApp messaging service are very popular there. Twitter is less so. But, you know, Modi himself - he's a big Twitter user. He's actually now the world leader with the most followers. And at the same time, these companies and their products - they're providing really powerful tools to people in India right now to, you know, raise money, crowdsource urgently needed medical aid in this moment of this COVID crisis. And, of course, people are using them to criticize the government. But we're seeing that criticism is clearly sort of being received by Modi's government as a threat, so we're seeing this increasingly aggressive pattern of crackdowns on dissent by his government. And, you know, this is just the latest example of that. CORNISH: That's NPR's Shannon Bond. Thank you. BOND: Thanks so much, Audie. AUDIE CORNISH, HOST:   India is grappling with a devastating surge in COVID cases, sending its health system to the verge of collapse. Now the Indian government has ordered Facebook and Twitter to take down posts, many of which show just how dire things really are, and the social companies are complying. NPR tech correspondent Shannon Bond is here to explain why. And, Shannon, we're going to start, of course, by noting Facebook is among NPR's financial supporters. Help us understand how the Indian government has made this approach to social media companies. SHANNON BOND, BYLINE: Right. The government says it's ordered Twitter, Facebook and Instagram to take down about a hundred posts. And according to local media reports, the government says these were cases where it said people were misusing social media to create panic during the pandemic. And so sources familiar with the companies tell me that Twitter and Facebook have complied in some of these cases but not all of them. And what that means is for some of these posts, they are blocking them from appearing on their services in India, although we can still see them outside of India. CORNISH: Can you give an example of the kind of post that might have been taken down? BOND: Yeah. So many were critical of Prime Minister Narendra Modi's management of this crisis. They've been sharing pictures of the devastation in India, pictures of bodies lying on the ground. Some were showing burning funeral pyres side by side with these big political rallies that were held in recent months. And some of these were from really high-profile users. So these were people like journalists and even political opponents of Modi. And now, of course, Audie, India is the world's largest democracy, but this is an escalating pattern that we have seen from Modi's government of stifling dissent. CORNISH: I want to come back to that. But first, these companies are always talking about freedom of expression - right? - talking about it like a core value. Why are they saying they're complying with this request? BOND: Right. I think they're in a pretty difficult situation here. You know, if they want to operate in a country like India, they have to follow local laws. So, you know, Twitter said in a statement it's complying with Indian law. That's its policy. So even if a post does not break Twitter's rules, if it breaks local law, Twitter will block the post in that country. And, you know, these - there are real consequences here. Just a few months ago, India threatened to throw Twitter employees in jail when Twitter refused to block some of Modi's critics on the platform. Now, Facebook declined to comment on this, and it's a little hard to know much more about what's happening inside the companies. Indian law limits what the companies can say about these government orders, so we don't know exactly how many of these posts actually have been blocked out of, you know, the total number of takedown notices the government has issued. But clearly, this is a case where this order is in conflict with the values these companies say they were founded on, like free speech - this idea that, you know, they provide a platform for anyone. CORNISH: Is it fair to say it's also, like, a major profit market, right? BOND: Yeah. I mean, India is a huge market - hundreds of millions of users. Facebook, its WhatsApp messaging service are very popular there. Twitter is less so. But, you know, Modi himself - he's a big Twitter user. He's actually now the world leader with the most followers. And at the same time, these companies and their products - they're providing really powerful tools to people in India right now to, you know, raise money, crowdsource urgently needed medical aid in this moment of this COVID crisis. And, of course, people are using them to criticize the government. But we're seeing that criticism is clearly sort of being received by Modi's government as a threat, so we're seeing this increasingly aggressive pattern of crackdowns on dissent by his government. And, you know, this is just the latest example of that. CORNISH: That's NPR's Shannon Bond. Thank you. BOND: Thanks so much, Audie.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-04-27-991116344": {"title": "D.C. Police Department Victim Of Apparent Ransomware Attack : NPR", "url": "https://www.npr.org/2021/04/27/991116344/d-c-police-department-victim-of-apparent-ransomware-attack", "author": "No author found", "published_date": "2021-04-27", "content": "", "section": "Technology", "disclaimer": ""}, "2021-04-29-991933904": {"title": "Get Ready For A Shortage Of iPads And MacBooks : NPR", "url": "https://www.npr.org/2021/04/29/991933904/its-not-just-cars-ipads-and-macs-suffer-wrath-of-semiconductor-crunch", "author": "No author found", "published_date": "2021-04-29", "content": "", "section": "Business", "disclaimer": ""}, "2021-04-29-991684891": {"title": "With Ransomware Attacks, Criminals Have The Upper Hand : NPR", "url": "https://www.npr.org/2021/04/29/991684891/in-the-ransomware-battle-cyber-criminals-have-the-upper-hand", "author": "No author found", "published_date": "2021-04-29", "content": "STEVE INSKEEP, HOST:  Hackers say they have seized many computer records from the Washington, D. C. , police. They're demanding ransom money or else they'll go public with confidential police files. This is an example of an all-too-common story. Ransomware has become an industry. NPR national security correspondent Greg Myre is here. Greg, good morning. GREG MYRE, BYLINE: Hi, Steve. INSKEEP: OK. So what happened to the D. C. police? MYRE: Well, a known ransomware group posted on the dark web this week that it had captured all this data. And it's posted a few screenshots to prove its claim. Now, the D. C. police have confirmed a breach. But they haven't provided details. They're certainly trying to determine very urgently if this is mission critical data, stuff they would need for arrests and prosecution. Or is it mostly just kind of embarrassing stuff like, perhaps, disciplinary records of police officers, names of police informants. INSKEEP: OK. So they're investigating this. And we said this is common. Is it typical that people end up paying the ransom? MYRE: Yes. It really is, Steve. Cybercriminals have the upper hand right now. Just one example - more than two dozen U. S. municipalities have already been hit this year. And overall, payments are skyrocketing. It's hard to get definitive figures because many victims don't want to go public. But Palo Alto Networks, a cybersecurity firm, says the average payment almost tripled last year, went from a little over 100,000 in 2019 to more than 300,000 last year. INSKEEP: Wow. MYRE: We also know the U. S. is the most targeted country. Many of the attackers are from Russia and Eastern Europe. And they're rarely arrested. Here's Ryan Olson of Palo Alto Networks. RYAN OLSON: There are certainly cases where people have been caught from running ransomware attacks. But it seems like it is a pretty small minority. It doesn't seem like there's a high likelihood of a ransomware attacker today ending up in handcuffs. MYRE: And that's because countries like Russia, for example, would never extradite a suspect to the U. S. INSKEEP: OK. So what is known about the Washington, D. C. , attackers? MYRE: So there's a group that calls itself Babuk. And it emerged on the dark web just earlier this year. It puts out statements in sort of awkward English and Russian, which suggests but doesn't prove they may be Russian. They've also been blamed for a recent attack against the NBA's Houston Rockets. And according to Kimberly Goody, who follows cybercrime at the firm Mandiant, ransomware attackers like Babuk are now very, very specialized. And they often partner up with someone or two or three other groups to carry out an attack and then split up the ransom money afterward. Here's what she said. KIMBERLY GOODY: With a typical ransomware operation that we see today, one threat actor is gaining access to organizations. Another is deploying the ransomware. And then maybe a third party altogether is providing the ransomware that is actually deployed. INSKEEP: So who has to be most worried about this happening to them? MYRE: So basically, everybody. Anybody can get hit. And these are often crimes of opportunity. But two groups in particular stand out, hospitals and local governments. With hospitals, obviously, data on patients is a life and death matter. If attackers lock up a computer system there, they have to respond urgently. And that almost always means paying ransom. And also, both hospitals and municipal governments do have money. They have lots of people logging onto their computer systems. Some now have insurance to pay a ransom. So they're often prime targets. The Biden administration says it will soon announce plans to upgrade cybersecurity. But it's not clear how they plan to combat ransomware. INSKEEP: Greg, thanks so much. MYRE: My pleasure. INSKEEP: NPR's Greg Myre. (SOUNDBITE OF SUBLAB AND AZALEH'S \"ARCANUM\") STEVE INSKEEP, HOST:   Hackers say they have seized many computer records from the Washington, D. C. , police. They're demanding ransom money or else they'll go public with confidential police files. This is an example of an all-too-common story. Ransomware has become an industry. NPR national security correspondent Greg Myre is here. Greg, good morning. GREG MYRE, BYLINE: Hi, Steve. INSKEEP: OK. So what happened to the D. C. police? MYRE: Well, a known ransomware group posted on the dark web this week that it had captured all this data. And it's posted a few screenshots to prove its claim. Now, the D. C. police have confirmed a breach. But they haven't provided details. They're certainly trying to determine very urgently if this is mission critical data, stuff they would need for arrests and prosecution. Or is it mostly just kind of embarrassing stuff like, perhaps, disciplinary records of police officers, names of police informants. INSKEEP: OK. So they're investigating this. And we said this is common. Is it typical that people end up paying the ransom? MYRE: Yes. It really is, Steve. Cybercriminals have the upper hand right now. Just one example - more than two dozen U. S. municipalities have already been hit this year. And overall, payments are skyrocketing. It's hard to get definitive figures because many victims don't want to go public. But Palo Alto Networks, a cybersecurity firm, says the average payment almost tripled last year, went from a little over 100,000 in 2019 to more than 300,000 last year. INSKEEP: Wow. MYRE: We also know the U. S. is the most targeted country. Many of the attackers are from Russia and Eastern Europe. And they're rarely arrested. Here's Ryan Olson of Palo Alto Networks. RYAN OLSON: There are certainly cases where people have been caught from running ransomware attacks. But it seems like it is a pretty small minority. It doesn't seem like there's a high likelihood of a ransomware attacker today ending up in handcuffs. MYRE: And that's because countries like Russia, for example, would never extradite a suspect to the U. S. INSKEEP: OK. So what is known about the Washington, D. C. , attackers? MYRE: So there's a group that calls itself Babuk. And it emerged on the dark web just earlier this year. It puts out statements in sort of awkward English and Russian, which suggests but doesn't prove they may be Russian. They've also been blamed for a recent attack against the NBA's Houston Rockets. And according to Kimberly Goody, who follows cybercrime at the firm Mandiant, ransomware attackers like Babuk are now very, very specialized. And they often partner up with someone or two or three other groups to carry out an attack and then split up the ransom money afterward. Here's what she said. KIMBERLY GOODY: With a typical ransomware operation that we see today, one threat actor is gaining access to organizations. Another is deploying the ransomware. And then maybe a third party altogether is providing the ransomware that is actually deployed. INSKEEP: So who has to be most worried about this happening to them? MYRE: So basically, everybody. Anybody can get hit. And these are often crimes of opportunity. But two groups in particular stand out, hospitals and local governments. With hospitals, obviously, data on patients is a life and death matter. If attackers lock up a computer system there, they have to respond urgently. And that almost always means paying ransom. And also, both hospitals and municipal governments do have money. They have lots of people logging onto their computer systems. Some now have insurance to pay a ransom. So they're often prime targets. The Biden administration says it will soon announce plans to upgrade cybersecurity. But it's not clear how they plan to combat ransomware. INSKEEP: Greg, thanks so much. MYRE: My pleasure. INSKEEP: NPR's Greg Myre. (SOUNDBITE OF SUBLAB AND AZALEH'S \"ARCANUM\")", "section": "National Security", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-04-29-991333036": {"title": "After SolarWinds Hack, Biden Plans Executive Order Strengthening Cybersecurity : NPR", "url": "https://www.npr.org/2021/04/29/991333036/biden-order-to-require-new-cybersecurity-standards-in-response-to-solarwinds-att", "author": "No author found", "published_date": "2021-04-29", "content": "RACHEL MARTIN, HOST:  You might remember that just before President Biden took office, the U. S. discovered a massive Russian hack of a Texas software company called SolarWinds. Now the Biden administration plans to release an executive order to prevent future hacks. Dina Temple-Raston of NPR's investigations team spoke exclusively with the senior White House adviser in charge of the response. DINA TEMPLE-RASTON, BYLINE: The U. S. hasn't had much of a strategy to battle cyber attacks. Anne Neuberger thinks it requires a change in the way we think about them. ANNE NEUBERGER: We're working to shift our mindset from responding incident by incident to preventing them in the first place. TEMPLE-RASTON: She's the deputy national security adviser for cyber and emerging technology at the White House, and she's working on an executive order slated for release in just a couple of weeks. Among other things, the order will create something like the National Transportation Safety Board. Think of a hack like a plane crash. Just as the NTSB inspects the wreckage to see if there needs to be a systematic fix, a cyber NTSB would paw through code and other evidence to do the same. NEUBERGER: What can we learn with regard to how we get advanced warning of such incidents? What allowed it to be successful? Potentially, what allowed it to be broad, if it was? Which sectors were affected? Why? TEMPLE-RASTON: And so do you think that the NTSB is a good metaphor for it? NEUBERGER: We do. TEMPLE-RASTON: Neuberger says we need a new strategy because we've become so connected. All of us are vulnerable to attack. But there still isn't a unified plan for how to respond. For example, when companies get hacked, a lot of them don't tell anyone. A way to fix that, Neuberger says, would be to require federal contractors to report any breach. NEUBERGER: If you're doing business with the federal government, then when you have an incident, you must notify us quickly because we'd like to take that incident and ensure that the tactics, techniques and procedures, the information, is broadly shared. TEMPLE-RASTON: Companies are supposed to report attacks to the Department of Homeland Security now, but because it isn't required, many don't. In next month's executive order, Neuberger said they'll set this as a goal, provide a timeline, and then establish a process to work out the details. Alex Stamos runs the Internet Observatory at Stanford University. ALEX STAMOS: This is actually kind of a weakness in our overall cyber strategy as a country, is that nobody is really in charge of looking at the big picture. TEMPLE-RASTON: He'd like the idea of a cyber NTSB and getting perspective on the threat. STAMOS: You have the FBI, which is deeply involved in incident response, but they are there to enforce the law, right? It is not their job to come up with conclusions for the entire society. You have DHS CISA, the Cybersecurity Infrastructure Security Agency. Their job is to work on defense. So they're probably the closest of the agencies to this, but they don't have any investigative powers. And so we're in this weird position where it's really nobody's job in six months to tell us what happened. TEMPLE-RASTON: What happened is that Russian hackers piggybacked on a SolarWind software update and then slipped right into Fortune 500 companies and government computer networks. Neuberger says that's a problem that needs to be addressed. NEUBERGER: If you or I are going out to buy network management software, like SolarWinds, and we want to buy the software that is most secure, we have no way, Dina, of assessing which that is. TEMPLE-RASTON: She suggests there's a way that the federal government can incentivize private companies to be safer. What if a government contract no longer went to the lowest bidder, but instead was awarded to a company that could document exactly how and where their software was built? NEUBERGER: You know what? I'm willing to pay $5 more for the more secure software because I don't want to bring more risk into my network. TEMPLE-RASTON: And they would need to say where their code was written and maintained. Kiersten Todt is the managing director of the Cyber Readiness Institute. She helped the Obama administration think through cyber issues, and she's been briefed on the new order. KIERSTEN TODT: I think it's a first step. It's definitely not the Holy Grail. It's not a destination. It's the departure point. TEMPLE-RASTON: But it's easier said than done. TODT: The key is going to be in how each of these elements of the executive order are executed and really how government is going to bring industry in to perform the functions to really look pre-event, middle of event, post-event, and how we take those lessons learned and integrate them. TEMPLE-RASTON: Todt thinks the government is going to have to work with companies to tell them what secure software looks like, and an executive order alone won't do that. And while you may never have heard of SolarWinds or been affected by that attack, we are all increasingly vulnerable. NEUBERGER: You know, cyber threats loom large in a way that Americans feel. TEMPLE-RASTON: Anne Neuberger again. NEUBERGER: Can we trust our water, our power to be resilient? We see small companies being forced to pay a ransom to get their business back up and running. You know, we see school systems' networks down due to criminals. So those risks touch everyday Americans' lives, as well as at the national level. TEMPLE-RASTON: The Biden administration has already leveled sanctions against Russia for the SolarWinds attack, and the White House has said there would be more seen and unseen responses to the breach. The unseen responses, like whether the Biden administration is preparing an attack in cyberspace, Neuberger declined to talk about directly. Dina Temple-Raston, NPR News. RACHEL MARTIN, HOST:   You might remember that just before President Biden took office, the U. S. discovered a massive Russian hack of a Texas software company called SolarWinds. Now the Biden administration plans to release an executive order to prevent future hacks. Dina Temple-Raston of NPR's investigations team spoke exclusively with the senior White House adviser in charge of the response. DINA TEMPLE-RASTON, BYLINE: The U. S. hasn't had much of a strategy to battle cyber attacks. Anne Neuberger thinks it requires a change in the way we think about them. ANNE NEUBERGER: We're working to shift our mindset from responding incident by incident to preventing them in the first place. TEMPLE-RASTON: She's the deputy national security adviser for cyber and emerging technology at the White House, and she's working on an executive order slated for release in just a couple of weeks. Among other things, the order will create something like the National Transportation Safety Board. Think of a hack like a plane crash. Just as the NTSB inspects the wreckage to see if there needs to be a systematic fix, a cyber NTSB would paw through code and other evidence to do the same. NEUBERGER: What can we learn with regard to how we get advanced warning of such incidents? What allowed it to be successful? Potentially, what allowed it to be broad, if it was? Which sectors were affected? Why? TEMPLE-RASTON: And so do you think that the NTSB is a good metaphor for it? NEUBERGER: We do. TEMPLE-RASTON: Neuberger says we need a new strategy because we've become so connected. All of us are vulnerable to attack. But there still isn't a unified plan for how to respond. For example, when companies get hacked, a lot of them don't tell anyone. A way to fix that, Neuberger says, would be to require federal contractors to report any breach. NEUBERGER: If you're doing business with the federal government, then when you have an incident, you must notify us quickly because we'd like to take that incident and ensure that the tactics, techniques and procedures, the information, is broadly shared. TEMPLE-RASTON: Companies are supposed to report attacks to the Department of Homeland Security now, but because it isn't required, many don't. In next month's executive order, Neuberger said they'll set this as a goal, provide a timeline, and then establish a process to work out the details. Alex Stamos runs the Internet Observatory at Stanford University. ALEX STAMOS: This is actually kind of a weakness in our overall cyber strategy as a country, is that nobody is really in charge of looking at the big picture. TEMPLE-RASTON: He'd like the idea of a cyber NTSB and getting perspective on the threat. STAMOS: You have the FBI, which is deeply involved in incident response, but they are there to enforce the law, right? It is not their job to come up with conclusions for the entire society. You have DHS CISA, the Cybersecurity Infrastructure Security Agency. Their job is to work on defense. So they're probably the closest of the agencies to this, but they don't have any investigative powers. And so we're in this weird position where it's really nobody's job in six months to tell us what happened. TEMPLE-RASTON: What happened is that Russian hackers piggybacked on a SolarWind software update and then slipped right into Fortune 500 companies and government computer networks. Neuberger says that's a problem that needs to be addressed. NEUBERGER: If you or I are going out to buy network management software, like SolarWinds, and we want to buy the software that is most secure, we have no way, Dina, of assessing which that is. TEMPLE-RASTON: She suggests there's a way that the federal government can incentivize private companies to be safer. What if a government contract no longer went to the lowest bidder, but instead was awarded to a company that could document exactly how and where their software was built? NEUBERGER: You know what? I'm willing to pay $5 more for the more secure software because I don't want to bring more risk into my network. TEMPLE-RASTON: And they would need to say where their code was written and maintained. Kiersten Todt is the managing director of the Cyber Readiness Institute. She helped the Obama administration think through cyber issues, and she's been briefed on the new order. KIERSTEN TODT: I think it's a first step. It's definitely not the Holy Grail. It's not a destination. It's the departure point. TEMPLE-RASTON: But it's easier said than done. TODT: The key is going to be in how each of these elements of the executive order are executed and really how government is going to bring industry in to perform the functions to really look pre-event, middle of event, post-event, and how we take those lessons learned and integrate them. TEMPLE-RASTON: Todt thinks the government is going to have to work with companies to tell them what secure software looks like, and an executive order alone won't do that. And while you may never have heard of SolarWinds or been affected by that attack, we are all increasingly vulnerable. NEUBERGER: You know, cyber threats loom large in a way that Americans feel. TEMPLE-RASTON: Anne Neuberger again. NEUBERGER: Can we trust our water, our power to be resilient? We see small companies being forced to pay a ransom to get their business back up and running. You know, we see school systems' networks down due to criminals. So those risks touch everyday Americans' lives, as well as at the national level. TEMPLE-RASTON: The Biden administration has already leveled sanctions against Russia for the SolarWinds attack, and the White House has said there would be more seen and unseen responses to the breach. The unseen responses, like whether the Biden administration is preparing an attack in cyberspace, Neuberger declined to talk about directly. Dina Temple-Raston, NPR News.", "section": "Investigations", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-04-30-992551579": {"title": "'Creepy' Robot Dog Loses Job With New York Police Department  : NPR", "url": "https://www.npr.org/2021/04/30/992551579/creepy-robot-dog-loses-job-with-new-york-police-department", "author": "No author found", "published_date": "2021-04-30", "content": "", "section": "Law", "disclaimer": ""}, "2021-04-30-992545143": {"title": "New Tiny Computers Could Have A Huge Impact : NPR", "url": "https://www.npr.org/2021/04/30/992545143/new-tiny-computers-could-have-a-huge-impact", "author": "No author found", "published_date": "2021-04-30", "content": "MARY LOUISE KELLY, HOST:  It feels like computers are getting smaller all the time. What used to fill a room now fits in your pocket. Now some companies are betting big on new ones that run at the atomic level. NPR's Geoff Brumfiel has more on how these tiny machines could have a huge impact on our lives. GEOFF BRUMFIEL, BYLINE: Inside a bland-looking suburban office building near Washington, D. C. , Christopher Monroe is working on the future. CHRISTOPHER MONROE: We actually only recently expanded, taking over the entire building. We only had a third of it before. BRUMFIEL: Monroe is chief scientist at a company called IonQ. IonQ is trying to develop an entirely new kind of computer known as a quantum computer. In a glass display case in the lobby is one of the early prototypes. MONROE: So if you look closely in that little circle there, you might be able to see a chip, a silicon chip. BRUMFIEL: The microchip looks a lot like those in other computers, but the thing is that's not what makes this quantum computer tick. The machine does calculations using individual atoms. MONROE: Atoms are basically glued to that surface. They're not glued. They're just levitating. BRUMFIEL: Above the microchip and then poked and prodded with lasers. Think of it as an atomic abacus. And the hope is that this kind of computer will be able to provide answers to really complex questions. MONROE: We're building something that's going to hit everything - oil and gas, energy, Big Pharma, financials, logistics. Almost any company that has a hard problem, which is everybody, they're going to be able to use quantum computers for it. BRUMFIEL: Quantum computers are machines that calculate using the rules of a theory called quantum mechanics. These rules govern very small things like individual atoms. Marissa Giustina works on quantum computers for Google. MARISSA GIUSTINA: Because our intuition doesn't operate according to quantum mechanics, it's kind of difficult to get a feeling for how the rules are different. But there are things we gain and things we lose, I would say. BRUMFIEL: The gains these computers are capable of are incredible. In 2019, Google's machine solved a problem in three minutes that would take a normal supercomputer up to 10,000 years. It sounds impressive, but the problem was an abstract math equation - nothing particularly useful. And there are a lot of other problems that normal computers are way better at solving than quantum machines. Simply counting numbers, for example - one, two, three - quantum computers are terrible at it. GIUSTINA: It's just hard. Our could count to, I think, four a couple of years ago. So (laughter). . . RAJIBUL ISLAM: In the future, I don't think that everybody will stop using classical machines and go to quantum. That's not going to happen. BRUMFIEL: Rajibul Islam is a researcher at the University of Waterloo in Canada. He says that normal computers aren't going to disappear, but there is evidence that quantum computers might be able to do some things that are impossible right now - break some kinds of encryption, for example, discover new materials in medicines or figure out the best way to send out packages from a central warehouse. All these difficult problems might be solvable if scientists could just build a better quantum computer. ISLAM: We know where quantum computers will make a difference. It's a matter of high-quality engineering and then making the systems better and better so that we get there. BRUMFIEL: At the moment, nobody's quite sure which application will be the killer app. But Google, IBM and other big companies are all investing heavily to make more powerful, more reliable machines. And so is IonQ. The startup has raised about 80 million in capital, and Monroe and his team are working hard on their latest quantum machines. He takes me to see them in a large room at the back of the building. MONROE: These are a couple of the next-generation systems that are being built right now, actually. BRUMFIEL: Even though IonQ's computers haven't solved any impossible problems just yet, Monroe says he's not losing any sleep. MONROE: There's so many very hard problems out there that regular computers can't touch because they're too hard. If you're going to have any hope with those problems, it has to be quantum computing. BRUMFIEL: Monroe and others believe the future is quantum. They're just not exactly sure when that future will come. Geoff Brumfiel, NPR News. MARY LOUISE KELLY, HOST:   It feels like computers are getting smaller all the time. What used to fill a room now fits in your pocket. Now some companies are betting big on new ones that run at the atomic level. NPR's Geoff Brumfiel has more on how these tiny machines could have a huge impact on our lives. GEOFF BRUMFIEL, BYLINE: Inside a bland-looking suburban office building near Washington, D. C. , Christopher Monroe is working on the future. CHRISTOPHER MONROE: We actually only recently expanded, taking over the entire building. We only had a third of it before. BRUMFIEL: Monroe is chief scientist at a company called IonQ. IonQ is trying to develop an entirely new kind of computer known as a quantum computer. In a glass display case in the lobby is one of the early prototypes. MONROE: So if you look closely in that little circle there, you might be able to see a chip, a silicon chip. BRUMFIEL: The microchip looks a lot like those in other computers, but the thing is that's not what makes this quantum computer tick. The machine does calculations using individual atoms. MONROE: Atoms are basically glued to that surface. They're not glued. They're just levitating. BRUMFIEL: Above the microchip and then poked and prodded with lasers. Think of it as an atomic abacus. And the hope is that this kind of computer will be able to provide answers to really complex questions. MONROE: We're building something that's going to hit everything - oil and gas, energy, Big Pharma, financials, logistics. Almost any company that has a hard problem, which is everybody, they're going to be able to use quantum computers for it. BRUMFIEL: Quantum computers are machines that calculate using the rules of a theory called quantum mechanics. These rules govern very small things like individual atoms. Marissa Giustina works on quantum computers for Google. MARISSA GIUSTINA: Because our intuition doesn't operate according to quantum mechanics, it's kind of difficult to get a feeling for how the rules are different. But there are things we gain and things we lose, I would say. BRUMFIEL: The gains these computers are capable of are incredible. In 2019, Google's machine solved a problem in three minutes that would take a normal supercomputer up to 10,000 years. It sounds impressive, but the problem was an abstract math equation - nothing particularly useful. And there are a lot of other problems that normal computers are way better at solving than quantum machines. Simply counting numbers, for example - one, two, three - quantum computers are terrible at it. GIUSTINA: It's just hard. Our could count to, I think, four a couple of years ago. So (laughter). . . RAJIBUL ISLAM: In the future, I don't think that everybody will stop using classical machines and go to quantum. That's not going to happen. BRUMFIEL: Rajibul Islam is a researcher at the University of Waterloo in Canada. He says that normal computers aren't going to disappear, but there is evidence that quantum computers might be able to do some things that are impossible right now - break some kinds of encryption, for example, discover new materials in medicines or figure out the best way to send out packages from a central warehouse. All these difficult problems might be solvable if scientists could just build a better quantum computer. ISLAM: We know where quantum computers will make a difference. It's a matter of high-quality engineering and then making the systems better and better so that we get there. BRUMFIEL: At the moment, nobody's quite sure which application will be the killer app. But Google, IBM and other big companies are all investing heavily to make more powerful, more reliable machines. And so is IonQ. The startup has raised about 80 million in capital, and Monroe and his team are working hard on their latest quantum machines. He takes me to see them in a large room at the back of the building. MONROE: These are a couple of the next-generation systems that are being built right now, actually. BRUMFIEL: Even though IonQ's computers haven't solved any impossible problems just yet, Monroe says he's not losing any sleep. MONROE: There's so many very hard problems out there that regular computers can't touch because they're too hard. If you're going to have any hope with those problems, it has to be quantum computing. BRUMFIEL: Monroe and others believe the future is quantum. They're just not exactly sure when that future will come. Geoff Brumfiel, NPR News.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-04-30-992383825": {"title": "'Disaster Girl' NFT Sells For Nearly $500,000 : NPR", "url": "https://www.npr.org/2021/04/30/992383825/disaster-girl-the-stuff-of-memes-sells-for-nearly-500-000-as-nft", "author": "No author found", "published_date": "2021-04-30", "content": "", "section": "Technology", "disclaimer": ""}, "2021-04-30-992148909": {"title": "Review: 'New Pok\u00e9mon Snap' For Nintendo Switch : NPR", "url": "https://www.npr.org/2021/04/30/992148909/channel-your-inner-wildlife-photographer-and-chill-out-with-new-pokemon-snap", "author": "No author found", "published_date": "2021-04-30", "content": "", "section": "Games", "disclaimer": ""}, "2021-05-01-992736637": {"title": "English Football Players And Clubs Boycott Social Media To Protest Racism : NPR", "url": "https://www.npr.org/2021/05/01/992736637/english-soccer-players-clubs-and-coaches-boycott-social-media-to-protest-racism", "author": "No author found", "published_date": "2021-05-01", "content": "", "section": "Sports", "disclaimer": ""}, "2021-05-01-992670142": {"title": "Apple Warns Of Product Shortage Due To Supply Chain Issue : NPR", "url": "https://www.npr.org/2021/05/01/992670142/apple-warns-of-product-shortage-due-to-supply-chain-issue", "author": "No author found", "published_date": "2021-05-01", "content": "SCOTT SIMON, HOST:  Apple has new iPad Pros and updated Macs. And you can order them now, but you may not receive them for a while. This week, the company, which we should say is among NPR's financial supporters, warned that it cannot keep up with demand because of a global shortage of semiconductor computer chips, the same shortage that's already brought many auto factories to a standstill. NPR tech correspondent Shannon Bond joins us. Shannon, thanks so much for being with us. SHANNON BOND, BYLINE: Hi, Scott. Happy to be here. SIMON: So customers can click and pay now, but then what? BOND: Well, they're going to need to be a bit patient. So, for example, if you go to Apple's website right now and look at one of these new iPad Pros, it says it's available starting in the second half of May. But, you know, I tried to go through and actually put one in a cart and order it. And it says it won't be delivered until late June or even early July. You know, that's quite a wait for this. And that's because Apple says it's running into this problem that is bedeviling supply chains across the world. There's a big shortage of chips right now. And chips are those little electronics inside. . . SIMON: Yeah. BOND: . . . So many products that we use every day - right? - not just our phones and our laptops, but also video game consoles, even our cars. SIMON: This is a huge problem for Apple and certainly every other person in the industry, isn't it? BOND: That's right. I mean, Apple says this issue, it's going to cause their sales in the next couple of months to be about $3-4 billion less than they would be. You know, that sounds like a lot of money. That (laughter) is a lot of money. Actually, for Apple, that's not that huge an amount of money. They're still expecting strong growth, but the point is, the growth could have been stronger because there has just been huge demand over the past year for iPads, computers. They've just been selling like crazy during the pandemic. Apple says over the last nine months, Mac sales were the highest they've ever been. And even, you know, just this week, it reported blockbuster sales and record profits in the first three months of the year. SIMON: So profits are still strong. But this is - I mean, a $4 billion bump in the road is not small change. BOND: Well, you know, it's interesting here because for Apple, it's actually largely, so far, been able to avoid this chip shortage. It's known for really managing its supply chain quite well. But this warning shows even Apple is not immune to these problems in the global supply chain. SIMON: And why is there this global chip shortage? BOND: I mean, it's really demand, right? So over the past year, people have been stuck at home. Many people bought new computers. They bought new monitors for work and school. They also bought new TVs and PlayStations and appliances. You know, companies and schools had to invest more in electronics to make remote work and classes happen. And then there's this other factor, which is cars. So these days, cars have hundreds, even thousands of chips in them. They, you know, track and control everything from tire pressure to the entertainment system to the safety features we rely on. Now, last summer, car sales, you know, went down dramatically when manufacturing shut down. But then they recovered much more quickly than anyone expected, including the chip-makers. So on the one hand, there's more demand. On the other side of the equation, there have been supply issues, including manufacturing disruptions from the winter storms in Texas and a big fire at a factory in Japan. SIMON: Anybody have any ideas on how long this shortage might last in the supply chain? BOND: Well, Apple's CEO was asked about this, Tim Cook. He said it's really hard to give an answer about that. Other CEOs we've heard from in the past couple of weeks have been pretty pessimistic. Ford warned it's going to get worse before it gets better. Nokia said this shortage could drag on for maybe another year or two. Now, chip-makers in Taiwan, where many of these chips are made, they're boosting production, but it's going to take time to rebuild inventory. These are complicated pieces of equipment to make. They're done in these specialized fabrication plants. So for all of these companies and all of those customers out there, it's going to be a waiting game. SIMON: NPR's Shannon Bond, thanks so much. BOND: Thanks for having me. (SOUNDBITE OF MUSIC) SCOTT SIMON, HOST:   Apple has new iPad Pros and updated Macs. And you can order them now, but you may not receive them for a while. This week, the company, which we should say is among NPR's financial supporters, warned that it cannot keep up with demand because of a global shortage of semiconductor computer chips, the same shortage that's already brought many auto factories to a standstill. NPR tech correspondent Shannon Bond joins us. Shannon, thanks so much for being with us. SHANNON BOND, BYLINE: Hi, Scott. Happy to be here. SIMON: So customers can click and pay now, but then what? BOND: Well, they're going to need to be a bit patient. So, for example, if you go to Apple's website right now and look at one of these new iPad Pros, it says it's available starting in the second half of May. But, you know, I tried to go through and actually put one in a cart and order it. And it says it won't be delivered until late June or even early July. You know, that's quite a wait for this. And that's because Apple says it's running into this problem that is bedeviling supply chains across the world. There's a big shortage of chips right now. And chips are those little electronics inside. . . SIMON: Yeah. BOND: . . . So many products that we use every day - right? - not just our phones and our laptops, but also video game consoles, even our cars. SIMON: This is a huge problem for Apple and certainly every other person in the industry, isn't it? BOND: That's right. I mean, Apple says this issue, it's going to cause their sales in the next couple of months to be about $3-4 billion less than they would be. You know, that sounds like a lot of money. That (laughter) is a lot of money. Actually, for Apple, that's not that huge an amount of money. They're still expecting strong growth, but the point is, the growth could have been stronger because there has just been huge demand over the past year for iPads, computers. They've just been selling like crazy during the pandemic. Apple says over the last nine months, Mac sales were the highest they've ever been. And even, you know, just this week, it reported blockbuster sales and record profits in the first three months of the year. SIMON: So profits are still strong. But this is - I mean, a $4 billion bump in the road is not small change. BOND: Well, you know, it's interesting here because for Apple, it's actually largely, so far, been able to avoid this chip shortage. It's known for really managing its supply chain quite well. But this warning shows even Apple is not immune to these problems in the global supply chain. SIMON: And why is there this global chip shortage? BOND: I mean, it's really demand, right? So over the past year, people have been stuck at home. Many people bought new computers. They bought new monitors for work and school. They also bought new TVs and PlayStations and appliances. You know, companies and schools had to invest more in electronics to make remote work and classes happen. And then there's this other factor, which is cars. So these days, cars have hundreds, even thousands of chips in them. They, you know, track and control everything from tire pressure to the entertainment system to the safety features we rely on. Now, last summer, car sales, you know, went down dramatically when manufacturing shut down. But then they recovered much more quickly than anyone expected, including the chip-makers. So on the one hand, there's more demand. On the other side of the equation, there have been supply issues, including manufacturing disruptions from the winter storms in Texas and a big fire at a factory in Japan. SIMON: Anybody have any ideas on how long this shortage might last in the supply chain? BOND: Well, Apple's CEO was asked about this, Tim Cook. He said it's really hard to give an answer about that. Other CEOs we've heard from in the past couple of weeks have been pretty pessimistic. Ford warned it's going to get worse before it gets better. Nokia said this shortage could drag on for maybe another year or two. Now, chip-makers in Taiwan, where many of these chips are made, they're boosting production, but it's going to take time to rebuild inventory. These are complicated pieces of equipment to make. They're done in these specialized fabrication plants. So for all of these companies and all of those customers out there, it's going to be a waiting game. SIMON: NPR's Shannon Bond, thanks so much. BOND: Thanks for having me. (SOUNDBITE OF MUSIC)", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-05-03-993223307": {"title": "Google Union Workers Fight for a Say in Company Culture : The Indicator from Planet Money : NPR", "url": "https://www.npr.org/2021/05/03/993223307/a-21st-century-union", "author": "No author found", "published_date": "2021-05-03", "content": "SYLVIE DOUGLIS, BYLINE: NPR. (SOUNDBITE OF DROP ELECTRIC SONG, \"WAKING UP TO THE FIRE\")STACEY VANEK SMITH, HOST:  This is THE INDICATOR FROM PLANET MONEY. I'm Stacey Vanek Smith, and I'm joined today by Preeti Varathan. Welcome, Preeti. PREETI VARATHAN, BYLINE: Hi. I'm so glad to be here. VANEK SMITH: And you have brought us a story about unions. So, of course, unions are on the decline. They have been for a while. VARATHAN: Right. But there is actually one place where union organizing is surprisingly growing, and you'd be surprised by how much those workers make. Do you mind if I ask you what you make? XAVID PRETZER: I'd rather not, like, go into the numbers here. Would it be OK if I sort of followed up with you afterwards? VARATHAN: Yeah, that's totally fine. VANEK SMITH: Oh, art of the dodge. (LAUGHTER)VARATHAN: I should tell you they did actually follow up. And let's just say they probably make more than we do - roughly 350- to $450,000 a year. VANEK SMITH: Oh, wow. They work, I am assuming, not in public radio. VARATHAN: No, just, you know, a small little shop called Google - might have heard of it. (SOUNDBITE OF MUSIC)VARATHAN: Today on the show, we're looking at a different kind of union led by white-collar workers who aren't just thinking about money and pay but about what companies do with the stuff they make and whether these workers should have a say. VANEK SMITH: Welcome to the union of the 21st century. And we should say, by the way, that Google is one of the funders of this program. (SOUNDBITE OF MUSIC)VARATHAN: If right now you're thinking, why the hell would Google workers want a union, you're probably not alone. I mean, the perks at this company are totally wild, like the cafeteria food. VANEK SMITH: Google workers have been served banana cheesecake, lobster, slow-cooked duck. And the perks extend way beyond food too. I mean, Google is a place where you can get on-site haircuts. They'll do your laundry. This is literally a place that had Lady Gaga come speak on campus. VARATHAN: And so, like, I wouldn't fault anyone for thinking, why do these workers need a union? VANEK SMITH: And basically, there seem to be two main reasons. That is according to Xavid Pretzer, a software engineer at Google and a member of the new Google union. PRETZER: I started to have a growing sense that, you know, Google as a company was making decisions more like a conventional company in search of, like, whatever would make the most profit, rather than, you know, sticking to the ideal of prioritizing making the world a better place over other concerns. VARATHAN: This leads to reason No. 1. Google workers want a say in the decisions the company makes. VANEK SMITH: Google used to have this motto, don't be evil. Xavid loved that motto, and they think that nowadays, Google sometimes can be a little bit evil. VARATHAN: What was the decision you saw that made you think, OK, hold on; sometimes, this company does sort of do things that maybe are considered evil? PRETZER: Yeah, so, I mean, I think the biggest one for me personally that changed how I see things was related to some of the activism around the Customs and Border Patrol contracts. VANEK SMITH: Here is what Xavid is talking about. Back in 2019, more than 1,000 Google workers signed a petition asking the company to stop doing any work with the U. S. Border Patrol, which included groups like ICE. The idea was that workers wanted a say in all kinds of company decisions. VARATHAN: Right. And to be honest with you, Stacey, the first question I had to ask was, should workers have a say in this kind of stuff? - because when you work for a private company, there's a bit of an assumed contract. You know, you exchange your work for pay and proper working conditions. And the company, in exchange for paying and treating you well, well, they get to do what they want with your work. Veena Dubal, though, says that thinking is wrong. She's a labor lawyer in San Francisco. VEENA DUBAL: You can imagine if you are a worker at Google that's producing something and has strongly held political beliefs and you don't want what you're working on to ultimately be used for war, then that impacts your working conditions, impacts how you feel about what you're doing at work and how you're contributing to your employer. VARATHAN: What Veena is saying is that how we think about working conditions and what can and cannot impact them has to evolve. VANEK SMITH: So reason No. 1 that Google workers wanted to form a union was that they did not want their employer to be evil, which brings us to reason No. 2. VARATHAN: Basically, union members really want all the workers at Google to be treated equally. Here's Xavid again. PRETZER: We talk about the cafeterias. But for the people who put on all the work to create that food to make the cafeterias function, they're not compensated or treated nearly as well as the people like me consuming the food. VARATHAN: Google actually employs more than 130,000 contract and temp workers who work alongside Google's full-time workforce. In fact, at Google, there are more contract and temp workers than full-time workers. VANEK SMITH: Temp workers, on average, are paid less. And when the company hits an economic downturn, those workers are often the first to go. VARATHAN: So a lot of Googlers like Xavid feel like this is deeply unfair. VANEK SMITH: But there were some obstacles to changing things. For instance, federal labor law makes it really hard for different kinds of workers, like full-time workers and temp workers, to form a union together. VARATHAN: And so Google workers chose a different path. They formed what's called a minority union. And, Stacey, I think we should probably explain that one. VANEK SMITH: Yes. OK, so here's how it works. In a standard union, workers have the right to sit down with their employer and bargain over a contract. This is a traditional way that unions exercise power through arguments over things like wages and unfair labor practices, and those are reflected in a revised contract. VARATHAN: But what Google has - a minority union - works a little differently. Minority unions don't have the support of a majority of workers. Right now Google's union only has about 800 or so workers, and that's super-small. It's just a fraction of Google's workforce. And because of this, under current labor law, Google isn't forced to recognize this union. They're not forced to sit down with them at the bargaining table. Basically, if Google wanted to, they could pretend this union didn't exist. VANEK SMITH: We did reach out to Google. It responded with a written statement saying it's worked hard to create a supportive and rewarding workplace and that it would continue to engage directly with all of its employees. The company did not clarify whether it recognizes this new group as a bona fide union or even whether it would work with them going forward, which kind of begs the question, like, what power does this union even have, if any, right? I mean, like, why are they calling this a union instead of, like, a workers advocacy club? VARATHAN: Right, and look. On its face, maybe there isn't much that differentiates this group from a club, except one important thing. And you actually kind of said it, Stacey - that they call themselves a union. Veena Dubal, our labor lawyer from earlier, says that that one word uniting underneath it, it changes things. DUBAL: Their vision is not to change things necessarily through the official channels or talking to managers but to actually use worker power to use the tools that workers have always had, direct actions in particular, to change things. VARATHAN: What this all comes down to is basically one thing - raw people power. And before those skeptics in the back smirk, let me explain. Today 800 people at a powerful company can actually make a lot of noise. They can blast the internet with stories of poor working conditions or shady things their company is doing. VANEK SMITH: Yeah, and we actually saw proof of this at Google back in 2018. This was during the height of the #MeToo movement, and thousands of Google workers across the globe dropped whatever they were doing, and they walked out to protest how the company had handled cases of sexual harassment. VARATHAN: And the photos of those workers standing, agitating, making a list of demands - that took over the internet. VANEK SMITH: Yeah, and it is safe to say that was a very, very bad day for Google. VARATHAN: This union - they're following in the steps of that kind of legacy. And it may not seem like much, you know, just a band of 800 people trying to take on a titan of industry. But perhaps when you're dealing with these kinds of laws and a company that has the power and resources of a small country, your best bet is to defer to the original source of labor power - people organizing, making some noise, showing up. (SOUNDBITE OF MUSIC)VANEK SMITH: This episode of THE INDICATOR was produced by Brittany Cronin with help from Josh Newell. It was fact-checked by Sam Cai. THE INDICATOR is edited by Kate Concannon and is a production of NPR. (SOUNDBITE OF MUSIC) SYLVIE DOUGLIS, BYLINE: NPR. (SOUNDBITE OF DROP ELECTRIC SONG, \"WAKING UP TO THE FIRE\") STACEY VANEK SMITH, HOST:   This is THE INDICATOR FROM PLANET MONEY. I'm Stacey Vanek Smith, and I'm joined today by Preeti Varathan. Welcome, Preeti. PREETI VARATHAN, BYLINE: Hi. I'm so glad to be here. VANEK SMITH: And you have brought us a story about unions. So, of course, unions are on the decline. They have been for a while. VARATHAN: Right. But there is actually one place where union organizing is surprisingly growing, and you'd be surprised by how much those workers make. Do you mind if I ask you what you make? XAVID PRETZER: I'd rather not, like, go into the numbers here. Would it be OK if I sort of followed up with you afterwards? VARATHAN: Yeah, that's totally fine. VANEK SMITH: Oh, art of the dodge. (LAUGHTER) VARATHAN: I should tell you they did actually follow up. And let's just say they probably make more than we do - roughly 350- to $450,000 a year. VANEK SMITH: Oh, wow. They work, I am assuming, not in public radio. VARATHAN: No, just, you know, a small little shop called Google - might have heard of it. (SOUNDBITE OF MUSIC) VARATHAN: Today on the show, we're looking at a different kind of union led by white-collar workers who aren't just thinking about money and pay but about what companies do with the stuff they make and whether these workers should have a say. VANEK SMITH: Welcome to the union of the 21st century. And we should say, by the way, that Google is one of the funders of this program. (SOUNDBITE OF MUSIC) VARATHAN: If right now you're thinking, why the hell would Google workers want a union, you're probably not alone. I mean, the perks at this company are totally wild, like the cafeteria food. VANEK SMITH: Google workers have been served banana cheesecake, lobster, slow-cooked duck. And the perks extend way beyond food too. I mean, Google is a place where you can get on-site haircuts. They'll do your laundry. This is literally a place that had Lady Gaga come speak on campus. VARATHAN: And so, like, I wouldn't fault anyone for thinking, why do these workers need a union? VANEK SMITH: And basically, there seem to be two main reasons. That is according to Xavid Pretzer, a software engineer at Google and a member of the new Google union. PRETZER: I started to have a growing sense that, you know, Google as a company was making decisions more like a conventional company in search of, like, whatever would make the most profit, rather than, you know, sticking to the ideal of prioritizing making the world a better place over other concerns. VARATHAN: This leads to reason No. 1. Google workers want a say in the decisions the company makes. VANEK SMITH: Google used to have this motto, don't be evil. Xavid loved that motto, and they think that nowadays, Google sometimes can be a little bit evil. VARATHAN: What was the decision you saw that made you think, OK, hold on; sometimes, this company does sort of do things that maybe are considered evil? PRETZER: Yeah, so, I mean, I think the biggest one for me personally that changed how I see things was related to some of the activism around the Customs and Border Patrol contracts. VANEK SMITH: Here is what Xavid is talking about. Back in 2019, more than 1,000 Google workers signed a petition asking the company to stop doing any work with the U. S. Border Patrol, which included groups like ICE. The idea was that workers wanted a say in all kinds of company decisions. VARATHAN: Right. And to be honest with you, Stacey, the first question I had to ask was, should workers have a say in this kind of stuff? - because when you work for a private company, there's a bit of an assumed contract. You know, you exchange your work for pay and proper working conditions. And the company, in exchange for paying and treating you well, well, they get to do what they want with your work. Veena Dubal, though, says that thinking is wrong. She's a labor lawyer in San Francisco. VEENA DUBAL: You can imagine if you are a worker at Google that's producing something and has strongly held political beliefs and you don't want what you're working on to ultimately be used for war, then that impacts your working conditions, impacts how you feel about what you're doing at work and how you're contributing to your employer. VARATHAN: What Veena is saying is that how we think about working conditions and what can and cannot impact them has to evolve. VANEK SMITH: So reason No. 1 that Google workers wanted to form a union was that they did not want their employer to be evil, which brings us to reason No. 2. VARATHAN: Basically, union members really want all the workers at Google to be treated equally. Here's Xavid again. PRETZER: We talk about the cafeterias. But for the people who put on all the work to create that food to make the cafeterias function, they're not compensated or treated nearly as well as the people like me consuming the food. VARATHAN: Google actually employs more than 130,000 contract and temp workers who work alongside Google's full-time workforce. In fact, at Google, there are more contract and temp workers than full-time workers. VANEK SMITH: Temp workers, on average, are paid less. And when the company hits an economic downturn, those workers are often the first to go. VARATHAN: So a lot of Googlers like Xavid feel like this is deeply unfair. VANEK SMITH: But there were some obstacles to changing things. For instance, federal labor law makes it really hard for different kinds of workers, like full-time workers and temp workers, to form a union together. VARATHAN: And so Google workers chose a different path. They formed what's called a minority union. And, Stacey, I think we should probably explain that one. VANEK SMITH: Yes. OK, so here's how it works. In a standard union, workers have the right to sit down with their employer and bargain over a contract. This is a traditional way that unions exercise power through arguments over things like wages and unfair labor practices, and those are reflected in a revised contract. VARATHAN: But what Google has - a minority union - works a little differently. Minority unions don't have the support of a majority of workers. Right now Google's union only has about 800 or so workers, and that's super-small. It's just a fraction of Google's workforce. And because of this, under current labor law, Google isn't forced to recognize this union. They're not forced to sit down with them at the bargaining table. Basically, if Google wanted to, they could pretend this union didn't exist. VANEK SMITH: We did reach out to Google. It responded with a written statement saying it's worked hard to create a supportive and rewarding workplace and that it would continue to engage directly with all of its employees. The company did not clarify whether it recognizes this new group as a bona fide union or even whether it would work with them going forward, which kind of begs the question, like, what power does this union even have, if any, right? I mean, like, why are they calling this a union instead of, like, a workers advocacy club? VARATHAN: Right, and look. On its face, maybe there isn't much that differentiates this group from a club, except one important thing. And you actually kind of said it, Stacey - that they call themselves a union. Veena Dubal, our labor lawyer from earlier, says that that one word uniting underneath it, it changes things. DUBAL: Their vision is not to change things necessarily through the official channels or talking to managers but to actually use worker power to use the tools that workers have always had, direct actions in particular, to change things. VARATHAN: What this all comes down to is basically one thing - raw people power. And before those skeptics in the back smirk, let me explain. Today 800 people at a powerful company can actually make a lot of noise. They can blast the internet with stories of poor working conditions or shady things their company is doing. VANEK SMITH: Yeah, and we actually saw proof of this at Google back in 2018. This was during the height of the #MeToo movement, and thousands of Google workers across the globe dropped whatever they were doing, and they walked out to protest how the company had handled cases of sexual harassment. VARATHAN: And the photos of those workers standing, agitating, making a list of demands - that took over the internet. VANEK SMITH: Yeah, and it is safe to say that was a very, very bad day for Google. VARATHAN: This union - they're following in the steps of that kind of legacy. And it may not seem like much, you know, just a band of 800 people trying to take on a titan of industry. But perhaps when you're dealing with these kinds of laws and a company that has the power and resources of a small country, your best bet is to defer to the original source of labor power - people organizing, making some noise, showing up. (SOUNDBITE OF MUSIC) VANEK SMITH: This episode of THE INDICATOR was produced by Brittany Cronin with help from Josh Newell. It was fact-checked by Sam Cai. THE INDICATOR is edited by Kate Concannon and is a production of NPR. (SOUNDBITE OF MUSIC)", "section": "A 21st Century Union", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-05-03-993047721": {"title": "Verizon Sells Off AOL And Yahoo To Private Equity Firm : NPR", "url": "https://www.npr.org/2021/05/03/993047721/internet-oldies-aol-and-yahoo-sold-again", "author": "No author found", "published_date": "2021-05-03", "content": "", "section": "Business", "disclaimer": ""}, "2021-05-04-993579600": {"title": "Snapchat Can Be Sued Over Role In Fatal Car Crash, Court Rules : NPR", "url": "https://www.npr.org/2021/05/04/993579600/snapchat-can-be-sued-for-role-in-fatal-car-crash-court-rules", "author": "No author found", "published_date": "2021-05-04", "content": "", "section": "Technology", "disclaimer": ""}, "2021-05-04-991943295": {"title": "Utah's 'Silicon Slopes' Hoping State Changes Its Reputation : NPR", "url": "https://www.npr.org/2021/05/04/991943295/tech-sees-bigger-opportunity-in-utah-if-the-state-works-on-its-image", "author": "No author found", "published_date": "2021-05-04", "content": "AILSA CHANG, HOST:  Utah has one of the fastest-growing tech sectors in the country. Companies and the state want that to continue, but industry leaders argue that in order to do that, the state's reputation needs some work. Tech lobbyists are pushing for more socially inclusive legislation at the state Capitol in the hopes that that will help attract more out-of-state talent. From member station KUER, Sonja Hutson reports. SONJA HUTSON, BYLINE: In 2018, Kimmy Paluch was 36 years old and living in Oakland, Calif. , with her husband and their two kids. They were running a consulting firm aimed at helping tech and other businesses launch new products. KIMMY PALUCH: We ourselves had gotten very disillusioned with the Silicon Valley bubble, one, for the innovations that were getting funded - that they were only serving the 1% and then, two, for the lack of capital flowing to underrepresented founders. HUTSON: She saw an opportunity to change things in Utah. Its tech market is newer and experiencing a lot of growth. And it was personal, too. Paluch is a Black woman and an immigrant. But Utah has a reputation problem, she says. PALUCH: I remember telling my Bay Area friends that we're moving to Utah, and they were like, why are you moving to Utah? HUTSON: It's no secret Utah is very white. Three-quarters of the population identifies that way. The state is also predominantly Mormon and Republican. Paluch isn't any of those things. She's Black, Catholic and politically liberal. Paluch says she was actually excited to live in a place with a different political climate, but the cultural differences did give her and her husband pause. PALUCH: We do have to think and question, like, will I feel like I'm part of this state? HUTSON: Notions about Utah's culture are something job recruiters encounter when convincing applicants to take a job here. Take this recruiting video from a Utah-based company you may have heard of - overstock. com. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED PERSON: So what's so great about Salt Lake City and Utah? It's probably cooler than you think. With fantastic local breweries, clubs and live events, Salt Lake's nightlife has something to offer for everyone. HUTSON: But it's not just concerns about being able to have a beer on a Friday night that companies have to address. It's also political differences, according to Sunny Washington. She's a lobbyist for Silicon Slopes, the industry's advocacy organization named after the popular term for the industry here. SUNNY WASHINGTON: As much as companies try and do all the active outreach, it can honestly be undone if we have some crazy law that is not very reflective of our state. HUTSON: That's why Silicon Slopes has gotten involved in several high-profile pieces of state legislation related to social issues. Washington and other lobbyists argued against an unsuccessful bill that would have banned transgender girls from competing on girls school sports teams. They supported legislation to change the name of Dixie State University. WASHINGTON: We have a lot of work to do to make people feel like, hey; you know, Utah is a great place where, you know, I can bring my family and they're going to feel included. HUTSON: Utah House Speaker Brad Wilson and other top Republicans here pride themselves on making Utah business-friendly, and Wilson says that can sometimes be in conflict with preventing businesses from changing his home state. BRAD WILSON: Utah is distinctive and very special, and we should protect distinctive Utah and not be afraid of or embarrassed by the things that make Utah different. HUTSON: But Kimmy Paluch from Oakland, who wound up making the move to Utah, says the economic opportunity that lawmakers like Wilson have worked so hard to cultivate - it only matters if it's available to everyone. It's not, she says, if people don't feel welcome coming to Utah. For NPR News, I'm Sonja Hutson in Salt Lake City. (SOUNDBITE OF CROOKED COLOURS SONG, \"NEVER DANCE ALONE\") AILSA CHANG, HOST:   Utah has one of the fastest-growing tech sectors in the country. Companies and the state want that to continue, but industry leaders argue that in order to do that, the state's reputation needs some work. Tech lobbyists are pushing for more socially inclusive legislation at the state Capitol in the hopes that that will help attract more out-of-state talent. From member station KUER, Sonja Hutson reports. SONJA HUTSON, BYLINE: In 2018, Kimmy Paluch was 36 years old and living in Oakland, Calif. , with her husband and their two kids. They were running a consulting firm aimed at helping tech and other businesses launch new products. KIMMY PALUCH: We ourselves had gotten very disillusioned with the Silicon Valley bubble, one, for the innovations that were getting funded - that they were only serving the 1% and then, two, for the lack of capital flowing to underrepresented founders. HUTSON: She saw an opportunity to change things in Utah. Its tech market is newer and experiencing a lot of growth. And it was personal, too. Paluch is a Black woman and an immigrant. But Utah has a reputation problem, she says. PALUCH: I remember telling my Bay Area friends that we're moving to Utah, and they were like, why are you moving to Utah? HUTSON: It's no secret Utah is very white. Three-quarters of the population identifies that way. The state is also predominantly Mormon and Republican. Paluch isn't any of those things. She's Black, Catholic and politically liberal. Paluch says she was actually excited to live in a place with a different political climate, but the cultural differences did give her and her husband pause. PALUCH: We do have to think and question, like, will I feel like I'm part of this state? HUTSON: Notions about Utah's culture are something job recruiters encounter when convincing applicants to take a job here. Take this recruiting video from a Utah-based company you may have heard of - overstock. com. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED PERSON: So what's so great about Salt Lake City and Utah? It's probably cooler than you think. With fantastic local breweries, clubs and live events, Salt Lake's nightlife has something to offer for everyone. HUTSON: But it's not just concerns about being able to have a beer on a Friday night that companies have to address. It's also political differences, according to Sunny Washington. She's a lobbyist for Silicon Slopes, the industry's advocacy organization named after the popular term for the industry here. SUNNY WASHINGTON: As much as companies try and do all the active outreach, it can honestly be undone if we have some crazy law that is not very reflective of our state. HUTSON: That's why Silicon Slopes has gotten involved in several high-profile pieces of state legislation related to social issues. Washington and other lobbyists argued against an unsuccessful bill that would have banned transgender girls from competing on girls school sports teams. They supported legislation to change the name of Dixie State University. WASHINGTON: We have a lot of work to do to make people feel like, hey; you know, Utah is a great place where, you know, I can bring my family and they're going to feel included. HUTSON: Utah House Speaker Brad Wilson and other top Republicans here pride themselves on making Utah business-friendly, and Wilson says that can sometimes be in conflict with preventing businesses from changing his home state. BRAD WILSON: Utah is distinctive and very special, and we should protect distinctive Utah and not be afraid of or embarrassed by the things that make Utah different. HUTSON: But Kimmy Paluch from Oakland, who wound up making the move to Utah, says the economic opportunity that lawmakers like Wilson have worked so hard to cultivate - it only matters if it's available to everyone. It's not, she says, if people don't feel welcome coming to Utah. For NPR News, I'm Sonja Hutson in Salt Lake City. (SOUNDBITE OF CROOKED COLOURS SONG, \"NEVER DANCE ALONE\")", "section": "National", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-05-04-993451278": {"title": "Reinstate Trump? Facebook Oversight Board Set To Rule On Indefinite Ban : NPR", "url": "https://www.npr.org/2021/05/04/993451278/facebook-board-readies-for-its-biggest-decision-yet-whether-to-reinstate-trump", "author": "No author found", "published_date": "2021-05-04", "content": "", "section": "Technology", "disclaimer": ""}, "2021-05-04-993273526": {"title": "Epic Games Vs. Apple: What You Need To Know About The Trial : NPR", "url": "https://www.npr.org/2021/05/04/993273526/the-epic-versus-apple-trial-has-begun-heres-what-you-need-to-know", "author": "No author found", "published_date": "2021-05-04", "content": "", "section": "Technology", "disclaimer": ""}, "2021-05-05-987679590": {"title": "Facebook Ban On Donald Trump Will Hold, Social Network's Oversight Board Rules : NPR", "url": "https://www.npr.org/2021/05/05/987679590/facebook-justified-in-banning-donald-trump-social-medias-oversight-board-rules", "author": "No author found", "published_date": "2021-05-05", "content": "AILSA CHANG, HOST:  Former President Donald Trump will remain off of the world's largest social network, at least for now. Facebook's oversight board has upheld the ban that the company put in place after the January 6 attack on the U. S. Capitol. At the time, Facebook had said that Trump was using its platform to, quote, \"incite violent insurrection. \" But even as the oversight board agreed with that, it said Facebook was wrong to impose an indefinite suspension and must either reinstate Trump or ban him permanently. All right, so joining us now is NPR tech correspondent Shannon Bond and senior political editor and correspondent Domenico Montanaro. And before we begin, we should note that Facebook is among NPR's financial supporters. Hey to both of you. SHANNON BOND, BYLINE: Hi, Ailsa. DOMENICO MONTANARO, BYLINE: Hey there. CHANG: So, Shannon, let's start with you. Before we even get into this decision, can you just talk about what is Facebook's oversight board? Like, who's on it? What are they meant to do? BOND: Right. So it's currently 20 people on this panel. This is an advisory board. It was created and funded by Facebook. And it's made up of human rights experts, lawyers, journalists. There's even an ex-prime minister. And the idea is that they give advice, and they review the toughest decisions that Facebook makes about what people can and can't post, such as this decision about banning Donald Trump. CHANG: OK. So tell us about this decision that they reached today about Trump. BOND: Right. So the board said that when Facebook made this very controversial choice to suspend Trump indefinitely from Facebook and Instagram after January 6, the suspension was justified. It said, you know, Trump indeed broke Facebook's rules. He praised the rioters at the Capitol. and that just goes against Facebook's rules about potentially inciting violence. But the board took issue with the penalty that Facebook gave Trump - this indefinite suspension, which, you know, Facebook asked the board to sort of weigh in. You know, should we keep it going or should we let him back on? And the board said, no, no, no. Facebook, that is your job. So here's what Michael McConnell, a law professor at Stanford, who is a co-chair of the board, here's what he told me today. MICHAEL MCCONNELL: You know, we are not here for Facebook just to, you know, lob, you know, politically controversial hot potatoes to us for us to decide. We are an oversight board. BOND: So the board is saying, you know, Facebook, you can't punt this decision to us. It's punted it back to Facebook. CHANG: Yeah. BOND: It's given the company six months to decide will it allow Trump back or will it ban him permanently? CHANG: OK. And how has Facebook, the company, responded to this decision? BOND: Well, just to be clear, this board doesn't have any legal or enforcement authority, but Facebook has agreed to be bound by its rulings on these decisions. So it says it's going to review what it did in this case with Trump and come back with a, quote, \"clear and proportionate\" action on his account. CHANG: OK. Well Domenico, has there been any response yet from former President Trump? MONTANARO: There has. And he hasn't responded to the specifics of what the oversight board did or said or what Facebook said in response. But, you know, Trump remains banned on Facebook, Twitter and YouTube, and he called the stances of those companies a, quote, \"total disgrace and an embarrassment to the (ph) country. \" He also promised a degree of retribution. He threatened that they must pay a political price. You know, and the fact is, you know, he said social media companies, not just Facebook, are corrupt and disgraceful. And there's certainly not an effort on his part to tone down any of the rhetoric that got him suspended from Facebook in the first place. CHANG: Yeah. Well, how big of a deal is this for Trump, politically speaking - I mean, at least for now - to be off of Facebook and to be off of Instagram? MONTANARO: It's a big deal. You know, some people look at Twitter and they think that because Trump has been off of Twitter, that that's even bigger. And that's a big piece of it because, you know, he's permanently banned from Twitter. And he - that was a key way for him to get his message out and to control the news narrative. But Facebook was much more important for campaigning, for the campaign infrastructure, for fundraising, for targeting voters. You know, one strategist I talked to this week said that he viewed this upcoming Facebook decision as make or break for Trump's political future. You know, he has the strongest fundraising list of any of the potential Republican candidates. So much of how Trump was able to raise small-dollar donations was through Facebook. His campaign was always able to use Facebook to microtarget swing voters and did it in unprecedented ways. That's why, you know, Brad Parscale, who was his former campaign manager and digital director in 2016, said Facebook was, quote, \"the highway\" that Trump drove his car on to win in 2016. And operatives say that without Facebook, it's going to be tough for his campaign to do that if he wants to run in 2024 again. CHANG: So interesting. Well Shannon, I mean, beyond this situation with the former president, what are the implications of this decision for Facebook in the larger sense? BOND: Yeah. Well, the board came down pretty hard on Facebook and particularly what CEO Mark Zuckerberg has said about, you know, taking a very hands-off approach to political speech. You know, he says it's already highly scrutinized. Facebook, you know, in some cases doesn't necessarily penalize high-profile users, politicians because if what they say is considered newsworthy. And the board said Facebook should not be treating politicians differently than other users. And here, it really has zeroed in on something that many critics say about Facebook. Too often, it feels like this company is making up the rules as it goes along. And that makes it hard for users to understand what's happening. It's also fueled accusations that the company is politically biased. That's something we've heard from Republicans, and I imagine we're going to keep hearing. CHANG: Domenico, back to you. I mean, Trump's team has said that they are aiming to create their own social media platform. What would that even be? And, like, where does that effort stand right now? MONTANARO: Well, it hasn't happened yet. You know, yesterday they launched kind of a blog-like feature on their site where you can't even comment and - you know, as a place for him to kind of get out some of his message. But that is nothing compared to what he was able to do with something like Facebook. His team is promising that they're going to, you know, still launch this social media platform. But how much of an impact that could actually have when you've got a kind of giant like Facebook, Twitter, YouTube keeping him off? We're going to have to wait and see. CHANG: That is NPR's Domenico Montanaro and Shannon Bond. Thanks to both of you. MONTANARO: You're welcome. BOND: Thank you. AILSA CHANG, HOST:   Former President Donald Trump will remain off of the world's largest social network, at least for now. Facebook's oversight board has upheld the ban that the company put in place after the January 6 attack on the U. S. Capitol. At the time, Facebook had said that Trump was using its platform to, quote, \"incite violent insurrection. \" But even as the oversight board agreed with that, it said Facebook was wrong to impose an indefinite suspension and must either reinstate Trump or ban him permanently. All right, so joining us now is NPR tech correspondent Shannon Bond and senior political editor and correspondent Domenico Montanaro. And before we begin, we should note that Facebook is among NPR's financial supporters. Hey to both of you. SHANNON BOND, BYLINE: Hi, Ailsa. DOMENICO MONTANARO, BYLINE: Hey there. CHANG: So, Shannon, let's start with you. Before we even get into this decision, can you just talk about what is Facebook's oversight board? Like, who's on it? What are they meant to do? BOND: Right. So it's currently 20 people on this panel. This is an advisory board. It was created and funded by Facebook. And it's made up of human rights experts, lawyers, journalists. There's even an ex-prime minister. And the idea is that they give advice, and they review the toughest decisions that Facebook makes about what people can and can't post, such as this decision about banning Donald Trump. CHANG: OK. So tell us about this decision that they reached today about Trump. BOND: Right. So the board said that when Facebook made this very controversial choice to suspend Trump indefinitely from Facebook and Instagram after January 6, the suspension was justified. It said, you know, Trump indeed broke Facebook's rules. He praised the rioters at the Capitol. and that just goes against Facebook's rules about potentially inciting violence. But the board took issue with the penalty that Facebook gave Trump - this indefinite suspension, which, you know, Facebook asked the board to sort of weigh in. You know, should we keep it going or should we let him back on? And the board said, no, no, no. Facebook, that is your job. So here's what Michael McConnell, a law professor at Stanford, who is a co-chair of the board, here's what he told me today. MICHAEL MCCONNELL: You know, we are not here for Facebook just to, you know, lob, you know, politically controversial hot potatoes to us for us to decide. We are an oversight board. BOND: So the board is saying, you know, Facebook, you can't punt this decision to us. It's punted it back to Facebook. CHANG: Yeah. BOND: It's given the company six months to decide will it allow Trump back or will it ban him permanently? CHANG: OK. And how has Facebook, the company, responded to this decision? BOND: Well, just to be clear, this board doesn't have any legal or enforcement authority, but Facebook has agreed to be bound by its rulings on these decisions. So it says it's going to review what it did in this case with Trump and come back with a, quote, \"clear and proportionate\" action on his account. CHANG: OK. Well Domenico, has there been any response yet from former President Trump? MONTANARO: There has. And he hasn't responded to the specifics of what the oversight board did or said or what Facebook said in response. But, you know, Trump remains banned on Facebook, Twitter and YouTube, and he called the stances of those companies a, quote, \"total disgrace and an embarrassment to the (ph) country. \" He also promised a degree of retribution. He threatened that they must pay a political price. You know, and the fact is, you know, he said social media companies, not just Facebook, are corrupt and disgraceful. And there's certainly not an effort on his part to tone down any of the rhetoric that got him suspended from Facebook in the first place. CHANG: Yeah. Well, how big of a deal is this for Trump, politically speaking - I mean, at least for now - to be off of Facebook and to be off of Instagram? MONTANARO: It's a big deal. You know, some people look at Twitter and they think that because Trump has been off of Twitter, that that's even bigger. And that's a big piece of it because, you know, he's permanently banned from Twitter. And he - that was a key way for him to get his message out and to control the news narrative. But Facebook was much more important for campaigning, for the campaign infrastructure, for fundraising, for targeting voters. You know, one strategist I talked to this week said that he viewed this upcoming Facebook decision as make or break for Trump's political future. You know, he has the strongest fundraising list of any of the potential Republican candidates. So much of how Trump was able to raise small-dollar donations was through Facebook. His campaign was always able to use Facebook to microtarget swing voters and did it in unprecedented ways. That's why, you know, Brad Parscale, who was his former campaign manager and digital director in 2016, said Facebook was, quote, \"the highway\" that Trump drove his car on to win in 2016. And operatives say that without Facebook, it's going to be tough for his campaign to do that if he wants to run in 2024 again. CHANG: So interesting. Well Shannon, I mean, beyond this situation with the former president, what are the implications of this decision for Facebook in the larger sense? BOND: Yeah. Well, the board came down pretty hard on Facebook and particularly what CEO Mark Zuckerberg has said about, you know, taking a very hands-off approach to political speech. You know, he says it's already highly scrutinized. Facebook, you know, in some cases doesn't necessarily penalize high-profile users, politicians because if what they say is considered newsworthy. And the board said Facebook should not be treating politicians differently than other users. And here, it really has zeroed in on something that many critics say about Facebook. Too often, it feels like this company is making up the rules as it goes along. And that makes it hard for users to understand what's happening. It's also fueled accusations that the company is politically biased. That's something we've heard from Republicans, and I imagine we're going to keep hearing. CHANG: Domenico, back to you. I mean, Trump's team has said that they are aiming to create their own social media platform. What would that even be? And, like, where does that effort stand right now? MONTANARO: Well, it hasn't happened yet. You know, yesterday they launched kind of a blog-like feature on their site where you can't even comment and - you know, as a place for him to kind of get out some of his message. But that is nothing compared to what he was able to do with something like Facebook. His team is promising that they're going to, you know, still launch this social media platform. But how much of an impact that could actually have when you've got a kind of giant like Facebook, Twitter, YouTube keeping him off? We're going to have to wait and see. CHANG: That is NPR's Domenico Montanaro and Shannon Bond. Thanks to both of you. MONTANARO: You're welcome. BOND: Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-05-05-993737331": {"title": "ShakeAlert Earthquake Warning System Now Includes Washington State : NPR", "url": "https://www.npr.org/2021/05/05/993737331/entire-u-s-west-coast-now-covered-by-earthquake-early-warning-system", "author": "No author found", "published_date": "2021-05-05", "content": "", "section": "National", "disclaimer": ""}, "2021-05-06-994376673": {"title": "Oversight Board Says Facebook Must Revisit 'Arbitrary' Indefinite Trump Ban : NPR", "url": "https://www.npr.org/2021/05/06/994376673/oversight-board-says-facebook-must-revisit-arbitrary-indefinite-trump-ban", "author": "No author found", "published_date": "2021-05-06", "content": "AILSA CHANG, HOST:  Facebook's Oversight Board decided yesterday that the company was justified to suspend then-President Donald Trump's Facebook account after a mob of his supporters stormed the U. S. Capitol last January. However, the board said that Facebook was trying to avoid its responsibility by suspending Trump indefinitely and then asking the board to decide if that ban should be permanent. This oversight board was created to help Facebook answer tough questions around freedom of expression online. Thomas Hughes is the director of the Oversight Board Administration. He is not a voting member of the board. And he joins us now. We should note that Facebook is a financial supporter of NPR. Thomas Hughes, welcome. THOMAS HUGHES: Thank you. CHANG: So tell us, why did the board say that Facebook needs to make its own decision about whether to ban Trump permanently? Like, why did the board feel it could not make the call ultimately on its own as the oversight board? HUGHES: Well, the decision itself has a number of facets, but one of the core criteria that the board has looked at is the protection of free speech. And underpinning those protections are the fact that Facebook must make decisions that are transparent, that they are accountable for those and that they have a clear set of rules and penalties that can be understood by all users. That's a clear criteria in international human rights standards. So the board very clearly said that the suspension of Donald Trump was necessary to keep people safe. It very clearly said President Trump's actions encouraged and legitimized violence and was a severe violation. But at the same time, it was very clear in saying that this was an arbitrary penalty and that Facebook was acting with too much discretion and that within six months, it needed to re-examine that indefinite suspension and impose a penalty that was both consistent with that severity of the act itself but also looked at the prospect of future harm. And then in addition to that, of course, they've made a number of very, very clear, I think, very precise recommendations that speak to what Facebook should do in future cases and what sort of suspensions should be applied in those cases. CHANG: Why is the board simply disseminating recommendations and not a decision telling Facebook exactly what it should do with respect to former President Trump, whether that ban should be permanent? HUGHES: Sure, so the decision has two components. It has a binding element, and it has recommendations. That's the same for all the decisions that the oversight board has taken. The binding element of the decision is that an indefinite suspension is not consistent with international human rights standards, and it must go back and apply a proper penalty that is consistent with its rules and considers the future prospect of harm. So there's both a binding component that says very clearly what Facebook must do next vis-a-vis former President Trump, but there's also a set of recommendations that say more broadly what it might do in similar cases with other individuals in other countries potentially. Now, as you've pointed out, the recommendations are not binding. But in previous decisions, you know, Facebook has responded, I would say, very well to those - to recommendations in previous decisions. CHANG: This decision by the board, it has reinforced ongoing criticism against Facebook that the platform is biased against conservatives. That's a claim many on the right have made for years without evidence. What's your reaction to that? HUGHES: I think the board's decision here actually speaks to that issue in quite a core way. I think those accusations are borne of a situation in which people don't fully have clarity or understand the internal decision-making processes that Facebook goes through. And if an arbitrary penalty is applied, one that's novel and doesn't exist in the rules, that reinforces that. So I think there needs to be consistency. There needs to be clarity, and there needs to be transparency. CHANG: I hear you try to differentiate between recommendations and binding aspects of the board's decision. But what I don't get is how binding any part of the board's decisions is because, yes, I get that Facebook agreed that decisions that are deemed to be binding will be binding on Facebook. But the board exists at the will of Facebook ultimately, so how binding is any of this on the company? HUGHES: The decisions are binding. The oversight board obviously has a legal agreement, an underpinning with Facebook, and those are consistent with the bylaws. And within those, it's very clear that the decision that the board takes is binding on Facebook. Then there's the structural issues of independence. And then beyond that, of course, there's the individual board members themselves. . . CHANG: Right. But those structural issues are everything, right? If Facebook created the board, Facebook could also dissolve the board. So how binding ultimately is anything the board decides? HUGHES: No, Facebook can't dissolve the board. So there is a trust in place, and obviously the trust holds the funds, and there are a group of trustees. And they are the guarantors in that sense of the arm's-length relationship between the board and Facebook. So Facebook cannot appoint board members. It cannot remove board members. It cannot remove the funds that have been put into the trust. It's legally obliged to implement the binding components of decisions. You know, as much as at all possible when we talk about the creation of a, you know, properly, you know, independent, self-regulatory structure, I think this structure does embody that. CHANG: But if this board abdicates final authority on cases like former President Trump, on whether a ban on former President Trump should be permanent, what does that suggest about the board's ultimate role in checking Facebook's power when it comes to influencing speech online? HUGHES: So the Facebook - sorry, the board has not abdicated any of its responsibility. It's made a very clear, I think, very strong decision. And the clear decision is that an indefinite suspension is not consistent with free expression standards and that Facebook must go back and re-examine those. And that is a decision which has incredible meaning and importance, not only specifically to this case but to how Facebook looks at every other case in the future. CHANG: Thomas Hughes is the director of Facebook's Oversight Board Administration. Thank you very much for joining us today. HUGHES: It's a pleasure. Thank you very much for having me. (SOUNDBITE OF MUSIC) AILSA CHANG, HOST:   Facebook's Oversight Board decided yesterday that the company was justified to suspend then-President Donald Trump's Facebook account after a mob of his supporters stormed the U. S. Capitol last January. However, the board said that Facebook was trying to avoid its responsibility by suspending Trump indefinitely and then asking the board to decide if that ban should be permanent. This oversight board was created to help Facebook answer tough questions around freedom of expression online. Thomas Hughes is the director of the Oversight Board Administration. He is not a voting member of the board. And he joins us now. We should note that Facebook is a financial supporter of NPR. Thomas Hughes, welcome. THOMAS HUGHES: Thank you. CHANG: So tell us, why did the board say that Facebook needs to make its own decision about whether to ban Trump permanently? Like, why did the board feel it could not make the call ultimately on its own as the oversight board? HUGHES: Well, the decision itself has a number of facets, but one of the core criteria that the board has looked at is the protection of free speech. And underpinning those protections are the fact that Facebook must make decisions that are transparent, that they are accountable for those and that they have a clear set of rules and penalties that can be understood by all users. That's a clear criteria in international human rights standards. So the board very clearly said that the suspension of Donald Trump was necessary to keep people safe. It very clearly said President Trump's actions encouraged and legitimized violence and was a severe violation. But at the same time, it was very clear in saying that this was an arbitrary penalty and that Facebook was acting with too much discretion and that within six months, it needed to re-examine that indefinite suspension and impose a penalty that was both consistent with that severity of the act itself but also looked at the prospect of future harm. And then in addition to that, of course, they've made a number of very, very clear, I think, very precise recommendations that speak to what Facebook should do in future cases and what sort of suspensions should be applied in those cases. CHANG: Why is the board simply disseminating recommendations and not a decision telling Facebook exactly what it should do with respect to former President Trump, whether that ban should be permanent? HUGHES: Sure, so the decision has two components. It has a binding element, and it has recommendations. That's the same for all the decisions that the oversight board has taken. The binding element of the decision is that an indefinite suspension is not consistent with international human rights standards, and it must go back and apply a proper penalty that is consistent with its rules and considers the future prospect of harm. So there's both a binding component that says very clearly what Facebook must do next vis-a-vis former President Trump, but there's also a set of recommendations that say more broadly what it might do in similar cases with other individuals in other countries potentially. Now, as you've pointed out, the recommendations are not binding. But in previous decisions, you know, Facebook has responded, I would say, very well to those - to recommendations in previous decisions. CHANG: This decision by the board, it has reinforced ongoing criticism against Facebook that the platform is biased against conservatives. That's a claim many on the right have made for years without evidence. What's your reaction to that? HUGHES: I think the board's decision here actually speaks to that issue in quite a core way. I think those accusations are borne of a situation in which people don't fully have clarity or understand the internal decision-making processes that Facebook goes through. And if an arbitrary penalty is applied, one that's novel and doesn't exist in the rules, that reinforces that. So I think there needs to be consistency. There needs to be clarity, and there needs to be transparency. CHANG: I hear you try to differentiate between recommendations and binding aspects of the board's decision. But what I don't get is how binding any part of the board's decisions is because, yes, I get that Facebook agreed that decisions that are deemed to be binding will be binding on Facebook. But the board exists at the will of Facebook ultimately, so how binding is any of this on the company? HUGHES: The decisions are binding. The oversight board obviously has a legal agreement, an underpinning with Facebook, and those are consistent with the bylaws. And within those, it's very clear that the decision that the board takes is binding on Facebook. Then there's the structural issues of independence. And then beyond that, of course, there's the individual board members themselves. . . CHANG: Right. But those structural issues are everything, right? If Facebook created the board, Facebook could also dissolve the board. So how binding ultimately is anything the board decides? HUGHES: No, Facebook can't dissolve the board. So there is a trust in place, and obviously the trust holds the funds, and there are a group of trustees. And they are the guarantors in that sense of the arm's-length relationship between the board and Facebook. So Facebook cannot appoint board members. It cannot remove board members. It cannot remove the funds that have been put into the trust. It's legally obliged to implement the binding components of decisions. You know, as much as at all possible when we talk about the creation of a, you know, properly, you know, independent, self-regulatory structure, I think this structure does embody that. CHANG: But if this board abdicates final authority on cases like former President Trump, on whether a ban on former President Trump should be permanent, what does that suggest about the board's ultimate role in checking Facebook's power when it comes to influencing speech online? HUGHES: So the Facebook - sorry, the board has not abdicated any of its responsibility. It's made a very clear, I think, very strong decision. And the clear decision is that an indefinite suspension is not consistent with free expression standards and that Facebook must go back and re-examine those. And that is a decision which has incredible meaning and importance, not only specifically to this case but to how Facebook looks at every other case in the future. CHANG: Thomas Hughes is the director of Facebook's Oversight Board Administration. Thank you very much for joining us today. HUGHES: It's a pleasure. Thank you very much for having me. (SOUNDBITE OF MUSIC)", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-05-06-994138707": {"title": "Twitter Releases New Feature To Prompt Users To Reconsider Mean Tweets : NPR", "url": "https://www.npr.org/2021/05/06/994138707/want-to-send-a-mean-tweet-twitters-new-feature-wants-you-to-think-again", "author": "No author found", "published_date": "2021-05-06", "content": "", "section": "Technology", "disclaimer": ""}, "2021-05-06-994063372": {"title": "Why Facebook's Decision On Trump Could Be 'Make Or Break' For His Political Future : NPR", "url": "https://www.npr.org/2021/05/06/994063372/why-facebooks-decision-on-trump-could-be-make-or-break-for-his-political-future", "author": "No author found", "published_date": "2021-05-06", "content": "", "section": "Politics", "disclaimer": ""}, "2021-05-06-994123311": {"title": "Google Adopts Pandemic Telework Changes : NPR", "url": "https://www.npr.org/2021/05/06/994123311/google-adapts-to-long-term-telework-offers-employees-hybrid-work-week", "author": "No author found", "published_date": "2021-05-06", "content": "", "section": "Business", "disclaimer": ""}, "2021-05-07-994812274": {"title": "Basecamp Blowup: Banning Politics At Work Prompts Over A Dozen Employees To Quit : NPR", "url": "https://www.npr.org/2021/05/07/994812274/basecamp-blowup-banning-politics-at-work-prompts-over-a-dozen-employees-to-quit", "author": "No author found", "published_date": "2021-05-07", "content": "AUDIE CORNISH, HOST:  It's been more than a week since Jason Fried, CEO of the web software company Basecamp, made a blog post outlining some policy changes at the company. And one of those changes - no more politics at work. When it comes to talking about politics and current events on work accounts, Fried wrote, it's become too much. It's a major distraction. It saps our energy and redirects our dialogue towards dark places. He went on, it's not healthy, and it hasn't served us well. The response? At least 20 employees have quit. Now to talk more about what's unfolding at Basecamp, we turn to tech reporter Casey Newton, who's been following this. Welcome to the program. CASEY NEWTON: Good to be here. CORNISH: So 20 out of what I understand is something like 57, 60 employees is a lot (laughter). So what prompted this new policy? NEWTON: Well, in February, the company began having discussions about a list that some workers had maintained for a while about names of customers that they found funny for some reason. Some of those were ethnic names, you know, maybe of Asian or African descent. And the company started a conversation about why they had done that, why they felt bad about it. And it kind of begun (ph) to spiral from there. A committee was formed to work on issues of diversity, equity and inclusion. And some very angry threads were posted to the internal Basecamp software that Basecamp makes. And it was out of those threads that this new policy emerged that the CEO wanted to shut those conversations down. CORNISH: So was the goal to shut down what was happening in response or to actually create an apolitical workplace, which is sort of how it's being reported? NEWTON: The public narrative was that this was about stopping employees from discussing hot-button political topics. But when I talked to employees, what they told me was all of those discussions that they'd been having internally were really about the company itself and how the company could be better and be a more just and equitable organization. So I think from the founder's perspective, though, I think they had started to feel like the company was getting away from them a little bit, like the employees were starting to have a few too many ideas about how the place should be run. And they wanted to sort of pull that back and make sure that they were in complete control. CORNISH: You've spoken to other CEOs from different companies about this issue. What are they hearing, especially after this last year where, you know, a bunch of them put out all kinds of statements regarding maybe the Black Lives Matter movement or other things kind of telling the public they were going to care about these issues more? NEWTON: That's right. Well, you know, so certainly Basecamp is not the first tech company to come down and say that they don't want political discussions in the workplace. The cryptocurrency company Coinbase had kind of been the first one. And I think there are some CEOs in that kind of conservative to libertarian realm who like the idea of a politics-free workplace, you know, whatever that means. I think on the more liberal to progressive side, though, what I'm hearing from CEOs is they think that there is no way that you can eliminate these kinds of discussions from the workplace, but what you can do is channel them. You can create dedicated spaces inside company chat for workers to kind of go at it. And you can encourage employees to essentially ask for consent before wading in political topics. You know, maybe say something like, hey, you know, I would love to talk about that congressional race. Are you OK with that? And they told me that that's been a much more successful approach than trying to ban these conversations altogether. CORNISH: Have you heard from any of the workers who have left the company or otherwise? NEWTON: I have, and, you know, it's a really heartbreaking time for them. You know, something I will just never forget about this company is that when one employee said earlier this year that they'd like to start a committee to work on diversity issues, 20 people, about a third of the company, stepped up and volunteered to do it. That really shows you how invested they were in making this place a better workplace. And now, I would say probably over half of those employees are gone, more might be leaving. So these are people who really loved Basecamp and thought it was a great place to work. And so these past few weeks have just been head-spinning for them. CORNISH: Finally, why do you think the tech industry is where we are seeing this very public discussion break out? NEWTON: The tech industry is where American workers have the most power and agency. They're well-paid. They have savings. They're highly skilled. They can go out and get good jobs in other places. So they're less afraid of speaking out than maybe a blue-collar worker might be. So it's a really interesting thing to watch because I think as the tech industry has these conversations more and more, I sort of assume that they're going to begin filtering down to other parts of the economy. CORNISH: That is Casey Newton, founder and editor of Platformer, a daily newsletter about big tech and democracy and also a contributing editor at The Verge. Thanks so much. NEWTON: Thank you, Audie. (SOUNDBITE OF MUSIC) AUDIE CORNISH, HOST:   It's been more than a week since Jason Fried, CEO of the web software company Basecamp, made a blog post outlining some policy changes at the company. And one of those changes - no more politics at work. When it comes to talking about politics and current events on work accounts, Fried wrote, it's become too much. It's a major distraction. It saps our energy and redirects our dialogue towards dark places. He went on, it's not healthy, and it hasn't served us well. The response? At least 20 employees have quit. Now to talk more about what's unfolding at Basecamp, we turn to tech reporter Casey Newton, who's been following this. Welcome to the program. CASEY NEWTON: Good to be here. CORNISH: So 20 out of what I understand is something like 57, 60 employees is a lot (laughter). So what prompted this new policy? NEWTON: Well, in February, the company began having discussions about a list that some workers had maintained for a while about names of customers that they found funny for some reason. Some of those were ethnic names, you know, maybe of Asian or African descent. And the company started a conversation about why they had done that, why they felt bad about it. And it kind of begun (ph) to spiral from there. A committee was formed to work on issues of diversity, equity and inclusion. And some very angry threads were posted to the internal Basecamp software that Basecamp makes. And it was out of those threads that this new policy emerged that the CEO wanted to shut those conversations down. CORNISH: So was the goal to shut down what was happening in response or to actually create an apolitical workplace, which is sort of how it's being reported? NEWTON: The public narrative was that this was about stopping employees from discussing hot-button political topics. But when I talked to employees, what they told me was all of those discussions that they'd been having internally were really about the company itself and how the company could be better and be a more just and equitable organization. So I think from the founder's perspective, though, I think they had started to feel like the company was getting away from them a little bit, like the employees were starting to have a few too many ideas about how the place should be run. And they wanted to sort of pull that back and make sure that they were in complete control. CORNISH: You've spoken to other CEOs from different companies about this issue. What are they hearing, especially after this last year where, you know, a bunch of them put out all kinds of statements regarding maybe the Black Lives Matter movement or other things kind of telling the public they were going to care about these issues more? NEWTON: That's right. Well, you know, so certainly Basecamp is not the first tech company to come down and say that they don't want political discussions in the workplace. The cryptocurrency company Coinbase had kind of been the first one. And I think there are some CEOs in that kind of conservative to libertarian realm who like the idea of a politics-free workplace, you know, whatever that means. I think on the more liberal to progressive side, though, what I'm hearing from CEOs is they think that there is no way that you can eliminate these kinds of discussions from the workplace, but what you can do is channel them. You can create dedicated spaces inside company chat for workers to kind of go at it. And you can encourage employees to essentially ask for consent before wading in political topics. You know, maybe say something like, hey, you know, I would love to talk about that congressional race. Are you OK with that? And they told me that that's been a much more successful approach than trying to ban these conversations altogether. CORNISH: Have you heard from any of the workers who have left the company or otherwise? NEWTON: I have, and, you know, it's a really heartbreaking time for them. You know, something I will just never forget about this company is that when one employee said earlier this year that they'd like to start a committee to work on diversity issues, 20 people, about a third of the company, stepped up and volunteered to do it. That really shows you how invested they were in making this place a better workplace. And now, I would say probably over half of those employees are gone, more might be leaving. So these are people who really loved Basecamp and thought it was a great place to work. And so these past few weeks have just been head-spinning for them. CORNISH: Finally, why do you think the tech industry is where we are seeing this very public discussion break out? NEWTON: The tech industry is where American workers have the most power and agency. They're well-paid. They have savings. They're highly skilled. They can go out and get good jobs in other places. So they're less afraid of speaking out than maybe a blue-collar worker might be. So it's a really interesting thing to watch because I think as the tech industry has these conversations more and more, I sort of assume that they're going to begin filtering down to other parts of the economy. CORNISH: That is Casey Newton, founder and editor of Platformer, a daily newsletter about big tech and democracy and also a contributing editor at The Verge. Thanks so much. NEWTON: Thank you, Audie. (SOUNDBITE OF MUSIC)", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-05-07-994436847": {"title": "Oversight Board Says Facebook, Not Trump, Is The Problem : NPR", "url": "https://www.npr.org/2021/05/07/994436847/what-we-learned-about-facebook-from-trump-decision", "author": "No author found", "published_date": "2021-05-07", "content": "SCOTT SIMON, HOST:  Facebook has almost 2 billion daily users, more spending power than many countries, and now it even has its own version of Supreme Court to pass judgment on the toughest decisions that it makes about what people can and cannot say on the platform. This week, that court ruled on the biggest question yet, whether Facebook should let former President Donald Trump back onto its platforms. NPR tech correspondent Shannon Bond has been following this story. We ought to note Facebook is among NPR's financial supporters. Shannon, thanks so much for being with us. SHANNON BOND, BYLINE: Glad to be here, Scott. SIMON: And help us understand what happened this week. BOND: Well, as you'll remember, shortly after a pro-Trump mob stormed the Capitol on January 6, Facebook had suspended Donald Trump from Facebook and Instagram. They said he was praising violence, and that broke its rules. In this penalty was an indefinite suspension. And so what it did was it asked this new Oversight Board, this advisory panel that it's created to review big decisions, to decide two things, both if it was right to kick Trump off and if he should be let back on. And so then this week, we heard from the board. SIMON: And they said? BOND: Well, the board said the suspension was justified - right? - that Trump did break Facebook's rules. But it said an indefinite suspension is not something that's in Facebook's rulebook, and it goes against human rights principles. So the board says Facebook needs to make a decision. It needs to either ban Trump permanently or put a timeframe on the suspension when he will be allowed back on. Here is board co-chair Helle Thorning-Schmidt - she's a former prime minister of Denmark - in an interview with Axios. (SOUNDBITE OF ARCHIVED RECORDING)HELLE THORNING-SCHMIDT: And what we're telling Facebook is that they can't invent penalties as they go along. They have to stick to their own rules. BOND: And what's more, the board slammed Facebook, actually, for trying to offload this decision to the board. It said that's just not its role. SIMON: Shannon, does this decision wind up saying more about Facebook than Donald Trump? BOND: Well, I think, you know, it's really interesting. Like, the board here is getting at a criticism that lots of people have about Facebook - right? - that its decisions seem arbitrary. It's not always clear what its rules are, why they're being applied, if they're being applied fairly. And the board members said, you know, in many cases it's that lack of clarity that's helped fuel these persistent claims we hear that Facebook is politically biased. So I think it is about Facebook. For its part, Facebook says it's going to review this ruling, and it's going to come back with what it calls a, quote, \"clear and proportionate action. \" So we'll sort of wait to see just what it does with what the board has told it. SIMON: Let's remind ourselves, Facebook created this board to hold itself accountable. Did the board's decision satisfy anyone? BOND: Pretty much not. For people across the political spectrum, I think this decision seemed to confirm whatever they sort of thought about Facebook and the board beforehand. We've heard from Republicans, like House Minority Leader Kevin McCarthy, who said this is just more evidence of why Big Tech has too much power. You know, Republicans continually accuse these companies of censorship. He says this is why these companies need to be reined in with new laws. And then there are other critics who say, look; just what Facebook is doing with this oversight board, it's just a way of ducking responsibility and that what's really needed is some sort of much more independent accountability. SIMON: But what would that look like? I mean, after all, it's Facebook's money. BOND: Right. Well, so for one view of that, I spoke with Rashad Robinson. He heads the civil rights group Color of Change. Here's what he told me. RASHAD ROBINSON: The question will be, will our elected officials step up and stop allowing this unaccountable single billionaire person to have this type of outsized power in our democracy, in our economy, in our media? BOND: You know, so what he's saying there is, you know, it's really Congress that needs to step in here, regulate these tech giants, regulate the power of billionaires like Facebook CEO Mark Zuckerberg. You know, and new government regulations, that's something a lot of people are talking about. But, of course, that gets into areas that raise their own thorny questions. I mean, just how much should the government be involved in deciding what people can say online? That's - you know, that is uncomfortable territory for a lot of people. Now, Helle Thorning-Schmidt of the oversight board, she said she doesn't think governments should be making these calls. She says, yes, people are also clearly unhappy about the companies making these calls. So at least from where she stands, the oversight board may just be the best option. SIMON: NPR tech correspondent Shannon Bond, thanks so much. BOND: Thanks for having me. (SOUNDBITE OF MUSIC) SCOTT SIMON, HOST:   Facebook has almost 2 billion daily users, more spending power than many countries, and now it even has its own version of Supreme Court to pass judgment on the toughest decisions that it makes about what people can and cannot say on the platform. This week, that court ruled on the biggest question yet, whether Facebook should let former President Donald Trump back onto its platforms. NPR tech correspondent Shannon Bond has been following this story. We ought to note Facebook is among NPR's financial supporters. Shannon, thanks so much for being with us. SHANNON BOND, BYLINE: Glad to be here, Scott. SIMON: And help us understand what happened this week. BOND: Well, as you'll remember, shortly after a pro-Trump mob stormed the Capitol on January 6, Facebook had suspended Donald Trump from Facebook and Instagram. They said he was praising violence, and that broke its rules. In this penalty was an indefinite suspension. And so what it did was it asked this new Oversight Board, this advisory panel that it's created to review big decisions, to decide two things, both if it was right to kick Trump off and if he should be let back on. And so then this week, we heard from the board. SIMON: And they said? BOND: Well, the board said the suspension was justified - right? - that Trump did break Facebook's rules. But it said an indefinite suspension is not something that's in Facebook's rulebook, and it goes against human rights principles. So the board says Facebook needs to make a decision. It needs to either ban Trump permanently or put a timeframe on the suspension when he will be allowed back on. Here is board co-chair Helle Thorning-Schmidt - she's a former prime minister of Denmark - in an interview with Axios. (SOUNDBITE OF ARCHIVED RECORDING) HELLE THORNING-SCHMIDT: And what we're telling Facebook is that they can't invent penalties as they go along. They have to stick to their own rules. BOND: And what's more, the board slammed Facebook, actually, for trying to offload this decision to the board. It said that's just not its role. SIMON: Shannon, does this decision wind up saying more about Facebook than Donald Trump? BOND: Well, I think, you know, it's really interesting. Like, the board here is getting at a criticism that lots of people have about Facebook - right? - that its decisions seem arbitrary. It's not always clear what its rules are, why they're being applied, if they're being applied fairly. And the board members said, you know, in many cases it's that lack of clarity that's helped fuel these persistent claims we hear that Facebook is politically biased. So I think it is about Facebook. For its part, Facebook says it's going to review this ruling, and it's going to come back with what it calls a, quote, \"clear and proportionate action. \" So we'll sort of wait to see just what it does with what the board has told it. SIMON: Let's remind ourselves, Facebook created this board to hold itself accountable. Did the board's decision satisfy anyone? BOND: Pretty much not. For people across the political spectrum, I think this decision seemed to confirm whatever they sort of thought about Facebook and the board beforehand. We've heard from Republicans, like House Minority Leader Kevin McCarthy, who said this is just more evidence of why Big Tech has too much power. You know, Republicans continually accuse these companies of censorship. He says this is why these companies need to be reined in with new laws. And then there are other critics who say, look; just what Facebook is doing with this oversight board, it's just a way of ducking responsibility and that what's really needed is some sort of much more independent accountability. SIMON: But what would that look like? I mean, after all, it's Facebook's money. BOND: Right. Well, so for one view of that, I spoke with Rashad Robinson. He heads the civil rights group Color of Change. Here's what he told me. RASHAD ROBINSON: The question will be, will our elected officials step up and stop allowing this unaccountable single billionaire person to have this type of outsized power in our democracy, in our economy, in our media? BOND: You know, so what he's saying there is, you know, it's really Congress that needs to step in here, regulate these tech giants, regulate the power of billionaires like Facebook CEO Mark Zuckerberg. You know, and new government regulations, that's something a lot of people are talking about. But, of course, that gets into areas that raise their own thorny questions. I mean, just how much should the government be involved in deciding what people can say online? That's - you know, that is uncomfortable territory for a lot of people. Now, Helle Thorning-Schmidt of the oversight board, she said she doesn't think governments should be making these calls. She says, yes, people are also clearly unhappy about the companies making these calls. So at least from where she stands, the oversight board may just be the best option. SIMON: NPR tech correspondent Shannon Bond, thanks so much. BOND: Thanks for having me. (SOUNDBITE OF MUSIC)", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-05-07-994197864": {"title": "For Mother's Day, More Brands Are Letting People Opt Out This Year : NPR", "url": "https://www.npr.org/2021/05/07/994197864/in-a-grief-filled-year-brands-from-etsy-to-pandora-let-you-skip-mothers-day-emai", "author": "No author found", "published_date": "2021-05-07", "content": "", "section": "Family", "disclaimer": ""}, "2021-05-07-982709480": {"title": "Massachusetts Passes One Of The First State-Wide Laws On Facial Recognition  : NPR", "url": "https://www.npr.org/2021/05/07/982709480/massachusetts-pioneers-rules-for-police-use-of-facial-recognition-tech", "author": "No author found", "published_date": "2021-05-07", "content": "", "section": "Technology", "disclaimer": ""}, "2021-05-07-994539614": {"title": "Environmental Concerns Arise Over Energy Needed To Mine Bitcoin : NPR", "url": "https://www.npr.org/2021/05/07/994539614/environmental-concerns-arise-over-energy-needed-to-mine-bitcoin", "author": "No author found", "published_date": "2021-05-07", "content": "NOEL KING, HOST:  Making or mining bitcoin requires a lot of energy, which can mean burning more fossil fuels. Now, at the same time, states are making a push for clean energy. So does something here have to give? Here's Vaughn Golden from member station WSKG in New York's Finger Lakes. (SOUNDBITE OF CAR HONKING)UNIDENTIFIED PERSON: I know. VAUGHN GOLDEN, BYLINE: About 100 people are walking down the shoulder of a highway overlooking Seneca Lake. They're heading down to the Greenidge Generation power plant. The natural gas-fired facility generates some electricity. But what's gotten the attention of the activists is their generation of Bitcoin. UNIDENTIFIED PROTESTERS: (Chanting) Hey hey, ho ho, Greenidge Bitcoin\u2019s got to go. GOLDEN: They're protesting today because Greenidge is looking to expand its Bitcoin mining. That would probably mean burning more natural gas and emitting more greenhouse gases. Yvonne Taylor is vice president of Seneca Lake Guardian and is leading the opposition to Greenidge. YVONNE TAYLOR: We simply cannot allow this ludicrous scheme of burning fossil fuels to make fake money in the midst of climate change. GOLDEN: Generating or mining cryptocurrency is complicated. There's no actual mining. The gist is that a whole lot of computers do a whole lot of calculations to create digital currency. That requires a ton of energy, which can mean burning more fossil fuels. And that's the case with Greenidge. The plant isn't always producing electricity for the grid. So a few years ago, they figured out they could make a profit by using excess power to mine bitcoin. Dale Irwin manages the plant. DALE IRWIN: We came up to that it was a very good business solution for us. GOLDEN: Irwin won't say exactly how much more the plant will emit with its expansion, only that it will be in compliance with its permits. IRWIN: We follow all laws and regulations the DEC apply to us. We'll review them, we'll study what they ask, and we'll do everything. GOLDEN: New York's environmental regulator says it's closely monitoring Greenidge's bitcoin expansion. Researchers at Cambridge University estimate that bitcoin mining is actively using over 120 million megawatt hours of energy every year. That's more electricity than the entire state of Virginia consumed in 2019. When Bitcoin miners are buying electricity off the grid, utilities have to be ready to meet more demand. Eilyan Bitar is a professor at Cornell University who studies power markets and electrical grids. He says electrical utilities could struggle to meet bitcoin's increasing demand for power. EILYAN BITAR: Inevitably, that would drive an increase in the supply of generation or electricity from more dispatchable generators, like natural gas, which produces greenhouse gas emissions. GOLDEN: Bitar says more bitcoin mining will likely slow down progress of states trying to lower carbon emissions. There are a few attempts to regulate bitcoin's energy consumption. Missoula, Mont. , requires all cryptocurrency mining to be offset with renewable energy. Plans to increase bitcoin production capacity at the Greenidge plant in New York were approved. But a local legislator is now pushing for a statewide moratorium on cryptocurrency mining. It is the first such measure introduced in the U. S. For NPR News, I'm Vaughn Golden in Binghamton, N. Y. (SOUNDBITE OF KLIMEKS' \"RINGS OF SATURN\") NOEL KING, HOST:   Making or mining bitcoin requires a lot of energy, which can mean burning more fossil fuels. Now, at the same time, states are making a push for clean energy. So does something here have to give? Here's Vaughn Golden from member station WSKG in New York's Finger Lakes. (SOUNDBITE OF CAR HONKING) UNIDENTIFIED PERSON: I know. VAUGHN GOLDEN, BYLINE: About 100 people are walking down the shoulder of a highway overlooking Seneca Lake. They're heading down to the Greenidge Generation power plant. The natural gas-fired facility generates some electricity. But what's gotten the attention of the activists is their generation of Bitcoin. UNIDENTIFIED PROTESTERS: (Chanting) Hey hey, ho ho, Greenidge Bitcoin\u2019s got to go. GOLDEN: They're protesting today because Greenidge is looking to expand its Bitcoin mining. That would probably mean burning more natural gas and emitting more greenhouse gases. Yvonne Taylor is vice president of Seneca Lake Guardian and is leading the opposition to Greenidge. YVONNE TAYLOR: We simply cannot allow this ludicrous scheme of burning fossil fuels to make fake money in the midst of climate change. GOLDEN: Generating or mining cryptocurrency is complicated. There's no actual mining. The gist is that a whole lot of computers do a whole lot of calculations to create digital currency. That requires a ton of energy, which can mean burning more fossil fuels. And that's the case with Greenidge. The plant isn't always producing electricity for the grid. So a few years ago, they figured out they could make a profit by using excess power to mine bitcoin. Dale Irwin manages the plant. DALE IRWIN: We came up to that it was a very good business solution for us. GOLDEN: Irwin won't say exactly how much more the plant will emit with its expansion, only that it will be in compliance with its permits. IRWIN: We follow all laws and regulations the DEC apply to us. We'll review them, we'll study what they ask, and we'll do everything. GOLDEN: New York's environmental regulator says it's closely monitoring Greenidge's bitcoin expansion. Researchers at Cambridge University estimate that bitcoin mining is actively using over 120 million megawatt hours of energy every year. That's more electricity than the entire state of Virginia consumed in 2019. When Bitcoin miners are buying electricity off the grid, utilities have to be ready to meet more demand. Eilyan Bitar is a professor at Cornell University who studies power markets and electrical grids. He says electrical utilities could struggle to meet bitcoin's increasing demand for power. EILYAN BITAR: Inevitably, that would drive an increase in the supply of generation or electricity from more dispatchable generators, like natural gas, which produces greenhouse gas emissions. GOLDEN: Bitar says more bitcoin mining will likely slow down progress of states trying to lower carbon emissions. There are a few attempts to regulate bitcoin's energy consumption. Missoula, Mont. , requires all cryptocurrency mining to be offset with renewable energy. Plans to increase bitcoin production capacity at the Greenidge plant in New York were approved. But a local legislator is now pushing for a statewide moratorium on cryptocurrency mining. It is the first such measure introduced in the U. S. For NPR News, I'm Vaughn Golden in Binghamton, N. Y. (SOUNDBITE OF KLIMEKS' \"RINGS OF SATURN\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-05-08-995040240": {"title": "Ransomware Attack Shuts Down Colonial Pipeline : NPR", "url": "https://www.npr.org/2021/05/08/995040240/cybersecurity-attack-shuts-down-a-top-u-s-gasoline-pipeline", "author": "No author found", "published_date": "2021-05-08", "content": "", "section": "National Security", "disclaimer": ""}, "2021-05-09-994850492": {"title": "How Kids Can Avoid Toxic Fandoms : NPR", "url": "https://www.npr.org/2021/05/09/994850492/fandom-can-be-a-lot-like-high-school-heres-how-to-avoid-the-bad-stuff", "author": "No author found", "published_date": "2021-05-09", "content": "", "section": "Book News & Features", "disclaimer": ""}, "2021-05-09-994620764": {"title": "Elon Musk Hosts 'Saturday Night Live' : NPR", "url": "https://www.npr.org/2021/05/09/994620764/elon-musk-hosts-snl", "author": "No author found", "published_date": "2021-05-09", "content": "SACHA PFEIFFER, HOST:  There was a lot of controversy about billionaire tech entrepreneur Elon Musk getting to host \"Saturday Night Live\" on NBC last night. And in his opening monologue, he made a surprising admission. (SOUNDBITE OF TV SHOW, \"SATURDAY NIGHT LIVE\")ELON MUSK: (As self) I'm actually making history tonight as the first person with Asperger's to host \"SNL. \"(APPLAUSE)MUSK: (As self) Or at least the first to admit it. (LAUGHTER)PFEIFFER: That statement was not entirely true, as it turns out. To help us sort through that and the rest of Musk's \"SNL\" appearance, we're joined by NPR TV critic Eric Deggans Hi, Eric. ERIC DEGGANS, BYLINE: Hi. PFEIFFER: Eric, I watched really mostly just the monologue, and I expected to dislike it because Musk can come across as such a jerk on Twitter. DEGGANS: Yeah. PFEIFFER: But, you know, maybe he didn't write it, and I know it was totally scripted, but I found it - he came across as more likable and human than I expected. What was your assessment on how he did as host? DEGGANS: Yeah. I thought overall he did OK. I mean, they gave him a monologue that was self-deprecating, and he had a lot of jokes where he poked fun at himself, like that one where he said, I've reinvented the electric car, and I'm putting people on Mars. Did you really think I'd be chill? (LAUGHTER)DEGGANS: You know? And for somebody who isn't a professional performer, you know, he kind of threw himself into the skits. But, you know, anybody who was expecting either this epically bad performance or epically significant appearance like, say, a critic like me, it was just kind of so-so enough to be - I was a little disappointed. I was expecting something more. I don't know. PFEIFFER: Truth-squad (ph) that Asperger's statement for us. Was it not totally true? DEGGANS: Well, no, it wasn't totally true because Dan Aykroyd, a member of the show's founding cast, he hosted the show in 2003, and he's openly talked about his Asperger's diagnosis for years. So Elon wasn't quite on the mark there, but, you know, seeing him talk about his own Asperger's felt like a little bit of breaking news and kind of seemed in line with the focus of the monologue, which was trying to humanize him and help him maybe smooth over that image that you talked about, that problematic image that has come from his more controversial public moments. PFEIFFER: Yeah, kind of explained him more. DEGGANS: Yeah. PFEIFFER: You know, the LA Times has said that he's the first non-athlete or performer to host since Donald Trump. So why do you think they had him do that? But let me acknowledge that certainly it was a good publicity stunt because here we are talking about it. DEGGANS: (Laughter) I know. I know. I think people underestimate \"SNL's\" executive producer Lorne Michaels, his talent for getting the show in the headlines by picking these controversial, unexpected people sometimes to host. And Musk, he's the CEO of Tesla, the founder of SpaceX. You know, he's at the forefront of a lot of controversies. I think people were kind of afraid that Musk might you use the show the way Donald Trump did - you know, a problematic person using an \"SNL\" appearance to sort of humanize himself. And it did give Musk a chance to talk about pet projects, like this cryptocurrency he supports, Dogecoin. Here's a clip from the show's \"Weekend Update\" segment where the co-anchors, they just keep asking him, what is Dogecoin? (SOUNDBITE OF TV SHOW, \"SATURDAY NIGHT LIVE\")MICHAEL CHE: (As self) What is it, man? MUSK: (As self) I keep telling you it's a cryptocurrency you can trade for conventional money. CHE: (As self) Oh, so it's a hustle. MUSK: (As self) Yeah, it's a hustle. (LAUGHTER)CHE: (As self) Why didn't you just say that, man? DEGGANS: Now, I'm not sure how much it helped that cryptocurrency to have Musk joking about it being a hustle on national TV, but it definitely helped make him look better. PFEIFFER: So remind us a little more what it is about Elon Musk that makes him so controversial in the first place? DEGGANS: Well, he's had, as I said, a lot of public controversies, including public comments where he seemed to downplay the seriousness of the coronavirus pandemic last year, criticized mask-wearing. And then back in 2018, you may remember, he tried to involve himself in attempts to rescue a group of soccer players trapped in a cave, and he was criticized for offering aid that wasn't all that helpful. And then in return, he unfairly implied that one of the people who was criticizing him was a pedophile with no evidence. And so that - that kind of stuff is very controversial. PFEIFFER: So when you factor all of that in, in some ways, does having him host damage the show long term even if there's some short-term publicity bump? DEGGANS: Ultimately, I think \"SNL\" gains more than they lose from this. They get enhanced public commentary. They're probably going to see a bump in the ratings. But for fans like me, this could feel like a - kind of like a disappointing stunt. But still, you know, one of my favorite moments - Musk wasn't really in - it was the show's cold open, which featured Miley Cyrus singing \"Light Of A Clear Blue Morning,\" which is a song by Dolly Parton, who's also her godmother. And so Miley Cyrus sang this for Mother's Day, and it led into this bit where cast members were doing comedy with their actual mothers. And let's check out a bit of the song. It's pretty nice. (SOUNDBITE OF TV SHOW, \"SATURDAY NIGHT LIVE\")MILEY CYRUS: (As self, singing) It's been a long, dark night, and I've been waiting for the morning. It's been a long, hard fight. But I see a brand-new day dawning. PFEIFFER: Oh, that is a nice touch. DEGGANS: Yeah. PFEIFFER: That's NPR TV critic Eric Deggans. Eric, thank you. DEGGANS: Thank you. SACHA PFEIFFER, HOST:   There was a lot of controversy about billionaire tech entrepreneur Elon Musk getting to host \"Saturday Night Live\" on NBC last night. And in his opening monologue, he made a surprising admission. (SOUNDBITE OF TV SHOW, \"SATURDAY NIGHT LIVE\") ELON MUSK: (As self) I'm actually making history tonight as the first person with Asperger's to host \"SNL. \" (APPLAUSE) MUSK: (As self) Or at least the first to admit it. (LAUGHTER) PFEIFFER: That statement was not entirely true, as it turns out. To help us sort through that and the rest of Musk's \"SNL\" appearance, we're joined by NPR TV critic Eric Deggans Hi, Eric. ERIC DEGGANS, BYLINE: Hi. PFEIFFER: Eric, I watched really mostly just the monologue, and I expected to dislike it because Musk can come across as such a jerk on Twitter. DEGGANS: Yeah. PFEIFFER: But, you know, maybe he didn't write it, and I know it was totally scripted, but I found it - he came across as more likable and human than I expected. What was your assessment on how he did as host? DEGGANS: Yeah. I thought overall he did OK. I mean, they gave him a monologue that was self-deprecating, and he had a lot of jokes where he poked fun at himself, like that one where he said, I've reinvented the electric car, and I'm putting people on Mars. Did you really think I'd be chill? (LAUGHTER) DEGGANS: You know? And for somebody who isn't a professional performer, you know, he kind of threw himself into the skits. But, you know, anybody who was expecting either this epically bad performance or epically significant appearance like, say, a critic like me, it was just kind of so-so enough to be - I was a little disappointed. I was expecting something more. I don't know. PFEIFFER: Truth-squad (ph) that Asperger's statement for us. Was it not totally true? DEGGANS: Well, no, it wasn't totally true because Dan Aykroyd, a member of the show's founding cast, he hosted the show in 2003, and he's openly talked about his Asperger's diagnosis for years. So Elon wasn't quite on the mark there, but, you know, seeing him talk about his own Asperger's felt like a little bit of breaking news and kind of seemed in line with the focus of the monologue, which was trying to humanize him and help him maybe smooth over that image that you talked about, that problematic image that has come from his more controversial public moments. PFEIFFER: Yeah, kind of explained him more. DEGGANS: Yeah. PFEIFFER: You know, the LA Times has said that he's the first non-athlete or performer to host since Donald Trump. So why do you think they had him do that? But let me acknowledge that certainly it was a good publicity stunt because here we are talking about it. DEGGANS: (Laughter) I know. I know. I think people underestimate \"SNL's\" executive producer Lorne Michaels, his talent for getting the show in the headlines by picking these controversial, unexpected people sometimes to host. And Musk, he's the CEO of Tesla, the founder of SpaceX. You know, he's at the forefront of a lot of controversies. I think people were kind of afraid that Musk might you use the show the way Donald Trump did - you know, a problematic person using an \"SNL\" appearance to sort of humanize himself. And it did give Musk a chance to talk about pet projects, like this cryptocurrency he supports, Dogecoin. Here's a clip from the show's \"Weekend Update\" segment where the co-anchors, they just keep asking him, what is Dogecoin? (SOUNDBITE OF TV SHOW, \"SATURDAY NIGHT LIVE\") MICHAEL CHE: (As self) What is it, man? MUSK: (As self) I keep telling you it's a cryptocurrency you can trade for conventional money. CHE: (As self) Oh, so it's a hustle. MUSK: (As self) Yeah, it's a hustle. (LAUGHTER) CHE: (As self) Why didn't you just say that, man? DEGGANS: Now, I'm not sure how much it helped that cryptocurrency to have Musk joking about it being a hustle on national TV, but it definitely helped make him look better. PFEIFFER: So remind us a little more what it is about Elon Musk that makes him so controversial in the first place? DEGGANS: Well, he's had, as I said, a lot of public controversies, including public comments where he seemed to downplay the seriousness of the coronavirus pandemic last year, criticized mask-wearing. And then back in 2018, you may remember, he tried to involve himself in attempts to rescue a group of soccer players trapped in a cave, and he was criticized for offering aid that wasn't all that helpful. And then in return, he unfairly implied that one of the people who was criticizing him was a pedophile with no evidence. And so that - that kind of stuff is very controversial. PFEIFFER: So when you factor all of that in, in some ways, does having him host damage the show long term even if there's some short-term publicity bump? DEGGANS: Ultimately, I think \"SNL\" gains more than they lose from this. They get enhanced public commentary. They're probably going to see a bump in the ratings. But for fans like me, this could feel like a - kind of like a disappointing stunt. But still, you know, one of my favorite moments - Musk wasn't really in - it was the show's cold open, which featured Miley Cyrus singing \"Light Of A Clear Blue Morning,\" which is a song by Dolly Parton, who's also her godmother. And so Miley Cyrus sang this for Mother's Day, and it led into this bit where cast members were doing comedy with their actual mothers. And let's check out a bit of the song. It's pretty nice. (SOUNDBITE OF TV SHOW, \"SATURDAY NIGHT LIVE\") MILEY CYRUS: (As self, singing) It's been a long, dark night, and I've been waiting for the morning. It's been a long, hard fight. But I see a brand-new day dawning. PFEIFFER: Oh, that is a nice touch. DEGGANS: Yeah. PFEIFFER: That's NPR TV critic Eric Deggans. Eric, thank you. DEGGANS: Thank you.", "section": "Television", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-05-10-995662926": {"title": "DarkSide Hacker Cyberattack Cause Colonial Pipeline Shutdown : The Indicator from Planet Money : NPR", "url": "https://www.npr.org/2021/05/10/995662926/the-hacking-business", "author": "No author found", "published_date": "2021-05-10", "content": "SYLVIE DOUGLIS, BYLINE: NPR. (SOUNDBITE OF DROP ELECTRIC SONG, \"WAKING UP TO THE FIRE\")STACEY VANEK SMITH, HOST:  This is THE INDICATOR FROM PLANET MONEY. I'm Stacey Vanek Smith. Over the weekend, news broke about a massive cyberattack on an oil pipeline that stretches more than 5,000 miles from the Gulf Coast all the way to the northeast of the United States. The pipeline is run by this company called Colonial, and it is responsible for delivering nearly half of the gasoline and jet fuel used on the east coast. Hacking has become a huge global business, and hacker groups are bringing in billions of dollars from desperate companies and individuals trying to get their data back or regain access to their systems. The White House has said a group of hackers known as DarkSide is responsible. They're thought to operate out of Russia. And in a very interesting twist, DarkSide released a public statement. I mean, I'm looking at a press release right now saying, like, we are apolitical. We do not participate in geopolitics. I mean, is this typical or. . . JAYA BALOO: This is not typical. VANEK SMITH: Jaya Baloo is the chief information security officer at Avast Software, an antivirus company. BALOO: There's a whole bunch of ransomware groups. Not all of them take the effort to issue these type of statements, to, you know, do press releases. The question is, why are they doing such a good communication strategy? VANEK SMITH: Today on the show, the hacking business - how big is it? Who is it targeting? And why would a group of hackers bother with a press release? (SOUNDBITE OF MUSIC)VANEK SMITH: What went through your head when you saw the news? BALOO: The first thought that went through my head is how good we are at getting attacked, actually. And this is saying something. VANEK SMITH: Like, how good the U. S. is at getting attacked by cyberattackers. BALOO: Well, it's not just the U. S. anymore, unfortunately. We saw it during the COVID pandemic. We saw ransomware also getting to hospitals. I mean, we've seen tons of critical infrastructure being held at the mercy of these attackers, who are pretty much deploying rather standard, by this point in time, methods to go and victimize really important pieces of infrastructure that we all depend on. VANEK SMITH: So if you don't mind getting very, very basic, like, what exactly happens in a ransomware attack? I mean, I know there have been some really, really high-profile ones. Like, Sony got slammed with a huge one. I also remember the infidelity dating site, Ashley Madison. I remember they had a very theatrical hack happen to them. BALOO: I love this because I think it was almost like a movie plot. The employees came to work. And when they turned on their machines, it started blasting AC/DC. VANEK SMITH: (Laughter) Which song? BALOO: It was \"Thunderstruck. \"(SOUNDBITE OF SONG, \"THUNDERSTRUCK\")AC/DC: (Singing) Thunderstruck. BALOO: (Singing) Thunderstruck. And yeah, it was awesome. I mean, it wasn't awesome. Obviously, it wasn't really awesome, but you get, like, the movie plot imagery that happens. So they come to work. AC/DC's \"Thunderstruck\" is blasting at full-pitch. (SOUNDBITE OF SONG, \"THUNDERSTRUCK\")AC/DC: (Singing) We're doin' fine. VANEK SMITH: So obviously, you know, you could be locked out of your email. That doesn't seem like that big of a deal. Maybe it is a little bit if things get leaked. But, like, what are companies getting locked out of that is so valuable? - because the ransoms are often for millions of dollars. BALOO: Well, let's be honest. It's millions of dollars because it's not just about the connectivity and the access. It's also about the data that's been encrypted in the first place. In the case of the Sony attack, it was months of embarrassing details about all these actors that were under contract to Sony and, you know, racist comments by management and terrible stuff, so nobody wants this information out there. VANEK SMITH: Is there also system stuff in addition to, like. . . BALOO: Yes, absolutely. VANEK SMITH: . . . The sort of embarrassment factor? OK. BALOO: No. And unfortunately, like, the systems that are interconnected that are not just, like, the IT of the company but also the operational tech of the company - they are still running at a, very often, base system of just regular Windows. And unfortunately, these systems can be compromised during such an attack. So it's, you know, not just like, oh, let's just shut off internet access for the company. You have no email. It could be that part of that really critical infrastructure that actually runs that pipeline or operates that technology of the pipeline also needs to be shut down because it's running on Windows. VANEK SMITH: So this organization DarkSide, I mean, is it, like - do they have offices? Is it a traditional-looking company or not? BALOO: Some of their practices are certainly traditional in the sense of their communications, their operations, their methods, the way that they have taken quite a professional stance to a lot of the communications they've had with their victims to ensure them that they will actually see their data back if they pay the ransom. VANEK SMITH: Yeah, they're organized. BALOO: They're very organized with, you know, a call center handling, like, customer questions and complaints - so really incredibly well-organized in that regard. VANEK SMITH: Like, a call center people can call in to - it's like so. . . BALOO: Yes. VANEK SMITH: If you've been hacked, press one. If your systems have been frozen, press two (laughter). BALOO: Kind of like that. VANEK SMITH: Your call is important to us. BALOO: Exactly. But it's. . . VANEK SMITH: Really? BALOO: Yes, really. And if you've taken a look at them, they say that they don't want to hack critical infrastructure. They don't want to hack for political motivations, and they're not, you know, really trying to hack hospitals, et cetera. VANEK SMITH: I mean, I'm looking at a press release right now saying, like, we are apolitical. We do not participate in geopolitics. And they apparently give money to charity. It's like there's - I have. . . BALOO: It's a little Robin Hood-y (ph). Yeah. VANEK SMITH: It's a little Robin Hood-y. There's something sort of endearing about it. I mean, is this typical, or. . . BALOO: This is not typical. There's a whole bunch of ransomware groups. Not all of them take the effort to issue these type of statements, to, you know, do press releases. I think what they've done very well from the beginning is a communications strategy. They've got that down. The question is, why are they doing such a good communication strategy? And I feel it's more to be kind of, like, professional about this and say, hey, ransomware is just a business, like everything else. And we say what we do, and we do what we say. So if you pay us, we get - give you your data back. VANEK SMITH: I mean, that is really interesting that it's almost like - it seems like reputation is important, even for a group like this, because there needs to be the trust that if you give them money, they will give you your data back. So brand reputation is important, even among ransomware. BALOO: Yeah. And I think this is, like, a gross, naive misassumption on the part of anyone who falls for this communications lure. Bottom line, they're still in the business of ransomware, and they will always harm folks that never should be harmed because they think it's a victimless crime. And we've proven with the potential impact of this attack that it's not. VANEK SMITH: As you point out, DarkSide says that they won't hack hospitals and things like that. But obviously, there have been some high-profile hospital hacks. There was one after COVID started, I think, in New Jersey, where a New Jersey hospital paid something like almost $700,000. It seems like holding people's data hostage pays a lot. Is that fair to say? BALOO: I think that's very fair to say. VANEK SMITH: Is this, like, many billions of dollars a year or millions? Or how big is this business globally? BALOO: I think it's many billions of dollars a year. If you take a look at the total cybersecurity threat that we're facing in 2021, we're looking at trillions in terms of the damage that's being caused by different types of cybersecurity threats. VANEK SMITH: What kind of a threat does this pose to, I guess, the U. S. economy and other economies around the world? BALOO: I think, honestly, this is a ticking time bomb that's only going to get worse, especially when it comes to critical infrastructure. You mentioned that hospital in New Jersey. There were hospitals all over Europe that still had this issue. There are universities that have these issues, and there are people who cannot pay that still become victims. But I think that, unfortunately, there's going to have to be an even worse one for us to kind of wake up and smell the coffee. It's not going to be enough to ask for critical infrastructure to be disconnected from the internet because pretty much everything is going to be connected to the internet, especially that operational technology. I mean, it hasn't stopped us from buying internet-connected toasters and blenders. It's not going to stop us from putting all of our network management facilities for all this critical infra (ph) online. VANEK SMITH: Jaya, thank you so much for talking with us today. BALOO: Oh, thank you so much, Stacey. (SOUNDBITE OF AC/DC SONG, \"THUNDERSTRUCK\")VANEK SMITH: President Biden is reportedly preparing an executive order strengthening cybersecurity for federal agencies. There is no word yet on whether or not Colonial has decided to pay off the DarkSide gang to get its data back or not. (SOUNDBITE OF SONG, \"THUNDERSTRUCK\")AC/DC: (Singing) Thunderstruck. VANEK SMITH: This episode of THE INDICATOR was produced by Dave Blanchard with help from Josh Newell. It was fact-checked by Sam Cai. THE INDICATOR is edited by Kate Concannon and is a production of NPR. (SOUNDBITE OF SONG, \"THUNDERSTRUCK\")AC/DC: (Singing) Yeah, yeah, yeah. Say yeah, it's all right. We're doin' fine. SYLVIE DOUGLIS, BYLINE: NPR. (SOUNDBITE OF DROP ELECTRIC SONG, \"WAKING UP TO THE FIRE\") STACEY VANEK SMITH, HOST:   This is THE INDICATOR FROM PLANET MONEY. I'm Stacey Vanek Smith. Over the weekend, news broke about a massive cyberattack on an oil pipeline that stretches more than 5,000 miles from the Gulf Coast all the way to the northeast of the United States. The pipeline is run by this company called Colonial, and it is responsible for delivering nearly half of the gasoline and jet fuel used on the east coast. Hacking has become a huge global business, and hacker groups are bringing in billions of dollars from desperate companies and individuals trying to get their data back or regain access to their systems. The White House has said a group of hackers known as DarkSide is responsible. They're thought to operate out of Russia. And in a very interesting twist, DarkSide released a public statement. I mean, I'm looking at a press release right now saying, like, we are apolitical. We do not participate in geopolitics. I mean, is this typical or. . . JAYA BALOO: This is not typical. VANEK SMITH: Jaya Baloo is the chief information security officer at Avast Software, an antivirus company. BALOO: There's a whole bunch of ransomware groups. Not all of them take the effort to issue these type of statements, to, you know, do press releases. The question is, why are they doing such a good communication strategy? VANEK SMITH: Today on the show, the hacking business - how big is it? Who is it targeting? And why would a group of hackers bother with a press release? (SOUNDBITE OF MUSIC) VANEK SMITH: What went through your head when you saw the news? BALOO: The first thought that went through my head is how good we are at getting attacked, actually. And this is saying something. VANEK SMITH: Like, how good the U. S. is at getting attacked by cyberattackers. BALOO: Well, it's not just the U. S. anymore, unfortunately. We saw it during the COVID pandemic. We saw ransomware also getting to hospitals. I mean, we've seen tons of critical infrastructure being held at the mercy of these attackers, who are pretty much deploying rather standard, by this point in time, methods to go and victimize really important pieces of infrastructure that we all depend on. VANEK SMITH: So if you don't mind getting very, very basic, like, what exactly happens in a ransomware attack? I mean, I know there have been some really, really high-profile ones. Like, Sony got slammed with a huge one. I also remember the infidelity dating site, Ashley Madison. I remember they had a very theatrical hack happen to them. BALOO: I love this because I think it was almost like a movie plot. The employees came to work. And when they turned on their machines, it started blasting AC/DC. VANEK SMITH: (Laughter) Which song? BALOO: It was \"Thunderstruck. \" (SOUNDBITE OF SONG, \"THUNDERSTRUCK\") AC/DC: (Singing) Thunderstruck. BALOO: (Singing) Thunderstruck. And yeah, it was awesome. I mean, it wasn't awesome. Obviously, it wasn't really awesome, but you get, like, the movie plot imagery that happens. So they come to work. AC/DC's \"Thunderstruck\" is blasting at full-pitch. (SOUNDBITE OF SONG, \"THUNDERSTRUCK\") AC/DC: (Singing) We're doin' fine. VANEK SMITH: So obviously, you know, you could be locked out of your email. That doesn't seem like that big of a deal. Maybe it is a little bit if things get leaked. But, like, what are companies getting locked out of that is so valuable? - because the ransoms are often for millions of dollars. BALOO: Well, let's be honest. It's millions of dollars because it's not just about the connectivity and the access. It's also about the data that's been encrypted in the first place. In the case of the Sony attack, it was months of embarrassing details about all these actors that were under contract to Sony and, you know, racist comments by management and terrible stuff, so nobody wants this information out there. VANEK SMITH: Is there also system stuff in addition to, like. . . BALOO: Yes, absolutely. VANEK SMITH: . . . The sort of embarrassment factor? OK. BALOO: No. And unfortunately, like, the systems that are interconnected that are not just, like, the IT of the company but also the operational tech of the company - they are still running at a, very often, base system of just regular Windows. And unfortunately, these systems can be compromised during such an attack. So it's, you know, not just like, oh, let's just shut off internet access for the company. You have no email. It could be that part of that really critical infrastructure that actually runs that pipeline or operates that technology of the pipeline also needs to be shut down because it's running on Windows. VANEK SMITH: So this organization DarkSide, I mean, is it, like - do they have offices? Is it a traditional-looking company or not? BALOO: Some of their practices are certainly traditional in the sense of their communications, their operations, their methods, the way that they have taken quite a professional stance to a lot of the communications they've had with their victims to ensure them that they will actually see their data back if they pay the ransom. VANEK SMITH: Yeah, they're organized. BALOO: They're very organized with, you know, a call center handling, like, customer questions and complaints - so really incredibly well-organized in that regard. VANEK SMITH: Like, a call center people can call in to - it's like so. . . BALOO: Yes. VANEK SMITH: If you've been hacked, press one. If your systems have been frozen, press two (laughter). BALOO: Kind of like that. VANEK SMITH: Your call is important to us. BALOO: Exactly. But it's. . . VANEK SMITH: Really? BALOO: Yes, really. And if you've taken a look at them, they say that they don't want to hack critical infrastructure. They don't want to hack for political motivations, and they're not, you know, really trying to hack hospitals, et cetera. VANEK SMITH: I mean, I'm looking at a press release right now saying, like, we are apolitical. We do not participate in geopolitics. And they apparently give money to charity. It's like there's - I have. . . BALOO: It's a little Robin Hood-y (ph). Yeah. VANEK SMITH: It's a little Robin Hood-y. There's something sort of endearing about it. I mean, is this typical, or. . . BALOO: This is not typical. There's a whole bunch of ransomware groups. Not all of them take the effort to issue these type of statements, to, you know, do press releases. I think what they've done very well from the beginning is a communications strategy. They've got that down. The question is, why are they doing such a good communication strategy? And I feel it's more to be kind of, like, professional about this and say, hey, ransomware is just a business, like everything else. And we say what we do, and we do what we say. So if you pay us, we get - give you your data back. VANEK SMITH: I mean, that is really interesting that it's almost like - it seems like reputation is important, even for a group like this, because there needs to be the trust that if you give them money, they will give you your data back. So brand reputation is important, even among ransomware. BALOO: Yeah. And I think this is, like, a gross, naive misassumption on the part of anyone who falls for this communications lure. Bottom line, they're still in the business of ransomware, and they will always harm folks that never should be harmed because they think it's a victimless crime. And we've proven with the potential impact of this attack that it's not. VANEK SMITH: As you point out, DarkSide says that they won't hack hospitals and things like that. But obviously, there have been some high-profile hospital hacks. There was one after COVID started, I think, in New Jersey, where a New Jersey hospital paid something like almost $700,000. It seems like holding people's data hostage pays a lot. Is that fair to say? BALOO: I think that's very fair to say. VANEK SMITH: Is this, like, many billions of dollars a year or millions? Or how big is this business globally? BALOO: I think it's many billions of dollars a year. If you take a look at the total cybersecurity threat that we're facing in 2021, we're looking at trillions in terms of the damage that's being caused by different types of cybersecurity threats. VANEK SMITH: What kind of a threat does this pose to, I guess, the U. S. economy and other economies around the world? BALOO: I think, honestly, this is a ticking time bomb that's only going to get worse, especially when it comes to critical infrastructure. You mentioned that hospital in New Jersey. There were hospitals all over Europe that still had this issue. There are universities that have these issues, and there are people who cannot pay that still become victims. But I think that, unfortunately, there's going to have to be an even worse one for us to kind of wake up and smell the coffee. It's not going to be enough to ask for critical infrastructure to be disconnected from the internet because pretty much everything is going to be connected to the internet, especially that operational technology. I mean, it hasn't stopped us from buying internet-connected toasters and blenders. It's not going to stop us from putting all of our network management facilities for all this critical infra (ph) online. VANEK SMITH: Jaya, thank you so much for talking with us today. BALOO: Oh, thank you so much, Stacey. (SOUNDBITE OF AC/DC SONG, \"THUNDERSTRUCK\") VANEK SMITH: President Biden is reportedly preparing an executive order strengthening cybersecurity for federal agencies. There is no word yet on whether or not Colonial has decided to pay off the DarkSide gang to get its data back or not. (SOUNDBITE OF SONG, \"THUNDERSTRUCK\") AC/DC: (Singing) Thunderstruck. VANEK SMITH: This episode of THE INDICATOR was produced by Dave Blanchard with help from Josh Newell. It was fact-checked by Sam Cai. THE INDICATOR is edited by Kate Concannon and is a production of NPR. (SOUNDBITE OF SONG, \"THUNDERSTRUCK\") AC/DC: (Singing) Yeah, yeah, yeah. Say yeah, it's all right. We're doin' fine.", "section": "The Hacking Business", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-05-10-995405459": {"title": "What We Know About The Ransomware Attack On A Critical U.S. Pipeline : NPR", "url": "https://www.npr.org/2021/05/10/995405459/what-we-know-about-the-ransomware-attack-on-a-critical-u-s-pipeline", "author": "No author found", "published_date": "2021-05-10", "content": "", "section": "National Security", "disclaimer": ""}, "2021-05-10-995328226": {"title": "Hate Speech, Harassment 'Significant Problem' For LGBTQ Users: Report : NPR", "url": "https://www.npr.org/2021/05/10/995328226/social-media-hate-speech-harassment-significant-problem-for-lgbtq-users-report", "author": "No author found", "published_date": "2021-05-10", "content": "", "section": "Technology", "disclaimer": ""}, "2021-05-11-995751007": {"title": "States Call On Facebook To Stop Plans For An Instagram For Kids : NPR", "url": "https://www.npr.org/2021/05/11/995751007/states-call-on-facebook-to-stop-plans-for-an-instagram-for-kids", "author": "No author found", "published_date": "2021-05-11", "content": "RACHEL MARTIN, HOST:  A bipartisan group of 44 attorneys general is telling Facebook to scrap its plans for an Instagram for kids. They're worried about children's safety, privacy, their mental health. Facebook says even though kids under the age of 13 aren't supposed to sign up for the photo sharing app now, many still do. So it wants to build a version just for them. NPR's Shannon Bond has been following this story. We should note, Facebook is among NPR's financial supporters. Shannon, explain the argument the AGs are making. SHANNON BOND, BYLINE: Well, they lay them out in - their concerns - in this letter they wrote to Facebook CEO Mark Zuckerberg. And basically they're saying children are just not equipped to navigate the challenges of social media, so things like knowing what's appropriate to share, who can see what they share. They listed fears about cyberbullying and exposure to online predators. And they pointed to research suggesting that use of social media could be connected with things like depression, lower self-esteem, body image concerns. Remember, you know, Instagram is a visual platform. It's full of selfies. And these AGs aren't the only ones concerned. Child safety groups and members of Congress have also raised alarm about this idea. MARTIN: So, I mean, why would Facebook even go down this road in the first place? BOND: I mean, bluntly, Rachel, they see demand for this product. So as you said, Facebook's rules prohibit kids under 13 from signing up. You have to put in a birth year when you sign up. The company says it kicks people off if it finds out that they misrepresented their age. But even Mark Zuckerberg acknowledged at a congressional hearing back in March, some kids do lie about their age to use these apps. (SOUNDBITE OF ARCHIVED RECORDING)MARK ZUCKERBERG: We worry that kids may find ways to try to lie and evade some of our systems. But if we create a safe system that has appropriate parent controls, then we might be able to get people into using that instead. MARTIN: So he's trying to frame this as Facebook doing the responsible thing instead of just making Facebook or making Instagram more difficult for kids to get on in the first place. BOND: Yeah. I mean, I think it is fair to sort of see Facebook's framing of this as kind of pragmatic. They're saying, you know, kids are already online. Let's give parents better ability to monitor what they're doing with this app that they're talking about as being called Instagram Youth. Now, in a statement in response to the AG's letter, specifically, Facebook says it's working with child safety and privacy experts. It's pledged not to show ads in any version of Instagram for under 13s. But look, even without ads, this is still important to Facebook's business. This is their next generation of users and building something to get them into this world of apps owned by Facebook. MARTIN: Right. So are critics of this idea, are they concerned about the kids more or are they just concerned about Facebook's overreach? BOND: I think it's both. So, you know, the AGs in their letter also says Facebook just does not have a good track record when it comes to protecting kids. The company has another app for kids. It's called Messenger Kids for messaging. And they cited, you know, these news reports recently, you know, in the past few years about a design flaw that allowed children to evade parental controls and join group chats with strangers. This question of what impact social media has on kids' health and well-being is something both Republicans and Democrats have zeroed in on when questioning Facebook executives. This really is a bipartisan issue that's seen as a real sore point for the company. And companies like Facebook or YouTube, which has a YouTube Kids app, you know, their argument is that technology is, you know, has ups and downs, but it ultimately is something that can help people connect and learn. That is not sitting easy with either Congress or state regulators, as we're seeing. MARTIN: Right. And just because kids want something doesn't mean they should get it. BOND: Wise words. MARTIN: NPR's Shannon Bond, thank you, appreciate you. BOND: Thanks, Rachel. (SOUNDBITE OF KOLOTO'S \"PRIMER\") RACHEL MARTIN, HOST:   A bipartisan group of 44 attorneys general is telling Facebook to scrap its plans for an Instagram for kids. They're worried about children's safety, privacy, their mental health. Facebook says even though kids under the age of 13 aren't supposed to sign up for the photo sharing app now, many still do. So it wants to build a version just for them. NPR's Shannon Bond has been following this story. We should note, Facebook is among NPR's financial supporters. Shannon, explain the argument the AGs are making. SHANNON BOND, BYLINE: Well, they lay them out in - their concerns - in this letter they wrote to Facebook CEO Mark Zuckerberg. And basically they're saying children are just not equipped to navigate the challenges of social media, so things like knowing what's appropriate to share, who can see what they share. They listed fears about cyberbullying and exposure to online predators. And they pointed to research suggesting that use of social media could be connected with things like depression, lower self-esteem, body image concerns. Remember, you know, Instagram is a visual platform. It's full of selfies. And these AGs aren't the only ones concerned. Child safety groups and members of Congress have also raised alarm about this idea. MARTIN: So, I mean, why would Facebook even go down this road in the first place? BOND: I mean, bluntly, Rachel, they see demand for this product. So as you said, Facebook's rules prohibit kids under 13 from signing up. You have to put in a birth year when you sign up. The company says it kicks people off if it finds out that they misrepresented their age. But even Mark Zuckerberg acknowledged at a congressional hearing back in March, some kids do lie about their age to use these apps. (SOUNDBITE OF ARCHIVED RECORDING) MARK ZUCKERBERG: We worry that kids may find ways to try to lie and evade some of our systems. But if we create a safe system that has appropriate parent controls, then we might be able to get people into using that instead. MARTIN: So he's trying to frame this as Facebook doing the responsible thing instead of just making Facebook or making Instagram more difficult for kids to get on in the first place. BOND: Yeah. I mean, I think it is fair to sort of see Facebook's framing of this as kind of pragmatic. They're saying, you know, kids are already online. Let's give parents better ability to monitor what they're doing with this app that they're talking about as being called Instagram Youth. Now, in a statement in response to the AG's letter, specifically, Facebook says it's working with child safety and privacy experts. It's pledged not to show ads in any version of Instagram for under 13s. But look, even without ads, this is still important to Facebook's business. This is their next generation of users and building something to get them into this world of apps owned by Facebook. MARTIN: Right. So are critics of this idea, are they concerned about the kids more or are they just concerned about Facebook's overreach? BOND: I think it's both. So, you know, the AGs in their letter also says Facebook just does not have a good track record when it comes to protecting kids. The company has another app for kids. It's called Messenger Kids for messaging. And they cited, you know, these news reports recently, you know, in the past few years about a design flaw that allowed children to evade parental controls and join group chats with strangers. This question of what impact social media has on kids' health and well-being is something both Republicans and Democrats have zeroed in on when questioning Facebook executives. This really is a bipartisan issue that's seen as a real sore point for the company. And companies like Facebook or YouTube, which has a YouTube Kids app, you know, their argument is that technology is, you know, has ups and downs, but it ultimately is something that can help people connect and learn. That is not sitting easy with either Congress or state regulators, as we're seeing. MARTIN: Right. And just because kids want something doesn't mean they should get it. BOND: Wise words. MARTIN: NPR's Shannon Bond, thank you, appreciate you. BOND: Thanks, Rachel. (SOUNDBITE OF KOLOTO'S \"PRIMER\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-05-11-994395889": {"title": "The story of Section 230 goes back to an AOL troll. Now the law may be undone : NPR", "url": "https://www.npr.org/2021/05/11/994395889/how-one-mans-fight-against-an-aol-troll-sealed-the-tech-industrys-power", "author": "No author found", "published_date": "2021-05-11", "content": "RACHEL MARTIN, HOST:  The tech industry's enormous power can be traced to the 1990s and a troll on AOL. The lawsuit that resulted determined how the internet works today. NPR's Bobby Allyn has more. BOBBY ALLYN, BYLINE: In April 1995, Ken Zeran's phone started ringing and ringing some more. It just wouldn't stop. KEN ZERAN: It wasn't like every second, but it was just lots of calls. ALLYN: He ran a real estate magazine in Seattle, but these calls had nothing to do with that. These callers were angry, often screaming,ZERAN: How could you do this? What a loser you are. I mean, I'm just paraphrasing all of it now. You could use your own sense and think of what they might be saying, given what had just happened in Oklahoma City. ALLYN: This was just days after the Oklahoma City bombing, the domestic terrorist attack that killed more than 160 people. On AOL, someone had impersonated Zeran with his real phone number and advertised, quote, \"great Oklahoma T-shirts\" that were anything but great. They made light of the bombing and said tasteless things about the victims. Zeran wanted these ads taken down so his phone would stop ringing. He called AOL. ZERAN: And basically I told them, you know, my phone's ringing off the hook, and I can't get anything done. And it's all these people upset about something that they saw on AOL. ALLYN: AOL removed the ad, but more popped up. He tried AOL's legal department, the FBI, the Secret Service. He called everyone he could to get these ads taken down, but his phone kept ringing. ZERAN: I didn't want the thing to go any further and have some, you know, nitwit show up with a shotgun on my property. The problem was AOL would not post something on their server telling their audience that this is a bunch of baloney, a hoax or whatever. ALLYN: Zeran has never been able to find his troll. AOL was easier to find, and he thought they contributed to his pain by not doing enough to take down the ads. So he sued AOL. He didn't know it at the time, but this was about to make history. The court had a tough decision to make. Does it protect Zeran or does the court preserve the free and open internet as an idea? Well, Zeran lost. ZERAN: The judge made a huge mistake because by removing responsibility, they created chaos. ALLYN: Experts agree this court decision has added to online chaos and arguably made confronting harassment, disinformation and other abuse less urgent for Silicon Valley. To this day, if you try to sue a website for something someone posted, judges will say, no, you can't do that and point to the Zeran precedent. It's happened hundreds and hundreds of times. But legal scholar Jeff Kosseff says back then, the court handed down this ruling to strengthen a brand-new law written for an industry in its infancy. JEFF KOSSEFF: They took this really exceptionalist view by saying, you know, Congress wanted to treat the internet differently than other media and provide this strong protection in an effort to encourage innovation and speech on the internet. ALLYN: With internet companies now transformed into global titans, thanks in part to this legal protection, there's a movement afoot to weaken the law. It's even playing out in the courts. A panel of federal appeals judges this month ruled that the messaging app Snapchat actually could be sued after the app was used in a fatal car crash. The decision made one lawyer tweet, the reign of Zeran is over. Maybe not, but for those hoping to sue social media companies, it provided some hope. Bobby Allyn, NPR News, San Francisco. (SOUNDBITE OF KETTEL'S \"RIBCAGE\") RACHEL MARTIN, HOST:   The tech industry's enormous power can be traced to the 1990s and a troll on AOL. The lawsuit that resulted determined how the internet works today. NPR's Bobby Allyn has more. BOBBY ALLYN, BYLINE: In April 1995, Ken Zeran's phone started ringing and ringing some more. It just wouldn't stop. KEN ZERAN: It wasn't like every second, but it was just lots of calls. ALLYN: He ran a real estate magazine in Seattle, but these calls had nothing to do with that. These callers were angry, often screaming, ZERAN: How could you do this? What a loser you are. I mean, I'm just paraphrasing all of it now. You could use your own sense and think of what they might be saying, given what had just happened in Oklahoma City. ALLYN: This was just days after the Oklahoma City bombing, the domestic terrorist attack that killed more than 160 people. On AOL, someone had impersonated Zeran with his real phone number and advertised, quote, \"great Oklahoma T-shirts\" that were anything but great. They made light of the bombing and said tasteless things about the victims. Zeran wanted these ads taken down so his phone would stop ringing. He called AOL. ZERAN: And basically I told them, you know, my phone's ringing off the hook, and I can't get anything done. And it's all these people upset about something that they saw on AOL. ALLYN: AOL removed the ad, but more popped up. He tried AOL's legal department, the FBI, the Secret Service. He called everyone he could to get these ads taken down, but his phone kept ringing. ZERAN: I didn't want the thing to go any further and have some, you know, nitwit show up with a shotgun on my property. The problem was AOL would not post something on their server telling their audience that this is a bunch of baloney, a hoax or whatever. ALLYN: Zeran has never been able to find his troll. AOL was easier to find, and he thought they contributed to his pain by not doing enough to take down the ads. So he sued AOL. He didn't know it at the time, but this was about to make history. The court had a tough decision to make. Does it protect Zeran or does the court preserve the free and open internet as an idea? Well, Zeran lost. ZERAN: The judge made a huge mistake because by removing responsibility, they created chaos. ALLYN: Experts agree this court decision has added to online chaos and arguably made confronting harassment, disinformation and other abuse less urgent for Silicon Valley. To this day, if you try to sue a website for something someone posted, judges will say, no, you can't do that and point to the Zeran precedent. It's happened hundreds and hundreds of times. But legal scholar Jeff Kosseff says back then, the court handed down this ruling to strengthen a brand-new law written for an industry in its infancy. JEFF KOSSEFF: They took this really exceptionalist view by saying, you know, Congress wanted to treat the internet differently than other media and provide this strong protection in an effort to encourage innovation and speech on the internet. ALLYN: With internet companies now transformed into global titans, thanks in part to this legal protection, there's a movement afoot to weaken the law. It's even playing out in the courts. A panel of federal appeals judges this month ruled that the messaging app Snapchat actually could be sued after the app was used in a fatal car crash. The decision made one lawyer tweet, the reign of Zeran is over. Maybe not, but for those hoping to sue social media companies, it provided some hope. Bobby Allyn, NPR News, San Francisco. (SOUNDBITE OF KETTEL'S \"RIBCAGE\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-05-12-996360738": {"title": "Elon Musk Says Tesla Won't Accept Bitcoin For Car Purchases Any More : NPR", "url": "https://www.npr.org/2021/05/12/996360738/never-mind-elon-musk-says-tesla-wont-accept-bitcoin-for-car-purchases-any-more", "author": "No author found", "published_date": "2021-05-12", "content": "", "section": "Business", "disclaimer": ""}, "2021-05-12-996348384": {"title": "Internet Subsidy Gives $50 A Month Discounts For Low-Income Americans : NPR", "url": "https://www.npr.org/2021/05/12/996348384/internet-subsidy-gives-50-a-month-discounts-for-low-income-americans", "author": "No author found", "published_date": "2021-05-12", "content": "", "section": "Technology", "disclaimer": ""}, "2021-05-12-996355601": {"title": "Biden Executive Order Follows Recent Cyberattacks : NPR", "url": "https://www.npr.org/2021/05/12/996355601/in-wake-of-pipeline-hack-biden-signs-executive-order-on-cybersecurity", "author": "No author found", "published_date": "2021-05-12", "content": "", "section": "Politics", "disclaimer": ""}, "2021-05-12-996118335": {"title": "Amazon Wins Case Against EU Regulators Over Luxembourg Taxes : NPR", "url": "https://www.npr.org/2021/05/12/996118335/amazon-wins-case-against-eu-regulators-over-luxembourg-taxes", "author": "No author found", "published_date": "2021-05-12", "content": "", "section": "Europe", "disclaimer": ""}, "2021-05-12-996007048": {"title": "Oregon Trail Gets A Makeover With More Accurate Native American Representation : NPR", "url": "https://www.npr.org/2021/05/12/996007048/no-bows-and-arrows-and-no-broken-english-on-the-updated-oregon-trail", "author": "No author found", "published_date": "2021-05-12", "content": "MARY LOUISE KELLY, HOST:  A generation of kids grew up playing an early educational video game called The Oregon Trail. It's about pioneers on the trail west, and they remember it mostly for the moment their party died of dysentery. Well, now a new spin on the wagon train game focuses on more accurately representing Native Americans they meet along the way. And it includes playable Native characters. The Northwest News Network's Anna King has more. ANNA KING, BYLINE: Jazz Halfmoon, now 38, remembers playing Oregon Trail as a reward for doing well in class. JAZZ HALFMOON: And that was on the old, super old computer. The green screen was, like, the only color. KING: Halfmoon grew up on the Confederated Tribes of the Umatilla Reservation in northeast Oregon. HALFMOON: I remember being like, oh, like the Indians killed off, you know, somebody in your wagon train, you know? And it's like, well, we're Indians, you know, like. . . KING: The company, Gameloft tackled the redesign of Oregon Trail. Its target audience - the now-40-year-olds and their kids and more Native American players. Lead designer Jarrad Trudgen had to root out historical inaccuracies and cliches about Native American culture. JARRAD TRUDGEN: Well, as a white, middle-class Australian, I don't think I can really speak to that. KING: So he brought in some Indigenous historians. They listened to early test music for the game and said back off the drums and flutes and don't use broken, stilted English. Trudgen got it. TRUDGEN: It's like a trope to try and make Native American people seem primitive when actually there's a lot of bilingual or polylingual Native Americans at that time. KING: The team of historians came up with more appropriate character names and advocated for new roles for Native Americans, not just guides or trappers. University of Nebraska historian Margaret Huettl has Lac Courte Oreilles tribal ancestors. She researched old photos and drawings for accurate depictions of different tribes' clothing and style. MARGARET HUETTL: Initially, all of the Native people had braids, and I think we suggested maybe they don't all have to have braids. KING: One major teaching moment for Trudgen - bows and arrows. He definitely wanted them. Huettl explained that if you were a Native American trapper at the time, you were more likely to have a rifle. So bows and arrows are an outdated stereotype. David Lewis teaches anthropology and ethnic studies at Oregon State University, and he's a member of the Confederated Tribes of Grand Ronde Territories, where many settlers ended up. DAVID LEWIS: They were excited initially for all the new products, the guns and the metals and the fabrics and things like that. KING: But the real Oregon Trail wasn't a positive story for Native Americans. The settlers kept coming. LEWIS: By and large, the experience of Native people was one of continual loss for really the first 70 or 80 years. KING: It's hard to put all that into a video game, but historian Margaret Huettl says the designers were serious about getting it right. HUETTL: It was clear that they were listening to us and taking what we had to say seriously. KING: Yes, the flutes are mostly gone, too, but they did leave one old moment in the new version. You can still die of dysentery. For NPR News, I'm Anna King. MARY LOUISE KELLY, HOST:   A generation of kids grew up playing an early educational video game called The Oregon Trail. It's about pioneers on the trail west, and they remember it mostly for the moment their party died of dysentery. Well, now a new spin on the wagon train game focuses on more accurately representing Native Americans they meet along the way. And it includes playable Native characters. The Northwest News Network's Anna King has more. ANNA KING, BYLINE: Jazz Halfmoon, now 38, remembers playing Oregon Trail as a reward for doing well in class. JAZZ HALFMOON: And that was on the old, super old computer. The green screen was, like, the only color. KING: Halfmoon grew up on the Confederated Tribes of the Umatilla Reservation in northeast Oregon. HALFMOON: I remember being like, oh, like the Indians killed off, you know, somebody in your wagon train, you know? And it's like, well, we're Indians, you know, like. . . KING: The company, Gameloft tackled the redesign of Oregon Trail. Its target audience - the now-40-year-olds and their kids and more Native American players. Lead designer Jarrad Trudgen had to root out historical inaccuracies and cliches about Native American culture. JARRAD TRUDGEN: Well, as a white, middle-class Australian, I don't think I can really speak to that. KING: So he brought in some Indigenous historians. They listened to early test music for the game and said back off the drums and flutes and don't use broken, stilted English. Trudgen got it. TRUDGEN: It's like a trope to try and make Native American people seem primitive when actually there's a lot of bilingual or polylingual Native Americans at that time. KING: The team of historians came up with more appropriate character names and advocated for new roles for Native Americans, not just guides or trappers. University of Nebraska historian Margaret Huettl has Lac Courte Oreilles tribal ancestors. She researched old photos and drawings for accurate depictions of different tribes' clothing and style. MARGARET HUETTL: Initially, all of the Native people had braids, and I think we suggested maybe they don't all have to have braids. KING: One major teaching moment for Trudgen - bows and arrows. He definitely wanted them. Huettl explained that if you were a Native American trapper at the time, you were more likely to have a rifle. So bows and arrows are an outdated stereotype. David Lewis teaches anthropology and ethnic studies at Oregon State University, and he's a member of the Confederated Tribes of Grand Ronde Territories, where many settlers ended up. DAVID LEWIS: They were excited initially for all the new products, the guns and the metals and the fabrics and things like that. KING: But the real Oregon Trail wasn't a positive story for Native Americans. The settlers kept coming. LEWIS: By and large, the experience of Native people was one of continual loss for really the first 70 or 80 years. KING: It's hard to put all that into a video game, but historian Margaret Huettl says the designers were serious about getting it right. HUETTL: It was clear that they were listening to us and taking what we had to say seriously. KING: Yes, the flutes are mostly gone, too, but they did leave one old moment in the new version. You can still die of dysentery. For NPR News, I'm Anna King.", "section": "Games", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-05-13-996570855": {"title": "Just 12 People Are Behind Most Vaccine Hoaxes On Social Media, Research Shows : NPR", "url": "https://www.npr.org/2021/05/13/996570855/disinformation-dozen-test-facebooks-twitters-ability-to-curb-vaccine-hoaxes", "author": "No author found", "published_date": "2021-05-13", "content": "AILSA CHANG, HOST:  In the fight to persuade skeptics to get COVID-19 vaccine shots, public health officials face a big hurdle - anti-vaccine claims, many of which come from a handful of influential social media figures. NPR's Shannon Bond reportsSHANNON BOND, BYLINE: This problem is nothing new to people who track misinformation. Many misleading claims and outright lies about COVID vaccines mirror what's been said about other vaccines. John Gregory is deputy health editor at NewsGuard. JOHN GREGORY: You know, it's almost like a conspiracy theory Mad Libs. They just inserted the new claims. BOND: And it's not just the claims that are familiar, it's who is making them. Just 12 people dubbed the disinformation dozen are responsible for the bulk of anti-vaccine content on Facebook, Instagram and Twitter, researchers found. Imran Ahmed is CEO of the Center for Countering Digital Hate, which identified these figures. IMRAN AHMED: The disinformation dozen produce 65% of the shares of anti-vaccine misinformation on social media platforms. They're producing the most shared content. BOND: Some focus on natural health. Some sell supplements and books. And many have long spread scientifically disproven medical claims and conspiracies. And they're still doing it now, proving how hard it is to stop hoaxes on social media. Ahmed says the claims they make about COVID come straight from the anti-vaccination playbook,AHMED: Denying that COVID exists, claiming that false cures are in fact the way to solve COVID and not vaccination, decrying vaccines and decrying doctors as being in some way venal or motivated by other factors when they recommend vaccines. BOND: Lawmakers and state regulators have urged Facebook and Twitter to ban all 12 accounts. A note - Facebook is among NPR's financial supporters. The companies have stepped up the fight. They've labeled posts, even removed falsehoods and banned people who repeatedly share debunked claims. Still, the disinformation dozen are easy to find on social media. Ahmed says sometimes they skirt the platform's rules by using codes. AHMED: So, for example, instead of saying vaccine, they may in a video hold up the V sign with their fingers and say, if you're around someone who has been - hold up V sign - you know, X might happen to youBOND: Or they take something true and distort it, like falsely linking a famous person's death to the fact they got a vaccine days or weeks earlier. Facebook says it now limits the reach of posts that could discourage people from getting vaccinated, even if they don't explicitly break its rules. Some of the disinformation dozen have toned down their posts, but the cat-and-mouse game continues. Take anti-vaccine activist Robert F. Kennedy Jr. ROBERT F KENNEDY JR: I have to post like unicorns and kitty cat pictures on there. I can't post anything. It doesn't matter how true it is. BOND: Facebook, which owns Instagram, kicked Kennedy off the photo-sharing app in February, but he's still on Facebook. There, he advertises his website, a newsletter where he makes claims that would break Facebook's rules if posted there. Kennedy told NPR he's never posted misinformation and accused Facebook of censorship. He says the crackdown has sapped his ability to raise donations. KENNEDY: It's cost us hundreds of thousands of dollars. BOND: Even as the social media companies have gotten tougher recently, researchers worry the persistence of these hoaxes will further erode confidence among people who are already hesitant about the COVID vaccines. That's especially concerning as shots roll out for kids 12 and up. Jessica Calarco is a sociologist at Indiana University. She's found more than a quarter of parents don't plan to vaccinate their kids. JESSICA CALARCO: So many of these moms are turning to Facebook, are turning to Twitter, turning to other social media platforms. And they're saying, every time I open my phone, I see something different. BOND: Like stories about bad side effects. Even some parents who have been giving their kids routine childhood vaccines said they're unsure about COVID jabs. CALARCO: And those kinds of social media-based reports are, in many mothers' minds, kind of weighed equally against the kinds of expert medical recommendations coming out of things like the CDC. BOND: And that could make it hard to push down infection rates. Shannon Bond, NPR News. AILSA CHANG, HOST:   In the fight to persuade skeptics to get COVID-19 vaccine shots, public health officials face a big hurdle - anti-vaccine claims, many of which come from a handful of influential social media figures. NPR's Shannon Bond reports SHANNON BOND, BYLINE: This problem is nothing new to people who track misinformation. Many misleading claims and outright lies about COVID vaccines mirror what's been said about other vaccines. John Gregory is deputy health editor at NewsGuard. JOHN GREGORY: You know, it's almost like a conspiracy theory Mad Libs. They just inserted the new claims. BOND: And it's not just the claims that are familiar, it's who is making them. Just 12 people dubbed the disinformation dozen are responsible for the bulk of anti-vaccine content on Facebook, Instagram and Twitter, researchers found. Imran Ahmed is CEO of the Center for Countering Digital Hate, which identified these figures. IMRAN AHMED: The disinformation dozen produce 65% of the shares of anti-vaccine misinformation on social media platforms. They're producing the most shared content. BOND: Some focus on natural health. Some sell supplements and books. And many have long spread scientifically disproven medical claims and conspiracies. And they're still doing it now, proving how hard it is to stop hoaxes on social media. Ahmed says the claims they make about COVID come straight from the anti-vaccination playbook, AHMED: Denying that COVID exists, claiming that false cures are in fact the way to solve COVID and not vaccination, decrying vaccines and decrying doctors as being in some way venal or motivated by other factors when they recommend vaccines. BOND: Lawmakers and state regulators have urged Facebook and Twitter to ban all 12 accounts. A note - Facebook is among NPR's financial supporters. The companies have stepped up the fight. They've labeled posts, even removed falsehoods and banned people who repeatedly share debunked claims. Still, the disinformation dozen are easy to find on social media. Ahmed says sometimes they skirt the platform's rules by using codes. AHMED: So, for example, instead of saying vaccine, they may in a video hold up the V sign with their fingers and say, if you're around someone who has been - hold up V sign - you know, X might happen to you BOND: Or they take something true and distort it, like falsely linking a famous person's death to the fact they got a vaccine days or weeks earlier. Facebook says it now limits the reach of posts that could discourage people from getting vaccinated, even if they don't explicitly break its rules. Some of the disinformation dozen have toned down their posts, but the cat-and-mouse game continues. Take anti-vaccine activist Robert F. Kennedy Jr. ROBERT F KENNEDY JR: I have to post like unicorns and kitty cat pictures on there. I can't post anything. It doesn't matter how true it is. BOND: Facebook, which owns Instagram, kicked Kennedy off the photo-sharing app in February, but he's still on Facebook. There, he advertises his website, a newsletter where he makes claims that would break Facebook's rules if posted there. Kennedy told NPR he's never posted misinformation and accused Facebook of censorship. He says the crackdown has sapped his ability to raise donations. KENNEDY: It's cost us hundreds of thousands of dollars. BOND: Even as the social media companies have gotten tougher recently, researchers worry the persistence of these hoaxes will further erode confidence among people who are already hesitant about the COVID vaccines. That's especially concerning as shots roll out for kids 12 and up. Jessica Calarco is a sociologist at Indiana University. She's found more than a quarter of parents don't plan to vaccinate their kids. JESSICA CALARCO: So many of these moms are turning to Facebook, are turning to Twitter, turning to other social media platforms. And they're saying, every time I open my phone, I see something different. BOND: Like stories about bad side effects. Even some parents who have been giving their kids routine childhood vaccines said they're unsure about COVID jabs. CALARCO: And those kinds of social media-based reports are, in many mothers' minds, kind of weighed equally against the kinds of expert medical recommendations coming out of things like the CDC. BOND: And that could make it hard to push down infection rates. Shannon Bond, NPR News.", "section": "Untangling Disinformation", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-05-13-996617504": {"title": "'Disinformation Dozen' \u2014 Just 12 People \u2014 Behind Bulk Of Vaccine Falsities Online : NPR", "url": "https://www.npr.org/2021/05/13/996617504/disinformation-dozen-just-12-people-behind-bulk-of-vaccine-falsities-onl", "author": "No author found", "published_date": "2021-05-13", "content": "", "section": "Technology", "disclaimer": ""}, "2021-05-13-996299367": {"title": "Could A Ban On Ransom Payments Have Stopped The Colonial Pipeline Attack? : NPR", "url": "https://www.npr.org/2021/05/13/996299367/how-to-stop-ransomware-attacks-1-proposal-would-prohibit-victims-from-paying-up", "author": "No author found", "published_date": "2021-05-13", "content": "", "section": "National Security", "disclaimer": ""}, "2021-05-16-997363526": {"title": "Microsoft Board Investigated Bill Gates' 'Intimate Relationship' With Employee : NPR", "url": "https://www.npr.org/2021/05/16/997363526/microsoft-board-investigated-bill-gates-intimate-relationship-with-employee", "author": "No author found", "published_date": "2021-05-16", "content": "", "section": "Technology", "disclaimer": ""}, "2021-05-18-990234501": {"title": "Researchers Worry Facebook Is Muddying Platform's Link To Depression : NPR", "url": "https://www.npr.org/2021/05/18/990234501/facebook-calls-links-to-depression-inconclusive-these-researchers-disagree", "author": "No author found", "published_date": "2021-05-18", "content": "MARY LOUISE KELLY, HOST:  American kids and teenagers are spending more time looking at social media than ever before. The thing is, we still do not have a complete understanding of what that might be doing to their brains. That has a lot of people concerned, including lawmakers in Congress and even social media companies themselves, including Facebook, according to new reporting from NPR's Miles Parks. Hey, Miles. MILES PARKS, BYLINE: Hey there. KELLY: So let me note, Facebook is a financial supporter of NPR. And then let me ask you, what do we know about the impact of social media on children's mental health? PARKS: Well, the field of studying these platforms is pretty new, but a number of recent studies do seem to indicate some sort of association between social media use and poor mental health outcomes like depression. Here's Jean Twenge, who's a psychology professor at San Diego State University. JEAN TWENGE: The correlational evidence showing that there is a link between social media use and depression is pretty definitive at this point. PARKS: But the social media companies and Facebook, in particular, have not embraced that research. For years, Facebook CEO Mark Zuckerberg and other people at the company have over and over again kind of referred to this research about depression and social media as inconclusive. That word comes up a lot when they're talking about this sort of research, which is important because it was recently revealed that the company is working on plans to develop an Instagram app for kids under the age of 13. And those sorts of growth plans get really complicated if there is ever any sort of consensus that these sorts of platforms are bad for kids. KELLY: You mentioned Facebook has not embraced some of the research that's out there on this subject. Has the company done its own research? How much does it know about how Facebook affects people's mental health? PARKS: That's a little unclear. We know Facebook knows more than it's publicly revealed. What was interesting as I was reporting this story was I was calling all of these researchers who focus specifically on the link between social media and depression, and I find out that Facebook has also been reaching out to a bunch of these same people for the first time in their careers just in the last couple months. Twenge and two other mental health researchers I talked to described getting contacted by the company about potentially giving their thoughts on some sort of internal information. Also, at a congressional hearing earlier this year, Zuckerberg told a member of Congress, Congresswoman Cathy McMorris Rodgers, that the company has done research on the mental health effects to children. But Rodgers says when her staff reached out to Facebook after that hearing, they declined to give her more specifics. CATHY MCMORRIS RODGERS: They seem to be more concerned about their current business model, and they have become very wealthy. But the fact of the matter is we're seeing more and more evidence that their current business model is harming our kids. PARKS: Rodgers says that lack of transparency means parents specifically are really at a disadvantage 'cause they're trying to decide just how much is too much when it comes to their kids and using social media. KELLY: Did you ask Facebook? What do they say about all this? PARKS: So the company declined to give me any more detail about these meeting requests with the researchers, though a spokesperson did note that Facebook does reach out to lots of different subject matter experts all the time. Generally, though, researchers I talked to were really skeptical about Facebook's interest in objective data about the platform's effects. I talked to Martin Paulus, who leads the Laureate Institute for Brain Research. MARTIN PAULUS: Yes, they want to say they want research. But they're not necessarily interested in research that potentially would show that some of the things that they do are bad for the kids. PARKS: Paulus actually gave a presentation at Facebook a few years ago. But he says the outreach at that time kind of felt like what he called a face-saving activity as opposed to a real desire to improve the platforms. KELLY: Miles, this all comes, of course, as we're engaged in this broader debate in the country of whether and how social media companies should be regulated. How does this fit in? PARKS: Well, you can't write laws unless you know exactly what the problems you're fixing and the ways to solve them. Another thing I heard from a lot of researchers is there's not enough government funding going to looking at all of these impacts, but it is on lawmakers' minds. The issue of kids' mental health is one of the only things related to Big Tech that both Republicans and Democrats are concerned about. So it's a place regulation is at least possible. KELLY: NPR's Miles Parks. Thanks. PARKS: Thank you. MARY LOUISE KELLY, HOST:   American kids and teenagers are spending more time looking at social media than ever before. The thing is, we still do not have a complete understanding of what that might be doing to their brains. That has a lot of people concerned, including lawmakers in Congress and even social media companies themselves, including Facebook, according to new reporting from NPR's Miles Parks. Hey, Miles. MILES PARKS, BYLINE: Hey there. KELLY: So let me note, Facebook is a financial supporter of NPR. And then let me ask you, what do we know about the impact of social media on children's mental health? PARKS: Well, the field of studying these platforms is pretty new, but a number of recent studies do seem to indicate some sort of association between social media use and poor mental health outcomes like depression. Here's Jean Twenge, who's a psychology professor at San Diego State University. JEAN TWENGE: The correlational evidence showing that there is a link between social media use and depression is pretty definitive at this point. PARKS: But the social media companies and Facebook, in particular, have not embraced that research. For years, Facebook CEO Mark Zuckerberg and other people at the company have over and over again kind of referred to this research about depression and social media as inconclusive. That word comes up a lot when they're talking about this sort of research, which is important because it was recently revealed that the company is working on plans to develop an Instagram app for kids under the age of 13. And those sorts of growth plans get really complicated if there is ever any sort of consensus that these sorts of platforms are bad for kids. KELLY: You mentioned Facebook has not embraced some of the research that's out there on this subject. Has the company done its own research? How much does it know about how Facebook affects people's mental health? PARKS: That's a little unclear. We know Facebook knows more than it's publicly revealed. What was interesting as I was reporting this story was I was calling all of these researchers who focus specifically on the link between social media and depression, and I find out that Facebook has also been reaching out to a bunch of these same people for the first time in their careers just in the last couple months. Twenge and two other mental health researchers I talked to described getting contacted by the company about potentially giving their thoughts on some sort of internal information. Also, at a congressional hearing earlier this year, Zuckerberg told a member of Congress, Congresswoman Cathy McMorris Rodgers, that the company has done research on the mental health effects to children. But Rodgers says when her staff reached out to Facebook after that hearing, they declined to give her more specifics. CATHY MCMORRIS RODGERS: They seem to be more concerned about their current business model, and they have become very wealthy. But the fact of the matter is we're seeing more and more evidence that their current business model is harming our kids. PARKS: Rodgers says that lack of transparency means parents specifically are really at a disadvantage 'cause they're trying to decide just how much is too much when it comes to their kids and using social media. KELLY: Did you ask Facebook? What do they say about all this? PARKS: So the company declined to give me any more detail about these meeting requests with the researchers, though a spokesperson did note that Facebook does reach out to lots of different subject matter experts all the time. Generally, though, researchers I talked to were really skeptical about Facebook's interest in objective data about the platform's effects. I talked to Martin Paulus, who leads the Laureate Institute for Brain Research. MARTIN PAULUS: Yes, they want to say they want research. But they're not necessarily interested in research that potentially would show that some of the things that they do are bad for the kids. PARKS: Paulus actually gave a presentation at Facebook a few years ago. But he says the outreach at that time kind of felt like what he called a face-saving activity as opposed to a real desire to improve the platforms. KELLY: Miles, this all comes, of course, as we're engaged in this broader debate in the country of whether and how social media companies should be regulated. How does this fit in? PARKS: Well, you can't write laws unless you know exactly what the problems you're fixing and the ways to solve them. Another thing I heard from a lot of researchers is there's not enough government funding going to looking at all of these impacts, but it is on lawmakers' minds. The issue of kids' mental health is one of the only things related to Big Tech that both Republicans and Democrats are concerned about. So it's a place regulation is at least possible. KELLY: NPR's Miles Parks. Thanks. PARKS: Thank you.", "section": "Untangling Disinformation", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-05-18-997549334": {"title": "'You Can't Just Concede.' How One Expert Explains Negotiating With Cybercriminals : NPR", "url": "https://www.npr.org/2021/05/18/997549334/you-cant-just-concede-how-one-expert-explains-negotiating-with-cybercriminals", "author": "No author found", "published_date": "2021-05-18", "content": "RACHEL MARTIN, HOST:  The operators of the Colonial Pipeline now say things are back to normal after a ransomware attack led them to shut down the pipeline. They reportedly paid upwards of $5 million to the hackers who had infiltrated their network. But not all cyber extortion attacks end this way. Bill Siegel runs Coveware. It's a company that responds to ransomware attacks and often negotiates with hackers. I asked him to explain the objective for these kinds of negotiations. BILL SIEGEL: Well, at the end of the day, the goal is to find a way for the company to recover without having to pay at all. But that'd be. . . MARTIN: Does that ever happen? SIEGEL: Oh, yeah, absolutely. It's not a foregone conclusion that a company has to pay a ransom for sure. A lot of times when an attack happens, it's very difficult for a big company to determine immediately what the situation is because if you're a large company and you've got, you know, 10,000 servers globally and you've got backups at, you know, 15 different locations throughout the globe, it can take days sometimes to actually safely check the integrity of those backups. And so when we're managing a large, you know, enterprise incident, you don't want to start negotiating when you realize you need it; you want to be done. And so we'll kick off negotiation knowing that a very likely outcome is that we actually don't end up paying. But we want to. . . MARTIN: So you can be negotiating just to buy time? So the company can figure out if they have a backup, and they can say, sorry, your threat's not good here because we're safe. SIEGEL: Of course, yeah. That's the goal, right? You know, the cost for a large company being down is so substantial that hours can mean the difference in, you know, millions or tens of millions of dollars of lost profit. Or in the case of, you know, a hospital or something, it can mean the difference between life and death. So you don't want to waste any time. You want to basically get to the finish line and be ready, even if the conclusion is, well, we don't need to do anything. And that's the best conclusion. MARTIN: So what happens when it becomes clear that a company really is at risk and they don't have adequate backup and the hackers really do have all the power? I mean, what do you and your clients have in terms of leverage in a situation like that? SIEGEL: The answer is you have very little, but there - you still have to find ways to negotiate successfully on behalf of your client, right? You can't just concede. You can't look desperate. So you have to find ways, you know, to draw the negotiation to some semblance of a successful conclusion. What we do, in as much as there is a lot of skill and tactics and experience and data brought into actually the how of how we perform negotiation, there is as much experience and skill used in just the overall project management of the incident and helping the company think through these decisions and manage their own time and decision-making. MARTIN: If a situation occurs, a cyberattack happens, the company is forced to pay ransom, what's to prevent those same hackers from, six months, a year later, just coming back and doing the same thing again? SIEGEL: Yeah, there's absolutely nothing, is the answer. One of the biggest fallacies and misunderstood aspects of these attacks is that they are like lightning strikes, right? It's like, well, it happened once; it's not going to happen again. That's just - that's not the way it works. The groups that are carrying this out are part of a very well-organized and a very large industry. The power laws of economics dictate how they behave, right? If there's one thing I've observed over doing a few thousand of these over the last couple of years is that economics rule how behavior runs in this space. If it is cost effective - i. e. , cheap to attack a company - and has a high likelihood of being profitable at low risk, they will do it, and they will do it over and over and over again, just like any other business would do the exact same thing if they found a very cheap way to sell very high-profit products. And so it's. . . MARTIN: You've seen this? SIEGEL: Yeah, of course. If a company does not take it seriously and they don't fix the vulnerabilities that allowed it to happen in the first place, there's a 100% chance it happens again. MARTIN: Are you able to tell us the origin country of most of the cyberattacks that you see? SIEGEL: You know, we don't do very detailed attribution. What I would say is that the contributory factors that have led us to where we are today are as much socioeconomic as they are other things. There are such low barriers to entry to cybercrime, and there are lots of well-educated, sometimes STEM-educated individuals in lots of parts of the world. They don't have the job prospects that will pay them the money that they aspire to make, and sometimes their local jurisdictions are kind of out of the reach of Western law enforcement. And it's - you know, while it may be sort of frowned upon, it's sort of condoned by wherever they live - right? - because the local economy actually benefits from the laundered proceeds of those attacks filtering back in. And these people are buying houses and buying Starbucks and buying cars, and that's a good thing for the local economy, so they sort of look the other way. MARTIN: Have you thought about your company's role in all of this, I mean, especially when you consider those repeat offenders and how paying ransom, agreeing to pay a ransom to a group of hackers, doesn't prevent them from coming back? I mean, you as a facilitator of these payments, are you concerned that you are actually helping perpetuate this cycle? SIEGEL: Of course. And I think if you're going to be in this industry, you have to have a pretty big altruistic chip on your shoulder. And we founded this company to try and solve the problem. That may seem weird, but the reality is, when we founded the company, there was no centralized data on how these attacks happened. And we felt that the first thing you have to do to solve the problem is to collect the data, and I think we've done that very well. MARTIN: So what that means is any time you're in a negotiation, yes, you're helping your client, but you are learning things. You're learning things about the attackers. You're learning things about the process. And then you make those more publicly available or available to law enforcement, perhaps, or other entities within the U. S. government so that they can work on cracking down on the issue of cyberattacks. SIEGEL: That's correct. We share information with law enforcement. We share information with the public. And we have absolutely no problem winding up our company and closing it down if ransomware ceases to exist as a problem. MARTIN: And that would be the goal, presumably. SIEGEL: A hundred percent. MARTIN: Bill Siegel - he is the CEO of Coveware, which responds to ransomware attacks. Thank you so much for taking the time to explain all this. We do appreciate it. SIEGEL: Thank you so much for having me. (SOUNDBITE OF SYNTHETIC EPIPHANY'S \"THE ART OF WAR\") RACHEL MARTIN, HOST:   The operators of the Colonial Pipeline now say things are back to normal after a ransomware attack led them to shut down the pipeline. They reportedly paid upwards of $5 million to the hackers who had infiltrated their network. But not all cyber extortion attacks end this way. Bill Siegel runs Coveware. It's a company that responds to ransomware attacks and often negotiates with hackers. I asked him to explain the objective for these kinds of negotiations. BILL SIEGEL: Well, at the end of the day, the goal is to find a way for the company to recover without having to pay at all. But that'd be. . . MARTIN: Does that ever happen? SIEGEL: Oh, yeah, absolutely. It's not a foregone conclusion that a company has to pay a ransom for sure. A lot of times when an attack happens, it's very difficult for a big company to determine immediately what the situation is because if you're a large company and you've got, you know, 10,000 servers globally and you've got backups at, you know, 15 different locations throughout the globe, it can take days sometimes to actually safely check the integrity of those backups. And so when we're managing a large, you know, enterprise incident, you don't want to start negotiating when you realize you need it; you want to be done. And so we'll kick off negotiation knowing that a very likely outcome is that we actually don't end up paying. But we want to. . . MARTIN: So you can be negotiating just to buy time? So the company can figure out if they have a backup, and they can say, sorry, your threat's not good here because we're safe. SIEGEL: Of course, yeah. That's the goal, right? You know, the cost for a large company being down is so substantial that hours can mean the difference in, you know, millions or tens of millions of dollars of lost profit. Or in the case of, you know, a hospital or something, it can mean the difference between life and death. So you don't want to waste any time. You want to basically get to the finish line and be ready, even if the conclusion is, well, we don't need to do anything. And that's the best conclusion. MARTIN: So what happens when it becomes clear that a company really is at risk and they don't have adequate backup and the hackers really do have all the power? I mean, what do you and your clients have in terms of leverage in a situation like that? SIEGEL: The answer is you have very little, but there - you still have to find ways to negotiate successfully on behalf of your client, right? You can't just concede. You can't look desperate. So you have to find ways, you know, to draw the negotiation to some semblance of a successful conclusion. What we do, in as much as there is a lot of skill and tactics and experience and data brought into actually the how of how we perform negotiation, there is as much experience and skill used in just the overall project management of the incident and helping the company think through these decisions and manage their own time and decision-making. MARTIN: If a situation occurs, a cyberattack happens, the company is forced to pay ransom, what's to prevent those same hackers from, six months, a year later, just coming back and doing the same thing again? SIEGEL: Yeah, there's absolutely nothing, is the answer. One of the biggest fallacies and misunderstood aspects of these attacks is that they are like lightning strikes, right? It's like, well, it happened once; it's not going to happen again. That's just - that's not the way it works. The groups that are carrying this out are part of a very well-organized and a very large industry. The power laws of economics dictate how they behave, right? If there's one thing I've observed over doing a few thousand of these over the last couple of years is that economics rule how behavior runs in this space. If it is cost effective - i. e. , cheap to attack a company - and has a high likelihood of being profitable at low risk, they will do it, and they will do it over and over and over again, just like any other business would do the exact same thing if they found a very cheap way to sell very high-profit products. And so it's. . . MARTIN: You've seen this? SIEGEL: Yeah, of course. If a company does not take it seriously and they don't fix the vulnerabilities that allowed it to happen in the first place, there's a 100% chance it happens again. MARTIN: Are you able to tell us the origin country of most of the cyberattacks that you see? SIEGEL: You know, we don't do very detailed attribution. What I would say is that the contributory factors that have led us to where we are today are as much socioeconomic as they are other things. There are such low barriers to entry to cybercrime, and there are lots of well-educated, sometimes STEM-educated individuals in lots of parts of the world. They don't have the job prospects that will pay them the money that they aspire to make, and sometimes their local jurisdictions are kind of out of the reach of Western law enforcement. And it's - you know, while it may be sort of frowned upon, it's sort of condoned by wherever they live - right? - because the local economy actually benefits from the laundered proceeds of those attacks filtering back in. And these people are buying houses and buying Starbucks and buying cars, and that's a good thing for the local economy, so they sort of look the other way. MARTIN: Have you thought about your company's role in all of this, I mean, especially when you consider those repeat offenders and how paying ransom, agreeing to pay a ransom to a group of hackers, doesn't prevent them from coming back? I mean, you as a facilitator of these payments, are you concerned that you are actually helping perpetuate this cycle? SIEGEL: Of course. And I think if you're going to be in this industry, you have to have a pretty big altruistic chip on your shoulder. And we founded this company to try and solve the problem. That may seem weird, but the reality is, when we founded the company, there was no centralized data on how these attacks happened. And we felt that the first thing you have to do to solve the problem is to collect the data, and I think we've done that very well. MARTIN: So what that means is any time you're in a negotiation, yes, you're helping your client, but you are learning things. You're learning things about the attackers. You're learning things about the process. And then you make those more publicly available or available to law enforcement, perhaps, or other entities within the U. S. government so that they can work on cracking down on the issue of cyberattacks. SIEGEL: That's correct. We share information with law enforcement. We share information with the public. And we have absolutely no problem winding up our company and closing it down if ransomware ceases to exist as a problem. MARTIN: And that would be the goal, presumably. SIEGEL: A hundred percent. MARTIN: Bill Siegel - he is the CEO of Coveware, which responds to ransomware attacks. Thank you so much for taking the time to explain all this. We do appreciate it. SIEGEL: Thank you so much for having me. (SOUNDBITE OF SYNTHETIC EPIPHANY'S \"THE ART OF WAR\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-05-19-993247101": {"title": "2020 Census Data And Differential Privacy: What You Need To Know : NPR", "url": "https://www.npr.org/2021/05/19/993247101/for-the-u-s-census-keeping-your-data-anonymous-and-useful-is-a-tricky-balance", "author": "No author found", "published_date": "2021-05-19", "content": "SCOTT SIMON, HOST:  Federal court is expected to rule soon in a lawsuit that could cause major delays to upcoming elections. The state of Alabama is trying to stop the Census Bureau from putting in place new privacy protections for redistricting data. NPR census correspondent Hansi Lo Wang explains. HANSI LO WANG, BYLINE: This legal fight is about a tricky balancing act the Census Bureau has to face every 10 years. How does the bureau release detailed demographic information from the national headcount in which every household is legally required to participate while also keeping this promise. . . (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED PERSON: After sending your census response, your personal information is kept safe. WANG: . . . As described in these 2020 census ads? (SOUNDBITE OF YOUTUBE VIDEO, \"MAKE IT COUNT / #2020CENSUS\")ANNE FRANCIS GUZMAN: (As Mrs. Lopez) It's completely safe. They can't share your answers with anyone - no police, no immigration. WANG: Those census answers are shared with the public 72 years after they're collected. Until then, the bureau uses them to produce a lot of statistics about people's race, ethnicity, age, sex and other characteristics. Under federal law, the bureau has to keep people anonymous in those statistics. And a few years ago, the bureau concluded the privacy protections it's used in the past are no longer strong enough. CYNTHIA DWORK: It was only a matter of time in the digital age before somebody would break them. WANG: This is Cynthia Dwork. DWORK: I'm a professor of computer science at Harvard. WANG: Who's also with the research arm of Microsoft, one of NPR's financial supporters. Dwork co-invented differential privacy. It's the mathematical concept the bureau is using to build a new privacy protection system for the census data expected out by mid-August. Dwork says the new protections are needed to keep up with advances in computing and the growing amount of data available from commercial sources. They've made it easier to trace statistics back to an individual and use them against people. DWORK: I come from a privileged home. I never think of whether anyone's going to question my right to be residing there. But there are people who are in much more precarious situations than I am. It's to protect them that these things become so important. It's to protect the vulnerable. ALEXIS SANTOS: What's at stake is our understanding of the portrait of the United States. WANG: Alexis Santos is a demographer at Penn State University and one of the many users of census data who have been looking at early tests of the bureau's privacy protection system and are concerned about how it blurs the census results. SANTOS: What we're seeing with the implementation of differential privacy, at least with the data I've analyzed, is that you have blurry patches. You have blurry areas. You have areas that do not look as they should look. WANG: Based on preliminary analysis, Santos says the new system could make some of the new 2020 census data useless, especially information that many policymakers and researchers rely on to determine the needs of small geographic areas and minority groups within communities. SANTOS: A lot of people who are working everyday jobs who rely on demographics, they get their information from public data. And what we are at risk here is of putting out tabulations that do not help them at all and can misguide the decisions they're making. WANG: Alabama is arguing in its lawsuit that the bureau's privacy plan will make the data unusable for the redrawing of voting districts. The bureau has been adjusting its privacy protections, and it says the plan it recently finalized will ensure, quote, \"the accuracy of data necessary for redistricting and Voting Rights Act enforcement. \" Still, some civil rights advocates are skeptical of the bureau's plans, including Thomas Saenz, president of the Mexican American Legal Defense and Educational Fund. THOMAS SAENZ: At this point, it seems not at all clear that anything the bureau releases will eliminate the possibility that the Voting Rights Act and its enforcement could be adversely affected by differential privacy. WANG: And that could potentially result in more lawsuits. SAENZ: Yes. WANG: For Alabama's lawsuit, if the courts ultimately block the bureau's differential privacy plans, officials estimate it could take at least half a year to develop new plans and would further push back the release of data that state and local redistricting officials have already spent months waiting for because of delays caused by the pandemic and the Trump administration. Hansi Lo Wang, NPR News, New York. SCOTT SIMON, HOST:   Federal court is expected to rule soon in a lawsuit that could cause major delays to upcoming elections. The state of Alabama is trying to stop the Census Bureau from putting in place new privacy protections for redistricting data. NPR census correspondent Hansi Lo Wang explains. HANSI LO WANG, BYLINE: This legal fight is about a tricky balancing act the Census Bureau has to face every 10 years. How does the bureau release detailed demographic information from the national headcount in which every household is legally required to participate while also keeping this promise. . . (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED PERSON: After sending your census response, your personal information is kept safe. WANG: . . . As described in these 2020 census ads? (SOUNDBITE OF YOUTUBE VIDEO, \"MAKE IT COUNT / #2020CENSUS\") ANNE FRANCIS GUZMAN: (As Mrs. Lopez) It's completely safe. They can't share your answers with anyone - no police, no immigration. WANG: Those census answers are shared with the public 72 years after they're collected. Until then, the bureau uses them to produce a lot of statistics about people's race, ethnicity, age, sex and other characteristics. Under federal law, the bureau has to keep people anonymous in those statistics. And a few years ago, the bureau concluded the privacy protections it's used in the past are no longer strong enough. CYNTHIA DWORK: It was only a matter of time in the digital age before somebody would break them. WANG: This is Cynthia Dwork. DWORK: I'm a professor of computer science at Harvard. WANG: Who's also with the research arm of Microsoft, one of NPR's financial supporters. Dwork co-invented differential privacy. It's the mathematical concept the bureau is using to build a new privacy protection system for the census data expected out by mid-August. Dwork says the new protections are needed to keep up with advances in computing and the growing amount of data available from commercial sources. They've made it easier to trace statistics back to an individual and use them against people. DWORK: I come from a privileged home. I never think of whether anyone's going to question my right to be residing there. But there are people who are in much more precarious situations than I am. It's to protect them that these things become so important. It's to protect the vulnerable. ALEXIS SANTOS: What's at stake is our understanding of the portrait of the United States. WANG: Alexis Santos is a demographer at Penn State University and one of the many users of census data who have been looking at early tests of the bureau's privacy protection system and are concerned about how it blurs the census results. SANTOS: What we're seeing with the implementation of differential privacy, at least with the data I've analyzed, is that you have blurry patches. You have blurry areas. You have areas that do not look as they should look. WANG: Based on preliminary analysis, Santos says the new system could make some of the new 2020 census data useless, especially information that many policymakers and researchers rely on to determine the needs of small geographic areas and minority groups within communities. SANTOS: A lot of people who are working everyday jobs who rely on demographics, they get their information from public data. And what we are at risk here is of putting out tabulations that do not help them at all and can misguide the decisions they're making. WANG: Alabama is arguing in its lawsuit that the bureau's privacy plan will make the data unusable for the redrawing of voting districts. The bureau has been adjusting its privacy protections, and it says the plan it recently finalized will ensure, quote, \"the accuracy of data necessary for redistricting and Voting Rights Act enforcement. \" Still, some civil rights advocates are skeptical of the bureau's plans, including Thomas Saenz, president of the Mexican American Legal Defense and Educational Fund. THOMAS SAENZ: At this point, it seems not at all clear that anything the bureau releases will eliminate the possibility that the Voting Rights Act and its enforcement could be adversely affected by differential privacy. WANG: And that could potentially result in more lawsuits. SAENZ: Yes. WANG: For Alabama's lawsuit, if the courts ultimately block the bureau's differential privacy plans, officials estimate it could take at least half a year to develop new plans and would further push back the release of data that state and local redistricting officials have already spent months waiting for because of delays caused by the pandemic and the Trump administration. Hansi Lo Wang, NPR News, New York.", "section": "National", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-05-20-998709152": {"title": "New Brain-Controlled Robotic Arm Gives Wearer The Sense Of Touch : NPR", "url": "https://www.npr.org/2021/05/20/998709152/new-brain-controlled-robotic-arm-gives-wearer-the-sense-of-touch", "author": "No author found", "published_date": "2021-05-20", "content": "MARY LOUISE KELLY, HOST:  A robotic arm with a sense of touch has allowed a man who is paralyzed to quickly perform tasks like pouring water in a cup. NPR's Jon Hamilton reports the arm provides sensory information directly to the man's brain. JON HAMILTON, BYLINE: It's hard to hold on to something you can't feel, says Jen Collinger of the University of Pittsburgh. JEN COLLINGER: Even something simple, like picking up a cup and trying to maintain the appropriate amount of pressure as you move it to another location, that relies a lot on the tactile feedback from your hand. HAMILTON: Collinger is part of a team that's been looking for ways to add sensory feedback to a robotic arm and hand. The scientists have been working with Nathan Copeland, who is in his 30s and paralyzed. He has learned to control the device using just his thoughts. Collinger says the team began by finding a way to send electrical signals to the part of Copeland's brain that processes sensory information. COLLINGER: It turned out that stimulating in the fingertip-related areas in the brain generated sensations that felt like they were coming from the participant's own hand. HAMILTON: Next, the team figured out how to generate those signals when the robotic arm and hand made contact with something. Collinger says the final step was to have Copeland perform tasks like picking up a block or pouring water from one cup into another. COLLINGER: With just visual feedback, his median time was about 20 seconds. With sensory feedback, he was able to complete it in 10. HAMILTON: Not much slower than a person using their own hand, the team reports in the journal Science. And Copeland, who has been paralyzed since he was a teenager, says the results showed just how much people rely on a sense of touch. NATHAN COPELAND: When I only had visual feedback, I could see that the hand had touched the object. But sometimes I would go to pick it up, and it would fall out. HAMILTON: Copeland says that problem went away when he started receiving tactile feedback. COPELAND: The sensation would actually change intensity based on how much force the hand was exerting on the object, so I could also tell if I had a firm grip on it or not. HAMILTON: Copeland says adding a sense of touch also made using the robotic arm feel more natural. COPELAND: The control is so intuitive that I'm basically just thinking about things as if I were moving my own arm. HAMILTON: The results have implications beyond robotic arms. Jeremy Brown of Johns Hopkins University says high-tech prosthetic limbs also work better when they simulate a sense of touch. He says some do this by vibrating or providing some other form of what's known as haptic feedback. JEREMY BROWN: You could build these arms. They operate just like our natural limbs do, right? But when you give somebody the ability to try and control this thing, until they have the haptics, it's clunky. HAMILTON: Brown says touch tells us a lot more than just whether our hand has encountered an object. BROWN: I feel the pressure. I feel the slip. I feel with the object is wet or dry. I can feel the texture of it. I know whether it's rough, whether it's smooth. I mean, we feel all of this the minute you come into contact with something. HAMILTON: Scientists are just beginning to learn how to make artificial hands and fingers that can detect these features. Brown says the more information a prosthetic or robotic limb provides, the more useful it will be. But he says a sense of touch is about more than just increasing dexterity. BROWN: It's not just the ability to reach in your pocket and grab your keys. It's also the ability to hold a loved one's hand and feel that emotional connection as well. HAMILTON: Brown says that's something people miss after they lose an arm or a hand. He's hoping his own research will help bring that connection back. Jon Hamilton, NPR News. (SOUNDBITE OF MUSIC) MARY LOUISE KELLY, HOST:   A robotic arm with a sense of touch has allowed a man who is paralyzed to quickly perform tasks like pouring water in a cup. NPR's Jon Hamilton reports the arm provides sensory information directly to the man's brain. JON HAMILTON, BYLINE: It's hard to hold on to something you can't feel, says Jen Collinger of the University of Pittsburgh. JEN COLLINGER: Even something simple, like picking up a cup and trying to maintain the appropriate amount of pressure as you move it to another location, that relies a lot on the tactile feedback from your hand. HAMILTON: Collinger is part of a team that's been looking for ways to add sensory feedback to a robotic arm and hand. The scientists have been working with Nathan Copeland, who is in his 30s and paralyzed. He has learned to control the device using just his thoughts. Collinger says the team began by finding a way to send electrical signals to the part of Copeland's brain that processes sensory information. COLLINGER: It turned out that stimulating in the fingertip-related areas in the brain generated sensations that felt like they were coming from the participant's own hand. HAMILTON: Next, the team figured out how to generate those signals when the robotic arm and hand made contact with something. Collinger says the final step was to have Copeland perform tasks like picking up a block or pouring water from one cup into another. COLLINGER: With just visual feedback, his median time was about 20 seconds. With sensory feedback, he was able to complete it in 10. HAMILTON: Not much slower than a person using their own hand, the team reports in the journal Science. And Copeland, who has been paralyzed since he was a teenager, says the results showed just how much people rely on a sense of touch. NATHAN COPELAND: When I only had visual feedback, I could see that the hand had touched the object. But sometimes I would go to pick it up, and it would fall out. HAMILTON: Copeland says that problem went away when he started receiving tactile feedback. COPELAND: The sensation would actually change intensity based on how much force the hand was exerting on the object, so I could also tell if I had a firm grip on it or not. HAMILTON: Copeland says adding a sense of touch also made using the robotic arm feel more natural. COPELAND: The control is so intuitive that I'm basically just thinking about things as if I were moving my own arm. HAMILTON: The results have implications beyond robotic arms. Jeremy Brown of Johns Hopkins University says high-tech prosthetic limbs also work better when they simulate a sense of touch. He says some do this by vibrating or providing some other form of what's known as haptic feedback. JEREMY BROWN: You could build these arms. They operate just like our natural limbs do, right? But when you give somebody the ability to try and control this thing, until they have the haptics, it's clunky. HAMILTON: Brown says touch tells us a lot more than just whether our hand has encountered an object. BROWN: I feel the pressure. I feel the slip. I feel with the object is wet or dry. I can feel the texture of it. I know whether it's rough, whether it's smooth. I mean, we feel all of this the minute you come into contact with something. HAMILTON: Scientists are just beginning to learn how to make artificial hands and fingers that can detect these features. Brown says the more information a prosthetic or robotic limb provides, the more useful it will be. But he says a sense of touch is about more than just increasing dexterity. BROWN: It's not just the ability to reach in your pocket and grab your keys. It's also the ability to hold a loved one's hand and feel that emotional connection as well. HAMILTON: Brown says that's something people miss after they lose an arm or a hand. He's hoping his own research will help bring that connection back. Jon Hamilton, NPR News. (SOUNDBITE OF MUSIC)", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-05-20-998455891": {"title": "Twitter Will Verify Certain Users Again After A 3 Year Hiatus : NPR", "url": "https://www.npr.org/2021/05/20/998455891/twitter-relaunches-verification-check-heres-how-to-apply-for-one", "author": "No author found", "published_date": "2021-05-20", "content": "", "section": "Technology", "disclaimer": ""}, "2021-05-21-999360273": {"title": "'Charlie Bit My Finger' Stars To Auction Off Viral Video As NFT : NPR", "url": "https://www.npr.org/2021/05/21/999360273/viral-charlie-bit-my-finger-video-to-leave-youtube-sell-as-nft", "author": "No author found", "published_date": "2021-05-21", "content": "", "section": "Pop Culture", "disclaimer": ""}, "2021-05-21-998910662": {"title": "Apple's Tim Cook Calls Fortnite Maker Malicious : NPR", "url": "https://www.npr.org/2021/05/21/998910662/tim-cook-defends-apples-app-store-rules-calls-maker-of-fortnite-malicious", "author": "No author found", "published_date": "2021-05-21", "content": "AUDIE CORNISH, HOST:  For the first time, the CEO of the world's most valuable company defended that company in court. Apple CEO Tim Cook testified in a lawsuit that centers on a key feature of iPhones and iPads - the App Store. The maker of the hit video game Fortnite says the way Apple runs its App Store hurts consumers and drives out competition. NPR tech reporter Bobby Allyn has been covering the federal trial in Oakland and joins us now. And, of course, Bobby, we should note Apple is among NPR's financial supporters. And let's start with the courthouse itself, though. What was the scene like there? BOBBY ALLYN, BYLINE: Yeah. So I was standing at the courthouse's entrance, you know, early this morning with the rest of the media scrum waiting for Tim Cook to arrive. He, of course, is the trial's star witness. Everyone had their cameras out, ready to go. But then, Cook dodged the spotlight. He basically slunk through a side door in the parking lot. As he was going through security, though, he did flash a peace sign at the cameras. CORNISH: Now, I said earlier that this is about Fortnite arguing they're hurting consumers and driving out competition with the App Store. What more can you tell us in the way of background? ALLYN: Exactly. So at a very high level, this trial is about the power that Apple has over the 1 billion iPhones in circulation around the world. And so specifically, Apple not only controls the stores where we download apps but also controls how payments are processed. And Apple, you know, tacks on this 30% commission. Take the game Fortnite. That's what this trial is all about, right? If you're playing it on your iPhone and you want to be dressed like, say, a creepy bear, you can get it through the app. Boom. You got the creepy bear outfit - great. But what you don't see, Audie, is that 30% of your money is actually going to Apple. And the maker of Fortnite, Epic Games, says this shows that Apple is a monopoly. They call Apple's iPhone a walled garden because consumers have no choice. It's Apple or nothing. Epic argues that's illegal. CORNISH: What did Tim Cook have to say in his testimony? ALLYN: Yeah. Cook defended these fees. He says - you ever notice when you're on an iPhone that it's just less buggy and has less malware than maybe some other devices? He says that is because Apple has a very rigorous review process, and it's paid for by these fees. Cook says it's all about maintaining Apple's high bar for data privacy and for safety. But the most startling moment today came when the judge, Yvonne Gonzalez Rogers, drilled into Cook over a series of very, very sharp questions. Until this point, I should note, you know, most people assumed that Apple had the upper hand in the trial, but Rogers dressed down Cook. I mean, it really changed the game. The judge said over and over that there appears to be a lack of competition on Apple's App Store. And she called this, quote, \"troubling. \" The judge asked Cook, what's so wrong with giving iPhone gamers a little bit of choice? - because right now, Audie, they don't have it. CORNISH: What's next in the trial? ALLYN: Yeah. So it'll wrap up next week, and the judge warned that it's going to be some time before she rules. She has a mountain of evidence. The law is largely on Apple's side here, but the questions today from the judge have thrown real uncertainty into the final verdict. I mean, she could force Apple to let developers process their own payments. Time will tell. But if nothing else, Audie, this trial has really drawn some negative publicity to the practices that developers, you know, only really dared to whisper about before this because Apple has just such immense power over them. CORNISH: That's NPR's Bobby Allyn in Oakland, Calif. Thanks for following. ALLYN: Thanks. AUDIE CORNISH, HOST:   For the first time, the CEO of the world's most valuable company defended that company in court. Apple CEO Tim Cook testified in a lawsuit that centers on a key feature of iPhones and iPads - the App Store. The maker of the hit video game Fortnite says the way Apple runs its App Store hurts consumers and drives out competition. NPR tech reporter Bobby Allyn has been covering the federal trial in Oakland and joins us now. And, of course, Bobby, we should note Apple is among NPR's financial supporters. And let's start with the courthouse itself, though. What was the scene like there? BOBBY ALLYN, BYLINE: Yeah. So I was standing at the courthouse's entrance, you know, early this morning with the rest of the media scrum waiting for Tim Cook to arrive. He, of course, is the trial's star witness. Everyone had their cameras out, ready to go. But then, Cook dodged the spotlight. He basically slunk through a side door in the parking lot. As he was going through security, though, he did flash a peace sign at the cameras. CORNISH: Now, I said earlier that this is about Fortnite arguing they're hurting consumers and driving out competition with the App Store. What more can you tell us in the way of background? ALLYN: Exactly. So at a very high level, this trial is about the power that Apple has over the 1 billion iPhones in circulation around the world. And so specifically, Apple not only controls the stores where we download apps but also controls how payments are processed. And Apple, you know, tacks on this 30% commission. Take the game Fortnite. That's what this trial is all about, right? If you're playing it on your iPhone and you want to be dressed like, say, a creepy bear, you can get it through the app. Boom. You got the creepy bear outfit - great. But what you don't see, Audie, is that 30% of your money is actually going to Apple. And the maker of Fortnite, Epic Games, says this shows that Apple is a monopoly. They call Apple's iPhone a walled garden because consumers have no choice. It's Apple or nothing. Epic argues that's illegal. CORNISH: What did Tim Cook have to say in his testimony? ALLYN: Yeah. Cook defended these fees. He says - you ever notice when you're on an iPhone that it's just less buggy and has less malware than maybe some other devices? He says that is because Apple has a very rigorous review process, and it's paid for by these fees. Cook says it's all about maintaining Apple's high bar for data privacy and for safety. But the most startling moment today came when the judge, Yvonne Gonzalez Rogers, drilled into Cook over a series of very, very sharp questions. Until this point, I should note, you know, most people assumed that Apple had the upper hand in the trial, but Rogers dressed down Cook. I mean, it really changed the game. The judge said over and over that there appears to be a lack of competition on Apple's App Store. And she called this, quote, \"troubling. \" The judge asked Cook, what's so wrong with giving iPhone gamers a little bit of choice? - because right now, Audie, they don't have it. CORNISH: What's next in the trial? ALLYN: Yeah. So it'll wrap up next week, and the judge warned that it's going to be some time before she rules. She has a mountain of evidence. The law is largely on Apple's side here, but the questions today from the judge have thrown real uncertainty into the final verdict. I mean, she could force Apple to let developers process their own payments. Time will tell. But if nothing else, Audie, this trial has really drawn some negative publicity to the practices that developers, you know, only really dared to whisper about before this because Apple has just such immense power over them. CORNISH: That's NPR's Bobby Allyn in Oakland, Calif. Thanks for following. ALLYN: Thanks.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-05-21-999178100": {"title": "Tinder, Bumble Launch Features To Match Vaccinated Singles : Coronavirus Updates : NPR", "url": "https://www.npr.org/2021/05/21/999178100/single-dating-apps-are-making-it-easier-to-swipe-right-for-a-match-whos-vaccinat", "author": "No author found", "published_date": "2021-05-21", "content": "", "section": "Coronavirus Updates", "disclaimer": ""}, "2021-05-21-998659427": {"title": "Game Review: 'Never Yield' Is A Speedy, Stylish Side-Scroller : NPR", "url": "https://www.npr.org/2021/05/21/998659427/new-game-never-yield-is-a-speedy-stylish-side-scroller-with-tons-of-replay-value", "author": "No author found", "published_date": "2021-05-21", "content": "", "section": "Gaming", "disclaimer": ""}, "2021-05-21-997954472": {"title": "The Energy Lurking In Sewers Could Help Fight Climate Change : NPR", "url": "https://www.npr.org/2021/05/21/997954472/how-your-hot-showers-and-toilet-flushes-can-help-the-climate", "author": "No author found", "published_date": "2021-05-21", "content": "RACHEL MARTIN, HOST:  A secret weapon against climate change might be hiding in sewers. The underground pipes contain excess energy that could heat and cool buildings. The concept is called sewer heat recovery. One of the largest such projects in the U. S. is underway in Denver. Sam Brasch of Colorado Public Radio reports. (SOUNDBITE OF VEHICLE BEEPING)SAM BRASCH, BYLINE: At a construction site in north Denver, Katie Hegarty oversees a crew inside a recently dug pit. At the bottom is a sewer pipe. It's one of the main arteries transporting the city's wastewater. KATIE HEGARTY: We still call it wastewater, but it's not wasted. We're using it to recover heat that can both heat and cool this campus. BRASCH: That campus will soon host the National Western Stock Show and Rodeo. It's an old West event getting new West digs. A massive remodel is adding an arena, offices and classrooms. And all that new space will be kept comfy with sewer heat. HEGARTY: I've built all sorts of different projects. Nothing like this before. BRASCH: It's no mystery where the excess heat comes from. Any time you take a shower or wash the dishes, you're literally sending energy down the drain. The Department of Energy estimates the total amount could power about 30 million U. S. homes for a whole year. By recovering some of it, buildings can avoid climate warming emissions. And there's another benefit, too. WILLIAM CAVANAUGH: After the wastewater is collected and treated, we return it to the river and recharge the river at this location. BRASCH: William Cavanaugh is with the Metro Wastewater Reclamation District. We're outside its massive treatment plants, where waterfalls of clean sewage cascade into Denver's South Platte River. Cavanaugh says the water is warmer than the river itself and that thermal pollution can harm aquatic life. But the sewer heat system will actually cool the wastewater. CAVANAUGH: That's correct. We're removing thermal energy. And so that'll help us move towards our goals of reducing the temperature in our effluent. BRASCH: So to recap, the project will cut carbon emissions and improve river health. It's a win-win. So what's making this possible now? Shanti Pless is with the National Renewable Energy Laboratory. And he says one reason is improvements to heat pumps, which are basically reversible air conditioners. SHANTI PLESS: With the advent of large-scale heat pumps, we can now cost effectively, you know, use, you know, say, 70-degree wastewater to heat our buildings and our hot water systems. BRASCH: Pless says the technology is opening up a whole new world of renewable heat mining. But those systems tend to work best for whole neighborhoods or districts, not individual homes or buildings. He says the Denver project could prove the upfront investment is worth it. PLESS: The National Western project has been a great local example for us to take that idea to the to the rest of the country. BRASCH: But the people behind the project also worry it could trigger a kind of sewer heat gold rush. Brad Buchanan is the CEO of the National Western Center. And he says his plans for the campus came together. BRAD BUCHANAN: We have to answer the question, how do we protect these sewer thermal energy rights? BRASCH: The result was an agreement guaranteeing the campus exclusive access to energy inside nearby sewer pipes. Buchanan says that has him thinking about the whole future of real estate. BUCHANAN: If folks sort of start to look at not just where light rail lines are located or good schools are located, but what's the proximity to a large sanitary sewer line running through Denver somewhere? BRASCH: Because if you choose the right place, a wealth of sewer heat could be all yours. For NPR News, I'm Sam Brasch in Denver. (SOUNDBITE OF MUSIC) RACHEL MARTIN, HOST:   A secret weapon against climate change might be hiding in sewers. The underground pipes contain excess energy that could heat and cool buildings. The concept is called sewer heat recovery. One of the largest such projects in the U. S. is underway in Denver. Sam Brasch of Colorado Public Radio reports. (SOUNDBITE OF VEHICLE BEEPING) SAM BRASCH, BYLINE: At a construction site in north Denver, Katie Hegarty oversees a crew inside a recently dug pit. At the bottom is a sewer pipe. It's one of the main arteries transporting the city's wastewater. KATIE HEGARTY: We still call it wastewater, but it's not wasted. We're using it to recover heat that can both heat and cool this campus. BRASCH: That campus will soon host the National Western Stock Show and Rodeo. It's an old West event getting new West digs. A massive remodel is adding an arena, offices and classrooms. And all that new space will be kept comfy with sewer heat. HEGARTY: I've built all sorts of different projects. Nothing like this before. BRASCH: It's no mystery where the excess heat comes from. Any time you take a shower or wash the dishes, you're literally sending energy down the drain. The Department of Energy estimates the total amount could power about 30 million U. S. homes for a whole year. By recovering some of it, buildings can avoid climate warming emissions. And there's another benefit, too. WILLIAM CAVANAUGH: After the wastewater is collected and treated, we return it to the river and recharge the river at this location. BRASCH: William Cavanaugh is with the Metro Wastewater Reclamation District. We're outside its massive treatment plants, where waterfalls of clean sewage cascade into Denver's South Platte River. Cavanaugh says the water is warmer than the river itself and that thermal pollution can harm aquatic life. But the sewer heat system will actually cool the wastewater. CAVANAUGH: That's correct. We're removing thermal energy. And so that'll help us move towards our goals of reducing the temperature in our effluent. BRASCH: So to recap, the project will cut carbon emissions and improve river health. It's a win-win. So what's making this possible now? Shanti Pless is with the National Renewable Energy Laboratory. And he says one reason is improvements to heat pumps, which are basically reversible air conditioners. SHANTI PLESS: With the advent of large-scale heat pumps, we can now cost effectively, you know, use, you know, say, 70-degree wastewater to heat our buildings and our hot water systems. BRASCH: Pless says the technology is opening up a whole new world of renewable heat mining. But those systems tend to work best for whole neighborhoods or districts, not individual homes or buildings. He says the Denver project could prove the upfront investment is worth it. PLESS: The National Western project has been a great local example for us to take that idea to the to the rest of the country. BRASCH: But the people behind the project also worry it could trigger a kind of sewer heat gold rush. Brad Buchanan is the CEO of the National Western Center. And he says his plans for the campus came together. BRAD BUCHANAN: We have to answer the question, how do we protect these sewer thermal energy rights? BRASCH: The result was an agreement guaranteeing the campus exclusive access to energy inside nearby sewer pipes. Buchanan says that has him thinking about the whole future of real estate. BUCHANAN: If folks sort of start to look at not just where light rail lines are located or good schools are located, but what's the proximity to a large sanitary sewer line running through Denver somewhere? BRASCH: Because if you choose the right place, a wealth of sewer heat could be all yours. For NPR News, I'm Sam Brasch in Denver. (SOUNDBITE OF MUSIC)", "section": "Environment And Energy Collaborative", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-05-21-998859506": {"title": "Apple CEO Tim Cook Is Taking The Witness Stand Friday. Here's Why It's A Big Deal  : NPR", "url": "https://www.npr.org/2021/05/21/998859506/apple-ceo-tim-cook-is-taking-the-witness-stand-friday-heres-why-its-a-big-deal", "author": "No author found", "published_date": "2021-05-21", "content": "", "section": "Technology", "disclaimer": ""}, "2021-05-22-999302007": {"title": "Clubhouse Becomes A Meeting Place For Israelis And Palestinians : NPR", "url": "https://www.npr.org/2021/05/22/999302007/clubhouse-becomes-an-emotional-meeting-place-for-israelis-and-palestinians", "author": "No author found", "published_date": "2021-05-22", "content": "", "section": "Middle East", "disclaimer": ""}, "2021-05-22-999343673": {"title": "Internet Explorer is dead : NPR", "url": "https://www.npr.org/2021/05/22/999343673/internet-explorer-the-love-to-hate-it-web-browser-will-die-next-year", "author": "No author found", "published_date": "2021-05-22", "content": "", "section": "Technology", "disclaimer": ""}, "2021-05-22-998549000": {"title": "Interview: 'Version Zero' Author David Yoon : NPR", "url": "https://www.npr.org/2021/05/22/998549000/in-david-yoons-new-novel-resetting-the-internet-to-version-zero", "author": "No author found", "published_date": "2021-05-22", "content": "SCOTT SIMON, HOST:  Everybody jokes about just doing away with the internet after some data hack, service outage or other frustration reveals how much of our lives revolve around it. As David Yoon writes in his new novel of a fictitious platform called Wren - and only the name may be fictitious - quote, \"everyone loved it, everyone hated it. People used it for news, for gossip, social plans, dining tips, political views, dating, shopping, driving directions, blah, blah, blah. The people could not stop themselves. They said they were addicted. \"\"Version Zero\" is the story of tech workers who disrupt - and don't high-tech wizards love that word? - the internet with unforeseen consequences. It is David Yoon's first novel for adult readers. His YA novel, \"Frankly In Love,\" was a bestseller. He joins us now. Thanks so much for being with us. DAVID YOON: Thanks for having me. SIMON: Before you became a writer, you knew this tech world, didn't you? YOON: I did. I worked in tech for something like over a dozen years, first as a web designer in the early days of the internet and then as a user experience expert. And I would design not just the interfaces that you would push buttons and scroll around in but also how to get customers on board and how to make them do the things that the business wanted them to do, as opposed to what the users themselves wanted to do. So there was a lot of psychological considerations in my job. SIMON: Max, your principal character, begins to work on something called the Soul Project, and he gets chilled by something he learns, doesn't he? We don't have to give it away, but, boy, it's chilly. Yeah. YOON: Yeah. So, I mean, Max is the hero of the story. He's this brilliant, sort of idealistic 20-something tech want-repreneur (ph). He really wants to be, like, the next Steve Jobs. And he believes that tech can make the world a better place. And he works for this fictitious company, Wren. He discovers that they're doing some pretty shady stuff with user data, like selling it to spooks and spy agencies. And he blows the whistle. And what happens is he probably gets fired and then blacklisted from the entire industry that he, you know, idolizes. So he has this massive, you know, crisis of faith, and he has to sit there and figure out what to do with his life. And what he wants to do is exact revenge on the people that shut him out of the tech industry that he so loved. SIMON: Wren isn't exactly an outlier of a company, is it? YOON: (Laughter) It's a barely thinly veiled sort of version of Facebook smashed with Twitter smashed with Instagram. So, yeah, it should feel really familiar. SIMON: Yeah, no, absolutely. Now, another point your novel seems to keep returning to is that technology makes an awful lot of money while producing nothing. Is that a fair way of putting it? YOON: It kind of is. I mean, it's - technology - and I'm paraphrasing the novelist Ted Chiang, who I just kind of worship. He says that technology and capitalism are so intertwined that it becomes hard to separate the two. And in my mind, technology is almost like a pure form of capitalism because it's up in this cloud and it scales infinitely and you can have billions of users, and it seems endless and infinite. And when you sort of reach that level of abstraction, you know, you're not selling anything. You're selling - what? - engagement? Eyeballs and impressions? These are not tangible things. SIMON: A point that your your novel also makes, of course, is that it's pretty much impossible not to be online somehow these days - isn't it? - including our conversation here. YOON: Right, yeah, exactly. SIMON: Let's state for the record Facebook and Zoom are among NPR's funders. YOON: (Laughter) Yeah. I mean, modern sort of American capitalist life has always been mediated by these huge companies. Like, we used to be afraid of the credit card companies and the phone companies back in the day. The image that we used to have was, like, banks of thousands of employees just dutifully sort of writing down what you were saying. It's kind of funny. Now that we have AI voice recognition technology and auto transcription, that image becomes much smaller. It could probably fit on your phone. And the fact that, like, increasingly all of your not just business communications, but your friendships and your dating, like, stuff that really matters, is being mediated through these giant companies. It really should give us a little bit of pause, at least, to wonder why do we need so much technology and so much infrastructure simply to be friends with someone? SIMON: There's a line that chilled me that I wrote down that you wrote. I think it's Max who says, when we stop looking at one another in the eyes, bad things happen. YOON: That was sort of another thing that, I mean, working in the tech industry and something that Max realizes is when you build a system for normal human beings that is not really compatible with our normal human instincts, which is small groups, intimate eye contact, being in a room together, when you take away that identity and make a hugely anonymous system - think about driving your car, for instance. You take millions of people and you turn them into vehicles, and they stop being people and you wind up with things like road rage. You don't wind up with things like, you know, supermarket aisle rage very much. And so the internet is kind of like the same effect but on a much larger scale. It becomes much easier for one bad actor to, under an anonymous profile, have an outsized influence on a lot of people. I mean, look at - Q is a perfect example of that, how big an effect one person can have, for better or worse. SIMON: What's the challenge of writing for adults? YOON: Adults, I think, are more interested in exploring things that are unsettled. You know, in YA, I think for the most part, educators and librarians who are the people who buy these books, buy YA, are looking for teachable moments that they can present to their students and say, this is what we learned about racism recently. This is what we learned about, you know, anything in humanity. And so they deal with kind of the known and the teachable, and the adult world kind of deals with the unknown and the unteachable, the unresolved. And the internet, in my mind, is very much unresolved. It's this huge thing that we built sort of not in response to a particular problem, per se, apart from provide a distributed network that was immune from attack during a Cold War situation. But beyond that, it wasn't really built to solve any particular problem. It's created a bunch of problems. It's made a bunch of wonderful things, too. But in my mind, the jury is still out on has it all been worth it? SIMON: David Yoon - his novel, his first for adults, \"Version Zero. \" Thank you so much for being with us. YOON: Thanks for having me. It was a pleasure. SCOTT SIMON, HOST:   Everybody jokes about just doing away with the internet after some data hack, service outage or other frustration reveals how much of our lives revolve around it. As David Yoon writes in his new novel of a fictitious platform called Wren - and only the name may be fictitious - quote, \"everyone loved it, everyone hated it. People used it for news, for gossip, social plans, dining tips, political views, dating, shopping, driving directions, blah, blah, blah. The people could not stop themselves. They said they were addicted. \" \"Version Zero\" is the story of tech workers who disrupt - and don't high-tech wizards love that word? - the internet with unforeseen consequences. It is David Yoon's first novel for adult readers. His YA novel, \"Frankly In Love,\" was a bestseller. He joins us now. Thanks so much for being with us. DAVID YOON: Thanks for having me. SIMON: Before you became a writer, you knew this tech world, didn't you? YOON: I did. I worked in tech for something like over a dozen years, first as a web designer in the early days of the internet and then as a user experience expert. And I would design not just the interfaces that you would push buttons and scroll around in but also how to get customers on board and how to make them do the things that the business wanted them to do, as opposed to what the users themselves wanted to do. So there was a lot of psychological considerations in my job. SIMON: Max, your principal character, begins to work on something called the Soul Project, and he gets chilled by something he learns, doesn't he? We don't have to give it away, but, boy, it's chilly. Yeah. YOON: Yeah. So, I mean, Max is the hero of the story. He's this brilliant, sort of idealistic 20-something tech want-repreneur (ph). He really wants to be, like, the next Steve Jobs. And he believes that tech can make the world a better place. And he works for this fictitious company, Wren. He discovers that they're doing some pretty shady stuff with user data, like selling it to spooks and spy agencies. And he blows the whistle. And what happens is he probably gets fired and then blacklisted from the entire industry that he, you know, idolizes. So he has this massive, you know, crisis of faith, and he has to sit there and figure out what to do with his life. And what he wants to do is exact revenge on the people that shut him out of the tech industry that he so loved. SIMON: Wren isn't exactly an outlier of a company, is it? YOON: (Laughter) It's a barely thinly veiled sort of version of Facebook smashed with Twitter smashed with Instagram. So, yeah, it should feel really familiar. SIMON: Yeah, no, absolutely. Now, another point your novel seems to keep returning to is that technology makes an awful lot of money while producing nothing. Is that a fair way of putting it? YOON: It kind of is. I mean, it's - technology - and I'm paraphrasing the novelist Ted Chiang, who I just kind of worship. He says that technology and capitalism are so intertwined that it becomes hard to separate the two. And in my mind, technology is almost like a pure form of capitalism because it's up in this cloud and it scales infinitely and you can have billions of users, and it seems endless and infinite. And when you sort of reach that level of abstraction, you know, you're not selling anything. You're selling - what? - engagement? Eyeballs and impressions? These are not tangible things. SIMON: A point that your your novel also makes, of course, is that it's pretty much impossible not to be online somehow these days - isn't it? - including our conversation here. YOON: Right, yeah, exactly. SIMON: Let's state for the record Facebook and Zoom are among NPR's funders. YOON: (Laughter) Yeah. I mean, modern sort of American capitalist life has always been mediated by these huge companies. Like, we used to be afraid of the credit card companies and the phone companies back in the day. The image that we used to have was, like, banks of thousands of employees just dutifully sort of writing down what you were saying. It's kind of funny. Now that we have AI voice recognition technology and auto transcription, that image becomes much smaller. It could probably fit on your phone. And the fact that, like, increasingly all of your not just business communications, but your friendships and your dating, like, stuff that really matters, is being mediated through these giant companies. It really should give us a little bit of pause, at least, to wonder why do we need so much technology and so much infrastructure simply to be friends with someone? SIMON: There's a line that chilled me that I wrote down that you wrote. I think it's Max who says, when we stop looking at one another in the eyes, bad things happen. YOON: That was sort of another thing that, I mean, working in the tech industry and something that Max realizes is when you build a system for normal human beings that is not really compatible with our normal human instincts, which is small groups, intimate eye contact, being in a room together, when you take away that identity and make a hugely anonymous system - think about driving your car, for instance. You take millions of people and you turn them into vehicles, and they stop being people and you wind up with things like road rage. You don't wind up with things like, you know, supermarket aisle rage very much. And so the internet is kind of like the same effect but on a much larger scale. It becomes much easier for one bad actor to, under an anonymous profile, have an outsized influence on a lot of people. I mean, look at - Q is a perfect example of that, how big an effect one person can have, for better or worse. SIMON: What's the challenge of writing for adults? YOON: Adults, I think, are more interested in exploring things that are unsettled. You know, in YA, I think for the most part, educators and librarians who are the people who buy these books, buy YA, are looking for teachable moments that they can present to their students and say, this is what we learned about racism recently. This is what we learned about, you know, anything in humanity. And so they deal with kind of the known and the teachable, and the adult world kind of deals with the unknown and the unteachable, the unresolved. And the internet, in my mind, is very much unresolved. It's this huge thing that we built sort of not in response to a particular problem, per se, apart from provide a distributed network that was immune from attack during a Cold War situation. But beyond that, it wasn't really built to solve any particular problem. It's created a bunch of problems. It's made a bunch of wonderful things, too. But in my mind, the jury is still out on has it all been worth it? SIMON: David Yoon - his novel, his first for adults, \"Version Zero. \" Thank you so much for being with us. YOON: Thanks for having me. It was a pleasure.", "section": "Author Interviews", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-05-23-999144297": {"title": "What The Rise Of Amazon Has To Do With The Rise Of Trump : NPR", "url": "https://www.npr.org/2021/05/23/999144297/what-the-rise-of-amazon-has-to-do-with-the-rise-of-trump", "author": "No author found", "published_date": "2021-05-23", "content": "", "section": "Politics", "disclaimer": ""}, "2021-05-25-1000251909": {"title": "D.C. Sues Amazon, Accusing It Of Inflating Prices And Abusing Its Monopoly : NPR", "url": "https://www.npr.org/2021/05/25/1000251909/d-c-sues-amazon-accusing-it-of-inflating-prices-and-abusing-its-monopoly", "author": "No author found", "published_date": "2021-05-25", "content": "", "section": "Business", "disclaimer": ""}, "2021-05-26-1000529597": {"title": "Recommendation systems are increasingly determining what we like and dislike : Planet Money : NPR", "url": "https://www.npr.org/2021/05/26/1000529597/runaway-recommendation-engine", "author": "No author found", "published_date": "2021-05-26", "content": "SYLVIE DOUGLIS, BYLINE: This is PLANET MONEY from NPR. (SOUNDBITE OF COIN SPINNING)KEVIN ROOSE: There's a person who I'm pretty sure helped make the modern internet so addictive. But it was kind of an accident, and I'm not even sure he knows it yet. His name is Doug Terry. DOUG TERRY: I'm a distinguished scientist at Amazon. MARY CHILDS, HOST:  Oh, wow, a distinguished scientist. TERRY: (Laughter). CHILDS: Do we call you Distinguished Doug? TERRY: It's actually - Distinguished Doctor Doug is what people call me. ROOSE: Distinguished Doctor Doug is an engineer, an inventor. CHILDS: What's the thing that you're proudest of that you've invented ever? TERRY: The thing that I'm. . . CHILDS: Unless it's a state secret. TERRY: (Laughter) Well, there's this thing called the domain name system, all these little names that you type in these days with dots on it, you know, amazon. com. CHILDS: You did that? TERRY: That was my PhD dissertation, was designing that, yeah. CHILDS: In 1990, Doug was a researcher at this utopia called Xerox PARC, this Disneyland of computer inventions that would give the world such hits as the personal computer, Ethernet, laser jet printing. Doug says their inventions were often just solutions to things that annoyed them. ROOSE: Right, which for Doug was his email. Back then, email didn't really have rules yet or etiquette. Doug's inbox every day was just full of chain letters and meeting-scheduling threads and message board posts and reply-alls and people just spamming each other with random links. It was chaos. TERRY: And so people were getting, you know, hundreds of email messages per day, which by today's standards maybe isn't that much, but at the time it seemed like a lot to be spending an hour of my day reading email. CHILDS: A whole hour. TERRY: (Laughter). ROOSE: Right. I know, right? Let's trade. I want to go back to an hour of email a day. CHILDS: Seriously. ROOSE: Doug's inbox, like everybody's inbox, just displayed emails in the order they were received. And you could do some simple kinds of filtering, like send all emails from that super annoying co-worker directly to the trash. But there wasn't a really good way to do other more subtle kinds of filtering - filtering that required a little more judgment. TERRY: And that's where I came up with this idea of saying, you know, let's figure out how to make humans part of the system. CHILDS: Taking human likes and dislikes and turning them into a recommendation system - that was Doug and his team's invention. It was just for them and some of their colleagues to clean up their inboxes, but their solution would eventually come to define the modern internet. ROOSE: Doug's invention - this thing that he created to manage his inbox - was the first real recommendation engine. And today, the entire world runs on recommendation engines. Billions of dollars a year are spent and lost based on what is and isn't recommended to us. They determine everything that shows up on our Instagram feeds, our TikTok For You pages, our Twitter timelines. They determine what we watch or listen to, maybe which politicians we vote for. They tell us what we like and what we hate. (SOUNDBITE OF MUSIC)ROOSE: Hello, and welcome to PLANET MONEY. I'm Kevin Roose, New York Times tech columnist. CHILDS: And I'm Mary Childs. And, Kevin, you wrote this fantastic book, \"Futureproof: 9 Rules For Humans In The Age Of Automation,\" which is how I learned about Doug and the world of recommendation algorithms. Your book is so good, Kevin. I love it. I read it every day. ROOSE: Thank you for recommending it. Today on the show, how Doug's mission to build a better email inbox kind of created the world as we know it and not only changed what we watch on TV and what music we listen to, but really changed us - all of us - at a really fundamental level. (SOUNDBITE OF MUSIC)CHILDS: Distinguished Doctor Doug and his team are about to do this world-changing thing. They're going to start with fixing their email inboxes, and in doing so, they will teach machines how to fake making value judgments, how to curate, how to determine importance. ROOSE: Because the problem as he saw it wasn't actually that people were getting too many emails. Like, that was bad, but the bigger problem was that all the emails looked the same. TERRY: An email message from my boss saying, I need a response in five minutes, is much more important than, you know, a message forwarded from a friend of mine saying, did you see the baseball game last night? CHILDS: Doug's inbox was organized by chronology, but he doesn't want chronology. He wants priority. So he starts to teach his inbox what was important. Emails from one person to just one other person - important. Send it to the top of the inbox. Emails to a bunch of people - eh, bottom of the list, maybe straight to the trash. ROOSE: You need sort of, like, the bouncer at the velvet rope. . . TERRY: (Laughter). ROOSE: . . . Over your inbox saying, like, you can come in. . . CHILDS: (Laughter). ROOSE: . . . But you look like trouble. TERRY: Well, yeah, but not only the bouncer, but a personal bouncer - right? - someone who knows me personally and knows what - you know, the people I want to let in and the people I don't want to let in. ROOSE: So he and a group of co-workers build this filtering program, and his inbox actually gets a little cleaner. His boss's emails are surfacing properly. CHILDS: Their next step is to add another layer from a totally different approach, one that draws on the infinitely complicated and ever-changing human user. How do you talk to your bouncer and say, hey, man, not so many today, or, like, listen. You let somebody in last week who was a real scoundrel. I don't want that to happen again. TERRY: Well, it had - I introduced \"like-it\" and \"hate-it\" buttons. So now on Facebook you always see \"like-it\" buttons or \"like\" buttons and so on. The system I built was the first one that had a \"like-it\" button, and it also had a \"hate-it\" button. ROOSE: Wait, you invented. . . CHILDS: You invented the \"like\" button? ROOSE: You invented the \"like\" button and the domain name? TERRY: (Laughter). CHILDS: We are in the presence of greatness. TERRY: (Laughter). CHILDS: So Doug is happily hitting \"like\" and \"hate\" on his emails, and it's working. His inbox is even better. So he invites some of his co-workers to try out their little inbox filter, too. And they start hitting \"like\" and \"hate\" on their emails, too, which leads Doug and his colleagues to their next real big insight. Doug didn't need to rate every single email because his colleagues were doing it, too, with essentially the same emails. ROOSE: This right here is the insight that will change the internet forever, that Doug's colleagues \"likes\" and \"hates\" could act as a filter on his inbox. He called this collaborative filtering. ROOSE: The whole point of collaborative filtering is, I would say I liked or hated something, and then that would help other people because that's the community aspect. Then other people could say, oh, show me articles sent to this newsgroup on baseball that Doug \"liked,\" or don't send me anything that Doug didn't \"like. \"ROOSE: Doug and his colleagues built an email system that sorted people's inboxes. It recommended the emails they should look at first by using this collaborative filtering idea, and it kind of worked. He says his email time got cut down from an hour a day down to 30 minutes a day. It improved his life and the lives and inboxes of his Xerox PARC co-workers. CHILDS: And because it was at Xerox PARC, which is where the architecture of the computer age was drafted, their collaborative filtering invention becomes part of the canon, a tool for every other engineer who comes after. ROOSE: And that's what the next part of this show is about - taking Doug's invention and scaling it to billions of people, attaching it to superpowered artificial intelligence and using it to bring order to this chaotic world of online information. CHILDS: The modern era of collaborative filtering started 16 years after Doug and his team's invention in 2006. It started because this big company, Netflix, had a problem-tunity (ph). If people couldn't find something they wanted to rent, they were more likely to cancel their subscription. If Netflix hooked them with a really good recommendation right away, they were happier. They would consume more. So anything that made those recommendations more precise and appealing to users - that was money. ROOSE: Netflix, at the time, was using a descendant of Doug's collaborative filtering idea as the basis for their recommendation system, which drove 60% of rentals. But its recommendation system had plateaued. It wasn't improving. CHILDS: Here's Robert Bell - Bob - he is also a distinguished computer scientist - talking about Netflix's problem. (SOUNDBITE OF ARCHIVED RECORDING)BOB BELL: And so they had some ideas for how to improve those recommendations, but they weren't quite sure how to do it. And so they came up with the idea of a contest. CHILDS: This is from a talk Bob gave about entering this Netflix contest. (SOUNDBITE OF ARCHIVED RECORDING)BELL: And to show that they were really serious about this, the idea was to release data to people. And they offered a million-dollar prize. CHILDS: A million dollars - they called it, very creatively, the Netflix Prize. ROOSE: (Laughter) And to win, you had to improve Netflix's recommendations by at least 10% to make better predictions than Netflix had about what people on its service would watch and like. And to help, Netflix published all of its data of all customers' anonymized ratings of movies and TV shows and whatever else - more than 100 million ratings in all from 480,000 customers. CHILDS: 100 million ratings - that was a ton of data, way more than anyone had had access to before, big enough that engineers could actually play with it, which made it the most exciting thing to happen in data science since ever. Almost 50,000 teams downloaded the data, including Bob. ROOSE: He downloads his data, and he starts digging in. BELL: And the surprise for everybody, I think, is that the most-rated movie during this period was \"Miss Congeniality. \" That was rated by almost half of the users. CHILDS: Bob and his team set out to make a better recommendation system. He starts with the obvious part of collaborative filtering - the part Netflix was already doing - basically matching up people with similar tastes. Like, oh, you liked \"Miss Congeniality. \" Well, we know that people who like \"Miss Congeniality\" often tend to like \"Legally Blonde. \" So maybe you should watch that. But this system couldn't take into account how weird people are and how weird movies are. BELL: Movies are very complex things and humans are even more complex. And so what we see in a movie that we like or dislike is very hard to characterize in just a handful of factors. And so in some sense, in order to model all of that, you almost need an unlimited number of factors that you might consider. CHILDS: The original collaborative filtering required users to tell the algorithm, hey, I like what this guy likes, thumbs up, or thumbs down. Bob and his team took this idea further. They realized that machines could figure out people's tastes on their own by grouping movies together and teasing out what they had in common based on factors that you couldn't just see or guess. ROOSE: Right. Like, I no longer had to say, hey, I liked \"The Pelican Brief\" and \"Erin Brockovich. \" Please find me other movies to watch. Now the machine can actually sniff out, on its own, these hidden threads between the movies I watched. Like, maybe it's suspenseful legal thrillers, or maybe its depth of character development, or maybe it's something that only the machine sees. CHILDS: Bob and his team looked at data that was explicit, like ratings, and implicit. Like, the data point that helped them the most was whether you had rated something at all. BELL: If we're trying to figure out whether you'd like a science fiction movie, if you've rated other science fiction movies, even if you didn't rate them real high, that sort of says that you least have some interest in science fiction. CHILDS: Using that factor got them to a 5% improvement over what Netflix was already doing, which meant Bob and his team were halfway to the prize already. From there, they added layer and layer and layer of different factors until they did it. They crossed the 10% improvement threshold. Bob and his team won the Netflix prize and the million dollars. ROOSE: People who work on recommendation algorithms told me that this Netflix prize ended up being this huge moment in their field, that this thrillingly large data set that got all these brilliant engineers excited about building recommendation engines basically started a recommendation revolution. And this is when lots of other tech companies started realizing that recommendations could be used for so much more than just movies. They could help us figure out which music to listen to, which clothes to wear, which restaurants to patronize, maybe even which news was important. CHILDS: And for a long time, people were mostly focused on building these cool new exciting algorithms. Scientists were stoked to see what they could do. And most users were like, oh, great, I really am interested in this. Thank you. But there's obviously another side to this, which is when do these suggestions stop being helpful nudges towards something I would get to eventually and start becoming programming? That's after the break. (SOUNDBITE OF MUSIC)CHILDS: In the world of recommendation algorithms, there's this team of researchers who've been studying the code and the systems and their effects on us to find out if in addition to guiding us to our preferences these programs can actually change our preferences. JINGJING ZHANG: My name is Jingjing Zhang. And my work - I look at how all our recommendations affect our decision-making. CHILDS: So you would really think that Jingjing would be better than the average person at not getting sucked into a vortex of addictive stuff. ZHANG: In my personal life, if I go to YouTube and then search for certain videos, they would have related videos. I thought, oh, these must be highly relevant to what I'm looking for now. So I will consume more and more and then spend more time than I expected (laughter) on YouTube or some other websites. ROOSE: I can definitely relate. And to figure out if recommendation systems are changing us, Jingjing and her team created a series of experiments using college students, basically fiddling with recommendations and seeing how those recommendations affected the students' behavior. CHILDS: And in one of those experiments, they were trying to gauge just how much of an effect these algorithms have on us, how powerful the power of robot suggestion is. So they chose something consumable but perfectly subjective - music. ZHANG: What we did is that we took the top 100 songs from this annual Billboard list, and then we provide different recommendation for these songs. CHILDS: The recommendations, which were on a five-star system, were manipulated, tweaked up or down. But the researchers told the students that the ratings were perfectly tailored to them. The students had to listen to the whole song and then say if they wanted to buy it, and if so, how much they would pay. And this is a great way to design an experiment, by the way, because it relies on something that economists call revealed preference theory, which basically holds that if you want to figure out what someone actually likes, look at what they actually pay for. ROOSE: And, like, Jingjing and her team are pretty sure that forcing students to actually listen to these songs would negate the impact of the recommendations. The students would form their own opinions and ignore the star ratings. You're not going to let an algorithm boss you around, right? ZHANG: What we found is that on average for each one-star manipulation, that's going to increase the willingness to pay per price by the 7% to 17%. CHILDS: The students offered significantly more money for higher-rated songs, even when those ratings were totally manipulated. Jingjing tested this and retested this. And the results were clear. When a machine tells us that we're going to like something, we trust the machine more than ourselves. ROOSE: And, like, look, recommendations aren't all bad. Sometimes they're great. They save us time. They help us avoid decision fatigue. Sometimes I just don't want to, like, manually curate my own playlists of vibey electronic music. But here's what I worry about. These recommendation systems are getting so good that if we aren't vigilant, we're just going to end up drifting toward whatever the machine tells us we like. CHILDS: This isn't just a problem of human psychology. It's also a computer science problem. Jingjing says it becomes a feedback loop. Those little drifts add up. ZHANG: Over time, this will make the system less effective, less accurate and provide less diverse recommendations. Eventually, I know this longitudinal impact on the system will make the system provide similar items to everybody, like, regardless of personal test. CHILDS: Which, knowing the history, knowing how all of this got started, this is so far from the original goal. We built - or, OK, Doug built these machines to save us time and help us find what we want. ROOSE: Now, instead of Doug's friends and colleagues all helpfully filtering each other's emails, it's just these giant opaque algorithms owned by companies that want to make a profit off our behavior recommending things that will keep us scrolling and clicking and watching forever and ever. Do you ever feel like you contributed to something that is not entirely good for society? TERRY: I hope not. So I - up until this point - thanks, Kevin - I hadn't really felt that way. CHILDS: And to be fair to Doug and his team, this is not actually what they built. They built an algorithm designed to read their minds. There is a huge difference between an algorithm built to read your mind and an algorithm designed to lead your mind, to take you to some new destination that you maybe wouldn't have arrived at yourself. ROOSE: Right. Like, there's always been advertising - billboards and magazine spreads and TV ads - and you could see those things and decide, like, no, I don't like those shoes, not for me. But now, we've got these machines telling us, like, no, no, no. You do like those shoes. They are perfectly selected for you. Trust us on this one because we know you better than you know yourself. And sometimes, that might be true. But it's not always true. And so now, the question for all of us is which of our preferences are actually ours, and which were put there by a machine? (SOUNDBITE OF MUSIC)CHILDS: If you know anyone who inadvertently changed the course of history and there's a great story behind it, let us know. Send us an email - planetmoney@npr. org. We're also on all the social media things influencing your choices. This week on TikTok, we explore the idea that you can only be friends with about 150 people. Today's show was produced by Dan Girma with help from Emma Peaslee, mastered by Gilly Moon and edited by Nick Fountain. PLANET MONEY's supervising producer is Alex Goldmark. Thank you also to Jesse Bockstedt (ph) and Cami Rothe (ph). Here's a decision I am not influencing you to make. Kevin has that new book out. This is basically a chapter from it - \"Futureproof: Nine Rules For\" - Kevin, what is it again? ROOSE: \"Nine Rules For Humans In The Age Of Automation. \"CHILDS: . . . \"Humans In The Age Of Automation\" - stunning, beautiful, resist that machine drift. ROOSE: Thank you for that very human, non-algorithmic recommendation. CHILDS: (Laughter) I have not been manipulated. OK, Kevin, say your name. ROOSE: I'm Kevin Roose. CHILDS: And I'm Mary Childs. This is NPR. Thanks for listening. (SOUNDBITE OF MUSIC) SYLVIE DOUGLIS, BYLINE: This is PLANET MONEY from NPR. (SOUNDBITE OF COIN SPINNING) KEVIN ROOSE: There's a person who I'm pretty sure helped make the modern internet so addictive. But it was kind of an accident, and I'm not even sure he knows it yet. His name is Doug Terry. DOUG TERRY: I'm a distinguished scientist at Amazon. MARY CHILDS, HOST:   Oh, wow, a distinguished scientist. TERRY: (Laughter). CHILDS: Do we call you Distinguished Doug? TERRY: It's actually - Distinguished Doctor Doug is what people call me. ROOSE: Distinguished Doctor Doug is an engineer, an inventor. CHILDS: What's the thing that you're proudest of that you've invented ever? TERRY: The thing that I'm. . . CHILDS: Unless it's a state secret. TERRY: (Laughter) Well, there's this thing called the domain name system, all these little names that you type in these days with dots on it, you know, amazon. com. CHILDS: You did that? TERRY: That was my PhD dissertation, was designing that, yeah. CHILDS: In 1990, Doug was a researcher at this utopia called Xerox PARC, this Disneyland of computer inventions that would give the world such hits as the personal computer, Ethernet, laser jet printing. Doug says their inventions were often just solutions to things that annoyed them. ROOSE: Right, which for Doug was his email. Back then, email didn't really have rules yet or etiquette. Doug's inbox every day was just full of chain letters and meeting-scheduling threads and message board posts and reply-alls and people just spamming each other with random links. It was chaos. TERRY: And so people were getting, you know, hundreds of email messages per day, which by today's standards maybe isn't that much, but at the time it seemed like a lot to be spending an hour of my day reading email. CHILDS: A whole hour. TERRY: (Laughter). ROOSE: Right. I know, right? Let's trade. I want to go back to an hour of email a day. CHILDS: Seriously. ROOSE: Doug's inbox, like everybody's inbox, just displayed emails in the order they were received. And you could do some simple kinds of filtering, like send all emails from that super annoying co-worker directly to the trash. But there wasn't a really good way to do other more subtle kinds of filtering - filtering that required a little more judgment. TERRY: And that's where I came up with this idea of saying, you know, let's figure out how to make humans part of the system. CHILDS: Taking human likes and dislikes and turning them into a recommendation system - that was Doug and his team's invention. It was just for them and some of their colleagues to clean up their inboxes, but their solution would eventually come to define the modern internet. ROOSE: Doug's invention - this thing that he created to manage his inbox - was the first real recommendation engine. And today, the entire world runs on recommendation engines. Billions of dollars a year are spent and lost based on what is and isn't recommended to us. They determine everything that shows up on our Instagram feeds, our TikTok For You pages, our Twitter timelines. They determine what we watch or listen to, maybe which politicians we vote for. They tell us what we like and what we hate. (SOUNDBITE OF MUSIC) ROOSE: Hello, and welcome to PLANET MONEY. I'm Kevin Roose, New York Times tech columnist. CHILDS: And I'm Mary Childs. And, Kevin, you wrote this fantastic book, \"Futureproof: 9 Rules For Humans In The Age Of Automation,\" which is how I learned about Doug and the world of recommendation algorithms. Your book is so good, Kevin. I love it. I read it every day. ROOSE: Thank you for recommending it. Today on the show, how Doug's mission to build a better email inbox kind of created the world as we know it and not only changed what we watch on TV and what music we listen to, but really changed us - all of us - at a really fundamental level. (SOUNDBITE OF MUSIC) CHILDS: Distinguished Doctor Doug and his team are about to do this world-changing thing. They're going to start with fixing their email inboxes, and in doing so, they will teach machines how to fake making value judgments, how to curate, how to determine importance. ROOSE: Because the problem as he saw it wasn't actually that people were getting too many emails. Like, that was bad, but the bigger problem was that all the emails looked the same. TERRY: An email message from my boss saying, I need a response in five minutes, is much more important than, you know, a message forwarded from a friend of mine saying, did you see the baseball game last night? CHILDS: Doug's inbox was organized by chronology, but he doesn't want chronology. He wants priority. So he starts to teach his inbox what was important. Emails from one person to just one other person - important. Send it to the top of the inbox. Emails to a bunch of people - eh, bottom of the list, maybe straight to the trash. ROOSE: You need sort of, like, the bouncer at the velvet rope. . . TERRY: (Laughter). ROOSE: . . . Over your inbox saying, like, you can come in. . . CHILDS: (Laughter). ROOSE: . . . But you look like trouble. TERRY: Well, yeah, but not only the bouncer, but a personal bouncer - right? - someone who knows me personally and knows what - you know, the people I want to let in and the people I don't want to let in. ROOSE: So he and a group of co-workers build this filtering program, and his inbox actually gets a little cleaner. His boss's emails are surfacing properly. CHILDS: Their next step is to add another layer from a totally different approach, one that draws on the infinitely complicated and ever-changing human user. How do you talk to your bouncer and say, hey, man, not so many today, or, like, listen. You let somebody in last week who was a real scoundrel. I don't want that to happen again. TERRY: Well, it had - I introduced \"like-it\" and \"hate-it\" buttons. So now on Facebook you always see \"like-it\" buttons or \"like\" buttons and so on. The system I built was the first one that had a \"like-it\" button, and it also had a \"hate-it\" button. ROOSE: Wait, you invented. . . CHILDS: You invented the \"like\" button? ROOSE: You invented the \"like\" button and the domain name? TERRY: (Laughter). CHILDS: We are in the presence of greatness. TERRY: (Laughter). CHILDS: So Doug is happily hitting \"like\" and \"hate\" on his emails, and it's working. His inbox is even better. So he invites some of his co-workers to try out their little inbox filter, too. And they start hitting \"like\" and \"hate\" on their emails, too, which leads Doug and his colleagues to their next real big insight. Doug didn't need to rate every single email because his colleagues were doing it, too, with essentially the same emails. ROOSE: This right here is the insight that will change the internet forever, that Doug's colleagues \"likes\" and \"hates\" could act as a filter on his inbox. He called this collaborative filtering. ROOSE: The whole point of collaborative filtering is, I would say I liked or hated something, and then that would help other people because that's the community aspect. Then other people could say, oh, show me articles sent to this newsgroup on baseball that Doug \"liked,\" or don't send me anything that Doug didn't \"like. \" ROOSE: Doug and his colleagues built an email system that sorted people's inboxes. It recommended the emails they should look at first by using this collaborative filtering idea, and it kind of worked. He says his email time got cut down from an hour a day down to 30 minutes a day. It improved his life and the lives and inboxes of his Xerox PARC co-workers. CHILDS: And because it was at Xerox PARC, which is where the architecture of the computer age was drafted, their collaborative filtering invention becomes part of the canon, a tool for every other engineer who comes after. ROOSE: And that's what the next part of this show is about - taking Doug's invention and scaling it to billions of people, attaching it to superpowered artificial intelligence and using it to bring order to this chaotic world of online information. CHILDS: The modern era of collaborative filtering started 16 years after Doug and his team's invention in 2006. It started because this big company, Netflix, had a problem-tunity (ph). If people couldn't find something they wanted to rent, they were more likely to cancel their subscription. If Netflix hooked them with a really good recommendation right away, they were happier. They would consume more. So anything that made those recommendations more precise and appealing to users - that was money. ROOSE: Netflix, at the time, was using a descendant of Doug's collaborative filtering idea as the basis for their recommendation system, which drove 60% of rentals. But its recommendation system had plateaued. It wasn't improving. CHILDS: Here's Robert Bell - Bob - he is also a distinguished computer scientist - talking about Netflix's problem. (SOUNDBITE OF ARCHIVED RECORDING) BOB BELL: And so they had some ideas for how to improve those recommendations, but they weren't quite sure how to do it. And so they came up with the idea of a contest. CHILDS: This is from a talk Bob gave about entering this Netflix contest. (SOUNDBITE OF ARCHIVED RECORDING) BELL: And to show that they were really serious about this, the idea was to release data to people. And they offered a million-dollar prize. CHILDS: A million dollars - they called it, very creatively, the Netflix Prize. ROOSE: (Laughter) And to win, you had to improve Netflix's recommendations by at least 10% to make better predictions than Netflix had about what people on its service would watch and like. And to help, Netflix published all of its data of all customers' anonymized ratings of movies and TV shows and whatever else - more than 100 million ratings in all from 480,000 customers. CHILDS: 100 million ratings - that was a ton of data, way more than anyone had had access to before, big enough that engineers could actually play with it, which made it the most exciting thing to happen in data science since ever. Almost 50,000 teams downloaded the data, including Bob. ROOSE: He downloads his data, and he starts digging in. BELL: And the surprise for everybody, I think, is that the most-rated movie during this period was \"Miss Congeniality. \" That was rated by almost half of the users. CHILDS: Bob and his team set out to make a better recommendation system. He starts with the obvious part of collaborative filtering - the part Netflix was already doing - basically matching up people with similar tastes. Like, oh, you liked \"Miss Congeniality. \" Well, we know that people who like \"Miss Congeniality\" often tend to like \"Legally Blonde. \" So maybe you should watch that. But this system couldn't take into account how weird people are and how weird movies are. BELL: Movies are very complex things and humans are even more complex. And so what we see in a movie that we like or dislike is very hard to characterize in just a handful of factors. And so in some sense, in order to model all of that, you almost need an unlimited number of factors that you might consider. CHILDS: The original collaborative filtering required users to tell the algorithm, hey, I like what this guy likes, thumbs up, or thumbs down. Bob and his team took this idea further. They realized that machines could figure out people's tastes on their own by grouping movies together and teasing out what they had in common based on factors that you couldn't just see or guess. ROOSE: Right. Like, I no longer had to say, hey, I liked \"The Pelican Brief\" and \"Erin Brockovich. \" Please find me other movies to watch. Now the machine can actually sniff out, on its own, these hidden threads between the movies I watched. Like, maybe it's suspenseful legal thrillers, or maybe its depth of character development, or maybe it's something that only the machine sees. CHILDS: Bob and his team looked at data that was explicit, like ratings, and implicit. Like, the data point that helped them the most was whether you had rated something at all. BELL: If we're trying to figure out whether you'd like a science fiction movie, if you've rated other science fiction movies, even if you didn't rate them real high, that sort of says that you least have some interest in science fiction. CHILDS: Using that factor got them to a 5% improvement over what Netflix was already doing, which meant Bob and his team were halfway to the prize already. From there, they added layer and layer and layer of different factors until they did it. They crossed the 10% improvement threshold. Bob and his team won the Netflix prize and the million dollars. ROOSE: People who work on recommendation algorithms told me that this Netflix prize ended up being this huge moment in their field, that this thrillingly large data set that got all these brilliant engineers excited about building recommendation engines basically started a recommendation revolution. And this is when lots of other tech companies started realizing that recommendations could be used for so much more than just movies. They could help us figure out which music to listen to, which clothes to wear, which restaurants to patronize, maybe even which news was important. CHILDS: And for a long time, people were mostly focused on building these cool new exciting algorithms. Scientists were stoked to see what they could do. And most users were like, oh, great, I really am interested in this. Thank you. But there's obviously another side to this, which is when do these suggestions stop being helpful nudges towards something I would get to eventually and start becoming programming? That's after the break. (SOUNDBITE OF MUSIC) CHILDS: In the world of recommendation algorithms, there's this team of researchers who've been studying the code and the systems and their effects on us to find out if in addition to guiding us to our preferences these programs can actually change our preferences. JINGJING ZHANG: My name is Jingjing Zhang. And my work - I look at how all our recommendations affect our decision-making. CHILDS: So you would really think that Jingjing would be better than the average person at not getting sucked into a vortex of addictive stuff. ZHANG: In my personal life, if I go to YouTube and then search for certain videos, they would have related videos. I thought, oh, these must be highly relevant to what I'm looking for now. So I will consume more and more and then spend more time than I expected (laughter) on YouTube or some other websites. ROOSE: I can definitely relate. And to figure out if recommendation systems are changing us, Jingjing and her team created a series of experiments using college students, basically fiddling with recommendations and seeing how those recommendations affected the students' behavior. CHILDS: And in one of those experiments, they were trying to gauge just how much of an effect these algorithms have on us, how powerful the power of robot suggestion is. So they chose something consumable but perfectly subjective - music. ZHANG: What we did is that we took the top 100 songs from this annual Billboard list, and then we provide different recommendation for these songs. CHILDS: The recommendations, which were on a five-star system, were manipulated, tweaked up or down. But the researchers told the students that the ratings were perfectly tailored to them. The students had to listen to the whole song and then say if they wanted to buy it, and if so, how much they would pay. And this is a great way to design an experiment, by the way, because it relies on something that economists call revealed preference theory, which basically holds that if you want to figure out what someone actually likes, look at what they actually pay for. ROOSE: And, like, Jingjing and her team are pretty sure that forcing students to actually listen to these songs would negate the impact of the recommendations. The students would form their own opinions and ignore the star ratings. You're not going to let an algorithm boss you around, right? ZHANG: What we found is that on average for each one-star manipulation, that's going to increase the willingness to pay per price by the 7% to 17%. CHILDS: The students offered significantly more money for higher-rated songs, even when those ratings were totally manipulated. Jingjing tested this and retested this. And the results were clear. When a machine tells us that we're going to like something, we trust the machine more than ourselves. ROOSE: And, like, look, recommendations aren't all bad. Sometimes they're great. They save us time. They help us avoid decision fatigue. Sometimes I just don't want to, like, manually curate my own playlists of vibey electronic music. But here's what I worry about. These recommendation systems are getting so good that if we aren't vigilant, we're just going to end up drifting toward whatever the machine tells us we like. CHILDS: This isn't just a problem of human psychology. It's also a computer science problem. Jingjing says it becomes a feedback loop. Those little drifts add up. ZHANG: Over time, this will make the system less effective, less accurate and provide less diverse recommendations. Eventually, I know this longitudinal impact on the system will make the system provide similar items to everybody, like, regardless of personal test. CHILDS: Which, knowing the history, knowing how all of this got started, this is so far from the original goal. We built - or, OK, Doug built these machines to save us time and help us find what we want. ROOSE: Now, instead of Doug's friends and colleagues all helpfully filtering each other's emails, it's just these giant opaque algorithms owned by companies that want to make a profit off our behavior recommending things that will keep us scrolling and clicking and watching forever and ever. Do you ever feel like you contributed to something that is not entirely good for society? TERRY: I hope not. So I - up until this point - thanks, Kevin - I hadn't really felt that way. CHILDS: And to be fair to Doug and his team, this is not actually what they built. They built an algorithm designed to read their minds. There is a huge difference between an algorithm built to read your mind and an algorithm designed to lead your mind, to take you to some new destination that you maybe wouldn't have arrived at yourself. ROOSE: Right. Like, there's always been advertising - billboards and magazine spreads and TV ads - and you could see those things and decide, like, no, I don't like those shoes, not for me. But now, we've got these machines telling us, like, no, no, no. You do like those shoes. They are perfectly selected for you. Trust us on this one because we know you better than you know yourself. And sometimes, that might be true. But it's not always true. And so now, the question for all of us is which of our preferences are actually ours, and which were put there by a machine? (SOUNDBITE OF MUSIC) CHILDS: If you know anyone who inadvertently changed the course of history and there's a great story behind it, let us know. Send us an email - planetmoney@npr. org. We're also on all the social media things influencing your choices. This week on TikTok, we explore the idea that you can only be friends with about 150 people. Today's show was produced by Dan Girma with help from Emma Peaslee, mastered by Gilly Moon and edited by Nick Fountain. PLANET MONEY's supervising producer is Alex Goldmark. Thank you also to Jesse Bockstedt (ph) and Cami Rothe (ph). Here's a decision I am not influencing you to make. Kevin has that new book out. This is basically a chapter from it - \"Futureproof: Nine Rules For\" - Kevin, what is it again? ROOSE: \"Nine Rules For Humans In The Age Of Automation. \" CHILDS: . . . \"Humans In The Age Of Automation\" - stunning, beautiful, resist that machine drift. ROOSE: Thank you for that very human, non-algorithmic recommendation. CHILDS: (Laughter) I have not been manipulated. OK, Kevin, say your name. ROOSE: I'm Kevin Roose. CHILDS: And I'm Mary Childs. This is NPR. Thanks for listening. (SOUNDBITE OF MUSIC)", "section": "Runaway Recommendation Engine", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-05-26-1000390936": {"title": "Europe Wants Social Media Platforms To Do More To Stop Disinformation : NPR", "url": "https://www.npr.org/2021/05/26/1000390936/europe-wants-social-media-giants-to-do-more-to-stop-disinformation", "author": "No author found", "published_date": "2021-05-26", "content": "", "section": "Technology", "disclaimer": ""}, "2021-05-26-1000400943": {"title": "Pipeline Companies Will Need To Report Cyberattacks To U.S. : NPR", "url": "https://www.npr.org/2021/05/26/1000400943/homeland-security-expected-to-issue-1st-cybersecurity-regs-for-pipelines", "author": "No author found", "published_date": "2021-05-26", "content": "RACHEL MARTIN, HOST:  For the first time, the Department of Homeland Security has decided it needs to regulate cybersecurity in the pipeline industry. The Washington Post first reported this move, which means a new set of rules to safeguard pipeline companies against cyberattacks like the one that crippled the Colonial Pipeline earlier this month and forced it to shut down. That meant fuel shortages for days across the eastern part of the United States. We're going to turn now to Chris Krebs. He was the first director of the Cybersecurity and Infrastructure Security Agency at DHS when it was founded in 2018. He left the job in November of 2020. Chris, thanks so much for being back on the show. CHRIS KREBS: Thanks for having me on, Rachel. Good morning. MARTIN: Good morning. Why do pipelines need their own set of regulations? KREBS: Well, the operating conditions of pipeline is one of our critical infrastructures. They have some unique aspects, and given the way that the U. S. government divvies up the oversight and management of the various critical infrastructure sectors, pipelines, oddly enough, fall under the Transportation Security Administration. You might think, sounds like an Energy Department area. MARTIN: Right - instead of the people who are watching over the metal detectors at airports. KREBS: Yeah. Well, but ultimately, a pipeline is a mode of transportation, and there are multiple products that move through pipelines, including water and chemicals and gases. And so what you really think about is not the product that flows through the pipes, but it's the modality itself. It's the infrastructure itself. And TSA is uniquely situated to be helpful here. And so what you're seeing is, as you pointed out, the first security regulation from TSA over pipelines, and it's an incremental step, at least for the moment. MARTIN: So what's it going to change? KREBS: Well, for one, this specific directive - and the directive is focused. It's threat-oriented and likely be time limited, but it's going to require reporting of security incidents to TSA and to my old agency, CISA. And that's it. But there's additional authority that may take a little bit more time to develop where you may see things like security standards or baseline standards of performance for security measures. MARTIN: So this is primarily a reporting mechanism. Private companies then are going to have to disclose when they've been hacked to the federal government. Are they interested in revealing that information? KREBS: Well, that's the interesting thing, right? When you think back to the initial days of the Colonial Pipeline hack a couple weeks ago and my predecessor, the acting director, was in Congress, and he was asked questions about what you know, what don't you know. And ultimately, early on, there wasn't a lot of information available to the federal government because it's not required to report on incidents. And I think that's a key element that has to change across all of our critical infrastructures, not just pipelines. But these companies need to report to the government because if we don't really know how big the problem is, it's hard to make informed policy and operational decisions going forward. MARTIN: So these regulations are supposed to be mandatory. How do you enforce that? KREBS: Well, there are a number of different ways they can do that. First is just through the kind of the wag your finger and you engage them all the way up to security fines and shutdown of operations. These are the sorts of directives that TSA issues and implements all the time at airports - just recently, mask mandates on commercial air travel. So there's a regime in place. There are relationships with the pipeline sector, and now it's just a matter of getting it out there and helping these organizations understand who they need to talk to and how to do it. MARTIN: And you nodded to this earlier, but help us understand what comes from that information. So the federal government finds out about a particular hack, or now they have a bunch of data points about several hacks. What does that do to prevent them? KREBS: Well, I think one of the things that's important right now is that due to a lack of a mandatory reporting regime on ransomware specifically, we don't really understand how bad the problem is. And one of the things that I would greatly encourage is anyone that has a ransomware event notifies the government so that we - so the government can take action needed, including working with our foreign partners, as well as some of the countries that may be harboring these ransomware actors, so that we can put an end to this now. MARTIN: Chris Krebs, former director of the Cybersecurity and Infrastructure Security Agency at DHS, we appreciate you taking the time. Thank you. KREBS: Thanks a lot. RACHEL MARTIN, HOST:   For the first time, the Department of Homeland Security has decided it needs to regulate cybersecurity in the pipeline industry. The Washington Post first reported this move, which means a new set of rules to safeguard pipeline companies against cyberattacks like the one that crippled the Colonial Pipeline earlier this month and forced it to shut down. That meant fuel shortages for days across the eastern part of the United States. We're going to turn now to Chris Krebs. He was the first director of the Cybersecurity and Infrastructure Security Agency at DHS when it was founded in 2018. He left the job in November of 2020. Chris, thanks so much for being back on the show. CHRIS KREBS: Thanks for having me on, Rachel. Good morning. MARTIN: Good morning. Why do pipelines need their own set of regulations? KREBS: Well, the operating conditions of pipeline is one of our critical infrastructures. They have some unique aspects, and given the way that the U. S. government divvies up the oversight and management of the various critical infrastructure sectors, pipelines, oddly enough, fall under the Transportation Security Administration. You might think, sounds like an Energy Department area. MARTIN: Right - instead of the people who are watching over the metal detectors at airports. KREBS: Yeah. Well, but ultimately, a pipeline is a mode of transportation, and there are multiple products that move through pipelines, including water and chemicals and gases. And so what you really think about is not the product that flows through the pipes, but it's the modality itself. It's the infrastructure itself. And TSA is uniquely situated to be helpful here. And so what you're seeing is, as you pointed out, the first security regulation from TSA over pipelines, and it's an incremental step, at least for the moment. MARTIN: So what's it going to change? KREBS: Well, for one, this specific directive - and the directive is focused. It's threat-oriented and likely be time limited, but it's going to require reporting of security incidents to TSA and to my old agency, CISA. And that's it. But there's additional authority that may take a little bit more time to develop where you may see things like security standards or baseline standards of performance for security measures. MARTIN: So this is primarily a reporting mechanism. Private companies then are going to have to disclose when they've been hacked to the federal government. Are they interested in revealing that information? KREBS: Well, that's the interesting thing, right? When you think back to the initial days of the Colonial Pipeline hack a couple weeks ago and my predecessor, the acting director, was in Congress, and he was asked questions about what you know, what don't you know. And ultimately, early on, there wasn't a lot of information available to the federal government because it's not required to report on incidents. And I think that's a key element that has to change across all of our critical infrastructures, not just pipelines. But these companies need to report to the government because if we don't really know how big the problem is, it's hard to make informed policy and operational decisions going forward. MARTIN: So these regulations are supposed to be mandatory. How do you enforce that? KREBS: Well, there are a number of different ways they can do that. First is just through the kind of the wag your finger and you engage them all the way up to security fines and shutdown of operations. These are the sorts of directives that TSA issues and implements all the time at airports - just recently, mask mandates on commercial air travel. So there's a regime in place. There are relationships with the pipeline sector, and now it's just a matter of getting it out there and helping these organizations understand who they need to talk to and how to do it. MARTIN: And you nodded to this earlier, but help us understand what comes from that information. So the federal government finds out about a particular hack, or now they have a bunch of data points about several hacks. What does that do to prevent them? KREBS: Well, I think one of the things that's important right now is that due to a lack of a mandatory reporting regime on ransomware specifically, we don't really understand how bad the problem is. And one of the things that I would greatly encourage is anyone that has a ransomware event notifies the government so that we - so the government can take action needed, including working with our foreign partners, as well as some of the countries that may be harboring these ransomware actors, so that we can put an end to this now. MARTIN: Chris Krebs, former director of the Cybersecurity and Infrastructure Security Agency at DHS, we appreciate you taking the time. Thank you. KREBS: Thanks a lot.", "section": "National Security", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-05-27-1000444659": {"title": "'Helgoland' Is A Poetic Argument For Carlo Rovelli's View Of Quantum Mechanics : NPR", "url": "https://www.npr.org/2021/05/27/1000444659/helgoland-offers-a-new-way-to-understand-the-world-and-our-place-in-it", "author": "No author found", "published_date": "2021-05-27", "content": "", "section": "Book Reviews", "disclaimer": ""}, "2021-05-27-1000694357": {"title": "TSA Now Requires That Pipelines Report Cyberattacks : NPR", "url": "https://www.npr.org/2021/05/27/1000694357/in-wake-of-colonial-attack-pipelines-now-must-report-cybersecurity-breaches", "author": "No author found", "published_date": "2021-05-27", "content": "", "section": "National Security", "disclaimer": ""}, "2021-05-28-1001402799": {"title": "SolarWinds, supply chain hacks, and cybersecurity : Planet Money : NPR", "url": "https://www.npr.org/2021/05/28/1001402799/one-hack-to-fool-them-all", "author": "No author found", "published_date": "2021-05-28", "content": "SYLVIE DOUGLIS, BYLINE: This is PLANET MONEY from NPR. (SOUNDBITE OF COIN SPINNING)JACOB GOLDSTEIN, HOST:  In December of last year, somebody at a cybersecurity company, a company called FireEye, noticed something just a tiny bit out of the ordinary. Somebody was logging in to the company's system using an employee's username and login, but they were using a different phone number than the employee had used before. DINA TEMPLE-RASTON, HOST:  So people get new phone numbers. That's not the big deal. This particular company, though - FireEye - is in the computer security business. So they take this kind of thing really seriously. KEVIN MANDIA: So one of our staff members called the person, you know, whose account was used and said, hey, did you register a second phone? TEMPLE-RASTON: That's Kevin Mandia, the CEO of FireEye. (SOUNDBITE OF ARCHIVED NPR BROADCAST)MANDIA: And the gentleman said, no, I did not register that phone. So who did? GOLDSTEIN: Who indeed? TEMPLE-RASTON: Yeah. Well, so Mandia and his team at FireEye, they start trying to figure out exactly that. You know, how did some random person get into their network and end up registering a new phone? And the more they learned, the more worried Mandia got. MANDIA: It just felt like the breach that I was always worried about. We didn't know a lot at the time. It just felt like it was time to brace for impact. (SOUNDBITE OF ARNAUD RIGNON AND SEBASTIEN LANGOLFF'S \"DARK WOOD\")GOLDSTEIN: Hello, and welcome to PLANET MONEY. I'm Jacob Goldstein. TEMPLE-RASTON: And I'm Dina Temple-Raston. Today on the show, the story of a single hack that got inside some of the biggest corporations in the world and even deep inside the United States government itself. GOLDSTEIN: It was a particular style of hack that seems to be becoming more common. In fact, just today, Friday, May 28, as this show is about to go out, there is news of another, similar kind of hack. And I think our vulnerability to this particular kind of hack really tells us something not just about software and cybersecurity, but about the way business works today and about how it might need to change. (SOUNDBITE OF ARNAUD RIGNON AND SEBASTIEN LANGOLFF'S \"DARK WOOD\")GOLDSTEIN: Dina, you are on the breaking news investigative team here at NPR, and you have spent months working on this story, so why don't you just pick up where we left off with Kevin Mandia, the CEO of FireEye? TEMPLE-RASTON: Right. He's realized there's somebody who's not an employee who's inside their network, and that's a problem. MANDIA: So we had several weeks where I'm sitting here going, boy, I wonder how they broke in. And it is a terrible nag, Dina, when you're responding to a breach anywhere, whether it's your own house or someone else's house, and you don't know how they broke in. TEMPLE-RASTON: So FireEye is in the business of trying to figure out exactly that kind of thing. And that's what other companies typically pay them to do. And what they do is they try to think back to what the earliest evidence of compromise could be, you know, like where they might have seen some sort of stranger in their network or where that stranger could've come in. And they traced this back literally for weeks. And they think it all started with some software from a company called SolarWinds. MANDIA: So at that point, the only logical conclusion that I drew was something's wrong with the SolarWinds server. GOLDSTEIN: So SolarWinds - we know now that's what this big hack that this whole story is about came to be called, the SolarWinds hack. And I want to be honest with you. I've been sort of following that story, but I don't think I have ever really understood, like, what is SolarWinds? What is it? TEMPLE-RASTON: SolarWinds is a software company. And they make a bunch of different kinds of software, but the one that's at the center of this story is a software they make to manage computer networks. GOLDSTEIN: OK, so nothing to do with either the sun or the wind. If I'm thinking alternative energy, I'm entirely in the wrong universe. TEMPLE-RASTON: Entirely in the wrong - I have no idea what kind of - how they came up with the name. GOLDSTEIN: OK. TEMPLE-RASTON: What I can tell you is that it's what's called network management software. This is what IT people use basically so they can keep sort of an eye on the entire network. So, for example, you know, if you have that printer on the fifth floor that's always breaking down, they can see that on one screen. If there's a router that goes down, they can see all that on the same screen. So think of it as actually something that touches everything in a network. And the reason it's kind of genius to actually hack into something like network management software is because it touches everything. And it means if you're inside of it, then you can touch everything, too. GOLDSTEIN: So it's like if you're inside this, you can get inside of everything at a company, at an organization. Can you give me just, like, a list of companies and government agencies that were using SolarWinds when this happened? TEMPLE-RASTON: So one, obviously, is FireEye. GOLDSTEIN: That's the company we talked about at the beginning of the show that was running SolarWinds software and figured out that something was wrong. TEMPLE-RASTON: Right. But in addition to that, I mean, some really big companies were running the software - Microsoft, Intel, Cisco. Then if you look at the federal government, the Department of Homeland Security was running it. The Treasury was running it. Even parts of the Pentagon were. GOLDSTEIN: Wow. TEMPLE-RASTON: So this was something that was really widespread. And again, you'd never heard of it. I'd never heard of it. But the people who knew about this were the people who were in the back room of your IT department. And for those people, SolarWinds was everywhere. GOLDSTEIN: And we know that FireEye figures out that the SolarWinds server was hacked. And then Kevin Mandia, the CEO of FireEye, he tells SolarWinds, you know, you've got a problem here. TEMPLE-RASTON: And then SolarWinds does this incredibly surprising thing. It goes and tells the world. In fact, their CEO, Sudhakar Ramakrishna, was so focused on getting the whole story out, he even talked to us. (SOUNDBITE OF ARCHIVED NPR BROADCAST)SUDHAKAR RAMAKRISHNA: You forget about competition and competitors. And in that context, you - the right thing to do is to report. The right thing to do is to give them the ability to fix those issues and protect their customers. TEMPLE-RASTON: What he doesn't say is that everyone was probably going to find out anyway. GOLDSTEIN: Right, right. So now they have to figure out, you know, who hacked us, and how did they hack us. TEMPLE-RASTON: And in order to answer those questions, they need to call in an expert. And the expert they called was a guy named Adam Meyers. ADAM MEYERS: And so the first call we took, I'm sitting outside of my in-laws' house in the driver's seat of my vehicle. I'm sitting in the driver's seat, and I'm outside while everybody's inside, having this phone call with the lawyers. And we're kind of getting our arms around what was going on. TEMPLE-RASTON: Adam Meyers is a genius at reverse engineering. And what that means is he looks at the hack, and he looks at all the code, and he just sort of teases it out to try and figure out what each piece of code does, how it works, what its job is. And then once he figures that out, he just keeps digging deeper and deeper and deeper until he can essentially figure out the whole hack. GOLDSTEIN: So as best as he has figured it out, what is the story of this hack? TEMPLE-RASTON: Well, the first thing they realize is that this wasn't a regular hack, that actually it started in a place they hadn't expected. And the place where it started was in what they call their development environment. What it is is it's this - think of it as a clean room in a factory where you actually write the software, you write the patch, and then you actually seal it up before you send it to someone else, before you put it out for people to use the patch. GOLDSTEIN: And what happened in this sort of factory clean room where they're making the software patch? TEMPLE-RASTON: It seems that bad guys appeared to have snuck in. SolarWinds didn't have a clean environment. What they had was a development environment that was connected to a network that was connected to the internet. So that meant at the very last second - and this is what Meyers figured out. At that very last second, instead of having SolarWinds send out their own patch, the bad guys swapped it with their own. Meyers explained it with this metaphor. (SOUNDBITE OF ARCHIVED NPR BROADCAST)MEYERS: Let's go with Halloween candy, right? Like, when I was growing up, you used to have to check your Halloween candy 'cause somebody might have put a razor blade in your Reese's Peanut Butter Cup, right? GOLDSTEIN: So, OK, stay with this metaphor, right? In a typical hack, the hackers open the candy wrapper and stick the razor blade in. But, you know, now the wrapper is open. This is pretty easy to detect. But in this instance, in the SolarWinds hack, they did something much more clever and much more insidious. (SOUNDBITE OF ARCHIVED NPR BROADCAST)MEYERS: Imagine those Reese's Peanut Butter Cups going into the package, and just before the machine comes down and seals the package, some other thing comes in and slides a razor blade into your Reese's Peanut Butter Cup, right? So that is - you know, and then the package gets sealed and it goes out the door to the store. TEMPLE-RASTON: And that's why this hack was so effective, because when the software patch from SolarWinds goes out to all these big companies and government agencies, it looks like it's sealed software. But in fact, there's a razor blade - malware code, essentially - that's hiding inside. GOLDSTEIN: So there's this phrase, Dina, that I've seen in some of your reporting on this that as a sort of econ nerd interested in the cybersecurity stuff I got pretty excited about. And that phrase is supply chain hack, right? This has been called a supply chain hack. And so supply chain there refers to the idea - like in the same way we might think of, say, a car company having a supply chain, right? Like whatever - Ford buys parts from literally thousands of different companies. Software works kind of the same way, right? Like, the Department of Defense and Microsoft and Cisco - these companies don't just write their own software. They have a software supply chain - right? - all these little things like this software they're getting from SolarWinds. And so if you can hack into the supply chain, you can get everywhere with one hack. TEMPLE-RASTON: It's much more efficient. GOLDSTEIN: Yeah, it's much more efficient. It's a really good way to hack everybody all at once. TEMPLE-RASTON: Exactly. Instead of trying to break into the Treasury or the Pentagon and Department of Homeland Security, just find a software that's ubiquitous, and break into that. And this is why people like Adam Meyers have been so worried about supply chain hacks. MEYERS: The reason that software supply chain keeps me up at night - you know, think about all the apps on your mobile device, on your tablet, on your computer. You're only as secure as the development environment that those were built in, and you're only as secure as the weakest link in that chain. TEMPLE-RASTON: And for a bunch of giant companies and federal agencies, the weakest link was SolarWinds. GOLDSTEIN: After the break, what the bad guys got, who the bad guys are and what the United States is doing to try to prevent this from happening again. (SOUNDBITE OF CESAR GIMENO LAVIN AND SIMON JOSEPH ALEXANDER JAMES' \"THE DEVIL LIVES NEAR\")GOLDSTEIN: The story so far - the bad guys got their razor blades into thousands of packages of Reese's Peanut Butter Cups. Those Reese's Peanut Butter Cups got sent to the Department of Defense and Microsoft and Cisco and everybody else. I get that it's big. I get that it's big. And, you know, there is one other, like, admission I have about this hack - is I don't really know what happened or what the implications are. What was the bad thing that happened because of this hack? TEMPLE-RASTON: Well, so there were two big things. The first is this was clearly an espionage operation. They were taking information out of networks. We don't know what it was, and nobody has really talked specifically about that. But we do know that, for example, they were reading emails from government officials, officials at DHS, officials at the Treasury. And the reason why that's important is because there's a lot of information that can be in an email. It could be an attachment or something like that. GOLDSTEIN: Sure, sure. TEMPLE-RASTON: The second thing that's worth. . . GOLDSTEIN: So just spying. So this is like straight-up very successful spy operation. TEMPLE-RASTON: We think so, right? GOLDSTEIN: Yeah. TEMPLE-RASTON: And that seems to be what the motivation was here. But the other thing that people aren't talking about quite as much - something called a backdoor. GOLDSTEIN: OK. TEMPLE-RASTON: And a backdoor is malicious code that you plant in a network for use later. What a backdoor allows you to do is, say, for example, steal emails later when everybody's relaxed. Or a backdoor could allow you to plant ransomware. Think about the Colonial Pipeline. That actually wasn't a hack. That was a ransomware attack. And their system was frozen until they paid a certain amount of money to some criminals. And the same thing could happen with SolarWinds. I mean, we don't know about it because this little piece of ransomware could be hidden in code that they haven't discovered yet. GOLDSTEIN: So we know the bad guys got in. We are pretty sure they were spying. And maybe they also planted some things that will allow them to do bad things in the future, we just don't know that part yet. TEMPLE-RASTON: Exactly. Exactly. GOLDSTEIN: So do we know who the bad guys are? TEMPLE-RASTON: We think we know. Russian intelligence, a group called the SVR, is thought to be behind this. And there are a couple of reasons for that. One, this was an incredibly sophisticated hack. Not only did they get into where they were actually building the software, but Adam Meyers told us they were super careful about covering their tracks so that there wouldn't be little clues that they might be able to find to tell them who was behind it. And that's the sort of thing that you see a nation-state do. And because of that. . . GOLDSTEIN: Like, it's just - like, a criminal wouldn't care that much. TEMPLE-RASTON: They don't care. GOLDSTEIN: Yeah, right. TEMPLE-RASTON: A criminal just wants their money, right? GOLDSTEIN: (Laughter) Right. TEMPLE-RASTON: But this was artful. This was artful. GOLDSTEIN: And so this new hack that we mentioned earlier in the show, this hack that we are just learning about today as the show is going out, it seems similar in some key ways to the SolarWinds hack. For one, it appears to have been done by the Russians. For another, it looks like it was another supply chain hack. And it is also targeting, ultimately, the U. S. government. In this case, the hackers apparently hacked an email service software that is used by lots of people, including government agencies. And then they used that hack to send malicious emails out into the world that looked like they were from this U. S. government agency. TEMPLE-RASTON: Exactly. GOLDSTEIN: So this is, like, kind of Cold War-ish, right? It's definitely country versus country. Like, this is Russia at some level - well, attacking is too strong a word, but Russia coming at the United States. TEMPLE-RASTON: Yeah, this is \"Spy Vs. Spy\" stuff. GOLDSTEIN: So what's the U. S. going to do about it? Is the U. S. going to hack back? Is that the way this works? Like you hacked us, we'll hack you? Did we already hack them and we don't know it? TEMPLE-RASTON: Possibly, although I suspect that, you know, everybody's sort of watching for it. But there's an entire military command, Cyber Command, and the National Security Agency, and their job is to do exactly that. And, you know, we were talking before about backdoors. Backdoors are put in in case you need them later, right? So a lot of people believe that after the Sony hack, once they had determined that North Korea was behind it, that the U. S. retaliated by turning off the internet in North Korea for a couple of days just to let them know, hey, we're in your systems, and you should be careful. We're watching you. Of course, the U. S. has never admitted that publicly. I mean, this is one of the reasons they call cyber the perfect weapon, because it's short of war and it's hard to attribute it. So you can do a lot of the same things you would do with what they call metal on steel, you know, kinetic things. You can do that just by using computer code. GOLDSTEIN: So one last thing in terms of, you know, what's coming next, what are we going to do about this - you, Dina, have reported on this executive order that President Biden just issued that's going to set standards. It's going to set rules, basically, for companies that sell software to the federal government. And the idea is that forcing companies to follow these rules should make supply chain hacks like SolarWinds less likely in the future. And I know you've described two of these rules that seem especially key, especially relevant here. What are they? TEMPLE-RASTON: Well, one is something they call provenance. And provenance basically means you have to tell us where all the code you're using comes from. And this is a big deal because it's cheaper to actually have software written in other countries because coders in a lot of other countries make a lot less money than coders in, say, Silicon Valley or coders in the United States more generally. GOLDSTEIN: OK. TEMPLE-RASTON: For example, some of SolarWinds' code was written in Eastern Europe. And apparently, the government didn't know that. GOLDSTEIN: OK. TEMPLE-RASTON: Now, nobody has connected that to the hack, but it's emblematic of a larger problem, which is that people don't know where the code in their software actually comes from. GOLDSTEIN: And so to be clear, it's OK to have your code - some of your code come from overseas or whatever, but you just have to be able to document for all of the code where each chunk came from. TEMPLE-RASTON: Yes, and whether or not - for example, the federal government may decide to go with a different company because they like where their code was built better, right? This. . . GOLDSTEIN: Right, right. TEMPLE-RASTON: . . . Would be another consideration. Before, it was all about price, or it was largely about price - maybe reputation, but. . . GOLDSTEIN: Yeah. TEMPLE-RASTON: . . . Largely about price. Now it's going to be much more about whether or not you can set up a defense in terms of knowing where your code is coming from, knowing how your code is made, knowing how you developed your software. Those are all really important things. GOLDSTEIN: So, OK, provenance - know where your code comes from. That is one of the new standards. What's the other one that's also important? TEMPLE-RASTON: Well, the other one really goes directly to the SolarWinds hack. Remember, we think hackers somehow got into the so-called development environment - right? - that digital place where engineers at SolarWinds actually write the code, build the software or build a patch. So this new standard will require that the development environment be essentially cut off from the internet. They call it air gapped. And so that would make it a lot more like a clean room in a factory. And to go back to the earlier Reese's Peanut Butter Cup metaphor, this should make it harder for hackers to sneak inside and slip those razor blades inside the sealed wrapper. GOLDSTEIN: So these kinds of changes - you know, requiring the place where the coders are writing software to be separated from the internet and requiring companies to know where all of the code comes from - these will make software safer and probably more expensive, right? It's making it less efficient in the name of safety. That's, like, a trade-off. The government is saying, let's make this trade-off at this point. TEMPLE-RASTON: Right, although hacks cost a lot of money, right? GOLDSTEIN: Yes. No, I agree. I agree. Yes. TEMPLE-RASTON: So it's unclear where the trade-off will be. GOLDSTEIN: So more expensive upfront but maybe cheaper in the long run. TEMPLE-RASTON: Right. GOLDSTEIN: And I do feel like it's interesting to think about this story in relation to the economy more generally - right? - because. . . TEMPLE-RASTON: Right. GOLDSTEIN: . . . It seems like one of the big economic lessons of the pandemic is that what seemed optimally efficient in lots of industries - you know, automaking or whatever, this idea of, like, don't hold extra inventory, lean manufacturing - it turned out to be not very resilient. Once things started getting weird in the world, suddenly there are shortages of cars, shortages of everything. TEMPLE-RASTON: Right. GOLDSTEIN: And so this relentless pursuit of efficiency left us, left the economy vulnerable - surprisingly vulnerable. And it feels analogous to this SolarWinds story, where software is this incredibly efficient industry, and doing things like having programmers be networked and using code from all these different sources - these are very efficient practices that let people build really powerful software really cheaply. But what we're learning now with this hack is that, as you say, like, maybe that's not really most efficient in the long run even if it superficially seems so. TEMPLE-RASTON: Yeah, I'm not sure we learned that from this hack. . . GOLDSTEIN: (Laughter) Fair. TEMPLE-RASTON: . . . 'Cause I think that we've known for some time that this was a vulnerability. And there was never. . . GOLDSTEIN: Yeah. TEMPLE-RASTON: . . . Really the impetus to have people say, let's not do it this way. They were chasing, you know, who could do it the most cheaply and not necessarily the most safely. And I think that what has happened as we've seen these hacks grow more and more sophisticated, I think there's a realization that the way we used to do things, we can't do them that way anymore and that we have to have defense much more in mind than we did in the past. (SOUNDBITE OF BERNARD BERNIE RUBINSTEIN AND JOHN MARK CACAVAS JR. 'S \"WIGGIN' ALONG\")GOLDSTEIN: What other stories about spying should we do? Let us know. You can email us at planetmoney@npr. org. You can also find us on many of the social media. We are @planetmoney. I'll note that we just hit our one-year anniversary on TikTok. If you haven't checked out PLANET MONEY TikTok yet, you should. It's strange and smart and great. Today's show was produced by Maria Paz Gutierrez with engineering help from Gilly Moon. Bryant Urstadt edited the show. Alex Goldmark is our supervising producer. I'm Jacob Goldstein. This is NPR. Thanks for listening. (SOUNDBITE OF BERNARD BERNIE RUBINSTEIN AND JOHN MARK CACAVAS JR. 'S \"WIGGIN' ALONG\") SYLVIE DOUGLIS, BYLINE: This is PLANET MONEY from NPR. (SOUNDBITE OF COIN SPINNING) JACOB GOLDSTEIN, HOST:   In December of last year, somebody at a cybersecurity company, a company called FireEye, noticed something just a tiny bit out of the ordinary. Somebody was logging in to the company's system using an employee's username and login, but they were using a different phone number than the employee had used before. DINA TEMPLE-RASTON, HOST:   So people get new phone numbers. That's not the big deal. This particular company, though - FireEye - is in the computer security business. So they take this kind of thing really seriously. KEVIN MANDIA: So one of our staff members called the person, you know, whose account was used and said, hey, did you register a second phone? TEMPLE-RASTON: That's Kevin Mandia, the CEO of FireEye. (SOUNDBITE OF ARCHIVED NPR BROADCAST) MANDIA: And the gentleman said, no, I did not register that phone. So who did? GOLDSTEIN: Who indeed? TEMPLE-RASTON: Yeah. Well, so Mandia and his team at FireEye, they start trying to figure out exactly that. You know, how did some random person get into their network and end up registering a new phone? And the more they learned, the more worried Mandia got. MANDIA: It just felt like the breach that I was always worried about. We didn't know a lot at the time. It just felt like it was time to brace for impact. (SOUNDBITE OF ARNAUD RIGNON AND SEBASTIEN LANGOLFF'S \"DARK WOOD\") GOLDSTEIN: Hello, and welcome to PLANET MONEY. I'm Jacob Goldstein. TEMPLE-RASTON: And I'm Dina Temple-Raston. Today on the show, the story of a single hack that got inside some of the biggest corporations in the world and even deep inside the United States government itself. GOLDSTEIN: It was a particular style of hack that seems to be becoming more common. In fact, just today, Friday, May 28, as this show is about to go out, there is news of another, similar kind of hack. And I think our vulnerability to this particular kind of hack really tells us something not just about software and cybersecurity, but about the way business works today and about how it might need to change. (SOUNDBITE OF ARNAUD RIGNON AND SEBASTIEN LANGOLFF'S \"DARK WOOD\") GOLDSTEIN: Dina, you are on the breaking news investigative team here at NPR, and you have spent months working on this story, so why don't you just pick up where we left off with Kevin Mandia, the CEO of FireEye? TEMPLE-RASTON: Right. He's realized there's somebody who's not an employee who's inside their network, and that's a problem. MANDIA: So we had several weeks where I'm sitting here going, boy, I wonder how they broke in. And it is a terrible nag, Dina, when you're responding to a breach anywhere, whether it's your own house or someone else's house, and you don't know how they broke in. TEMPLE-RASTON: So FireEye is in the business of trying to figure out exactly that kind of thing. And that's what other companies typically pay them to do. And what they do is they try to think back to what the earliest evidence of compromise could be, you know, like where they might have seen some sort of stranger in their network or where that stranger could've come in. And they traced this back literally for weeks. And they think it all started with some software from a company called SolarWinds. MANDIA: So at that point, the only logical conclusion that I drew was something's wrong with the SolarWinds server. GOLDSTEIN: So SolarWinds - we know now that's what this big hack that this whole story is about came to be called, the SolarWinds hack. And I want to be honest with you. I've been sort of following that story, but I don't think I have ever really understood, like, what is SolarWinds? What is it? TEMPLE-RASTON: SolarWinds is a software company. And they make a bunch of different kinds of software, but the one that's at the center of this story is a software they make to manage computer networks. GOLDSTEIN: OK, so nothing to do with either the sun or the wind. If I'm thinking alternative energy, I'm entirely in the wrong universe. TEMPLE-RASTON: Entirely in the wrong - I have no idea what kind of - how they came up with the name. GOLDSTEIN: OK. TEMPLE-RASTON: What I can tell you is that it's what's called network management software. This is what IT people use basically so they can keep sort of an eye on the entire network. So, for example, you know, if you have that printer on the fifth floor that's always breaking down, they can see that on one screen. If there's a router that goes down, they can see all that on the same screen. So think of it as actually something that touches everything in a network. And the reason it's kind of genius to actually hack into something like network management software is because it touches everything. And it means if you're inside of it, then you can touch everything, too. GOLDSTEIN: So it's like if you're inside this, you can get inside of everything at a company, at an organization. Can you give me just, like, a list of companies and government agencies that were using SolarWinds when this happened? TEMPLE-RASTON: So one, obviously, is FireEye. GOLDSTEIN: That's the company we talked about at the beginning of the show that was running SolarWinds software and figured out that something was wrong. TEMPLE-RASTON: Right. But in addition to that, I mean, some really big companies were running the software - Microsoft, Intel, Cisco. Then if you look at the federal government, the Department of Homeland Security was running it. The Treasury was running it. Even parts of the Pentagon were. GOLDSTEIN: Wow. TEMPLE-RASTON: So this was something that was really widespread. And again, you'd never heard of it. I'd never heard of it. But the people who knew about this were the people who were in the back room of your IT department. And for those people, SolarWinds was everywhere. GOLDSTEIN: And we know that FireEye figures out that the SolarWinds server was hacked. And then Kevin Mandia, the CEO of FireEye, he tells SolarWinds, you know, you've got a problem here. TEMPLE-RASTON: And then SolarWinds does this incredibly surprising thing. It goes and tells the world. In fact, their CEO, Sudhakar Ramakrishna, was so focused on getting the whole story out, he even talked to us. (SOUNDBITE OF ARCHIVED NPR BROADCAST) SUDHAKAR RAMAKRISHNA: You forget about competition and competitors. And in that context, you - the right thing to do is to report. The right thing to do is to give them the ability to fix those issues and protect their customers. TEMPLE-RASTON: What he doesn't say is that everyone was probably going to find out anyway. GOLDSTEIN: Right, right. So now they have to figure out, you know, who hacked us, and how did they hack us. TEMPLE-RASTON: And in order to answer those questions, they need to call in an expert. And the expert they called was a guy named Adam Meyers. ADAM MEYERS: And so the first call we took, I'm sitting outside of my in-laws' house in the driver's seat of my vehicle. I'm sitting in the driver's seat, and I'm outside while everybody's inside, having this phone call with the lawyers. And we're kind of getting our arms around what was going on. TEMPLE-RASTON: Adam Meyers is a genius at reverse engineering. And what that means is he looks at the hack, and he looks at all the code, and he just sort of teases it out to try and figure out what each piece of code does, how it works, what its job is. And then once he figures that out, he just keeps digging deeper and deeper and deeper until he can essentially figure out the whole hack. GOLDSTEIN: So as best as he has figured it out, what is the story of this hack? TEMPLE-RASTON: Well, the first thing they realize is that this wasn't a regular hack, that actually it started in a place they hadn't expected. And the place where it started was in what they call their development environment. What it is is it's this - think of it as a clean room in a factory where you actually write the software, you write the patch, and then you actually seal it up before you send it to someone else, before you put it out for people to use the patch. GOLDSTEIN: And what happened in this sort of factory clean room where they're making the software patch? TEMPLE-RASTON: It seems that bad guys appeared to have snuck in. SolarWinds didn't have a clean environment. What they had was a development environment that was connected to a network that was connected to the internet. So that meant at the very last second - and this is what Meyers figured out. At that very last second, instead of having SolarWinds send out their own patch, the bad guys swapped it with their own. Meyers explained it with this metaphor. (SOUNDBITE OF ARCHIVED NPR BROADCAST) MEYERS: Let's go with Halloween candy, right? Like, when I was growing up, you used to have to check your Halloween candy 'cause somebody might have put a razor blade in your Reese's Peanut Butter Cup, right? GOLDSTEIN: So, OK, stay with this metaphor, right? In a typical hack, the hackers open the candy wrapper and stick the razor blade in. But, you know, now the wrapper is open. This is pretty easy to detect. But in this instance, in the SolarWinds hack, they did something much more clever and much more insidious. (SOUNDBITE OF ARCHIVED NPR BROADCAST) MEYERS: Imagine those Reese's Peanut Butter Cups going into the package, and just before the machine comes down and seals the package, some other thing comes in and slides a razor blade into your Reese's Peanut Butter Cup, right? So that is - you know, and then the package gets sealed and it goes out the door to the store. TEMPLE-RASTON: And that's why this hack was so effective, because when the software patch from SolarWinds goes out to all these big companies and government agencies, it looks like it's sealed software. But in fact, there's a razor blade - malware code, essentially - that's hiding inside. GOLDSTEIN: So there's this phrase, Dina, that I've seen in some of your reporting on this that as a sort of econ nerd interested in the cybersecurity stuff I got pretty excited about. And that phrase is supply chain hack, right? This has been called a supply chain hack. And so supply chain there refers to the idea - like in the same way we might think of, say, a car company having a supply chain, right? Like whatever - Ford buys parts from literally thousands of different companies. Software works kind of the same way, right? Like, the Department of Defense and Microsoft and Cisco - these companies don't just write their own software. They have a software supply chain - right? - all these little things like this software they're getting from SolarWinds. And so if you can hack into the supply chain, you can get everywhere with one hack. TEMPLE-RASTON: It's much more efficient. GOLDSTEIN: Yeah, it's much more efficient. It's a really good way to hack everybody all at once. TEMPLE-RASTON: Exactly. Instead of trying to break into the Treasury or the Pentagon and Department of Homeland Security, just find a software that's ubiquitous, and break into that. And this is why people like Adam Meyers have been so worried about supply chain hacks. MEYERS: The reason that software supply chain keeps me up at night - you know, think about all the apps on your mobile device, on your tablet, on your computer. You're only as secure as the development environment that those were built in, and you're only as secure as the weakest link in that chain. TEMPLE-RASTON: And for a bunch of giant companies and federal agencies, the weakest link was SolarWinds. GOLDSTEIN: After the break, what the bad guys got, who the bad guys are and what the United States is doing to try to prevent this from happening again. (SOUNDBITE OF CESAR GIMENO LAVIN AND SIMON JOSEPH ALEXANDER JAMES' \"THE DEVIL LIVES NEAR\") GOLDSTEIN: The story so far - the bad guys got their razor blades into thousands of packages of Reese's Peanut Butter Cups. Those Reese's Peanut Butter Cups got sent to the Department of Defense and Microsoft and Cisco and everybody else. I get that it's big. I get that it's big. And, you know, there is one other, like, admission I have about this hack - is I don't really know what happened or what the implications are. What was the bad thing that happened because of this hack? TEMPLE-RASTON: Well, so there were two big things. The first is this was clearly an espionage operation. They were taking information out of networks. We don't know what it was, and nobody has really talked specifically about that. But we do know that, for example, they were reading emails from government officials, officials at DHS, officials at the Treasury. And the reason why that's important is because there's a lot of information that can be in an email. It could be an attachment or something like that. GOLDSTEIN: Sure, sure. TEMPLE-RASTON: The second thing that's worth. . . GOLDSTEIN: So just spying. So this is like straight-up very successful spy operation. TEMPLE-RASTON: We think so, right? GOLDSTEIN: Yeah. TEMPLE-RASTON: And that seems to be what the motivation was here. But the other thing that people aren't talking about quite as much - something called a backdoor. GOLDSTEIN: OK. TEMPLE-RASTON: And a backdoor is malicious code that you plant in a network for use later. What a backdoor allows you to do is, say, for example, steal emails later when everybody's relaxed. Or a backdoor could allow you to plant ransomware. Think about the Colonial Pipeline. That actually wasn't a hack. That was a ransomware attack. And their system was frozen until they paid a certain amount of money to some criminals. And the same thing could happen with SolarWinds. I mean, we don't know about it because this little piece of ransomware could be hidden in code that they haven't discovered yet. GOLDSTEIN: So we know the bad guys got in. We are pretty sure they were spying. And maybe they also planted some things that will allow them to do bad things in the future, we just don't know that part yet. TEMPLE-RASTON: Exactly. Exactly. GOLDSTEIN: So do we know who the bad guys are? TEMPLE-RASTON: We think we know. Russian intelligence, a group called the SVR, is thought to be behind this. And there are a couple of reasons for that. One, this was an incredibly sophisticated hack. Not only did they get into where they were actually building the software, but Adam Meyers told us they were super careful about covering their tracks so that there wouldn't be little clues that they might be able to find to tell them who was behind it. And that's the sort of thing that you see a nation-state do. And because of that. . . GOLDSTEIN: Like, it's just - like, a criminal wouldn't care that much. TEMPLE-RASTON: They don't care. GOLDSTEIN: Yeah, right. TEMPLE-RASTON: A criminal just wants their money, right? GOLDSTEIN: (Laughter) Right. TEMPLE-RASTON: But this was artful. This was artful. GOLDSTEIN: And so this new hack that we mentioned earlier in the show, this hack that we are just learning about today as the show is going out, it seems similar in some key ways to the SolarWinds hack. For one, it appears to have been done by the Russians. For another, it looks like it was another supply chain hack. And it is also targeting, ultimately, the U. S. government. In this case, the hackers apparently hacked an email service software that is used by lots of people, including government agencies. And then they used that hack to send malicious emails out into the world that looked like they were from this U. S. government agency. TEMPLE-RASTON: Exactly. GOLDSTEIN: So this is, like, kind of Cold War-ish, right? It's definitely country versus country. Like, this is Russia at some level - well, attacking is too strong a word, but Russia coming at the United States. TEMPLE-RASTON: Yeah, this is \"Spy Vs. Spy\" stuff. GOLDSTEIN: So what's the U. S. going to do about it? Is the U. S. going to hack back? Is that the way this works? Like you hacked us, we'll hack you? Did we already hack them and we don't know it? TEMPLE-RASTON: Possibly, although I suspect that, you know, everybody's sort of watching for it. But there's an entire military command, Cyber Command, and the National Security Agency, and their job is to do exactly that. And, you know, we were talking before about backdoors. Backdoors are put in in case you need them later, right? So a lot of people believe that after the Sony hack, once they had determined that North Korea was behind it, that the U. S. retaliated by turning off the internet in North Korea for a couple of days just to let them know, hey, we're in your systems, and you should be careful. We're watching you. Of course, the U. S. has never admitted that publicly. I mean, this is one of the reasons they call cyber the perfect weapon, because it's short of war and it's hard to attribute it. So you can do a lot of the same things you would do with what they call metal on steel, you know, kinetic things. You can do that just by using computer code. GOLDSTEIN: So one last thing in terms of, you know, what's coming next, what are we going to do about this - you, Dina, have reported on this executive order that President Biden just issued that's going to set standards. It's going to set rules, basically, for companies that sell software to the federal government. And the idea is that forcing companies to follow these rules should make supply chain hacks like SolarWinds less likely in the future. And I know you've described two of these rules that seem especially key, especially relevant here. What are they? TEMPLE-RASTON: Well, one is something they call provenance. And provenance basically means you have to tell us where all the code you're using comes from. And this is a big deal because it's cheaper to actually have software written in other countries because coders in a lot of other countries make a lot less money than coders in, say, Silicon Valley or coders in the United States more generally. GOLDSTEIN: OK. TEMPLE-RASTON: For example, some of SolarWinds' code was written in Eastern Europe. And apparently, the government didn't know that. GOLDSTEIN: OK. TEMPLE-RASTON: Now, nobody has connected that to the hack, but it's emblematic of a larger problem, which is that people don't know where the code in their software actually comes from. GOLDSTEIN: And so to be clear, it's OK to have your code - some of your code come from overseas or whatever, but you just have to be able to document for all of the code where each chunk came from. TEMPLE-RASTON: Yes, and whether or not - for example, the federal government may decide to go with a different company because they like where their code was built better, right? This. . . GOLDSTEIN: Right, right. TEMPLE-RASTON: . . . Would be another consideration. Before, it was all about price, or it was largely about price - maybe reputation, but. . . GOLDSTEIN: Yeah. TEMPLE-RASTON: . . . Largely about price. Now it's going to be much more about whether or not you can set up a defense in terms of knowing where your code is coming from, knowing how your code is made, knowing how you developed your software. Those are all really important things. GOLDSTEIN: So, OK, provenance - know where your code comes from. That is one of the new standards. What's the other one that's also important? TEMPLE-RASTON: Well, the other one really goes directly to the SolarWinds hack. Remember, we think hackers somehow got into the so-called development environment - right? - that digital place where engineers at SolarWinds actually write the code, build the software or build a patch. So this new standard will require that the development environment be essentially cut off from the internet. They call it air gapped. And so that would make it a lot more like a clean room in a factory. And to go back to the earlier Reese's Peanut Butter Cup metaphor, this should make it harder for hackers to sneak inside and slip those razor blades inside the sealed wrapper. GOLDSTEIN: So these kinds of changes - you know, requiring the place where the coders are writing software to be separated from the internet and requiring companies to know where all of the code comes from - these will make software safer and probably more expensive, right? It's making it less efficient in the name of safety. That's, like, a trade-off. The government is saying, let's make this trade-off at this point. TEMPLE-RASTON: Right, although hacks cost a lot of money, right? GOLDSTEIN: Yes. No, I agree. I agree. Yes. TEMPLE-RASTON: So it's unclear where the trade-off will be. GOLDSTEIN: So more expensive upfront but maybe cheaper in the long run. TEMPLE-RASTON: Right. GOLDSTEIN: And I do feel like it's interesting to think about this story in relation to the economy more generally - right? - because. . . TEMPLE-RASTON: Right. GOLDSTEIN: . . . It seems like one of the big economic lessons of the pandemic is that what seemed optimally efficient in lots of industries - you know, automaking or whatever, this idea of, like, don't hold extra inventory, lean manufacturing - it turned out to be not very resilient. Once things started getting weird in the world, suddenly there are shortages of cars, shortages of everything. TEMPLE-RASTON: Right. GOLDSTEIN: And so this relentless pursuit of efficiency left us, left the economy vulnerable - surprisingly vulnerable. And it feels analogous to this SolarWinds story, where software is this incredibly efficient industry, and doing things like having programmers be networked and using code from all these different sources - these are very efficient practices that let people build really powerful software really cheaply. But what we're learning now with this hack is that, as you say, like, maybe that's not really most efficient in the long run even if it superficially seems so. TEMPLE-RASTON: Yeah, I'm not sure we learned that from this hack. . . GOLDSTEIN: (Laughter) Fair. TEMPLE-RASTON: . . . 'Cause I think that we've known for some time that this was a vulnerability. And there was never. . . GOLDSTEIN: Yeah. TEMPLE-RASTON: . . . Really the impetus to have people say, let's not do it this way. They were chasing, you know, who could do it the most cheaply and not necessarily the most safely. And I think that what has happened as we've seen these hacks grow more and more sophisticated, I think there's a realization that the way we used to do things, we can't do them that way anymore and that we have to have defense much more in mind than we did in the past. (SOUNDBITE OF BERNARD BERNIE RUBINSTEIN AND JOHN MARK CACAVAS JR. 'S \"WIGGIN' ALONG\") GOLDSTEIN: What other stories about spying should we do? Let us know. You can email us at planetmoney@npr. org. You can also find us on many of the social media. We are @planetmoney. I'll note that we just hit our one-year anniversary on TikTok. If you haven't checked out PLANET MONEY TikTok yet, you should. It's strange and smart and great. Today's show was produced by Maria Paz Gutierrez with engineering help from Gilly Moon. Bryant Urstadt edited the show. Alex Goldmark is our supervising producer. I'm Jacob Goldstein. This is NPR. Thanks for listening. (SOUNDBITE OF BERNARD BERNIE RUBINSTEIN AND JOHN MARK CACAVAS JR. 'S \"WIGGIN' ALONG\")", "section": "One Hack to Fool Them All", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-05-28-1001367629": {"title": "What Microsoft Officials Know About Russia's Phishing Hack Targeting USAID : NPR", "url": "https://www.npr.org/2021/05/28/1001367629/russian-hackers-launched-a-new-supply-chain-hack-this-time-they-phished", "author": "No author found", "published_date": "2021-05-28", "content": "AILSA CHANG, HOST:  Russian hackers are at it again. The same group that hacked into software made by SolarWinds appears to have launched another supply chain hack. That's according to Microsoft. The company sent out an alert last night saying hackers who appear to be linked to the Russian intelligence service broke into the email marketing company Constant Contact in order to impersonate the government agency USAID. Dina Temple-Raston of NPR's investigations team has been tracking Russian hacking operations and joins us now. Hey, Dina. DINA TEMPLE-RASTON, BYLINE: Good morning. Hi. CHANG: Hi. So we should first note that both Microsoft and Constant Contact are financial supporters of NPR. OK, so tell us more about what Microsoft discovered. TEMPLE-RASTON: Well, it has this cybercrimes team that's watching for these kinds of intrusions all the time. This week they found hackers in a bunch of international development and human right organization systems. And as best as they can tell, the hackers broke into a company that was helping USAID with marketing, and they used that hack to send phishing emails. You know, Microsoft told us it wasn't a huge hack. They said maybe as many as 3,000 accounts were either hacked or threatened, maybe as many as 150 institutions. But they think the actual numbers are probably a lot smaller than that. CHANG: And these are phishing emails. Like, we're talking about fake emails that looked like they were from USAID. TEMPLE-RASTON: Exactly. So unsuspecting recipients would open these emails. They'd click on the links. And by doing that, the malware would be installed on their systems. And then the malware would basically give the hackers free access. They could steal data. They could infect other computers on these networks. They could read emails. They could even plant other malware. We talked to Tom Burt, vice president of consumer security and trust at Microsoft. He was behind that advisory last night, and he said that the hackers actually kind of customized the malware depending on the target. TOM BURT: These guys are actually doing something a little different in, even before the malware gets installed, they're doing some things to help them understand the environment that they are going to try to install the malware into so they can pick the right malware package. TEMPLE-RASTON: The reason that's important is because that's the kind of thing that nation-state hackers do. It's not the kind of thing that common cybercriminals do. CHANG: That's so. . . TEMPLE-RASTON: They just aren't that careful. CHANG: . . . Interesting. OK, so Russian intelligence is definitely behind this hack. TEMPLE-RASTON: We asked Tom Burt that, too, and he says they think it was a subset of the SolarWinds hacking group linked to the Russian intelligence service, the SVR. BURT: The association with the SVR comes from what - the techniques we see them using and from the kinds of targets that they are targeting. So it's a collection of circumstantial evidence, you might say, that point in a consistent direction. TEMPLE-RASTON: So the group that was behind SolarWinds is known as APT29 or Cozy Bear. And Microsoft said that they saw a lot of things that seem to overlap with Cozy Bear - easy to say. But they don't want to say unequivocally that it is the exact same people. It might be a subset. What they're not equivocating about, though, is that this hack came from Russia. CHANG: OK. And is the technique here similar to what was found in the SolarWinds hack late last year? TEMPLE-RASTON: Yes and no. The SolarWinds attack was actually really complicated and stealthy, and Microsoft appears to have seen this latest hack really quickly. And it's much simpler. I mean, the hackers aren't directly targeting companies or institutions they want to hack. They're focusing on suppliers in this case, just like they were in SolarWinds. And they're finding a company further down the supply chain, like a software company, to hack into them instead. The big question now is what the response is going to be. President Biden has already warned that Russia shouldn't be doing these attacks, and now they've done another one. So the question is whether or not this is going to force a response from the U. S. CHANG: Yeah. All right. That is NPR investigations correspondent Dina Temple-Raston. Thank you, Dina. TEMPLE-RASTON: You're welcome. AILSA CHANG, HOST:   Russian hackers are at it again. The same group that hacked into software made by SolarWinds appears to have launched another supply chain hack. That's according to Microsoft. The company sent out an alert last night saying hackers who appear to be linked to the Russian intelligence service broke into the email marketing company Constant Contact in order to impersonate the government agency USAID. Dina Temple-Raston of NPR's investigations team has been tracking Russian hacking operations and joins us now. Hey, Dina. DINA TEMPLE-RASTON, BYLINE: Good morning. Hi. CHANG: Hi. So we should first note that both Microsoft and Constant Contact are financial supporters of NPR. OK, so tell us more about what Microsoft discovered. TEMPLE-RASTON: Well, it has this cybercrimes team that's watching for these kinds of intrusions all the time. This week they found hackers in a bunch of international development and human right organization systems. And as best as they can tell, the hackers broke into a company that was helping USAID with marketing, and they used that hack to send phishing emails. You know, Microsoft told us it wasn't a huge hack. They said maybe as many as 3,000 accounts were either hacked or threatened, maybe as many as 150 institutions. But they think the actual numbers are probably a lot smaller than that. CHANG: And these are phishing emails. Like, we're talking about fake emails that looked like they were from USAID. TEMPLE-RASTON: Exactly. So unsuspecting recipients would open these emails. They'd click on the links. And by doing that, the malware would be installed on their systems. And then the malware would basically give the hackers free access. They could steal data. They could infect other computers on these networks. They could read emails. They could even plant other malware. We talked to Tom Burt, vice president of consumer security and trust at Microsoft. He was behind that advisory last night, and he said that the hackers actually kind of customized the malware depending on the target. TOM BURT: These guys are actually doing something a little different in, even before the malware gets installed, they're doing some things to help them understand the environment that they are going to try to install the malware into so they can pick the right malware package. TEMPLE-RASTON: The reason that's important is because that's the kind of thing that nation-state hackers do. It's not the kind of thing that common cybercriminals do. CHANG: That's so. . . TEMPLE-RASTON: They just aren't that careful. CHANG: . . . Interesting. OK, so Russian intelligence is definitely behind this hack. TEMPLE-RASTON: We asked Tom Burt that, too, and he says they think it was a subset of the SolarWinds hacking group linked to the Russian intelligence service, the SVR. BURT: The association with the SVR comes from what - the techniques we see them using and from the kinds of targets that they are targeting. So it's a collection of circumstantial evidence, you might say, that point in a consistent direction. TEMPLE-RASTON: So the group that was behind SolarWinds is known as APT29 or Cozy Bear. And Microsoft said that they saw a lot of things that seem to overlap with Cozy Bear - easy to say. But they don't want to say unequivocally that it is the exact same people. It might be a subset. What they're not equivocating about, though, is that this hack came from Russia. CHANG: OK. And is the technique here similar to what was found in the SolarWinds hack late last year? TEMPLE-RASTON: Yes and no. The SolarWinds attack was actually really complicated and stealthy, and Microsoft appears to have seen this latest hack really quickly. And it's much simpler. I mean, the hackers aren't directly targeting companies or institutions they want to hack. They're focusing on suppliers in this case, just like they were in SolarWinds. And they're finding a company further down the supply chain, like a software company, to hack into them instead. The big question now is what the response is going to be. President Biden has already warned that Russia shouldn't be doing these attacks, and now they've done another one. So the question is whether or not this is going to force a response from the U. S. CHANG: Yeah. All right. That is NPR investigations correspondent Dina Temple-Raston. Thank you, Dina. TEMPLE-RASTON: You're welcome.", "section": "Investigations", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-05-28-1001237516": {"title": "What We Know About The Apparent Russian Hack Exploiting USAID : NPR", "url": "https://www.npr.org/2021/05/28/1001237516/what-we-know-about-the-apparent-russian-hack-exploiting-a-u-s-aid-agency", "author": "No author found", "published_date": "2021-05-28", "content": "", "section": "National Security", "disclaimer": ""}, "2021-05-28-1000902810": {"title": "Jen Gunter: The Truth About Our Bodies : NPR", "url": "https://www.npr.org/2021/05/28/1000902810/jen-gunter-the-truth-about-our-bodies", "author": "No author found", "published_date": "2021-05-28", "content": "MANOUSH ZOMORODI, HOST:  It's the TED Radio Hour from NPR. I'm Manoush Zomorodi. Today on the show, how we learn about our bodies and tell fact from fiction. JEN GUNTER: Well, I think the issue is the medical internet is both amazing and is awful. And it shouldn't be that kind of crapshoot. ZOMORODI: This is Dr. Jen Gunter. GUNTER: I am an OB-GYN and a pain medicine physician and an author and podcaster. ZOMORODI: Jen is also internet famous for calling out celebrities who share misinformation about health and wellness. GUNTER: I would say that my mission is to give people factual, accessible information about their health because I want people to be empowered about your health. But you can only be empowered with accurate information. ZOMORODI: And for her, part of empowering people is to write guides to traditionally taboo women's health topics, including one called \"The Vagina Bible\" and her latest, \"The Menopause Manifesto. \" She also recently started a podcast called \"Body Stuff. \"(SOUNDBITE OF PODCAST, \"BODY STUFF\")GUNTER: I'm Dr. Jen Gunter. I love science. And I hate [expletive]. ZOMORODI: In 2019, Jen gave a TED Talk called \"Why Can't We Talk About Periods? \" And today she's brought us a selection of TED Talks, ones that have influenced her as she's become an outspoken critic on how society uses language and psychological tactics to shame and trick people about their basic bodily functions. Her story goes back 17 years ago when Jen herself was having a health crisis. GUNTER: I initially got interested in how people access information online because I was in that position. And so that really started it, when I had my pregnancy. And I had a triplet pregnancy, but it was incredibly complicated. And one of my sons died at birth, and my other two boys were in the intensive care unit for a long time. ZOMORODI: I'm so sorry. GUNTER: And so - and they had all these other medical problems as well as prematurity. And when I didn't get answers from my own doctors, I went online. And I was horrified. This was sort of the earlier stages of the medical internet, if you will. And I just thought, wow. If it's so hard for me to get practical information, like, useful information that can help me today. . . ZOMORODI: As a physician. GUNTER: Right. As a physician caring for my babies, right? Like, I wanted help. I wanted - there's gaps in medicine. You know, your doctors can tell you stuff. But they can't tell you, like, what are the tips and tricks for taking your babies out in a stroller when you have two children on oxygen, right? ZOMORODI: Oh, my gosh. GUNTER: Like, those are things that other experienced parents can tell you. But then, how do you know you're getting that right information? So I realized there were so many gaps that were important but not covered by medicine and how easy it was to fall down snake oil-filled rabbit holes, for lack of a better word. And I just thought if I was struggling like this - me, this person who's always been obsessed with evidence-based medicine - how was everyone else managing? And so I decided that I was going to fix the medical internet. ZOMORODI: (Laughter) Just a small goal, really, Jen? GUNTER: Right. That's - I was very naive about it. ZOMORODI: OK. So naive, but absolutely driven. And you're still doing that. And we're going to talk about some of the talks that have sort of propelled you as you try to fix the medical internet. But first, let's talk about your own talk. It's called \"Why Can't We Talk About Periods? \" And, Jen, from what I understand, you had absolutely terrible periods as a teenager. But you felt like you didn't have anyone to really talk to about your symptoms. GUNTER: Right. I mean, as far as my mother was concerned, you didn't talk about anything from down there. And she suffered with periods. So suck it up, sister. (LAUGHTER)GUNTER: And, yeah, so there was just - there's no information. And so I spent two days each month curled up with a heating pad. I couldn't go to school. And, you know, why was this happening? Why was I suffering so much? And it just felt to me like this big biological flaw. ZOMORODI: And did you ask your doctor, like, what is going on? GUNTER: I think I didn't actually get taken to one until maybe I was like 16. So I'd been suffering for, you know, several years. And my mother took me to her doctor, who basically said, yeah, period. Yeah. That's it. So basically, you know, it was just no practical information. And it's sad to me that, you know, that happened in the, I guess, early 1980s and that I still hear that same story from young women today. (SOUNDBITE OF MUSIC)ZOMORODI: And in your talk, you go back to kind of the historical roots of why you didn't have any access to information and you felt ashamed of this bodily function. (SOUNDBITE OF TED TALK)GUNTER: Why can't we talk about periods? And it's not about the blood, as Freud would have you say, because if it were, there'd be an ear, nose and throat surgeon up here right now talking about the taboos of nosebleeds, right? And it's not even about periods because otherwise, when we got rid of our toxic, shameful periods when we became menopausal, we'd be elevated to a higher social status. (LAUGHTER, APPLAUSE)GUNTER: It's just a patriarchal society is invested in oppressing women. And at different points in our lives, different things are used. And menstruation is used during what we in medicine call the reproductive years. It's been around since pretty much the beginning of time. Many cultures thought that women could spoil crops or milk or wilt flowers. And then when religion came along, purity myths only made that worse. And medicine wasn't any help. In the 1920s and '30s, there was the idea that women elaborated something called a menotoxin (ph). We could wilt flowers just by walking by. ZOMORODI: OK, so how have things changed? Let's fast-forward to when you were becoming a gynecologist. Are doctors taught - well, I guess there's two things. Were they taught, when you were in medical school, to speak more frankly about this stuff? And what about today when you talk to medical students? You know, what's the status quo now? GUNTER: Well, certainly, in the realm of gynecology, these words have always been used. But the publicability, this ability to talk outside of an office, is, I think, relatively new, right? ZOMORODI: Yeah, yeah. GUNTER: You know, '50s, '60s, '70s, '80s, your uterus is trouble; we don't hear about it. You know, really, I think it's sort of taken social media and being online to sort of raise the noise level enough that the conversation is catching. ZOMORODI: That's exactly what you do in your talk. You tell the audience what you tell your patients about how their periods work. (SOUNDBITE OF TED TALK)GUNTER: Well, what if everybody knew about periods like a gynecologist? Wouldn't that be great? Then you would all know what I know. You'd know that menstruation is a pretty unique phenomenon among mammals. Most mammals have estrous. Humans, some primates, some bats, the elephant shrew and the spiny mouse menstruate. And with menstruation, what happens is the brain triggers the ovary to start producing an egg. Estrogen is released, and it starts to build up the lining of the uterus, cell upon cell, like bricks. And what happens if you build a brick wall too high without mortar? Well, it's unstable. So what happens when you ovulate? You release a hormone called progesterone, which is progestational. It gets the uterus ready. It acts like a mortar, and it holds those bricks together. It also causes some changes to make the lining more hospitable for implantation. If there's no pregnancy, lining comes out. There's bleeding from the blood vessels, and that's the period. And I always find this point really interesting because with estrous, the final signaling to get the lining of the uterus ready actually comes from the embryo. But with menstruation, that choice comes from the ovary. It's as if choice is coded in to our reproductive tract. (CHEERING)ZOMORODI: You got big cheers there. You get a little political there at the end, Jen. Do you think politics and medicine - I mean, clearly they've always been intertwined when it comes to women and reproduction. Have they always been intertwined for you? GUNTER: I think so. You know, when I started in medical school, to get an abortion in Manitoba required approval of a three-person panel, and you didn't even get the privilege of pleading your own case in person. You told your family doctor, who then submitted a letter on your behalf. ZOMORODI: Wow. GUNTER: How wrong is that? And throughout the history of humanity, how medicine has been accessed for women is different than how it has been accessed by the people in power, men. And so, yeah, I think if you want to care for people and you want to help them medically, politics is simply part of it. ZOMORODI: There are a lot of folks, of course, who either because they can't or they won't go see a doctor, they look for information online now. You know, you go - back in the day, you'd go to the library. Nobody's there trying to sell you products at the same time - right? - whether that's to promote cleanliness or vagina health or, like - I actually was at the doctor's office today, and they were touting a three-pack. After you give birth, you know, come back. We'll slim down your tummy and tighten up your pores and, like, three procedures, plastic surgery procedures, for the low, low price of like - I think it was $7,500. I was like, what? That - huh? There's this overlap between medicine and the commoditization of what women need to do to be healthy/well/look good. GUNTER: Yeah. Every now and then, I get messages from people who've been at the gynecologist. And while they're sitting there waiting, wearing a robe, naked in the office, they look on the wall, and there's an advertisement for some kind of vaginal enhancement procedure. And. . . ZOMORODI: I saw that. GUNTER: Yeah. And how at your most vulnerable - you're naked in a doctor's office and you see that. And you're supposed to be there to get factual, accurate information about your vagina, your vulva, your body. And to have this implication on the wall that there's something troublesome with your body, I have a problem with that. I think that cosmetic procedures need to not be folded in with annual exams and seeking care for medical problems. ZOMORODI: So let's go back to your talk. Part of being able to look away from a lot of these advertisements or be like, that's ridiculous, is knowing how your body works, right? GUNTER: Exactly. Information is power. Knowledge is power. (SOUNDBITE OF TED TALK)GUNTER: It shouldn't be an act of feminism to know how your body works. It shouldn't. . . (APPLAUSE)GUNTER: It shouldn't be an act of feminism to ask for help when you're suffering. The only curse here is the ability to convince half the population that the very biological machinery that perpetuates the species, that gives everything that we have is somehow dirty or toxic. And I'm not going to stand for it. (APPLAUSE)GUNTER: And the way we break that curse - it's knowledge. ZOMORODI: In a minute, we'll be back with physician and author Jen Gunter and more facts about how our bodies work. I'm Manoush Zomorodi, and you're listening to the TED Radio Hour from NPR. Stay with us. It's the TED Radio Hour from NPR. I'm Manoush Zomorodi. And today, our guest is Dr. Jen Gunter. She's a practicing OB-GYN and physician but has also made a name for herself debunking celebrity wellness trends and helping us make informed decisions about our health. GUNTER: Yeah. I mean, I think debunking is an extension of my quest to know. All sort of misinformation, you know, has this root in not being informed. And I just think that so much of medicine is not that difficult. It might be complex. And obviously you don't need to know all of the nuances of everything to have a good working knowledge. But the good working knowledge - a lot of it's not really that hard. It's just our ivory tower makes it seem like it is. And so I want that to be as accessible to everyone as it is to me. ZOMORODI: That, I think, is the common theme of all the talks that you have chosen for us this hour. And so that brings me to the first talk that you've chosen, which is from Lera Boroditsky. Lera is a cognitive scientist, and she gave her talk in 2017. It's called \"How Language Changes The Way We Think\" (ph). OK, why was this - you were like, yes, I will pick talks for you, and we got to start with this one. Why? GUNTER: Because this changed a lot of things for me. I remember reading about this talk, like, when it came out, and I remember seeking it out and listening to it and then being like, whoa. Whoa. The idea that the words we use can shape our thoughts, I mean, it makes so much sense when you hear someone say it. But until someone actually studies it, how do you know? And then when you hear, like, wow, whether I think something is weak or strong could be affected by the words I choose for that, it's pretty powerful. (SOUNDBITE OF TED TALK)LERA BORODITSKY: There are about 7,000 languages spoken around the world, and all the languages differ from one another in all kinds of ways. Some languages have different sounds. They have different vocabularies. And they also have different structures. That begs the question, does the language we speak shape the way we think? Now, this is an ancient question. People have been speculating about this question for forever. Charlemagne, Holy Roman emperor, said, to have a second language is to have a second soul. Strong statement that language crafts reality. But on the other hand, Shakespeare has Juliet say, what's in a name? A rose by any other name would smell as sweet. Well, that suggests that maybe language doesn't craft reality. These arguments have gone back-and-forth for thousands of years. But until recently, there hasn't been any data to help us decide either way. ZOMORODI: OK, so we should say Lera was one of the first linguists to question what most experts in the field believed to be true, that all languages have a common underlying structure. So, you know, even though we make different sounds with our mouths or use different words, when we speak different languages, we're all pretty much thinking the same. But she says that over the past 20 years, that has been debunked. And, Jen, you told me that Lera had a big influence on you and how you think about things medically. Can you tell me why? GUNTER: Yeah. So I started thinking about, wow, if words affect, like, how we might think about things, if they can reversely craft our thoughts, if you will, I started to think about medical terms. Until relatively recently, you know, doctors learned Latin and Greek, and they learned all what all the roots meant. And I think some of that's been forgotten now, and I guess that's good. But the word pudendum, which is used to describe the sort of external genitalia, mostly for women, so the vulva and around the anal area - well, the Latin root for that, pudere, is to shame. And the clitoris - the root for that is to hide. And the hymen is named after the Greek god of marriage. ZOMORODI: Wow. GUNTER: Right? So we're actually - when we're seeing those words, we're imbuing those body parts with false information. ZOMORODI: It's such an interesting way to think about it. So I grew up speaking German to my mother. And German has gendered articles. And in Lera's talk, her section about how gendered language can affect how we view things, like literal things, was something I'd wondered about, like, for years. But she put a finer point on it. (SOUNDBITE OF TED TALK)BORODITSKY: Lots of languages have grammatical gender. So every noun gets assigned a gender, often masculine or feminine, and these genders differ across languages. So, for example, the sun is feminine in German but masculine in Spanish, and the moon the reverse. Could this actually have any consequence for how people think? Do German speakers think of the sun as somehow more female-like, the moon somehow more male-like? Actually, it turns out that's the case. So if you ask German and Spanish speakers to, say, describe a bridge, like the one here - bridge happens to be grammatically feminine in German, grammatically masculine in Spanish - German speakers are more likely to say bridges are beautiful, elegant, stereotypically feminine words, whereas Spanish speakers will be more likely to say they're strong or long, masculine words. ZOMORODI: That's fascinating. So as someone who talks a lot about gender, how does what Lera says about gendered language strike you, Jen? GUNTER: Well, first of all, I have to point out that I'm fascinated that long is a masculine word. (LAUGHTER)GUNTER: I think - and we all know why. ZOMORODI: Little too on the nose, right? GUNTER: Yeah. Exactly. I think it's fascinating because we assign physical qualities to gender. And we judge people by these physical qualities. And I don't think that's right. Any person can be beautiful. Any person can be strong. But these are sort of these - again, these stereotypical, patriarchal concepts that, you know, never really had any place in medicine or in language. But, you know, now that we know that gender is fluid and people shouldn't be judged by their gender, like, these are things that we should strive to move away from. These seem like a remnant of an older time that we should evolve from. ZOMORODI: I can just imagine some people listening would think like, oh, come on. Like, so these gendered pronouns, these are languages that have evolved over centuries. What do you want us to do? GUNTER: I guess what I would say is we evolve. And we change. And as we learn things, we take that in. And I think what we don't realize is so much of what we think is true or what we think is convention is actually something that's been forced upon us by those in power. And so why not evolve if it makes everything better for people? If we can change language to be more inclusive, to bring more people to the table, isn't that a good thing? I mean, I have a hard time finding downsides with that. ZOMORODI: So how we are influenced to think certain things is also at the heart of the next talk that you chose to bring us. It's from a man named James Randi, whom I had not heard of, but who was a very famous illusionist-turned-professional-debunker. I read with fascination his obit in the Times because he just died last year at the age of 92. The talk he gave in 2007 is called \"Homeopathy, Quackery And Fraud. \" And you - again, you were like, oh, we need to talk about this, about James Randi. What - have you always been a James Randi fan? (SOUNDBITE OF MUSIC)GUNTER: No, relatively recently. So yeah, I love how James Randi calls himself a conjurer. (SOUNDBITE OF TED TALK)JAMES RANDI: I have a very peculiar background, attitude and approach to the real world because I am a conjurer. I prefer that term over magician because if I were a magician, that would mean that I use spells and incantations and weird gestures in order to accomplish real magic. No. I don't do that. I'm a conjurer, who is someone who pretends to be a real magician. GUNTER: I didn't know, really, anything about the Amazing Randi or magic or anything until his organization asked me to speak a few years ago. ZOMORODI: Oh. GUNTER: And I think it's fascinating because, you know, people who practice snake oil, people who push quackery are essentially lying about being a conjurer. And magicians - or conjurers are honest about it, right? They're honest about it. And fun fact, I'm - you know, I'm now partnered with the love of my life, who's actually a magician (laughter). ZOMORODI: No. Come on. GUNTER: Yes. ZOMORODI: Perfect. GUNTER: Yeah. (SOUNDBITE OF TED TALK)RANDI: Now, how do we go about that sort of thing? We depend on the fact that audiences, such as yourselves, will make assumptions. For example, when I walked up here and I took the microphone from the stand and switched it on, you assumed this was a microphone, which it is not. (LAUGHTER)RANDI: As a matter of fact, this is something that about half of you - more than half of you will not be familiar with it. It's a beard trimmer - you see? - and makes a very bad microphone. I've tried it many times. ZOMORODI: (Laughter) OK. So James was holding a beard trimmer instead of a microphone. Jen, why do you think his talk has stuck with you? GUNTER: Well, I think that's how a lot of misinformation spreads. It's based on assumptions. And if you look at the marketing for a lot of, you know, snake oil or medical misinformation, you know, they use a lot of terms and rhetoric, terms like God words, terms where we fill in the blank about what we assume to be true. So if I say something is natural or I say something is ancient, you automatically fill in the blank that that thing is probably a good thing for you, right? ZOMORODI: Yeah. GUNTER: So when those marketing terms are used, they're being used because they know you will make an assumption about it. ZOMORODI: His life was very interesting in that he was a follow-up to a lot of Houdini's sort of, you know, getting out of boxes that were sunk in hundreds of feet of water, all kinds of things. But then sort of midway through his life, he stopped escaping and started, really, on this mission to try and help people who had sunk hundreds, thousands of dollars into things like seances, being contacted to the dead, homeopathic medicine. He had a big career switch. I guess you would say, though, that those two things are related in some ways. GUNTER: Absolutely, because all of these sort of fake medical things are using tricks. And they're preying on people. I mean, there's some - I don't know if you remember back in - I think it might have been the '80s, when people were performing that so-called, like, bloodless surgery, you know? They went to these other countries. And there were these incredible videos where it looked like people were plunging their hands into abdomens and pulling out diseased body parts. ZOMORODI: Oh, yes. Yes. GUNTER: Right. I think that's kind of how Randi maybe got sort of involved with it. Or there was - there were these sort of televangelists, sort of preacher types who would have these auditoriums filled with people. And you'd get healed, you know? And they'd call out the person - is Mary Smith (ph) here? Is Mary Smith here? And, of course, Mary Smith would come up. And then they'd say, well, oh, Mary Smith, you live here, and you have this daughter here. And, you know, the person was being fed all this information in an earpiece. So - you know, people are spending money. And if they have cancer, they're getting harmed - or they have an illness - because they might not be getting the treatment they need. ZOMORODI: Yeah. So homeopathic medicine, he definitely takes aim at that. And, Jen, what is your issue with homeopathic medicine? GUNTER: So homeopathy means something that has been diluted to the point where there's essentially, like, one molecule in - you know, like, diluted to the point where the water has memory of the original substance. That's. . . ZOMORODI: Oh, that's what it means? GUNTER: That's what homeopathy is. Yeah. It's - so you take something that's like the original thing, like a syphilitic ulcer, and you put it in water to - or alcohol or whatever - to make a solution. And then you dilute it out and dilute it out and dilute it out and dilute it out, you know, maybe, you know, a hundred times or 60 times or 1,000 times or whatever the dilution is. And then that product that you end up with is the homeopathic product. ZOMORODI: So that's different than a midwife saying, make sure you drink some of this herbal tea, which will stimulate your milk production. . . GUNTER: Right. ZOMORODI: . . . Or Chinese medicine and herbs. That's not considered homeopathy? GUNTER: No. Those are completely different things. And each one of those interventions deserves to be studied - right? - to see if they're effective or not, because you have to remember, if something is producing a biological effect, then there is something pharmaceutical about it, right? And so the assumption should not be that that is benign or safe, right? So, I mean, a tragic example is, you know, a lot of old-time recipes for menstrual problems, which was often a euphemism for being pregnant, but not always, involved a substance called pennyroyal, which is horribly toxic to the body and often fatal when consumed. It certainly can induce uterine contractions. But, you know, death of the person taking it's kind of an undesired side effect. So - yeah, so can this herbal thing produce the effect? If it's producing an effect, you should be able to prove it. ZOMORODI: You mentioned this very briefly at the beginning of our conversation, but you have a lot of empathy. You've written that you have a lot of empathy for people who do want to believe all kinds of things because of a personal tragedy that you had. Can you just elaborate a little bit more about what you think the mindset is? GUNTER: Sure. I mean, you're desperate, you know? When my kids were in the intensive care unit and my son, you know, 1 pound, 11 ounces - and on top of that, he was diagnosed with an uncommon heart defect, nothing to do with being premature - right? - so just one bad thing on top of another. And he needed to have surgery to fix this complex heart defect, but he was too small for the equipment, you know? And I had another son who vomited after every single feed because his - just his - you know, his whole system wasn't developed yet. And so the first two years of his life, everything was a vomit, you know? I smelt - the back of my hair smelt like vomit - I'm not kidding - for two years. And, you know, he developed all kinds of - he couldn't eat solid food because of that because it's worse to vomit up solids than it is to vomit up liquids. ZOMORODI: Right. GUNTER: He didn't have his first solid food until he was 3 1/2. ZOMORODI: Wow. GUNTER: So I got lost in all these food blogs and food allergy things and - because you're desperate. I mean, here I've got this - you know, my son is 3. He hasn't eaten a bite of solid food. You can't even put it on his lip - and he freaks out. And you've done everything medicine has given you. You've done everything. You've gone to three different occupational therapists. You've tried this. You've tried that. You've had these interventions. And you're in this space where there is nothing to do but to wait. And it's a very vulnerable place to be. So I get it. ZOMORODI: I mean, it goes back to what you said before about knowledge and accurate information being crucial. And, I mean, I guess it's - feels or seems strange to lump homeopathic medicine and belief in the supernatural with misinformation in general. But I think what I'm hearing you say is that, especially for people who are in that vulnerable space, they can be gateways in some way. GUNTER: Yeah. I think that social media and the way we consume news in this 24/7 news cycle is this toxic combination that lets misinformation just metastasize, because there's this concept called the illusory truth effect. We all mistake repetition for accuracy. And so if you see the same story on your Instagram feed - and maybe you see it two or three times because maybe several influencers that you follow post it. And then you see it on your Facebook feed because what chases you on Facebook - what you saw on Instagram, right? ZOMORODI: Yeah. GUNTER: And then you see some people. And then maybe you decide, oh, look; there's this Facebook community that was recommended for me. And all these people seem nice. And then you get in there. And then all of a sudden, they're talking about conspiracy theories. And maybe you heard about that somewhere, but you don't quite remember where. It's really - we've created this echo chamber where the misinformation reverberates. And you know what? The misinformation is often fantastical and a bit like, whoa. And the truth is so stodgy and boring sometimes. And so how do you have - how does the stodgy truth about - you know, about the immune system, you know, how does that compete with it, you know? - like, wah-wah, wah-wah, wah-wah, and, you know, like in the \"Peanuts\" comic. And we have to learn to communicate in ways that people can hear. (SOUNDBITE OF MUSIC)ZOMORODI: In a minute, more from Dr. Jen Gunter and her mission to talk openly about basic bodily functions, like defecating. Today on the show, The Truth About Our Bodies. I'm Manoush Zomorodi, and you're listening to the TED Radio Hour from NPR. Stay with us. (SOUNDBITE OF MUSIC)ZOMORODI: It's the TED Radio Hour from NPR. I'm Manoush Zomorodi. Today on the show, debunking misinformation, stigma and shame about our bodies. Our guide through a selection of TED Talks is physician, author and podcaster Jen Gunter. And one topic in particular that Jen wants to demystify for us is poop. GUNTER: Everybody poops. This is one of those things people never talk about, but. . . ZOMORODI: So true. GUNTER: Like, why is your poop any more shameful than your runny nose? That's what I want to know. ZOMORODI: It doesn't smell the same, does it? OK, wait. We're going to get to that. GUNTER: (Laughter). ZOMORODI: But let's start with the talk that you have brought us, which is by Dr. Giulia Enders, called \"The Surprisingly Charming Science Of Your Gut. \"(SOUNDBITE OF TED TALK)GIULIA ENDERS: It took me three steps to love the gut. And the very first was just looking at it and asking questions like, how does it work and why, maybe, does it have to look so weird for that sometimes? And it actually wasn't me asking the first kind of these questions, but my roommate. So after one heavy night of partying, he came into our shared-room kitchen, and he said, Giulia, you study medicine. How does pooping work? (LAUGHTER)ENDERS: And I did study medicine, but I had no idea, so I had to go up to my room and look it up in different books. And I found something interesting, I thought, at that time. So it turns out we don't only have this outer sphincter. We also have an inner sphincter muscle. The outer sphincter we all know. We can control it. We know what's going on there. The inner one, we really don't. So what happens is when there are leftovers from digestion, they're being delivered to the inner one first. So this inner one will open in a reflex and let through a little bit for testing. So there are sensory cells that will analyze what has been delivered. Is it gaseous or is it solid? And they will then send this information up to our brain. And this is the moment when our brain knows, oh, I have to go to the toilet. ZOMORODI: I mean, is she - she's the most charming doctor. She's just the best. And it really - it reminds me of a friend of mine who I used to go on a lot of work trips with, and he used to go, (imitating trumpet). And that was - the trumpet noise was when he had to excuse himself. But most people are not that comfortable - well, other than little kids - are not that comfortable about talking openly about the need to go or pooping, right? GUNTER: Right. But they want to be (laughter). ZOMORODI: That is true. Tell me more about that. GUNTER: You know, I talk a lot about poop in the office, how to have bowel movement. I take care of a lot of people who have pelvic pain. And a lot of times, that's related to the same muscles that you use for defecation, to have a bowel movement. So there's a lot of crossover. And so chronic constipation can actually lead to pelvic pain and vice versa. So I'm always talking to people like, do you mechanically know how to have a bowel movement? And people are like, there's a way? I'm like, there is. We talk about, you know, that - why you really need to have fiber, why you really need to have these things. You know, people - we say, oh, you must have fiber; you must have fiber. But people want to know the why. They want to know the why. (SOUNDBITE OF TED TALK)ENDERS: Like, those funny rumbling noises that happen when you're in a group of friends or at the office conference table going like, (imitating stomach rumbling). This is not because we're hungry. This is because our small intestine's actually a huge neat freak, and it takes the time in between digestion to clean everything up, resulting in those eight meters of gut - really, seven of them - being very clean and hardly smell like anything. It will, to achieve this, create a strong muscular wave that moves everything forward that's been left over after digestion. This can sometimes create a sound but doesn't necessarily have to always. So what we're embarrassed of is really a sign of something keeping our insides fine and tidy. ZOMORODI: Can we just clarify one thing? First of all, I need to know about the right way to poop. And second of all, poop is basically just waste, right? GUNTER: Right, absolutely. It's all the leftovers that you don't need, plus cells from the lining of your colon and bacteria and indigestible fiber, the - you know, sort of the nonsoluble fiber. So, yeah, so the leftovers, if you will, and some other stuff along for the ride. You know, there might be a little bit of gas that a lot of us might think smells a bit like sulfur, and it's because of the bacteria, right? So we depend on bacteria inside our bodies to help with digestion, to help with so many things. I mean, we have this important microbiome. And I think also, too, you know, a lot of our misconceptions about the colon come from before we knew about the microbiome, actually, right? ZOMORODI: Oh, yeah. GUNTER: So it's sort of a different story to say, well, you have gas because you normally have this bacteria that's helping you break down food and produce vitamins, and it's really important part of your health, and so you should be proud of your sulfur. . . ZOMORODI: Yeah. GUNTER: . . . Because that means you've got a healthy microbiome - right? - as opposed to, you should be ashamed of it. ZOMORODI: OK, I'm going to try. But I should say, you know, earlier we mentioned that you are now doing a podcast. It's called \"Body Stuff. \" And this talk, the one that we've been discussing, is - it particularly speaks to you because you have an entire episode dedicated to poop. And you talk to a rather unusual expert who says we were not always so embarrassed to talk about it. GUNTER: So we talked to Dr. Barbara Penner, who's an architectural historian. And, you know, she wrote a book called \"Bathroom\" about how toilet design and ideas about poop have, I guess, shaped each other. And that's one of the great things about expanding your search for knowledge beyond, like, just medicine. Like, medicine's part of society. Like, you have to look at all of society to understand where we are. ZOMORODI: Right, which is exactly what you and Dr. Barbara Penner explain in your podcast. (SOUNDBITE OF PODCAST, \"BODY STUFF\")BARBARA PENNER: If we look at pre-modern times, let's say pre-18th century, there are loads of examples of two- and three-seater outhouses. GUNTER: Seats for people to poop side by side. PENNER: And these really remind us that there just was not the same sense of shame around bodily functions. And we know that for many people, going to the toilet could even be a time for socializing. GUNTER: And that was totally normal until the 19th century, the Victorian era in England. That's when indoor plumbing became much more available in England and the U. S. , and it's when we learned more about how disease is spread. ZOMORODI: OK, so let's time travel back to today. And the goal with pooping, I mean, I think it's pretty fair to say, is that everyone just wants their - sorry, listeners, to speak for you, but everyone (laughter) wants their poop to be regular and normal, like once a day, fully formed. Is that the right goal? GUNTER: Well, yes and no. Their poop should be regular for them. So what's regular and normal for me might not be regular and normal for you. You want the system to be working fine. So if once a day is what happens for you, that's great. If it's twice a day, that's fine. If it's every other day, that's OK. You know, so instead of thinking about, like, how often, you should think about more, like, is there any discomfort? Am I feeling unwell otherwise? Is there blood in my stool, which is certainly a very concerning sign and should always be reported to your doctor? You should just think about it in terms of health. I always think your body's kind of working the best when you're not really thinking about it. ZOMORODI: Yeah. GUNTER: And also a change - people should be aware of changes. So if everything was going right, and then all of a sudden there's a change for you, then that's something to think about. ZOMORODI: What I like about you, Jen, though, is that you don't just talk about the negative stuff. You also talk about the positive stuff. And in this episode about poop, you have an expert with you, and you introduce some terminology that I had never heard called poo-phoria, which is the lovely side of pooping. GUNTER: Yes. Our doctor of poo-ology (laughter), our gastroenterologist is Dr. Anish Sheth. And he wrote the book \"What Your Poo Is Telling You\" (ph). (SOUNDBITE OF PODCAST, \"BODY STUFF\")GUNTER: So what's a monster poo? ANISH SHETH: Monster poo just means you're just having a large, huge bowel movement. When you have a monster poo, you can experience this sort of sense of joy and elation that we call poo-phoria, right? It comes from sort of distending the rectum, which we talked about as being a very sensitive area, and then having it decompress sort of in a single bolus of stool as it comes out. And that sometimes just makes us, like, feel great, like you want to high-five the first person you see when you come out of the toilet. ZOMORODI: (Laughter) Has making this episode changed the way that you approach your own bathroom time, Jen? Is that too personal a question to ask you on public radio? GUNTER: You can ask me anything. I, like. . . ZOMORODI: OK. GUNTER: Seriously, I have, like, no shame. I'm the person that when, like - well, back in the before time, when you used to try on bras in the department store, I'd just, like, walk out of the change room going, does this one fit? ZOMORODI: (Laughter). GUNTER: So I think - I mean, I knew - I would say I knew most of the medicine. But I've always been a fiber evangelical, but I've certainly even doubled down more. Like, fiber is the way. ZOMORODI: Fiber is the way. GUNTER: Fiber is the way. ZOMORODI: But don't go too crazy, right? GUNTER: Well, you can, yeah. I mean, you can. I have on occasion found out that sometimes you can overdo it and get a little gastric distress. But when your stool moves along as it should, when it's not hard and scratchy, you lower your risk of getting hemorrhoids. And no one is ever happy with hemorrhoids. ZOMORODI: No. OK, for those poor souls who don't know, why do we need fiber? Why is fiber so important? What does it do? GUNTER: Fiber - ooh. People should talk about fiber like it's sexy 'cause it is. It's good for your body. One, it's really important because some fiber function is prebiotics. So for your colon, it helps you produce more good bacteria. Fiber draws water into the stool, making it softer, and then it's less scratchy when it comes out. Think of it like a sponge, a poo sponge. That's what fiber is. It's a poo sponge. ZOMORODI: Do I have to? Like. . . GUNTER: Yeah. ZOMORODI: All right. GUNTER: It's a great way to think about it. We're giving it an upgrade. ZOMORODI: OK. GUNTER: So fiber draws water into the stool, and that increases the bulk. And the bulk of the stool helps stimulate the colon to move the stool along. ZOMORODI: So, you know, listening to you, I feel like we need to have, like, a call-in show or something. But what's your advice for making sure we ask our doctors the right questions? Because we need to be more fearless, too - right? - about bringing up issues that we might feel, oh, it's nothing or we feel squeamish about it or, you know, it's embarrassing. It's too - it's a human, right? GUNTER: Well, I think - you know, I hate to put the onus on the patient because the doctor should be creating a welcoming environment for that. A lot of things in medicine occupy this in-between, this land of in-between where, you know, how to have a bowel movement isn't really, like, a medical problem. ZOMORODI: Right. GUNTER: But if it's not done right, it can be, right? So it's the same thing, like, with, like, how to wash your vulva. It's not - that's not really, like, medicine. But if it's done wrong, it is. So, you know, these are areas I think medicine needs to step up. It's like practical information people need so they can live their lives. It really should be part of health maintenance and disease prevention. ZOMORODI: So let's say someone is thinking, well, it's not really a problem, at least not yet, so I'm not going to bother with going to the doctor's office. But then how can people find the right health information online? GUNTER: Yeah. I mean, I think it's natural for people to want to research what's going on with their bodies online. You know, write down what's bothering you or what's concerning you, and think about what organ system you might think that involves. So, for example, if it's your poo, you're having a problem having a bowel movement, I would go to the American Gastrointestinal Association (ph), and then I would see what the experts have to say. Or the American Academy of Family Physicians - great place to start. You know, or if it's an OB-GYN question, start with, you know, the American College of OB-GYN. I think people forget that medical professional societies actually have great information online. That's a good place to start. And the National Library of Medicine and the Centers for Disease Control - they all have great information. ZOMORODI: Can I just ask one thing that I've been wondering might be adding to this problem of lack of information about our bodies - is, at least in my experience, how specialized Western medicine has become. Like, if you go to see a podiatrist, they are definitely going to say, like, yup, it's a foot problem, as opposed to maybe it's a problem with, you know, your back or other ways that you carry yourself. Like, we don't treat the body very holistically here in the United States. Is that part of the problem? And - I don't know - do you see this changing at all as we look forward into the future? GUNTER: Yeah. So I think that one of the root causes of many problems is the lack of investment in primary care. You know, we have these amazing family physicians, these amazing pediatricians, you know, these amazing front-line doctors who are not subspecialized. Their specialty is all of you, right? And how can they look after all of you in 15 or 20 minutes? ZOMORODI: No, right. GUNTER: So to me, one of the root causes of problems, certainly in North America, is this idea that we are fairly well situated to manage acute problems. You have a sore throat, you come in, you get checked for strep throat. You break your toe, you come in, you get your toe splinted. You know, you have this acute problem, and you come in and get it fixed. But many of us also then get stuck in this idea that problems can be fixed. But a lot of medicine is chronic care, right? It's things that don't go away with a pill or a surgery. Or maybe those things can help, but they're part of the long-term management. And we need to invest in systems that account for that. ZOMORODI: Going back to the debunking of health myths, your specialty, how much do you worry that the - we're sort of entering a period that is ripe for more of this, considering the sort of post - hopefully post-COVID era where we're talking about long-haul symptoms? We don't know a lot about it. There are starting to be studies, but there aren't that many. It seems like there are going to be a lot of very vulnerable people looking for answers to feel better for a very long time to come. GUNTER: Yeah, I think that is definitely ripe for charlatans to take advantage of it. I think also, too, you know, many people who have unstudied medical conditions, and certainly something like long COVID is something that is obviously unstudied, in part because it's so new - I think that a lot of times, doctors really just also need to say, I don't know; I don't have an answer, instead of brushing somebody off as, no, that can't be or, let me doctor-splain (ph) that to you. When I'm honest - because I deal with chronic pain every day. I deal with a lot of conditions that are - that don't have easy fixes. And sometimes I sit down with people, and I sort of say, yeah, that sucks. You are right. We don't have this information. You are right. And I think that sometimes people want to hear that. And I think when people have difficult illnesses or illnesses that don't have answers, they get that you might not have an immediate cure. But when you say that - I don't know, but let's work on this together - I think that's welcoming. And I - so I think medicine has to figure out how to be more welcoming, how to advocate for studying things, how to look at the way we allocate research funds to make sure that we're bringing everything to the table. One thing the pandemic has shown us is that if you throw a lot of money and a lot of smart minds at things, you can solve a difficult problem pretty quickly. That's kind of a hopeful thing. (SOUNDBITE OF MUSIC)ZOMORODI: Thank you again to Dr. Jen Gunter for spending the hour with us. You can find \"Body Stuff With Dr. Jen Gunter\" wherever you listen to podcasts. (SOUNDBITE OF MUSIC)ZOMORODI: This episode was produced by Christina Cala and Matthew Cloutier, and it was edited by Sanaz Meshkinpour. Our TED Radio production staff also includes Jeff Rogers, Rachel Faulkner, Diba Mohtasham, James Delahoussaye, J. C. Howard, Katie Monteleone, Janet Lee and Fiona Geiran. Our audio engineer is Daniel Shukin (ph). Our theme music was written by Ramtin Arablouei. Our partners at TED are Chris Anderson, Colin Helms, Anna Phelan and Michelle Quint. I'm Manoush Zomorodi, and you've been listening to the TED Radio Hour from NPR. MANOUSH ZOMORODI, HOST:   It's the TED Radio Hour from NPR. I'm Manoush Zomorodi. Today on the show, how we learn about our bodies and tell fact from fiction. JEN GUNTER: Well, I think the issue is the medical internet is both amazing and is awful. And it shouldn't be that kind of crapshoot. ZOMORODI: This is Dr. Jen Gunter. GUNTER: I am an OB-GYN and a pain medicine physician and an author and podcaster. ZOMORODI: Jen is also internet famous for calling out celebrities who share misinformation about health and wellness. GUNTER: I would say that my mission is to give people factual, accessible information about their health because I want people to be empowered about your health. But you can only be empowered with accurate information. ZOMORODI: And for her, part of empowering people is to write guides to traditionally taboo women's health topics, including one called \"The Vagina Bible\" and her latest, \"The Menopause Manifesto. \" She also recently started a podcast called \"Body Stuff. \" (SOUNDBITE OF PODCAST, \"BODY STUFF\") GUNTER: I'm Dr. Jen Gunter. I love science. And I hate [expletive]. ZOMORODI: In 2019, Jen gave a TED Talk called \"Why Can't We Talk About Periods? \" And today she's brought us a selection of TED Talks, ones that have influenced her as she's become an outspoken critic on how society uses language and psychological tactics to shame and trick people about their basic bodily functions. Her story goes back 17 years ago when Jen herself was having a health crisis. GUNTER: I initially got interested in how people access information online because I was in that position. And so that really started it, when I had my pregnancy. And I had a triplet pregnancy, but it was incredibly complicated. And one of my sons died at birth, and my other two boys were in the intensive care unit for a long time. ZOMORODI: I'm so sorry. GUNTER: And so - and they had all these other medical problems as well as prematurity. And when I didn't get answers from my own doctors, I went online. And I was horrified. This was sort of the earlier stages of the medical internet, if you will. And I just thought, wow. If it's so hard for me to get practical information, like, useful information that can help me today. . . ZOMORODI: As a physician. GUNTER: Right. As a physician caring for my babies, right? Like, I wanted help. I wanted - there's gaps in medicine. You know, your doctors can tell you stuff. But they can't tell you, like, what are the tips and tricks for taking your babies out in a stroller when you have two children on oxygen, right? ZOMORODI: Oh, my gosh. GUNTER: Like, those are things that other experienced parents can tell you. But then, how do you know you're getting that right information? So I realized there were so many gaps that were important but not covered by medicine and how easy it was to fall down snake oil-filled rabbit holes, for lack of a better word. And I just thought if I was struggling like this - me, this person who's always been obsessed with evidence-based medicine - how was everyone else managing? And so I decided that I was going to fix the medical internet. ZOMORODI: (Laughter) Just a small goal, really, Jen? GUNTER: Right. That's - I was very naive about it. ZOMORODI: OK. So naive, but absolutely driven. And you're still doing that. And we're going to talk about some of the talks that have sort of propelled you as you try to fix the medical internet. But first, let's talk about your own talk. It's called \"Why Can't We Talk About Periods? \" And, Jen, from what I understand, you had absolutely terrible periods as a teenager. But you felt like you didn't have anyone to really talk to about your symptoms. GUNTER: Right. I mean, as far as my mother was concerned, you didn't talk about anything from down there. And she suffered with periods. So suck it up, sister. (LAUGHTER) GUNTER: And, yeah, so there was just - there's no information. And so I spent two days each month curled up with a heating pad. I couldn't go to school. And, you know, why was this happening? Why was I suffering so much? And it just felt to me like this big biological flaw. ZOMORODI: And did you ask your doctor, like, what is going on? GUNTER: I think I didn't actually get taken to one until maybe I was like 16. So I'd been suffering for, you know, several years. And my mother took me to her doctor, who basically said, yeah, period. Yeah. That's it. So basically, you know, it was just no practical information. And it's sad to me that, you know, that happened in the, I guess, early 1980s and that I still hear that same story from young women today. (SOUNDBITE OF MUSIC) ZOMORODI: And in your talk, you go back to kind of the historical roots of why you didn't have any access to information and you felt ashamed of this bodily function. (SOUNDBITE OF TED TALK) GUNTER: Why can't we talk about periods? And it's not about the blood, as Freud would have you say, because if it were, there'd be an ear, nose and throat surgeon up here right now talking about the taboos of nosebleeds, right? And it's not even about periods because otherwise, when we got rid of our toxic, shameful periods when we became menopausal, we'd be elevated to a higher social status. (LAUGHTER, APPLAUSE) GUNTER: It's just a patriarchal society is invested in oppressing women. And at different points in our lives, different things are used. And menstruation is used during what we in medicine call the reproductive years. It's been around since pretty much the beginning of time. Many cultures thought that women could spoil crops or milk or wilt flowers. And then when religion came along, purity myths only made that worse. And medicine wasn't any help. In the 1920s and '30s, there was the idea that women elaborated something called a menotoxin (ph). We could wilt flowers just by walking by. ZOMORODI: OK, so how have things changed? Let's fast-forward to when you were becoming a gynecologist. Are doctors taught - well, I guess there's two things. Were they taught, when you were in medical school, to speak more frankly about this stuff? And what about today when you talk to medical students? You know, what's the status quo now? GUNTER: Well, certainly, in the realm of gynecology, these words have always been used. But the publicability, this ability to talk outside of an office, is, I think, relatively new, right? ZOMORODI: Yeah, yeah. GUNTER: You know, '50s, '60s, '70s, '80s, your uterus is trouble; we don't hear about it. You know, really, I think it's sort of taken social media and being online to sort of raise the noise level enough that the conversation is catching. ZOMORODI: That's exactly what you do in your talk. You tell the audience what you tell your patients about how their periods work. (SOUNDBITE OF TED TALK) GUNTER: Well, what if everybody knew about periods like a gynecologist? Wouldn't that be great? Then you would all know what I know. You'd know that menstruation is a pretty unique phenomenon among mammals. Most mammals have estrous. Humans, some primates, some bats, the elephant shrew and the spiny mouse menstruate. And with menstruation, what happens is the brain triggers the ovary to start producing an egg. Estrogen is released, and it starts to build up the lining of the uterus, cell upon cell, like bricks. And what happens if you build a brick wall too high without mortar? Well, it's unstable. So what happens when you ovulate? You release a hormone called progesterone, which is progestational. It gets the uterus ready. It acts like a mortar, and it holds those bricks together. It also causes some changes to make the lining more hospitable for implantation. If there's no pregnancy, lining comes out. There's bleeding from the blood vessels, and that's the period. And I always find this point really interesting because with estrous, the final signaling to get the lining of the uterus ready actually comes from the embryo. But with menstruation, that choice comes from the ovary. It's as if choice is coded in to our reproductive tract. (CHEERING) ZOMORODI: You got big cheers there. You get a little political there at the end, Jen. Do you think politics and medicine - I mean, clearly they've always been intertwined when it comes to women and reproduction. Have they always been intertwined for you? GUNTER: I think so. You know, when I started in medical school, to get an abortion in Manitoba required approval of a three-person panel, and you didn't even get the privilege of pleading your own case in person. You told your family doctor, who then submitted a letter on your behalf. ZOMORODI: Wow. GUNTER: How wrong is that? And throughout the history of humanity, how medicine has been accessed for women is different than how it has been accessed by the people in power, men. And so, yeah, I think if you want to care for people and you want to help them medically, politics is simply part of it. ZOMORODI: There are a lot of folks, of course, who either because they can't or they won't go see a doctor, they look for information online now. You know, you go - back in the day, you'd go to the library. Nobody's there trying to sell you products at the same time - right? - whether that's to promote cleanliness or vagina health or, like - I actually was at the doctor's office today, and they were touting a three-pack. After you give birth, you know, come back. We'll slim down your tummy and tighten up your pores and, like, three procedures, plastic surgery procedures, for the low, low price of like - I think it was $7,500. I was like, what? That - huh? There's this overlap between medicine and the commoditization of what women need to do to be healthy/well/look good. GUNTER: Yeah. Every now and then, I get messages from people who've been at the gynecologist. And while they're sitting there waiting, wearing a robe, naked in the office, they look on the wall, and there's an advertisement for some kind of vaginal enhancement procedure. And. . . ZOMORODI: I saw that. GUNTER: Yeah. And how at your most vulnerable - you're naked in a doctor's office and you see that. And you're supposed to be there to get factual, accurate information about your vagina, your vulva, your body. And to have this implication on the wall that there's something troublesome with your body, I have a problem with that. I think that cosmetic procedures need to not be folded in with annual exams and seeking care for medical problems. ZOMORODI: So let's go back to your talk. Part of being able to look away from a lot of these advertisements or be like, that's ridiculous, is knowing how your body works, right? GUNTER: Exactly. Information is power. Knowledge is power. (SOUNDBITE OF TED TALK) GUNTER: It shouldn't be an act of feminism to know how your body works. It shouldn't. . . (APPLAUSE) GUNTER: It shouldn't be an act of feminism to ask for help when you're suffering. The only curse here is the ability to convince half the population that the very biological machinery that perpetuates the species, that gives everything that we have is somehow dirty or toxic. And I'm not going to stand for it. (APPLAUSE) GUNTER: And the way we break that curse - it's knowledge. ZOMORODI: In a minute, we'll be back with physician and author Jen Gunter and more facts about how our bodies work. I'm Manoush Zomorodi, and you're listening to the TED Radio Hour from NPR. Stay with us. It's the TED Radio Hour from NPR. I'm Manoush Zomorodi. And today, our guest is Dr. Jen Gunter. She's a practicing OB-GYN and physician but has also made a name for herself debunking celebrity wellness trends and helping us make informed decisions about our health. GUNTER: Yeah. I mean, I think debunking is an extension of my quest to know. All sort of misinformation, you know, has this root in not being informed. And I just think that so much of medicine is not that difficult. It might be complex. And obviously you don't need to know all of the nuances of everything to have a good working knowledge. But the good working knowledge - a lot of it's not really that hard. It's just our ivory tower makes it seem like it is. And so I want that to be as accessible to everyone as it is to me. ZOMORODI: That, I think, is the common theme of all the talks that you have chosen for us this hour. And so that brings me to the first talk that you've chosen, which is from Lera Boroditsky. Lera is a cognitive scientist, and she gave her talk in 2017. It's called \"How Language Changes The Way We Think\" (ph). OK, why was this - you were like, yes, I will pick talks for you, and we got to start with this one. Why? GUNTER: Because this changed a lot of things for me. I remember reading about this talk, like, when it came out, and I remember seeking it out and listening to it and then being like, whoa. Whoa. The idea that the words we use can shape our thoughts, I mean, it makes so much sense when you hear someone say it. But until someone actually studies it, how do you know? And then when you hear, like, wow, whether I think something is weak or strong could be affected by the words I choose for that, it's pretty powerful. (SOUNDBITE OF TED TALK) LERA BORODITSKY: There are about 7,000 languages spoken around the world, and all the languages differ from one another in all kinds of ways. Some languages have different sounds. They have different vocabularies. And they also have different structures. That begs the question, does the language we speak shape the way we think? Now, this is an ancient question. People have been speculating about this question for forever. Charlemagne, Holy Roman emperor, said, to have a second language is to have a second soul. Strong statement that language crafts reality. But on the other hand, Shakespeare has Juliet say, what's in a name? A rose by any other name would smell as sweet. Well, that suggests that maybe language doesn't craft reality. These arguments have gone back-and-forth for thousands of years. But until recently, there hasn't been any data to help us decide either way. ZOMORODI: OK, so we should say Lera was one of the first linguists to question what most experts in the field believed to be true, that all languages have a common underlying structure. So, you know, even though we make different sounds with our mouths or use different words, when we speak different languages, we're all pretty much thinking the same. But she says that over the past 20 years, that has been debunked. And, Jen, you told me that Lera had a big influence on you and how you think about things medically. Can you tell me why? GUNTER: Yeah. So I started thinking about, wow, if words affect, like, how we might think about things, if they can reversely craft our thoughts, if you will, I started to think about medical terms. Until relatively recently, you know, doctors learned Latin and Greek, and they learned all what all the roots meant. And I think some of that's been forgotten now, and I guess that's good. But the word pudendum, which is used to describe the sort of external genitalia, mostly for women, so the vulva and around the anal area - well, the Latin root for that, pudere, is to shame. And the clitoris - the root for that is to hide. And the hymen is named after the Greek god of marriage. ZOMORODI: Wow. GUNTER: Right? So we're actually - when we're seeing those words, we're imbuing those body parts with false information. ZOMORODI: It's such an interesting way to think about it. So I grew up speaking German to my mother. And German has gendered articles. And in Lera's talk, her section about how gendered language can affect how we view things, like literal things, was something I'd wondered about, like, for years. But she put a finer point on it. (SOUNDBITE OF TED TALK) BORODITSKY: Lots of languages have grammatical gender. So every noun gets assigned a gender, often masculine or feminine, and these genders differ across languages. So, for example, the sun is feminine in German but masculine in Spanish, and the moon the reverse. Could this actually have any consequence for how people think? Do German speakers think of the sun as somehow more female-like, the moon somehow more male-like? Actually, it turns out that's the case. So if you ask German and Spanish speakers to, say, describe a bridge, like the one here - bridge happens to be grammatically feminine in German, grammatically masculine in Spanish - German speakers are more likely to say bridges are beautiful, elegant, stereotypically feminine words, whereas Spanish speakers will be more likely to say they're strong or long, masculine words. ZOMORODI: That's fascinating. So as someone who talks a lot about gender, how does what Lera says about gendered language strike you, Jen? GUNTER: Well, first of all, I have to point out that I'm fascinated that long is a masculine word. (LAUGHTER) GUNTER: I think - and we all know why. ZOMORODI: Little too on the nose, right? GUNTER: Yeah. Exactly. I think it's fascinating because we assign physical qualities to gender. And we judge people by these physical qualities. And I don't think that's right. Any person can be beautiful. Any person can be strong. But these are sort of these - again, these stereotypical, patriarchal concepts that, you know, never really had any place in medicine or in language. But, you know, now that we know that gender is fluid and people shouldn't be judged by their gender, like, these are things that we should strive to move away from. These seem like a remnant of an older time that we should evolve from. ZOMORODI: I can just imagine some people listening would think like, oh, come on. Like, so these gendered pronouns, these are languages that have evolved over centuries. What do you want us to do? GUNTER: I guess what I would say is we evolve. And we change. And as we learn things, we take that in. And I think what we don't realize is so much of what we think is true or what we think is convention is actually something that's been forced upon us by those in power. And so why not evolve if it makes everything better for people? If we can change language to be more inclusive, to bring more people to the table, isn't that a good thing? I mean, I have a hard time finding downsides with that. ZOMORODI: So how we are influenced to think certain things is also at the heart of the next talk that you chose to bring us. It's from a man named James Randi, whom I had not heard of, but who was a very famous illusionist-turned-professional-debunker. I read with fascination his obit in the Times because he just died last year at the age of 92. The talk he gave in 2007 is called \"Homeopathy, Quackery And Fraud. \" And you - again, you were like, oh, we need to talk about this, about James Randi. What - have you always been a James Randi fan? (SOUNDBITE OF MUSIC) GUNTER: No, relatively recently. So yeah, I love how James Randi calls himself a conjurer. (SOUNDBITE OF TED TALK) JAMES RANDI: I have a very peculiar background, attitude and approach to the real world because I am a conjurer. I prefer that term over magician because if I were a magician, that would mean that I use spells and incantations and weird gestures in order to accomplish real magic. No. I don't do that. I'm a conjurer, who is someone who pretends to be a real magician. GUNTER: I didn't know, really, anything about the Amazing Randi or magic or anything until his organization asked me to speak a few years ago. ZOMORODI: Oh. GUNTER: And I think it's fascinating because, you know, people who practice snake oil, people who push quackery are essentially lying about being a conjurer. And magicians - or conjurers are honest about it, right? They're honest about it. And fun fact, I'm - you know, I'm now partnered with the love of my life, who's actually a magician (laughter). ZOMORODI: No. Come on. GUNTER: Yes. ZOMORODI: Perfect. GUNTER: Yeah. (SOUNDBITE OF TED TALK) RANDI: Now, how do we go about that sort of thing? We depend on the fact that audiences, such as yourselves, will make assumptions. For example, when I walked up here and I took the microphone from the stand and switched it on, you assumed this was a microphone, which it is not. (LAUGHTER) RANDI: As a matter of fact, this is something that about half of you - more than half of you will not be familiar with it. It's a beard trimmer - you see? - and makes a very bad microphone. I've tried it many times. ZOMORODI: (Laughter) OK. So James was holding a beard trimmer instead of a microphone. Jen, why do you think his talk has stuck with you? GUNTER: Well, I think that's how a lot of misinformation spreads. It's based on assumptions. And if you look at the marketing for a lot of, you know, snake oil or medical misinformation, you know, they use a lot of terms and rhetoric, terms like God words, terms where we fill in the blank about what we assume to be true. So if I say something is natural or I say something is ancient, you automatically fill in the blank that that thing is probably a good thing for you, right? ZOMORODI: Yeah. GUNTER: So when those marketing terms are used, they're being used because they know you will make an assumption about it. ZOMORODI: His life was very interesting in that he was a follow-up to a lot of Houdini's sort of, you know, getting out of boxes that were sunk in hundreds of feet of water, all kinds of things. But then sort of midway through his life, he stopped escaping and started, really, on this mission to try and help people who had sunk hundreds, thousands of dollars into things like seances, being contacted to the dead, homeopathic medicine. He had a big career switch. I guess you would say, though, that those two things are related in some ways. GUNTER: Absolutely, because all of these sort of fake medical things are using tricks. And they're preying on people. I mean, there's some - I don't know if you remember back in - I think it might have been the '80s, when people were performing that so-called, like, bloodless surgery, you know? They went to these other countries. And there were these incredible videos where it looked like people were plunging their hands into abdomens and pulling out diseased body parts. ZOMORODI: Oh, yes. Yes. GUNTER: Right. I think that's kind of how Randi maybe got sort of involved with it. Or there was - there were these sort of televangelists, sort of preacher types who would have these auditoriums filled with people. And you'd get healed, you know? And they'd call out the person - is Mary Smith (ph) here? Is Mary Smith here? And, of course, Mary Smith would come up. And then they'd say, well, oh, Mary Smith, you live here, and you have this daughter here. And, you know, the person was being fed all this information in an earpiece. So - you know, people are spending money. And if they have cancer, they're getting harmed - or they have an illness - because they might not be getting the treatment they need. ZOMORODI: Yeah. So homeopathic medicine, he definitely takes aim at that. And, Jen, what is your issue with homeopathic medicine? GUNTER: So homeopathy means something that has been diluted to the point where there's essentially, like, one molecule in - you know, like, diluted to the point where the water has memory of the original substance. That's. . . ZOMORODI: Oh, that's what it means? GUNTER: That's what homeopathy is. Yeah. It's - so you take something that's like the original thing, like a syphilitic ulcer, and you put it in water to - or alcohol or whatever - to make a solution. And then you dilute it out and dilute it out and dilute it out and dilute it out, you know, maybe, you know, a hundred times or 60 times or 1,000 times or whatever the dilution is. And then that product that you end up with is the homeopathic product. ZOMORODI: So that's different than a midwife saying, make sure you drink some of this herbal tea, which will stimulate your milk production. . . GUNTER: Right. ZOMORODI: . . . Or Chinese medicine and herbs. That's not considered homeopathy? GUNTER: No. Those are completely different things. And each one of those interventions deserves to be studied - right? - to see if they're effective or not, because you have to remember, if something is producing a biological effect, then there is something pharmaceutical about it, right? And so the assumption should not be that that is benign or safe, right? So, I mean, a tragic example is, you know, a lot of old-time recipes for menstrual problems, which was often a euphemism for being pregnant, but not always, involved a substance called pennyroyal, which is horribly toxic to the body and often fatal when consumed. It certainly can induce uterine contractions. But, you know, death of the person taking it's kind of an undesired side effect. So - yeah, so can this herbal thing produce the effect? If it's producing an effect, you should be able to prove it. ZOMORODI: You mentioned this very briefly at the beginning of our conversation, but you have a lot of empathy. You've written that you have a lot of empathy for people who do want to believe all kinds of things because of a personal tragedy that you had. Can you just elaborate a little bit more about what you think the mindset is? GUNTER: Sure. I mean, you're desperate, you know? When my kids were in the intensive care unit and my son, you know, 1 pound, 11 ounces - and on top of that, he was diagnosed with an uncommon heart defect, nothing to do with being premature - right? - so just one bad thing on top of another. And he needed to have surgery to fix this complex heart defect, but he was too small for the equipment, you know? And I had another son who vomited after every single feed because his - just his - you know, his whole system wasn't developed yet. And so the first two years of his life, everything was a vomit, you know? I smelt - the back of my hair smelt like vomit - I'm not kidding - for two years. And, you know, he developed all kinds of - he couldn't eat solid food because of that because it's worse to vomit up solids than it is to vomit up liquids. ZOMORODI: Right. GUNTER: He didn't have his first solid food until he was 3 1/2. ZOMORODI: Wow. GUNTER: So I got lost in all these food blogs and food allergy things and - because you're desperate. I mean, here I've got this - you know, my son is 3. He hasn't eaten a bite of solid food. You can't even put it on his lip - and he freaks out. And you've done everything medicine has given you. You've done everything. You've gone to three different occupational therapists. You've tried this. You've tried that. You've had these interventions. And you're in this space where there is nothing to do but to wait. And it's a very vulnerable place to be. So I get it. ZOMORODI: I mean, it goes back to what you said before about knowledge and accurate information being crucial. And, I mean, I guess it's - feels or seems strange to lump homeopathic medicine and belief in the supernatural with misinformation in general. But I think what I'm hearing you say is that, especially for people who are in that vulnerable space, they can be gateways in some way. GUNTER: Yeah. I think that social media and the way we consume news in this 24/7 news cycle is this toxic combination that lets misinformation just metastasize, because there's this concept called the illusory truth effect. We all mistake repetition for accuracy. And so if you see the same story on your Instagram feed - and maybe you see it two or three times because maybe several influencers that you follow post it. And then you see it on your Facebook feed because what chases you on Facebook - what you saw on Instagram, right? ZOMORODI: Yeah. GUNTER: And then you see some people. And then maybe you decide, oh, look; there's this Facebook community that was recommended for me. And all these people seem nice. And then you get in there. And then all of a sudden, they're talking about conspiracy theories. And maybe you heard about that somewhere, but you don't quite remember where. It's really - we've created this echo chamber where the misinformation reverberates. And you know what? The misinformation is often fantastical and a bit like, whoa. And the truth is so stodgy and boring sometimes. And so how do you have - how does the stodgy truth about - you know, about the immune system, you know, how does that compete with it, you know? - like, wah-wah, wah-wah, wah-wah, and, you know, like in the \"Peanuts\" comic. And we have to learn to communicate in ways that people can hear. (SOUNDBITE OF MUSIC) ZOMORODI: In a minute, more from Dr. Jen Gunter and her mission to talk openly about basic bodily functions, like defecating. Today on the show, The Truth About Our Bodies. I'm Manoush Zomorodi, and you're listening to the TED Radio Hour from NPR. Stay with us. (SOUNDBITE OF MUSIC) ZOMORODI: It's the TED Radio Hour from NPR. I'm Manoush Zomorodi. Today on the show, debunking misinformation, stigma and shame about our bodies. Our guide through a selection of TED Talks is physician, author and podcaster Jen Gunter. And one topic in particular that Jen wants to demystify for us is poop. GUNTER: Everybody poops. This is one of those things people never talk about, but. . . ZOMORODI: So true. GUNTER: Like, why is your poop any more shameful than your runny nose? That's what I want to know. ZOMORODI: It doesn't smell the same, does it? OK, wait. We're going to get to that. GUNTER: (Laughter). ZOMORODI: But let's start with the talk that you have brought us, which is by Dr. Giulia Enders, called \"The Surprisingly Charming Science Of Your Gut. \" (SOUNDBITE OF TED TALK) GIULIA ENDERS: It took me three steps to love the gut. And the very first was just looking at it and asking questions like, how does it work and why, maybe, does it have to look so weird for that sometimes? And it actually wasn't me asking the first kind of these questions, but my roommate. So after one heavy night of partying, he came into our shared-room kitchen, and he said, Giulia, you study medicine. How does pooping work? (LAUGHTER) ENDERS: And I did study medicine, but I had no idea, so I had to go up to my room and look it up in different books. And I found something interesting, I thought, at that time. So it turns out we don't only have this outer sphincter. We also have an inner sphincter muscle. The outer sphincter we all know. We can control it. We know what's going on there. The inner one, we really don't. So what happens is when there are leftovers from digestion, they're being delivered to the inner one first. So this inner one will open in a reflex and let through a little bit for testing. So there are sensory cells that will analyze what has been delivered. Is it gaseous or is it solid? And they will then send this information up to our brain. And this is the moment when our brain knows, oh, I have to go to the toilet. ZOMORODI: I mean, is she - she's the most charming doctor. She's just the best. And it really - it reminds me of a friend of mine who I used to go on a lot of work trips with, and he used to go, (imitating trumpet). And that was - the trumpet noise was when he had to excuse himself. But most people are not that comfortable - well, other than little kids - are not that comfortable about talking openly about the need to go or pooping, right? GUNTER: Right. But they want to be (laughter). ZOMORODI: That is true. Tell me more about that. GUNTER: You know, I talk a lot about poop in the office, how to have bowel movement. I take care of a lot of people who have pelvic pain. And a lot of times, that's related to the same muscles that you use for defecation, to have a bowel movement. So there's a lot of crossover. And so chronic constipation can actually lead to pelvic pain and vice versa. So I'm always talking to people like, do you mechanically know how to have a bowel movement? And people are like, there's a way? I'm like, there is. We talk about, you know, that - why you really need to have fiber, why you really need to have these things. You know, people - we say, oh, you must have fiber; you must have fiber. But people want to know the why. They want to know the why. (SOUNDBITE OF TED TALK) ENDERS: Like, those funny rumbling noises that happen when you're in a group of friends or at the office conference table going like, (imitating stomach rumbling). This is not because we're hungry. This is because our small intestine's actually a huge neat freak, and it takes the time in between digestion to clean everything up, resulting in those eight meters of gut - really, seven of them - being very clean and hardly smell like anything. It will, to achieve this, create a strong muscular wave that moves everything forward that's been left over after digestion. This can sometimes create a sound but doesn't necessarily have to always. So what we're embarrassed of is really a sign of something keeping our insides fine and tidy. ZOMORODI: Can we just clarify one thing? First of all, I need to know about the right way to poop. And second of all, poop is basically just waste, right? GUNTER: Right, absolutely. It's all the leftovers that you don't need, plus cells from the lining of your colon and bacteria and indigestible fiber, the - you know, sort of the nonsoluble fiber. So, yeah, so the leftovers, if you will, and some other stuff along for the ride. You know, there might be a little bit of gas that a lot of us might think smells a bit like sulfur, and it's because of the bacteria, right? So we depend on bacteria inside our bodies to help with digestion, to help with so many things. I mean, we have this important microbiome. And I think also, too, you know, a lot of our misconceptions about the colon come from before we knew about the microbiome, actually, right? ZOMORODI: Oh, yeah. GUNTER: So it's sort of a different story to say, well, you have gas because you normally have this bacteria that's helping you break down food and produce vitamins, and it's really important part of your health, and so you should be proud of your sulfur. . . ZOMORODI: Yeah. GUNTER: . . . Because that means you've got a healthy microbiome - right? - as opposed to, you should be ashamed of it. ZOMORODI: OK, I'm going to try. But I should say, you know, earlier we mentioned that you are now doing a podcast. It's called \"Body Stuff. \" And this talk, the one that we've been discussing, is - it particularly speaks to you because you have an entire episode dedicated to poop. And you talk to a rather unusual expert who says we were not always so embarrassed to talk about it. GUNTER: So we talked to Dr. Barbara Penner, who's an architectural historian. And, you know, she wrote a book called \"Bathroom\" about how toilet design and ideas about poop have, I guess, shaped each other. And that's one of the great things about expanding your search for knowledge beyond, like, just medicine. Like, medicine's part of society. Like, you have to look at all of society to understand where we are. ZOMORODI: Right, which is exactly what you and Dr. Barbara Penner explain in your podcast. (SOUNDBITE OF PODCAST, \"BODY STUFF\") BARBARA PENNER: If we look at pre-modern times, let's say pre-18th century, there are loads of examples of two- and three-seater outhouses. GUNTER: Seats for people to poop side by side. PENNER: And these really remind us that there just was not the same sense of shame around bodily functions. And we know that for many people, going to the toilet could even be a time for socializing. GUNTER: And that was totally normal until the 19th century, the Victorian era in England. That's when indoor plumbing became much more available in England and the U. S. , and it's when we learned more about how disease is spread. ZOMORODI: OK, so let's time travel back to today. And the goal with pooping, I mean, I think it's pretty fair to say, is that everyone just wants their - sorry, listeners, to speak for you, but everyone (laughter) wants their poop to be regular and normal, like once a day, fully formed. Is that the right goal? GUNTER: Well, yes and no. Their poop should be regular for them. So what's regular and normal for me might not be regular and normal for you. You want the system to be working fine. So if once a day is what happens for you, that's great. If it's twice a day, that's fine. If it's every other day, that's OK. You know, so instead of thinking about, like, how often, you should think about more, like, is there any discomfort? Am I feeling unwell otherwise? Is there blood in my stool, which is certainly a very concerning sign and should always be reported to your doctor? You should just think about it in terms of health. I always think your body's kind of working the best when you're not really thinking about it. ZOMORODI: Yeah. GUNTER: And also a change - people should be aware of changes. So if everything was going right, and then all of a sudden there's a change for you, then that's something to think about. ZOMORODI: What I like about you, Jen, though, is that you don't just talk about the negative stuff. You also talk about the positive stuff. And in this episode about poop, you have an expert with you, and you introduce some terminology that I had never heard called poo-phoria, which is the lovely side of pooping. GUNTER: Yes. Our doctor of poo-ology (laughter), our gastroenterologist is Dr. Anish Sheth. And he wrote the book \"What Your Poo Is Telling You\" (ph). (SOUNDBITE OF PODCAST, \"BODY STUFF\") GUNTER: So what's a monster poo? ANISH SHETH: Monster poo just means you're just having a large, huge bowel movement. When you have a monster poo, you can experience this sort of sense of joy and elation that we call poo-phoria, right? It comes from sort of distending the rectum, which we talked about as being a very sensitive area, and then having it decompress sort of in a single bolus of stool as it comes out. And that sometimes just makes us, like, feel great, like you want to high-five the first person you see when you come out of the toilet. ZOMORODI: (Laughter) Has making this episode changed the way that you approach your own bathroom time, Jen? Is that too personal a question to ask you on public radio? GUNTER: You can ask me anything. I, like. . . ZOMORODI: OK. GUNTER: Seriously, I have, like, no shame. I'm the person that when, like - well, back in the before time, when you used to try on bras in the department store, I'd just, like, walk out of the change room going, does this one fit? ZOMORODI: (Laughter). GUNTER: So I think - I mean, I knew - I would say I knew most of the medicine. But I've always been a fiber evangelical, but I've certainly even doubled down more. Like, fiber is the way. ZOMORODI: Fiber is the way. GUNTER: Fiber is the way. ZOMORODI: But don't go too crazy, right? GUNTER: Well, you can, yeah. I mean, you can. I have on occasion found out that sometimes you can overdo it and get a little gastric distress. But when your stool moves along as it should, when it's not hard and scratchy, you lower your risk of getting hemorrhoids. And no one is ever happy with hemorrhoids. ZOMORODI: No. OK, for those poor souls who don't know, why do we need fiber? Why is fiber so important? What does it do? GUNTER: Fiber - ooh. People should talk about fiber like it's sexy 'cause it is. It's good for your body. One, it's really important because some fiber function is prebiotics. So for your colon, it helps you produce more good bacteria. Fiber draws water into the stool, making it softer, and then it's less scratchy when it comes out. Think of it like a sponge, a poo sponge. That's what fiber is. It's a poo sponge. ZOMORODI: Do I have to? Like. . . GUNTER: Yeah. ZOMORODI: All right. GUNTER: It's a great way to think about it. We're giving it an upgrade. ZOMORODI: OK. GUNTER: So fiber draws water into the stool, and that increases the bulk. And the bulk of the stool helps stimulate the colon to move the stool along. ZOMORODI: So, you know, listening to you, I feel like we need to have, like, a call-in show or something. But what's your advice for making sure we ask our doctors the right questions? Because we need to be more fearless, too - right? - about bringing up issues that we might feel, oh, it's nothing or we feel squeamish about it or, you know, it's embarrassing. It's too - it's a human, right? GUNTER: Well, I think - you know, I hate to put the onus on the patient because the doctor should be creating a welcoming environment for that. A lot of things in medicine occupy this in-between, this land of in-between where, you know, how to have a bowel movement isn't really, like, a medical problem. ZOMORODI: Right. GUNTER: But if it's not done right, it can be, right? So it's the same thing, like, with, like, how to wash your vulva. It's not - that's not really, like, medicine. But if it's done wrong, it is. So, you know, these are areas I think medicine needs to step up. It's like practical information people need so they can live their lives. It really should be part of health maintenance and disease prevention. ZOMORODI: So let's say someone is thinking, well, it's not really a problem, at least not yet, so I'm not going to bother with going to the doctor's office. But then how can people find the right health information online? GUNTER: Yeah. I mean, I think it's natural for people to want to research what's going on with their bodies online. You know, write down what's bothering you or what's concerning you, and think about what organ system you might think that involves. So, for example, if it's your poo, you're having a problem having a bowel movement, I would go to the American Gastrointestinal Association (ph), and then I would see what the experts have to say. Or the American Academy of Family Physicians - great place to start. You know, or if it's an OB-GYN question, start with, you know, the American College of OB-GYN. I think people forget that medical professional societies actually have great information online. That's a good place to start. And the National Library of Medicine and the Centers for Disease Control - they all have great information. ZOMORODI: Can I just ask one thing that I've been wondering might be adding to this problem of lack of information about our bodies - is, at least in my experience, how specialized Western medicine has become. Like, if you go to see a podiatrist, they are definitely going to say, like, yup, it's a foot problem, as opposed to maybe it's a problem with, you know, your back or other ways that you carry yourself. Like, we don't treat the body very holistically here in the United States. Is that part of the problem? And - I don't know - do you see this changing at all as we look forward into the future? GUNTER: Yeah. So I think that one of the root causes of many problems is the lack of investment in primary care. You know, we have these amazing family physicians, these amazing pediatricians, you know, these amazing front-line doctors who are not subspecialized. Their specialty is all of you, right? And how can they look after all of you in 15 or 20 minutes? ZOMORODI: No, right. GUNTER: So to me, one of the root causes of problems, certainly in North America, is this idea that we are fairly well situated to manage acute problems. You have a sore throat, you come in, you get checked for strep throat. You break your toe, you come in, you get your toe splinted. You know, you have this acute problem, and you come in and get it fixed. But many of us also then get stuck in this idea that problems can be fixed. But a lot of medicine is chronic care, right? It's things that don't go away with a pill or a surgery. Or maybe those things can help, but they're part of the long-term management. And we need to invest in systems that account for that. ZOMORODI: Going back to the debunking of health myths, your specialty, how much do you worry that the - we're sort of entering a period that is ripe for more of this, considering the sort of post - hopefully post-COVID era where we're talking about long-haul symptoms? We don't know a lot about it. There are starting to be studies, but there aren't that many. It seems like there are going to be a lot of very vulnerable people looking for answers to feel better for a very long time to come. GUNTER: Yeah, I think that is definitely ripe for charlatans to take advantage of it. I think also, too, you know, many people who have unstudied medical conditions, and certainly something like long COVID is something that is obviously unstudied, in part because it's so new - I think that a lot of times, doctors really just also need to say, I don't know; I don't have an answer, instead of brushing somebody off as, no, that can't be or, let me doctor-splain (ph) that to you. When I'm honest - because I deal with chronic pain every day. I deal with a lot of conditions that are - that don't have easy fixes. And sometimes I sit down with people, and I sort of say, yeah, that sucks. You are right. We don't have this information. You are right. And I think that sometimes people want to hear that. And I think when people have difficult illnesses or illnesses that don't have answers, they get that you might not have an immediate cure. But when you say that - I don't know, but let's work on this together - I think that's welcoming. And I - so I think medicine has to figure out how to be more welcoming, how to advocate for studying things, how to look at the way we allocate research funds to make sure that we're bringing everything to the table. One thing the pandemic has shown us is that if you throw a lot of money and a lot of smart minds at things, you can solve a difficult problem pretty quickly. That's kind of a hopeful thing. (SOUNDBITE OF MUSIC) ZOMORODI: Thank you again to Dr. Jen Gunter for spending the hour with us. You can find \"Body Stuff With Dr. Jen Gunter\" wherever you listen to podcasts. (SOUNDBITE OF MUSIC) ZOMORODI: This episode was produced by Christina Cala and Matthew Cloutier, and it was edited by Sanaz Meshkinpour. Our TED Radio production staff also includes Jeff Rogers, Rachel Faulkner, Diba Mohtasham, James Delahoussaye, J. C. Howard, Katie Monteleone, Janet Lee and Fiona Geiran. Our audio engineer is Daniel Shukin (ph). Our theme music was written by Ramtin Arablouei. Our partners at TED are Chris Anderson, Colin Helms, Anna Phelan and Michelle Quint. I'm Manoush Zomorodi, and you've been listening to the TED Radio Hour from NPR.", "section": "TED Radio Hour", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-05-28-1000580256": {"title": "In 'Mass Effect,' The Story Starts With The Spaceship : NPR", "url": "https://www.npr.org/2021/05/28/1000580256/reading-the-game-in-mass-effect-the-story-starts-with-the-spaceship", "author": "No author found", "published_date": "2021-05-28", "content": "", "section": "Reading The Game", "disclaimer": ""}, "2021-05-30-1001627869": {"title": "'Charlie Bit Me' Will Remain On YouTube After NFT Auction Switcheroo : NPR", "url": "https://www.npr.org/2021/05/30/1001627869/charlie-bit-me-will-remain-on-youtube-after-nft-auction-switcheroo", "author": "No author found", "published_date": "2021-05-30", "content": "", "section": "Pop Culture", "disclaimer": ""}, "2021-06-01-1002336381": {"title": "No Meat Price Hike If JBS Rebounds Fast After Ransomware Attack : NPR", "url": "https://www.npr.org/2021/06/01/1002336381/put-your-wallet-away-meat-prices-are-not-likely-to-rise-after-jbs-cyberattack", "author": "No author found", "published_date": "2021-06-01", "content": "", "section": "Business", "disclaimer": ""}, "2021-06-01-1002219089": {"title": "Parents Say There Doesn't Need To Be A Kid-Only Instagram, Just A Kid-Friendlier One : NPR", "url": "https://www.npr.org/2021/06/01/1002219089/parents-say-there-doesnt-need-to-a-kid-only-instagram-just-a-kid-friendlier-one", "author": "No author found", "published_date": "2021-06-01", "content": "AUDIE CORNISH, HOST:  Social media companies ban kids under 13 from signing up because of federal privacy law. But ask any parent. . . DANIELLE HAWKINS: She got on Instagram and Snapchat without my approval when she was about 12. TITANIA JORDAN: They have Instagram, Snapchat, TikTok. BLYTHE WINSLOW: My 11-year-old has been gunning for social media probably since she was 8 or 9 years old. CORNISH: Now Facebook, which owns Instagram, says it has a solution for underage kids. NPR's Shannon Bond has more on this story. And a quick note before we begin - Facebook and TikTok are among NPR's financial supporters. SHANNON BOND, BYLINE: Here's how Facebook CEO Mark Zuckerberg explained the problem at a congressional hearing in March. (SOUNDBITE OF ARCHIVED RECORDING)MARK ZUCKERBERG: There is clearly a large number of people under the age of 13 who would want to use a service like Instagram. We currently do not allow them to do that. BOND: His solution - Instagram Youth, a version of the app just for kids with extra parental controls. So far, it's just an idea Facebook's working on, but it's getting a lot of attention. Parents say Zuckerberg is right. Kids are going on social media despite these apps' age limits. CHARITY WHITE-VOTH: I was the last holdout of her friends' parents around Snapchat. BOND: For Charity White-Voth in San Diego, the struggle began long before her daughter's 13th birthday. WHITE-VOTH: And, you know, she said, mom, all my friends. Well really, she was not joking. Like, they were on it, and they were using it. And I was like, I just don't feel comfortable. I don't think it's the right thing to do. So I held out for a long time, I think until she was just 13. BOND: She still worries her daughter is too young to appreciate the consequences of sharing on these apps - that things posted online are on the internet forever. Another big worry for many parents - the focus on likes, followers and selfies, especially on visual platforms like Instagram, TikTok and Snapchat. Danielle Hawkins, a mom who lives near Detroit, says it just makes existing problems worse. HAWKINS: Body image, who you are, how accepted you are is a very big part of becoming a teenager. BOND: Her oldest daughter started using Instagram and Snapchat last year at 12, but she's not allowed to anymore. Blythe Winslow says those worries are grounded in research. She's a mom of two tween girls in Cincinnati and co-founder of everyschool. org, a nonprofit that advises schools on how to use technology. WINSLOW: You know, kids have more anxiety and depression. Empathy is on the decline. Creativity is on the decline. Suicide rates in kids ages 10 to 14 has tripled. Parents fear that social media might be linked to a lot of those problems. BOND: And those fears are fueling a backlash to Facebook. Child safety advocates, members of Congress and 44 attorneys general want it to scrap Instagram Youth. They cite worries about online predators, links to depression and body image concerns. And they say Facebook just doesn't have a good track record when it comes to privacy and protecting users. Jim Steyer heads the advocacy group Common Sense Media. JIM STEYER: We see this as Facebook doing the classic brand marketing approach, which is hook kids as early as possible. One, you get their loyalty from cradle to grave, and two, if you're lucky, you get their parents to come with them. BOND: Facebook says safety and privacy come first. It's working with experts to develop Instagram Youth. Some parents told NPR they would be interested in letting their kids use a version of the app with more limited content and the ability to monitor what they're up to. But San Diego dad Buyung Santoso says his kids, age 11 and 13, wouldn't go for that. BUYUNG SANTOSO: In fact, my daughter says that she didn't think that it was going to work because kids can do whatever they want, regardless of, you know, whether you need permission or not. BOND: Critics say instead of creating new apps for children, tech companies should concentrate on making their existing products safer for the kids they know are on there right now. Titania Jordan works at Atlanta software company Bark, which helps parents monitor their kids' online activity. And she's mom to a 12-year-old son who loves TikTok and Snapchat. JORDAN: We're not asking social media to parent our kids. It's not their job. Just don't make our job harder. BOND: For now, Facebook has not given a timeline for if or when it plans to roll out Instagram Youth. Shannon Bond, NPR News. (SOUNDBITE OF MUSIC) AUDIE CORNISH, HOST:   Social media companies ban kids under 13 from signing up because of federal privacy law. But ask any parent. . . DANIELLE HAWKINS: She got on Instagram and Snapchat without my approval when she was about 12. TITANIA JORDAN: They have Instagram, Snapchat, TikTok. BLYTHE WINSLOW: My 11-year-old has been gunning for social media probably since she was 8 or 9 years old. CORNISH: Now Facebook, which owns Instagram, says it has a solution for underage kids. NPR's Shannon Bond has more on this story. And a quick note before we begin - Facebook and TikTok are among NPR's financial supporters. SHANNON BOND, BYLINE: Here's how Facebook CEO Mark Zuckerberg explained the problem at a congressional hearing in March. (SOUNDBITE OF ARCHIVED RECORDING) MARK ZUCKERBERG: There is clearly a large number of people under the age of 13 who would want to use a service like Instagram. We currently do not allow them to do that. BOND: His solution - Instagram Youth, a version of the app just for kids with extra parental controls. So far, it's just an idea Facebook's working on, but it's getting a lot of attention. Parents say Zuckerberg is right. Kids are going on social media despite these apps' age limits. CHARITY WHITE-VOTH: I was the last holdout of her friends' parents around Snapchat. BOND: For Charity White-Voth in San Diego, the struggle began long before her daughter's 13th birthday. WHITE-VOTH: And, you know, she said, mom, all my friends. Well really, she was not joking. Like, they were on it, and they were using it. And I was like, I just don't feel comfortable. I don't think it's the right thing to do. So I held out for a long time, I think until she was just 13. BOND: She still worries her daughter is too young to appreciate the consequences of sharing on these apps - that things posted online are on the internet forever. Another big worry for many parents - the focus on likes, followers and selfies, especially on visual platforms like Instagram, TikTok and Snapchat. Danielle Hawkins, a mom who lives near Detroit, says it just makes existing problems worse. HAWKINS: Body image, who you are, how accepted you are is a very big part of becoming a teenager. BOND: Her oldest daughter started using Instagram and Snapchat last year at 12, but she's not allowed to anymore. Blythe Winslow says those worries are grounded in research. She's a mom of two tween girls in Cincinnati and co-founder of everyschool. org, a nonprofit that advises schools on how to use technology. WINSLOW: You know, kids have more anxiety and depression. Empathy is on the decline. Creativity is on the decline. Suicide rates in kids ages 10 to 14 has tripled. Parents fear that social media might be linked to a lot of those problems. BOND: And those fears are fueling a backlash to Facebook. Child safety advocates, members of Congress and 44 attorneys general want it to scrap Instagram Youth. They cite worries about online predators, links to depression and body image concerns. And they say Facebook just doesn't have a good track record when it comes to privacy and protecting users. Jim Steyer heads the advocacy group Common Sense Media. JIM STEYER: We see this as Facebook doing the classic brand marketing approach, which is hook kids as early as possible. One, you get their loyalty from cradle to grave, and two, if you're lucky, you get their parents to come with them. BOND: Facebook says safety and privacy come first. It's working with experts to develop Instagram Youth. Some parents told NPR they would be interested in letting their kids use a version of the app with more limited content and the ability to monitor what they're up to. But San Diego dad Buyung Santoso says his kids, age 11 and 13, wouldn't go for that. BUYUNG SANTOSO: In fact, my daughter says that she didn't think that it was going to work because kids can do whatever they want, regardless of, you know, whether you need permission or not. BOND: Critics say instead of creating new apps for children, tech companies should concentrate on making their existing products safer for the kids they know are on there right now. Titania Jordan works at Atlanta software company Bark, which helps parents monitor their kids' online activity. And she's mom to a 12-year-old son who loves TikTok and Snapchat. JORDAN: We're not asking social media to parent our kids. It's not their job. Just don't make our job harder. BOND: For now, Facebook has not given a timeline for if or when it plans to roll out Instagram Youth. Shannon Bond, NPR News. (SOUNDBITE OF MUSIC)", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-06-01-1002196245": {"title": "Autonomous Drone Strike In Libya Subject Of Recent United Nations Report : NPR", "url": "https://www.npr.org/2021/06/01/1002196245/a-u-n-report-suggests-libya-saw-the-first-battlefield-killing-by-an-autonomous-d", "author": "No author found", "published_date": "2021-06-01", "content": "", "section": "World", "disclaimer": ""}, "2021-06-01-1002160870": {"title": "JBS, The World's Largest Meat Processing Company, Hit By A Cyberattack : NPR", "url": "https://www.npr.org/2021/06/01/1002160870/a-cyberattack-has-disrupted-the-worlds-largest-meat-processing-company", "author": "No author found", "published_date": "2021-06-01", "content": "", "section": "Business", "disclaimer": ""}, "2021-06-02-1002525048": {"title": "Senate Democrats Urge Google To Investigate Racial Bias In Its Tools And The Company : NPR", "url": "https://www.npr.org/2021/06/02/1002525048/senate-democrats-to-google-investigate-racial-bias-in-your-tools-and-company", "author": "No author found", "published_date": "2021-06-02", "content": "", "section": "America Reckons With Racial Injustice", "disclaimer": ""}, "2021-06-02-1002109833": {"title": "Instagram Youth Won't Help Preteens On Social Media, Parents Say : NPR", "url": "https://www.npr.org/2021/06/02/1002109833/parents-to-facebook-dont-make-a-kid-only-instagram-just-a-better-instagram", "author": "No author found", "published_date": "2021-06-02", "content": "", "section": "Technology", "disclaimer": ""}, "2021-06-03-1003020300": {"title": "Colonial Pipeline CEO On Restored Operations, Paying Ransom And Cyberattacks : NPR", "url": "https://www.npr.org/2021/06/03/1003020300/colonial-pipeline-ceo-explains-the-decision-to-pay-hackers-4-4-million-ransom", "author": "No author found", "published_date": "2021-06-03", "content": "MARY LOUISE KELLY, HOST:  Panic fueling, long lines for gas, handwritten signs taped to pumps, empty - those were the headlines last month in the U. S. , particularly the southeast, fallout from a cyberattack. Colonial Pipeline provides nearly half the East Coast's fuel supply. And when hackers hit its network and demanded ransom, the company shut the pipeline down for six days and ended up paying that ransom, more than $4 million. Joe Blount signed off on that payment. He is CEO of Colonial Pipeline, and he joins me now. Welcome. JOE BLOUNT: Thank you, Mary Louise, for having us today. KELLY: Are your operations fully restored now? Any lasting damage? BLOUNT: No, definitely not fully restored. And I think if you talk to anybody whose suffered from one of these criminal cyberattacks, they would tell you that it takes months and months and months to restore all your IT infrastructure. In our case, our focus initially was to get the pipeline back up and running safely and as soon as we possibly could. So we got the critical IT structure put back together, but we have lots and months and months of work ahead of us. KELLY: Well, and help me understand this. The attack was on your computer system - right? - not on the actual pipeline. So why did you have to shut down the gas? Why not keep it flowing while you were dealing with the problem with the computers? BLOUNT: Well, let me take you back to the early morning of May 7. We knew immediately that there was an issue. And, you know, we are programmed to only operate the pipeline if we feel that it's in safe operating condition and won't cause any harm to employees, the communities we serve or to the environment. So we have what we call stop work authority at Colonial. Any of our employees has the opportunity to use it. If they identify a risk, their job is to contain it immediately. In this case, a ransomware note came across the screen in our control room. It was immediately recognized, and the control room supervisor immediately decided to shut down the pipeline. It was the right decision to make because you don't know what you have at that point in time. KELLY: Let's turn to the other decision you made, that you signed off on paying nearly $4 1/2 million ransom. This was in cryptocurrency. Doesn't that just encourage the next attack? BLOUNT: You know, obviously probably the hardest decision I've ever made in my career. You know, I've been around this asset for a long time. I've been an employee of Colonial Pipeline for three and a half years, but I've been in the industry for almost 39 (ph) now. So once we identified the risk and contained the risk by shutting the pipeline system down and immediately called in cyber experts to help us with identifying further what had been done to our system, one of the things that came up ultimately was the ransom and whether to pay the ransom or not. KELLY: Well, and take me inside that conversation because I'm thinking if I'm a hacker in Russia, my takeaway might well be, that worked great. Which big U. S. company should be hit next? BLOUNT: The conversations went like this. Do you pay the ransom or not? And, of course, the initial thought is you don't want to pay the ransom. You don't want to encourage. You don't want to pay these contemptible criminals. But our job and our duty is to the American public. So when you know that you have 100 million gallons of gasoline and diesel fuels and jet fuels that are going to go across the southeastern and eastern seaboard of the United States, it's a very critical decision to make. And if only that, the encryption tool, gets you there quicker, then it's the decision that had to be made. And I did make that decision that day. It was the right decision to make for the country. KELLY: You know, as I'm sure you know now - you would have learned it if you didn't know it before - the FBI policy is don't pay the ransom because it does encourage the next attack and the next one. What kind of advice, what kind of pressure were you getting from the government as you were weighing this? BLOUNT: I don't know that there was any pressure from the government. I think the FBI has stated in the past that they don't encourage it. But at the end of the day, it's a decision that has to be made by the company. KELLY: What role, in your view, should the government play when a private company like yours faces an attack like this, faces ransom? As this seems to be becoming a more frequent problem, is it too big for private companies to handle privately when so many Americans are ultimately affected? BLOUNT: I think that obviously private industry has a responsibility here. Pipelines do invest in cyberware and security. It's a natural extension of what we've done historically, which is focus on the physical security of our asset. So it really pretty much needs to become a private-public partnership. KELLY: So you're happy to share information with the government, but you would prefer to have a private contractor who's helping keep the system safe? BLOUNT: I think once we complete our investigation into this event, partnering with the government and sharing those learnings with our peers in the infrastructure space and more broadly across other sectors is very important so that they can learn lessons from our event. And obviously we can share with them what they've learned perhaps from similar type events. KELLY: Mr. Blount, thank you for your time. BLOUNT: Thank you very much. Have a great day. KELLY: And you as well. Joe Blount - he's the CEO of Colonial Pipeline. MARY LOUISE KELLY, HOST:   Panic fueling, long lines for gas, handwritten signs taped to pumps, empty - those were the headlines last month in the U. S. , particularly the southeast, fallout from a cyberattack. Colonial Pipeline provides nearly half the East Coast's fuel supply. And when hackers hit its network and demanded ransom, the company shut the pipeline down for six days and ended up paying that ransom, more than $4 million. Joe Blount signed off on that payment. He is CEO of Colonial Pipeline, and he joins me now. Welcome. JOE BLOUNT: Thank you, Mary Louise, for having us today. KELLY: Are your operations fully restored now? Any lasting damage? BLOUNT: No, definitely not fully restored. And I think if you talk to anybody whose suffered from one of these criminal cyberattacks, they would tell you that it takes months and months and months to restore all your IT infrastructure. In our case, our focus initially was to get the pipeline back up and running safely and as soon as we possibly could. So we got the critical IT structure put back together, but we have lots and months and months of work ahead of us. KELLY: Well, and help me understand this. The attack was on your computer system - right? - not on the actual pipeline. So why did you have to shut down the gas? Why not keep it flowing while you were dealing with the problem with the computers? BLOUNT: Well, let me take you back to the early morning of May 7. We knew immediately that there was an issue. And, you know, we are programmed to only operate the pipeline if we feel that it's in safe operating condition and won't cause any harm to employees, the communities we serve or to the environment. So we have what we call stop work authority at Colonial. Any of our employees has the opportunity to use it. If they identify a risk, their job is to contain it immediately. In this case, a ransomware note came across the screen in our control room. It was immediately recognized, and the control room supervisor immediately decided to shut down the pipeline. It was the right decision to make because you don't know what you have at that point in time. KELLY: Let's turn to the other decision you made, that you signed off on paying nearly $4 1/2 million ransom. This was in cryptocurrency. Doesn't that just encourage the next attack? BLOUNT: You know, obviously probably the hardest decision I've ever made in my career. You know, I've been around this asset for a long time. I've been an employee of Colonial Pipeline for three and a half years, but I've been in the industry for almost 39 (ph) now. So once we identified the risk and contained the risk by shutting the pipeline system down and immediately called in cyber experts to help us with identifying further what had been done to our system, one of the things that came up ultimately was the ransom and whether to pay the ransom or not. KELLY: Well, and take me inside that conversation because I'm thinking if I'm a hacker in Russia, my takeaway might well be, that worked great. Which big U. S. company should be hit next? BLOUNT: The conversations went like this. Do you pay the ransom or not? And, of course, the initial thought is you don't want to pay the ransom. You don't want to encourage. You don't want to pay these contemptible criminals. But our job and our duty is to the American public. So when you know that you have 100 million gallons of gasoline and diesel fuels and jet fuels that are going to go across the southeastern and eastern seaboard of the United States, it's a very critical decision to make. And if only that, the encryption tool, gets you there quicker, then it's the decision that had to be made. And I did make that decision that day. It was the right decision to make for the country. KELLY: You know, as I'm sure you know now - you would have learned it if you didn't know it before - the FBI policy is don't pay the ransom because it does encourage the next attack and the next one. What kind of advice, what kind of pressure were you getting from the government as you were weighing this? BLOUNT: I don't know that there was any pressure from the government. I think the FBI has stated in the past that they don't encourage it. But at the end of the day, it's a decision that has to be made by the company. KELLY: What role, in your view, should the government play when a private company like yours faces an attack like this, faces ransom? As this seems to be becoming a more frequent problem, is it too big for private companies to handle privately when so many Americans are ultimately affected? BLOUNT: I think that obviously private industry has a responsibility here. Pipelines do invest in cyberware and security. It's a natural extension of what we've done historically, which is focus on the physical security of our asset. So it really pretty much needs to become a private-public partnership. KELLY: So you're happy to share information with the government, but you would prefer to have a private contractor who's helping keep the system safe? BLOUNT: I think once we complete our investigation into this event, partnering with the government and sharing those learnings with our peers in the infrastructure space and more broadly across other sectors is very important so that they can learn lessons from our event. And obviously we can share with them what they've learned perhaps from similar type events. KELLY: Mr. Blount, thank you for your time. BLOUNT: Thank you very much. Have a great day. KELLY: And you as well. Joe Blount - he's the CEO of Colonial Pipeline.", "section": "National Security", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-06-03-1002926010": {"title": "United Airlines To Buy 15 Supersonic Jets That Can Virtually Halve Flight Times : NPR", "url": "https://www.npr.org/2021/06/03/1002926010/united-airlines-wants-to-revive-supersonic-travel-but-what-about-climate-change", "author": "No author found", "published_date": "2021-06-03", "content": "", "section": "Business", "disclaimer": ""}, "2021-06-03-1002819883": {"title": "REvil, A Notorious Ransomware Gang, Was Behind JBS Cyberattack, The FBI Says : NPR", "url": "https://www.npr.org/2021/06/03/1002819883/revil-a-notorious-ransomware-gang-was-behind-jbs-cyberattack-the-fbi-says", "author": "No author found", "published_date": "2021-06-03", "content": "", "section": "Business", "disclaimer": ""}, "2021-06-03-1002586066": {"title": "Review: Post-Apocalyptic Shooter 'Biomutant' : NPR", "url": "https://www.npr.org/2021/06/03/1002586066/biomutant-is-a-beautiful-game-but-it-might-be-best-for-beginners", "author": "No author found", "published_date": "2021-06-03", "content": "", "section": "Gaming", "disclaimer": ""}, "2021-06-04-1003205422": {"title": "States Fight Over How Our Data Is Tracked And Sold Online, As Congress Stalls  : NPR", "url": "https://www.npr.org/2021/06/04/1003205422/states-fight-over-how-our-data-is-tracked-and-sold-online-as-congress-stalls", "author": "No author found", "published_date": "2021-06-04", "content": "", "section": "Technology", "disclaimer": ""}, "2021-06-04-1003262750": {"title": "As Cyberattacks Surge, Biden Is Seeking To Step Up Defense : NPR", "url": "https://www.npr.org/2021/06/04/1003262750/as-cyber-attacks-surge-biden-seeks-to-mount-a-better-defense", "author": "No author found", "published_date": "2021-06-04", "content": "ARI SHAPIRO, HOST:  President Biden faces an escalating battle in cyberspace. After multiple hacks, the FBI says it's investigating around a hundred different types of ransomware. The Justice Department says it will start treating ransomware in a manner similar to terrorism. So what are the prospects of success? NPR's Greg Myre has our story. GREG MYRE, BYLINE: President Biden received no grace period when it came to cyber. APRIL FALCON DOSS: The cyber pressures that this administration has faced so far have been relentless. MYRE: April Falcon Doss is a former National Security Agency official who now heads a technology program at Georgetown's Law school. As the cyber breaches pile up, cyber experts say it's important to note the two distinct threats. Glenn Gerstell was a senior NSA official until last year. GLENN GERSTELL: There clearly is a dividing line between cyber hacks for intelligence-gathering purposes and these ransomware attacks that are designed principally for financial benefit. MYRE: On one side of that line is the SolarWinds attack uncovered last December. This was intelligence gathering by Russian spies quietly stealing U. S. government secrets. On the other side is ransomware, which is surging. Russian criminals are blamed for both the Colonial Pipeline attack that hit gasoline supplies in April and this week's hack that briefly shut down the world's largest meat supplier, JBS. These require different responses, Gerstell says. But he's quick to add. . . GERSTELL: Both the intelligence attacks and some of the most significant ransomware attacks we have have one thing in common, and that's Russia. MYRE: Biden says he'll raise the cyber issue with Russian leader Vladimir Putin at a June 16 summit in Switzerland. Despite all the evidence, Putin denies Russian involvement in the intelligence hacks and shrugs his shoulders when asked about the ransomware attacks from criminals based in Russia. Gerstell says the U. S. shouldn't accept this answer. GERSTELL: It's almost impossible to believe that a major criminal gang would operate inside of Russia and have real-world effects in the United States and Putin wouldn't know about it. MYRE: FBI Director Christopher Wray told The Wall Street Journal in a story published today that many of the hundred ransomware variants under investigation are linked to Russia. Last month, Biden laid out his cyber strategy in an executive order. April Falcon Doss says it's a good start. DOSS: There are many departments and agencies across government that really have cybersecurity postures that lag behind where they should be. MYRE: The government does face real limits when it comes to ransomware and private companies. DOSS: The government won't be able to actively protect the private sector from any possible ransomware attack because, thankfully, the government doesn't control the internet, right? We wouldn't want that. MYRE: Protecting the private sector falls to people like Adam Meyers, vice president for intelligence at the cybersecurity firm CrowdStrike. ADAM MEYERS: These companies can't put their head in the sand and hope it's not going to happen to them. It is going to happen to them; it's going to be a matter of when. MYRE: Meyers says too many companies aren't keeping their cyber defenses up to date. He cites the attack on the meat company, JBS, carried out with a malware known as REvil. Meyers knows it well but says many potential victims don't. MEYERS: I guarantee lots of organizations in the food processing world right now googling how to find - what is REvil? And if you need to look it up when it's happening, you're in a real bad spot. MYRE: How bad? I ask what the current ransom demand is for an attack on a large company. MEYERS: I see the payments going out, and the payments are just, you know, stomach-churning figures - you know, $2-, $4-, $8-, $10-, $30 million. MYRE: It's a price he believes many more companies will have to pay. Greg Myre, NPR News, Washington. (SOUNDBITE OF GLASS CANDY, \"BEAUTIFUL OBJECT (INSTRUMENTAL)\") ARI SHAPIRO, HOST:   President Biden faces an escalating battle in cyberspace. After multiple hacks, the FBI says it's investigating around a hundred different types of ransomware. The Justice Department says it will start treating ransomware in a manner similar to terrorism. So what are the prospects of success? NPR's Greg Myre has our story. GREG MYRE, BYLINE: President Biden received no grace period when it came to cyber. APRIL FALCON DOSS: The cyber pressures that this administration has faced so far have been relentless. MYRE: April Falcon Doss is a former National Security Agency official who now heads a technology program at Georgetown's Law school. As the cyber breaches pile up, cyber experts say it's important to note the two distinct threats. Glenn Gerstell was a senior NSA official until last year. GLENN GERSTELL: There clearly is a dividing line between cyber hacks for intelligence-gathering purposes and these ransomware attacks that are designed principally for financial benefit. MYRE: On one side of that line is the SolarWinds attack uncovered last December. This was intelligence gathering by Russian spies quietly stealing U. S. government secrets. On the other side is ransomware, which is surging. Russian criminals are blamed for both the Colonial Pipeline attack that hit gasoline supplies in April and this week's hack that briefly shut down the world's largest meat supplier, JBS. These require different responses, Gerstell says. But he's quick to add. . . GERSTELL: Both the intelligence attacks and some of the most significant ransomware attacks we have have one thing in common, and that's Russia. MYRE: Biden says he'll raise the cyber issue with Russian leader Vladimir Putin at a June 16 summit in Switzerland. Despite all the evidence, Putin denies Russian involvement in the intelligence hacks and shrugs his shoulders when asked about the ransomware attacks from criminals based in Russia. Gerstell says the U. S. shouldn't accept this answer. GERSTELL: It's almost impossible to believe that a major criminal gang would operate inside of Russia and have real-world effects in the United States and Putin wouldn't know about it. MYRE: FBI Director Christopher Wray told The Wall Street Journal in a story published today that many of the hundred ransomware variants under investigation are linked to Russia. Last month, Biden laid out his cyber strategy in an executive order. April Falcon Doss says it's a good start. DOSS: There are many departments and agencies across government that really have cybersecurity postures that lag behind where they should be. MYRE: The government does face real limits when it comes to ransomware and private companies. DOSS: The government won't be able to actively protect the private sector from any possible ransomware attack because, thankfully, the government doesn't control the internet, right? We wouldn't want that. MYRE: Protecting the private sector falls to people like Adam Meyers, vice president for intelligence at the cybersecurity firm CrowdStrike. ADAM MEYERS: These companies can't put their head in the sand and hope it's not going to happen to them. It is going to happen to them; it's going to be a matter of when. MYRE: Meyers says too many companies aren't keeping their cyber defenses up to date. He cites the attack on the meat company, JBS, carried out with a malware known as REvil. Meyers knows it well but says many potential victims don't. MEYERS: I guarantee lots of organizations in the food processing world right now googling how to find - what is REvil? And if you need to look it up when it's happening, you're in a real bad spot. MYRE: How bad? I ask what the current ransom demand is for an attack on a large company. MEYERS: I see the payments going out, and the payments are just, you know, stomach-churning figures - you know, $2-, $4-, $8-, $10-, $30 million. MYRE: It's a price he believes many more companies will have to pay. Greg Myre, NPR News, Washington. (SOUNDBITE OF GLASS CANDY, \"BEAUTIFUL OBJECT (INSTRUMENTAL)\")", "section": "National Security", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-06-04-1003284948": {"title": "Trump Suspended From Facebook For 2 Years : NPR", "url": "https://www.npr.org/2021/06/04/1003284948/trump-suspended-from-facebook-for-2-years", "author": "No author found", "published_date": "2021-06-04", "content": "MARY LOUISE KELLY, HOST:  Facebook has extended former President Donald Trump's suspension for at least two years, and it says they'll only reinstate him then if, quote, \"the risk to public safety has receded. \" It's part of big changes the social media company is making to how it treats all politicians. NPR tech correspondent Shannon Bond joins us. And I need to note Facebook is among NPR's financial supporters. Hey, Shannon. SHANNON BOND, BYLINE: Hey, Mary Louise. KELLY: OK, so as we noted, Trump was already suspended. Facebook suspended him right after the January 6 attack on the U. S. Capitol. So what exactly is new today? BOND: Well, at the time, Facebook said Trump was kicked off indefinitely. It's now put a time frame on this penalty. So he can't return before January 2023. And this is in response to Facebook's Oversight Board, which is this group of outside experts that Facebook created to review its toughest calls. Facebook had asked the board to weigh in on the Trump case. And last month, the board said, OK, suspending Trump was the right move. But it said Facebook can't just indefinitely suspend someone. That kind of penalty needs clear rules, a clear time frame. We should also note Facebook was not the only platform to kick off Trump. Twitter banned him permanently after January 6. KELLY: And do we know why this time frame? Is there something special about January 2023? BOND: Well, also at the board's urging, Facebook has set these new rules for how it treats public figures in times of civil unrest and violence, for cases just like this one. And so it says under those new rules, the maximum suspension is two years and that what Trump did in stoking this violence was so serious, he deserves that maximum. To be clear, it hasn't explained why two years is the maximum. What it means is that once 2023 rolls around, Facebook will consider whether there's still a serious risk to public safety before letting Trump back. And if he does come back, he will face stricter penalties, including the possibility of a permanent ban if he keeps breaking Facebook's rules. KELLY: What are we hearing in reaction to this from Trump? BOND: He put out a statement describing Facebook's decision as an insult to the people who voted for him and continued his baseless attacks on the legitimacy of the 2020 election. He then followed up with another statement, hinting he would run for the presidency again and taking direct aim at Facebook's CEO. He said, quote, \"Next time I'm in the White House, there will be no more dinners, at his request, with Mark Zuckerberg and his wife. It will be all business. \" But Trump is not the only person unhappy. Many critics of Facebook are also unhappy with this decision. Civil rights groups and others - they say Facebook - Trump should be permanently banned already. And they're worried that he's going to be back in time for the next presidential election in 2024. KELLY: Shannon, just setting Trump aside for a second, we mentioned this Facebook move is part of changes to how they want to treat all politicians. What kind of differences are you watching for in how politicians use Facebook? BOND: I think it's all going to come down to how aggressively Facebook actually enforces these new rules. I asked this of Paul Barrett, who's deputy director at NYU's Center for Business and Human Rights. Here's what he said. PAUL BARRETT: It'll all depend on whether Facebook has the courage of its convictions. That'll really be a whole new world for public figures who, I think, are generally speaking quite used to using language in kind of extreme and often reckless ways. BOND: And, you know, the reason they've done that is that, as we've reported, for years Facebook has given politicians lots of leeway in what they post. Zuckerberg has said political speech is already highly scrutinized. He doesn't want to be the arbiter of truth. So this is a big shift here. Facebook is now saying politicians - not just Trump but any political leader anywhere in the world - will be held mostly to the same rules as other users. And in some cases, these kind of figures - they should actually be held to a higher standard. That's a big change here. KELLY: Thank you, Shannon. BOND: Thank you, Mary Louise. KELLY: NPR's Shannon Bond. MARY LOUISE KELLY, HOST:   Facebook has extended former President Donald Trump's suspension for at least two years, and it says they'll only reinstate him then if, quote, \"the risk to public safety has receded. \" It's part of big changes the social media company is making to how it treats all politicians. NPR tech correspondent Shannon Bond joins us. And I need to note Facebook is among NPR's financial supporters. Hey, Shannon. SHANNON BOND, BYLINE: Hey, Mary Louise. KELLY: OK, so as we noted, Trump was already suspended. Facebook suspended him right after the January 6 attack on the U. S. Capitol. So what exactly is new today? BOND: Well, at the time, Facebook said Trump was kicked off indefinitely. It's now put a time frame on this penalty. So he can't return before January 2023. And this is in response to Facebook's Oversight Board, which is this group of outside experts that Facebook created to review its toughest calls. Facebook had asked the board to weigh in on the Trump case. And last month, the board said, OK, suspending Trump was the right move. But it said Facebook can't just indefinitely suspend someone. That kind of penalty needs clear rules, a clear time frame. We should also note Facebook was not the only platform to kick off Trump. Twitter banned him permanently after January 6. KELLY: And do we know why this time frame? Is there something special about January 2023? BOND: Well, also at the board's urging, Facebook has set these new rules for how it treats public figures in times of civil unrest and violence, for cases just like this one. And so it says under those new rules, the maximum suspension is two years and that what Trump did in stoking this violence was so serious, he deserves that maximum. To be clear, it hasn't explained why two years is the maximum. What it means is that once 2023 rolls around, Facebook will consider whether there's still a serious risk to public safety before letting Trump back. And if he does come back, he will face stricter penalties, including the possibility of a permanent ban if he keeps breaking Facebook's rules. KELLY: What are we hearing in reaction to this from Trump? BOND: He put out a statement describing Facebook's decision as an insult to the people who voted for him and continued his baseless attacks on the legitimacy of the 2020 election. He then followed up with another statement, hinting he would run for the presidency again and taking direct aim at Facebook's CEO. He said, quote, \"Next time I'm in the White House, there will be no more dinners, at his request, with Mark Zuckerberg and his wife. It will be all business. \" But Trump is not the only person unhappy. Many critics of Facebook are also unhappy with this decision. Civil rights groups and others - they say Facebook - Trump should be permanently banned already. And they're worried that he's going to be back in time for the next presidential election in 2024. KELLY: Shannon, just setting Trump aside for a second, we mentioned this Facebook move is part of changes to how they want to treat all politicians. What kind of differences are you watching for in how politicians use Facebook? BOND: I think it's all going to come down to how aggressively Facebook actually enforces these new rules. I asked this of Paul Barrett, who's deputy director at NYU's Center for Business and Human Rights. Here's what he said. PAUL BARRETT: It'll all depend on whether Facebook has the courage of its convictions. That'll really be a whole new world for public figures who, I think, are generally speaking quite used to using language in kind of extreme and often reckless ways. BOND: And, you know, the reason they've done that is that, as we've reported, for years Facebook has given politicians lots of leeway in what they post. Zuckerberg has said political speech is already highly scrutinized. He doesn't want to be the arbiter of truth. So this is a big shift here. Facebook is now saying politicians - not just Trump but any political leader anywhere in the world - will be held mostly to the same rules as other users. And in some cases, these kind of figures - they should actually be held to a higher standard. That's a big change here. KELLY: Thank you, Shannon. BOND: Thank you, Mary Louise. KELLY: NPR's Shannon Bond.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-06-05-1003623528": {"title": "California Approves A Pilot Program For Driverless Rides : NPR", "url": "https://www.npr.org/2021/06/05/1003623528/california-approves-pilot-program-for-driverless-rides", "author": "No author found", "published_date": "2021-06-05", "content": "", "section": "Technology", "disclaimer": ""}, "2021-06-06-1003755600": {"title": "El Salvador's President Proposes Using Bitcoin As Legal Tender : NPR", "url": "https://www.npr.org/2021/06/06/1003755600/bitcoin-cryptocurrency-money-el-salvador", "author": "No author found", "published_date": "2021-06-06", "content": "", "section": "Latin America", "disclaimer": ""}, "2021-06-07-1003972313": {"title": "Cyberattackers Target Companies, Demand Millions In Ransom : Consider This from NPR : NPR", "url": "https://www.npr.org/2021/06/07/1003972313/how-the-biden-administration-is-confronting-a-surge-in-cyberattacks", "author": "No author found", "published_date": "2021-06-07", "content": "AUDIE CORNISH, HOST:  A month ago, a pipeline carrying roughly 45% of fuel supplies for the entire East Coast went offline. (SOUNDBITE OF TV SHOW, \"NBC NIGHTLY NEWS\")JOSE DIAZ-BALART: Pipeline cyberattack - a major source of our nation's fuel shut down by hackers demanding ransom. CORNISH: Five thousand five hundred miles of a pipeline run by Colonial Pipeline Company were shut down after hackers broke into the company's computer systems, encrypted certain data and demanded a ransom to unlock them. That's what's known as a ransomware attack. (SOUNDBITE OF TV SHOW, \"THE WEEK WITH JOSHUA JOHNSON\")BLAYNE ALEXANDER: Across the Southeast and up the East Coast, gas prices are going up, and pumps are going dry. CORNISH: The pipeline's week-long shutdown led to panic buying, which caused widespread fuel shortages and temporary price hikes. And the hackers - well, they got what they wanted. (SOUNDBITE OF ARCHIVED NPR BROADCAST)JOE BLOUNT: Of course, the initial thought is you don't want to pay the ransom. You don't want to encourage. You don't want to pay these contemptible criminals. CORNISH: Colonial Pipeline CEO Joe Blount told NPR his company agreed to pay hackers, believed to be Russian, a ransom of nearly $4. 5 million to get its pipeline back online. (SOUNDBITE OF ARCHIVED NPR BROADCAST)BLOUNT: When you know that you have 100 million gallons of gasolines and diesel fuels and jet fuels that are going to go across the Southeastern and Eastern Seaboard of the United States, it's a very critical decision to make. And if owning that, the encryption tool, gets you there quicker, then it's the decision that had to be made. (SOUNDBITE OF MUSIC)CORNISH: CONSIDER THIS - attacks like the Colonial Pipeline hack are on the rise, and now the U. S. government says it will start treating them like terrorism. From NPR, I'm Audie Cornish. It's Monday, June 7. It's CONSIDER THIS FROM NPR. The director of the FBI says this is a moment like 9/11, when the U. S. had to face a new reality about an existential threat. In a print interview this week with The Wall Street Journal, Christopher Wray said, quote, \"there's a shared responsibility not just across government agencies, but across the private sector and even the average American. \" He wasn't just talking about the Colonial Pipeline hack. Right now, Wray told the Journal, the FBI is investigating around a hundred different types of ransomware, many tracing back to hackers in Russia. (SOUNDBITE OF TV SHOW, \"SQUAWK BOX\")BECKY QUICK: We are learning more about the scale of the hack into Microsoft's Exchange Server email software. Hundreds of thousands of government offices, small businesses and schools could be affected. CORNISH: In recent months, Microsoft's email service was compromised and left the company scrambling to push out software fixes to customers. Another attack happened in Florida, where hackers targeted a water treatment plant using remote access to increase levels of dangerous chemicals in the water supply. (SOUNDBITE OF TV SHOW, \"WORLD NEWS TONIGHT WITH DAVID MUIR\")VICTOR OQUENDO: City officials have disabled that remote access system that was used in the hack. There are several safeguards in place that would have prevented that contaminated water from ever entering the supply. CORNISH: And just last week. . . (SOUNDBITE OF TV SHOW, \"CNN NEWSROOM\")ALISYN CAMEROTA: Another U. S. company victimized by a cyberattack. CORNISH: . . . JBS, the world's largest meat supplier, was targeted with ransomware. (SOUNDBITE OF ARCHIVED RECORDING)ALEX MARQUARDT: Here in the U. S. , they've got processing facilities that do chicken, beef and pork. CORNISH: All of those facilities were shut down for a few days. And the FBI later said that it appeared a Russian-linked group of hackers was behind the attack. JBS plants are back up now, and it's unclear if the company paid any ransom to hackers. (SOUNDBITE OF ARCHIVED NPR BROADCAST)ANNE NEUBERGER: Ransomware is a difficult problem. CORNISH: In an interview with NPR last month, Anne Neuberger, the senior White House adviser in charge of the cyber response, acknowledged that some companies simply are not equipped to defend themselves from ransomware attacks. (SOUNDBITE OF ARCHIVED NPR BROADCAST)NEUBERGER: We discourage the payment of ransoms, and we also understand that sometimes companies are in a difficult place if they don't have backups. I hope that each company, each government agency that looks at the number of incidents that have occurred recognize the need for us to build secure and resilient digital infrastructure. (SOUNDBITE OF MUSIC)CORNISH: And how will the Biden administration help companies do that? Well, that's the question our national security correspondent Greg Myre has been looking into. (SOUNDBITE OF ARCHIVED NPR BROADCAST)GREG MYRE: President Biden received no grace period when it came to cyber. APRIL FALCON DOSS: The cyber pressures that this administration has faced so far have been relentless. MYRE: April Falcon Doss is a former National Security Agency official who now heads a technology program at Georgetown's law school. As the cyber breaches pile up, cyber experts say it's important to note the two distinct threats. Glenn Gerstell was a senior NSA official until last year. GLENN GERSTELL: There clearly is a dividing line between cyber hacks for intelligence-gathering purposes and these ransomware attacks that are designed principally for financial benefit. MYRE: On one side of that line is the SolarWinds attack uncovered last December. This was intelligence gathering by Russian spies quietly stealing U. S. government secrets. On the other side is ransomware, which is surging. These require different responses, Gerstell says, but he's quick to add. . . GERSTELL: Both the intelligence attacks and some of the most significant ransomware attacks we have have one thing in common, and that's Russia. MYRE: Biden says he'll raise the cyber issue with Russian leader Vladimir Putin at a June 16 summit in Switzerland. Despite all the evidence, Putin denies Russian involvement in the intelligence hacks and shrugs his shoulders when asked about the ransomware attacks from criminals based in Russia. Gerstell says the U. S. shouldn't accept this answer. GERSTELL: It's almost impossible to believe that a major criminal gang would operate inside of Russia and have real-world effects in the United States and Putin wouldn't know about it. MYRE: FBI Director Christopher Wray told The Wall Street Journal that many of the hundred ransomware variants under investigation are linked to Russia. Last month, Biden laid out his cyber strategy in an executive order. April Falcon Doss says it's a good start. DOSS: There are many departments and agencies across government that really have cybersecurity postures that lag behind where they should be. MYRE: The government does face real limits when it comes to ransomware and private companies. DOSS: The government won't be able to actively protect the private sector from any possible ransomware attack because, thankfully, the government doesn't control the internet, right? We wouldn't want that. MYRE: Protecting the private sector falls to people like Adam Meyers, vice president for intelligence at the cybersecurity firm CrowdStrike. ADAM MEYERS: These companies can't put their head in the sand and hope it's not going to happen to them. It is going to happen to them. It's going to be a matter of when. MYRE: Meyers says too many companies aren't keeping their cyberdefenses up to date. He cites the attack on the meat company JBS, carried out with a malware known as REvil. Meyers knows it well but says many potential victims don't. MEYERS: I guarantee lots of organizations in the food processing world right now Googling how to find, what is REvil? And if you need to look it up when it's happening, you're in a real bad spot. MYRE: How bad? I ask what the current ransom demand is for an attack on a large company. MEYERS: I see the payments going out, and the payments are just, you know, stomach-churning figures - you know, $2 million, $4 million, $8 million, $10 million, $30 million. MYRE: It's a price he believes many more companies will have to pay. (SOUNDBITE OF MUSIC)CORNISH: NPR's Greg Myre. (SOUNDBITE OF MUSIC)CORNISH: Now, as we mentioned, at least one company already has paid a big price to ransomware hackers - Colonial Pipeline Company, which paid more than $4 million in cryptocurrency to hackers. As of Monday, the Justice Department announced that the majority of that money has since been recaptured by FBI investigators who'd been tracing the group behind the attack. In any event, it's true that not all cyber extortion attacks end with a ransom payment. (SOUNDBITE OF ARCHIVED NPR BROADCAST)BILL SIEGEL: It's not a foregone conclusion that a company has to pay a ransom for sure. CORNISH: Bill Siegel runs Coveware It's a company that responds to ransomware attacks and sometimes negotiates with hackers. He spoke to NPR's Rachel Martin about what ransomware negotiations look like from the inside. (SOUNDBITE OF ARCHIVED NPR BROADCAST)SIEGEL: Well, at the end of the day, the goal is to find a way for the company to recover without having to pay at all. RACHEL MARTIN: Does that ever happen? SIEGEL: Oh, yeah, absolutely. A lot of times when an attack happens, it's very difficult for a big company to determine immediately what the situation is because if you're a large company and you've got, you know, 10,000 servers globally and you've got backups at, you know, 15 different locations throughout the globe, it can take days sometimes to actually safely check the integrity of those backups. And so when we're managing a large, you know, enterprise incident, you don't want to start negotiating when you realize you need it; you want to be done. And so we'll kick off negotiation knowing a very likely outcome is that we actually don't end up paying. MARTIN: So you can be negotiating just to buy time so the company can figure out if they have a backup and they can say, sorry, your threat's not good here because we're safe. SIEGEL: Of course, yeah. That's the goal, right? The cost for a large company being down is so substantial that hours can mean the difference in, you know, millions or tens of millions of dollars of lost profit. Or in the case of a, you know, a hospital or something, it can mean the difference between life and death. So you don't want to waste any time. You want to basically get to the finish line and be ready, even if the conclusion is, well, we don't need to do anything. And that's the best conclusion. MARTIN: Are you able to tell us the origin country of most of the cyberattacks that you see? SIEGEL: You know, we don't do very detailed attribution. What I would say is that the contributory factors that have led us to where we are today are as much socioeconomic as they are other things. There are such low barriers to entry to cybercrime, and there are lots of well-educated, sometimes STEM-educated individuals in lots of parts of the world. They don't have the job prospects that will pay them the money that they aspire to make, and sometimes their local jurisdictions are kind of out of the reach of Western law enforcement. And it's - you know, while it may be sort of frowned upon, it's sort of condoned by wherever they live - right? - because the local economy actually benefits from the laundered proceeds of those attacks filtering back in. These people are buying houses and buying Starbucks and buying cars. And that's a good thing for the local economy, so they sort of look the other way. MARTIN: If a situation occurs, a cyberattack happens, the company is forced to pay ransom, what's to prevent those same hackers from, six months, a year later, just coming back and doing the same thing again? SIEGEL: Yeah, there's absolutely nothing, is the answer. One of the biggest fallacies and misunderstood aspects of these attacks is that they are like lightning strikes, right? It's like, oh, it happened once; it's not going to happen again. That's just - that's not the way it works. The groups that are carrying this out are part of a very well-organized and a very large industry. If it is cost effective - i. e. , cheap - to attack a company and has a high likelihood of being profitable at low risk, they will do it, and they will do it over and over and over again, just like any other business would do the exact same thing if they found a very cheap way to sell very high-profit products. And so if. . . MARTIN: You've seen this? SIEGEL: Yeah, of course. If a company does not take it seriously and they don't fix the vulnerabilities that allowed it to happen in the first place, there's a 100% chance it happens again. (SOUNDBITE OF MUSIC)CORNISH: Bill Siegel, the CEO of Coveware. He spoke to NPR's Rachel Martin on Morning Edition. (SOUNDBITE OF MUSIC)CORNISH: It's CONSIDER THIS FROM NPR. I'm Audie Cornish. (SOUNDBITE OF MUSIC) AUDIE CORNISH, HOST:   A month ago, a pipeline carrying roughly 45% of fuel supplies for the entire East Coast went offline. (SOUNDBITE OF TV SHOW, \"NBC NIGHTLY NEWS\") JOSE DIAZ-BALART: Pipeline cyberattack - a major source of our nation's fuel shut down by hackers demanding ransom. CORNISH: Five thousand five hundred miles of a pipeline run by Colonial Pipeline Company were shut down after hackers broke into the company's computer systems, encrypted certain data and demanded a ransom to unlock them. That's what's known as a ransomware attack. (SOUNDBITE OF TV SHOW, \"THE WEEK WITH JOSHUA JOHNSON\") BLAYNE ALEXANDER: Across the Southeast and up the East Coast, gas prices are going up, and pumps are going dry. CORNISH: The pipeline's week-long shutdown led to panic buying, which caused widespread fuel shortages and temporary price hikes. And the hackers - well, they got what they wanted. (SOUNDBITE OF ARCHIVED NPR BROADCAST) JOE BLOUNT: Of course, the initial thought is you don't want to pay the ransom. You don't want to encourage. You don't want to pay these contemptible criminals. CORNISH: Colonial Pipeline CEO Joe Blount told NPR his company agreed to pay hackers, believed to be Russian, a ransom of nearly $4. 5 million to get its pipeline back online. (SOUNDBITE OF ARCHIVED NPR BROADCAST) BLOUNT: When you know that you have 100 million gallons of gasolines and diesel fuels and jet fuels that are going to go across the Southeastern and Eastern Seaboard of the United States, it's a very critical decision to make. And if owning that, the encryption tool, gets you there quicker, then it's the decision that had to be made. (SOUNDBITE OF MUSIC) CORNISH: CONSIDER THIS - attacks like the Colonial Pipeline hack are on the rise, and now the U. S. government says it will start treating them like terrorism. From NPR, I'm Audie Cornish. It's Monday, June 7. It's CONSIDER THIS FROM NPR. The director of the FBI says this is a moment like 9/11, when the U. S. had to face a new reality about an existential threat. In a print interview this week with The Wall Street Journal, Christopher Wray said, quote, \"there's a shared responsibility not just across government agencies, but across the private sector and even the average American. \" He wasn't just talking about the Colonial Pipeline hack. Right now, Wray told the Journal, the FBI is investigating around a hundred different types of ransomware, many tracing back to hackers in Russia. (SOUNDBITE OF TV SHOW, \"SQUAWK BOX\") BECKY QUICK: We are learning more about the scale of the hack into Microsoft's Exchange Server email software. Hundreds of thousands of government offices, small businesses and schools could be affected. CORNISH: In recent months, Microsoft's email service was compromised and left the company scrambling to push out software fixes to customers. Another attack happened in Florida, where hackers targeted a water treatment plant using remote access to increase levels of dangerous chemicals in the water supply. (SOUNDBITE OF TV SHOW, \"WORLD NEWS TONIGHT WITH DAVID MUIR\") VICTOR OQUENDO: City officials have disabled that remote access system that was used in the hack. There are several safeguards in place that would have prevented that contaminated water from ever entering the supply. CORNISH: And just last week. . . (SOUNDBITE OF TV SHOW, \"CNN NEWSROOM\") ALISYN CAMEROTA: Another U. S. company victimized by a cyberattack. CORNISH: . . . JBS, the world's largest meat supplier, was targeted with ransomware. (SOUNDBITE OF ARCHIVED RECORDING) ALEX MARQUARDT: Here in the U. S. , they've got processing facilities that do chicken, beef and pork. CORNISH: All of those facilities were shut down for a few days. And the FBI later said that it appeared a Russian-linked group of hackers was behind the attack. JBS plants are back up now, and it's unclear if the company paid any ransom to hackers. (SOUNDBITE OF ARCHIVED NPR BROADCAST) ANNE NEUBERGER: Ransomware is a difficult problem. CORNISH: In an interview with NPR last month, Anne Neuberger, the senior White House adviser in charge of the cyber response, acknowledged that some companies simply are not equipped to defend themselves from ransomware attacks. (SOUNDBITE OF ARCHIVED NPR BROADCAST) NEUBERGER: We discourage the payment of ransoms, and we also understand that sometimes companies are in a difficult place if they don't have backups. I hope that each company, each government agency that looks at the number of incidents that have occurred recognize the need for us to build secure and resilient digital infrastructure. (SOUNDBITE OF MUSIC) CORNISH: And how will the Biden administration help companies do that? Well, that's the question our national security correspondent Greg Myre has been looking into. (SOUNDBITE OF ARCHIVED NPR BROADCAST) GREG MYRE: President Biden received no grace period when it came to cyber. APRIL FALCON DOSS: The cyber pressures that this administration has faced so far have been relentless. MYRE: April Falcon Doss is a former National Security Agency official who now heads a technology program at Georgetown's law school. As the cyber breaches pile up, cyber experts say it's important to note the two distinct threats. Glenn Gerstell was a senior NSA official until last year. GLENN GERSTELL: There clearly is a dividing line between cyber hacks for intelligence-gathering purposes and these ransomware attacks that are designed principally for financial benefit. MYRE: On one side of that line is the SolarWinds attack uncovered last December. This was intelligence gathering by Russian spies quietly stealing U. S. government secrets. On the other side is ransomware, which is surging. These require different responses, Gerstell says, but he's quick to add. . . GERSTELL: Both the intelligence attacks and some of the most significant ransomware attacks we have have one thing in common, and that's Russia. MYRE: Biden says he'll raise the cyber issue with Russian leader Vladimir Putin at a June 16 summit in Switzerland. Despite all the evidence, Putin denies Russian involvement in the intelligence hacks and shrugs his shoulders when asked about the ransomware attacks from criminals based in Russia. Gerstell says the U. S. shouldn't accept this answer. GERSTELL: It's almost impossible to believe that a major criminal gang would operate inside of Russia and have real-world effects in the United States and Putin wouldn't know about it. MYRE: FBI Director Christopher Wray told The Wall Street Journal that many of the hundred ransomware variants under investigation are linked to Russia. Last month, Biden laid out his cyber strategy in an executive order. April Falcon Doss says it's a good start. DOSS: There are many departments and agencies across government that really have cybersecurity postures that lag behind where they should be. MYRE: The government does face real limits when it comes to ransomware and private companies. DOSS: The government won't be able to actively protect the private sector from any possible ransomware attack because, thankfully, the government doesn't control the internet, right? We wouldn't want that. MYRE: Protecting the private sector falls to people like Adam Meyers, vice president for intelligence at the cybersecurity firm CrowdStrike. ADAM MEYERS: These companies can't put their head in the sand and hope it's not going to happen to them. It is going to happen to them. It's going to be a matter of when. MYRE: Meyers says too many companies aren't keeping their cyberdefenses up to date. He cites the attack on the meat company JBS, carried out with a malware known as REvil. Meyers knows it well but says many potential victims don't. MEYERS: I guarantee lots of organizations in the food processing world right now Googling how to find, what is REvil? And if you need to look it up when it's happening, you're in a real bad spot. MYRE: How bad? I ask what the current ransom demand is for an attack on a large company. MEYERS: I see the payments going out, and the payments are just, you know, stomach-churning figures - you know, $2 million, $4 million, $8 million, $10 million, $30 million. MYRE: It's a price he believes many more companies will have to pay. (SOUNDBITE OF MUSIC) CORNISH: NPR's Greg Myre. (SOUNDBITE OF MUSIC) CORNISH: Now, as we mentioned, at least one company already has paid a big price to ransomware hackers - Colonial Pipeline Company, which paid more than $4 million in cryptocurrency to hackers. As of Monday, the Justice Department announced that the majority of that money has since been recaptured by FBI investigators who'd been tracing the group behind the attack. In any event, it's true that not all cyber extortion attacks end with a ransom payment. (SOUNDBITE OF ARCHIVED NPR BROADCAST) BILL SIEGEL: It's not a foregone conclusion that a company has to pay a ransom for sure. CORNISH: Bill Siegel runs Coveware It's a company that responds to ransomware attacks and sometimes negotiates with hackers. He spoke to NPR's Rachel Martin about what ransomware negotiations look like from the inside. (SOUNDBITE OF ARCHIVED NPR BROADCAST) SIEGEL: Well, at the end of the day, the goal is to find a way for the company to recover without having to pay at all. RACHEL MARTIN: Does that ever happen? SIEGEL: Oh, yeah, absolutely. A lot of times when an attack happens, it's very difficult for a big company to determine immediately what the situation is because if you're a large company and you've got, you know, 10,000 servers globally and you've got backups at, you know, 15 different locations throughout the globe, it can take days sometimes to actually safely check the integrity of those backups. And so when we're managing a large, you know, enterprise incident, you don't want to start negotiating when you realize you need it; you want to be done. And so we'll kick off negotiation knowing a very likely outcome is that we actually don't end up paying. MARTIN: So you can be negotiating just to buy time so the company can figure out if they have a backup and they can say, sorry, your threat's not good here because we're safe. SIEGEL: Of course, yeah. That's the goal, right? The cost for a large company being down is so substantial that hours can mean the difference in, you know, millions or tens of millions of dollars of lost profit. Or in the case of a, you know, a hospital or something, it can mean the difference between life and death. So you don't want to waste any time. You want to basically get to the finish line and be ready, even if the conclusion is, well, we don't need to do anything. And that's the best conclusion. MARTIN: Are you able to tell us the origin country of most of the cyberattacks that you see? SIEGEL: You know, we don't do very detailed attribution. What I would say is that the contributory factors that have led us to where we are today are as much socioeconomic as they are other things. There are such low barriers to entry to cybercrime, and there are lots of well-educated, sometimes STEM-educated individuals in lots of parts of the world. They don't have the job prospects that will pay them the money that they aspire to make, and sometimes their local jurisdictions are kind of out of the reach of Western law enforcement. And it's - you know, while it may be sort of frowned upon, it's sort of condoned by wherever they live - right? - because the local economy actually benefits from the laundered proceeds of those attacks filtering back in. These people are buying houses and buying Starbucks and buying cars. And that's a good thing for the local economy, so they sort of look the other way. MARTIN: If a situation occurs, a cyberattack happens, the company is forced to pay ransom, what's to prevent those same hackers from, six months, a year later, just coming back and doing the same thing again? SIEGEL: Yeah, there's absolutely nothing, is the answer. One of the biggest fallacies and misunderstood aspects of these attacks is that they are like lightning strikes, right? It's like, oh, it happened once; it's not going to happen again. That's just - that's not the way it works. The groups that are carrying this out are part of a very well-organized and a very large industry. If it is cost effective - i. e. , cheap - to attack a company and has a high likelihood of being profitable at low risk, they will do it, and they will do it over and over and over again, just like any other business would do the exact same thing if they found a very cheap way to sell very high-profit products. And so if. . . MARTIN: You've seen this? SIEGEL: Yeah, of course. If a company does not take it seriously and they don't fix the vulnerabilities that allowed it to happen in the first place, there's a 100% chance it happens again. (SOUNDBITE OF MUSIC) CORNISH: Bill Siegel, the CEO of Coveware. He spoke to NPR's Rachel Martin on Morning Edition. (SOUNDBITE OF MUSIC) CORNISH: It's CONSIDER THIS FROM NPR. I'm Audie Cornish. (SOUNDBITE OF MUSIC)", "section": "How The Biden Administration Is Confronting A Surge In Cyberattacks", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-06-07-1004050873": {"title": "Some Of Bitcoin Ransom Paid By Colonial Pipeline Recovered By U.S. Government : NPR", "url": "https://www.npr.org/2021/06/07/1004050873/u-s-retrieves-some-of-the-colonial-pipeline-ransom", "author": "No author found", "published_date": "2021-06-07", "content": "", "section": "Business", "disclaimer": ""}, "2021-06-07-1004101336": {"title": "Did Zoom Trounce Google Meet? : The Indicator from Planet Money : NPR", "url": "https://www.npr.org/2021/06/07/1004101336/a-technology-tale-david-beats-goliath", "author": "No author found", "published_date": "2021-06-07", "content": "SYLVIE DOUGLIS, BYLINE: NPR. (SOUNDBITE OF DROP ELECTRIC SONG, \"WAKING UP TO THE FIRE\")SALLY HERSHIPS, HOST:  So, Stacey, how many Zoom calls have you been on today, not counting this one? STACEY VANEK SMITH, HOST:  So many Zoom calls - that's all I do all day is stare at my face and other people's faces on Zoom. HERSHIPS: I hear you. And multiple estimates say that out of all the online conferencing software, Zoom is the most popular. Last year, its mobile app was downloaded 485 million times. It's, like, become the generic name for something, like Jacuzzi or Scotch tape, and that is huge for a brand. But there is a mystery afoot. I'm Sally Herships. VANEK SMITH: And I'm Stacey Vanek Smith on tenterhooks. HERSHIPS: (Laughter). VANEK SMITH: This is THE INDICATOR FROM PLANET MONEY. The global market for conferencing software is worth $8. 7 billion, and there are all these huge players vying for that money. I mean, like, Google has 120,000 employees. Microsoft has over 150,000 workers. Zoom has just a few thousand. It's pretty tiny. Zoom should never have beaten out its mammoth competition, so how did it do it? Today on the show - a David-and-Goliath tale of technology. (SOUNDBITE OF MUSIC)HERSHIPS: Wayne Kurtzman is a research analyst who covers social conference platforms like Zoom, so he spends a lot of time thinking about why some companies are more successful than others. WAYNE KURTZMAN: What Zoom did right was something really, really simple. It focused on delivering happiness. And that sounds so esoteric and so nonbusiness that it's perfect. HERSHIPS: OK, wait a second. I have to push back a tiny bit (laughter) here because as somebody who has spent, like, a great deal of the pandemic on Zoom, I don't know how happy Zoom makes me. KURTZMAN: Maybe a lot happier than not having Zoom. VANEK SMITH: Zoom's mission statement is to, quote, \"make video communication frictionless\" and its philosophy is, quote, \"delivering happiness. \" For a lot of us, especially during the pandemic, videoconferencing has delivered a lot of happiness. I mean, it has been a way to see friends, loved ones, family that you just could not see in person. It's also been a way to keep your business going. HERSHIPS: But let's be honest. There is kind of a love-hate thing going on with online conferencing. It does not always make us happy, so we are going to circle back to this later. VANEK SMITH: I will hold you to that, Sally Herships, because we have things to discuss. But in the meantime, Wayne says, when the pandemic was at its height, it was this very particular, really difficult time. And he says Zoom offered videoconferencing that didn't create, you know, another source of stress. KURTZMAN: It just works. There are only about seven buttons maximum on any given screen. It just works. And that's actually why we use a lot of Google and a lot of the things we use. When it just works, we're happy. HERSHIPS: Still, there are these other enormous companies that offer similar services, and Zoom managed to beat them - like Cisco and Google. So let's look at their mission statements too. Let's start with Cisco's because Eric Yuan, Zoom's CEO, used to work there. Stacey, would you please read Cisco's mission statement? VANEK SMITH: Absolutely. Here it is; quote, \"to inspire new possibilities for our customers by reimagining their applications, securing their data, transforming their infrastructure and empowering their teams. \"HERSHIPS: How are you feeling? VANEK SMITH: Lost. HERSHIPS: (Laughter). VANEK SMITH: You know, happiness - I choose happiness, Sally. And Eric reportedly says that when he worked at Cisco, he, quote, \"did not see a single happy customer. \" I mean, granted, he's now the competition, so you might take that with a grain of salt - but still. And it is true that Zoom has all these really fun features. For instance, you know, I'm talking to you now from the surface of Mars. I could have a mustache if I wanted to, or there's, like, skin-smoothing technology to make you look, like, young and fabulous. HERSHIPS: This is all true. But sometimes, these special effects can backfire, which is exactly what happened to this lawyer in Texas who had what you might call a tiny little mishap during virtual court. And you need to know his filter was a cat. (SOUNDBITE OF ARCHIVED RECORDING)ROY FERGUSON: Mr. Ponton, I believe you have a filter turned on in the video settings. You might want to take a. . . ROD PONTON: Ah (ph), I'm trying to - can you hear me, Judge? VANEK SMITH: So if somehow you missed this video, it is - it's epic. It's, like, this little - huge kitten face. It's so sweet with, like, little folded-down ears and these giant rolling eyes, and the little kitten's mouth is moving along with the lawyer's. So you have, like, these two very serious men sort of peering into their cameras with this cat talking to them. (SOUNDBITE OF ARCHIVED RECORDING)PONTON: I'm here live. I'm not a cat. (LAUGHTER)VANEK SMITH: It's amazing. I mean, it's, like, in my opinion, one of the best things to come out of 2020 (laughter). Anyway, back to Cisco, which does not have a cat filter. When Eric left Cisco and founded Zoom, he decided to make happiness key. And Wayne the analyst says don't be skeptical. The strategy worked. KURTZMAN: Even talking to a lot of the folks who are working at Zoom, it wasn't just something on the board that they followed. It really had a different way that they handle customers. VANEK SMITH: But, of course, we can't really keep talking about Zoom's big win without looking at one of its biggest contenders - the 800-pound gorilla, Google. Google, you know, basically owns us all. We use Gmail and Calendars and Google Maps. And, you know, Google has its own videoconferencing software, Google Meet - also Google Hangouts. So let's look at Google's mission statement. Here it is; quote, \"to organize the world's information and make it universally accessible and useful. \" Oof (ph), just not - I'm feeling - I'm dead inside. HERSHIPS: But to be fair, Google has been organized. It's been trying to dominate the conferencing market. But unlike Zoom, Google is a giant company. It wants you to use all of its different products and services, so it inadvertently put this speed bump in place. KURTZMAN: One of the challenges Google threw up there - and any barrier at this time, perhaps, is one too much - is that you actually have to use a Gmail address. HERSHIPS: Also, if you are a paying Google Meet customer, you can't just buy Google Meet. You have to buy a package. And this is where Zoom won out again. Not only did Zoom make an effort to be easy to use, but it was also easy to buy, which, in terms of business strategy, sounds almost comically obvious. But again, during all that disruption when the pandemic hit, some of these conferencing software companies were forcing potential customers to talk to a sales rep first. And there could be a wait of multiple weeks to do that. VANEK SMITH: To be fair, Google videoconferencing has done really well. And, of course, Sally, you know, Zoom has had its issues. It has not been totally smooth sailing. Security was a pretty major issue for a while. I don't know if you remember people Zoom bombing, like strangers showing up in meetings. And that's a problem if you're trying to have some kind of secure conversation. Wayne says Zoom has solved the problem, and he said there was a very good reason that it jumped on that issue so quickly. KURTZMAN: Trust, as it's often said, is earned in crops and lost in buckets. HERSHIPS: That makes sense. But we can't talk about Zoom without talking about the other kind of happiness, like the kind I feel draining from my soul (laughter) after a day of staring at a webcam. VANEK SMITH: Oh, my God. HERSHIPS: Zoom fatigue is real. VANEK SMITH: Oh, my gosh - the amount of my brain devoted to, like, worrying about flyaway hair has, like, quintupled the last year (laughter). I spend so much of my time when I'm supposed to be talking about economics wondering, like, if my hair has been doing that all day. It's a problem. HERSHIPS: All right. But still, I think we have to just admit that videoconferencing is probably here to stay. It can make life better in so many ways. VANEK SMITH: Yeah, it definitely can. But I think I'm going to go ahead and turn my camera off right Sally. (SOUNDBITE OF MUSIC)HERSHIPS: This episode was produced by Dave Blanchard. It was fact-checked by Michael He and edited by Kate Concannon. THE INDICATOR is a production of NPR. (SOUNDBITE OF MUSIC)VANEK SMITH: P. S. I am not a cat. HERSHIPS: (Laughter). SYLVIE DOUGLIS, BYLINE: NPR. (SOUNDBITE OF DROP ELECTRIC SONG, \"WAKING UP TO THE FIRE\") SALLY HERSHIPS, HOST:   So, Stacey, how many Zoom calls have you been on today, not counting this one? STACEY VANEK SMITH, HOST:   So many Zoom calls - that's all I do all day is stare at my face and other people's faces on Zoom. HERSHIPS: I hear you. And multiple estimates say that out of all the online conferencing software, Zoom is the most popular. Last year, its mobile app was downloaded 485 million times. It's, like, become the generic name for something, like Jacuzzi or Scotch tape, and that is huge for a brand. But there is a mystery afoot. I'm Sally Herships. VANEK SMITH: And I'm Stacey Vanek Smith on tenterhooks. HERSHIPS: (Laughter). VANEK SMITH: This is THE INDICATOR FROM PLANET MONEY. The global market for conferencing software is worth $8. 7 billion, and there are all these huge players vying for that money. I mean, like, Google has 120,000 employees. Microsoft has over 150,000 workers. Zoom has just a few thousand. It's pretty tiny. Zoom should never have beaten out its mammoth competition, so how did it do it? Today on the show - a David-and-Goliath tale of technology. (SOUNDBITE OF MUSIC) HERSHIPS: Wayne Kurtzman is a research analyst who covers social conference platforms like Zoom, so he spends a lot of time thinking about why some companies are more successful than others. WAYNE KURTZMAN: What Zoom did right was something really, really simple. It focused on delivering happiness. And that sounds so esoteric and so nonbusiness that it's perfect. HERSHIPS: OK, wait a second. I have to push back a tiny bit (laughter) here because as somebody who has spent, like, a great deal of the pandemic on Zoom, I don't know how happy Zoom makes me. KURTZMAN: Maybe a lot happier than not having Zoom. VANEK SMITH: Zoom's mission statement is to, quote, \"make video communication frictionless\" and its philosophy is, quote, \"delivering happiness. \" For a lot of us, especially during the pandemic, videoconferencing has delivered a lot of happiness. I mean, it has been a way to see friends, loved ones, family that you just could not see in person. It's also been a way to keep your business going. HERSHIPS: But let's be honest. There is kind of a love-hate thing going on with online conferencing. It does not always make us happy, so we are going to circle back to this later. VANEK SMITH: I will hold you to that, Sally Herships, because we have things to discuss. But in the meantime, Wayne says, when the pandemic was at its height, it was this very particular, really difficult time. And he says Zoom offered videoconferencing that didn't create, you know, another source of stress. KURTZMAN: It just works. There are only about seven buttons maximum on any given screen. It just works. And that's actually why we use a lot of Google and a lot of the things we use. When it just works, we're happy. HERSHIPS: Still, there are these other enormous companies that offer similar services, and Zoom managed to beat them - like Cisco and Google. So let's look at their mission statements too. Let's start with Cisco's because Eric Yuan, Zoom's CEO, used to work there. Stacey, would you please read Cisco's mission statement? VANEK SMITH: Absolutely. Here it is; quote, \"to inspire new possibilities for our customers by reimagining their applications, securing their data, transforming their infrastructure and empowering their teams. \" HERSHIPS: How are you feeling? VANEK SMITH: Lost. HERSHIPS: (Laughter). VANEK SMITH: You know, happiness - I choose happiness, Sally. And Eric reportedly says that when he worked at Cisco, he, quote, \"did not see a single happy customer. \" I mean, granted, he's now the competition, so you might take that with a grain of salt - but still. And it is true that Zoom has all these really fun features. For instance, you know, I'm talking to you now from the surface of Mars. I could have a mustache if I wanted to, or there's, like, skin-smoothing technology to make you look, like, young and fabulous. HERSHIPS: This is all true. But sometimes, these special effects can backfire, which is exactly what happened to this lawyer in Texas who had what you might call a tiny little mishap during virtual court. And you need to know his filter was a cat. (SOUNDBITE OF ARCHIVED RECORDING) ROY FERGUSON: Mr. Ponton, I believe you have a filter turned on in the video settings. You might want to take a. . . ROD PONTON: Ah (ph), I'm trying to - can you hear me, Judge? VANEK SMITH: So if somehow you missed this video, it is - it's epic. It's, like, this little - huge kitten face. It's so sweet with, like, little folded-down ears and these giant rolling eyes, and the little kitten's mouth is moving along with the lawyer's. So you have, like, these two very serious men sort of peering into their cameras with this cat talking to them. (SOUNDBITE OF ARCHIVED RECORDING) PONTON: I'm here live. I'm not a cat. (LAUGHTER) VANEK SMITH: It's amazing. I mean, it's, like, in my opinion, one of the best things to come out of 2020 (laughter). Anyway, back to Cisco, which does not have a cat filter. When Eric left Cisco and founded Zoom, he decided to make happiness key. And Wayne the analyst says don't be skeptical. The strategy worked. KURTZMAN: Even talking to a lot of the folks who are working at Zoom, it wasn't just something on the board that they followed. It really had a different way that they handle customers. VANEK SMITH: But, of course, we can't really keep talking about Zoom's big win without looking at one of its biggest contenders - the 800-pound gorilla, Google. Google, you know, basically owns us all. We use Gmail and Calendars and Google Maps. And, you know, Google has its own videoconferencing software, Google Meet - also Google Hangouts. So let's look at Google's mission statement. Here it is; quote, \"to organize the world's information and make it universally accessible and useful. \" Oof (ph), just not - I'm feeling - I'm dead inside. HERSHIPS: But to be fair, Google has been organized. It's been trying to dominate the conferencing market. But unlike Zoom, Google is a giant company. It wants you to use all of its different products and services, so it inadvertently put this speed bump in place. KURTZMAN: One of the challenges Google threw up there - and any barrier at this time, perhaps, is one too much - is that you actually have to use a Gmail address. HERSHIPS: Also, if you are a paying Google Meet customer, you can't just buy Google Meet. You have to buy a package. And this is where Zoom won out again. Not only did Zoom make an effort to be easy to use, but it was also easy to buy, which, in terms of business strategy, sounds almost comically obvious. But again, during all that disruption when the pandemic hit, some of these conferencing software companies were forcing potential customers to talk to a sales rep first. And there could be a wait of multiple weeks to do that. VANEK SMITH: To be fair, Google videoconferencing has done really well. And, of course, Sally, you know, Zoom has had its issues. It has not been totally smooth sailing. Security was a pretty major issue for a while. I don't know if you remember people Zoom bombing, like strangers showing up in meetings. And that's a problem if you're trying to have some kind of secure conversation. Wayne says Zoom has solved the problem, and he said there was a very good reason that it jumped on that issue so quickly. KURTZMAN: Trust, as it's often said, is earned in crops and lost in buckets. HERSHIPS: That makes sense. But we can't talk about Zoom without talking about the other kind of happiness, like the kind I feel draining from my soul (laughter) after a day of staring at a webcam. VANEK SMITH: Oh, my God. HERSHIPS: Zoom fatigue is real. VANEK SMITH: Oh, my gosh - the amount of my brain devoted to, like, worrying about flyaway hair has, like, quintupled the last year (laughter). I spend so much of my time when I'm supposed to be talking about economics wondering, like, if my hair has been doing that all day. It's a problem. HERSHIPS: All right. But still, I think we have to just admit that videoconferencing is probably here to stay. It can make life better in so many ways. VANEK SMITH: Yeah, it definitely can. But I think I'm going to go ahead and turn my camera off right Sally. (SOUNDBITE OF MUSIC) HERSHIPS: This episode was produced by Dave Blanchard. It was fact-checked by Michael He and edited by Kate Concannon. THE INDICATOR is a production of NPR. (SOUNDBITE OF MUSIC) VANEK SMITH: P. S. I am not a cat. HERSHIPS: (Laughter).", "section": "A Technology Tale: David Beats Goliath", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-06-08-1004600001": {"title": "The Senate Passes A Bill To Encourage Tech Competition, Especially With China : NPR", "url": "https://www.npr.org/2021/06/08/1004600001/the-senate-passes-a-bill-to-encourage-tech-competition-especially-with-china", "author": "No author found", "published_date": "2021-06-08", "content": "", "section": "National", "disclaimer": ""}, "2021-06-08-1004264531": {"title": "Fake COVID Vaccine Cards Are Sold Online But Using One Is Illegal : NPR", "url": "https://www.npr.org/2021/06/08/1004264531/fake-covid-vaccine-cards-keep-getting-sold-online-using-one-is-a-crime", "author": "No author found", "published_date": "2021-06-08", "content": "", "section": "Law", "disclaimer": ""}, "2021-06-08-1004269902": {"title": "Former Hacker Sheds Light On How Cyber Criminals Operate : NPR", "url": "https://www.npr.org/2021/06/08/1004269902/former-hacker-sheds-light-on-how-cyber-criminals-operate", "author": "No author found", "published_date": "2021-06-08", "content": "LEILA FADEL, HOST:  To find out more about how these cybercriminals operate, we spoke earlier to Dmitry Smilyanets, a threat intelligence analyst for the cybersecurity firm Recorded Future and a former hacker himself. He says the world should get ready for more ransomware attacks. DMITRY SMILYANETS: Unfortunately, there is nothing can stop them at this moment. Hopefully, after that meeting between two presidents, Mr. Biden and Mr. Putin, hopefully there will be a change because only Putin can stop these guys. FADEL: What do you mean by that? SMILYANETS: I mean that without his approval, local law enforcement and Russian federal law enforcement are not investigating these guys. I believe that federal law enforcement in Russia already track those guys. And just by the order, they can stop them immediately. FADEL: President Biden recently said there isn't really evidence that there's links between these hackers and the government. Is that accurate? SMILYANETS: Yes, it is accurate. They are not members of Russian special forces - 100%. These are the guys who are just hackers and criminals and financially motivated guys. But it doesn't mean they don't have connections to the state guys. And I believe most of the guys, top-level guys, have these connections. FADEL: So not sponsored by the government, but if the government took an interest in stopping it, they would be able to. SMILYANETS: Absolutely, and we've witnessed that. After DarkSide attacked Colonial Pipeline, news reached Russian media. So it took them a few hours to shut down completely. That happened immediately, very quickly, like by the script or by the very strict order. FADEL: Do you think that's maybe changed how concerned cybercriminals are about repercussions after the Colonial Pipeline attack? SMILYANETS: I don't think so. There's so much money to be made for them. They are on the hunt for big money, and they will never stop unless stopped by somebody. FADEL: And this is not just a few guys in a basement, right? It sounds like these are very sophisticated operations at this point. SMILYANETS: Absolutely. And some of the groups, you won't believe it, but they have hundreds of people working for them. So it's very organized. It's very professional. FADEL: Why is so much of this happening from Russia? SMILYANETS: Well, it's a great question. Just because they feel safe. Just imagine a greenhouse where your vegetables grow, perfect sunlight, perfect watering system and no wind, nothing bothers them so they can grow. That's what's happening currently in Russia. FADEL: Walk me through how people get started. SMILYANETS: Well, before you buy ransom software package, you go, you join this telegram channels that are full of tutorials and videos. It's just about curiosity and how much free time you have. And I believe young guys in Russia have plenty of free time. FADEL: What do you mean? SMILYANETS: Russia still has great educational system and very strong mathematical school. And unfortunately, young people on graduation, they don't see any opportunities. To start a job without connections, it's pretty hard to find a good job. So these people, if they can't focus on work, daily work, they start exploring possibilities. And the internet is full of these possibilities, including criminal underground. FADEL: What can be done to thwart cyberattacks as we watch really this rise? SMILYANETS: Paying attention to the closest releases of vulnerabilities and patch them as soon as possible, have a good threat intelligence provider that will alert you on new trends or on your credentials being exposed on the dark web. And, well, there is not a 100% solution to prevent it. So I would say pray. It helps because you're vulnerable, and it's just a matter of time when your company will get effected. FADEL: Dmitry Smilyanets, thank you for joining us. SMILYANETS: Thank you very much. LEILA FADEL, HOST:   To find out more about how these cybercriminals operate, we spoke earlier to Dmitry Smilyanets, a threat intelligence analyst for the cybersecurity firm Recorded Future and a former hacker himself. He says the world should get ready for more ransomware attacks. DMITRY SMILYANETS: Unfortunately, there is nothing can stop them at this moment. Hopefully, after that meeting between two presidents, Mr. Biden and Mr. Putin, hopefully there will be a change because only Putin can stop these guys. FADEL: What do you mean by that? SMILYANETS: I mean that without his approval, local law enforcement and Russian federal law enforcement are not investigating these guys. I believe that federal law enforcement in Russia already track those guys. And just by the order, they can stop them immediately. FADEL: President Biden recently said there isn't really evidence that there's links between these hackers and the government. Is that accurate? SMILYANETS: Yes, it is accurate. They are not members of Russian special forces - 100%. These are the guys who are just hackers and criminals and financially motivated guys. But it doesn't mean they don't have connections to the state guys. And I believe most of the guys, top-level guys, have these connections. FADEL: So not sponsored by the government, but if the government took an interest in stopping it, they would be able to. SMILYANETS: Absolutely, and we've witnessed that. After DarkSide attacked Colonial Pipeline, news reached Russian media. So it took them a few hours to shut down completely. That happened immediately, very quickly, like by the script or by the very strict order. FADEL: Do you think that's maybe changed how concerned cybercriminals are about repercussions after the Colonial Pipeline attack? SMILYANETS: I don't think so. There's so much money to be made for them. They are on the hunt for big money, and they will never stop unless stopped by somebody. FADEL: And this is not just a few guys in a basement, right? It sounds like these are very sophisticated operations at this point. SMILYANETS: Absolutely. And some of the groups, you won't believe it, but they have hundreds of people working for them. So it's very organized. It's very professional. FADEL: Why is so much of this happening from Russia? SMILYANETS: Well, it's a great question. Just because they feel safe. Just imagine a greenhouse where your vegetables grow, perfect sunlight, perfect watering system and no wind, nothing bothers them so they can grow. That's what's happening currently in Russia. FADEL: Walk me through how people get started. SMILYANETS: Well, before you buy ransom software package, you go, you join this telegram channels that are full of tutorials and videos. It's just about curiosity and how much free time you have. And I believe young guys in Russia have plenty of free time. FADEL: What do you mean? SMILYANETS: Russia still has great educational system and very strong mathematical school. And unfortunately, young people on graduation, they don't see any opportunities. To start a job without connections, it's pretty hard to find a good job. So these people, if they can't focus on work, daily work, they start exploring possibilities. And the internet is full of these possibilities, including criminal underground. FADEL: What can be done to thwart cyberattacks as we watch really this rise? SMILYANETS: Paying attention to the closest releases of vulnerabilities and patch them as soon as possible, have a good threat intelligence provider that will alert you on new trends or on your credentials being exposed on the dark web. And, well, there is not a 100% solution to prevent it. So I would say pray. It helps because you're vulnerable, and it's just a matter of time when your company will get effected. FADEL: Dmitry Smilyanets, thank you for joining us. SMILYANETS: Thank you very much.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-06-08-1004191828": {"title": "Biden's Plan To Reduce Shortages Of Critical Products : NPR", "url": "https://www.npr.org/2021/06/08/1004191828/how-the-biden-white-house-aims-to-address-risks-to-u-s-supply-chains", "author": "No author found", "published_date": "2021-06-08", "content": "", "section": "Politics", "disclaimer": ""}, "2021-06-09-1004857510": {"title": "How Monoprice sells electronics for as cheap as possible : Planet Money : NPR", "url": "https://www.npr.org/2021/06/09/1004857510/how-stuff-gets-cheaper-classic", "author": "No author found", "published_date": "2021-06-09", "content": "JACOB GOLDSTEIN, HOST:  Hey, just a quick note - today's show is a rerun. It originally ran in 2014. (SOUNDBITE OF ARCHIVED BROADCAST)ROBERT SMITH, HOST:  A while back, I got this big flat-screen TV for my bedroom. It was a banner day. Took it out of the box, set it up over there in the corner. You know what it doesn't come with? It doesn't come with the cables you need to connect it to all your other stuff. So I go to Best Buy, like, hey, I got this new TV. And he's like, yeah, you're going to need an HDMI cable. And bad news, they're $45 - $45 for some wires and plastic. And I paid it. I paid it because otherwise, my TV was just a big thousand-dollar black painting on the wall. GOLDSTEIN: Robert, today, you can go online and buy that exact cable that you paid - whatever, 45 bucks for - today, you can buy it for $3. 61. SMITH: Yeah, I should have waited. Now, we take it for granted that things get cheaper, that there is competition in technological items. There's technological advancement. But we became interested. How does this exactly happen? How does something that used to cost $45, that I was willing to pay $45 for, how does that now cost three or $4? GOLDSTEIN: And there's this one particular company that got famous for selling cheap HDMI cables. The company is called Monoprice. And when they emerged a few years ago, they started out as sort of this cult secret among nerds who loved buying cheap cables. But pretty soon, other companies started noticing as well. Bernard Luthi used to work for one of those companies. BERNARD LUTHI: And I remember. I remember sitting in a room with our CEO, and he asked us, have you heard of this company Monoprice? And he said, they're eating our shorts in - around the cable business. GOLDSTEIN: Eating our shorts. LUTHI: Eating our shorts in the cable business. Is that a term - eating our shorts? (LAUGHTER)LUTHI: No. Well, maybe they were eating our shorts. GOLDSTEIN: Luthi was so impressed by Monoprice he went to work there. He's now the president of the company. SMITH: The story of the HDMI cable is something that Monoprice does over and over again, and not just with cables but with speakers and cameras, electric guitars, literally thousands of other things. And for all that gear, the basic idea is the same. Take something that's popular, take something that people love, and figure out how to sell it for less. (SOUNDBITE OF MUSIC)SMITH: Hello, and welcome back to PLANET MONEY. I'm Robert Smith. GOLDSTEIN: And I'm Jacob Goldstein. Today on the show, we figure out why some stuff gets cheaper, like, say, consumer electronics. There's no law that says they have to get cheaper. And yet, year after year, decade after decade, they do. SMITH: Today, we visit a company where people make this happen. GOLDSTEIN: I went out to Monoprice a few weeks ago. Their headquarters is in this super generic office park in the awesomely named Rancho Cucamonga, Calif. It's at the base of the foothills just outside of LA, and they've got their offices there and this big warehouse. UNIDENTIFIED MAN: It's probably about 174,000 square feet in size. GOLDSTEIN: I feel like everybody always says how many football fields, something like that is. UNIDENTIFIED MAN: I'm not sure how many football fields that is. GOLDSTEIN: I looked it up. You could fit three football fields in the Monoprice warehouse. And cables, it turns out, still a big deal at Monoprice. UNIDENTIFIED MAN: Here are some cables, more cables, 1,000-foot, 500,000-foot cables. We've got cables everywhere. GOLDSTEIN: What's the biggest seller? UNIDENTIFIED MAN: 3992, or a 6-foot HDMI cable. A 6-foot HDMI cables is product number 3992, and it sells like crazy. GOLDSTEIN: You have, like, a trophy on your wall that says 3992 on it? UNIDENTIFIED MAN: No, but everyone knows that number. Everybody in this building knows that PID number. SMITH: Monoprice doesn't just buy cheap stuff from other companies. They don't just find little things in markets in China and then sell it at retail. They design stuff. They tweak it. They put the Monoprice name right on it. GOLDSTEIN: I visited this room at the company's headquarters where a lot of this work happens. It's called the Test Lab. And the first thing to say about the Test Lab is it is not a lab. Picture more like a rec room for somebody who is super into electronics. One side of the room is, like, speaker-land. ALBERT CARDENAS: This is my neck of the woods here. This is my little audio corner. GOLDSTEIN: Albert Cardenas is Monoprice's speaker guy. What is that on the wall? CARDENAS: Basically, it's foam. Kind of looks like a padded cell. (LAUGHTER)GOLDSTEIN: There's speaker parts, speaker boxes, speaker wires. Albert starts taking apart a speaker to show me his work. CARDENAS: And the grille removes. And you get a aluminum mid-range and a three-quarter-inch aluminum tweeter. SMITH: The guys in this room are tinkerers. There's no brand-new concepts. No one's coming up with inventions that no one has ever seen before. The form of progress at Monoprice is to take, like, a little piece of metal in an already existing speaker and just make it a little bit thinner. CARDENAS: So basically, I redesign what's called the faceplate here. GOLDSTEIN: He says this made the sound clearer. He gives me a little demonstration. He puts his hand in front of his mouth. CARDENAS: So this would have been the before. This would have been the after. One more time. This is the before. This is the after. GOLDSTEIN: Another corner of the Test Lab belongs to a guy named Chris Aplin (ph). There's this big fancy monitor sitting on a desk in that corner of the room. Pro-tip - if you want to sound like a savvy tech expert, don't call a monitor a monitor. Call it a display. That's what Chris does. CHRIS APLIN: This is our newest 4K display, utilizing some of the fanciest things on the market right now. I should turn it on for you. SMITH: Chris and Albert's job is to be on the hunt at all times, looking for popular stuff that they can figure out how to sell at a discount. And to be clear about this, there is a lot of popular stuff that Monoprice doesn't sell at all because they take a look at it, and it's already so cheap. GOLDSTEIN: One really striking example of this is flat-screen TVs. If you walk into a store and buy a TV, almost any TV, you are probably paying about what it costs to make that TV and get it to you. You're probably getting a good deal when you buy a flat-screen TV. So Monoprice does not sell flat-screen TVs because there's no way they could sell them at a discount and make a profit. SMITH: So a lot of what happens at Monoprice is essentially detective work - seeing an object and saying, could we make money off of that? And this can take months or even years. GOLDSTEIN: And as it happens, the story of this fancy monitor that Chris just turned on is actually a really good example of the kind of detective work these guys go through to figure this stuff out. That story of the monitor, it starts about four years ago when Chris was walking through a Best Buy. He goes there sometimes to check out the competition. And also, he needed some random thing that Monoprice didn't carry. APLIN: So I was walking by, and the images of honeybees buzzing around on the screen caught my eye. GOLDSTEIN: Chris was way off to the side of the monitor. He wasn't looking straight at it. He was maybe 10 feet away. But even so, he says, it blew his mind. It was better than any monitor he had ever seen. APLIN: I could see the pollen on their abdomen. And I could see every fluttering detail as the wings flapped. It was spectacular. SMITH: And what did you think or feel when you saw it? APLIN: I got to have it (laughter). But unfortunately, I saw the price tag shortly thereafter. And their first introduction was over $1,000. SMITH: The monitor was, of course, made by Apple, a Cinema Display. GOLDSTEIN: Cinema. Chris, in his own words, is a PC fanboy. So what he really wants is a monitor like this one he's staring at in Best Buy, but one that's cheaper and one that's made for a PC. For Chris, a monitor like this would be, and I'm quoting him here, \"a white unicorn. \"APLIN: It was something I dreamed of. It was not available on the market. It was something I so wanted to give to my friends, my - you know, my customers and myself but had no way of getting it. That really was my, like, mythical creature. SMITH: Standing there staring at this thing in Best Buy, Chris starts to think, why is this so expensive? Why does it cost a thousand bucks? Now, it could just be the Apple brand. People are willing to pay a lot of extra money for that logo. Or it could be that only Apple is able to manufacture this monitor. Perhaps they were the first ones to go to some factory in Asia and say, this is exactly what we want. Make this thing. In other words, maybe it's so expensive because there's no competition. GOLDSTEIN: Chris knows he's not going to be able to get some other factory to start making a knockoff. It's just too time-consuming and too expensive for Monoprice to do that. But Chris also knows that when a hot new gadget comes out, there's usually some guy with the right connections at the factory who can get you the the online equivalent of a back-alley deal. APLIN: My thought process was, here, there's no way - no way in hell that. . . SMITH: You can say hell. APLIN: OK. SMITH: Go with it. APLIN: No way in hell that Apple was getting these exclusively made for just them and they weren't getting out somehow. GOLDSTEIN: Coming up in a minute, Chris goes in search of his unicorn. So Chris sees that amazing monitor at Best Buy, and then he goes straight home and starts doing some detective work. APLIN: First things first is I go to eBay. GOLDSTEIN: He types in the specs for the monitor. His search results come up, and he sees that, in fact, there are a few people in Korea who are selling cheaper PC versions of these monitors on eBay. They cost $700 each, and Chris orders two. Then he waits for them to come by ship all the way from Korea. APLIN: So $1,400 later and almost three and a half months of waiting, our monitors finally arrived. One came cracked, essentially split in half, while one was perfectly great in working order. GOLDSTEIN: The one that worked was as beautiful as the monitor Chris had seen in Best Buy. So he does more digging, calls his contacts in Korea, searches this U. S. Customs database that tracks every product that comes into this country. And Chris figures out a few things. The panels for these monitors are being made at a single factory in Korea. And what these guys are selling on eBay is factory rejects - panels that work but that have little flaws in them, flaws that mean Apple won't sell them at retail. This means Chris and Monoprice are stuck. APLIN: There's no way we're going to go out there, buy a factory of rejects, rebuild a monitor and be like, hey, guys, the new hotness is here; buy it for $500. GOLDSTEIN: So for now, Apple still gets the market for this fancy new monitor all to itself. SMITH: But about a year later, Chris starts hearing that the factory in Korea has expanded production of the panels. But demand for the fancy Apple monitor has not kept up. This means there may be a way for Chris and Monoprice to make a deal to get some of those magic panels. Chris goes to Korea to figure out whether the rumors are true or whether somebody's still trying to pass off factory rejects. APLIN: Once we were able to verify that we did, in fact, have our little white unicorn, we showed up with a wad of cash and ordered as many panels as we could. GOLDSTEIN: About nine months later, Monoprice started selling its first version of that fancy monitor. APLIN: We sold it for - oh, it was $425. 99 at the time. That's what it was. GOLDSTEIN: Four hundred and twenty-five bucks. And Apple's monitor, using the same screen, was how much? APLIN: Double our cost, at 999. GOLDSTEIN: So you sold it for half the price. APLIN: Yes. SMITH: To be clear, even though the panel, the screen, is exactly the same as the screen in the Apple monitor, that doesn't mean the whole package is identical to an Apple. One review of the Monoprice monitor had the headline, poor design trumped by great screen, low price. GOLDSTEIN: Still, Chris has done it. The monitor's a hit. Monoprice sells a ton of them. It's a happy ending. But as usually happens in the electronics business, the happy ending doesn't last for long. SMITH: Because Chris Aplin was not the only one chasing the white-unicorn monitor. Samsung actually brought out a similar monitor around the same time. And in the two years since the monitor came out, more factories have started to make similar panels, and more companies have started selling the monitors, which, of course, keep getting better and keep getting cheaper. GOLDSTEIN: How many people sell that monitor now? APLIN: Samsung, BenQ, Dell - one, two, three - five - there's five factories out there now. It has definitely gotten a lot tighter than what it was. SMITH: More companies selling the monitor means more price competition, which means these monitors are moving from that category of something that cost too much to the other category of something that's a good deal. The price of the monitor is now pretty close to the cost of production. GOLDSTEIN: The monitor Chris and I are staring at in the Test Lab, that is already several generations beyond that first one he saw at Best Buy four years ago. And just this fall, Apple brought out a new monitor that's even better than this one. Chris, once again, is chasing after Apple. He says we can expect a Monoprice version sometime next year. (SOUNDBITE OF BRAD LANG'S \"SLIDE BY SLIDE\")SMITH: We always love to hear what you think of the show. Please email us, planetmoney@npr. org or tweet at us. We will see it - @planetmoney. GOLDSTEIN: Robert, you tweet @radiosmith. I tweet @jacobgoldstein. I'd like to say thanks to Geoffrey Morrison, a journalist who's written about Monoprice for CNET, who talked to me for this story, also to the people at IHS who helped me understand some details about the monitor business. SMITH: And thanks to our producer Phia Bennin. Now that you're at the end of the episode, NPR recommends that you check out the TED Radio Hour. You can find it on iTunes, Stitcher or your podcast distribution mechanism. I don't even know what to call those things. You're podcatcher (ph). I'm Robert Smith. GOLDSTEIN: And I'm Jacob Goldstein. SMITH: Thanks for listening. JACOB GOLDSTEIN, HOST:   Hey, just a quick note - today's show is a rerun. It originally ran in 2014. (SOUNDBITE OF ARCHIVED BROADCAST) ROBERT SMITH, HOST:   A while back, I got this big flat-screen TV for my bedroom. It was a banner day. Took it out of the box, set it up over there in the corner. You know what it doesn't come with? It doesn't come with the cables you need to connect it to all your other stuff. So I go to Best Buy, like, hey, I got this new TV. And he's like, yeah, you're going to need an HDMI cable. And bad news, they're $45 - $45 for some wires and plastic. And I paid it. I paid it because otherwise, my TV was just a big thousand-dollar black painting on the wall. GOLDSTEIN: Robert, today, you can go online and buy that exact cable that you paid - whatever, 45 bucks for - today, you can buy it for $3. 61. SMITH: Yeah, I should have waited. Now, we take it for granted that things get cheaper, that there is competition in technological items. There's technological advancement. But we became interested. How does this exactly happen? How does something that used to cost $45, that I was willing to pay $45 for, how does that now cost three or $4? GOLDSTEIN: And there's this one particular company that got famous for selling cheap HDMI cables. The company is called Monoprice. And when they emerged a few years ago, they started out as sort of this cult secret among nerds who loved buying cheap cables. But pretty soon, other companies started noticing as well. Bernard Luthi used to work for one of those companies. BERNARD LUTHI: And I remember. I remember sitting in a room with our CEO, and he asked us, have you heard of this company Monoprice? And he said, they're eating our shorts in - around the cable business. GOLDSTEIN: Eating our shorts. LUTHI: Eating our shorts in the cable business. Is that a term - eating our shorts? (LAUGHTER) LUTHI: No. Well, maybe they were eating our shorts. GOLDSTEIN: Luthi was so impressed by Monoprice he went to work there. He's now the president of the company. SMITH: The story of the HDMI cable is something that Monoprice does over and over again, and not just with cables but with speakers and cameras, electric guitars, literally thousands of other things. And for all that gear, the basic idea is the same. Take something that's popular, take something that people love, and figure out how to sell it for less. (SOUNDBITE OF MUSIC) SMITH: Hello, and welcome back to PLANET MONEY. I'm Robert Smith. GOLDSTEIN: And I'm Jacob Goldstein. Today on the show, we figure out why some stuff gets cheaper, like, say, consumer electronics. There's no law that says they have to get cheaper. And yet, year after year, decade after decade, they do. SMITH: Today, we visit a company where people make this happen. GOLDSTEIN: I went out to Monoprice a few weeks ago. Their headquarters is in this super generic office park in the awesomely named Rancho Cucamonga, Calif. It's at the base of the foothills just outside of LA, and they've got their offices there and this big warehouse. UNIDENTIFIED MAN: It's probably about 174,000 square feet in size. GOLDSTEIN: I feel like everybody always says how many football fields, something like that is. UNIDENTIFIED MAN: I'm not sure how many football fields that is. GOLDSTEIN: I looked it up. You could fit three football fields in the Monoprice warehouse. And cables, it turns out, still a big deal at Monoprice. UNIDENTIFIED MAN: Here are some cables, more cables, 1,000-foot, 500,000-foot cables. We've got cables everywhere. GOLDSTEIN: What's the biggest seller? UNIDENTIFIED MAN: 3992, or a 6-foot HDMI cable. A 6-foot HDMI cables is product number 3992, and it sells like crazy. GOLDSTEIN: You have, like, a trophy on your wall that says 3992 on it? UNIDENTIFIED MAN: No, but everyone knows that number. Everybody in this building knows that PID number. SMITH: Monoprice doesn't just buy cheap stuff from other companies. They don't just find little things in markets in China and then sell it at retail. They design stuff. They tweak it. They put the Monoprice name right on it. GOLDSTEIN: I visited this room at the company's headquarters where a lot of this work happens. It's called the Test Lab. And the first thing to say about the Test Lab is it is not a lab. Picture more like a rec room for somebody who is super into electronics. One side of the room is, like, speaker-land. ALBERT CARDENAS: This is my neck of the woods here. This is my little audio corner. GOLDSTEIN: Albert Cardenas is Monoprice's speaker guy. What is that on the wall? CARDENAS: Basically, it's foam. Kind of looks like a padded cell. (LAUGHTER) GOLDSTEIN: There's speaker parts, speaker boxes, speaker wires. Albert starts taking apart a speaker to show me his work. CARDENAS: And the grille removes. And you get a aluminum mid-range and a three-quarter-inch aluminum tweeter. SMITH: The guys in this room are tinkerers. There's no brand-new concepts. No one's coming up with inventions that no one has ever seen before. The form of progress at Monoprice is to take, like, a little piece of metal in an already existing speaker and just make it a little bit thinner. CARDENAS: So basically, I redesign what's called the faceplate here. GOLDSTEIN: He says this made the sound clearer. He gives me a little demonstration. He puts his hand in front of his mouth. CARDENAS: So this would have been the before. This would have been the after. One more time. This is the before. This is the after. GOLDSTEIN: Another corner of the Test Lab belongs to a guy named Chris Aplin (ph). There's this big fancy monitor sitting on a desk in that corner of the room. Pro-tip - if you want to sound like a savvy tech expert, don't call a monitor a monitor. Call it a display. That's what Chris does. CHRIS APLIN: This is our newest 4K display, utilizing some of the fanciest things on the market right now. I should turn it on for you. SMITH: Chris and Albert's job is to be on the hunt at all times, looking for popular stuff that they can figure out how to sell at a discount. And to be clear about this, there is a lot of popular stuff that Monoprice doesn't sell at all because they take a look at it, and it's already so cheap. GOLDSTEIN: One really striking example of this is flat-screen TVs. If you walk into a store and buy a TV, almost any TV, you are probably paying about what it costs to make that TV and get it to you. You're probably getting a good deal when you buy a flat-screen TV. So Monoprice does not sell flat-screen TVs because there's no way they could sell them at a discount and make a profit. SMITH: So a lot of what happens at Monoprice is essentially detective work - seeing an object and saying, could we make money off of that? And this can take months or even years. GOLDSTEIN: And as it happens, the story of this fancy monitor that Chris just turned on is actually a really good example of the kind of detective work these guys go through to figure this stuff out. That story of the monitor, it starts about four years ago when Chris was walking through a Best Buy. He goes there sometimes to check out the competition. And also, he needed some random thing that Monoprice didn't carry. APLIN: So I was walking by, and the images of honeybees buzzing around on the screen caught my eye. GOLDSTEIN: Chris was way off to the side of the monitor. He wasn't looking straight at it. He was maybe 10 feet away. But even so, he says, it blew his mind. It was better than any monitor he had ever seen. APLIN: I could see the pollen on their abdomen. And I could see every fluttering detail as the wings flapped. It was spectacular. SMITH: And what did you think or feel when you saw it? APLIN: I got to have it (laughter). But unfortunately, I saw the price tag shortly thereafter. And their first introduction was over $1,000. SMITH: The monitor was, of course, made by Apple, a Cinema Display. GOLDSTEIN: Cinema. Chris, in his own words, is a PC fanboy. So what he really wants is a monitor like this one he's staring at in Best Buy, but one that's cheaper and one that's made for a PC. For Chris, a monitor like this would be, and I'm quoting him here, \"a white unicorn. \" APLIN: It was something I dreamed of. It was not available on the market. It was something I so wanted to give to my friends, my - you know, my customers and myself but had no way of getting it. That really was my, like, mythical creature. SMITH: Standing there staring at this thing in Best Buy, Chris starts to think, why is this so expensive? Why does it cost a thousand bucks? Now, it could just be the Apple brand. People are willing to pay a lot of extra money for that logo. Or it could be that only Apple is able to manufacture this monitor. Perhaps they were the first ones to go to some factory in Asia and say, this is exactly what we want. Make this thing. In other words, maybe it's so expensive because there's no competition. GOLDSTEIN: Chris knows he's not going to be able to get some other factory to start making a knockoff. It's just too time-consuming and too expensive for Monoprice to do that. But Chris also knows that when a hot new gadget comes out, there's usually some guy with the right connections at the factory who can get you the the online equivalent of a back-alley deal. APLIN: My thought process was, here, there's no way - no way in hell that. . . SMITH: You can say hell. APLIN: OK. SMITH: Go with it. APLIN: No way in hell that Apple was getting these exclusively made for just them and they weren't getting out somehow. GOLDSTEIN: Coming up in a minute, Chris goes in search of his unicorn. So Chris sees that amazing monitor at Best Buy, and then he goes straight home and starts doing some detective work. APLIN: First things first is I go to eBay. GOLDSTEIN: He types in the specs for the monitor. His search results come up, and he sees that, in fact, there are a few people in Korea who are selling cheaper PC versions of these monitors on eBay. They cost $700 each, and Chris orders two. Then he waits for them to come by ship all the way from Korea. APLIN: So $1,400 later and almost three and a half months of waiting, our monitors finally arrived. One came cracked, essentially split in half, while one was perfectly great in working order. GOLDSTEIN: The one that worked was as beautiful as the monitor Chris had seen in Best Buy. So he does more digging, calls his contacts in Korea, searches this U. S. Customs database that tracks every product that comes into this country. And Chris figures out a few things. The panels for these monitors are being made at a single factory in Korea. And what these guys are selling on eBay is factory rejects - panels that work but that have little flaws in them, flaws that mean Apple won't sell them at retail. This means Chris and Monoprice are stuck. APLIN: There's no way we're going to go out there, buy a factory of rejects, rebuild a monitor and be like, hey, guys, the new hotness is here; buy it for $500. GOLDSTEIN: So for now, Apple still gets the market for this fancy new monitor all to itself. SMITH: But about a year later, Chris starts hearing that the factory in Korea has expanded production of the panels. But demand for the fancy Apple monitor has not kept up. This means there may be a way for Chris and Monoprice to make a deal to get some of those magic panels. Chris goes to Korea to figure out whether the rumors are true or whether somebody's still trying to pass off factory rejects. APLIN: Once we were able to verify that we did, in fact, have our little white unicorn, we showed up with a wad of cash and ordered as many panels as we could. GOLDSTEIN: About nine months later, Monoprice started selling its first version of that fancy monitor. APLIN: We sold it for - oh, it was $425. 99 at the time. That's what it was. GOLDSTEIN: Four hundred and twenty-five bucks. And Apple's monitor, using the same screen, was how much? APLIN: Double our cost, at 999. GOLDSTEIN: So you sold it for half the price. APLIN: Yes. SMITH: To be clear, even though the panel, the screen, is exactly the same as the screen in the Apple monitor, that doesn't mean the whole package is identical to an Apple. One review of the Monoprice monitor had the headline, poor design trumped by great screen, low price. GOLDSTEIN: Still, Chris has done it. The monitor's a hit. Monoprice sells a ton of them. It's a happy ending. But as usually happens in the electronics business, the happy ending doesn't last for long. SMITH: Because Chris Aplin was not the only one chasing the white-unicorn monitor. Samsung actually brought out a similar monitor around the same time. And in the two years since the monitor came out, more factories have started to make similar panels, and more companies have started selling the monitors, which, of course, keep getting better and keep getting cheaper. GOLDSTEIN: How many people sell that monitor now? APLIN: Samsung, BenQ, Dell - one, two, three - five - there's five factories out there now. It has definitely gotten a lot tighter than what it was. SMITH: More companies selling the monitor means more price competition, which means these monitors are moving from that category of something that cost too much to the other category of something that's a good deal. The price of the monitor is now pretty close to the cost of production. GOLDSTEIN: The monitor Chris and I are staring at in the Test Lab, that is already several generations beyond that first one he saw at Best Buy four years ago. And just this fall, Apple brought out a new monitor that's even better than this one. Chris, once again, is chasing after Apple. He says we can expect a Monoprice version sometime next year. (SOUNDBITE OF BRAD LANG'S \"SLIDE BY SLIDE\") SMITH: We always love to hear what you think of the show. Please email us, planetmoney@npr. org or tweet at us. We will see it - @planetmoney. GOLDSTEIN: Robert, you tweet @radiosmith. I tweet @jacobgoldstein. I'd like to say thanks to Geoffrey Morrison, a journalist who's written about Monoprice for CNET, who talked to me for this story, also to the people at IHS who helped me understand some details about the monitor business. SMITH: And thanks to our producer Phia Bennin. Now that you're at the end of the episode, NPR recommends that you check out the TED Radio Hour. You can find it on iTunes, Stitcher or your podcast distribution mechanism. I don't even know what to call those things. You're podcatcher (ph). I'm Robert Smith. GOLDSTEIN: And I'm Jacob Goldstein. SMITH: Thanks for listening.", "section": "How Stuff Gets Cheaper (Classic)", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-06-09-1004750274": {"title": "Biden Drops Trump's Ban on TikTok And WeChat \u2014 But Will Continue The Scrutiny : NPR", "url": "https://www.npr.org/2021/06/09/1004750274/biden-replaces-trump-bans-on-tiktok-wechat-with-order-to-scrutinize-apps", "author": "No author found", "published_date": "2021-06-09", "content": "", "section": "Technology", "disclaimer": ""}, "2021-06-09-1004684932": {"title": "Fastly Says Internet Outage Was Caused By One Customer Changing A Setting : NPR", "url": "https://www.npr.org/2021/06/09/1004684932/fastly-tuesday-internet-outage-down-was-caused-by-one-customer-changing-setting", "author": "No author found", "published_date": "2021-06-09", "content": "", "section": "Business", "disclaimer": ""}, "2021-06-09-1004649214": {"title": "Senate-Passed Bill Encourages Tech Competition, Especially With China : NPR", "url": "https://www.npr.org/2021/06/09/1004649214/senate-passed-bill-encourages-tech-competition-especially-with-china", "author": "No author found", "published_date": "2021-06-09", "content": "RACHEL MARTIN, HOST:  So the Senate did something remarkable yesterday. It passed a bill with strong bipartisan support, and it's a big one. The Innovation and Competition Act of 2021 unlocks nearly $250 billion in funding for science and technology in the U. S. It's designed to counter China's growing strength in those areas. NPR China affairs correspondent John Ruwitch reports. JOHN RUWITCH, BYLINE: The bill passed with more than two-thirds of the Senate in favor, which highlights the level of alarm over China's burgeoning tech prowess. (SOUNDBITE OF ARCHIVED RECORDING)CHUCK SCHUMER: The world is more competitive now than at any time since the end of the second world war. RUWITCH: Senate Majority Leader Chuck Schumer was a key sponsor and led the charge to get it passed. (SOUNDBITE OF ARCHVIED RECORDING)SCHUMER: If we do nothing, our days as the dominant superpower may be ending. We don't mean to let those days end on our watch. We don't mean to see America becoming a middling nation in this century. We mean for America to lead it. RUWITCH: The bill pours close to $200 billion into science and technology research and development through grants, scholarships and other channels. It also allocates $52 billion in emergency funding to boost semiconductor production in America. Michael Santoro, a business school professor at Santa Clara University, likes the basic research funding but says the money for semiconductors is misguided. The U. S. already leads in chip design, and most cutting-edge microchips are manufactured in Taiwan and South Korea, both U. S. friends. MICHAEL SANTORO: We're zagging at the precise moment where we should be zigging. So what is it that makes America strong? Not industrial policy. RUWITCH: He thinks China will probably see the bill as ineffectual. It also won't change Beijing's thinking. SANTORO: Why would you change when your competitor, you know, has told you that they're afraid of you and they're starting to mimic your tactics? RUWITCH: The White House put out a statement saying President Biden applauded the passage of the bill. Now it heads to the House for consideration. John Ruwitch, NPR News. (SOUNDBITE OF AMBINATE'S \"DIVIDE\") RACHEL MARTIN, HOST:   So the Senate did something remarkable yesterday. It passed a bill with strong bipartisan support, and it's a big one. The Innovation and Competition Act of 2021 unlocks nearly $250 billion in funding for science and technology in the U. S. It's designed to counter China's growing strength in those areas. NPR China affairs correspondent John Ruwitch reports. JOHN RUWITCH, BYLINE: The bill passed with more than two-thirds of the Senate in favor, which highlights the level of alarm over China's burgeoning tech prowess. (SOUNDBITE OF ARCHIVED RECORDING) CHUCK SCHUMER: The world is more competitive now than at any time since the end of the second world war. RUWITCH: Senate Majority Leader Chuck Schumer was a key sponsor and led the charge to get it passed. (SOUNDBITE OF ARCHVIED RECORDING) SCHUMER: If we do nothing, our days as the dominant superpower may be ending. We don't mean to let those days end on our watch. We don't mean to see America becoming a middling nation in this century. We mean for America to lead it. RUWITCH: The bill pours close to $200 billion into science and technology research and development through grants, scholarships and other channels. It also allocates $52 billion in emergency funding to boost semiconductor production in America. Michael Santoro, a business school professor at Santa Clara University, likes the basic research funding but says the money for semiconductors is misguided. The U. S. already leads in chip design, and most cutting-edge microchips are manufactured in Taiwan and South Korea, both U. S. friends. MICHAEL SANTORO: We're zagging at the precise moment where we should be zigging. So what is it that makes America strong? Not industrial policy. RUWITCH: He thinks China will probably see the bill as ineffectual. It also won't change Beijing's thinking. SANTORO: Why would you change when your competitor, you know, has told you that they're afraid of you and they're starting to mimic your tactics? RUWITCH: The White House put out a statement saying President Biden applauded the passage of the bill. Now it heads to the House for consideration. John Ruwitch, NPR News. (SOUNDBITE OF AMBINATE'S \"DIVIDE\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-06-10-1005093802": {"title": "Inner Workings Of DarkSide Cybergang Reveal It's Run Like Any Other Business : NPR", "url": "https://www.npr.org/2021/06/10/1005093802/inner-workings-of-darkside-cybergang-reveal-its-run-like-any-other-business", "author": "No author found", "published_date": "2021-06-10", "content": "TERRY GROSS, HOST:  This is FRESH AIR. I'm Terry Gross. Ransomware attacks have disrupted the flow of gas and the supply of meat in just the past few weeks after Colonial Pipeline and JBS, the meat processing company, had their computer systems held hostage for ransom. Similar ransomware attacks have been waged on many companies, large and small, and on hospitals, the police and cities. My guest got an inside look at how the new breed of ransomware attackers operate. Michael Schwirtz is an investigative reporter at The New York Times who gained access to secret communications from the cybercriminal operation DarkSide that attacked Colonial Pipeline. These communications offered what he described as an extraordinary glimpse into the internal workings of a Russian-speaking gang that had become the face of global cybercrime. DarkSide pulled in millions of dollars in ransom payments each month after. They were outed as the attackers of Colonial Pipeline, they went dark. Schwirtz has also reported on the company that attacked JBS, which is called REvil - R-E-V-I-L. These cybercriminals and many others are believed to be operating from Russia. Schwirtz worked in The New York Times' Russia bureau from 2006 to 2012. Last year, he was a lead reporter on the team that won a Pulitzer Prize for a series of articles about Russian intelligence operations around the world. We recorded our interview yesterday morning. Michael Schwirtz, welcome to FRESH AIR. The inner workings of ransomware that you found out were fascinating. Let's start with what you learned the victim sees on the screen when DarkSide captures the computer system. MICHAEL SCHWIRTZ: Right. When the ransomware is uploaded into a victim's computer system, the first thing they see is a ransom note. It says at the top, welcome to DarkSide. And it contains a list of instructions on how the victim can go about unlocking their data. They have no access to their data. And what they need to do is they'll rely on DarkSide by paying a ransom to provide them with a key that will allow them to get these files back. And the letter is written in a kind of very formal, businesslike manner with very subtle threats. They're warned - victims are warned not to try and tamper with their computer systems themselves, try not to access their data themselves, because this may result in the loss of the data completely. And so they're instructed to get in touch immediately with a DarkSide representative to begin negotiations over the ransom. GROSS: And it not only locks victims out of computer systems. The hackers can steal proprietary data. SCHWIRTZ: Right. And this is basically to put added pressure on the business. Not only does the victim risk losing access to important computer files that may be necessary for the day-to-day running of the business, but the hackers will threaten to spill this information into the public domain to be used by competitors, to be used by other hackers to carry out additional attacks on the company. And so they're really, really hard pressed to act very, very quickly to clear this up - the victims are. GROSS: Now, the ransom is paid and cryptocurrency like Bitcoin. Most people don't know how to use Bitcoin. So DarkSide actually has, like, a helpdesk to help the victims pay the ransom. SCHWIRTZ: Right. It's a really user-friendly experience. There's a helpdesk like any other. . . GROSS: Great (laughter). SCHWIRTZ: . . . You know, when your internet goes out, you contact your internet service provider. And sometimes there's a chat. It's a very similar service. And it's the goal of these hackers to make this as simple as possible, so that people are more willing to just pay the ransom and get it out of the way and get back to business, rather than put up a real fight to try and get their data back that wouldn't result in them getting paid. GROSS: DarkSide is a cybercriminal gang, but it's set up like a business with affiliates. What are the affiliates? SCHWIRTZ: What DarkSide does is they're a ransomware creator. So they create the program that is uploaded into a victim's computer system that locks down their data. But what they do is they basically contract out to these affiliates who are other hackers. And these are the people that are responsible for actually penetrating the victim's computer services. And what they do is operate basically on a subscription service. You, as an affiliate, can sign on to DarkSide services, in which case you get access to their malware, their ransomware to use for a fee that operates on a sliding scale depending upon the size of the ransom. GROSS: What's the profit model for both DarkSide and for the affiliate it's working with? For example, Colonial Pipeline was told to pay $4. 5 million to get access again to its computer system. Colonial Pipeline paid the $4. 5 million. How is that divided between DarkSide and the affiliate that actually did the hack? SCHWIRTZ: So DarkSide takes a cut. And so the way it worked with DarkSide, which I am told is fairly generous, if the ransom that was charged that was eventually obtained was less $500,000, DarkSide would take about a 25% cut. And this moved down to about 10% for ransoms over $5 million. So DarkSide would have taken about 10% of the ransom paid by Colonial Pipeline for its attack, with the remaining going to the affiliate, which is the - an organization or an individual that actually penetrated the computer systems and infected the company's computer systems with the ransomware. GROSS: So do these different ransomware groups compete with each other? Do they advertise to affiliates that want to work with a group that actually has the malware that they need? SCHWIRTZ: They do, because it's a symbiotic relationship with these affiliates. You know, they can work - DarkSide can work with dozens of affiliates who are working round the clock trying to find vulnerabilities in various companies and inserting the malware. And they just have to sit back and wait for these attacks to be successful. But they do advertise. There are dark web forums, a number of very, very big and prominent Russian-language dark web forums which exist, in part, to serve as advertising platforms for these groups, not only of the ransomware developers advertising on those platforms, the affiliates are also advertising their services. So these forums act as kind of grease to this operation, allowing these groups to interact with one another and form partnerships. GROSS: So you got access to the DarkSide dashboard. Explain what a dashboard is for people who don't know and what you saw on it. SCHWIRTZ: So the dashboard is is sort of the interface that is used both by DarkSide developers themselves and by the affiliates. And so what I got access to was the affiliate dashboard. And from there, you can get access to news about the latest hacks coming from DarkSide. You can get news about the profits. It had a ticker on it that was set up to count profits coming in, so you could keep an eye on how well the group was doing financially. And it also provided, like we were talking about, a tech support function where you can enter into a chat with a customer service representative from the DarkSide if you were an affiliate and had any problems. GROSS: What insights did seeing the dashboard give you about the operation? SCHWIRTZ: One thing that I think was the most striking was just how mundane it is. It was like entering into any other sort of company's computer systems. It was - there was a news ticker. There were press releases talking about latest services that were being offered to affiliates. One of the more recent press releases was about a news service in which DarkSide would be starting up a project to offer DDoS attacks - distributed denial of service attacks - against victims' computer systems, which is a way of overloading a victim's computer systems with fraudulent requests. And this was another way to put the screws to victims who may not be so willing to fork out the ransom. And so that - I mean, that was the most striking thing about it. This was being run just like a regular business. And, you know, we were able to get a look at how this business was run and how it was developed, going back into the archives and looking at news release, looking at company communications, going back to the group's inception, which occurred around August of last year. GROSS: You make contact with a customer support employee. It sounds so legit. So what was the communication? SCHWIRTZ: After I had spent some time exploring the dashboard, I decided that I was going to reach out to the customer support office at DarkSide. And it's a very simple thing to do. It's a similar interface to one that everybody is used to using when talking to customer support. There's a little button down in the lower right-hand corner of the screen that says chat. I opened the window and just wrote hello in Russian just to see if I could get any response. And sure enough, within about five or 10 minutes, somebody came on the line and said they were there and asked what I needed. And at that point, I introduced myself as a reporter with The New York Times, as we are required to do according to our rules. And within minutes, I was kicked out of the site, and the account was closed down. GROSS: Was that the response you were expecting when you identified yourself? SCHWIRTZ: It was. It was. I had a small sliver of hope that I might be able to engage with somebody from DarkSide for a bit longer. But that was definitely the odds-on reaction that I was expecting. GROSS: A lot of reporters would have just entered under a false identity, gone in undercover, so to speak. What is The New York Times' rule surrounding that? SCHWIRTZ: Ethically, we're not allowed to go undercover. And as a rule, I always introduce myself as a Times reporter first so that nobody's under any illusion about who I am and what I want. And so while going in undercover and pretending to be an affiliate - and in this case, we were using the account of an affiliate named Woris. So this was an actual account for an actual affiliate that had been in contact and involved in attacks with DarkSide in the past. So I wanted to make it very clear that I was not this individual Woris and that I was somebody new. And ethically, that is - that's Times policy. GROSS: Well, we need to take a short break here, and then we'll talk some more and pick up where we left off. If you're just joining us, my guest is New York Times investigative reporter Michael Schwirtz. We'll be right back. This is FRESH AIR. (SOUNDBITE OF MATT ULERY'S \"GAVE PROOF\")GROSS: This is FRESH AIR. Let's get back to my interview with New York Times investigative reporter Michael Schwirtz about ransomware attacks and how the attackers operate. He gained access to secret communications from the cybercriminal operation DarkSide that attacked Colonial Pipeline. He's also written about how REvil operates. That's the cybergang behind the ransomware attack on JBS, the giant meat processing company. So you not only managed to get a momentary chat (laughter) with basically somebody from customer support, you got access to some secret communications from DarkSide. What were some of these communications? SCHWIRTZ: Correct. Well, the communications were saved, essentially, within the chat system on the dashboard. And so this individual, Woris, was the affiliate, had been communicating throughout probably since about February with the customer support service from DarkSide because the affiliate had been having trouble getting a victim to pay. And so I was able to basically trace the process of an attack and the process of squeezing a victim from the - almost from the very beginning by following these chats and from the sort of mirror images of what we're used to. What we normally get is a victim explaining to us how these attacks were carried out from their perspective. So it was very, very interesting to watch how one of these attacks and the negotiations - the subsequent negotiations that occurred over the ransom played out from the perspective of the hackers who were involved in the attack. And the victim, which in this case is a small American publishing company that deals primarily with clients in primary education, the victim was putting up a bit of a fight. And Woris, the affiliate, was in discussions with DarkSide about how to put on additional pressure so that this victim would pay up. And it wasn't a small amount of money they were talking about. It's a small company, but what the ransom was that they had decided on was $1. 75 million. And so this company seems to have balked at paying this amount of money to get its systems back online and was putting up a resistance. And the chat consists of these two individuals or perhaps groups basically charting out a strategy for putting the squeeze on them to get them to pay up. GROSS: So this isn't a big corporate publishing company we're talking about. It was a family-run company. And for this company, 1. 7 million was a lot. So what were the threats against them? SCHWIRTZ: There was a number of threats that they had come up with, and it's unclear to me how many of these were implemented. There were - one of the earliest threats that they had discussed was essentially trying to blackmail the company. They threatened - because, as we mentioned, they had gained control over proprietary information. This is information about clients, again, who are primarily in primary school education. And at one point, they decided to threaten to spill information about clients onto the dark web. And they added that this information could be used by pedophiles to make fake IDs that would allow them to enter schools and threaten children. I think this was a fanciful idea on their part, but it shows sort of the mindset that they had. They were willing to make these kinds of threats in order to try and get this company to pay up. GROSS: In one of the conversations between DarkSide and Woris, Woris was laughing about the pedophile threat. And Woris, whoever that is - or whoever the group is wrote, I laughed to the depth of my soul about the leaked IDs possibly being used by pedophiles to enter the school. I didn't think it would scare them that much. SCHWIRTZ: Right. And I think this company, you know, for good reason, was really spooked that, one, proprietary information about clients would get out. This could, perhaps, be a threat to them. But also, this would be a big threat to their business if it was discovered that they had lost control of information and allowed people's identities to be compromised, right? Nobody wants to, you know, imagine that their personal information is floating around on some dark web site, you know, ready to be plucked up by a cybercriminal and used for who knows what means. GROSS: Does DarkSide and the affiliate that it's working with to do the ransomware attack, do they collaborate on what the threats should be and how they should be expressed to the victim? SCHWIRTZ: They do. At several points in the chat, it becomes clear that Woris is the one writing communications that they want sent to the victims. So they write a letter that is supposed to be addressed to clients of this company that is refusing to pay. And then the letter is passed on to DarkSide. And DarkSide is actually doing the direct negotiations with the company. So when the company is communicating with the hackers that hacked into its system, it's communicating with DarkSide. But Woris is there behind the scenes, basically, coaching DarkSide on what to say. GROSS: So how did the publishing company that was - that had its computer system held hostage by Woris and DarkSide, how did the company handle it? I know the company negotiated. Who do they negotiate with? And what do you know about how the negotiations went? SCHWIRTZ: They negotiated directly with DarkSide. So as I explained early on, they would have received this letter, a ransom note, giving them instructions on how to contact DarkSide and begin these negotiations. And that appears to be what they did. The negotiations were done primarily through email and a specialized chat service probably similar to the one that I was seeing on the dashboard, the DarkSide dashboard for the affiliates. And they were communicating with somebody who used very, very bad English. And. . . GROSS: Because they're Russian-speaking, the cybergangs. SCHWIRTZ: They're Russian-speaking. It's interesting to me that there were not better English speakers that could be utilized for this purpose. But when you look at some of the communications between the DarkSide negotiators and the company, the English language skills are pretty poor. And, you know, this company negotiated with DarkSide for several weeks and maybe a few months before - negotiations broke down around the time of the Colonial Pipeline hack, at which point, DarkSide had to contend with all of the troubles that arose following the massive international reaction to that attack. GROSS: So during the months of negotiation, was this publishing company locked out of its own system? And if so, how did it function? You might not know the answer to that. SCHWIRTZ: According to the company - and I've communicated with them - they were locked out of their information for a while. And it was pretty damaging to their business. They wouldn't go specifically into sort of monetary losses that they endured as a result of this. But according to them, it was fairly damaging. And they were working very hard to both keep their systems online, but also avoid paying what would have been a very, very steep price. They also approached the FBI. And the FBI began investigating as well. The thing that I don't know - I do know the ransom was never paid. I do not know what happened to the company's information because DarkSide, as has been reported, has gone quiet, at least, if it hasn't disappeared completely. And so the fate of victims who had not yet resolved their attacks, I think, is a bit unclear. GROSS: Do you think that the publishing company negotiated a long time to stall so that the FBI could continue to investigate who was behind the attack? SCHWIRTZ: There was some indication that that was the case. And I don't - I'm not privy to details about the federal investigation into the case. But, yeah, there is some indication that the company was trying to, basically, keep DarkSide on the line while the FBI investigated. And as has been revealed in almost-daily updates about the Colonial Pipeline attack, it seems as if the FBI had been investigating DarkSide almost since its inception. And it had gained a lot of real insight into how the company operated. GROSS: Let's take a short break here, and then we'll talk some more. If you're just joining us, my guest is New York Times investigative reporter Michael Schwirtz. We'll talk more about ransomware attacks and who the attackers are after we take a short break. I'm Terry Gross. And this is FRESH AIR. (SOUNDBITE OF JESSICA WILLIAMS TRIO'S \"WEIRDO\")GROSS: This is FRESH AIR. I'm Terry Gross. Let's get back to my interview with New York Times investigative reporter Michael Schwirtz. He's been writing about ransomware attacks and how the attackers operate. He gained access to secret communications from the cybercriminal operation DarkSide that attacked Colonial Pipeline. These communications offered what he describes as an extraordinary glimpse into the internal workings of a Russian-speaking gang that had become the face of global cybercrime. He's also written about how REvil operates - that spelt R-E-V-I-L. That's the cybergang behind the ransomware attack on JBS, the giant meat processing company. Let's talk about the Colonial Pipeline hack. Colonial Pipeline paid the ransom. The CEO says he thought it was in the best interest of the country to make sure that the oil kept flowing because this is a pipeline that supplies much of the East Coast. So they paid - and I think they paid pretty quickly. So was this attack against Colonial Pipeline through an affiliate of DarkSide? SCHWIRTZ: Yeah. That's how it would have worked. I don't know that we have a lot of details about the affiliate in this case, but it would have been likely an affiliate using DarkSide's ransomware in the same way that Woris sort of carried out the attack on this publishing company, another affiliate would have carried out the attack on Colonial Pipeline. And DarkSide would have been the direct interface conducting negotiations with Colonial to get their systems back up and running. GROSS: Do you have any idea what the negotiations were like between the affiliate and Colonial Pipeline? SCHWIRTZ: I do not know, but it seemed to have happened very, very quickly. The CEO of Colonial testified this week that the ransom was paid even before the FBI was contacted to inform them about the ransomware attack. I believe the first we had heard the Colonial Pipeline had been the victim of a ransom attack was on the 7 of May. And by the 8 of May, there's evidence that money had been transferred from Colonial to a Bitcoin account operated by DarkSide. So if there were any negotiations, they happened very, very quickly and resulted in a big payday for DarkSide, at least initially. GROSS: You know, authorities often warn that you should not pay ransomware attackers, because even if you pay, they might still not free up your computer system. Do they offer any guarantee? Does DarkSide have any ethics about actually following through on its word that if you pay the ransom, you'll get your intact computer system again? SCHWIRTZ: The whole ransomware industry depends on a kind of honor system. And so it is very much in the interest of the ransomware companies to pay. If it gets out there that there's a ransomware criminal gang that is locking down computers, collecting ransoms and refusing to pay, there's going to be very, very little incentive for victims to hand over a bunch of money. Everything in the ransomware business revolves around making it as easy as possible for victims to hand over money. If it becomes any more difficult than it is, you know, victims are going to invest their time and energy into finding ways to avoid doing that. What these ransomware companies want you to do when you're a victim of these attacks is to make a calculation in your head. How much is it going to cost me to engage into lengthy negotiations to try and get this ransom tossed out? How much is it going to cost me to resist? And is it just cheaper for me to pay this ransom and get on with my business? And I think for a number of companies, because of the way the ransomware industry has evolved, a number of companies make the calculation that it's just better to pay and get on with it. Obviously, then this feeds the industry and allows it to continue to grow. GROSS: My understanding is that the CEO of Colonial Pipeline did not communicate with the FBI until after the ransom was paid, but the FBI did eventually manage very recently to get access to a Bitcoin wallet that was used by Colonial Pipeline to pay the ransomware attacker. What do you know about how the FBI was able to do that or what that even means? Most of us don't really understand cryptocurrency talk, so if you can explain what happened. SCHWIRTZ: Right. And this was a really big deal because I think it's, you know, the first or at least the first major effort by the FBI to really go after one of these, you know, largely virtual ransomware game. And what appears to have happened is that the FBI, soon after DarkSide's creation in about August 2020, started investigating its finances. And basically, the way these groups operate is they set up cryptocurrency accounts which allow for easily transferable funds from a victim to the hackers. And they set up a number of these accounts into which victims will pour their funds. And so when this Colonial Pipeline attack happened, the FBI already had very good insights into where DarkSide was storing its money, these digital wallets, as they're called, for Bitcoin. And what appears to have happened is that the FBI actually hacked into one of these wallets that was containing Bitcoins that were transferred from the Colonial Pipeline Company and took it back. And this amounted to - because of the price, the changing price in Bitcoin, this was a little less than what the company paid, but nevertheless, it was over $2 million worth of Bitcoin that was taken back from the hackers, which is just something that we've never seen before. GROSS: So my understanding is that the affiliate of DarkSide didn't get paid, but DarkSide managed to keep their money because it was only the wallet from the affiliate that was hacked. SCHWIRTZ: It appears that DarkSide managed to keep its money, but that that much is not clear either. Shortly after the Colonial Pipeline attack, DarkSide came under what it said were threats coming from the United States, some sort of undetermined kind of attack from the United States. And it announced publicly on its public-facing webpage that its Bitcoin accounts had been drained. And there had been mystery about whether, in fact, they drained the Bitcoin accounts themselves in order to hide their assets or that somebody else might have done it. At the time, the United States said that it had not infiltrated the group's accounts. But it seems that later, just in the last few days, the FBI had been able to at least find one wallet probably belonging to an affiliate from which it extracted these funds. GROSS: Let me reintroduce you again. If you're just joining us, my guest is New York Times investigative reporter Michael Schwirtz. We'll talk more about ransomware attacks after a break. This is FRESH AIR. (SOUNDBITE OF MUSIC)GROSS: This is FRESH AIR. Let's get back to my interview with New York Times investigative reporter Michael Schwirtz about ransomware attacks and how the attackers operate. He gained access to secret communications from the cybercriminal operation DarkSide that attacked Colonial Pipeline. So DarkSide went dark. What does it mean that DarkSide went dark? Does it mean they disappear, or maybe they're just kind of creating another iteration of the group with, you know, with different - I don't even know the language - different passwords or encryption or whatever? SCHWIRTZ: I mean, a different - I mean, just a rebranding exercise. That's possibly what it was. The timeline of the shutdown is unclear. So shortly after DarkSide was identified by the U. S. government as being involved in the Colonial Pipeline attack, the group itself announced that it was shutting down. And this was a few days after they were announced in connection with this attack. They announced that they were voluntarily shutting down and that they would be operating as kind of a private service, so they wouldn't be taking on new affiliates. They would continue to work with their affiliates in some guise. And they announced that they were taking down all of their infrastructure, their dashboard and things like that. But when I entered into the dashboard, which was about 10 days after this announcement, it was still open and active, though it had been clear that the accounts were drained or at least the tickers which showed the profits that they were bringing in from these random attacks read zero. And so whether or not they have shut down and these individuals have decided they've made enough money and they're going to retire and then find some other line of work or whether they are just rebranding and regrouping, it's unclear. There's some evidence that exists that DarkSide was merely an affiliate of this other large ransomware hacking group REvil that then repackaged itself as a ransomware developer around August last year. So these groups go through a number of iterations. You know, they shut down and pick back up all the time. And so it wouldn't be surprising that the individuals who are behind DarkSide either joined other groups or set up another group under a different name and continue doing this sort of work. GROSS: So how big of a victory do you think the FBI actually scored against DarkSide in particular and ransomware hackers in general? SCHWIRTZ: I think it's hard to say right now, but I think it'll be interesting to see what the reaction is to the FBI's going in and retaking some of this ransom that Colonial Pipeline paid. It basically sends a message that there's not the impunity that you thought you had. In the past, once you got the money, you were basically scot free. And this is showing that there perhaps some consequences, at least to targeting the wrong kind of company. I don't know that the FBI has the resources every single time there's an attack to go after and take the money back. It's probably a large effort. And this is, you know, perhaps - I don't want to say it's completely symbolic, but perhaps, you know, the larger effect will be symbolic by putting these individuals on notice that there are cases in which they will cross the line and their earnings could be in jeopardy. GROSS: So what's the understanding of what kind of case would cross the line? And do groups like DarkSide or REvil have a code about who is off-limits? SCHWIRTZ: Well, what was special about the Colonial Pipeline attack was that it was a company that was involved in critical infrastructure. This company had customers going from Texas to New York. And shutting down the pipeline, which we should be clear, the company made the decision to shut down the pipeline as an administrative matter because it wasn't able to ensure that its customers would be able to pay for its deliveries. DarkSide didn't, in fact, shut down the company's pipeline. But nevertheless, it caused huge amounts of disruption and was a real wake-up call to policymakers, I think, in Washington and everywhere about the dangers that ransomware poses. And this is something that ransomware operators just really don't like. They'd like to operate in the shadows. They don't want a ton of attention. And they certainly don't want to touch off a geopolitical conflict as a result of their business. Their job, as they see it is, to just get money and do it as quickly as possible without causing anything of a fuss. And so there were some really real recriminations in the ransomware world following the Colonial Pipeline hack. One of the major forums where cybercriminality is organized, one of the major Russian-language forums announced that it was banning all ransomware activity from its site. REvil, which we've mentioned, and some other groups reiterated long-standing rules against attacks on critical infrastructure as well as hospitals, educational institutions. And I should say that DarkSide had these rules in place as well. And it's not clear whether the affiliate in this case that went after Colonial Pipeline just got a bit ahead of their skis and thought that, you know, they could attack the business side computer systems of this pipeline company and avoid sort of the larger ramifications that occurred or whether they just weren't thinking or they just got too greedy. But it's unclear. But there was a definite reset in the ransomware world as a result of this. GROSS: One of the things - perhaps the main thing that has made these ransomware attacks possible is cryptocurrency, digital currency like Bitcoin. And most of us don't really understand how this works. But can you explain a little bit about why cryptocurrency has allowed these ransomware attacks to flourish? SCHWIRTZ: One of the major features of cryptocurrency is that you can be anonymous. You're not handing over your banking information, right? You are transferring money into an anonymized wallet, essentially a digital wallet or an account that holds Bitcoin, which is just a currency like any other, like pounds, like dollars, like yen. And it's easily transferable from wallet to wallet. Once you transfer your dollars into Bitcoin, you can transfer from wall to wall. So it - in the past, the way a lot of cybercriminality worked, it revolved around banking systems, right? You had to find ways to get people to give you their banking login credentials - in which case, you could drain their accounts. But you couldn't just drain their account and send it to your account, you know? You had to launder the money through a range of accounts and, in some cases, use individuals to physically bring cash across borders. These days, you have your victim - one, you know, ransomware basically allows you to just ask your victim for the money. You don't have to trick them into giving you anything. You just have to infiltrate their systems and threaten to destroy their business. But then they just hand you over the money. And Bitcoin and other cryptocurrencies have allowed the transfer of this money to happen very, very easily. So it's just, you know, you transfer your dollars into Bitcoin. And then you send your money from your account to the hackers' account. And then the transaction is done. GROSS: So - you know, we were talking about DarkSide. You've also looked into REvil, which is another ransomware group that works with affiliates. The affiliates actually do the hacking of the group and ask for the ransom. But they do it with the help of REvil or DarkSide or whoever the malware originator is. So can you compare REvil and DarkSide or compare the attack on JBS to the attack on Colonial Pipeline just to show what these groups have in common and what the differences are? SCHWIRTZ: I mean, it's hard to compare and contrast. DarkSide is, perhaps, according to some cybersecurity researchers - the members of DarkSide of, the members that created DarkSide were, perhaps, affiliates of REvil. So they were, perhaps, working with REvil's ransomware at one point before they set off on their own and made their own product. The thing that ties them both together and I think is most significant is that both groups appear to operate largely inside Russia. And I'd caveat that to an extent because some of these groups can be rather big. And they - because of the nature of the work being online, individuals can operate anywhere in the world. But at least the core of the operation is based in Russia and among Russian-speaking users. GROSS: Let me reintroduce you if you're just joining us. My guest is New York Times investigative reporter Michael Schwirtz. We'll talk more about ransomware attacks after a break. This is FRESH AIR. (SOUNDBITE OF THE BUDOS BAND'S \"INTO THE FOG\")GROSS: This is FRESH AIR. Let's get back to my interview with New York Times investigative reporter Michael Schwirtz about ransomware attacks and how the attackers operate. So REvil and DarkSide are based in Russia, as are many other cybercriminal gangs. Why is Russia such a hub for cybercriminals? SCHWIRTZ: There are a number of reasons for this. First, you know, the education system that focuses on math and science is very, very robust. But there are countries with robust, you know, computer science cultures all around the world. And I think what sets Russia apart and what makes the country a greenhouse for this type of activity - to use the term one cybersecurity researcher used with me - is that the government at best turns a blind eye to these sorts of activities and at worst co-ops and uses these groups as part of a broader, geopolitical strategy meant to undermine Western countries. GROSS: How do they get away with it in Russia? SCHWIRTZ: There's a simple answer - there's a simple and more complicated answer to that. The simple answer is that the Russian government has, basically, taken the stance that if none of these individuals are attacking Russian interests, so companies inside of Russia, then they can't be prosecuted under Russian laws. Russian law, according to the Kremlin, according to Vladimir Putin himself, does not have a provision for prosecuting individuals for carrying out ransom attacks against American companies. And so as long as these groups avoid attacking companies within Russia - and often, these groups will have rules prohibiting attacks against companies not only in Russia but also in the former Soviet Union at large. They are able to do so with impunity, which makes this problem very pernicious and difficult to snuff out if you're coming at it from a law enforcement perspective. GROSS: With so many Russian cybergangs attacking computer systems in America and other places around the world, do we know if Russian intelligence is cooperating with them, helping them in any way, and if Putin sees this as a kind of way of flexing his muscles without having any fingerprints on it? SCHWIRTZ: And there's a number of different ways that I think the Russian government and the intelligence services are involved. I don't think that every single attack has a Russian intelligence or law enforcement angle to it. But there is evidence that Russian intelligence services have co-opted cybercriminals to engage in intelligence. You know, it just too good of an opportunity to explore the computer systems of your enemies if you've already got a robust industry of individuals breaking into systems. So what seems to occur on occasion is that the intelligence services will make relationships with these cyber criminals and ask them, say, you know, they'll make a deal and say, you know, let's say we'll let you continue to engage in these sorts of operations and make money. But if you come across any sort of computer systems that might interest us, if you break into any government computer systems that might possess intelligence that could be used for national security purposes, you need to let us know. Now, there are also more direct use of cybersecurity infrastructure by the intelligence services. We've seen cases - there was one case from a few years ago where the operator of a very large botnet, which is a network of infected computers, started running searches that appeared to indicate a hunt for actionable intelligence. There were searches for information about a weapons deal between the United States and Turkey. There were searches for information about the situation, the war going on in Ukraine. And this fell so far outside of the normal operations of this infected network, which was generally focused on stealing banking credentials, that most security researchers and intelligence officials in the United States and elsewhere assumed that this was the Russian intelligence services basically coopting an infected network to engage in intelligence gathering. GROSS: President Biden is meeting with Putin next week. Do you assume that ransomware is going to come up in the conversation? SCHWIRTZ: It's definitely going to come up in the conversation. I think the Biden administration has made that clear. The real question is what the United States can do about it. The United States has leveled sanctions against Russian entities for involvement in cyberattacks carried out by the Russian intelligence services. And these would be overt attacks, you know, presumably ordered at the highest level of government to, in fact, the government computer systems. And the SolarWinds attack recently, which was recently revealed, comes to mind as part of that. But these ransomware attacks fall into this sort of strange area where the Biden administration and Western governments in general have to be a bit more creative because normally, this would be a law enforcement issue. And if Russia were an ally, the FBI could meet with the FSB, which is Russia's version of the FBI, and hash out a plan for going after these groups. But that's an impossible thing to do when the Russian government is, at very best, turning a blind eye to these groups, but often protecting them. GROSS: So these cybergangs, this ransomware, this is like criminal activity. Even if the Russian intelligence is collaborating with them in some way, it's not official. And I don't know if the U. S. could prove that Russian intelligence is working with them at all. So can Biden use something like the military Cyber Command to go after the ransomware attackers, or would that be considered an inappropriate use of the military because it's a criminal action? SCHWIRTZ: Right. This is the sort of gray area that we find ourselves in. I think the administration is pretty reticent to use the military, like you said, to be - for involvement in what is generally considered a law enforcement issue. I think it's no surprise to see that it was the FBI that was involved in extracting these Bitcoins from the DarkSide affiliate's wallet and not some other entity within the U. S. government. It's a very difficult thing to unleash the U. S. military, even in the realm of cyber, on the citizens of a country with which you share an adversarial relationship or anywhere, right? The potential for escalation is just unknown. And I think the administration is rightly treading carefully. And there just isn't a playbook for dealing with this. And part of that reason is because, you know, there's a hazy line between criminality, pure criminality and, you know, Russian-government-sanctioned actions that the administration and I think everyone is trying to figure out in this world of cybercriminality. GROSS: Well, Michael Schwirtz, I want to thank you so much for talking with us. SCHWIRTZ: I really appreciate it. It's been an honor. Thank you. GROSS: Michael Schwirtz is an investigative reporter for The New York Times. If you'd like to catch up on FRESH AIR interviews you missed, like this week's interview with Rita Moreno about the ethnic stereotyping and sexual harassment she faced in Hollywood and her tumultuous relationship with Marlon Brando, check out our website. You'll find lots of FRESH AIR interviews. (SOUNDBITE OF MUSIC)GROSS: FRESH AIR's executive producer is Danny Miller. Our technical director and engineer is Audrey Bentham. Our interviews and reviews are produced and edited by Amy Salit, Phyllis Myers, Sam Briger, Lauren Krenzel, Heidi Saman, Therese Madden, Ann Marie Baldonado, Thea Chaloner, Seth Kelley, Kayla Lattimore and Joe Wolfram. Our associate producer of digital media is Molly Seavy-Nesper. Roberta Shorrock directs the show. I'm Terry Gross. TERRY GROSS, HOST:   This is FRESH AIR. I'm Terry Gross. Ransomware attacks have disrupted the flow of gas and the supply of meat in just the past few weeks after Colonial Pipeline and JBS, the meat processing company, had their computer systems held hostage for ransom. Similar ransomware attacks have been waged on many companies, large and small, and on hospitals, the police and cities. My guest got an inside look at how the new breed of ransomware attackers operate. Michael Schwirtz is an investigative reporter at The New York Times who gained access to secret communications from the cybercriminal operation DarkSide that attacked Colonial Pipeline. These communications offered what he described as an extraordinary glimpse into the internal workings of a Russian-speaking gang that had become the face of global cybercrime. DarkSide pulled in millions of dollars in ransom payments each month after. They were outed as the attackers of Colonial Pipeline, they went dark. Schwirtz has also reported on the company that attacked JBS, which is called REvil - R-E-V-I-L. These cybercriminals and many others are believed to be operating from Russia. Schwirtz worked in The New York Times' Russia bureau from 2006 to 2012. Last year, he was a lead reporter on the team that won a Pulitzer Prize for a series of articles about Russian intelligence operations around the world. We recorded our interview yesterday morning. Michael Schwirtz, welcome to FRESH AIR. The inner workings of ransomware that you found out were fascinating. Let's start with what you learned the victim sees on the screen when DarkSide captures the computer system. MICHAEL SCHWIRTZ: Right. When the ransomware is uploaded into a victim's computer system, the first thing they see is a ransom note. It says at the top, welcome to DarkSide. And it contains a list of instructions on how the victim can go about unlocking their data. They have no access to their data. And what they need to do is they'll rely on DarkSide by paying a ransom to provide them with a key that will allow them to get these files back. And the letter is written in a kind of very formal, businesslike manner with very subtle threats. They're warned - victims are warned not to try and tamper with their computer systems themselves, try not to access their data themselves, because this may result in the loss of the data completely. And so they're instructed to get in touch immediately with a DarkSide representative to begin negotiations over the ransom. GROSS: And it not only locks victims out of computer systems. The hackers can steal proprietary data. SCHWIRTZ: Right. And this is basically to put added pressure on the business. Not only does the victim risk losing access to important computer files that may be necessary for the day-to-day running of the business, but the hackers will threaten to spill this information into the public domain to be used by competitors, to be used by other hackers to carry out additional attacks on the company. And so they're really, really hard pressed to act very, very quickly to clear this up - the victims are. GROSS: Now, the ransom is paid and cryptocurrency like Bitcoin. Most people don't know how to use Bitcoin. So DarkSide actually has, like, a helpdesk to help the victims pay the ransom. SCHWIRTZ: Right. It's a really user-friendly experience. There's a helpdesk like any other. . . GROSS: Great (laughter). SCHWIRTZ: . . . You know, when your internet goes out, you contact your internet service provider. And sometimes there's a chat. It's a very similar service. And it's the goal of these hackers to make this as simple as possible, so that people are more willing to just pay the ransom and get it out of the way and get back to business, rather than put up a real fight to try and get their data back that wouldn't result in them getting paid. GROSS: DarkSide is a cybercriminal gang, but it's set up like a business with affiliates. What are the affiliates? SCHWIRTZ: What DarkSide does is they're a ransomware creator. So they create the program that is uploaded into a victim's computer system that locks down their data. But what they do is they basically contract out to these affiliates who are other hackers. And these are the people that are responsible for actually penetrating the victim's computer services. And what they do is operate basically on a subscription service. You, as an affiliate, can sign on to DarkSide services, in which case you get access to their malware, their ransomware to use for a fee that operates on a sliding scale depending upon the size of the ransom. GROSS: What's the profit model for both DarkSide and for the affiliate it's working with? For example, Colonial Pipeline was told to pay $4. 5 million to get access again to its computer system. Colonial Pipeline paid the $4. 5 million. How is that divided between DarkSide and the affiliate that actually did the hack? SCHWIRTZ: So DarkSide takes a cut. And so the way it worked with DarkSide, which I am told is fairly generous, if the ransom that was charged that was eventually obtained was less $500,000, DarkSide would take about a 25% cut. And this moved down to about 10% for ransoms over $5 million. So DarkSide would have taken about 10% of the ransom paid by Colonial Pipeline for its attack, with the remaining going to the affiliate, which is the - an organization or an individual that actually penetrated the computer systems and infected the company's computer systems with the ransomware. GROSS: So do these different ransomware groups compete with each other? Do they advertise to affiliates that want to work with a group that actually has the malware that they need? SCHWIRTZ: They do, because it's a symbiotic relationship with these affiliates. You know, they can work - DarkSide can work with dozens of affiliates who are working round the clock trying to find vulnerabilities in various companies and inserting the malware. And they just have to sit back and wait for these attacks to be successful. But they do advertise. There are dark web forums, a number of very, very big and prominent Russian-language dark web forums which exist, in part, to serve as advertising platforms for these groups, not only of the ransomware developers advertising on those platforms, the affiliates are also advertising their services. So these forums act as kind of grease to this operation, allowing these groups to interact with one another and form partnerships. GROSS: So you got access to the DarkSide dashboard. Explain what a dashboard is for people who don't know and what you saw on it. SCHWIRTZ: So the dashboard is is sort of the interface that is used both by DarkSide developers themselves and by the affiliates. And so what I got access to was the affiliate dashboard. And from there, you can get access to news about the latest hacks coming from DarkSide. You can get news about the profits. It had a ticker on it that was set up to count profits coming in, so you could keep an eye on how well the group was doing financially. And it also provided, like we were talking about, a tech support function where you can enter into a chat with a customer service representative from the DarkSide if you were an affiliate and had any problems. GROSS: What insights did seeing the dashboard give you about the operation? SCHWIRTZ: One thing that I think was the most striking was just how mundane it is. It was like entering into any other sort of company's computer systems. It was - there was a news ticker. There were press releases talking about latest services that were being offered to affiliates. One of the more recent press releases was about a news service in which DarkSide would be starting up a project to offer DDoS attacks - distributed denial of service attacks - against victims' computer systems, which is a way of overloading a victim's computer systems with fraudulent requests. And this was another way to put the screws to victims who may not be so willing to fork out the ransom. And so that - I mean, that was the most striking thing about it. This was being run just like a regular business. And, you know, we were able to get a look at how this business was run and how it was developed, going back into the archives and looking at news release, looking at company communications, going back to the group's inception, which occurred around August of last year. GROSS: You make contact with a customer support employee. It sounds so legit. So what was the communication? SCHWIRTZ: After I had spent some time exploring the dashboard, I decided that I was going to reach out to the customer support office at DarkSide. And it's a very simple thing to do. It's a similar interface to one that everybody is used to using when talking to customer support. There's a little button down in the lower right-hand corner of the screen that says chat. I opened the window and just wrote hello in Russian just to see if I could get any response. And sure enough, within about five or 10 minutes, somebody came on the line and said they were there and asked what I needed. And at that point, I introduced myself as a reporter with The New York Times, as we are required to do according to our rules. And within minutes, I was kicked out of the site, and the account was closed down. GROSS: Was that the response you were expecting when you identified yourself? SCHWIRTZ: It was. It was. I had a small sliver of hope that I might be able to engage with somebody from DarkSide for a bit longer. But that was definitely the odds-on reaction that I was expecting. GROSS: A lot of reporters would have just entered under a false identity, gone in undercover, so to speak. What is The New York Times' rule surrounding that? SCHWIRTZ: Ethically, we're not allowed to go undercover. And as a rule, I always introduce myself as a Times reporter first so that nobody's under any illusion about who I am and what I want. And so while going in undercover and pretending to be an affiliate - and in this case, we were using the account of an affiliate named Woris. So this was an actual account for an actual affiliate that had been in contact and involved in attacks with DarkSide in the past. So I wanted to make it very clear that I was not this individual Woris and that I was somebody new. And ethically, that is - that's Times policy. GROSS: Well, we need to take a short break here, and then we'll talk some more and pick up where we left off. If you're just joining us, my guest is New York Times investigative reporter Michael Schwirtz. We'll be right back. This is FRESH AIR. (SOUNDBITE OF MATT ULERY'S \"GAVE PROOF\") GROSS: This is FRESH AIR. Let's get back to my interview with New York Times investigative reporter Michael Schwirtz about ransomware attacks and how the attackers operate. He gained access to secret communications from the cybercriminal operation DarkSide that attacked Colonial Pipeline. He's also written about how REvil operates. That's the cybergang behind the ransomware attack on JBS, the giant meat processing company. So you not only managed to get a momentary chat (laughter) with basically somebody from customer support, you got access to some secret communications from DarkSide. What were some of these communications? SCHWIRTZ: Correct. Well, the communications were saved, essentially, within the chat system on the dashboard. And so this individual, Woris, was the affiliate, had been communicating throughout probably since about February with the customer support service from DarkSide because the affiliate had been having trouble getting a victim to pay. And so I was able to basically trace the process of an attack and the process of squeezing a victim from the - almost from the very beginning by following these chats and from the sort of mirror images of what we're used to. What we normally get is a victim explaining to us how these attacks were carried out from their perspective. So it was very, very interesting to watch how one of these attacks and the negotiations - the subsequent negotiations that occurred over the ransom played out from the perspective of the hackers who were involved in the attack. And the victim, which in this case is a small American publishing company that deals primarily with clients in primary education, the victim was putting up a bit of a fight. And Woris, the affiliate, was in discussions with DarkSide about how to put on additional pressure so that this victim would pay up. And it wasn't a small amount of money they were talking about. It's a small company, but what the ransom was that they had decided on was $1. 75 million. And so this company seems to have balked at paying this amount of money to get its systems back online and was putting up a resistance. And the chat consists of these two individuals or perhaps groups basically charting out a strategy for putting the squeeze on them to get them to pay up. GROSS: So this isn't a big corporate publishing company we're talking about. It was a family-run company. And for this company, 1. 7 million was a lot. So what were the threats against them? SCHWIRTZ: There was a number of threats that they had come up with, and it's unclear to me how many of these were implemented. There were - one of the earliest threats that they had discussed was essentially trying to blackmail the company. They threatened - because, as we mentioned, they had gained control over proprietary information. This is information about clients, again, who are primarily in primary school education. And at one point, they decided to threaten to spill information about clients onto the dark web. And they added that this information could be used by pedophiles to make fake IDs that would allow them to enter schools and threaten children. I think this was a fanciful idea on their part, but it shows sort of the mindset that they had. They were willing to make these kinds of threats in order to try and get this company to pay up. GROSS: In one of the conversations between DarkSide and Woris, Woris was laughing about the pedophile threat. And Woris, whoever that is - or whoever the group is wrote, I laughed to the depth of my soul about the leaked IDs possibly being used by pedophiles to enter the school. I didn't think it would scare them that much. SCHWIRTZ: Right. And I think this company, you know, for good reason, was really spooked that, one, proprietary information about clients would get out. This could, perhaps, be a threat to them. But also, this would be a big threat to their business if it was discovered that they had lost control of information and allowed people's identities to be compromised, right? Nobody wants to, you know, imagine that their personal information is floating around on some dark web site, you know, ready to be plucked up by a cybercriminal and used for who knows what means. GROSS: Does DarkSide and the affiliate that it's working with to do the ransomware attack, do they collaborate on what the threats should be and how they should be expressed to the victim? SCHWIRTZ: They do. At several points in the chat, it becomes clear that Woris is the one writing communications that they want sent to the victims. So they write a letter that is supposed to be addressed to clients of this company that is refusing to pay. And then the letter is passed on to DarkSide. And DarkSide is actually doing the direct negotiations with the company. So when the company is communicating with the hackers that hacked into its system, it's communicating with DarkSide. But Woris is there behind the scenes, basically, coaching DarkSide on what to say. GROSS: So how did the publishing company that was - that had its computer system held hostage by Woris and DarkSide, how did the company handle it? I know the company negotiated. Who do they negotiate with? And what do you know about how the negotiations went? SCHWIRTZ: They negotiated directly with DarkSide. So as I explained early on, they would have received this letter, a ransom note, giving them instructions on how to contact DarkSide and begin these negotiations. And that appears to be what they did. The negotiations were done primarily through email and a specialized chat service probably similar to the one that I was seeing on the dashboard, the DarkSide dashboard for the affiliates. And they were communicating with somebody who used very, very bad English. And. . . GROSS: Because they're Russian-speaking, the cybergangs. SCHWIRTZ: They're Russian-speaking. It's interesting to me that there were not better English speakers that could be utilized for this purpose. But when you look at some of the communications between the DarkSide negotiators and the company, the English language skills are pretty poor. And, you know, this company negotiated with DarkSide for several weeks and maybe a few months before - negotiations broke down around the time of the Colonial Pipeline hack, at which point, DarkSide had to contend with all of the troubles that arose following the massive international reaction to that attack. GROSS: So during the months of negotiation, was this publishing company locked out of its own system? And if so, how did it function? You might not know the answer to that. SCHWIRTZ: According to the company - and I've communicated with them - they were locked out of their information for a while. And it was pretty damaging to their business. They wouldn't go specifically into sort of monetary losses that they endured as a result of this. But according to them, it was fairly damaging. And they were working very hard to both keep their systems online, but also avoid paying what would have been a very, very steep price. They also approached the FBI. And the FBI began investigating as well. The thing that I don't know - I do know the ransom was never paid. I do not know what happened to the company's information because DarkSide, as has been reported, has gone quiet, at least, if it hasn't disappeared completely. And so the fate of victims who had not yet resolved their attacks, I think, is a bit unclear. GROSS: Do you think that the publishing company negotiated a long time to stall so that the FBI could continue to investigate who was behind the attack? SCHWIRTZ: There was some indication that that was the case. And I don't - I'm not privy to details about the federal investigation into the case. But, yeah, there is some indication that the company was trying to, basically, keep DarkSide on the line while the FBI investigated. And as has been revealed in almost-daily updates about the Colonial Pipeline attack, it seems as if the FBI had been investigating DarkSide almost since its inception. And it had gained a lot of real insight into how the company operated. GROSS: Let's take a short break here, and then we'll talk some more. If you're just joining us, my guest is New York Times investigative reporter Michael Schwirtz. We'll talk more about ransomware attacks and who the attackers are after we take a short break. I'm Terry Gross. And this is FRESH AIR. (SOUNDBITE OF JESSICA WILLIAMS TRIO'S \"WEIRDO\") GROSS: This is FRESH AIR. I'm Terry Gross. Let's get back to my interview with New York Times investigative reporter Michael Schwirtz. He's been writing about ransomware attacks and how the attackers operate. He gained access to secret communications from the cybercriminal operation DarkSide that attacked Colonial Pipeline. These communications offered what he describes as an extraordinary glimpse into the internal workings of a Russian-speaking gang that had become the face of global cybercrime. He's also written about how REvil operates - that spelt R-E-V-I-L. That's the cybergang behind the ransomware attack on JBS, the giant meat processing company. Let's talk about the Colonial Pipeline hack. Colonial Pipeline paid the ransom. The CEO says he thought it was in the best interest of the country to make sure that the oil kept flowing because this is a pipeline that supplies much of the East Coast. So they paid - and I think they paid pretty quickly. So was this attack against Colonial Pipeline through an affiliate of DarkSide? SCHWIRTZ: Yeah. That's how it would have worked. I don't know that we have a lot of details about the affiliate in this case, but it would have been likely an affiliate using DarkSide's ransomware in the same way that Woris sort of carried out the attack on this publishing company, another affiliate would have carried out the attack on Colonial Pipeline. And DarkSide would have been the direct interface conducting negotiations with Colonial to get their systems back up and running. GROSS: Do you have any idea what the negotiations were like between the affiliate and Colonial Pipeline? SCHWIRTZ: I do not know, but it seemed to have happened very, very quickly. The CEO of Colonial testified this week that the ransom was paid even before the FBI was contacted to inform them about the ransomware attack. I believe the first we had heard the Colonial Pipeline had been the victim of a ransom attack was on the 7 of May. And by the 8 of May, there's evidence that money had been transferred from Colonial to a Bitcoin account operated by DarkSide. So if there were any negotiations, they happened very, very quickly and resulted in a big payday for DarkSide, at least initially. GROSS: You know, authorities often warn that you should not pay ransomware attackers, because even if you pay, they might still not free up your computer system. Do they offer any guarantee? Does DarkSide have any ethics about actually following through on its word that if you pay the ransom, you'll get your intact computer system again? SCHWIRTZ: The whole ransomware industry depends on a kind of honor system. And so it is very much in the interest of the ransomware companies to pay. If it gets out there that there's a ransomware criminal gang that is locking down computers, collecting ransoms and refusing to pay, there's going to be very, very little incentive for victims to hand over a bunch of money. Everything in the ransomware business revolves around making it as easy as possible for victims to hand over money. If it becomes any more difficult than it is, you know, victims are going to invest their time and energy into finding ways to avoid doing that. What these ransomware companies want you to do when you're a victim of these attacks is to make a calculation in your head. How much is it going to cost me to engage into lengthy negotiations to try and get this ransom tossed out? How much is it going to cost me to resist? And is it just cheaper for me to pay this ransom and get on with my business? And I think for a number of companies, because of the way the ransomware industry has evolved, a number of companies make the calculation that it's just better to pay and get on with it. Obviously, then this feeds the industry and allows it to continue to grow. GROSS: My understanding is that the CEO of Colonial Pipeline did not communicate with the FBI until after the ransom was paid, but the FBI did eventually manage very recently to get access to a Bitcoin wallet that was used by Colonial Pipeline to pay the ransomware attacker. What do you know about how the FBI was able to do that or what that even means? Most of us don't really understand cryptocurrency talk, so if you can explain what happened. SCHWIRTZ: Right. And this was a really big deal because I think it's, you know, the first or at least the first major effort by the FBI to really go after one of these, you know, largely virtual ransomware game. And what appears to have happened is that the FBI, soon after DarkSide's creation in about August 2020, started investigating its finances. And basically, the way these groups operate is they set up cryptocurrency accounts which allow for easily transferable funds from a victim to the hackers. And they set up a number of these accounts into which victims will pour their funds. And so when this Colonial Pipeline attack happened, the FBI already had very good insights into where DarkSide was storing its money, these digital wallets, as they're called, for Bitcoin. And what appears to have happened is that the FBI actually hacked into one of these wallets that was containing Bitcoins that were transferred from the Colonial Pipeline Company and took it back. And this amounted to - because of the price, the changing price in Bitcoin, this was a little less than what the company paid, but nevertheless, it was over $2 million worth of Bitcoin that was taken back from the hackers, which is just something that we've never seen before. GROSS: So my understanding is that the affiliate of DarkSide didn't get paid, but DarkSide managed to keep their money because it was only the wallet from the affiliate that was hacked. SCHWIRTZ: It appears that DarkSide managed to keep its money, but that that much is not clear either. Shortly after the Colonial Pipeline attack, DarkSide came under what it said were threats coming from the United States, some sort of undetermined kind of attack from the United States. And it announced publicly on its public-facing webpage that its Bitcoin accounts had been drained. And there had been mystery about whether, in fact, they drained the Bitcoin accounts themselves in order to hide their assets or that somebody else might have done it. At the time, the United States said that it had not infiltrated the group's accounts. But it seems that later, just in the last few days, the FBI had been able to at least find one wallet probably belonging to an affiliate from which it extracted these funds. GROSS: Let me reintroduce you again. If you're just joining us, my guest is New York Times investigative reporter Michael Schwirtz. We'll talk more about ransomware attacks after a break. This is FRESH AIR. (SOUNDBITE OF MUSIC) GROSS: This is FRESH AIR. Let's get back to my interview with New York Times investigative reporter Michael Schwirtz about ransomware attacks and how the attackers operate. He gained access to secret communications from the cybercriminal operation DarkSide that attacked Colonial Pipeline. So DarkSide went dark. What does it mean that DarkSide went dark? Does it mean they disappear, or maybe they're just kind of creating another iteration of the group with, you know, with different - I don't even know the language - different passwords or encryption or whatever? SCHWIRTZ: I mean, a different - I mean, just a rebranding exercise. That's possibly what it was. The timeline of the shutdown is unclear. So shortly after DarkSide was identified by the U. S. government as being involved in the Colonial Pipeline attack, the group itself announced that it was shutting down. And this was a few days after they were announced in connection with this attack. They announced that they were voluntarily shutting down and that they would be operating as kind of a private service, so they wouldn't be taking on new affiliates. They would continue to work with their affiliates in some guise. And they announced that they were taking down all of their infrastructure, their dashboard and things like that. But when I entered into the dashboard, which was about 10 days after this announcement, it was still open and active, though it had been clear that the accounts were drained or at least the tickers which showed the profits that they were bringing in from these random attacks read zero. And so whether or not they have shut down and these individuals have decided they've made enough money and they're going to retire and then find some other line of work or whether they are just rebranding and regrouping, it's unclear. There's some evidence that exists that DarkSide was merely an affiliate of this other large ransomware hacking group REvil that then repackaged itself as a ransomware developer around August last year. So these groups go through a number of iterations. You know, they shut down and pick back up all the time. And so it wouldn't be surprising that the individuals who are behind DarkSide either joined other groups or set up another group under a different name and continue doing this sort of work. GROSS: So how big of a victory do you think the FBI actually scored against DarkSide in particular and ransomware hackers in general? SCHWIRTZ: I think it's hard to say right now, but I think it'll be interesting to see what the reaction is to the FBI's going in and retaking some of this ransom that Colonial Pipeline paid. It basically sends a message that there's not the impunity that you thought you had. In the past, once you got the money, you were basically scot free. And this is showing that there perhaps some consequences, at least to targeting the wrong kind of company. I don't know that the FBI has the resources every single time there's an attack to go after and take the money back. It's probably a large effort. And this is, you know, perhaps - I don't want to say it's completely symbolic, but perhaps, you know, the larger effect will be symbolic by putting these individuals on notice that there are cases in which they will cross the line and their earnings could be in jeopardy. GROSS: So what's the understanding of what kind of case would cross the line? And do groups like DarkSide or REvil have a code about who is off-limits? SCHWIRTZ: Well, what was special about the Colonial Pipeline attack was that it was a company that was involved in critical infrastructure. This company had customers going from Texas to New York. And shutting down the pipeline, which we should be clear, the company made the decision to shut down the pipeline as an administrative matter because it wasn't able to ensure that its customers would be able to pay for its deliveries. DarkSide didn't, in fact, shut down the company's pipeline. But nevertheless, it caused huge amounts of disruption and was a real wake-up call to policymakers, I think, in Washington and everywhere about the dangers that ransomware poses. And this is something that ransomware operators just really don't like. They'd like to operate in the shadows. They don't want a ton of attention. And they certainly don't want to touch off a geopolitical conflict as a result of their business. Their job, as they see it is, to just get money and do it as quickly as possible without causing anything of a fuss. And so there were some really real recriminations in the ransomware world following the Colonial Pipeline hack. One of the major forums where cybercriminality is organized, one of the major Russian-language forums announced that it was banning all ransomware activity from its site. REvil, which we've mentioned, and some other groups reiterated long-standing rules against attacks on critical infrastructure as well as hospitals, educational institutions. And I should say that DarkSide had these rules in place as well. And it's not clear whether the affiliate in this case that went after Colonial Pipeline just got a bit ahead of their skis and thought that, you know, they could attack the business side computer systems of this pipeline company and avoid sort of the larger ramifications that occurred or whether they just weren't thinking or they just got too greedy. But it's unclear. But there was a definite reset in the ransomware world as a result of this. GROSS: One of the things - perhaps the main thing that has made these ransomware attacks possible is cryptocurrency, digital currency like Bitcoin. And most of us don't really understand how this works. But can you explain a little bit about why cryptocurrency has allowed these ransomware attacks to flourish? SCHWIRTZ: One of the major features of cryptocurrency is that you can be anonymous. You're not handing over your banking information, right? You are transferring money into an anonymized wallet, essentially a digital wallet or an account that holds Bitcoin, which is just a currency like any other, like pounds, like dollars, like yen. And it's easily transferable from wallet to wallet. Once you transfer your dollars into Bitcoin, you can transfer from wall to wall. So it - in the past, the way a lot of cybercriminality worked, it revolved around banking systems, right? You had to find ways to get people to give you their banking login credentials - in which case, you could drain their accounts. But you couldn't just drain their account and send it to your account, you know? You had to launder the money through a range of accounts and, in some cases, use individuals to physically bring cash across borders. These days, you have your victim - one, you know, ransomware basically allows you to just ask your victim for the money. You don't have to trick them into giving you anything. You just have to infiltrate their systems and threaten to destroy their business. But then they just hand you over the money. And Bitcoin and other cryptocurrencies have allowed the transfer of this money to happen very, very easily. So it's just, you know, you transfer your dollars into Bitcoin. And then you send your money from your account to the hackers' account. And then the transaction is done. GROSS: So - you know, we were talking about DarkSide. You've also looked into REvil, which is another ransomware group that works with affiliates. The affiliates actually do the hacking of the group and ask for the ransom. But they do it with the help of REvil or DarkSide or whoever the malware originator is. So can you compare REvil and DarkSide or compare the attack on JBS to the attack on Colonial Pipeline just to show what these groups have in common and what the differences are? SCHWIRTZ: I mean, it's hard to compare and contrast. DarkSide is, perhaps, according to some cybersecurity researchers - the members of DarkSide of, the members that created DarkSide were, perhaps, affiliates of REvil. So they were, perhaps, working with REvil's ransomware at one point before they set off on their own and made their own product. The thing that ties them both together and I think is most significant is that both groups appear to operate largely inside Russia. And I'd caveat that to an extent because some of these groups can be rather big. And they - because of the nature of the work being online, individuals can operate anywhere in the world. But at least the core of the operation is based in Russia and among Russian-speaking users. GROSS: Let me reintroduce you if you're just joining us. My guest is New York Times investigative reporter Michael Schwirtz. We'll talk more about ransomware attacks after a break. This is FRESH AIR. (SOUNDBITE OF THE BUDOS BAND'S \"INTO THE FOG\") GROSS: This is FRESH AIR. Let's get back to my interview with New York Times investigative reporter Michael Schwirtz about ransomware attacks and how the attackers operate. So REvil and DarkSide are based in Russia, as are many other cybercriminal gangs. Why is Russia such a hub for cybercriminals? SCHWIRTZ: There are a number of reasons for this. First, you know, the education system that focuses on math and science is very, very robust. But there are countries with robust, you know, computer science cultures all around the world. And I think what sets Russia apart and what makes the country a greenhouse for this type of activity - to use the term one cybersecurity researcher used with me - is that the government at best turns a blind eye to these sorts of activities and at worst co-ops and uses these groups as part of a broader, geopolitical strategy meant to undermine Western countries. GROSS: How do they get away with it in Russia? SCHWIRTZ: There's a simple answer - there's a simple and more complicated answer to that. The simple answer is that the Russian government has, basically, taken the stance that if none of these individuals are attacking Russian interests, so companies inside of Russia, then they can't be prosecuted under Russian laws. Russian law, according to the Kremlin, according to Vladimir Putin himself, does not have a provision for prosecuting individuals for carrying out ransom attacks against American companies. And so as long as these groups avoid attacking companies within Russia - and often, these groups will have rules prohibiting attacks against companies not only in Russia but also in the former Soviet Union at large. They are able to do so with impunity, which makes this problem very pernicious and difficult to snuff out if you're coming at it from a law enforcement perspective. GROSS: With so many Russian cybergangs attacking computer systems in America and other places around the world, do we know if Russian intelligence is cooperating with them, helping them in any way, and if Putin sees this as a kind of way of flexing his muscles without having any fingerprints on it? SCHWIRTZ: And there's a number of different ways that I think the Russian government and the intelligence services are involved. I don't think that every single attack has a Russian intelligence or law enforcement angle to it. But there is evidence that Russian intelligence services have co-opted cybercriminals to engage in intelligence. You know, it just too good of an opportunity to explore the computer systems of your enemies if you've already got a robust industry of individuals breaking into systems. So what seems to occur on occasion is that the intelligence services will make relationships with these cyber criminals and ask them, say, you know, they'll make a deal and say, you know, let's say we'll let you continue to engage in these sorts of operations and make money. But if you come across any sort of computer systems that might interest us, if you break into any government computer systems that might possess intelligence that could be used for national security purposes, you need to let us know. Now, there are also more direct use of cybersecurity infrastructure by the intelligence services. We've seen cases - there was one case from a few years ago where the operator of a very large botnet, which is a network of infected computers, started running searches that appeared to indicate a hunt for actionable intelligence. There were searches for information about a weapons deal between the United States and Turkey. There were searches for information about the situation, the war going on in Ukraine. And this fell so far outside of the normal operations of this infected network, which was generally focused on stealing banking credentials, that most security researchers and intelligence officials in the United States and elsewhere assumed that this was the Russian intelligence services basically coopting an infected network to engage in intelligence gathering. GROSS: President Biden is meeting with Putin next week. Do you assume that ransomware is going to come up in the conversation? SCHWIRTZ: It's definitely going to come up in the conversation. I think the Biden administration has made that clear. The real question is what the United States can do about it. The United States has leveled sanctions against Russian entities for involvement in cyberattacks carried out by the Russian intelligence services. And these would be overt attacks, you know, presumably ordered at the highest level of government to, in fact, the government computer systems. And the SolarWinds attack recently, which was recently revealed, comes to mind as part of that. But these ransomware attacks fall into this sort of strange area where the Biden administration and Western governments in general have to be a bit more creative because normally, this would be a law enforcement issue. And if Russia were an ally, the FBI could meet with the FSB, which is Russia's version of the FBI, and hash out a plan for going after these groups. But that's an impossible thing to do when the Russian government is, at very best, turning a blind eye to these groups, but often protecting them. GROSS: So these cybergangs, this ransomware, this is like criminal activity. Even if the Russian intelligence is collaborating with them in some way, it's not official. And I don't know if the U. S. could prove that Russian intelligence is working with them at all. So can Biden use something like the military Cyber Command to go after the ransomware attackers, or would that be considered an inappropriate use of the military because it's a criminal action? SCHWIRTZ: Right. This is the sort of gray area that we find ourselves in. I think the administration is pretty reticent to use the military, like you said, to be - for involvement in what is generally considered a law enforcement issue. I think it's no surprise to see that it was the FBI that was involved in extracting these Bitcoins from the DarkSide affiliate's wallet and not some other entity within the U. S. government. It's a very difficult thing to unleash the U. S. military, even in the realm of cyber, on the citizens of a country with which you share an adversarial relationship or anywhere, right? The potential for escalation is just unknown. And I think the administration is rightly treading carefully. And there just isn't a playbook for dealing with this. And part of that reason is because, you know, there's a hazy line between criminality, pure criminality and, you know, Russian-government-sanctioned actions that the administration and I think everyone is trying to figure out in this world of cybercriminality. GROSS: Well, Michael Schwirtz, I want to thank you so much for talking with us. SCHWIRTZ: I really appreciate it. It's been an honor. Thank you. GROSS: Michael Schwirtz is an investigative reporter for The New York Times. If you'd like to catch up on FRESH AIR interviews you missed, like this week's interview with Rita Moreno about the ethnic stereotyping and sexual harassment she faced in Hollywood and her tumultuous relationship with Marlon Brando, check out our website. You'll find lots of FRESH AIR interviews. (SOUNDBITE OF MUSIC) GROSS: FRESH AIR's executive producer is Danny Miller. Our technical director and engineer is Audrey Bentham. Our interviews and reviews are produced and edited by Amy Salit, Phyllis Myers, Sam Briger, Lauren Krenzel, Heidi Saman, Therese Madden, Ann Marie Baldonado, Thea Chaloner, Seth Kelley, Kayla Lattimore and Joe Wolfram. Our associate producer of digital media is Molly Seavy-Nesper. Roberta Shorrock directs the show. I'm Terry Gross.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-06-10-1004387255": {"title": "India And Tech Companies Clash Over Censorship, Privacy And 'Digital Colonialism' : NPR", "url": "https://www.npr.org/2021/06/10/1004387255/india-and-tech-companies-clash-over-censorship-privacy-and-digital-colonialism", "author": "No author found", "published_date": "2021-06-10", "content": "", "section": "Asia", "disclaimer": ""}, "2021-06-10-1004874311": {"title": "How Bitcoin Has Fueled Ransomware Attacks : NPR", "url": "https://www.npr.org/2021/06/10/1004874311/how-bitcoin-has-fueled-ransomware-attacks", "author": "No author found", "published_date": "2021-06-10", "content": "NOEL KING, HOST:  The world's largest meat producer, JBS, says it paid $11 million in bitcoin as ransom to cybercriminals. The company says it made that payment to prevent more disruptions after its plants in North America and Australia were shut down. Hackers typically demand payment in cybercurrency because it is very hard to trace. Here's NPR's Greg Myre. GREG MYRE, BYLINE: The problem has long plagued bank robbers and drug smugglers - how to transport and hide large sums of ill-gotten gains without getting caught. At last, ransomware hackers have found an almost perfect solution - cryptocurrencies. YONATAN STRIEM-AMIT: You now have a possibility to move millions of dollars' worth of cryptocurrency across nationalities in seconds. MYRE: Yonatan Striem-Amit is a co-founder of Cybereason. It's a Boston-based company that offers protection from hackers. YONATAN STRIEM-AMIT: It really is a very powerful tool in the hands of criminals to perform money laundering, to shift currency from one state to another in a way that's, in a sense, untraceable and definitely uncontrollable. MYRE: Until recently, many cybercrimes involved the small-scale theft of individual credit cards or bank accounts. Hitesh Sheth runs the cybersecurity company Vectra in Northern California. HITESH SHETH: If we were talking like this two years ago, we would not be talking about Bitcoin as being the dominant form of paying off the ransom. MYRE: But Bitcoin and other cryptocurrencies made it possible to extort huge ransoms from large companies, hospitals and city governments. And if the thieves live in countries like Russia, which many do, there's virtually no chance of getting caught. Ironically, cryptocurrency exchanges take place on what are called public ledgers. This means anybody can watch online, but the parties in a transaction are anonymous, disguised with a random number. Yonatan Striem-Amit explains. YONATAN STRIEM-AMIT: You see exactly all the way the money moves from one address, one wallet to another. However, there is no way for us to associate a person with these wallets. And a lot of people would have not just one address, one wallet, but can have dozens, hundreds. MYRE: So hackers can keep moving the currency from one anonymous account to another. This makes it very difficult, though not impossible, to trace. Consider the case of Colonial Pipeline. The FBI did recover more than half of the $4. 4 million in ransom the company paid to the hackers, believed to be based in Russia. This was a big breakthrough, but it's unlikely to become the norm. The FBI says it worked its way through a maze of more than 20 cryptocurrency accounts to find the hackers. Private companies are realizing they need to focus more on the threat of ransomware. Again, Hitesh Sheth. SHETH: Cybersecurity, the last couple years, has become a hot topic. But, you know, it's not just cybersecurity as like, hey, how do I stop attacks? It's really gotten down to, what is our ransomware strategy? Right? It's gotten very specific. MYRE: The ransom demands and the payments have skyrocketed. Oren Wortman is with the insurance company Beecher Carlson. OREN WORTMAN: We have now seen with our clients ransoms paid in excess of $10 million with demands as high as 40, 50 and $60 million. MYRE: Some insurance companies are no longer covering ransomware. WORTMAN: There are insurers out there who are blanketly not writing any new business. There are insurers who are dropping business. MYRE: With all this going on, the Biden administration is starting to talk about regulating cryptocurrencies. But so far, it's just talk. Greg Myre, NPR News, Washington. (SOUNDBITE OF SUBLAB AND AZALEH'S \"VIDURA\")KING: And just a quick note - Cybereason, one of the companies in Greg's story, is an NPR sponsor. (SOUNDBITE OF SUBLAB AND AZALEH'S \"VIDURA\") NOEL KING, HOST:   The world's largest meat producer, JBS, says it paid $11 million in bitcoin as ransom to cybercriminals. The company says it made that payment to prevent more disruptions after its plants in North America and Australia were shut down. Hackers typically demand payment in cybercurrency because it is very hard to trace. Here's NPR's Greg Myre. GREG MYRE, BYLINE: The problem has long plagued bank robbers and drug smugglers - how to transport and hide large sums of ill-gotten gains without getting caught. At last, ransomware hackers have found an almost perfect solution - cryptocurrencies. YONATAN STRIEM-AMIT: You now have a possibility to move millions of dollars' worth of cryptocurrency across nationalities in seconds. MYRE: Yonatan Striem-Amit is a co-founder of Cybereason. It's a Boston-based company that offers protection from hackers. YONATAN STRIEM-AMIT: It really is a very powerful tool in the hands of criminals to perform money laundering, to shift currency from one state to another in a way that's, in a sense, untraceable and definitely uncontrollable. MYRE: Until recently, many cybercrimes involved the small-scale theft of individual credit cards or bank accounts. Hitesh Sheth runs the cybersecurity company Vectra in Northern California. HITESH SHETH: If we were talking like this two years ago, we would not be talking about Bitcoin as being the dominant form of paying off the ransom. MYRE: But Bitcoin and other cryptocurrencies made it possible to extort huge ransoms from large companies, hospitals and city governments. And if the thieves live in countries like Russia, which many do, there's virtually no chance of getting caught. Ironically, cryptocurrency exchanges take place on what are called public ledgers. This means anybody can watch online, but the parties in a transaction are anonymous, disguised with a random number. Yonatan Striem-Amit explains. YONATAN STRIEM-AMIT: You see exactly all the way the money moves from one address, one wallet to another. However, there is no way for us to associate a person with these wallets. And a lot of people would have not just one address, one wallet, but can have dozens, hundreds. MYRE: So hackers can keep moving the currency from one anonymous account to another. This makes it very difficult, though not impossible, to trace. Consider the case of Colonial Pipeline. The FBI did recover more than half of the $4. 4 million in ransom the company paid to the hackers, believed to be based in Russia. This was a big breakthrough, but it's unlikely to become the norm. The FBI says it worked its way through a maze of more than 20 cryptocurrency accounts to find the hackers. Private companies are realizing they need to focus more on the threat of ransomware. Again, Hitesh Sheth. SHETH: Cybersecurity, the last couple years, has become a hot topic. But, you know, it's not just cybersecurity as like, hey, how do I stop attacks? It's really gotten down to, what is our ransomware strategy? Right? It's gotten very specific. MYRE: The ransom demands and the payments have skyrocketed. Oren Wortman is with the insurance company Beecher Carlson. OREN WORTMAN: We have now seen with our clients ransoms paid in excess of $10 million with demands as high as 40, 50 and $60 million. MYRE: Some insurance companies are no longer covering ransomware. WORTMAN: There are insurers out there who are blanketly not writing any new business. There are insurers who are dropping business. MYRE: With all this going on, the Biden administration is starting to talk about regulating cryptocurrencies. But so far, it's just talk. Greg Myre, NPR News, Washington. (SOUNDBITE OF SUBLAB AND AZALEH'S \"VIDURA\") KING: And just a quick note - Cybereason, one of the companies in Greg's story, is an NPR sponsor. (SOUNDBITE OF SUBLAB AND AZALEH'S \"VIDURA\")", "section": "National Security", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-06-11-1005600579": {"title": "Why is it so hard to buy an affordable used car in 2021? : Planet Money : NPR", "url": "https://www.npr.org/2021/06/11/1005600579/used-car-talk", "author": "No author found", "published_date": "2021-06-11", "content": "SYLVIE DOUGLIS, BYLINE: This is PLANET MONEY from NPR. (SOUNDBITE OF COIN SPINNING)KEITH ROMER, HOST:  Jacob Roy (ph) is a college student studying aerospace engineering. And last week, he realized he had a problem. JACOB ROY: I need to have a car by Saturday, otherwise I don't know how this is going to work out. ROMER: Jacob is from Pearland, Texas, in the suburbs around Houston. But this summer, he's going to live in Dallas for an internship with a gas turbine manufacturer. And he knows he's going to need a car to get to and from his job each day. So he hits up his local used car dealer. ROY: So I go up to the guy. I'm like, hey, I have $4,500, right? What? Maybe this wasn't the best car negotiating tactic, right? I was like, what car can I buy? And the dude laughed and said it'd make a great down payment. So it was pretty demoralizing. AMANDA ARONCZYK, HOST:  Jacob spends three days just driving around the Houston area in his parents' car, visiting any used car lot he can find. ROY: There's a lot of times I would just be driving along the road, would stop, say hey, name my price, and they would say, yeah, you should just go somewhere else. ROMER: Before long, he's meeting people with cars on Craigslist at abandoned gas stations. He's test-driving cars that can barely get up to highway speeds. And the clock is ticking. He's going to leave for Dallas in a matter of days. ARONCZYK: It gets to the point where Jacob starts to figure out what his backup plans are. Like, maybe I just don't buy a car. Maybe I just take the Greyhound to Dallas. (SOUNDBITE OF ALEXANDER ACE BAKER AND CLAIR MARLO'S \"POLKA NOSTRAL\")ROY: I figured, OK, 'cause I've done this before in high school, right? If I had a job, I could take my bike there, right? And this place is like 20 minutes away by bike. And I would just bring a bag of clothes. So I can bike there, get in there, change and then go to work. ROMER: But this is, like, kind of your first grown-up job, right? ROY: My first in-person office job - yes, sir. ROMER: Like, so you don't especially want to roll up on a bicycle on your first day. ROY: No, not at all. (SOUNDBITE OF ALEXANDER ACE BAKER AND CLAIR MARLO'S \"POLKA NOSTRAL\")ROMER: Hello, and welcome to PLANET MONEY. I'm Keith Romer. ARONCZYK: And I'm Amanda Aronczyk. Like it or not, the United States is kind of built around cars, especially in places like Texas. And buying a car is always a giant hassle, but 21-year-old Jacob Roy had the misfortune of trying to buy his first-ever car at possibly the worst moment in history to buy a used car. All over the country, used cars are in really short supply, and they are really expensive. ROMER: And as you may have noticed, this is actually true for a lot of things - lumber and mattress foam and refrigerators and houses and microchips, which we will get to that. But today on the show, we're going to focus in specifically on what is going on with used cars because the weirdness in that market contains all these lessons about how our economy reacted to the pandemic and how things are going to work as we start to head towards a post-COVID world. ARONCZYK: Also, we'll see if Jacob ever gets his used car. (SOUNDBITE OF ALEXANDER ACE BAKER AND CLAIR MARLO'S \"POLKA NOSTRAL\")ROMER: So the simple version of the used car market goes like this. Every year, around 17 million new cars are purchased or leased in the United States. And over time, as their leases end or their original owners decide they are ready to unload those cars, those cars enter the used car market. New cars come in one end of the machine, used cars come out the other. ARONCZYK: But inside that market for used cars machine, there are all these little mechanisms that determine how many used cars come out the other side and which used cars come out the other side. ROMER: And so to try to get a better handle on why 21-year-old Jacob and our co-workers and your cousin and your neighbor and America is having such a hard time finding an affordable used car, we are going to pop the hood. . . ARONCZYK: Pop the hood. ROMER: . . . On the machine - yeah, pop the hood - and poke around a little. ARONCZYK: The first mechanism we're going to look at in the machine - used car dealers. ROMER: Now, you may have a particular idea of a used car dealer in your head - plaid suit, maybe a cowboy hat, some dude making all kinds of promises about how this Hyundai Elantra, Amanda, is going to change your life. ARONCZYK: Such a great car. ROMER: Nicholas Soukas (ph) - he is not that kind of used car dealer. NICHOLAS SOUKAS: Listen; it's just a piece of metal. It's nothing special. We're moving metal around here, nothing special. ROMER: I met Nick (ph) at a used car auction in Doylestown, Pa. , where he was trying to get his hands on some more metal he could move. SOUKAS: I noticed another blue Toyota down there which was quite nice from the outside. But it's not what's on the outside. It's what's on the inside that counts. ARONCZYK: Oh, Nick. So sweet. ROMER: Nick is 32 - no plaid suit. He is wearing high-top Nikes and camouflage pants and a pink T-shirt from Levi's. There are about 50 pretty beat-up cars scattered around the lot at the auction, each with a big orange number scrawled on its windshield. Nick gets behind the wheel of an '05 Camry to give the engine a quick test. SOUKAS: So right off the bat, we have a check engine light. It has 184,000 miles. And definitely, it needs a flex pipe. You can hear the flex pipe from the exhaust. (SOUNDBITE OF ENGINE REVVING)SOUKAS: You know, looks like we're going to have to skip this one. ARONCZYK: Nick comes to four or five auctions a week. A lot of his job actually is not selling cars. It's buying the cars that he's ultimately going to sell. And Nick says that part of the job has gotten really hard lately. SOUKAS: You know, I can't get inventory. I can't secure inventory. All I can do is stay firm on my prices and try to make as much money as I can on my cars. That's really it, you know? ARONCZYK: In a normal year, he would try to keep 150, 160 cars on his lot. But now he is down to 80 or 90. Nick's running into a version of the same problem that the college kid, Jacob, was having. Used cars, even at auction, are really expensive right now. SOUKAS: I've been looking at the prices on my cars that I sold in 2017 and 2018, and I can't even get those cars at the auction for the price I sold them back then, which is ridiculous. ROMER: So the retail price in 2017 is lower than the wholesale price now. SOUKAS: Correct, yeah. It's insane - absolutely insane. ARONCZYK: But whatever the price, the process to buy is the same. This is what's called a sealed-bid auction. If a dealer likes a car, he writes down the bid and he puts it in a lockbox. Whoever bids the highest gets to buy the car. SOUKAS: We all want that one car because it's phenomenal - low mileage, clean. Diamonds - you know, that's what we're looking for, diamonds. ROMER: But this auction - not a lot of diamonds. As we walk around the lot, Nick is like one of those forensic investigators on TV, like, taking the black light to a crime scene. People lie, Amanda. Evidence never lies. ARONCZYK: Nick has got to figure out what exactly is wrong with each car. . . SOUKAS: Let me just give it a little gas. ARONCZYK: . . . And whether that thing is so wrong that none of his customers will want to buy it. SOUKAS: I always check the rearview mirrors to see if I see a cloud of smoke. ROMER: Sometimes, like with a blue Jetta he looked at, the clue is under the hood. SOUKAS: Looks like a squirrel nest - little squirrel nest. ROMER: The nest was empty. Also, Nick says, it might have been a rat's nest. SOUKAS: One time I found five or six kittens inside a hood. I rescued all of them. ROMER: Sometimes, like with a blue Mustang, Nick doesn't even have to look that closely. SOUKAS: Water damage front right - you can see the mold growing from there. This is definitely not for me. ROMER: Finally, Nick sees a car in the lot that is at least worth taking for a test drive. SOUKAS: This one looks nice on the outside 'cause it's a Ford Explorer. I think it's an '08, '09. It's got a good copper color to it, which is quite uncommon on these vehicles. Does have some minor wear and tear, scratches, but it overall looks pretty decent. ROMER: Nick knows that all of the cars for sale here are trade-ins from a nearby new car dealership, which also has a used car lot attached to it. These cars here at the auction - they are the discards, cars that the dealer either couldn't sell or didn't even want to try selling. SOUKAS: We don't know what the problem is, but we'll find out now - drives good, doesn't sound terrible. ROMER: If you buy it, is that how you'll advertise it - drives good, doesn't sound terrible? SOUKAS: (Laughter) We would sell it as is. No, we would fix it and take care of that problem. ARONCZYK: The Explorer is not perfect. It's a 12-year-old car with 177,000 miles on it. But it doesn't have to be perfect. Nick just needs something to sell on his lot. ROMER: By the time we get back to the auction, Nick has decided that the Explorer is at least worth bidding on. SOUKAS: You know, I'm thinking - throwing a number out there - maybe 3,700, 3,800. I don't want to say too loud as these dealers are walking by, but maybe 4,000. I think 4,000 is a good number. I mean, it doesn't look like a bad car. ROMER: Nick changes his mind a couple times, brings his bid back down to 3,850. SOUKAS: I want you to give me the lucky number. And if I get it, I'll tell you I get it. I want you to give me the lucky number. ROMER: I think we go 3,863. SOUKAS: Thirty-eight sixty-three, OK. We'll see. If I get it, I'll give you a ring tomorrow. ROMER: (Laughter). SOUKAS: I'll thank you for this one. ROMER: In the end, Nick ends up bidding on just two cars, the Ford Explorer for my lucky number, 3,863, and the Jetta with the squirrel/rat's nest under the hood for $2,555. ARONCZYK: Nick drops off his two bids into the lockbox. He has to wait until tomorrow to see if he wins either of his bids. ROMER: Now, any individual used car dealer is just a small piece of the used car market machine we were talking about before. Nick, for example, says he sells 500 or 600 cars a year. ARONCZYK: So to figure out what's really going on, we have to go up even further in the used car pipeline to the people who actually run the auctions where dealers, like Nick, get their cars. MATT TRAPP: My name is Matt Trapp, and I'm a regional vice president for Manheim. ARONCZYK: Manheim is the biggest wholesale car auction company in the country. TRAPP: In the U. S. market, we will roughly sell about 4 million vehicles in a given year. ROMER: That's a lot of cars. TRAPP: It is a lot of cars, yes. ROMER: The cars sold at Matt's auctions come from all over - car dealers who want to unload their trade-ins or cars they've been leasing out whose leases had expired. ARONCZYK: They come from finance companies repossessing cars when people default on their loans or from rental car companies selling off cars that they've had for a couple years so they can buy new ones. That is how things usually work. ROMER: But Matt says things have not been working like usual. And the story that explains why the college kid, Jacob, is seeing such high prices at the lot and the dealer, Nick, is seeing such high prices when he tries to get inventory to sell - that story started a little more than a year ago. TRAPP: 2020 was an absolute roller coaster ride. When COVID hit, our volume went to about 20% of what we would see in a normal week. You know, we didn't know what to do, didn't know what was going to happen with the economy, what the needs were going to be. ROMER: Right at the start of the pandemic, travel fell off a cliff. ARONCZYK: So car rental companies started unloading their cars. Hertz, as you may remember, went into bankruptcy and dumped almost 200,000 cars into the market. Avis cut its fleet by about the same amount. ROMER: I mean, are you then getting calls from companies saying, like, look; we got 80,000 cars that we need to move. Where can we put them? TRAPP: Yeah, absolutely. I mean, we received those calls pretty much daily early on. And so our auctions actually became holding pens, and we were wedging vehicles in wherever we could. ROMER: For weeks and weeks, companies and dealers kept dropping off cars to sell that no one wanted to buy. TRAPP: There was a moment we were like, you know, if this lasts a long, long time, I mean, we could be just sitting on - if there's real - no real solution to this and the economy just craters, kind of like it happened in '08, I mean, we could be sitting on vehicles for years. ROMER: But that worst-case scenario is not what ended up happening. ARONCZYK: Because a lot of people who still had to go into work didn't want to take public transportation if they could avoid it. And people who worked from home started to realize that they could just as well be in Wyoming or Florida. TRAPP: And then we started to see this rebound. You know, through May and June, the demand started to come back. ROMER: The auctions that Matt runs actually went through their huge glut in used cars in a matter of months. And before long, they had a new problem, the opposite problem. All the channels they relied on for their supply of used cars started running dry. ARONCZYK: Because of COVID, car manufacturers closed their plants and dialed the number of new cars they were going to produce way back. And fewer new cars to sell means fewer trade-ins coming into Matt's auctions. ROMER: But there were these other, weirder things going on, too, like with car repossessions. Because of loan forgiveness programs and stimulus money, the number of people defaulting on their car payments actually went down in 2020. Car repossessions went down last year in a pandemic, which meant fewer repossessed cars showing up at Matt's auctions. ARONCZYK: And as people started being more willing to travel, they also started renting cars again. So rental car companies were a lot less eager to sell off their cars at Matt's auctions. TRAPP: You have rental fleets. They're trying to buy. They're not looking to deflate anything. They don't have enough cars. And you hear these stories of people, you know, flying into Denver and trying to get an SUV, and it's $5,000 a week. ROMER: Shoutout also to the people I read about in Hawaii who started renting U-Hauls instead of going to the rental car companies just because it was cheaper. ARONCZYK: For Matt, all of these different factors turned a situation where he had a historically high number of used cars into one where he had a historically low number of used cars. TRAPP: We've never seen anything like this. I talked to, you know, a lot of the guys I work with who have been in the industry twice as long as I have, and they can't recall a time - nothing, nothing at all to the degree to which we're seeing right now. ROMER: And like Nick was seeing at his dealership in New Jersey and the college kid, Jacob, on his quest in Texas, low supply and high demand means prices are going bonkers. TRAPP: I mean, dealers are just going anywhere and everywhere they can to find a vehicle. And they're just - they're paying up for it. ARONCZYK: Prices at Manheim's auctions have increased by almost 50% since a year ago. ROMER: Now, there is an obvious solution to this whole not enough cars problem. Car companies could just make more cars. (SOUNDBITE OF ANTHONY GODDARD AND RON KOMIE'S \"SIBERIAN TAVERN\")ARONCZYK: And believe me, they want to. They really, really want to. But they can't, for some obvious reasons and some less obvious ones. That is after the break. (SOUNDBITE OF ANTHONY GODDARD AND RON KOMIE'S \"SIBERIAN TAVERN\")ROMER: OK, we know some of you have been walking around your houses or driving in your increasingly valuable used cars listening to us and periodically shouting out, I know the answer. I know why there's a car shortage. It's semiconductors. I know it. And you are right to an extent - gold star. ARONCZYK: Well done. There is a semiconductor shortage right now. And that is a big problem for the car industry because, of course, these days, your car is as much a computer as it is a big hunk of metal machinery. And all of the computer-y stuff depends on semiconductors, microchips. ROMER: When I'm in my car, what is being controlled by a semiconductor that I don't realize? PEGGY CARRIERES: Your braking mechanism, your accelerator, your air conditioning, basically everything. ARONCZYK: That's Peggy Carrieres. She's a global vice president at Avnet, a giant electronics distributor. Peggy says in a normal market, microchips are pretty cheap. But right now, car companies just cannot get their hands on the ones they need to finish making their cars. ROMER: So these - like, these $50,000 SUVs are sitting there unfinished because they're missing microchips that cost pennies or a dollar or something. CARRIERES: I know of, you know, some cases where you have it completely assembled, and it's missing one part. Yes, that's happening. ROMER: To be clear, Peggy is not the reason car companies do not have enough semiconductors. But since her job is to help companies get the microchips they need, we figured she could at least help us understand what the problem was. CARRIERES: You know, if you look at 2020, you - I hate to say, you know, what else can go wrong because you just never know. But we had, you know, the pandemic, obviously. ARONCZYK: But also an earthquake - that was in February, shut down microchip factories in Japan. ROMER: And fires - three of them, actually - one in a semiconductor supplier, two more at different semiconductor plants, again in Japan. ARONCZYK: And locusts - just kidding. But there was an ice storm - that giant freeze where Texas lost power. That shut down Samsung's microchip plant for a little while. ROMER: And even the factories that were not taken out by all of these acts of God, they had a brutal time getting the semiconductors they could make to their customers. CARRIERES: We've got boats backed up at the docks, the ports. Like Long Beach is backed up big time. And they can't get the products to market. ARONCZYK: Shipping generally was a giant mess during the pandemic. The car companies were waiting for microchips. The microchip companies were waiting for parts they needed, and all the way down to, like, the raw metal ore to make the parts. Call that the broken supply chain explanation for why there aren't enough new cars and, therefore, not enough used cars. ROMER: But Peggy says there's another way to think about what is happening with the car industry. CARRIERES: I think historically, if you look at how the automotive industry has run their forecasts, it's very lean in their inventory model and in their forecast model. ARONCZYK: What that means is that car manufacturers have gotten really, really good at getting the exact right parts they need from their suppliers to the exact right factories at exactly the right moment, just in time. They don't want parts sitting around in some warehouse for months waiting to be used. ROMER: So when the pandemic hit, the car companies figured, we're not going to need more microchips until we start up the factories again. We'll just order more then. ARONCZYK: Meanwhile, demand for semiconductors went through the roof to run all the servers that all the working from home required, to go inside our kids' new iPads so they could go to school remotely. By the time a lot of the car companies realized demand for their cars was going to come back, it was too late. ROMER: Is it the right way to think about it that they just sort of gave up their place in line and had to go back to the back of the line? CARRIERES: That's exactly it. That's exactly what happened. And that really was, you know, a mistake that the automotive manufacturers made. In taking their orders out of the queue, they did lose their place in line. ROMER: And that line for semiconductors - it has gotten really, really long. CARRIERES: We literally have lead times that are over a year long right now. ARONCZYK: It's going to be a while before car manufacturers get all the chips they need to make all the new cars consumers want right now, which means it's also going to be a while before the used car market goes back to normal. ROMER: Matt Trapp, who runs all those giant used car auctions, was not willing to predict when that would happen. But he did have some practical advice. TRAPP: I tell my friends who are looking to buy a car - they ask me - it's like, Matt, I want to buy a used car. What do you suggest right now? And I tell them no. Why? Why would you? Unless yours is broken down on the side of the road or you really need to change into something different, just hold on. Just wait (laughter). ROMER: Your job is literally to sell millions of used cars to the United States, and your advice is don't buy a used car right now. TRAPP: (Laughter) If you - unless you absolutely have to, I'm saying probably wait. ARONCZYK: New car companies are slowly bringing some of their factories back online, figuring out ways to build cars without all those bells and whistles that requires so many microchips. Maybe you don't need a full navigation system. Production might get closer to normal later this year sometime, or maybe not until 2022. ROMER: And in the meantime, there are still some used cars out there. I talked to the used car dealer, Nick, the day after the auction. He had the winning bids on both the Ford Explorer and the Jetta with the squirrel/rat's nest under the hood. ARONCZYK: And Jacob Roy, the college kid in Texas who was looking for a car - he saw a Craigslist post for a gray Honda Civic that he could actually afford. He met the owner, took the car for a test drive. ROY: When I went from first to second gear, the car would, like, shutter and jump real bad, right? But I was like, that'll work. ARONCZYK: So Jacob got the guy to come down a few hundred bucks on the price, and that was that. He bought the car just days before he had to drive to Dallas to start his internship. ROMER: How old is the Civic? ROY: God, I feel like an idiot just telling you. (LAUGHTER)ROY: 2007, four-door sedan, 142,000 miles on it, and I paid 4,700. In normal years, this would be garbage, 100%. This would be a terrible price. ROMER: But 2021 is not a normal year. And prices are just going to be terrible for a little while - for lumber and mattress foam and refrigerators and used cars. (SOUNDBITE OF THOMAS RICHARD SMITH SR. SONG, \"SMALL TOWN BANJO BREAKDOWN\")ROMER: Are you in the market for some public radio swag? Then come on down to the NPR Shop. We got Micro-Face T-shirts. We've got tote bags. We got little hats that say NPR right across the front. Come on down to shop. npr. org/planetmoney - that is shop. npr. org/planetmoney - for all your public radio swag needs. (SOUNDBITE OF COW MOOING)ROMER: You can also email us at planetmoney@npr. org. We are on Instagram, Twitter, Facebook, TikTok. . . (SOUNDBITE OF CIRCUS HORN)ROMER: . . . @planetmoney. ARONCZYK: Do I have to do it, too? ROMER: You do. (SOUNDBITE OF WHISTLE)ARONCZYK: Today's show was produced by Dan Girma and Alexi Horowitz-Ghazi and mastered by. . . AMANDA ARONCZYK AND KEITH ROMER: Gilly Moon. (SOUNDBITE OF BOING)ARONCZYK: PLANET MONEY's supervising producer is Alex Goldmark. This episode was edited by Brittany Luse. I'm Amanda Aronczyk. (SOUNDBITE OF SPRING)ROMER: I'm Keith Romer. ARONCZYK AND ROMER: This is NPR. ROMER: Thanks for listening. (SOUNDBITE OF THOMAS RICHARD SMITH SR. SONG, \"SMALL TOWN BANJO BREAKDOWN\") SYLVIE DOUGLIS, BYLINE: This is PLANET MONEY from NPR. (SOUNDBITE OF COIN SPINNING) KEITH ROMER, HOST:   Jacob Roy (ph) is a college student studying aerospace engineering. And last week, he realized he had a problem. JACOB ROY: I need to have a car by Saturday, otherwise I don't know how this is going to work out. ROMER: Jacob is from Pearland, Texas, in the suburbs around Houston. But this summer, he's going to live in Dallas for an internship with a gas turbine manufacturer. And he knows he's going to need a car to get to and from his job each day. So he hits up his local used car dealer. ROY: So I go up to the guy. I'm like, hey, I have $4,500, right? What? Maybe this wasn't the best car negotiating tactic, right? I was like, what car can I buy? And the dude laughed and said it'd make a great down payment. So it was pretty demoralizing. AMANDA ARONCZYK, HOST:   Jacob spends three days just driving around the Houston area in his parents' car, visiting any used car lot he can find. ROY: There's a lot of times I would just be driving along the road, would stop, say hey, name my price, and they would say, yeah, you should just go somewhere else. ROMER: Before long, he's meeting people with cars on Craigslist at abandoned gas stations. He's test-driving cars that can barely get up to highway speeds. And the clock is ticking. He's going to leave for Dallas in a matter of days. ARONCZYK: It gets to the point where Jacob starts to figure out what his backup plans are. Like, maybe I just don't buy a car. Maybe I just take the Greyhound to Dallas. (SOUNDBITE OF ALEXANDER ACE BAKER AND CLAIR MARLO'S \"POLKA NOSTRAL\") ROY: I figured, OK, 'cause I've done this before in high school, right? If I had a job, I could take my bike there, right? And this place is like 20 minutes away by bike. And I would just bring a bag of clothes. So I can bike there, get in there, change and then go to work. ROMER: But this is, like, kind of your first grown-up job, right? ROY: My first in-person office job - yes, sir. ROMER: Like, so you don't especially want to roll up on a bicycle on your first day. ROY: No, not at all. (SOUNDBITE OF ALEXANDER ACE BAKER AND CLAIR MARLO'S \"POLKA NOSTRAL\") ROMER: Hello, and welcome to PLANET MONEY. I'm Keith Romer. ARONCZYK: And I'm Amanda Aronczyk. Like it or not, the United States is kind of built around cars, especially in places like Texas. And buying a car is always a giant hassle, but 21-year-old Jacob Roy had the misfortune of trying to buy his first-ever car at possibly the worst moment in history to buy a used car. All over the country, used cars are in really short supply, and they are really expensive. ROMER: And as you may have noticed, this is actually true for a lot of things - lumber and mattress foam and refrigerators and houses and microchips, which we will get to that. But today on the show, we're going to focus in specifically on what is going on with used cars because the weirdness in that market contains all these lessons about how our economy reacted to the pandemic and how things are going to work as we start to head towards a post-COVID world. ARONCZYK: Also, we'll see if Jacob ever gets his used car. (SOUNDBITE OF ALEXANDER ACE BAKER AND CLAIR MARLO'S \"POLKA NOSTRAL\") ROMER: So the simple version of the used car market goes like this. Every year, around 17 million new cars are purchased or leased in the United States. And over time, as their leases end or their original owners decide they are ready to unload those cars, those cars enter the used car market. New cars come in one end of the machine, used cars come out the other. ARONCZYK: But inside that market for used cars machine, there are all these little mechanisms that determine how many used cars come out the other side and which used cars come out the other side. ROMER: And so to try to get a better handle on why 21-year-old Jacob and our co-workers and your cousin and your neighbor and America is having such a hard time finding an affordable used car, we are going to pop the hood. . . ARONCZYK: Pop the hood. ROMER: . . . On the machine - yeah, pop the hood - and poke around a little. ARONCZYK: The first mechanism we're going to look at in the machine - used car dealers. ROMER: Now, you may have a particular idea of a used car dealer in your head - plaid suit, maybe a cowboy hat, some dude making all kinds of promises about how this Hyundai Elantra, Amanda, is going to change your life. ARONCZYK: Such a great car. ROMER: Nicholas Soukas (ph) - he is not that kind of used car dealer. NICHOLAS SOUKAS: Listen; it's just a piece of metal. It's nothing special. We're moving metal around here, nothing special. ROMER: I met Nick (ph) at a used car auction in Doylestown, Pa. , where he was trying to get his hands on some more metal he could move. SOUKAS: I noticed another blue Toyota down there which was quite nice from the outside. But it's not what's on the outside. It's what's on the inside that counts. ARONCZYK: Oh, Nick. So sweet. ROMER: Nick is 32 - no plaid suit. He is wearing high-top Nikes and camouflage pants and a pink T-shirt from Levi's. There are about 50 pretty beat-up cars scattered around the lot at the auction, each with a big orange number scrawled on its windshield. Nick gets behind the wheel of an '05 Camry to give the engine a quick test. SOUKAS: So right off the bat, we have a check engine light. It has 184,000 miles. And definitely, it needs a flex pipe. You can hear the flex pipe from the exhaust. (SOUNDBITE OF ENGINE REVVING) SOUKAS: You know, looks like we're going to have to skip this one. ARONCZYK: Nick comes to four or five auctions a week. A lot of his job actually is not selling cars. It's buying the cars that he's ultimately going to sell. And Nick says that part of the job has gotten really hard lately. SOUKAS: You know, I can't get inventory. I can't secure inventory. All I can do is stay firm on my prices and try to make as much money as I can on my cars. That's really it, you know? ARONCZYK: In a normal year, he would try to keep 150, 160 cars on his lot. But now he is down to 80 or 90. Nick's running into a version of the same problem that the college kid, Jacob, was having. Used cars, even at auction, are really expensive right now. SOUKAS: I've been looking at the prices on my cars that I sold in 2017 and 2018, and I can't even get those cars at the auction for the price I sold them back then, which is ridiculous. ROMER: So the retail price in 2017 is lower than the wholesale price now. SOUKAS: Correct, yeah. It's insane - absolutely insane. ARONCZYK: But whatever the price, the process to buy is the same. This is what's called a sealed-bid auction. If a dealer likes a car, he writes down the bid and he puts it in a lockbox. Whoever bids the highest gets to buy the car. SOUKAS: We all want that one car because it's phenomenal - low mileage, clean. Diamonds - you know, that's what we're looking for, diamonds. ROMER: But this auction - not a lot of diamonds. As we walk around the lot, Nick is like one of those forensic investigators on TV, like, taking the black light to a crime scene. People lie, Amanda. Evidence never lies. ARONCZYK: Nick has got to figure out what exactly is wrong with each car. . . SOUKAS: Let me just give it a little gas. ARONCZYK: . . . And whether that thing is so wrong that none of his customers will want to buy it. SOUKAS: I always check the rearview mirrors to see if I see a cloud of smoke. ROMER: Sometimes, like with a blue Jetta he looked at, the clue is under the hood. SOUKAS: Looks like a squirrel nest - little squirrel nest. ROMER: The nest was empty. Also, Nick says, it might have been a rat's nest. SOUKAS: One time I found five or six kittens inside a hood. I rescued all of them. ROMER: Sometimes, like with a blue Mustang, Nick doesn't even have to look that closely. SOUKAS: Water damage front right - you can see the mold growing from there. This is definitely not for me. ROMER: Finally, Nick sees a car in the lot that is at least worth taking for a test drive. SOUKAS: This one looks nice on the outside 'cause it's a Ford Explorer. I think it's an '08, '09. It's got a good copper color to it, which is quite uncommon on these vehicles. Does have some minor wear and tear, scratches, but it overall looks pretty decent. ROMER: Nick knows that all of the cars for sale here are trade-ins from a nearby new car dealership, which also has a used car lot attached to it. These cars here at the auction - they are the discards, cars that the dealer either couldn't sell or didn't even want to try selling. SOUKAS: We don't know what the problem is, but we'll find out now - drives good, doesn't sound terrible. ROMER: If you buy it, is that how you'll advertise it - drives good, doesn't sound terrible? SOUKAS: (Laughter) We would sell it as is. No, we would fix it and take care of that problem. ARONCZYK: The Explorer is not perfect. It's a 12-year-old car with 177,000 miles on it. But it doesn't have to be perfect. Nick just needs something to sell on his lot. ROMER: By the time we get back to the auction, Nick has decided that the Explorer is at least worth bidding on. SOUKAS: You know, I'm thinking - throwing a number out there - maybe 3,700, 3,800. I don't want to say too loud as these dealers are walking by, but maybe 4,000. I think 4,000 is a good number. I mean, it doesn't look like a bad car. ROMER: Nick changes his mind a couple times, brings his bid back down to 3,850. SOUKAS: I want you to give me the lucky number. And if I get it, I'll tell you I get it. I want you to give me the lucky number. ROMER: I think we go 3,863. SOUKAS: Thirty-eight sixty-three, OK. We'll see. If I get it, I'll give you a ring tomorrow. ROMER: (Laughter). SOUKAS: I'll thank you for this one. ROMER: In the end, Nick ends up bidding on just two cars, the Ford Explorer for my lucky number, 3,863, and the Jetta with the squirrel/rat's nest under the hood for $2,555. ARONCZYK: Nick drops off his two bids into the lockbox. He has to wait until tomorrow to see if he wins either of his bids. ROMER: Now, any individual used car dealer is just a small piece of the used car market machine we were talking about before. Nick, for example, says he sells 500 or 600 cars a year. ARONCZYK: So to figure out what's really going on, we have to go up even further in the used car pipeline to the people who actually run the auctions where dealers, like Nick, get their cars. MATT TRAPP: My name is Matt Trapp, and I'm a regional vice president for Manheim. ARONCZYK: Manheim is the biggest wholesale car auction company in the country. TRAPP: In the U. S. market, we will roughly sell about 4 million vehicles in a given year. ROMER: That's a lot of cars. TRAPP: It is a lot of cars, yes. ROMER: The cars sold at Matt's auctions come from all over - car dealers who want to unload their trade-ins or cars they've been leasing out whose leases had expired. ARONCZYK: They come from finance companies repossessing cars when people default on their loans or from rental car companies selling off cars that they've had for a couple years so they can buy new ones. That is how things usually work. ROMER: But Matt says things have not been working like usual. And the story that explains why the college kid, Jacob, is seeing such high prices at the lot and the dealer, Nick, is seeing such high prices when he tries to get inventory to sell - that story started a little more than a year ago. TRAPP: 2020 was an absolute roller coaster ride. When COVID hit, our volume went to about 20% of what we would see in a normal week. You know, we didn't know what to do, didn't know what was going to happen with the economy, what the needs were going to be. ROMER: Right at the start of the pandemic, travel fell off a cliff. ARONCZYK: So car rental companies started unloading their cars. Hertz, as you may remember, went into bankruptcy and dumped almost 200,000 cars into the market. Avis cut its fleet by about the same amount. ROMER: I mean, are you then getting calls from companies saying, like, look; we got 80,000 cars that we need to move. Where can we put them? TRAPP: Yeah, absolutely. I mean, we received those calls pretty much daily early on. And so our auctions actually became holding pens, and we were wedging vehicles in wherever we could. ROMER: For weeks and weeks, companies and dealers kept dropping off cars to sell that no one wanted to buy. TRAPP: There was a moment we were like, you know, if this lasts a long, long time, I mean, we could be just sitting on - if there's real - no real solution to this and the economy just craters, kind of like it happened in '08, I mean, we could be sitting on vehicles for years. ROMER: But that worst-case scenario is not what ended up happening. ARONCZYK: Because a lot of people who still had to go into work didn't want to take public transportation if they could avoid it. And people who worked from home started to realize that they could just as well be in Wyoming or Florida. TRAPP: And then we started to see this rebound. You know, through May and June, the demand started to come back. ROMER: The auctions that Matt runs actually went through their huge glut in used cars in a matter of months. And before long, they had a new problem, the opposite problem. All the channels they relied on for their supply of used cars started running dry. ARONCZYK: Because of COVID, car manufacturers closed their plants and dialed the number of new cars they were going to produce way back. And fewer new cars to sell means fewer trade-ins coming into Matt's auctions. ROMER: But there were these other, weirder things going on, too, like with car repossessions. Because of loan forgiveness programs and stimulus money, the number of people defaulting on their car payments actually went down in 2020. Car repossessions went down last year in a pandemic, which meant fewer repossessed cars showing up at Matt's auctions. ARONCZYK: And as people started being more willing to travel, they also started renting cars again. So rental car companies were a lot less eager to sell off their cars at Matt's auctions. TRAPP: You have rental fleets. They're trying to buy. They're not looking to deflate anything. They don't have enough cars. And you hear these stories of people, you know, flying into Denver and trying to get an SUV, and it's $5,000 a week. ROMER: Shoutout also to the people I read about in Hawaii who started renting U-Hauls instead of going to the rental car companies just because it was cheaper. ARONCZYK: For Matt, all of these different factors turned a situation where he had a historically high number of used cars into one where he had a historically low number of used cars. TRAPP: We've never seen anything like this. I talked to, you know, a lot of the guys I work with who have been in the industry twice as long as I have, and they can't recall a time - nothing, nothing at all to the degree to which we're seeing right now. ROMER: And like Nick was seeing at his dealership in New Jersey and the college kid, Jacob, on his quest in Texas, low supply and high demand means prices are going bonkers. TRAPP: I mean, dealers are just going anywhere and everywhere they can to find a vehicle. And they're just - they're paying up for it. ARONCZYK: Prices at Manheim's auctions have increased by almost 50% since a year ago. ROMER: Now, there is an obvious solution to this whole not enough cars problem. Car companies could just make more cars. (SOUNDBITE OF ANTHONY GODDARD AND RON KOMIE'S \"SIBERIAN TAVERN\") ARONCZYK: And believe me, they want to. They really, really want to. But they can't, for some obvious reasons and some less obvious ones. That is after the break. (SOUNDBITE OF ANTHONY GODDARD AND RON KOMIE'S \"SIBERIAN TAVERN\") ROMER: OK, we know some of you have been walking around your houses or driving in your increasingly valuable used cars listening to us and periodically shouting out, I know the answer. I know why there's a car shortage. It's semiconductors. I know it. And you are right to an extent - gold star. ARONCZYK: Well done. There is a semiconductor shortage right now. And that is a big problem for the car industry because, of course, these days, your car is as much a computer as it is a big hunk of metal machinery. And all of the computer-y stuff depends on semiconductors, microchips. ROMER: When I'm in my car, what is being controlled by a semiconductor that I don't realize? PEGGY CARRIERES: Your braking mechanism, your accelerator, your air conditioning, basically everything. ARONCZYK: That's Peggy Carrieres. She's a global vice president at Avnet, a giant electronics distributor. Peggy says in a normal market, microchips are pretty cheap. But right now, car companies just cannot get their hands on the ones they need to finish making their cars. ROMER: So these - like, these $50,000 SUVs are sitting there unfinished because they're missing microchips that cost pennies or a dollar or something. CARRIERES: I know of, you know, some cases where you have it completely assembled, and it's missing one part. Yes, that's happening. ROMER: To be clear, Peggy is not the reason car companies do not have enough semiconductors. But since her job is to help companies get the microchips they need, we figured she could at least help us understand what the problem was. CARRIERES: You know, if you look at 2020, you - I hate to say, you know, what else can go wrong because you just never know. But we had, you know, the pandemic, obviously. ARONCZYK: But also an earthquake - that was in February, shut down microchip factories in Japan. ROMER: And fires - three of them, actually - one in a semiconductor supplier, two more at different semiconductor plants, again in Japan. ARONCZYK: And locusts - just kidding. But there was an ice storm - that giant freeze where Texas lost power. That shut down Samsung's microchip plant for a little while. ROMER: And even the factories that were not taken out by all of these acts of God, they had a brutal time getting the semiconductors they could make to their customers. CARRIERES: We've got boats backed up at the docks, the ports. Like Long Beach is backed up big time. And they can't get the products to market. ARONCZYK: Shipping generally was a giant mess during the pandemic. The car companies were waiting for microchips. The microchip companies were waiting for parts they needed, and all the way down to, like, the raw metal ore to make the parts. Call that the broken supply chain explanation for why there aren't enough new cars and, therefore, not enough used cars. ROMER: But Peggy says there's another way to think about what is happening with the car industry. CARRIERES: I think historically, if you look at how the automotive industry has run their forecasts, it's very lean in their inventory model and in their forecast model. ARONCZYK: What that means is that car manufacturers have gotten really, really good at getting the exact right parts they need from their suppliers to the exact right factories at exactly the right moment, just in time. They don't want parts sitting around in some warehouse for months waiting to be used. ROMER: So when the pandemic hit, the car companies figured, we're not going to need more microchips until we start up the factories again. We'll just order more then. ARONCZYK: Meanwhile, demand for semiconductors went through the roof to run all the servers that all the working from home required, to go inside our kids' new iPads so they could go to school remotely. By the time a lot of the car companies realized demand for their cars was going to come back, it was too late. ROMER: Is it the right way to think about it that they just sort of gave up their place in line and had to go back to the back of the line? CARRIERES: That's exactly it. That's exactly what happened. And that really was, you know, a mistake that the automotive manufacturers made. In taking their orders out of the queue, they did lose their place in line. ROMER: And that line for semiconductors - it has gotten really, really long. CARRIERES: We literally have lead times that are over a year long right now. ARONCZYK: It's going to be a while before car manufacturers get all the chips they need to make all the new cars consumers want right now, which means it's also going to be a while before the used car market goes back to normal. ROMER: Matt Trapp, who runs all those giant used car auctions, was not willing to predict when that would happen. But he did have some practical advice. TRAPP: I tell my friends who are looking to buy a car - they ask me - it's like, Matt, I want to buy a used car. What do you suggest right now? And I tell them no. Why? Why would you? Unless yours is broken down on the side of the road or you really need to change into something different, just hold on. Just wait (laughter). ROMER: Your job is literally to sell millions of used cars to the United States, and your advice is don't buy a used car right now. TRAPP: (Laughter) If you - unless you absolutely have to, I'm saying probably wait. ARONCZYK: New car companies are slowly bringing some of their factories back online, figuring out ways to build cars without all those bells and whistles that requires so many microchips. Maybe you don't need a full navigation system. Production might get closer to normal later this year sometime, or maybe not until 2022. ROMER: And in the meantime, there are still some used cars out there. I talked to the used car dealer, Nick, the day after the auction. He had the winning bids on both the Ford Explorer and the Jetta with the squirrel/rat's nest under the hood. ARONCZYK: And Jacob Roy, the college kid in Texas who was looking for a car - he saw a Craigslist post for a gray Honda Civic that he could actually afford. He met the owner, took the car for a test drive. ROY: When I went from first to second gear, the car would, like, shutter and jump real bad, right? But I was like, that'll work. ARONCZYK: So Jacob got the guy to come down a few hundred bucks on the price, and that was that. He bought the car just days before he had to drive to Dallas to start his internship. ROMER: How old is the Civic? ROY: God, I feel like an idiot just telling you. (LAUGHTER) ROY: 2007, four-door sedan, 142,000 miles on it, and I paid 4,700. In normal years, this would be garbage, 100%. This would be a terrible price. ROMER: But 2021 is not a normal year. And prices are just going to be terrible for a little while - for lumber and mattress foam and refrigerators and used cars. (SOUNDBITE OF THOMAS RICHARD SMITH SR. SONG, \"SMALL TOWN BANJO BREAKDOWN\") ROMER: Are you in the market for some public radio swag? Then come on down to the NPR Shop. We got Micro-Face T-shirts. We've got tote bags. We got little hats that say NPR right across the front. Come on down to shop. npr. org/planetmoney - that is shop. npr. org/planetmoney - for all your public radio swag needs. (SOUNDBITE OF COW MOOING) ROMER: You can also email us at planetmoney@npr. org. We are on Instagram, Twitter, Facebook, TikTok. . . (SOUNDBITE OF CIRCUS HORN) ROMER: . . . @planetmoney. ARONCZYK: Do I have to do it, too? ROMER: You do. (SOUNDBITE OF WHISTLE) ARONCZYK: Today's show was produced by Dan Girma and Alexi Horowitz-Ghazi and mastered by. . . AMANDA ARONCZYK AND KEITH ROMER: Gilly Moon. (SOUNDBITE OF BOING) ARONCZYK: PLANET MONEY's supervising producer is Alex Goldmark. This episode was edited by Brittany Luse. I'm Amanda Aronczyk. (SOUNDBITE OF SPRING) ROMER: I'm Keith Romer. ARONCZYK AND ROMER: This is NPR. ROMER: Thanks for listening. (SOUNDBITE OF THOMAS RICHARD SMITH SR. SONG, \"SMALL TOWN BANJO BREAKDOWN\")", "section": "Used Car Talk", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-06-11-1005570791": {"title": "McDonald's Data Breach Hits The Chain In Asia : NPR", "url": "https://www.npr.org/2021/06/11/1005570791/now-its-mcdonalds-turn-a-data-breach-hits-the-chain-in-asia", "author": "No author found", "published_date": "2021-06-11", "content": "", "section": "Technology", "disclaimer": ""}, "2021-06-11-1005304644": {"title": "Social Audio Began As A Pandemic Fad. Tech Companies See It As The Future : NPR", "url": "https://www.npr.org/2021/06/11/1005304644/social-audio-began-as-a-pandemic-fad-tech-companies-see-it-as-the-future", "author": "No author found", "published_date": "2021-06-11", "content": "MARY LOUISE KELLY, HOST:  During the pandemic, an app called Clubhouse took off. It let people join live audio chats from their smartphones. Soon, there were game shows and celebrity appearances and some people becoming audio stars. Now the big social media companies are jumping in. NPR's Shannon Bond has more on how Silicon Valley is hoping to turn a pandemic-era fad into a permanent boom. SHANNON BOND, BYLINE: Reesha Howard was an early adopter of live audio. Lately, she's gotten hooked on Twitter's version, called Spaces, where she was among the first users. REESHA HOWARD: They said they wanted it to feel like a dinner party. They wanted you to feel like you were hosting people in your living room. Well, that's my thing. I love to have people in my living room. I love for us to sit on the couch together with a glass of wine in our hands, and we just go at it for hours together, having a good time. BOND: Howard now regularly hosts Spaces on Twitter, including one called Viral Talk, where she interviews someone whose social media post has gone viral. The chats are alive and ephemeral. Once they're over, they're gone. (SOUNDBITE OF ARCHIVED RECORDING)HOWARD: So today, welcome to Twitter Spaces and Viral Talk. BOND: She's done Spaces with the rapper Soulja Boy, talking about a beef he was in with professional wrestlers. (SOUNDBITE OF ARCHIVED RECORDING)SOULJA BOY: Where the wrestlers at? Where the WWE at? We could talk - we could settle all this right now over the phone, over the Twitter Space. BOND: Howard says she wasn't even following Soulja Boy when she first asked him to chat live with her. HOWARD: So little old me, I slid into Soulja Boy's DMs, like, hey, come on Twitter Spaces with me. And he was like, sounds good. And I'm like, what? BOND: Had you ever talked to him before? HOWARD: No, never. BOND: In just a few months, Howard has gone from fewer than a hundred followers on Twitter to more than 5,000 and calls herself the Queen of Spaces. She's one of a slew of people making names for themselves in live audio, and tech companies are paying attention. Fidji Simo is head of the Facebook app. She says, for the world's biggest social network, audio is today what video was a few years ago. FIDJI SIMO: Audio is one of these formats that we think is going to become very much a core way in which people interact, the same way video has become one of these ways. BOND: Facebook, which is among NPR's financial supporters, is getting ready to launch a bunch of products, from short audio posts to sound effects to live chat rooms, similar to Clubhouse and Twitter Spaces. But there's another important piece of the puzzle - building tools for people like Reesha Howard to start making a living from audio. SIMO: For creators, we think of it as, like, something that needs to be able to turn into a business for them from the get-go. BOND: Whether it's Facebook, Twitter or Clubhouse, they all have a lot to gain from winning creators' loyalty. There's the time people spend on their apps listening to audio. And the companies could eventually take a cut of the revenue their audio stars generate. So the race to roll out ways for hosts to get paid is heating up. ESTHER CRAWFORD: I think for a long time, creators bore the burden of making money, and they had to do a lot of legwork in order to go get sponsors and advertisers. BOND: Esther Crawford at Twitter says that's a big shift. Now some companies are paying creators directly, letting listeners tip them, even looking at selling tickets for exclusive events. Twitter has already launched a tip jar for power users. CRAWFORD: This is a way for creators to be rewarded for their time and energy that they're putting into hosting these public conversations on Twitter. BOND: But even as audio becomes a feature on nearly any social network you can think of, there's a big question hanging over all of this as pandemic restrictions ease. JASON CITRON: People are obviously going to spend less time on these services, right? BOND: Jason Citron is CEO of messaging app Discord, which has had audio chat for years. CITRON: But I do think that people have formed new habits, and they've tried new things, and so we believe that at the end of a school day or the end of a workday, people are still going to come home, and their friends are still going to be on their Discord. BOND: So Discord is doubling down on audio, with live events and paid tickets - areas where it will have plenty of competition. Shannon Bond, NPR News. MARY LOUISE KELLY, HOST:   During the pandemic, an app called Clubhouse took off. It let people join live audio chats from their smartphones. Soon, there were game shows and celebrity appearances and some people becoming audio stars. Now the big social media companies are jumping in. NPR's Shannon Bond has more on how Silicon Valley is hoping to turn a pandemic-era fad into a permanent boom. SHANNON BOND, BYLINE: Reesha Howard was an early adopter of live audio. Lately, she's gotten hooked on Twitter's version, called Spaces, where she was among the first users. REESHA HOWARD: They said they wanted it to feel like a dinner party. They wanted you to feel like you were hosting people in your living room. Well, that's my thing. I love to have people in my living room. I love for us to sit on the couch together with a glass of wine in our hands, and we just go at it for hours together, having a good time. BOND: Howard now regularly hosts Spaces on Twitter, including one called Viral Talk, where she interviews someone whose social media post has gone viral. The chats are alive and ephemeral. Once they're over, they're gone. (SOUNDBITE OF ARCHIVED RECORDING) HOWARD: So today, welcome to Twitter Spaces and Viral Talk. BOND: She's done Spaces with the rapper Soulja Boy, talking about a beef he was in with professional wrestlers. (SOUNDBITE OF ARCHIVED RECORDING) SOULJA BOY: Where the wrestlers at? Where the WWE at? We could talk - we could settle all this right now over the phone, over the Twitter Space. BOND: Howard says she wasn't even following Soulja Boy when she first asked him to chat live with her. HOWARD: So little old me, I slid into Soulja Boy's DMs, like, hey, come on Twitter Spaces with me. And he was like, sounds good. And I'm like, what? BOND: Had you ever talked to him before? HOWARD: No, never. BOND: In just a few months, Howard has gone from fewer than a hundred followers on Twitter to more than 5,000 and calls herself the Queen of Spaces. She's one of a slew of people making names for themselves in live audio, and tech companies are paying attention. Fidji Simo is head of the Facebook app. She says, for the world's biggest social network, audio is today what video was a few years ago. FIDJI SIMO: Audio is one of these formats that we think is going to become very much a core way in which people interact, the same way video has become one of these ways. BOND: Facebook, which is among NPR's financial supporters, is getting ready to launch a bunch of products, from short audio posts to sound effects to live chat rooms, similar to Clubhouse and Twitter Spaces. But there's another important piece of the puzzle - building tools for people like Reesha Howard to start making a living from audio. SIMO: For creators, we think of it as, like, something that needs to be able to turn into a business for them from the get-go. BOND: Whether it's Facebook, Twitter or Clubhouse, they all have a lot to gain from winning creators' loyalty. There's the time people spend on their apps listening to audio. And the companies could eventually take a cut of the revenue their audio stars generate. So the race to roll out ways for hosts to get paid is heating up. ESTHER CRAWFORD: I think for a long time, creators bore the burden of making money, and they had to do a lot of legwork in order to go get sponsors and advertisers. BOND: Esther Crawford at Twitter says that's a big shift. Now some companies are paying creators directly, letting listeners tip them, even looking at selling tickets for exclusive events. Twitter has already launched a tip jar for power users. CRAWFORD: This is a way for creators to be rewarded for their time and energy that they're putting into hosting these public conversations on Twitter. BOND: But even as audio becomes a feature on nearly any social network you can think of, there's a big question hanging over all of this as pandemic restrictions ease. JASON CITRON: People are obviously going to spend less time on these services, right? BOND: Jason Citron is CEO of messaging app Discord, which has had audio chat for years. CITRON: But I do think that people have formed new habits, and they've tried new things, and so we believe that at the end of a school day or the end of a workday, people are still going to come home, and their friends are still going to be on their Discord. BOND: So Discord is doubling down on audio, with live events and paid tickets - areas where it will have plenty of competition. Shannon Bond, NPR News.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-06-11-1005419007": {"title": "Privacy Experts Ask: Should State-Issued IDs Be Stored On Our iPhones?  : NPR", "url": "https://www.npr.org/2021/06/11/1005419007/privacy-experts-ask-should-state-issued-ids-be-stored-on-our-iphones", "author": "No author found", "published_date": "2021-06-11", "content": "NOEL KING, HOST:  Do you, like me, lose your driver's license all the time? Apple says don't worry about your wallet. It's in your iPhone. Privacy advocates are alarmed by this feature. Here's NPR's Bobby Allyn. And before he starts, know that Apple is one of NPR's financial supporters. BOBBY ALLYN, BYLINE: People already pay for coffee and train rides using their iPhones. But Apple says why stop there? (SOUNDBITE OF VIDEO)JENNIFER BAILEY: To be fully free of your physical wallet, there's one more thing we need to bring to iPhone, and that's your ID. ALLYN: Apple executive Jennifer Bailey is speaking on a slick video, talking as she walks through the company's Cupertino headquarters. It was produced for Apple's annual developers conference. (SOUNDBITE OF VIDEO)BAILEY: This fall, you'll just scan your driver's license or state ID in participating U. S. states. It's that easy. Your ID information is now in Wallet. ALLYN: So now you can store a digital copy of your driver's license on your iPhone, and it'll be seen as legitimate proof of ID. Apple says soon you'll be able to flash it to a TSA agent at an airport and move faster through a security check. The company says it's all about making life easier for everyone. OK. But should state-issued IDs really be stored on our iPhones at all? A growing chorus of privacy experts and advocates don't think so. EVAN GREER: This just strikes me as the latest example of where they're kind of trying to weave themselves into more and more aspects of our lives. ALLYN: Evan Greer is the director of the advocacy group Fight for the Future. GREER: And when Apple becomes kind of indispensable, it truly is too big to fail. ALLYN: And it isn't just the critics of big tech raising concerns. Elizabeth Renieris is a fellow at Stanford who studies these type of ID systems. ELIZABETH RENIERIS: The more the kind of sleeker these credentials are, the more they're embedded into things that we're always, you know, attached to, like a mobile device, which we take everywhere, the more there's kind of this incentive to introduce identity requirements in contexts where it never existed before. ALLYN: Meaning every time we use the digital ID, we could be creating another way to be tracked. And Apple, she says, could eventually sell this data to advertisers. Apple, which touts its privacy-first philosophy, wouldn't comment on whether this would ever happen. But to Aram Sinnreich, this is yet another reason why Congress should pass a law restricting how tech companies can use our online data. He studies online privacy at American University in Washington. ARAM SINNREICH: If there is no regulation holding Apple accountable, then there's nothing stopping them from surveilling us and using them as an element of the broader marketing infrastructure. ALLYN: And though Apple has made assurances about how safe the IDs will be, Sinnreich says there is still risk involved in linking a sensitive document to our phones. SINNREICH: What happens when Apple messes up? What happens when there is a large security breach and 100 million people's information gets leaked? ALLYN: Apple is not worried. It says when it stores our IDs on our phones, they will be encrypted and therefore safe. Renieris says Apple does have a good history with security, but there is something it's not talking about when it comes to its digital ID. RENIERIS: They have staked their reputation on privacy, but I think they need to be more transparent about the business model about how they make money off of this. ALLYN: Also available in Apple's forthcoming operating system - the ability to open office, home and hotel doors with an iPhone. Will opening your door become a moneymaker for Apple? Renieris says they can find a way. Bobby Allyn, NPR News, San Francisco. (SOUNDBITE OF MARLEY CARROLL'S \"FIREFLIES\") NOEL KING, HOST:   Do you, like me, lose your driver's license all the time? Apple says don't worry about your wallet. It's in your iPhone. Privacy advocates are alarmed by this feature. Here's NPR's Bobby Allyn. And before he starts, know that Apple is one of NPR's financial supporters. BOBBY ALLYN, BYLINE: People already pay for coffee and train rides using their iPhones. But Apple says why stop there? (SOUNDBITE OF VIDEO) JENNIFER BAILEY: To be fully free of your physical wallet, there's one more thing we need to bring to iPhone, and that's your ID. ALLYN: Apple executive Jennifer Bailey is speaking on a slick video, talking as she walks through the company's Cupertino headquarters. It was produced for Apple's annual developers conference. (SOUNDBITE OF VIDEO) BAILEY: This fall, you'll just scan your driver's license or state ID in participating U. S. states. It's that easy. Your ID information is now in Wallet. ALLYN: So now you can store a digital copy of your driver's license on your iPhone, and it'll be seen as legitimate proof of ID. Apple says soon you'll be able to flash it to a TSA agent at an airport and move faster through a security check. The company says it's all about making life easier for everyone. OK. But should state-issued IDs really be stored on our iPhones at all? A growing chorus of privacy experts and advocates don't think so. EVAN GREER: This just strikes me as the latest example of where they're kind of trying to weave themselves into more and more aspects of our lives. ALLYN: Evan Greer is the director of the advocacy group Fight for the Future. GREER: And when Apple becomes kind of indispensable, it truly is too big to fail. ALLYN: And it isn't just the critics of big tech raising concerns. Elizabeth Renieris is a fellow at Stanford who studies these type of ID systems. ELIZABETH RENIERIS: The more the kind of sleeker these credentials are, the more they're embedded into things that we're always, you know, attached to, like a mobile device, which we take everywhere, the more there's kind of this incentive to introduce identity requirements in contexts where it never existed before. ALLYN: Meaning every time we use the digital ID, we could be creating another way to be tracked. And Apple, she says, could eventually sell this data to advertisers. Apple, which touts its privacy-first philosophy, wouldn't comment on whether this would ever happen. But to Aram Sinnreich, this is yet another reason why Congress should pass a law restricting how tech companies can use our online data. He studies online privacy at American University in Washington. ARAM SINNREICH: If there is no regulation holding Apple accountable, then there's nothing stopping them from surveilling us and using them as an element of the broader marketing infrastructure. ALLYN: And though Apple has made assurances about how safe the IDs will be, Sinnreich says there is still risk involved in linking a sensitive document to our phones. SINNREICH: What happens when Apple messes up? What happens when there is a large security breach and 100 million people's information gets leaked? ALLYN: Apple is not worried. It says when it stores our IDs on our phones, they will be encrypted and therefore safe. Renieris says Apple does have a good history with security, but there is something it's not talking about when it comes to its digital ID. RENIERIS: They have staked their reputation on privacy, but I think they need to be more transparent about the business model about how they make money off of this. ALLYN: Also available in Apple's forthcoming operating system - the ability to open office, home and hotel doors with an iPhone. Will opening your door become a moneymaker for Apple? Renieris says they can find a way. Bobby Allyn, NPR News, San Francisco. (SOUNDBITE OF MARLEY CARROLL'S \"FIREFLIES\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-06-11-1005231250": {"title": "El Salvador Will Use Volcanic Energy To Mine Bitcoin : NPR", "url": "https://www.npr.org/2021/06/11/1005231250/el-salvador-plans-to-use-electricity-generated-from-volcanoes-to-mine-bitcoin", "author": "No author found", "published_date": "2021-06-11", "content": "", "section": "Energy", "disclaimer": ""}, "2021-06-12-1005908618": {"title": "Blue Origin Auction Winner Pays $28 Million For Space Flight : NPR", "url": "https://www.npr.org/2021/06/12/1005908618/jeff-bezos-blue-origin-space-auction-winner-28-million", "author": "No author found", "published_date": "2021-06-12", "content": "", "section": "Space", "disclaimer": ""}, "2021-06-12-1005690930": {"title": "DNA Evidence Just Solved One Of The Oldest Cold Cases Ever : NPR", "url": "https://www.npr.org/2021/06/12/1005690930/detectives-just-used-dna-to-solve-a-1956-double-homicide-they-may-have-made-hist", "author": "No author found", "published_date": "2021-06-12", "content": "", "section": "National", "disclaimer": ""}, "2021-06-12-1005624457": {"title": "Apple iPhones Can Soon Hold Your ID. Privacy Experts Are On Edge : NPR", "url": "https://www.npr.org/2021/06/12/1005624457/apple-iphones-can-soon-hold-your-id-privacy-experts-are-on-edge", "author": "No author found", "published_date": "2021-06-12", "content": "", "section": "Technology", "disclaimer": ""}, "2021-06-14-1005105667": {"title": "For Some Offices, The Return-To-Work Plan Embraces The Past : NPR", "url": "https://www.npr.org/2021/06/14/1005105667/its-personal-zoomd-out-workplace-ready-for-face-to-face-conversations-to-return", "author": "No author found", "published_date": "2021-06-14", "content": "STEVE INSKEEP, HOST:  People in many workplaces, including this one, are deciding what normal looks like as the pandemic eases. What did people really lose by working from home? Did some people gain? Should we all come back? These are especially pressing questions at one workplace, where face-to-face interactions are considered essential to people's best work. NPR's Andrea Hsu takes us there. ANDREA HSU, BYLINE: Vivek Jayaraman remembers the day he came back to his office in Ashburn, Va. VIVEK JAYARAMAN: I got a rush of just walking around the building. I didn't - there weren't even many people in the building at that point. HSU: Jayaraman is a neuroscientist at the Janelia Research Campus. It's part of the Howard Hughes Medical Institute. He studies the brains of fruit flies, how those brains help flies navigate their world. JAYARAMAN: I mean, there's a lot going on there. It's just very compressed. It's a miniaturized marvel is what it is. HSU: He's worked here for 15 years, and he's steeped in the ethos of this place, believing that it's not just collaboration but spontaneous creative collisions that lead to great discoveries. JAYARAMAN: This building - it's been socially engineered so that you do have those kinds of collisions. There's, like, one space where there's and coffee. It's deliberate. HSU: That's right. You're not supposed to have a coffee maker in your lab. The idea is you walk the halls. You run into someone you didn't plan to see. You start chatting. An idea gets sparked. You follow up, maybe at night when the coffee station turns into a pub. The pandemic shut all of that down. JAYARAMAN: The spontaneity is just gone. All you have now are these Zoom meetings. HSU: Where there's a set agenda, and everyone has to take turns. Jayaraman says some work did go on, but there were lab experiments that didn't happen. And who knows what ideas didn't get sparked when conversations moved online? JAYARAMAN: There's absolutely something lost in that process. And so I'd say that it's definitely held us back in terms of moving the science forward. HSU: Now, before the pandemic, there'd be maybe 750 people here on any given day. Now it's fewer than half that. And most seem to be tucked away in their offices. You don't see a lot of people wandering the halls. COVID safety protocols are still very much in force. Everyone's wearing masks and keeping their distance, especially in the cafeteria. RON VALE: You know, maybe I'll get that warm eggplant ragout sandwich, please. HSU: That's Ron Vale, the executive director of Janelia, ordering from a safe 8 or 10 feet away. Before the pandemic, he says, lunch was only served from 11:30 to 1. VALE: We wanted people, actually, to have lunch togetherHSU: And by together, he means at big, round tables that seat eight, like at a wedding. VALE: So we were encouraging, like, high-density interactions then, exactly the opposite of what we're doing now. HSU: There is only one chair at each table now, but they have been thinking hard about how to get people face-to-face again. Outside, they put up a tent and created some cozy seating areas. VALE: They're little fire pits with four chairs around them. HSU: And they're doing COVID testing twice a week for those who come on site. Vale says the plan is to bring everyone back to campus full time in late September. By then, they'll also require vaccinations. He does hope to hang on to some of the good things that have come out of the pandemic, for instance, the virtual conferences that were more accessible to scientists from smaller institutions and farther-flung places. They'll keep those going even when in-person conferences resume. VALE: And I think that will be a positive. HSU: Virginia Rutten and points out another positive. She's a graduate research fellow studying zebrafish. This past year, she's been able to ask questions of all kinds of folks who are normally kind of hard to reach. VIRGINIA RUTTEN: You just feel that everybody is a little bit more relaxed, has the time to explain the actual thing to you. And that's been really valuable and a real treat. HSU: And the kind of thing that's worth preserving. Andrea Hsu, NPR News. (SOUNDBITE OF LANTERNA'S \"BROOKLYN\") STEVE INSKEEP, HOST:   People in many workplaces, including this one, are deciding what normal looks like as the pandemic eases. What did people really lose by working from home? Did some people gain? Should we all come back? These are especially pressing questions at one workplace, where face-to-face interactions are considered essential to people's best work. NPR's Andrea Hsu takes us there. ANDREA HSU, BYLINE: Vivek Jayaraman remembers the day he came back to his office in Ashburn, Va. VIVEK JAYARAMAN: I got a rush of just walking around the building. I didn't - there weren't even many people in the building at that point. HSU: Jayaraman is a neuroscientist at the Janelia Research Campus. It's part of the Howard Hughes Medical Institute. He studies the brains of fruit flies, how those brains help flies navigate their world. JAYARAMAN: I mean, there's a lot going on there. It's just very compressed. It's a miniaturized marvel is what it is. HSU: He's worked here for 15 years, and he's steeped in the ethos of this place, believing that it's not just collaboration but spontaneous creative collisions that lead to great discoveries. JAYARAMAN: This building - it's been socially engineered so that you do have those kinds of collisions. There's, like, one space where there's and coffee. It's deliberate. HSU: That's right. You're not supposed to have a coffee maker in your lab. The idea is you walk the halls. You run into someone you didn't plan to see. You start chatting. An idea gets sparked. You follow up, maybe at night when the coffee station turns into a pub. The pandemic shut all of that down. JAYARAMAN: The spontaneity is just gone. All you have now are these Zoom meetings. HSU: Where there's a set agenda, and everyone has to take turns. Jayaraman says some work did go on, but there were lab experiments that didn't happen. And who knows what ideas didn't get sparked when conversations moved online? JAYARAMAN: There's absolutely something lost in that process. And so I'd say that it's definitely held us back in terms of moving the science forward. HSU: Now, before the pandemic, there'd be maybe 750 people here on any given day. Now it's fewer than half that. And most seem to be tucked away in their offices. You don't see a lot of people wandering the halls. COVID safety protocols are still very much in force. Everyone's wearing masks and keeping their distance, especially in the cafeteria. RON VALE: You know, maybe I'll get that warm eggplant ragout sandwich, please. HSU: That's Ron Vale, the executive director of Janelia, ordering from a safe 8 or 10 feet away. Before the pandemic, he says, lunch was only served from 11:30 to 1. VALE: We wanted people, actually, to have lunch together HSU: And by together, he means at big, round tables that seat eight, like at a wedding. VALE: So we were encouraging, like, high-density interactions then, exactly the opposite of what we're doing now. HSU: There is only one chair at each table now, but they have been thinking hard about how to get people face-to-face again. Outside, they put up a tent and created some cozy seating areas. VALE: They're little fire pits with four chairs around them. HSU: And they're doing COVID testing twice a week for those who come on site. Vale says the plan is to bring everyone back to campus full time in late September. By then, they'll also require vaccinations. He does hope to hang on to some of the good things that have come out of the pandemic, for instance, the virtual conferences that were more accessible to scientists from smaller institutions and farther-flung places. They'll keep those going even when in-person conferences resume. VALE: And I think that will be a positive. HSU: Virginia Rutten and points out another positive. She's a graduate research fellow studying zebrafish. This past year, she's been able to ask questions of all kinds of folks who are normally kind of hard to reach. VIRGINIA RUTTEN: You just feel that everybody is a little bit more relaxed, has the time to explain the actual thing to you. And that's been really valuable and a real treat. HSU: And the kind of thing that's worth preserving. Andrea Hsu, NPR News. (SOUNDBITE OF LANTERNA'S \"BROOKLYN\")", "section": "The Coronavirus Crisis", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-06-14-1006126724": {"title": "Alabama Hyundai Plant Halts Production Due To Car Ship Shortage : NPR", "url": "https://www.npr.org/2021/06/14/1006126724/hyundai-plant-in-alabama-pauses-manufacturing-due-to-car-chip-shortage", "author": "No author found", "published_date": "2021-06-14", "content": "", "section": "Business", "disclaimer": ""}, "2021-06-15-1006810293": {"title": "Why Geneva Is Teeming With Spies As Biden And Putin Prepare To Meet : NPR", "url": "https://www.npr.org/2021/06/15/1006810293/why-geneva-is-teeming-with-spies-as-biden-and-putin-prepare-to-meet", "author": "No author found", "published_date": "2021-06-15", "content": "MARY LOUISE KELLY, HOST:  At this precise moment outside Russia's Permanent Mission to the U. N. here in Geneva, there's a big steel fence, giant shrubs blocking the view. I'm counting one, two, three, four, five uniformed security guards keeping an eye on us. We can't see who's coming and going from behind these big gates - diplomats. You also have to wonder about spies, if this is like many diplomatic outposts around the world, which prompted us to wonder - are intelligence officers out in full force here in the city as the American and Russian delegations hit town? Well, we decided to make a phone call to Daniel Hoffman, former CIA station chief - served five years in Moscow, here to talk about what espionage efforts may or may not be underway. Hey there. DANIEL HOFFMAN: Hey, good to be on the program. KELLY: So let's fact-check what I just said. Is it safe to say the SVR - that is Russia's foreign intelligence service - that they are here in force? HOFFMAN: Oh, yeah. They're there in force, as are lots of other intelligence services, just seeking to gain as much information as they can on this summit. It's not just the United States and Russia. There are many countries watching very, very closely what might be happening in Geneva. China would be certainly high on that list as well. KELLY: It is safe to say American spies are here in force, too. HOFFMAN: Yeah, sure. Absolutely. And this is a time, you know, before the summit when not just the State Department, but the intelligence community and the Department of Defense really kick into high gear. We have a dizzying array of issues where our interests and Russia's collide. And most every single one of them has a component related to intelligence collection. And so President Biden, I'm sure, has asked the intelligence community to weigh in on all of these issues so he could be as prepared as possible when he meets with Vladimir Putin. KELLY: You're speaking as someone who's supported a number of big U. S. summits in past. What are the intelligence officers here trying to learn? HOFFMAN: Well, I think the goal is to learn Vladimir Putin's talking points. That would be a high priority. For example, Vladimir Putin is holding U. S. citizens - Trevor Reed, Paul Whelan. What might Vladimir Putin be interested in leveraging? What might he want in return for releasing those American citizens being held hostage? What are Vladimir Putin's talking points on the Havana syndrome, which we highly suspect Russia is responsible for? And then all of the other issues where we are in absolute confrontation, like Russia's use of banned chemical weapons against their own citizens and Sergei Skripal in the U. K. and the ransomware attacks in the United States - the Kremlin is, at the very least, allowing cyberhacking groups to homestead on their territory. Does Vladimir Putin know that they're mounting attacks against the United States? Is the Kremlin ordering them? Those would be some of the questions, I think, that President Biden would be asking of the intelligence community. KELLY: Yeah. How do you rate the chances of hotel rooms here in Geneva, meeting rooms at the summit being bugged? HOFFMAN: Well, all I can tell you is that I always assumed that hotel rooms had listening devices in them. Whether they did or they didn't is something that we may never know. But I think that it's something that all leaders, whether the Russian side or our side, have to factor into their planning. KELLY: Last question - does a summit like this also represent a recruitment opportunity? HOFFMAN: It's very clear - the United States and Russia - that the relationship is extraordinarily complicated and confrontational, and that always presents opportunities for the United States to mount recruitment operations. And it's also high on our list of priorities, frankly, because what happens in Russia is behind, you know, maybe not necessarily always an iron curtain anymore, but a cyber curtain. We need to determine exactly what cloak-and-dagger espionage operations the KGB operative and the Kremlin, Vladimir Putin, is planning against us so we can detect them and then preempt them before they're visited on our shores. We failed to do that with SolarWinds and DarkSide among other things, including election interference. And so it puts a premium on our intelligence services to mount, really, a full-court press. And on the other side, Russians who might be thinking about working for the United States understand the value to the United States of this protected information. KELLY: That is former CIA Station Chief Daniel Hoffman. Thank you so much. HOFFMAN: My pleasure. MARY LOUISE KELLY, HOST:   At this precise moment outside Russia's Permanent Mission to the U. N. here in Geneva, there's a big steel fence, giant shrubs blocking the view. I'm counting one, two, three, four, five uniformed security guards keeping an eye on us. We can't see who's coming and going from behind these big gates - diplomats. You also have to wonder about spies, if this is like many diplomatic outposts around the world, which prompted us to wonder - are intelligence officers out in full force here in the city as the American and Russian delegations hit town? Well, we decided to make a phone call to Daniel Hoffman, former CIA station chief - served five years in Moscow, here to talk about what espionage efforts may or may not be underway. Hey there. DANIEL HOFFMAN: Hey, good to be on the program. KELLY: So let's fact-check what I just said. Is it safe to say the SVR - that is Russia's foreign intelligence service - that they are here in force? HOFFMAN: Oh, yeah. They're there in force, as are lots of other intelligence services, just seeking to gain as much information as they can on this summit. It's not just the United States and Russia. There are many countries watching very, very closely what might be happening in Geneva. China would be certainly high on that list as well. KELLY: It is safe to say American spies are here in force, too. HOFFMAN: Yeah, sure. Absolutely. And this is a time, you know, before the summit when not just the State Department, but the intelligence community and the Department of Defense really kick into high gear. We have a dizzying array of issues where our interests and Russia's collide. And most every single one of them has a component related to intelligence collection. And so President Biden, I'm sure, has asked the intelligence community to weigh in on all of these issues so he could be as prepared as possible when he meets with Vladimir Putin. KELLY: You're speaking as someone who's supported a number of big U. S. summits in past. What are the intelligence officers here trying to learn? HOFFMAN: Well, I think the goal is to learn Vladimir Putin's talking points. That would be a high priority. For example, Vladimir Putin is holding U. S. citizens - Trevor Reed, Paul Whelan. What might Vladimir Putin be interested in leveraging? What might he want in return for releasing those American citizens being held hostage? What are Vladimir Putin's talking points on the Havana syndrome, which we highly suspect Russia is responsible for? And then all of the other issues where we are in absolute confrontation, like Russia's use of banned chemical weapons against their own citizens and Sergei Skripal in the U. K. and the ransomware attacks in the United States - the Kremlin is, at the very least, allowing cyberhacking groups to homestead on their territory. Does Vladimir Putin know that they're mounting attacks against the United States? Is the Kremlin ordering them? Those would be some of the questions, I think, that President Biden would be asking of the intelligence community. KELLY: Yeah. How do you rate the chances of hotel rooms here in Geneva, meeting rooms at the summit being bugged? HOFFMAN: Well, all I can tell you is that I always assumed that hotel rooms had listening devices in them. Whether they did or they didn't is something that we may never know. But I think that it's something that all leaders, whether the Russian side or our side, have to factor into their planning. KELLY: Last question - does a summit like this also represent a recruitment opportunity? HOFFMAN: It's very clear - the United States and Russia - that the relationship is extraordinarily complicated and confrontational, and that always presents opportunities for the United States to mount recruitment operations. And it's also high on our list of priorities, frankly, because what happens in Russia is behind, you know, maybe not necessarily always an iron curtain anymore, but a cyber curtain. We need to determine exactly what cloak-and-dagger espionage operations the KGB operative and the Kremlin, Vladimir Putin, is planning against us so we can detect them and then preempt them before they're visited on our shores. We failed to do that with SolarWinds and DarkSide among other things, including election interference. And so it puts a premium on our intelligence services to mount, really, a full-court press. And on the other side, Russians who might be thinking about working for the United States understand the value to the United States of this protected information. KELLY: That is former CIA Station Chief Daniel Hoffman. Thank you so much. HOFFMAN: My pleasure.", "section": "National Security", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-06-15-1006807299": {"title": "Lina Khan, Prominent Big Tech Critic, Will Lead The FTC  : NPR", "url": "https://www.npr.org/2021/06/15/1006807299/lina-khan-prominent-big-tech-critic-will-lead-the-ftc", "author": "No author found", "published_date": "2021-06-15", "content": "LEILA FADEL, HOST:  Big Tech has a new top regulator in Washington. And it's one of the industry's fiercest critics. President Biden, on Tuesday, named Lina Khan chairwoman of the Federal Trade Commission shortly after her Senate confirmation. The announcement has put Silicon Valley on edge. More from NPR's Bobby Allyn. BOBBY ALLYN, BYLINE: Not long ago, 32-year-old Lina Khan was an obscure academic. In 2017, while still a student at Yale Law School, she wrote a paper about Amazon that quickly changed that. Khan said, Amazon's practices are predatory and that the company got so big because U. S. competition laws are broken. Some called that view hipster antitrust. BILL KOVACIC: She challenged an orthodoxy with others, built a new community that has changed the debate. ALLYN: That's Bill Kovacic. He's the former chair of the FTC. He says having someone like Khan ready to review Silicon Valley's mergers, privacy practices and control of markets is not good news for Big Tech. KOVACIC: They never saw this coming. I would guess that the level of anxiety within that community increased dramatically over the last 24 hours. ALLYN: Tech industry lobbyists say Khan will be bad for innovation and consumers. Khan is forging ahead. At her April confirmation hearing, she pointed to one area of interest, Big Tech's reliance on our data. (SOUNDBITE OF ARCHIVED RECORDING)LINA KHAN: I worry that, in some cases, some of these companies may think it's just worth the cost of business to actually violate privacy laws. ALLYN: Kovacic says the biggest hurdle for Khan's agenda may be surviving challenges in the courts. Bobby Allyn, NPR News, San Francisco. (SOUNDBITE OF OMER KLEIN'S \"SLEEPWALKERS\") LEILA FADEL, HOST:   Big Tech has a new top regulator in Washington. And it's one of the industry's fiercest critics. President Biden, on Tuesday, named Lina Khan chairwoman of the Federal Trade Commission shortly after her Senate confirmation. The announcement has put Silicon Valley on edge. More from NPR's Bobby Allyn. BOBBY ALLYN, BYLINE: Not long ago, 32-year-old Lina Khan was an obscure academic. In 2017, while still a student at Yale Law School, she wrote a paper about Amazon that quickly changed that. Khan said, Amazon's practices are predatory and that the company got so big because U. S. competition laws are broken. Some called that view hipster antitrust. BILL KOVACIC: She challenged an orthodoxy with others, built a new community that has changed the debate. ALLYN: That's Bill Kovacic. He's the former chair of the FTC. He says having someone like Khan ready to review Silicon Valley's mergers, privacy practices and control of markets is not good news for Big Tech. KOVACIC: They never saw this coming. I would guess that the level of anxiety within that community increased dramatically over the last 24 hours. ALLYN: Tech industry lobbyists say Khan will be bad for innovation and consumers. Khan is forging ahead. At her April confirmation hearing, she pointed to one area of interest, Big Tech's reliance on our data. (SOUNDBITE OF ARCHIVED RECORDING) LINA KHAN: I worry that, in some cases, some of these companies may think it's just worth the cost of business to actually violate privacy laws. ALLYN: Kovacic says the biggest hurdle for Khan's agenda may be surviving challenges in the courts. Bobby Allyn, NPR News, San Francisco. (SOUNDBITE OF OMER KLEIN'S \"SLEEPWALKERS\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-06-16-1007137982": {"title": "A New Peloton Problem: Hackers Can Access Personal Data : NPR", "url": "https://www.npr.org/2021/06/16/1007137982/your-pricey-peloton-has-another-problem-for-you-to-sweat-over", "author": "No author found", "published_date": "2021-06-16", "content": "", "section": "Business", "disclaimer": ""}, "2021-06-16-1007104038": {"title": "2021 E3 Expo Reveals 'Tiny Tina's Wonderlands,' 'Elden Ring,' 'Zelda,' 'Metroid' : NPR", "url": "https://www.npr.org/2021/06/16/1007104038/e3-expo-2021-video-game-elden-ring-tiny-tinas-wonderlands-zelda-metroid", "author": "No author found", "published_date": "2021-06-16", "content": "", "section": "Gaming", "disclaimer": ""}, "2021-06-17-1007632156": {"title": "How Russian Hackers Have Built A Slick Ransomware Business Model : NPR", "url": "https://www.npr.org/2021/06/17/1007632156/biden-tells-putin-to-crackdown-on-ransomware-what-are-the-odds-he-will", "author": "No author found", "published_date": "2021-06-17", "content": "AUDIE CORNISH, HOST:  President Biden called for a crackdown on cyberattacks at his summit yesterday with Vladimir Putin, but the Russian leader has shown little interest in combating an emerging criminal industry in his country that's called ransomware as a service. You can think of it as an ecosystem comprised of small groups of hackers with a range of specialized skills who find each other in the dark corners of the internet. NPR's Greg Myre breaks it down for us. GREG MYRE, BYLINE: If you want to extort millions of dollars from a large U. S. company, you can't do it alone. It takes a village, a village of hackers with advanced computer skills who hang out on the dark web and most likely live in Russia. DMITRI ALPEROVITCH: Ransomware has become a huge business. And as any business, in order to scale it, they're coming up with innovative models. MYRE: Dmitri Alperovitch is head of the technology group Silverado Policy Accelerator. He says this model is ransomware as a service and includes three key players. The top tier is made up of small gangs. They make the sophisticated malware that locks up the computer systems that targeted companies. He estimates a dozen or so of these groups are doing this on a large scale. The best-known include DarkSide, blamed for the attack on Colonial Pipeline, and REvil, accused in the hack of the meat supplier JBS. But he adds. . . ALPEROVITCH: The people that are building the software are not actually the ones, most of the time, that are going to use it. They're going to recruit others. MYRE: Wendi Whitmore of the cybersecurity firm Palo Alto Networks says these malware-makers figured out it's more lucrative to disseminate their crippling software more widely through a second key group known as affiliates. WENDI WHITMORE: What they're doing is outsourcing parts of the supply chain, essentially, and then giving these organizations that they work with a cut of the profits. MYRE: The affiliates do much of the actual work. They launch the malware attack, demand the ransom, negotiate with the victim company and collect the money - almost always in a cryptocurrency like Bitcoin. As a result, the affiliates usually keep most of the money - often 75% or more. Still, the affiliates can't unleash these strikes unless they first gain access to a company's computer network. This brings us to the third key group - the old-fashioned hackers or access brokers who find a way in. If you need these guys, you'll find them on the dark web. ADAM MEYERS: You go into the underground forums and there's this whole category of threat actor we call an access broker. MYRE: Adam Meyers is with the cybersecurity company CrowdStrike. MEYERS: And what they do all day is hack into different businesses. And then they advertise that access. You want into company X? It's $4,000. MYRE: A small price to pay if that access leads to a multimillion-dollar ransom - of course, all these relationships require a lot of trust among criminals hiding behind online pseudonyms. ALPEROVITCH: How do you trust someone who is fundamentally untrustworthy, who is fundamentally a thief? MYRE: Again, Dmitri Alperovitch. ALPEROVITCH: It's very difficult to get into these criminal forms. You kind of have to prove that you're a criminal by committing some act of cybercrime and validate that you're not law enforcement. That's been a huge problem for them in the past. MYRE: At Wednesday's summit between Biden and Putin in Geneva, the American president said he would respond if the U. S. continues to be hit, especially in a critical industry like energy supplies or the water system. (SOUNDBITE OF ARCHIVED RECORDING)PRESIDENT JOE BIDEN: Responsible countries need to take action against criminals who conduct ransomware activities on their territory. MYRE: Putin could tell the Russian hackers to cut it out, says Alperovitch. ALPEROVITCH: They're not part of his inner circle. They're not, you know, generating any significant revenue for the Russian state. So this is the one issue that, if pressed on, Putin can actually give on. MYRE: So will he? Biden says he expects the answer to be clear within a few months. Greg Myre, NPR News. (SOUNDBITE OF THE FLAMING LIPS SONG, \"ARE YOU A HYPNOTIST? ? \") AUDIE CORNISH, HOST:   President Biden called for a crackdown on cyberattacks at his summit yesterday with Vladimir Putin, but the Russian leader has shown little interest in combating an emerging criminal industry in his country that's called ransomware as a service. You can think of it as an ecosystem comprised of small groups of hackers with a range of specialized skills who find each other in the dark corners of the internet. NPR's Greg Myre breaks it down for us. GREG MYRE, BYLINE: If you want to extort millions of dollars from a large U. S. company, you can't do it alone. It takes a village, a village of hackers with advanced computer skills who hang out on the dark web and most likely live in Russia. DMITRI ALPEROVITCH: Ransomware has become a huge business. And as any business, in order to scale it, they're coming up with innovative models. MYRE: Dmitri Alperovitch is head of the technology group Silverado Policy Accelerator. He says this model is ransomware as a service and includes three key players. The top tier is made up of small gangs. They make the sophisticated malware that locks up the computer systems that targeted companies. He estimates a dozen or so of these groups are doing this on a large scale. The best-known include DarkSide, blamed for the attack on Colonial Pipeline, and REvil, accused in the hack of the meat supplier JBS. But he adds. . . ALPEROVITCH: The people that are building the software are not actually the ones, most of the time, that are going to use it. They're going to recruit others. MYRE: Wendi Whitmore of the cybersecurity firm Palo Alto Networks says these malware-makers figured out it's more lucrative to disseminate their crippling software more widely through a second key group known as affiliates. WENDI WHITMORE: What they're doing is outsourcing parts of the supply chain, essentially, and then giving these organizations that they work with a cut of the profits. MYRE: The affiliates do much of the actual work. They launch the malware attack, demand the ransom, negotiate with the victim company and collect the money - almost always in a cryptocurrency like Bitcoin. As a result, the affiliates usually keep most of the money - often 75% or more. Still, the affiliates can't unleash these strikes unless they first gain access to a company's computer network. This brings us to the third key group - the old-fashioned hackers or access brokers who find a way in. If you need these guys, you'll find them on the dark web. ADAM MEYERS: You go into the underground forums and there's this whole category of threat actor we call an access broker. MYRE: Adam Meyers is with the cybersecurity company CrowdStrike. MEYERS: And what they do all day is hack into different businesses. And then they advertise that access. You want into company X? It's $4,000. MYRE: A small price to pay if that access leads to a multimillion-dollar ransom - of course, all these relationships require a lot of trust among criminals hiding behind online pseudonyms. ALPEROVITCH: How do you trust someone who is fundamentally untrustworthy, who is fundamentally a thief? MYRE: Again, Dmitri Alperovitch. ALPEROVITCH: It's very difficult to get into these criminal forms. You kind of have to prove that you're a criminal by committing some act of cybercrime and validate that you're not law enforcement. That's been a huge problem for them in the past. MYRE: At Wednesday's summit between Biden and Putin in Geneva, the American president said he would respond if the U. S. continues to be hit, especially in a critical industry like energy supplies or the water system. (SOUNDBITE OF ARCHIVED RECORDING) PRESIDENT JOE BIDEN: Responsible countries need to take action against criminals who conduct ransomware activities on their territory. MYRE: Putin could tell the Russian hackers to cut it out, says Alperovitch. ALPEROVITCH: They're not part of his inner circle. They're not, you know, generating any significant revenue for the Russian state. So this is the one issue that, if pressed on, Putin can actually give on. MYRE: So will he? Biden says he expects the answer to be clear within a few months. Greg Myre, NPR News. (SOUNDBITE OF THE FLAMING LIPS SONG, \"ARE YOU A HYPNOTIST? ? \")", "section": "National Security", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-06-17-1007106908": {"title": "Europe Is Launching A Satellite Made of Plywood Into Space : NPR", "url": "https://www.npr.org/2021/06/17/1007106908/plywood-satellite-wood-woodsat-european-space-agency-esa", "author": "No author found", "published_date": "2021-06-17", "content": "", "section": "Space", "disclaimer": ""}, "2021-06-17-1007385955": {"title": "Snapchat Ends 'Speed Filter' That Critics Say Encouraged Reckless Driving : NPR", "url": "https://www.npr.org/2021/06/17/1007385955/snapchat-ends-speed-filter-that-critics-say-encouraged-reckless-driving", "author": "No author found", "published_date": "2021-06-17", "content": "ARI SHAPIRO, HOST:  The messaging app Snapchat has been linked to deadly car crashes. The reason is a feature called the speed filter, which tracks your speed as you drive. Snap, the company that makes the app, has faced lawsuits over the filter, and it now says it's dropping the feature. NPR technology reporter Bobby Allyn broke this news. Hi, Bobby. BOBBY ALLYN, BYLINE: Hey. SHAPIRO: Tell us more about how this filter works and why people use it. ALLYN: Yeah. So many know Snapchat as the app, of course, that lets you chat with your friends in these fun, disappearing messages. And Snapchat has features in the photo sharing area where you could, you know, put on an animated pair of sunglasses when you're taking a selfie or capture how fast you're driving using your smartphone's GPS. But here's the problem with that, Ari. Some people turned the speed filter into a game by challenging each other to try to go more than a hundred miles per hour. And in cases from Pennsylvania to Wisconsin to Florida, young drivers got into deadly car crashes while someone in the car was using this speed filter. SHAPIRO: And now the company says it's dropping the feature completely. Do they say this is in response to the fatal crashes you're talking about? ALLYN: Yeah. So the company made no reference to the crashes when it told me it's scrapping it. Instead, the company said, quote, \"it's barely used by Snapchatters,\" suggesting there that, you know, it was dropped because it's unpopular. Snap has known about this problem, though, since, you know, at least 2015. And to discourage teens from using the filter to speed, Snap did make some changes. It posted a warning on the feature telling people not to snap and drive. And the company made it impossible to share a speed of over 35 miles per hour. It called that driving speed, and it made it, you know, impossible to share speeds with your friends over that limit. But now Snap says its feature will be gone for good. And Joel Feldman, who runs the End Distracted Driving nonprofit, says it's about time. JOEL FELDMAN: Lives will be saved. Crashes will be prevented. The lawyer in me says, my God, why did it take them so long? ALLYN: And, Ari, that's a good question. We don't know why it has taken so long. The company has never directly answered that. In their legal filings, Snapchat has said it fears a slippery slope, that if it removes one feature that's misused, where does it end? Might they start getting sued and pressured to drop other features that people misuse? SHAPIRO: So you talk about these lawsuits. What happens to them now that the feature is gone? ALLYN: Yeah. In recent years, at least 11 people have died in car crashes where the speed filter was suspected to have played a role. One of these cases involves the Wisconsin parents of two teen boys and a 20-year-old young man who all died in 2017 after their car lost control, and they crashed into a tree while one of them was using the speed filter. I talked to Mike Neff. He's a lawyer representing the family in this case, and he said Snap dropping the feature won't change the status of the lawsuits. MIKE NEFF: All it does is eliminate an unnecessary risk for people on the roads today and tomorrow. What happened to the families whose lives have been forever changed is not mitigated or lessened because Snapchat made this choice. ALLYN: Yeah. In response, Snapchat said the Wisconsin case is devastating and, quote, \"nothing is more important than the safety of our Snapchat community. \"SHAPIRO: That's NPR's Bobby Allyn. Thank you. ALLYN: Thanks, Ari. ARI SHAPIRO, HOST:   The messaging app Snapchat has been linked to deadly car crashes. The reason is a feature called the speed filter, which tracks your speed as you drive. Snap, the company that makes the app, has faced lawsuits over the filter, and it now says it's dropping the feature. NPR technology reporter Bobby Allyn broke this news. Hi, Bobby. BOBBY ALLYN, BYLINE: Hey. SHAPIRO: Tell us more about how this filter works and why people use it. ALLYN: Yeah. So many know Snapchat as the app, of course, that lets you chat with your friends in these fun, disappearing messages. And Snapchat has features in the photo sharing area where you could, you know, put on an animated pair of sunglasses when you're taking a selfie or capture how fast you're driving using your smartphone's GPS. But here's the problem with that, Ari. Some people turned the speed filter into a game by challenging each other to try to go more than a hundred miles per hour. And in cases from Pennsylvania to Wisconsin to Florida, young drivers got into deadly car crashes while someone in the car was using this speed filter. SHAPIRO: And now the company says it's dropping the feature completely. Do they say this is in response to the fatal crashes you're talking about? ALLYN: Yeah. So the company made no reference to the crashes when it told me it's scrapping it. Instead, the company said, quote, \"it's barely used by Snapchatters,\" suggesting there that, you know, it was dropped because it's unpopular. Snap has known about this problem, though, since, you know, at least 2015. And to discourage teens from using the filter to speed, Snap did make some changes. It posted a warning on the feature telling people not to snap and drive. And the company made it impossible to share a speed of over 35 miles per hour. It called that driving speed, and it made it, you know, impossible to share speeds with your friends over that limit. But now Snap says its feature will be gone for good. And Joel Feldman, who runs the End Distracted Driving nonprofit, says it's about time. JOEL FELDMAN: Lives will be saved. Crashes will be prevented. The lawyer in me says, my God, why did it take them so long? ALLYN: And, Ari, that's a good question. We don't know why it has taken so long. The company has never directly answered that. In their legal filings, Snapchat has said it fears a slippery slope, that if it removes one feature that's misused, where does it end? Might they start getting sued and pressured to drop other features that people misuse? SHAPIRO: So you talk about these lawsuits. What happens to them now that the feature is gone? ALLYN: Yeah. In recent years, at least 11 people have died in car crashes where the speed filter was suspected to have played a role. One of these cases involves the Wisconsin parents of two teen boys and a 20-year-old young man who all died in 2017 after their car lost control, and they crashed into a tree while one of them was using the speed filter. I talked to Mike Neff. He's a lawyer representing the family in this case, and he said Snap dropping the feature won't change the status of the lawsuits. MIKE NEFF: All it does is eliminate an unnecessary risk for people on the roads today and tomorrow. What happened to the families whose lives have been forever changed is not mitigated or lessened because Snapchat made this choice. ALLYN: Yeah. In response, Snapchat said the Wisconsin case is devastating and, quote, \"nothing is more important than the safety of our Snapchat community. \" SHAPIRO: That's NPR's Bobby Allyn. Thank you. ALLYN: Thanks, Ari.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-06-17-1007414231": {"title": "Sir Tim Berners-Lee Is Selling The Original Source Code For The World Wide Web  : NPR", "url": "https://www.npr.org/2021/06/17/1007414231/the-father-of-the-web-is-selling-the-source-code-as-an-nft", "author": "No author found", "published_date": "2021-06-17", "content": "", "section": "Technology", "disclaimer": ""}, "2021-06-17-1007496797": {"title": "Airlines, Banks And Other Companies Across The World Hit In Latest Web Outage : NPR", "url": "https://www.npr.org/2021/06/17/1007496797/airlines-banks-and-other-companies-across-the-world-hit-in-latest-web-outage", "author": "No author found", "published_date": "2021-06-17", "content": "", "section": "Technology", "disclaimer": ""}, "2021-06-17-1007472092": {"title": "Facebook Researchers Say They Can Detect Deepfakes And Where They Came From : NPR", "url": "https://www.npr.org/2021/06/17/1007472092/facebook-researchers-say-they-can-detect-deepfakes-and-where-they-came-from", "author": "No author found", "published_date": "2021-06-17", "content": "", "section": "Technology", "disclaimer": ""}, "2021-06-22-1008986894": {"title": "'Farming Simulator' Is A Smash Hit ... Farming Simulator : NPR", "url": "https://www.npr.org/2021/06/22/1008986894/farming-video-game-is-so-popular-people-pay-to-watch-gamers-play-it", "author": "No author found", "published_date": "2021-06-22", "content": "STEVE INSKEEP, HOST:  Players of video games have a chance to do things they'd never do in real life. And for some, that includes the joy of plowing a soybean field, baling hay or harvesting wheat. Farming Simulator is the latest of the many games with a fan base that is so big, people pay to watch other people play it. Jonathan Ahl of St. Louis Public Radio reports. JONATHAN AHL, BYLINE: Harley Hand is getting ready for a day on the farm. (SOUNDBITE OF ARCHIVED RECORDING)HARLEY HAND: Well, first, let me jump in a combine. We've got a soybean harvest, guys. We've got a big harvest, a bunch of fields that are ready to go. AHL: He makes an adjustment to his equipment, and he's on his way. (SOUNDBITE OF ARCHIVED RECORDING)HAND: Need to unfold the header. I guess it's - OK. Well, let's fold it up. There we go. All right. Let's roll. AHL: That sound - it isn't a real combine, of course, because Hand isn't on a real farm. He's in front of his computer in his house in rural Hazlehurst, Ga. , playing the game Farming Simulator and streaming the session online. He has more than 40,000 people following him on Facebook. Playing the game is his full-time job, with some subscribers paying $5 a month and others giving him tips while he plays. Hand says a lot of his interactions with his audience are about learning the ins and outs of farming. HAND: It's a huge learning experience for a lot of people that come into my streams. I've got a lot of people that know nothing about farming, and they come into the stream, and they're like - oh, really? - that's how that works. And it's pretty cool. AHL: Farming Simulator covers a lot of ground, including buying equipment, choosing crops, plowing, planting, fertilizing and harvesting, not to mention options to raise livestock. A. K. Rahming (ph) is a gamer and writer who has reviewed Farming Simulator for the website PC Invasion. He says the game is a lot like real farming. A K RAHMING: The monotony, the tediousness, the length of time that it takes to plow a field in Farming Sim, it does give you an appreciation for what real farmers have to do, I would say, from my experience. AHL: Monotony, tediousness - not the kind of words you usually associate with something that people would do for fun. But the game's realism is a big reason why it's so popular. Some of the game's most avid fans are farmers. Ryan Kuster farms in southwestern Wisconsin. RYAN KUSTER: Now, I can see why people love this game. Basically, it's just kind of your own little world where you can plant anything and everything you want. I think this would be actually really useful, like, for designing farm layouts even. AHL: Kuster says it's real, but not too real. There's no droughts or floods or insect infestations. Shelbey Walker is an agricultural communications researcher at the University of Hawaii - Manoa. She studied farmers and video games and found some farmers use the game as a quintessential busman's holiday. They drive a real tractor all day and unwind by driving a virtual one at night. SHELBEY WALKER: The conditions aren't always perfect. But within the game, the conditions are always perfect. So it's almost like this fantasy. It's - I get to do things in the digital realm that I don't get to do in real life. AHL: Walker says the game also attracts people like her who may not be farmers but feel connected to agriculture because they grew up in rural areas or were in 4-H. In addition to streamers like Hand, there's another outlet for rabid Farming Simulator fans, an esports league. Its 2021 Farming Simulator season will end in November with a tournament in Hanover, Germany. The top prize is $100,000, more than many real farmers make in a year. For NPR News, I'm Jonathan Ahl. (SOUNDBITE OF YEARS' \"THE ASSASSINATION OF DOW JONES\") STEVE INSKEEP, HOST:   Players of video games have a chance to do things they'd never do in real life. And for some, that includes the joy of plowing a soybean field, baling hay or harvesting wheat. Farming Simulator is the latest of the many games with a fan base that is so big, people pay to watch other people play it. Jonathan Ahl of St. Louis Public Radio reports. JONATHAN AHL, BYLINE: Harley Hand is getting ready for a day on the farm. (SOUNDBITE OF ARCHIVED RECORDING) HARLEY HAND: Well, first, let me jump in a combine. We've got a soybean harvest, guys. We've got a big harvest, a bunch of fields that are ready to go. AHL: He makes an adjustment to his equipment, and he's on his way. (SOUNDBITE OF ARCHIVED RECORDING) HAND: Need to unfold the header. I guess it's - OK. Well, let's fold it up. There we go. All right. Let's roll. AHL: That sound - it isn't a real combine, of course, because Hand isn't on a real farm. He's in front of his computer in his house in rural Hazlehurst, Ga. , playing the game Farming Simulator and streaming the session online. He has more than 40,000 people following him on Facebook. Playing the game is his full-time job, with some subscribers paying $5 a month and others giving him tips while he plays. Hand says a lot of his interactions with his audience are about learning the ins and outs of farming. HAND: It's a huge learning experience for a lot of people that come into my streams. I've got a lot of people that know nothing about farming, and they come into the stream, and they're like - oh, really? - that's how that works. And it's pretty cool. AHL: Farming Simulator covers a lot of ground, including buying equipment, choosing crops, plowing, planting, fertilizing and harvesting, not to mention options to raise livestock. A. K. Rahming (ph) is a gamer and writer who has reviewed Farming Simulator for the website PC Invasion. He says the game is a lot like real farming. A K RAHMING: The monotony, the tediousness, the length of time that it takes to plow a field in Farming Sim, it does give you an appreciation for what real farmers have to do, I would say, from my experience. AHL: Monotony, tediousness - not the kind of words you usually associate with something that people would do for fun. But the game's realism is a big reason why it's so popular. Some of the game's most avid fans are farmers. Ryan Kuster farms in southwestern Wisconsin. RYAN KUSTER: Now, I can see why people love this game. Basically, it's just kind of your own little world where you can plant anything and everything you want. I think this would be actually really useful, like, for designing farm layouts even. AHL: Kuster says it's real, but not too real. There's no droughts or floods or insect infestations. Shelbey Walker is an agricultural communications researcher at the University of Hawaii - Manoa. She studied farmers and video games and found some farmers use the game as a quintessential busman's holiday. They drive a real tractor all day and unwind by driving a virtual one at night. SHELBEY WALKER: The conditions aren't always perfect. But within the game, the conditions are always perfect. So it's almost like this fantasy. It's - I get to do things in the digital realm that I don't get to do in real life. AHL: Walker says the game also attracts people like her who may not be farmers but feel connected to agriculture because they grew up in rural areas or were in 4-H. In addition to streamers like Hand, there's another outlet for rabid Farming Simulator fans, an esports league. Its 2021 Farming Simulator season will end in November with a tournament in Hanover, Germany. The top prize is $100,000, more than many real farmers make in a year. For NPR News, I'm Jonathan Ahl. (SOUNDBITE OF YEARS' \"THE ASSASSINATION OF DOW JONES\")", "section": "Gaming", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-06-23-1009579599": {"title": "John McAfee Found Dead In A Spanish Prison Cell : NPR", "url": "https://www.npr.org/2021/06/23/1009579599/john-mcafee-software-pioneer-found-dead-in-a-spanish-prison-cell", "author": "No author found", "published_date": "2021-06-23", "content": "AUDIE CORNISH, HOST:  John McAfee is dead. He was 75 years old. McAfee was a millionaire who founded the well-known antivirus computer software that bears his name. NPR's Bobby Allyn joins us for more. And Bobby, first, just give us some more details about where he was and how he died. BOBBY ALLYN, BYLINE: John McAfee had been in prison in Spain since last October, and he was wanted in the U. S. in connection with three separate investigations related to tax fraud and a so-called pump-and-dump scheme involving cryptocurrency. Now, just earlier today, Audie, a Spanish court approved his extradition back to the U. S. to stand trial. Shortly after, though, his lawyer, Nishay Sanan, confirmed to NPR that he was found dead in his cell. NISHAY SANAN: Again, the U. S. government trying to erase John McAfee - and that's what it's always going to be. This man was a fighter. And in the minds of everyone who knew him, he will always be a fighter. CORNISH: But U. S. authorities had a different view. Exactly what were the cases against him related to? ALLYN: Yeah, they did indeed. So federal prosecutors say McAfee was a tax dodge, that he willfully failed to pay taxes from 2014 to 2018. And in another case, the Security (ph) and Exchange Commission said he made some $23 million by pumping up cryptocurrencies through his Twitter page and then dumping them for profit. There was a third case from the Federal Trade Commission, and it was aimed at this same alleged behavior. Now, McAfee didn't hide this, Audie. He was pretty brash about not paying taxes. I mean, he once tweeted that he hasn't paid taxes in eight years because, quote, \"taxation is illegal. \" And, you know, McAfee was a noted libertarian. He was very colorful, a sort of larger-than-life figure. And he once launched a longshot presidential bid under what he called the Cyber Party. CORNISH: You noted him being a larger-than-life figure. How will he be remembered? ALLYN: Yeah. His Twitter bio said this - iconoclast, lover of women, adventure and mystery, founder of McAfee Antivirus. And I talked to someone who knew him very well and once lived on one of his properties in Colorado. And she told me McAfee loved yoga retreats. He loved playing his grand piano. He loved going on long walks in nature. He moved to the Caribbean in 2009 after he lost most of his fortune in the Great Recession, and that's when his legal troubles really started. He was arrested in this very strange case in Guatemala for entering the country illegally. And, you know, that was after he was named, Audie, as a person of interest in the murder of his neighbor in Belize. So suffice it to say that there's been a lot swirling around McAfee. CORNISH: And the company that he founded, that still bears his name, how have they reacted? ALLYN: Yeah. They put out a statement, you know, saying that, you know, their thoughts are with John McAfee's family but that John McAfee has not been associated with the company in any capacity in more than 25 years. CORNISH: Before I let you go, Bobby, has there been any other word from McAfee's, I guess, estate, if there - is it - or was it just the defense attorney who spoke? ALLYN: Yeah. Right now our confirmation is coming from his U. S. -based defense lawyer, so we haven't heard anything from the McAfee estate. But, you know, as word comes in, we'll be sure to update you. CORNISH: That's NPR's Bobby Allyn. Thank you for your reporting. ALLYN: Thanks, Audie. (SOUNDBITE OF CLUSTER AND ENO'S \"SELANGE\") AUDIE CORNISH, HOST:   John McAfee is dead. He was 75 years old. McAfee was a millionaire who founded the well-known antivirus computer software that bears his name. NPR's Bobby Allyn joins us for more. And Bobby, first, just give us some more details about where he was and how he died. BOBBY ALLYN, BYLINE: John McAfee had been in prison in Spain since last October, and he was wanted in the U. S. in connection with three separate investigations related to tax fraud and a so-called pump-and-dump scheme involving cryptocurrency. Now, just earlier today, Audie, a Spanish court approved his extradition back to the U. S. to stand trial. Shortly after, though, his lawyer, Nishay Sanan, confirmed to NPR that he was found dead in his cell. NISHAY SANAN: Again, the U. S. government trying to erase John McAfee - and that's what it's always going to be. This man was a fighter. And in the minds of everyone who knew him, he will always be a fighter. CORNISH: But U. S. authorities had a different view. Exactly what were the cases against him related to? ALLYN: Yeah, they did indeed. So federal prosecutors say McAfee was a tax dodge, that he willfully failed to pay taxes from 2014 to 2018. And in another case, the Security (ph) and Exchange Commission said he made some $23 million by pumping up cryptocurrencies through his Twitter page and then dumping them for profit. There was a third case from the Federal Trade Commission, and it was aimed at this same alleged behavior. Now, McAfee didn't hide this, Audie. He was pretty brash about not paying taxes. I mean, he once tweeted that he hasn't paid taxes in eight years because, quote, \"taxation is illegal. \" And, you know, McAfee was a noted libertarian. He was very colorful, a sort of larger-than-life figure. And he once launched a longshot presidential bid under what he called the Cyber Party. CORNISH: You noted him being a larger-than-life figure. How will he be remembered? ALLYN: Yeah. His Twitter bio said this - iconoclast, lover of women, adventure and mystery, founder of McAfee Antivirus. And I talked to someone who knew him very well and once lived on one of his properties in Colorado. And she told me McAfee loved yoga retreats. He loved playing his grand piano. He loved going on long walks in nature. He moved to the Caribbean in 2009 after he lost most of his fortune in the Great Recession, and that's when his legal troubles really started. He was arrested in this very strange case in Guatemala for entering the country illegally. And, you know, that was after he was named, Audie, as a person of interest in the murder of his neighbor in Belize. So suffice it to say that there's been a lot swirling around McAfee. CORNISH: And the company that he founded, that still bears his name, how have they reacted? ALLYN: Yeah. They put out a statement, you know, saying that, you know, their thoughts are with John McAfee's family but that John McAfee has not been associated with the company in any capacity in more than 25 years. CORNISH: Before I let you go, Bobby, has there been any other word from McAfee's, I guess, estate, if there - is it - or was it just the defense attorney who spoke? ALLYN: Yeah. Right now our confirmation is coming from his U. S. -based defense lawyer, so we haven't heard anything from the McAfee estate. But, you know, as word comes in, we'll be sure to update you. CORNISH: That's NPR's Bobby Allyn. Thank you for your reporting. ALLYN: Thanks, Audie. (SOUNDBITE OF CLUSTER AND ENO'S \"SELANGE\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-06-23-1009567351": {"title": "NASA Probes Computer Outage On Hubble Space Telescope : NPR", "url": "https://www.npr.org/2021/06/23/1009567351/hubble-trouble-nasa-cant-figure-out-whats-causing-computer-issues-on-the-telesco", "author": "No author found", "published_date": "2021-06-23", "content": "", "section": "Space", "disclaimer": ""}, "2021-06-23-1001382019": {"title": "Supreme Court Rules For Cheerleader In Free Speech Case : NPR", "url": "https://www.npr.org/2021/06/23/1001382019/supreme-court-rules-cheerleaders-f-bombs-are-protected-by-the-first-amendment", "author": "No author found", "published_date": "2021-06-23", "content": "NOEL KING, HOST:  The Supreme Court sided with students today. The justices ruled that a cheerleader's online F-bombs hurled at her school and her team are protected speech under the First Amendment. In an 8-to-1 vote, the court said that school administrators do have the power to punish students' speech online or off campus if it disrupts the classroom, but the justices concluded that a few swear words posted online from off campus, as in this case, did not meet the definition of disruptive. With me now, NPR legal affairs correspondent Nina Totenberg. Hi, Nina. NINA TOTENBERG, BYLINE: Hi, Noel. KING: Why did this case go all the way to the Supreme Court? TOTENBERG: (Laughter) Well, this was a case brought by Brandi Levy, who at the time was a 14-year-old student in Mahanoy, Pa. She failed to win a promotion from the JV cheerleading squad to the varsity, and frustrated and upset, she launched a bunch of those F-bombs on Snapchat to some 200 of her friends, and they were all about school and life in general. When word of her message got out, she was suspended from the cheerleading squad, and she and her parents went to court, contending that she had a First Amendment right to express herself outside of school. A federal appeals court agreed with her, declaring that schools have no right to punish a student for speech outside of the school campus, ever. Well, today, the Supreme Court drew a much narrower line. In an opinion by Justice Stephen Breyer, the court said there are times when schools can punish students for off-campus speech, like targeted bullying and harassment, but not speech like this, that, in essence, is of - the essence of a person's First Amendment free expression. KING: What are some of the implications of today's ruling? TOTENBERG: This was pretty down-the-middle kind of an opinion, very workmanlike opinion by Justice Breyer, very typical. He noted that if a school can punish off-campus speech as easily as this, then all of a student's speech is subject to punishment 24 hours a day, when she's at school and when she's not at school. And writing for the majority, he said while public schools do have a special interest in regulating some off-campus student speech, the special interests offered by the school here are not sufficient to overcome Brandi Levy's interest in free expression. KING: OK. It was an 8-to-1 ruling. We have seen a bunch of lopsided opinions for this court. Is this another one of those? TOTENBERG: Yes and no. Technically, it's an 8-to-1 opinion, but Justice Alito, writing for himself and Justice Gorsuch, wrote a much longer concurring opinion than the majority opinion. Seven - even seven more - sorry, I misspoke there. It was seven more pages than the majority opinion. And he went off on a tangent of his own. And Justice Thomas, writing for himself, said once again that he doesn't think the First Amendment protects students' speech at all. So this is really more of a 6-3 decision. And like a lot of the opinions so far this year, three of the conservatives joined with the court's three liberals in a somewhat limited, sort of middling decision. KING: OK. And then there were a couple of other important decisions today. In the time we have left, can you tell us about a few? TOTENBERG: In a very important case, Justice Alito, who's written numerous opinions dramatically eroding the power of labor unions, did it again today by a straight 6-to-3 liberal-conservative split. He wrote the conservative court's opinion striking down a California law that allowed labor union organizers to meet with farmworkers on their employers' property during lunch or other off hours before or after work, a set number of days a year. The court said that was an unconstitutional taking of the growers' property. And while I haven't read everything, it could throw in doubt a similar law that's a federal law that's been in place for decades and decades - I would think more than a half century - that gives similar rights to labor organizers around the country but under federal law. And in another decision, the court set out limits for how far police can go without a warrant in pursuing onto a person's property someone who was observed committing a misdemeanor. In this case, it was a guy who was playing loud music while he was (laughter) driving down the highway late at night and was pursued by a policeman up into his own garage. The court said there are no hard-and-fast rules about this kind of thing but that, generally, misdemeanors don't qualify you to go running on to somebody's property if they're not serious. KING: NPR legal affairs correspondent Nina Totenberg. Thanks, Nina. TOTENBERG: Thank you, Noel. NOEL KING, HOST:   The Supreme Court sided with students today. The justices ruled that a cheerleader's online F-bombs hurled at her school and her team are protected speech under the First Amendment. In an 8-to-1 vote, the court said that school administrators do have the power to punish students' speech online or off campus if it disrupts the classroom, but the justices concluded that a few swear words posted online from off campus, as in this case, did not meet the definition of disruptive. With me now, NPR legal affairs correspondent Nina Totenberg. Hi, Nina. NINA TOTENBERG, BYLINE: Hi, Noel. KING: Why did this case go all the way to the Supreme Court? TOTENBERG: (Laughter) Well, this was a case brought by Brandi Levy, who at the time was a 14-year-old student in Mahanoy, Pa. She failed to win a promotion from the JV cheerleading squad to the varsity, and frustrated and upset, she launched a bunch of those F-bombs on Snapchat to some 200 of her friends, and they were all about school and life in general. When word of her message got out, she was suspended from the cheerleading squad, and she and her parents went to court, contending that she had a First Amendment right to express herself outside of school. A federal appeals court agreed with her, declaring that schools have no right to punish a student for speech outside of the school campus, ever. Well, today, the Supreme Court drew a much narrower line. In an opinion by Justice Stephen Breyer, the court said there are times when schools can punish students for off-campus speech, like targeted bullying and harassment, but not speech like this, that, in essence, is of - the essence of a person's First Amendment free expression. KING: What are some of the implications of today's ruling? TOTENBERG: This was pretty down-the-middle kind of an opinion, very workmanlike opinion by Justice Breyer, very typical. He noted that if a school can punish off-campus speech as easily as this, then all of a student's speech is subject to punishment 24 hours a day, when she's at school and when she's not at school. And writing for the majority, he said while public schools do have a special interest in regulating some off-campus student speech, the special interests offered by the school here are not sufficient to overcome Brandi Levy's interest in free expression. KING: OK. It was an 8-to-1 ruling. We have seen a bunch of lopsided opinions for this court. Is this another one of those? TOTENBERG: Yes and no. Technically, it's an 8-to-1 opinion, but Justice Alito, writing for himself and Justice Gorsuch, wrote a much longer concurring opinion than the majority opinion. Seven - even seven more - sorry, I misspoke there. It was seven more pages than the majority opinion. And he went off on a tangent of his own. And Justice Thomas, writing for himself, said once again that he doesn't think the First Amendment protects students' speech at all. So this is really more of a 6-3 decision. And like a lot of the opinions so far this year, three of the conservatives joined with the court's three liberals in a somewhat limited, sort of middling decision. KING: OK. And then there were a couple of other important decisions today. In the time we have left, can you tell us about a few? TOTENBERG: In a very important case, Justice Alito, who's written numerous opinions dramatically eroding the power of labor unions, did it again today by a straight 6-to-3 liberal-conservative split. He wrote the conservative court's opinion striking down a California law that allowed labor union organizers to meet with farmworkers on their employers' property during lunch or other off hours before or after work, a set number of days a year. The court said that was an unconstitutional taking of the growers' property. And while I haven't read everything, it could throw in doubt a similar law that's a federal law that's been in place for decades and decades - I would think more than a half century - that gives similar rights to labor organizers around the country but under federal law. And in another decision, the court set out limits for how far police can go without a warrant in pursuing onto a person's property someone who was observed committing a misdemeanor. In this case, it was a guy who was playing loud music while he was (laughter) driving down the highway late at night and was pursued by a policeman up into his own garage. The court said there are no hard-and-fast rules about this kind of thing but that, generally, misdemeanors don't qualify you to go running on to somebody's property if they're not serious. KING: NPR legal affairs correspondent Nina Totenberg. Thanks, Nina. TOTENBERG: Thank you, Noel.", "section": "Law", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-06-23-1008841328": {"title": "Is It OK To Commemorate One Of Iraq's Bloodiest Battles In A Video Game? : NPR", "url": "https://www.npr.org/2021/06/23/1008841328/is-it-ok-to-commemorate-one-of-iraqs-bloodiest-battles-in-a-videogame", "author": "No author found", "published_date": "2021-06-23", "content": "AUDIE CORNISH, HOST:  Can a civilian understand what it means to be in combat? Can a video game even come close to portraying that experience? The controversial new game Six Days In Fallujah attempts to do that. And as the so-called forever wars in Iraq and Afghanistan come to an end, NPR's Quil Lawrence reports some worry that this will trivialize the battle. And a warning - this story includes the sound of gunfire. QUIL LAWRENCE, BYLINE: Combat and storytelling are two very different skills. Elliot Ackerman has both. He's a decorated veteran and a novelist. He fought in the second battle of Fallujah in 2004, the biggest battle of the Iraq War. Ackerman's platoon got out ahead of the front line. ELLIOT ACKERMAN: We go even deeper into the city than we'd planned. LAWRENCE: They didn't want to turn back, so they hide in an empty building. ACKERMAN: And that building wound up being, like, a convenience store. We call it the candy store. LAWRENCE: They're low on food, so they pig out on warm Coca-Cola and Pringles. It doesn't take long for the insurgents to figure out where Ackerman's men are. The Marines pop smoke grenades for cover. ACKERMAN: You're standing in this, like, cloud of, you know, purple and yellow smoke. And you can hear the bullet snaps through the smoke because the insurgents see the smoke. And they can't see you, but they're shooting at the smoke. LAWRENCE: By dawn, they're surrounded, trapped in the store. Two men are down, and the medics have them. ACKERMAN: And I go and I kind of, like, stick my head out the door just to, like, see like, can we get out this way? And there is a RPK, which is, like, a light machine, and it just goes - gah (ph) - like that right down the alleyway, like, soon as I poked my head out. And I bump into Banotai. He was one of the squad leaders. And I remember I looked at him, and I was like, it's suicide if we go out that way. I just kind of blurted that out to him. And he later told me, it's like, you know, the time I was the most afraid was when you said that to me. LAWRENCE: That kind of fear and adrenaline, how the Marines escape the candy store, it's something only they experienced. But Ackerman rejects the idea that civilians can't possibly relate. ACKERMAN: You know, you ever been involved something tragic? Ever been in a car accident, crisis? It's the same thing, totally the same thing. LAWRENCE: Most people know trauma or loss. This past year, it seems global. Ackerman says both civilians and veterans have to try harder. ACKERMAN: So I think that to say, I can't imagine it, is a cop-out. It's basically telling a whole group of people, meaning veterans, that they can never come home. LAWRENCE: Because home is mostly just feeling understood, feeling at home. So how do you build that understanding about the past 20 years of war? Plenty of novels and essays and movies have tried. PETER TAMTE: I got a phone call. . . LAWRENCE: And there are less traditional ways. . . TAMTE: . . . Or email, actually. . . LAWRENCE: . . . Like what Peter Tamte does. TAMTE: . . . At first from a Marine who I'd gotten to know quite well who had been medevaced out of the battle for Fallujah. And he started telling me all these stories from the battle that I had not heard. LAWRENCE: Tamte is not a Marine, never served. He got to know a lot of Marines, though, when he was designing video training simulations for the military. One of those Marines called him back in 2004 straight from Fallujah. TAMTE: I was blown away by the things that he had said. And it was that conversation where he said, you know, Peter, our generation plays video games. LAWRENCE: He says, we don't read books or even watch movies so much. We play video games. TAMTE: I was like, yeah, I know. He said, would you be interested in creating a video game to tell the stories of the battle for Fallujah? And so - and I - immediately, I said yes. And I didn't really understand fully what I was getting myself into. LAWRENCE: Tamte called it Six Days In Fallujah, based on scenarios the Marines told him about. Then he spent the next five years working on it. The game included interviews with Americans but also Iraqis, documentary-style. While most of the civilians had left Fallujah, there were some stuck there during the battle. Tamte says American troops know what they did taking that city. TAMTE: One of the Marines articulated it. He said, you know, what happened to the people of Fallujah is tragic. It's tragic. And it wasn't their fault. They said at the same time, not my fault either. (SOUNDBITE OF GUNFIRE)LAWRENCE: This is a firefight I watched in Fallujah. Insurgents fired RPGs and mortars. Americans took out buildings with airstrikes. (SOUNDBITE OF GUNFIRE)LAWRENCE: Five years later, in 2009, Konami, one of the world's largest video game makers, had partnered with Tamte's company and was going to release the game. But the Iraq War was still raging. Tens of thousands of Iraqi civilians had died. Fallujah was still a combat zone. KEREN MEREDITH: This war is going on, and it's not a game. LAWRENCE: Keren Meredith lost her son, Ken Ballard, in Iraq. MEREDITH: Ken never got the chance to put another quarter in and play another game. And I just didn't think that it was right - the armchair warriors, the keyboard warriors who were so, you know, let's play a game. Oops, I got killed. OK, let's start over. LAWRENCE: After outraged Gold Star mothers got on cable news, the big corporate sponsor, Konami, just dumped the game. TAMTE: Well, you know, honestly, I was crushed initially. LAWRENCE: Peter Tamte says he'd been consumed by the project. And suddenly, no one would touch it. TAMTE: I thought that somehow, someway, I cannot walk away from the trust that these Marine soldiers and Iraqis at that point had given us to tell their stories. LAWRENCE: Tamte put the stories away on hard drives. TAMTE: I made a couple of backups, and I put them in safe deposit boxes. LAWRENCE: And that's where they sat for most of the decade. Tamte left the video game business altogether. Then this past February, he reached out - actually, his publicist did - with a trailer. They're making the game. (SOUNDBITE OF SIX DAYS IN FALLUJAH - OFFICAL GAMEPLAY REVEAL TRAILER)JASON KYLE: My son, he had his first birthday while we were in Fallujah. LAWRENCE: The trailer's part documentary with Fallujah veterans like Marine Sergeant Jason Kyle. (SOUNDBITE OF SIX DAYS IN FALLUJAH - OFFICAL GAMEPLAY REVEAL TRAILER)KYLE: That was the most difficult day I had there. It dawned on me. It's like, I can't die on my kid's birthday. LAWRENCE: And it's part you-are-there shooter game. (SOUNDBITE OF SIX DAYS IN FALLUJAH - OFFICAL GAMEPLAY REVEAL TRAILER)UNIDENTIFIED PERSON #1: Pin enemies in place with suppressive fire while you flank. LAWRENCE: Part of the game is played as an Iraqi family trying to escape the city. (SOUNDBITE OF SIX DAYS IN FALLUJAH - OFFICAL GAMEPLAY REVEAL TRAILER)UNIDENTIFIED ACTOR: (As soldier) What's that? (SOUNDBITE OF WOMAN SCREAMING)UNIDENTIFIED ACTOR: (As soldier) On our left. Who's there? Step out. LAWRENCE: There are also interviews with Fallujah civilians. . . (SOUNDBITE OF SIX DAYS IN FALLUJAH - OFFICAL GAMEPLAY REVEAL TRAILER)KYLE: . . . Kick that door down. And it's, like, a family of four. And I'm talking to the dad. I'm like, dude, like, why are you still here? And he's like. . . LAWRENCE: . . . Like this man whose father refused to leave his home in the city. (SOUNDBITE OF SIX DAYS IN FALLUJAH - OFFICAL GAMEPLAY REVEAL TRAILER)UNIDENTIFIED PERSON #2: (Non-English language spoken). LAWRENCE: Still, many people doubt that video games can handle serious subjects. The game isn't released yet, but the Gold Star mothers I spoke with, they still think players will just see this as shoot-'em-up entertainment. SCOTT SIMPSON: It's simply irredeemable. LAWRENCE: Scott Simpson, with Muslim Advocates, says it's entertainment made from a battle where Americans killed many Iraqi civilians. SIMPSON: There is no way to release a game that glorifies the killing that happened. Is it enough to have an interview of a soldier beforehand justifying their actions, actions that you're going to be taking, by the way? I don't think so. LAWRENCE: Simpson says he thinks the game could promote anti-Arab and anti-Muslim violence. Peter Tamte says none of that is his intention. He says he wants to reach an audience that won't otherwise know anything about Fallujah. TAMTE: I worry that if media collectively or video games specifically don't deal with the topic of the Iraq War, that millions of people will forget it's cost. LAWRENCE: And he's getting encouragement from some veterans of the battle. ACKERMAN: I think one of the huge problems we have right now is that so many Americans are just totally disconnected from our wars and our military. LAWRENCE: Elliot Ackerman, the novelist, was one of the Marines interviewed for Six Days In Fallujah. Gamers will actually play him trapped in that candy store he told us about. And he's OK with that. ACKERMAN: And so if you can get people paying attention and engaging with the subject matter through a video game, great. Like, I'm all about that. LAWRENCE: Six Days In Fallujah is slated for release this December, 17 years after the battle was fought. Quil Lawrence, NPR News. (SOUNDBITE OF MUSIC) AUDIE CORNISH, HOST:   Can a civilian understand what it means to be in combat? Can a video game even come close to portraying that experience? The controversial new game Six Days In Fallujah attempts to do that. And as the so-called forever wars in Iraq and Afghanistan come to an end, NPR's Quil Lawrence reports some worry that this will trivialize the battle. And a warning - this story includes the sound of gunfire. QUIL LAWRENCE, BYLINE: Combat and storytelling are two very different skills. Elliot Ackerman has both. He's a decorated veteran and a novelist. He fought in the second battle of Fallujah in 2004, the biggest battle of the Iraq War. Ackerman's platoon got out ahead of the front line. ELLIOT ACKERMAN: We go even deeper into the city than we'd planned. LAWRENCE: They didn't want to turn back, so they hide in an empty building. ACKERMAN: And that building wound up being, like, a convenience store. We call it the candy store. LAWRENCE: They're low on food, so they pig out on warm Coca-Cola and Pringles. It doesn't take long for the insurgents to figure out where Ackerman's men are. The Marines pop smoke grenades for cover. ACKERMAN: You're standing in this, like, cloud of, you know, purple and yellow smoke. And you can hear the bullet snaps through the smoke because the insurgents see the smoke. And they can't see you, but they're shooting at the smoke. LAWRENCE: By dawn, they're surrounded, trapped in the store. Two men are down, and the medics have them. ACKERMAN: And I go and I kind of, like, stick my head out the door just to, like, see like, can we get out this way? And there is a RPK, which is, like, a light machine, and it just goes - gah (ph) - like that right down the alleyway, like, soon as I poked my head out. And I bump into Banotai. He was one of the squad leaders. And I remember I looked at him, and I was like, it's suicide if we go out that way. I just kind of blurted that out to him. And he later told me, it's like, you know, the time I was the most afraid was when you said that to me. LAWRENCE: That kind of fear and adrenaline, how the Marines escape the candy store, it's something only they experienced. But Ackerman rejects the idea that civilians can't possibly relate. ACKERMAN: You know, you ever been involved something tragic? Ever been in a car accident, crisis? It's the same thing, totally the same thing. LAWRENCE: Most people know trauma or loss. This past year, it seems global. Ackerman says both civilians and veterans have to try harder. ACKERMAN: So I think that to say, I can't imagine it, is a cop-out. It's basically telling a whole group of people, meaning veterans, that they can never come home. LAWRENCE: Because home is mostly just feeling understood, feeling at home. So how do you build that understanding about the past 20 years of war? Plenty of novels and essays and movies have tried. PETER TAMTE: I got a phone call. . . LAWRENCE: And there are less traditional ways. . . TAMTE: . . . Or email, actually. . . LAWRENCE: . . . Like what Peter Tamte does. TAMTE: . . . At first from a Marine who I'd gotten to know quite well who had been medevaced out of the battle for Fallujah. And he started telling me all these stories from the battle that I had not heard. LAWRENCE: Tamte is not a Marine, never served. He got to know a lot of Marines, though, when he was designing video training simulations for the military. One of those Marines called him back in 2004 straight from Fallujah. TAMTE: I was blown away by the things that he had said. And it was that conversation where he said, you know, Peter, our generation plays video games. LAWRENCE: He says, we don't read books or even watch movies so much. We play video games. TAMTE: I was like, yeah, I know. He said, would you be interested in creating a video game to tell the stories of the battle for Fallujah? And so - and I - immediately, I said yes. And I didn't really understand fully what I was getting myself into. LAWRENCE: Tamte called it Six Days In Fallujah, based on scenarios the Marines told him about. Then he spent the next five years working on it. The game included interviews with Americans but also Iraqis, documentary-style. While most of the civilians had left Fallujah, there were some stuck there during the battle. Tamte says American troops know what they did taking that city. TAMTE: One of the Marines articulated it. He said, you know, what happened to the people of Fallujah is tragic. It's tragic. And it wasn't their fault. They said at the same time, not my fault either. (SOUNDBITE OF GUNFIRE) LAWRENCE: This is a firefight I watched in Fallujah. Insurgents fired RPGs and mortars. Americans took out buildings with airstrikes. (SOUNDBITE OF GUNFIRE) LAWRENCE: Five years later, in 2009, Konami, one of the world's largest video game makers, had partnered with Tamte's company and was going to release the game. But the Iraq War was still raging. Tens of thousands of Iraqi civilians had died. Fallujah was still a combat zone. KEREN MEREDITH: This war is going on, and it's not a game. LAWRENCE: Keren Meredith lost her son, Ken Ballard, in Iraq. MEREDITH: Ken never got the chance to put another quarter in and play another game. And I just didn't think that it was right - the armchair warriors, the keyboard warriors who were so, you know, let's play a game. Oops, I got killed. OK, let's start over. LAWRENCE: After outraged Gold Star mothers got on cable news, the big corporate sponsor, Konami, just dumped the game. TAMTE: Well, you know, honestly, I was crushed initially. LAWRENCE: Peter Tamte says he'd been consumed by the project. And suddenly, no one would touch it. TAMTE: I thought that somehow, someway, I cannot walk away from the trust that these Marine soldiers and Iraqis at that point had given us to tell their stories. LAWRENCE: Tamte put the stories away on hard drives. TAMTE: I made a couple of backups, and I put them in safe deposit boxes. LAWRENCE: And that's where they sat for most of the decade. Tamte left the video game business altogether. Then this past February, he reached out - actually, his publicist did - with a trailer. They're making the game. (SOUNDBITE OF SIX DAYS IN FALLUJAH - OFFICAL GAMEPLAY REVEAL TRAILER) JASON KYLE: My son, he had his first birthday while we were in Fallujah. LAWRENCE: The trailer's part documentary with Fallujah veterans like Marine Sergeant Jason Kyle. (SOUNDBITE OF SIX DAYS IN FALLUJAH - OFFICAL GAMEPLAY REVEAL TRAILER) KYLE: That was the most difficult day I had there. It dawned on me. It's like, I can't die on my kid's birthday. LAWRENCE: And it's part you-are-there shooter game. (SOUNDBITE OF SIX DAYS IN FALLUJAH - OFFICAL GAMEPLAY REVEAL TRAILER) UNIDENTIFIED PERSON #1: Pin enemies in place with suppressive fire while you flank. LAWRENCE: Part of the game is played as an Iraqi family trying to escape the city. (SOUNDBITE OF SIX DAYS IN FALLUJAH - OFFICAL GAMEPLAY REVEAL TRAILER) UNIDENTIFIED ACTOR: (As soldier) What's that? (SOUNDBITE OF WOMAN SCREAMING) UNIDENTIFIED ACTOR: (As soldier) On our left. Who's there? Step out. LAWRENCE: There are also interviews with Fallujah civilians. . . (SOUNDBITE OF SIX DAYS IN FALLUJAH - OFFICAL GAMEPLAY REVEAL TRAILER) KYLE: . . . Kick that door down. And it's, like, a family of four. And I'm talking to the dad. I'm like, dude, like, why are you still here? And he's like. . . LAWRENCE: . . . Like this man whose father refused to leave his home in the city. (SOUNDBITE OF SIX DAYS IN FALLUJAH - OFFICAL GAMEPLAY REVEAL TRAILER) UNIDENTIFIED PERSON #2: (Non-English language spoken). LAWRENCE: Still, many people doubt that video games can handle serious subjects. The game isn't released yet, but the Gold Star mothers I spoke with, they still think players will just see this as shoot-'em-up entertainment. SCOTT SIMPSON: It's simply irredeemable. LAWRENCE: Scott Simpson, with Muslim Advocates, says it's entertainment made from a battle where Americans killed many Iraqi civilians. SIMPSON: There is no way to release a game that glorifies the killing that happened. Is it enough to have an interview of a soldier beforehand justifying their actions, actions that you're going to be taking, by the way? I don't think so. LAWRENCE: Simpson says he thinks the game could promote anti-Arab and anti-Muslim violence. Peter Tamte says none of that is his intention. He says he wants to reach an audience that won't otherwise know anything about Fallujah. TAMTE: I worry that if media collectively or video games specifically don't deal with the topic of the Iraq War, that millions of people will forget it's cost. LAWRENCE: And he's getting encouragement from some veterans of the battle. ACKERMAN: I think one of the huge problems we have right now is that so many Americans are just totally disconnected from our wars and our military. LAWRENCE: Elliot Ackerman, the novelist, was one of the Marines interviewed for Six Days In Fallujah. Gamers will actually play him trapped in that candy store he told us about. And he's OK with that. ACKERMAN: And so if you can get people paying attention and engaging with the subject matter through a video game, great. Like, I'm all about that. LAWRENCE: Six Days In Fallujah is slated for release this December, 17 years after the battle was fought. Quil Lawrence, NPR News. (SOUNDBITE OF MUSIC)", "section": "National Security", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-06-25-1010066447": {"title": "Stung By Media Coverage, Silicon Valley Starts Its Own Publications  : NPR", "url": "https://www.npr.org/2021/06/25/1010066447/stung-by-media-coverage-silicon-valley-starts-its-own-publications", "author": "No author found", "published_date": "2021-06-25", "content": "AILSA CHANG, HOST:  Silicon Valley's elite love to complain about the media. In recent years, Big Tech has attracted a lot of scrutiny from how it treats gig workers to the spread of misinformation. Now the industry has come up with a way to control the narrative - by launching its own media publications. NPR's Bobby Allyn reports. BOBBY ALLYN, BYLINE: Marc Andreessen is something of a kingmaker in Silicon Valley. He's the co-founder of leading venture capital firm Andreessen Horowitz, which has had huge success by investing early in companies like Facebook, Twitter and Airbnb. Andreessen thinks of himself as an ideas guy, but if a journalist writes a story he doesn't like, he'll be quick to block them. I spoke to longtime journalist Timothy Lee about this. You've been covering the tech industry for more than a decade. Does Marc Andreessen have you blocked on Twitter? TIMOTHY LEE: (Laughter) Well, I think - I can check. Is he still on Twitter? He's definitely stopped being active. Yes, I am blocked. ALLYN: Silicon Valley doesn't like critical coverage because it wasn't always that way. In the early 2000s, journalists were wowed by shiny new gadgets and cool social media sites. But something shifted a few years after the iPhone was introduced in 2007. SARA WATSON: And, you know, it changed our entire relationship with technology. So I think that's a huge turning point. ALLYN: Tech critic Sara Watson says reviewers went from describing the iPhone as sexy to saying, wait a minute; what does this supercomputer in our pockets really mean for society? And the coverage kept getting tougher. Social media played a big role in the 2016 election and in the lead-up to the recent capital siege. Journalists have pried deeper and deeper into technology's role in democracy. WATSON: And that is not the environment that Andreessen Horowitz or any VC firm is used to. ALLYN: VC firms don't want to attract controversy because that could mean they lose a lot of money that they've poured into startups. So now Andreessen Horowitz has launched its own publication. It hopes to be the, quote, \"future of the media. \" Margit Wennmachers is a partner at the firm and the public face behind the publication. MARGIT WENNMACHERS: We are launching future. com, the go-to place that's all about the future, how technology shapes it and how to build it. ALLYN: Wennmachers says they are not hiding their bias. WENNMACHERS: We are taking a pro stance towards technology. ALLYN: Other tech companies from Snapchat to Uber have launched in-house media operations. Journalist Timothy Lee says while other industries have done this, too, the tech sector knows how we use the internet and has the ability to reach millions instantly. LEE: They just see, you know, media as another potential industry like that where they might be able to come along and build something better that was there before the same way they did with taxis and video streaming and lots of other stuff. ALLYN: Lee says tech running its own media helps avoid hard questions and lets them control the narrative. But more than that, it's aimed at getting people to have a more positive view of Silicon Valley. But it raises questions about fairness and accountability, two central tenets of journalism. Watson says they could break their own news and give exclusive interviews to their own outlet. WATSON: What I am more worried about is the way that they're kind of wielding access as a tool of power. ALLYN: Most media, like NPR, is supported by corporate sponsorship or advertisements. But Lee says it's an entirely different thing when the companies are editing and framing the stories with their own point of view. LEE: How are they going to make clear to readers, this is an independent news organization, versus, this is a article that was written by, you know, an investor in the company? ALLYN: Wennmachers says, why can't there be both articles from the news media and ones written by the tech industry? WENNMACHERS: People are like, there cannot be possibly any good content coming out of a company. And there are folks, admittedly, in the technology business who say, like, oh, all reporters are completely unfair. I think both are wrong. ALLYN: If you go to her site that says it's the future of media, you'll find articles like one on how the legal system should use more robots, and it's written by a guy who started a business that lets you hire robots as lawyers. Bobby Allyn, NPR News, San Francisco. AILSA CHANG, HOST:   Silicon Valley's elite love to complain about the media. In recent years, Big Tech has attracted a lot of scrutiny from how it treats gig workers to the spread of misinformation. Now the industry has come up with a way to control the narrative - by launching its own media publications. NPR's Bobby Allyn reports. BOBBY ALLYN, BYLINE: Marc Andreessen is something of a kingmaker in Silicon Valley. He's the co-founder of leading venture capital firm Andreessen Horowitz, which has had huge success by investing early in companies like Facebook, Twitter and Airbnb. Andreessen thinks of himself as an ideas guy, but if a journalist writes a story he doesn't like, he'll be quick to block them. I spoke to longtime journalist Timothy Lee about this. You've been covering the tech industry for more than a decade. Does Marc Andreessen have you blocked on Twitter? TIMOTHY LEE: (Laughter) Well, I think - I can check. Is he still on Twitter? He's definitely stopped being active. Yes, I am blocked. ALLYN: Silicon Valley doesn't like critical coverage because it wasn't always that way. In the early 2000s, journalists were wowed by shiny new gadgets and cool social media sites. But something shifted a few years after the iPhone was introduced in 2007. SARA WATSON: And, you know, it changed our entire relationship with technology. So I think that's a huge turning point. ALLYN: Tech critic Sara Watson says reviewers went from describing the iPhone as sexy to saying, wait a minute; what does this supercomputer in our pockets really mean for society? And the coverage kept getting tougher. Social media played a big role in the 2016 election and in the lead-up to the recent capital siege. Journalists have pried deeper and deeper into technology's role in democracy. WATSON: And that is not the environment that Andreessen Horowitz or any VC firm is used to. ALLYN: VC firms don't want to attract controversy because that could mean they lose a lot of money that they've poured into startups. So now Andreessen Horowitz has launched its own publication. It hopes to be the, quote, \"future of the media. \" Margit Wennmachers is a partner at the firm and the public face behind the publication. MARGIT WENNMACHERS: We are launching future. com, the go-to place that's all about the future, how technology shapes it and how to build it. ALLYN: Wennmachers says they are not hiding their bias. WENNMACHERS: We are taking a pro stance towards technology. ALLYN: Other tech companies from Snapchat to Uber have launched in-house media operations. Journalist Timothy Lee says while other industries have done this, too, the tech sector knows how we use the internet and has the ability to reach millions instantly. LEE: They just see, you know, media as another potential industry like that where they might be able to come along and build something better that was there before the same way they did with taxis and video streaming and lots of other stuff. ALLYN: Lee says tech running its own media helps avoid hard questions and lets them control the narrative. But more than that, it's aimed at getting people to have a more positive view of Silicon Valley. But it raises questions about fairness and accountability, two central tenets of journalism. Watson says they could break their own news and give exclusive interviews to their own outlet. WATSON: What I am more worried about is the way that they're kind of wielding access as a tool of power. ALLYN: Most media, like NPR, is supported by corporate sponsorship or advertisements. But Lee says it's an entirely different thing when the companies are editing and framing the stories with their own point of view. LEE: How are they going to make clear to readers, this is an independent news organization, versus, this is a article that was written by, you know, an investor in the company? ALLYN: Wennmachers says, why can't there be both articles from the news media and ones written by the tech industry? WENNMACHERS: People are like, there cannot be possibly any good content coming out of a company. And there are folks, admittedly, in the technology business who say, like, oh, all reporters are completely unfair. I think both are wrong. ALLYN: If you go to her site that says it's the future of media, you'll find articles like one on how the legal system should use more robots, and it's written by a guy who started a business that lets you hire robots as lawyers. Bobby Allyn, NPR News, San Francisco.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-06-26-1010606320": {"title": "New Podcast 'Delivery Wars' Looks At The Cost Of Convenience : NPR", "url": "https://www.npr.org/2021/06/26/1010606320/new-podcast-delivery-wars-looks-at-the-cost-of-convenience", "author": "No author found", "published_date": "2021-06-26", "content": "SARAH MCCAMMON, HOST:  As the pandemic raged last year and restaurants across the country struggled to stay afloat, many shifted to reach customers where they were, which was at home. Delivery apps like GrubHub and DoorDash made it easy to connect hungry customers to food options. But even as these apps became a lifeline for the industry, they were also a huge pain for some restaurant owners who complained about the high fees that make their already slim margins even slimmer. Just this week, San Francisco became the first city to set a permanent cap on fees from these apps. But overall, food delivery remains a huge business. Today, the biggest delivery apps - DoorDash Uber Eats and GrubHub - are worth more than $130 billion in total. AHMED ALI AKBAR: That's bigger than Chipotle, Pizza Hut, Taco Bell, KFC and the Olive Garden combined. MCCAMMON: Ahmed Ali Akbar is the host of a new podcast mini-series that explores the true cost of this convenience and what it means for restaurants, delivery drivers and consumers. The mini-series is called \"Land Of The Giants: Delivery Wars\" (ph). And when he spoke, Akbar told us why he thinks now is the time to take a deeper look at this industry. AKBAR: If you're a food writer, you've known that for a long time, restaurants have had a lot of complaints about delivery apps, the fees that you mentioned. But the pandemic really accelerated things for this industry. So it was kind of the perfect time to take a look at what was really happening and the different actors in this economy. MCCAMMON: In the first episode, you talk with restaurant owners who are trying to adapt during the pandemic. And I want to play a clip where you're interviewing the owner of a bagel shop who just said that these apps kept the restaurant afloat during the pandemic, but then he said this. (SOUNDBITE OF PODCAST, \"LAND OF THE GIANTS: DELIVERY WARS\")UNIDENTIFIED PERSON: The other thing that I don't like is how they sort of, you know, and I'm Italian American, to use the Mafia reference, but it's very Mafia-esque, very like, hey, pay up or you're not going to make any money. MCCAMMON: So how are these restaurant owners dealing with that? AKBAR: So what the restaurant owner there is referring to is the commission fee, which is about a 20 to 30% - it depends on the area - cut of each order that apps like GrubHub, Uber Eats and DoorDash take. Restaurant industry is a definitely a place where there are razor-thin margins. It's not an easy business by any means. So we spoke to one restaurant owner in Harlem who started packaging these notes in with his orders saying, please order from us directly. We have a website where, if you order from us on that website, you'll actually pay less, because when you order directly from him, they're paying less fees and commission. MCCAMMON: Yeah, as you mentioned, I mean, the restaurant business is a famously difficult one with thin margins. Then these delivery apps take their cut. I mean, is it even worth it for these businesses to be on these apps? AKBAR: That's a question I asked time and time again. And the answer was ambiguous because, you know, restaurateurs are customer-service focused. They want their food to go to their consumers. So it's kind of a can't-live-with-them-can't-live-without-them situation for a lot of these restaurant owners. MCCAMMON: So we talked a lot about the restaurants. What about the drivers? I mean, these are gig workers. They're using their cars, their fuel - right? - to deliver these orders. How are they coming out at the end of the day in terms of compensation for their labor? AKBAR: So this is a hotly-debated question. Many of the drivers we spoke to said that working for an app like DoorDash, it really helped them with their ability to have a flexible schedule and to pay their bills. Now, the question of wage is a really interesting one, because as an independent contractor, gig workers aren't compensated for waiting time. So we spoke to one driver who started signing on to the apps around 7:30 in the morning. And by 2:00 p. m. , they had only gotten two orders. So they made about $20 for all of that time working, which is significantly less than minimum wage. But of course, on a good night, sometimes they're making $17, $25 an hour. But then you start doing some of the math as you spend more time as a driver, the money spent on gas, the money spent on vehicle maintenance, what happens if you get injured and can no longer work, and the wages might not look as good as initially claimed. MCCAMMON: Do the prices the customers pay reflect the true cost of what we're getting? AKBAR: So one of the most interesting things about this is, that for the most part, these apps have not been profitable. A lot of venture capital money was injected into this industry because it was seen as a new Uber and Lyft possibility. Many cases, this means that the apps are operating at a loss and using the venture capital funds to subsidize some of the costs. But what we saw in our reporting was that basically the customer, even though they're paying fees and tips, they're actually getting a better deal than they might otherwise think. Delivery drivers and labor is like a huge cost for this industry, and it's not a cheap thing. So the way to get, you know, the kind of spread and reach across America that they have had is by subsidizing a lot of that wages. And it remains to be seen. We still don't really know whether the prices will increase for the consumer, but it's a possibility. MCCAMMON: Given what we've talked about when it comes to labor costs in particular and the cost to restaurants, you know, small businesses, what is the takeaway for consumers? I mean, should we skip the delivery apps and just walk in if we possibly can? AKBAR: That's not always a possibility for everybody, so I want to keep that in mind that these apps can provide some real accessibility. But a lot of the restaurants, they're asking customers that, hey, if you can, just call us in order and pick it up. We are going to see more of the profits of that order than if you order on the app. I do a mix personally. I think it's just fair to talk about what I do. I've seen that if I'm ordering on these apps, less of my money is going towards the restaurants. And if I'm going to support the restaurants, that's like one of the reasons why I'm ordering from a restaurant is to keep them in business, then it's probably not the best for them to order on an app. So I will often try to call them up myself and walk over, but I recognize that's not always a possibility as well. MCCAMMON: That was Ahmed Ali Akbar. He hosts the new mini-series \"Delivery Wars\" from \"Land Of The Giants\" podcast. Thank you so much for being with us. AKBAR: Thanks for having me. SARAH MCCAMMON, HOST:   As the pandemic raged last year and restaurants across the country struggled to stay afloat, many shifted to reach customers where they were, which was at home. Delivery apps like GrubHub and DoorDash made it easy to connect hungry customers to food options. But even as these apps became a lifeline for the industry, they were also a huge pain for some restaurant owners who complained about the high fees that make their already slim margins even slimmer. Just this week, San Francisco became the first city to set a permanent cap on fees from these apps. But overall, food delivery remains a huge business. Today, the biggest delivery apps - DoorDash Uber Eats and GrubHub - are worth more than $130 billion in total. AHMED ALI AKBAR: That's bigger than Chipotle, Pizza Hut, Taco Bell, KFC and the Olive Garden combined. MCCAMMON: Ahmed Ali Akbar is the host of a new podcast mini-series that explores the true cost of this convenience and what it means for restaurants, delivery drivers and consumers. The mini-series is called \"Land Of The Giants: Delivery Wars\" (ph). And when he spoke, Akbar told us why he thinks now is the time to take a deeper look at this industry. AKBAR: If you're a food writer, you've known that for a long time, restaurants have had a lot of complaints about delivery apps, the fees that you mentioned. But the pandemic really accelerated things for this industry. So it was kind of the perfect time to take a look at what was really happening and the different actors in this economy. MCCAMMON: In the first episode, you talk with restaurant owners who are trying to adapt during the pandemic. And I want to play a clip where you're interviewing the owner of a bagel shop who just said that these apps kept the restaurant afloat during the pandemic, but then he said this. (SOUNDBITE OF PODCAST, \"LAND OF THE GIANTS: DELIVERY WARS\") UNIDENTIFIED PERSON: The other thing that I don't like is how they sort of, you know, and I'm Italian American, to use the Mafia reference, but it's very Mafia-esque, very like, hey, pay up or you're not going to make any money. MCCAMMON: So how are these restaurant owners dealing with that? AKBAR: So what the restaurant owner there is referring to is the commission fee, which is about a 20 to 30% - it depends on the area - cut of each order that apps like GrubHub, Uber Eats and DoorDash take. Restaurant industry is a definitely a place where there are razor-thin margins. It's not an easy business by any means. So we spoke to one restaurant owner in Harlem who started packaging these notes in with his orders saying, please order from us directly. We have a website where, if you order from us on that website, you'll actually pay less, because when you order directly from him, they're paying less fees and commission. MCCAMMON: Yeah, as you mentioned, I mean, the restaurant business is a famously difficult one with thin margins. Then these delivery apps take their cut. I mean, is it even worth it for these businesses to be on these apps? AKBAR: That's a question I asked time and time again. And the answer was ambiguous because, you know, restaurateurs are customer-service focused. They want their food to go to their consumers. So it's kind of a can't-live-with-them-can't-live-without-them situation for a lot of these restaurant owners. MCCAMMON: So we talked a lot about the restaurants. What about the drivers? I mean, these are gig workers. They're using their cars, their fuel - right? - to deliver these orders. How are they coming out at the end of the day in terms of compensation for their labor? AKBAR: So this is a hotly-debated question. Many of the drivers we spoke to said that working for an app like DoorDash, it really helped them with their ability to have a flexible schedule and to pay their bills. Now, the question of wage is a really interesting one, because as an independent contractor, gig workers aren't compensated for waiting time. So we spoke to one driver who started signing on to the apps around 7:30 in the morning. And by 2:00 p. m. , they had only gotten two orders. So they made about $20 for all of that time working, which is significantly less than minimum wage. But of course, on a good night, sometimes they're making $17, $25 an hour. But then you start doing some of the math as you spend more time as a driver, the money spent on gas, the money spent on vehicle maintenance, what happens if you get injured and can no longer work, and the wages might not look as good as initially claimed. MCCAMMON: Do the prices the customers pay reflect the true cost of what we're getting? AKBAR: So one of the most interesting things about this is, that for the most part, these apps have not been profitable. A lot of venture capital money was injected into this industry because it was seen as a new Uber and Lyft possibility. Many cases, this means that the apps are operating at a loss and using the venture capital funds to subsidize some of the costs. But what we saw in our reporting was that basically the customer, even though they're paying fees and tips, they're actually getting a better deal than they might otherwise think. Delivery drivers and labor is like a huge cost for this industry, and it's not a cheap thing. So the way to get, you know, the kind of spread and reach across America that they have had is by subsidizing a lot of that wages. And it remains to be seen. We still don't really know whether the prices will increase for the consumer, but it's a possibility. MCCAMMON: Given what we've talked about when it comes to labor costs in particular and the cost to restaurants, you know, small businesses, what is the takeaway for consumers? I mean, should we skip the delivery apps and just walk in if we possibly can? AKBAR: That's not always a possibility for everybody, so I want to keep that in mind that these apps can provide some real accessibility. But a lot of the restaurants, they're asking customers that, hey, if you can, just call us in order and pick it up. We are going to see more of the profits of that order than if you order on the app. I do a mix personally. I think it's just fair to talk about what I do. I've seen that if I'm ordering on these apps, less of my money is going towards the restaurants. And if I'm going to support the restaurants, that's like one of the reasons why I'm ordering from a restaurant is to keep them in business, then it's probably not the best for them to order on an app. So I will often try to call them up myself and walk over, but I recognize that's not always a possibility as well. MCCAMMON: That was Ahmed Ali Akbar. He hosts the new mini-series \"Delivery Wars\" from \"Land Of The Giants\" podcast. Thank you so much for being with us. AKBAR: Thanks for having me.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-06-28-1011042126": {"title": "Facebook Gets Reprieve As Court Throws Out FTC, States' Antitrust Complaints : NPR", "url": "https://www.npr.org/2021/06/28/1011042126/facebook-gets-reprieve-as-court-throws-out-major-antitrust-complaints", "author": "No author found", "published_date": "2021-06-28", "content": "RACHEL MARTIN, HOST:  A federal judge dismissed two huge antitrust complaints against Facebook. It's a big win for that company. These suits were filed back in December - one by the federal government and one by most of the country's attorneys general. But this does not mean Facebook is out of the hot seat by any stretch of the imagination. For more, we are joined by NPR tech correspondent Shannon Bond. Just a note - Facebook is among NPR's financial supporters, but we cover them like any other company. Shannon, good morning. SHANNON BOND, BYLINE: Good morning, Rachel. MARTIN: These lawsuits were thrown out at a very early stage of the process, right? What happened? BOND: Right. Well, the Federal Trade Commission and these 48 attorneys general - they had accused Facebook of crushing its competition by buying up rivals, like Instagram and WhatsApp, and suffocating other companies by preventing them from accessing its platform and data. Facebook disputed these claims. It said the government hadn't shown any illegal behavior, and it asked the court to throw these suits out. And yesterday, the judge largely agreed with the company, and he tossed the complaints. MARTIN: So let's talk about that substance. What did the judge say was wrong with these cases? BOND: Well, of course, you know, we know Facebook boasts more than 2 billion users around the world. It's the largest social network. But Judge James Boasberg says the FTC just needs to show more evidence to back up its claim that under the law, Facebook has a monopoly. So he's given the FTC 30 days to file a new complaint addressing his concerns. Now, when it came to the states' case, the judge said their accusations about Instagram and WhatsApp just came too late. These were deals that were made years ago, right? Facebook bought Instagram in 2012. It bought WhatsApp in 2014. Now, people I talked to said that was kind of surprising. Back at the time these deals were made, the states didn't look at whether they were good or bad. And yet now the judge is saying it's too late to object. I spoke to Bill Kovacic. He's a former FTC chair and a law professor at George Washington. And he says these rulings show just how much of an uphill battle the government faces. BILL KOVACIC: You do not expect to get knocked out of the game in the very first inning, and the judge has given them a very sobering reminder of how hard it will be to succeed with this kind of very difficult case. MARTIN: So this is, no doubt, welcome news for Facebook. What are they saying? BOND: Well, it's - yes, it's definitely a temporary reprieve. A spokesman says the company is pleased that the court recognized the, quote, \"defects\" in the government's case, says Facebook competes fairly. Investors were also happy. The stock rose after the news. So Facebook's market cap has now passed $1 trillion for the first time. Very few companies can claim that. MARTIN: So if this is a temporary win, what's the government's next move? BOND: Well, the FTC and the state attorneys general say they're reviewing the judge's opinions. They're weighing their options. I think we can expect them to refile this complaint. They may also appeal this dismissal. Certainly, the FTC is not going to back down, Rachel. You know, it just got a new chairwoman, Lina Khan. She's an outspoken critic of Big Tech. And Kovacic, the former FTC chair I spoke with - he told me he sees two paths forward for the agency. KOVACIC: One is we're going to keep our foot on the accelerator when it comes to bringing tough cases. But the second path is to go to the Congress and say, see? This is why you have to do your job to give us better tools. BOND: And when it comes to Congress, right now the House Judiciary Committee is advancing a bipartisan package of bills. They seek to rein in Big Tech, curb some of what it can do and also beef up antimonopoly enforcement at agencies, including the FTC. And just yesterday, we heard from Democrats and Republicans on the committee. They're making that case. They're saying, you know, this is exactly why we need the kind of reforms we are proposing here, this dismissal itself. MARTIN: NPR tech correspondent Shannon Bond. Shannon, thank you for that. BOND: Thanks, Rachel. RACHEL MARTIN, HOST:   A federal judge dismissed two huge antitrust complaints against Facebook. It's a big win for that company. These suits were filed back in December - one by the federal government and one by most of the country's attorneys general. But this does not mean Facebook is out of the hot seat by any stretch of the imagination. For more, we are joined by NPR tech correspondent Shannon Bond. Just a note - Facebook is among NPR's financial supporters, but we cover them like any other company. Shannon, good morning. SHANNON BOND, BYLINE: Good morning, Rachel. MARTIN: These lawsuits were thrown out at a very early stage of the process, right? What happened? BOND: Right. Well, the Federal Trade Commission and these 48 attorneys general - they had accused Facebook of crushing its competition by buying up rivals, like Instagram and WhatsApp, and suffocating other companies by preventing them from accessing its platform and data. Facebook disputed these claims. It said the government hadn't shown any illegal behavior, and it asked the court to throw these suits out. And yesterday, the judge largely agreed with the company, and he tossed the complaints. MARTIN: So let's talk about that substance. What did the judge say was wrong with these cases? BOND: Well, of course, you know, we know Facebook boasts more than 2 billion users around the world. It's the largest social network. But Judge James Boasberg says the FTC just needs to show more evidence to back up its claim that under the law, Facebook has a monopoly. So he's given the FTC 30 days to file a new complaint addressing his concerns. Now, when it came to the states' case, the judge said their accusations about Instagram and WhatsApp just came too late. These were deals that were made years ago, right? Facebook bought Instagram in 2012. It bought WhatsApp in 2014. Now, people I talked to said that was kind of surprising. Back at the time these deals were made, the states didn't look at whether they were good or bad. And yet now the judge is saying it's too late to object. I spoke to Bill Kovacic. He's a former FTC chair and a law professor at George Washington. And he says these rulings show just how much of an uphill battle the government faces. BILL KOVACIC: You do not expect to get knocked out of the game in the very first inning, and the judge has given them a very sobering reminder of how hard it will be to succeed with this kind of very difficult case. MARTIN: So this is, no doubt, welcome news for Facebook. What are they saying? BOND: Well, it's - yes, it's definitely a temporary reprieve. A spokesman says the company is pleased that the court recognized the, quote, \"defects\" in the government's case, says Facebook competes fairly. Investors were also happy. The stock rose after the news. So Facebook's market cap has now passed $1 trillion for the first time. Very few companies can claim that. MARTIN: So if this is a temporary win, what's the government's next move? BOND: Well, the FTC and the state attorneys general say they're reviewing the judge's opinions. They're weighing their options. I think we can expect them to refile this complaint. They may also appeal this dismissal. Certainly, the FTC is not going to back down, Rachel. You know, it just got a new chairwoman, Lina Khan. She's an outspoken critic of Big Tech. And Kovacic, the former FTC chair I spoke with - he told me he sees two paths forward for the agency. KOVACIC: One is we're going to keep our foot on the accelerator when it comes to bringing tough cases. But the second path is to go to the Congress and say, see? This is why you have to do your job to give us better tools. BOND: And when it comes to Congress, right now the House Judiciary Committee is advancing a bipartisan package of bills. They seek to rein in Big Tech, curb some of what it can do and also beef up antimonopoly enforcement at agencies, including the FTC. And just yesterday, we heard from Democrats and Republicans on the committee. They're making that case. They're saying, you know, this is exactly why we need the kind of reforms we are proposing here, this dismissal itself. MARTIN: NPR tech correspondent Shannon Bond. Shannon, thank you for that. BOND: Thanks, Rachel.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-06-29-1011415134": {"title": "A Drone Is Swooping In To Assist Lifeguards On Lake Michigan : NPR", "url": "https://www.npr.org/2021/06/29/1011415134/a-drone-is-swooping-in-to-assist-lifeguards-on-lake-michigan", "author": "No author found", "published_date": "2021-06-29", "content": "ARI SHAPIRO, HOST:  Ocean swimming can be dangerous, and many beaches have lifeguards at the ready. But that's not the case for most beaches along the Great Lakes, some of which have treacherous riptides. So this year, one city in Michigan is getting creative with its water rescues. From Interlochen Public Radio, Dan Wanschura reports. DAN WANSCHURA, BYLINE: I'm on the pier at South Haven, which sits right on the shores of Lake Michigan. (SOUNDBITE OF WAVES SPLASHING)WANSCHURA: The city has two main public beaches and a popular lighthouse, an idyllic setting that attracts tens of thousands of tourists every summer. But swimming here can be dangerous because of rip currents and strong waves, and swimmers who are unfamiliar with them can get in trouble. ZACHARY KENREICH: It's the out-of-town people who come here on vacation and things like that that we need to work on educating. WANSCHURA: Zachary Kenreich is a paramedic with South Haven Area Emergency Services. Last year, his team responded to 23 water rescues on Lake Michigan. Three people drowned. That's when Kenreich started brainstorming on ways his department could cut down on its response time for people struggling in the water. And what he came up with was this. (SOUNDBITE OF DRONE BUZZING)WANSCHURA: Thanks to a $7,500 grant, the department was able to buy a special drone outfitted with some unique features. It's about the size of a Frisbee and is equipped with a camera. Dangling from the center of it is a small, folded-up flotation device, which can be released remotely by the drone operator. KENREICH: And I can drop it like that. WANSCHURA: Once it hits the water, a CO2 canister automatically inflates into a 3-foot-by-6-inch yellow flotation tube, big enough to support an adult. Drones dropping inflatables have been popular in Australia for a few years now. And this year, some beaches in California and Florida are also starting to deploy them. KENREICH: We have tested it multiple times. It's been working very well for us. And this doesn't change anything that we do normally. WANSCHURA: But not everyone is gung-ho about using these drones. Dave Benjamin heads the Great Lakes Surf Rescue Project, a water safety nonprofit group. DAVE BENJAMIN: This inflatable device would almost literally have to be dropped on their head or in their hands. WANSCHURA: If it's not, the victim might not be able to reach the flotation device, or waves could carry it to shore without them. Still, in South Haven, it normally takes emergency responders around eight minutes to get from the station to the beach and then to the victim in the water. That's pretty quick, but sometimes every second counts, and the drone can get help to the swimmer faster. It can fly up to 40 miles per hour and can reach a victim about three minutes quicker. Last year, there were 56 drownings in Lake Michigan, the most on record. B J FISHER: But it is a quick way to get a flotation device out to a victim. And it's very important that that is done as quickly as possible. WANSCHURA: B. J. Fisher is the director of health and safety at the American Lifeguard Association. He says integrating more technology into these rescue operations is a good thing, but installing more lifeguards at beaches would still be the best option. But that's a challenge for tourist cities like South Haven, which face staffing shortages and have liability concerns about using lifeguards. FISHER: It won't solve the problem, but it's better than nothing. WANSCHURA: With July right around the corner, more and more people are going to be getting in the Great Lakes. For the emergency services team here in South Haven, they hope this new drone means fun days at the beach won't turn tragic. For NPR News, I'm Dan Wanschura. (SOUNDBITE OF QUIET LIFE SONG, \"RECORD TIME\") ARI SHAPIRO, HOST:   Ocean swimming can be dangerous, and many beaches have lifeguards at the ready. But that's not the case for most beaches along the Great Lakes, some of which have treacherous riptides. So this year, one city in Michigan is getting creative with its water rescues. From Interlochen Public Radio, Dan Wanschura reports. DAN WANSCHURA, BYLINE: I'm on the pier at South Haven, which sits right on the shores of Lake Michigan. (SOUNDBITE OF WAVES SPLASHING) WANSCHURA: The city has two main public beaches and a popular lighthouse, an idyllic setting that attracts tens of thousands of tourists every summer. But swimming here can be dangerous because of rip currents and strong waves, and swimmers who are unfamiliar with them can get in trouble. ZACHARY KENREICH: It's the out-of-town people who come here on vacation and things like that that we need to work on educating. WANSCHURA: Zachary Kenreich is a paramedic with South Haven Area Emergency Services. Last year, his team responded to 23 water rescues on Lake Michigan. Three people drowned. That's when Kenreich started brainstorming on ways his department could cut down on its response time for people struggling in the water. And what he came up with was this. (SOUNDBITE OF DRONE BUZZING) WANSCHURA: Thanks to a $7,500 grant, the department was able to buy a special drone outfitted with some unique features. It's about the size of a Frisbee and is equipped with a camera. Dangling from the center of it is a small, folded-up flotation device, which can be released remotely by the drone operator. KENREICH: And I can drop it like that. WANSCHURA: Once it hits the water, a CO2 canister automatically inflates into a 3-foot-by-6-inch yellow flotation tube, big enough to support an adult. Drones dropping inflatables have been popular in Australia for a few years now. And this year, some beaches in California and Florida are also starting to deploy them. KENREICH: We have tested it multiple times. It's been working very well for us. And this doesn't change anything that we do normally. WANSCHURA: But not everyone is gung-ho about using these drones. Dave Benjamin heads the Great Lakes Surf Rescue Project, a water safety nonprofit group. DAVE BENJAMIN: This inflatable device would almost literally have to be dropped on their head or in their hands. WANSCHURA: If it's not, the victim might not be able to reach the flotation device, or waves could carry it to shore without them. Still, in South Haven, it normally takes emergency responders around eight minutes to get from the station to the beach and then to the victim in the water. That's pretty quick, but sometimes every second counts, and the drone can get help to the swimmer faster. It can fly up to 40 miles per hour and can reach a victim about three minutes quicker. Last year, there were 56 drownings in Lake Michigan, the most on record. B J FISHER: But it is a quick way to get a flotation device out to a victim. And it's very important that that is done as quickly as possible. WANSCHURA: B. J. Fisher is the director of health and safety at the American Lifeguard Association. He says integrating more technology into these rescue operations is a good thing, but installing more lifeguards at beaches would still be the best option. But that's a challenge for tourist cities like South Haven, which face staffing shortages and have liability concerns about using lifeguards. FISHER: It won't solve the problem, but it's better than nothing. WANSCHURA: With July right around the corner, more and more people are going to be getting in the Great Lakes. For the emergency services team here in South Haven, they hope this new drone means fun days at the beach won't turn tragic. For NPR News, I'm Dan Wanschura. (SOUNDBITE OF QUIET LIFE SONG, \"RECORD TIME\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-06-30-1011387838": {"title": "Change.Org Workers Form A Union, Giving Labor Activists Another Win In Tech  : NPR", "url": "https://www.npr.org/2021/06/30/1011387838/change-org-workers-form-a-union-giving-labor-activists-another-win-in-tech", "author": "No author found", "published_date": "2021-06-30", "content": "AILSA CHANG, HOST:  Change. org's online petitions draw attention to social issues around the world. But now the company's staff are turning the focus on themselves. Workers there have formed a union over issues like wages and racial inclusion, and labor activists working on the tech industry are hailing it as a victory. NPR's Bobby Allyn reports. BOBBY ALLYN, BYLINE: Erni Poche started as a temporary contractor at Change. org during the pandemic. Poche's job involved scouring the internet for campaigns that could go viral and providing resources to petition-creators. She was eventually hired full time, her salary just under $50,000 a year. ERNI POCHE: I live in New York City. That doesn't go a long way. ALLYN: To make ends meet, she also works as a part-time interpreter. Poche got to talking to others who had experience as contractors at the company. Everybody wanted better pay and more stability. POCHE: I definitely believe that Change. org can contribute to an equitable workplace, and that starts with paying folks a living wage. ALLYN: This push led Poche and about 70 of her colleagues to form a union under a unit of the Communications Workers of America, focused on people in media and tech. Sriya Sarkar is a content producer at Change. SRIYA SARKAR: We're drawing inspiration from the very people who come to our platform to create change in their communities. We're drawing inspiration from them by speaking up for the change we want to see internally. ALLYN: Sarkar says it took talking to more junior and lower-paid employees that there was a role for a union at Change. org. SARKAR: Unions, to me, honestly, were - I had always thought of them as something that, like, factory workers are involved with, and then the Pinkertons are sent in to bust kneecaps. I didn't think that unions were a relevant solution for tech companies. ALLYN: There has been a surge in employee activism in Silicon Valley in recent months. It's been driven by a desire to stand up for contractors in risky positions and employees wanting to speak out publicly about their company's role in society. That's resulted in a small union at Google and a handful of others at smaller tech companies. But this is how unionization at Change. org stands out - it has just around 200 employees, but it's now the largest tech company to not fight an employee union. The company instead agreed to voluntarily recognize it. That's according to Bec Wilson, a top executive at Change. BEC WILSON: It makes sense to me in these times of uncertainty that employees, including in tech and including our team, would seek the security and protection of unionization. ALLYN: The union says they will fight for a fair wage, especially for the more than 20% of its staff who are contractors. Another top priority for the union, something less traditional than pay and benefits - changing how the company handles race and diversity issues. Poche, who is a Black Latina, says the company has made strides recently in making diverse hires. But then, Poche says, they were the ones who took on online petitions involving race and the ones who had to educate the company's leadership about race. POCHE: We are not diversity, equity and inclusion specialists. ALLYN: Workers say they want to see more people of color in management positions. Though two of Change's six top executives are people of color, Sarkar says across management, Change has more work to do. SARKAR: Our leadership is overwhelmingly white. And it's 2021, and it's time to change that. ALLYN: Union officials and management will begin negotiating their first contract sometime this fall. Bobby Allyn, NPR News, San Francisco. (SOUNDBITE OF MUSIC) AILSA CHANG, HOST:   Change. org's online petitions draw attention to social issues around the world. But now the company's staff are turning the focus on themselves. Workers there have formed a union over issues like wages and racial inclusion, and labor activists working on the tech industry are hailing it as a victory. NPR's Bobby Allyn reports. BOBBY ALLYN, BYLINE: Erni Poche started as a temporary contractor at Change. org during the pandemic. Poche's job involved scouring the internet for campaigns that could go viral and providing resources to petition-creators. She was eventually hired full time, her salary just under $50,000 a year. ERNI POCHE: I live in New York City. That doesn't go a long way. ALLYN: To make ends meet, she also works as a part-time interpreter. Poche got to talking to others who had experience as contractors at the company. Everybody wanted better pay and more stability. POCHE: I definitely believe that Change. org can contribute to an equitable workplace, and that starts with paying folks a living wage. ALLYN: This push led Poche and about 70 of her colleagues to form a union under a unit of the Communications Workers of America, focused on people in media and tech. Sriya Sarkar is a content producer at Change. SRIYA SARKAR: We're drawing inspiration from the very people who come to our platform to create change in their communities. We're drawing inspiration from them by speaking up for the change we want to see internally. ALLYN: Sarkar says it took talking to more junior and lower-paid employees that there was a role for a union at Change. org. SARKAR: Unions, to me, honestly, were - I had always thought of them as something that, like, factory workers are involved with, and then the Pinkertons are sent in to bust kneecaps. I didn't think that unions were a relevant solution for tech companies. ALLYN: There has been a surge in employee activism in Silicon Valley in recent months. It's been driven by a desire to stand up for contractors in risky positions and employees wanting to speak out publicly about their company's role in society. That's resulted in a small union at Google and a handful of others at smaller tech companies. But this is how unionization at Change. org stands out - it has just around 200 employees, but it's now the largest tech company to not fight an employee union. The company instead agreed to voluntarily recognize it. That's according to Bec Wilson, a top executive at Change. BEC WILSON: It makes sense to me in these times of uncertainty that employees, including in tech and including our team, would seek the security and protection of unionization. ALLYN: The union says they will fight for a fair wage, especially for the more than 20% of its staff who are contractors. Another top priority for the union, something less traditional than pay and benefits - changing how the company handles race and diversity issues. Poche, who is a Black Latina, says the company has made strides recently in making diverse hires. But then, Poche says, they were the ones who took on online petitions involving race and the ones who had to educate the company's leadership about race. POCHE: We are not diversity, equity and inclusion specialists. ALLYN: Workers say they want to see more people of color in management positions. Though two of Change's six top executives are people of color, Sarkar says across management, Change has more work to do. SARKAR: Our leadership is overwhelmingly white. And it's 2021, and it's time to change that. ALLYN: Union officials and management will begin negotiating their first contract sometime this fall. Bobby Allyn, NPR News, San Francisco. (SOUNDBITE OF MUSIC)", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-07-01-1011899328": {"title": "Here's Why The #BlackTikTokStrike Is Happening : NPR", "url": "https://www.npr.org/2021/07/01/1011899328/black-tiktok-creators-are-on-strike-to-protest-a-lack-of-credit-for-their-work", "author": "No author found", "published_date": "2021-07-01", "content": "", "section": "Race", "disclaimer": ""}, "2021-07-01-1011907383": {"title": "New FTC Chair Lina Khan Wants To Redefine Monopoly Power For The Age Of Big Tech : NPR", "url": "https://www.npr.org/2021/07/01/1011907383/new-ftc-chair-lina-khan-wants-to-redefine-monopoly-power-for-the-age-of-big-tech", "author": "No author found", "published_date": "2021-07-01", "content": "", "section": "Technology", "disclaimer": ""}, "2021-07-02-1009925791": {"title": "Some Experts Think It's Time For An International Cyber Treaty : NPR", "url": "https://www.npr.org/2021/07/02/1009925791/hacks-are-prompting-calls-for-a-cyber-agreement-but-reaching-one-would-be-tough", "author": "No author found", "published_date": "2021-07-02", "content": "", "section": "National Security", "disclaimer": ""}, "2021-07-03-1012849198": {"title": "A New Ransomware Attack Hits Hundreds Of U.S. Companies : NPR", "url": "https://www.npr.org/2021/07/03/1012849198/ransomware-cyber-attack-revil-attack-huntress-labs", "author": "No author found", "published_date": "2021-07-03", "content": "", "section": "Technology", "disclaimer": ""}, "2021-07-05-1013166252": {"title": "Andy Jassy To Replace Jeff Bezos As Amazon CEO At Critical Time : NPR", "url": "https://www.npr.org/2021/07/05/1013166252/jeff-bezos-built-amazon-27-years-ago-he-now-steps-down-as-ceo-at-critical-time", "author": "No author found", "published_date": "2021-07-05", "content": "AILSA CHANG, HOST:  Jeff Bezos stepped down today as CEO of Amazon. Bezos will stay on as executive chairman of the company, but his longtime deputy, Andy Jassy, will handle day-to-day responsibilities at Amazon. NPR tech reporter Bobby Allyn joins us now to explain the significance of this transition. And we should note that Amazon is among NPR's financial supporters. Hi, Bobby. BOBBY ALLYN, BYLINE: Hey. What's up, Ailsa? CHANG: Hey. So remind us; why is Jeff Bezos stepping away now as CEO? ALLYN: Bezos founded Amazon 27 years ago in a garage in Bellevue, Wash. And this was a time, remember, when e-commerce was in its infancy. And frankly, many people back then were even afraid to buy things online with credit cards. Obviously, a lot has changed since then, and Amazon is now the largest online retailer, right? And Bezos, as we know, is the richest man on the planet. But, yeah, Bezos says he now wants to take a back seat. So he's still going to have pretty sizable power at the company as executive chairman. But now he's going to focus on side projects like climate change philanthropy and his rocket company, Blue Origin. Speaking of, in two weeks, Bezos and his brother Mark will be blasting off to the edge of space. . . CHANG: Right. ALLYN: . . . In one of the very rockets. Yeah. I talked to Bloomberg journalist Brad Stone about this Bezos transition. He's written two books on Amazon. BRAD STONE: And so look. I mean, this is someone who is obviously out to pursue his passions, have adventures and enjoy the extravagant wealth without compunction that he has accumulated. So I do think he'll be drifting further and further away from Amazon. CHANG: Literally into space. Well, what do we know about Bezos' replacement, Andy Jassy? Tell us more about him. ALLYN: Yeah. Jassy has long been Bezos' protege. He joined the company in 1997. And until today, Jesse was the top executive of Amazon Web Services. It's the company's very, very profitable cloud computing arm. But he's very different than Bezos. I mean, Bezos is described as being hotheaded. He has angry outbursts in meetings. Jassy is more calm. He's mild-mannered. He's soft-spoken. He's been described, Ailsa, as just much more approachable and easygoing than Bezos. And you know what? He's really unknown in Silicon Valley, unlike Bezos, who, as we know, is the constant target of criticism and controversy. And, you know, when the pandemic brought record profits for Amazon, scrutiny of the company intensified. Regulators here in the U. S. and in Europe are investigating Amazon's business practices. We have heard many stories about workers who say they've been mistreated at Amazon. Author Stone told me, you know, moving Jassy to CEO is perhaps aimed at improving Amazon's image in the world right now when so many are questioning the company's growth-at-all-costs strategy. STONE: We're wondering what the cost is not just to those workers but to society. So I think, yeah, Jassy has to kind of make Amazon a more empathetic company, a friendlier company. He has to find Amazon's heart. CHANG: Finding Amazon's heart. Well, I don't know how much lawmakers right now care about how empathetic Amazon is. Many of them think the company's anti-competitive. They're pushing through legislation to address that. Tell us; how is that going? ALLYN: Yeah, right. So there is a package of bipartisan bills moving through Congress that's aimed at Big Tech's power. And if passed, they really would remake how Amazon operates. I mean, one of the proposals would force Amazon to spin off its private label from its online marketplace. You know, Ailsa, critics have long said that Amazon gives its own products a leg up. Lawmakers are just really, really homing in on whether Amazon's business practices are anti-competitive. And we'll see what happens with this group of bills. But it's really just one group of proposals. . . CHANG: Right. ALLYN: . . . That are aimed at, you know, Amazon's troubles. There's a lot more regulatory and legal challenges ahead, and now it will be up to Jassy to call the shots on how Amazon will respond. CHANG: That is NPR's Bobby Allyn. Thank you, Bobby. ALLYN: Thanks, Ailsa. AILSA CHANG, HOST:   Jeff Bezos stepped down today as CEO of Amazon. Bezos will stay on as executive chairman of the company, but his longtime deputy, Andy Jassy, will handle day-to-day responsibilities at Amazon. NPR tech reporter Bobby Allyn joins us now to explain the significance of this transition. And we should note that Amazon is among NPR's financial supporters. Hi, Bobby. BOBBY ALLYN, BYLINE: Hey. What's up, Ailsa? CHANG: Hey. So remind us; why is Jeff Bezos stepping away now as CEO? ALLYN: Bezos founded Amazon 27 years ago in a garage in Bellevue, Wash. And this was a time, remember, when e-commerce was in its infancy. And frankly, many people back then were even afraid to buy things online with credit cards. Obviously, a lot has changed since then, and Amazon is now the largest online retailer, right? And Bezos, as we know, is the richest man on the planet. But, yeah, Bezos says he now wants to take a back seat. So he's still going to have pretty sizable power at the company as executive chairman. But now he's going to focus on side projects like climate change philanthropy and his rocket company, Blue Origin. Speaking of, in two weeks, Bezos and his brother Mark will be blasting off to the edge of space. . . CHANG: Right. ALLYN: . . . In one of the very rockets. Yeah. I talked to Bloomberg journalist Brad Stone about this Bezos transition. He's written two books on Amazon. BRAD STONE: And so look. I mean, this is someone who is obviously out to pursue his passions, have adventures and enjoy the extravagant wealth without compunction that he has accumulated. So I do think he'll be drifting further and further away from Amazon. CHANG: Literally into space. Well, what do we know about Bezos' replacement, Andy Jassy? Tell us more about him. ALLYN: Yeah. Jassy has long been Bezos' protege. He joined the company in 1997. And until today, Jesse was the top executive of Amazon Web Services. It's the company's very, very profitable cloud computing arm. But he's very different than Bezos. I mean, Bezos is described as being hotheaded. He has angry outbursts in meetings. Jassy is more calm. He's mild-mannered. He's soft-spoken. He's been described, Ailsa, as just much more approachable and easygoing than Bezos. And you know what? He's really unknown in Silicon Valley, unlike Bezos, who, as we know, is the constant target of criticism and controversy. And, you know, when the pandemic brought record profits for Amazon, scrutiny of the company intensified. Regulators here in the U. S. and in Europe are investigating Amazon's business practices. We have heard many stories about workers who say they've been mistreated at Amazon. Author Stone told me, you know, moving Jassy to CEO is perhaps aimed at improving Amazon's image in the world right now when so many are questioning the company's growth-at-all-costs strategy. STONE: We're wondering what the cost is not just to those workers but to society. So I think, yeah, Jassy has to kind of make Amazon a more empathetic company, a friendlier company. He has to find Amazon's heart. CHANG: Finding Amazon's heart. Well, I don't know how much lawmakers right now care about how empathetic Amazon is. Many of them think the company's anti-competitive. They're pushing through legislation to address that. Tell us; how is that going? ALLYN: Yeah, right. So there is a package of bipartisan bills moving through Congress that's aimed at Big Tech's power. And if passed, they really would remake how Amazon operates. I mean, one of the proposals would force Amazon to spin off its private label from its online marketplace. You know, Ailsa, critics have long said that Amazon gives its own products a leg up. Lawmakers are just really, really homing in on whether Amazon's business practices are anti-competitive. And we'll see what happens with this group of bills. But it's really just one group of proposals. . . CHANG: Right. ALLYN: . . . That are aimed at, you know, Amazon's troubles. There's a lot more regulatory and legal challenges ahead, and now it will be up to Jassy to call the shots on how Amazon will respond. CHANG: That is NPR's Bobby Allyn. Thank you, Bobby. ALLYN: Thanks, Ailsa.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-07-05-1011700976": {"title": "The Food Supply Chain May Be Vulnerable To Cyberattacks : NPR", "url": "https://www.npr.org/2021/07/05/1011700976/the-food-industry-may-be-finally-paying-attention-to-its-weakness-to-cyberattack", "author": "No author found", "published_date": "2021-07-05", "content": "AILSA CHANG, HOST:  A new cyberattack has shut down computers at thousands of small companies around the world. The cybercriminals behind it are demanding that companies pay a ransom in order to get their computers and their data back. The attack is similar to the one that recently hit the world's biggest meat processor, raising concerns about the U. S. food supply. Some critics say industry consolidation has made those supply chains more vulnerable. NPR's Dan Charles has the story. DAN CHARLES, BYLINE: The company JBS is a giant in the meat industry, with operations around the globe. When hackers took some of its computers hostage a month ago, JBS shut down several processing plants in the U. S. and Australia and then paid the ransom of $11 million. But it downplayed the impact. The company says it lost less than a day's worth of production. Yet John Hoffman, a senior research fellow at the Food Protection and Defense Institute at the University of Minnesota, says it's had a longer-lasting effect on the thinking of some industry executives. JOHN HOFFMAN: People just didn't accept that it was that big a risk. I think that's changed today. I've already heard from folks in government. It's changed. People are looking at this, saying, OK, we've got to do something. CHARLES: Hoffman says many food companies are still using outdated computers that aren't secure, including in processing plants. He remembers visiting one plant - he won't say at which company - when he noticed a supervisor sitting at a computer on the factory floor, monitoring production. Hoffman could see that the operating system was very old - Windows 98. HOFFMAN: And I'm walking through with the manager of the plant and one of the officers of the company, and I said, gee, is any of this connected to the internet? And they said, oh, no, no, this isn't connect to the internet. CHARLES: Well, in fact, it was. So employees could log in from home, monitor that equipment, even shut it down or change the settings if they needed to. HOFFMAN: I mean, right there, I mean, that's the definition of vulnerability. CHARLES: And Hoffman says if those computers are vulnerable, so is the food itself. HOFFMAN: They're controlling valves and monitoring temperatures and controlling mixes of additives to food. These are part of food safety. CHARLES: Hoffman has been pushing for the government to enforce computer security standards in the food industry the same way it enforces food safety standards. He thinks the JBS attack is convincing more people that this would be a good idea. Other longtime critics of the meat industry, like Diana Moss, president of the American Antitrust Institute, are drawing an additional lesson from the attack. Moss says this industry is too concentrated in the hands of too few companies, so a problem in just one company can disrupt supplies for millions of consumers. DIANA MOSS: What we have in the meat supply chain in beef is a cartel. CHARLES: Just four companies, including JBS, slaughter about 85% of the country's fed cattle, those that are raised for beef. Their slaughterhouses are enormous. Moss says a small number of companies also dominate chicken production, flour milling, other kinds of food processing. MOSS: So when you only have a few firms in this critical midstream part of the supply chain - processing, manufacturing - the supply chain becomes very unstable. It lacks resiliency and is very subject to sort of shocks to the system. HOFFMAN: The North American Meat Institute, though, which represents meat producers like JBS, says recent events actually show that the existing system is already resilient. The cyberattack on JBS didn't cause much disruption, and the Meat Institute says its member companies reacted immediately to that attack and reviewed their own computer systems to make sure they were secure. Dan Charles, NPR News. AILSA CHANG, HOST:   A new cyberattack has shut down computers at thousands of small companies around the world. The cybercriminals behind it are demanding that companies pay a ransom in order to get their computers and their data back. The attack is similar to the one that recently hit the world's biggest meat processor, raising concerns about the U. S. food supply. Some critics say industry consolidation has made those supply chains more vulnerable. NPR's Dan Charles has the story. DAN CHARLES, BYLINE: The company JBS is a giant in the meat industry, with operations around the globe. When hackers took some of its computers hostage a month ago, JBS shut down several processing plants in the U. S. and Australia and then paid the ransom of $11 million. But it downplayed the impact. The company says it lost less than a day's worth of production. Yet John Hoffman, a senior research fellow at the Food Protection and Defense Institute at the University of Minnesota, says it's had a longer-lasting effect on the thinking of some industry executives. JOHN HOFFMAN: People just didn't accept that it was that big a risk. I think that's changed today. I've already heard from folks in government. It's changed. People are looking at this, saying, OK, we've got to do something. CHARLES: Hoffman says many food companies are still using outdated computers that aren't secure, including in processing plants. He remembers visiting one plant - he won't say at which company - when he noticed a supervisor sitting at a computer on the factory floor, monitoring production. Hoffman could see that the operating system was very old - Windows 98. HOFFMAN: And I'm walking through with the manager of the plant and one of the officers of the company, and I said, gee, is any of this connected to the internet? And they said, oh, no, no, this isn't connect to the internet. CHARLES: Well, in fact, it was. So employees could log in from home, monitor that equipment, even shut it down or change the settings if they needed to. HOFFMAN: I mean, right there, I mean, that's the definition of vulnerability. CHARLES: And Hoffman says if those computers are vulnerable, so is the food itself. HOFFMAN: They're controlling valves and monitoring temperatures and controlling mixes of additives to food. These are part of food safety. CHARLES: Hoffman has been pushing for the government to enforce computer security standards in the food industry the same way it enforces food safety standards. He thinks the JBS attack is convincing more people that this would be a good idea. Other longtime critics of the meat industry, like Diana Moss, president of the American Antitrust Institute, are drawing an additional lesson from the attack. Moss says this industry is too concentrated in the hands of too few companies, so a problem in just one company can disrupt supplies for millions of consumers. DIANA MOSS: What we have in the meat supply chain in beef is a cartel. CHARLES: Just four companies, including JBS, slaughter about 85% of the country's fed cattle, those that are raised for beef. Their slaughterhouses are enormous. Moss says a small number of companies also dominate chicken production, flour milling, other kinds of food processing. MOSS: So when you only have a few firms in this critical midstream part of the supply chain - processing, manufacturing - the supply chain becomes very unstable. It lacks resiliency and is very subject to sort of shocks to the system. HOFFMAN: The North American Meat Institute, though, which represents meat producers like JBS, says recent events actually show that the existing system is already resilient. The cyberattack on JBS didn't cause much disruption, and the Meat Institute says its member companies reacted immediately to that attack and reviewed their own computer systems to make sure they were secure. Dan Charles, NPR News.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-07-05-1013117515": {"title": "Scale, Details Of Massive Kaseya Ransomware Attack Emerge : NPR", "url": "https://www.npr.org/2021/07/05/1013117515/scale-details-of-massive-kaseya-ransomware-attack-emerge", "author": "No author found", "published_date": "2021-07-05", "content": "", "section": "Technology", "disclaimer": ""}, "2021-07-06-1013420036": {"title": "Pentagon Scraps $10 Billion Contract With Microsoft, Bitterly Contested By Amazon : NPR", "url": "https://www.npr.org/2021/07/06/1013420036/pentagon-scraps-10-billion-contract-with-microsoft-bitterly-contested-by-amazon", "author": "No author found", "published_date": "2021-07-06", "content": "", "section": "Business", "disclaimer": ""}, "2021-07-06-1013266760": {"title": "Cyberattack On Kaseya Hit Up To 1,500 Organizations Worldwide : NPR", "url": "https://www.npr.org/2021/07/06/1013266760/biden-is-pressured-to-take-action-after-latest-ransomware-attack", "author": "No author found", "published_date": "2021-07-06", "content": "LEILA FADEL, HOST:  Thousands of companies are still working to recover their data after the single biggest global ransomware attack on record. The cyberattack has hit a broad range of businesses and public agencies in at least 17 countries worldwide, medical offices to grocery stores. Hackers went after business software company Kaseya. The cyberattack then trickled down to about 60 of Kaseya's clients. An affiliate of the REvil ransomware gang is behind the attack. The group is believed to be Russia-based and was also behind the hacking of meat processor JBS back in May. President Biden said this weekend that U. S. intelligence agencies are still working to pinpoint the source of the cyberattack. (SOUNDBITE OF ARCHIVED RECORDING)PRESIDENT JOE BIDEN: If it is, either with the knowledge of and-or the consequence of Russia, then I told Putin we will respond. FADEL: Dmitri Alperovitch is a cybersecurity expert. He's the co-founder and former chief technology officer of the cybersecurity company CrowdStrike. Dmitri, welcome. DMITRI ALPEROVITCH: Thanks for having me. FADEL: So the U. S. and other countries are still trying to figure out the scope of this massive cyberattack. And I want to ask you how this attack is different than what we've seen before. ALPEROVITCH: Well, the scale and scope of this attack is really unprecedented. The company Kaseya, whose software was compromised through this attack, now estimates that there are about 1,500 organizations worldwide that have been affected. Now, most of these organizations will be small and medium businesses. That's their bread and butter. And this will be dentist offices, car dealers, libraries, schools, grocery chains in Sweden and the like. FADEL: Now, why choose a company like Kaseya? ALPEROVITCH: Well, it really gives you unprecedented reach. So the hackers found what is known as a zero-day vulnerability, a previously unknown vulnerability, in Kaseya's product, and then they literally scanned the internet to find anyone that's using that software and started compromising each and every one of the customers that had that software on the internet. Now, it turns out that many of Kaseya's customers are actually not end users but managed service providers, companies that manage networks for smaller organizations. And as a result of hitting those companies, those managed service providers, they had access to hundreds of victims within each. FADEL: Wow. Now, these hackers are believed to be based in Russia and to operate with impunity. And last month, President Biden told Russian President Putin that these ransomware attacks have to stop. What does this latest attack tell you about Putin's response? ALPEROVITCH: Well, one thing is clear that, at best, Putin is dragging his feet and is not dealing with this issue. It is quite clear that the Russian intelligence services, Russian law enforcement, is capable of identifying these people and arresting them and prosecuting them. They're not yet doing that. And it is time, I believe, for President Biden to deliver an ultimatum to Putin that either these attacks will stop or the U. S. will start enforcing very severe sanctions against the Russian energy sector. FADEL: So that, you think, is the most effective way for the U. S. to respond? ALPEROVITCH: I think a message needs to be sent that this is something that is urgent and important for ordinary Americans, and President Biden, who is advocating foreign policy for the middle class, has to respond forcefully. FADEL: Now, the hackers are offering a universal decryptor for everyone's data if someone steps up and pays $70 million. Why offer something like that? ALPEROVITCH: Well, clearly, they think that perhaps they can pressure Kaseya into paying that amount, given that their software was responsible for this breach. And they realize that going to 1,500 organizations and trying to get a ransom from each one is going to be very difficult because many of these small businesses have been hit so hard during the pandemic and will be hard-pressed to find money to pay a significant ransom to these criminals. FADEL: Now, did REvil bite off more than it could chew, so to speak, by going after so many at the same time? ALPEROVITCH: I don't think so. I think it remains to be seen whether this action crossed a red line and will suffer a severe response. But it's clear that the U. S. government needs to engage in a serious discussion about how we - do we go after these cybercriminals using our intelligence community, using our Cyber Command capabilities, to try to disrupt their operations, just like we do against terrorist groups. FADEL: Now, is there proof that there are links between this gang and the Russian government? ALPEROVITCH: There is no proof of that, and in fact, it's probably unlikely that the Russian government is working with them or is directing them in any way. But it's pretty clear, with 20 years of history of cybercriminals operating freely from Russia without any harassment from Russian law enforcement - even though the U. S. government and other governments have provided detailed information to Russian law enforcement about these criminals. So at a minimum, they're providing safe harbor to them. FADEL: In the few seconds we do have left, what can companies and agencies do to protect themselves in an attack like this, against an attack like this? ALPEROVITCH: Well, the first thing that everyone needs to assume is that someone is going to come after you. The days of when you can assume that, if you're not a high-profile organization, you will not be hacked are over. FADEL: Dmitri Alperovitch is the chairman of the think tank Silverado Policy Accelerator. Thank you for taking the time. ALPEROVITCH: Thank you. LEILA FADEL, HOST:   Thousands of companies are still working to recover their data after the single biggest global ransomware attack on record. The cyberattack has hit a broad range of businesses and public agencies in at least 17 countries worldwide, medical offices to grocery stores. Hackers went after business software company Kaseya. The cyberattack then trickled down to about 60 of Kaseya's clients. An affiliate of the REvil ransomware gang is behind the attack. The group is believed to be Russia-based and was also behind the hacking of meat processor JBS back in May. President Biden said this weekend that U. S. intelligence agencies are still working to pinpoint the source of the cyberattack. (SOUNDBITE OF ARCHIVED RECORDING) PRESIDENT JOE BIDEN: If it is, either with the knowledge of and-or the consequence of Russia, then I told Putin we will respond. FADEL: Dmitri Alperovitch is a cybersecurity expert. He's the co-founder and former chief technology officer of the cybersecurity company CrowdStrike. Dmitri, welcome. DMITRI ALPEROVITCH: Thanks for having me. FADEL: So the U. S. and other countries are still trying to figure out the scope of this massive cyberattack. And I want to ask you how this attack is different than what we've seen before. ALPEROVITCH: Well, the scale and scope of this attack is really unprecedented. The company Kaseya, whose software was compromised through this attack, now estimates that there are about 1,500 organizations worldwide that have been affected. Now, most of these organizations will be small and medium businesses. That's their bread and butter. And this will be dentist offices, car dealers, libraries, schools, grocery chains in Sweden and the like. FADEL: Now, why choose a company like Kaseya? ALPEROVITCH: Well, it really gives you unprecedented reach. So the hackers found what is known as a zero-day vulnerability, a previously unknown vulnerability, in Kaseya's product, and then they literally scanned the internet to find anyone that's using that software and started compromising each and every one of the customers that had that software on the internet. Now, it turns out that many of Kaseya's customers are actually not end users but managed service providers, companies that manage networks for smaller organizations. And as a result of hitting those companies, those managed service providers, they had access to hundreds of victims within each. FADEL: Wow. Now, these hackers are believed to be based in Russia and to operate with impunity. And last month, President Biden told Russian President Putin that these ransomware attacks have to stop. What does this latest attack tell you about Putin's response? ALPEROVITCH: Well, one thing is clear that, at best, Putin is dragging his feet and is not dealing with this issue. It is quite clear that the Russian intelligence services, Russian law enforcement, is capable of identifying these people and arresting them and prosecuting them. They're not yet doing that. And it is time, I believe, for President Biden to deliver an ultimatum to Putin that either these attacks will stop or the U. S. will start enforcing very severe sanctions against the Russian energy sector. FADEL: So that, you think, is the most effective way for the U. S. to respond? ALPEROVITCH: I think a message needs to be sent that this is something that is urgent and important for ordinary Americans, and President Biden, who is advocating foreign policy for the middle class, has to respond forcefully. FADEL: Now, the hackers are offering a universal decryptor for everyone's data if someone steps up and pays $70 million. Why offer something like that? ALPEROVITCH: Well, clearly, they think that perhaps they can pressure Kaseya into paying that amount, given that their software was responsible for this breach. And they realize that going to 1,500 organizations and trying to get a ransom from each one is going to be very difficult because many of these small businesses have been hit so hard during the pandemic and will be hard-pressed to find money to pay a significant ransom to these criminals. FADEL: Now, did REvil bite off more than it could chew, so to speak, by going after so many at the same time? ALPEROVITCH: I don't think so. I think it remains to be seen whether this action crossed a red line and will suffer a severe response. But it's clear that the U. S. government needs to engage in a serious discussion about how we - do we go after these cybercriminals using our intelligence community, using our Cyber Command capabilities, to try to disrupt their operations, just like we do against terrorist groups. FADEL: Now, is there proof that there are links between this gang and the Russian government? ALPEROVITCH: There is no proof of that, and in fact, it's probably unlikely that the Russian government is working with them or is directing them in any way. But it's pretty clear, with 20 years of history of cybercriminals operating freely from Russia without any harassment from Russian law enforcement - even though the U. S. government and other governments have provided detailed information to Russian law enforcement about these criminals. So at a minimum, they're providing safe harbor to them. FADEL: In the few seconds we do have left, what can companies and agencies do to protect themselves in an attack like this, against an attack like this? ALPEROVITCH: Well, the first thing that everyone needs to assume is that someone is going to come after you. The days of when you can assume that, if you're not a high-profile organization, you will not be hacked are over. FADEL: Dmitri Alperovitch is the chairman of the think tank Silverado Policy Accelerator. Thank you for taking the time. ALPEROVITCH: Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-07-07-1013934643": {"title": "Google Play Store Faces Lawsuit From More Than 30 States : NPR", "url": "https://www.npr.org/2021/07/07/1013934643/more-than-30-states-sue-google-over-extravagant-fees-in-google-play-store", "author": "No author found", "published_date": "2021-07-07", "content": "", "section": "Technology", "disclaimer": ""}, "2021-07-07-1013898752": {"title": "'Speedrunners' Are Beating Video Games In Record Time For Charity : NPR", "url": "https://www.npr.org/2021/07/07/1013898752/speedrunners-are-beating-video-games-in-record-time-for-charity", "author": "No author found", "published_date": "2021-07-07", "content": "ARI SHAPIRO, HOST:  Many people know the satisfaction of beating a video game after many hours, even weeks of playing, and some know the satisfaction of beating games in a matter of minutes. PABLO MUNOZ-SNYDER: Speedrunning is completing a video game from start to finish as quickly as possible. MARY LOUISE KELLY, HOST:  That is Pablo Munoz-Snyder, who has a different online name and this humble take on his speedrunning skills. MUNOZ-SNYDER: You should introduce me as Dayoman, the very cool and beautiful world record-holder for Spyro 1. KELLY: He's taking part in this summer's semi-annual Games Done Quick event. It's a roster of speedrunners playing their favorite games as quick as they can. SHAPIRO: And they've got a big audience, too. Games Done Quick raises millions of dollars for charity. This summer, proceeds go to Doctors Without Borders. Games Done Quick Director Kasumi Yogi says the event has grown a lot in recent years. KASUMI YOGI: For a lot of the runners, it became an opportunity for them to make their passion their career. KELLY: And Dayoman is grateful. His passion for Spyro, which he's been playing since age 3, by the way, has given him this spotlight. MUNOZ-SNYDER: Coming full circle, like, you just get to play the game in front of a whole audience of people, and it's really special. You know what I'm saying? SHAPIRO: And in case you're wondering, Spyro can typically take six hours to beat. Dayoman has done it in 37 minutes and 57 seconds. (SOUNDBITE OF JON BATISTE'S \"GREEN HILL ZONE\") ARI SHAPIRO, HOST:   Many people know the satisfaction of beating a video game after many hours, even weeks of playing, and some know the satisfaction of beating games in a matter of minutes. PABLO MUNOZ-SNYDER: Speedrunning is completing a video game from start to finish as quickly as possible. MARY LOUISE KELLY, HOST:   That is Pablo Munoz-Snyder, who has a different online name and this humble take on his speedrunning skills. MUNOZ-SNYDER: You should introduce me as Dayoman, the very cool and beautiful world record-holder for Spyro 1. KELLY: He's taking part in this summer's semi-annual Games Done Quick event. It's a roster of speedrunners playing their favorite games as quick as they can. SHAPIRO: And they've got a big audience, too. Games Done Quick raises millions of dollars for charity. This summer, proceeds go to Doctors Without Borders. Games Done Quick Director Kasumi Yogi says the event has grown a lot in recent years. KASUMI YOGI: For a lot of the runners, it became an opportunity for them to make their passion their career. KELLY: And Dayoman is grateful. His passion for Spyro, which he's been playing since age 3, by the way, has given him this spotlight. MUNOZ-SNYDER: Coming full circle, like, you just get to play the game in front of a whole audience of people, and it's really special. You know what I'm saying? SHAPIRO: And in case you're wondering, Spyro can typically take six hours to beat. Dayoman has done it in 37 minutes and 57 seconds. (SOUNDBITE OF JON BATISTE'S \"GREEN HILL ZONE\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-07-07-1013760153": {"title": "Trump Sues Facebook, YouTube And Twitter For Kicking Him Off Their Platforms : NPR", "url": "https://www.npr.org/2021/07/07/1013760153/donald-trump-says-he-is-suing-facebook-google-and-twitter-for-alleged-censorship", "author": "No author found", "published_date": "2021-07-07", "content": "NOEL KING, HOST:  Former President Donald Trump was kicked off of Facebook, Twitter and YouTube, which Google owns, after his supporters attacked the U. S. Capitol on January 6. Now he is suing those companies. (SOUNDBITE OF ARCHIVED RECORDING)DONALD TRUMP: Our case will prove this censorship is unlawful. It's unconstitutional. And it's completely un-American. KING: NPR's Shannon Bond reports on the escalation of Trump's fight with Silicon Valley. And I should note that Facebook and Google are among NPR's financial supporters. SHANNON BOND, BYLINE: Donald Trump says this is about more than his ban from social media. He's filed class action lawsuits seeking to represent other conservatives whom he says the companies have mistreated. (SOUNDBITE OF ARCHIVED RECORDING)TRUMP: We're demanding an end to the shadow banning, a stop to the silencing and a stop to the blacklisting, banishing and canceling that you know so well. BOND: Conservatives frequently claim they're being censored by big tech even though there's little evidence to support that. Trump wants the court to order Facebook, Twitter and YouTube to give him and his fellow plaintiffs their accounts back. And the federal law that protects tech companies from being sued over their content decisions, Trump wants that declared unconstitutional. He says it's a battle over the First Amendment. (SOUNDBITE OF ARCHIVED RECORDING)TRUMP: And in the end, I am confident that we will achieve a historic victory for American freedom, and at the same time, freedom of speech. BOND: But legal experts say he has that argument all wrong because the First Amendment protects speech from government restrictions, not private companies. Eric Goldman, a law professor at Santa Clara University, has studied cases just like this one. ERIC GOLDMAN: The message is quite clear. The plaintiffs never win. They lose. And they usually lose early. BOND: Goldman says courts routinely reject the argument that social networks like Facebook and its CEO, Mark Zuckerberg, are acting like an arm of the government by restricting what users can post. GOLDMAN: It's like saying Mark Zuckerberg works for the government. I think we all know better than that. And so these arguments just really don't work. They're just not credible. BOND: Before he was banned, Trump relied on Twitter to speak directly to the public and on Facebook to raise money. Shortly after announcing the lawsuits, the former president began texting and emailing supporters, asking them for donations. Shannon Bond, NPR News. (SOUNDBITE OF L'INDECIS' \"STAYING THERE\") NOEL KING, HOST:   Former President Donald Trump was kicked off of Facebook, Twitter and YouTube, which Google owns, after his supporters attacked the U. S. Capitol on January 6. Now he is suing those companies. (SOUNDBITE OF ARCHIVED RECORDING) DONALD TRUMP: Our case will prove this censorship is unlawful. It's unconstitutional. And it's completely un-American. KING: NPR's Shannon Bond reports on the escalation of Trump's fight with Silicon Valley. And I should note that Facebook and Google are among NPR's financial supporters. SHANNON BOND, BYLINE: Donald Trump says this is about more than his ban from social media. He's filed class action lawsuits seeking to represent other conservatives whom he says the companies have mistreated. (SOUNDBITE OF ARCHIVED RECORDING) TRUMP: We're demanding an end to the shadow banning, a stop to the silencing and a stop to the blacklisting, banishing and canceling that you know so well. BOND: Conservatives frequently claim they're being censored by big tech even though there's little evidence to support that. Trump wants the court to order Facebook, Twitter and YouTube to give him and his fellow plaintiffs their accounts back. And the federal law that protects tech companies from being sued over their content decisions, Trump wants that declared unconstitutional. He says it's a battle over the First Amendment. (SOUNDBITE OF ARCHIVED RECORDING) TRUMP: And in the end, I am confident that we will achieve a historic victory for American freedom, and at the same time, freedom of speech. BOND: But legal experts say he has that argument all wrong because the First Amendment protects speech from government restrictions, not private companies. Eric Goldman, a law professor at Santa Clara University, has studied cases just like this one. ERIC GOLDMAN: The message is quite clear. The plaintiffs never win. They lose. And they usually lose early. BOND: Goldman says courts routinely reject the argument that social networks like Facebook and its CEO, Mark Zuckerberg, are acting like an arm of the government by restricting what users can post. GOLDMAN: It's like saying Mark Zuckerberg works for the government. I think we all know better than that. And so these arguments just really don't work. They're just not credible. BOND: Before he was banned, Trump relied on Twitter to speak directly to the public and on Facebook to raise money. Shortly after announcing the lawsuits, the former president began texting and emailing supporters, asking them for donations. Shannon Bond, NPR News. (SOUNDBITE OF L'INDECIS' \"STAYING THERE\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-07-09-1014415021": {"title": "Buying Hearing Aids Or Fixing Your Phone Could Get Easier With New Biden Rules : NPR", "url": "https://www.npr.org/2021/07/09/1014415021/how-new-biden-rules-could-make-it-easier-to-buy-hearing-aids-or-fix-your-phone", "author": "No author found", "published_date": "2021-07-09", "content": "NOEL KING, HOST:  President Biden will issue an executive order today to promote competition across a bunch of industries, including farming, airlines, prescription drugs and Internet service providers. NPR White House correspondent Asma Khalid got an early look at the executive order and is with us now. Good morning, Asma. ASMA KHALID, BYLINE: Good morning, Noel. KING: So this order is very consumer and worker-oriented. KHALID: That's right. The White House believes that it'll lead to lower prices for consumers, better wages for employees and, eventually, more durable, long-term economic growth. The goal is to tilt markets more in favor of workers and consumers over big, powerful companies. And in total, it includes some 20 - 72 - I'm sorry - different initiatives. It really is an indication of how this White House is thinking about economic policy and its hopes for kicking off a new era of enforcement of antitrust laws. KING: The aims are impressive. Among those 72 measures, what stood out to you? KHALID: Well, the order directs the Federal Trade Commission to limit non-competes. Those prevent a lot of workers, you know, from quitting one job to go to a better one. I spoke with Jason Furman. He was a chair of the Council of Economic Advisers during the Obama administration. And he said some of these ideas might seem small. But collectively, they could really transform the economy. And the example he gave me was this part of the order that would enable more hearing aids to be sold at pharmacies instead of having to go through a doctor. JASON FURMAN: There's no reason that hearing aids shouldn't be more like, you know, over-the-counter reading glasses. It's a lot of people who just can't believe how much they have to spend for these devices. They don't cost that much to make. KHALID: And the order that the president is going to be signing today envisions a proposal for this in the next few months. There's also a nugget in the order about airline fees and issuing rules to require refunds if you say, you know, pay for a check bag and it ends up delayed. KING: That would be nice. You mentioned we're getting some hints about how this administration thinks about antitrust. I would imagine a big part of this, then, is aimed at the tech sector. KHALID: Exactly, quite a bit. I mean, I would say some of the more sweeping changes really do target the tech sector. You know, the White House wants Obama-era net neutrality rules to be restored. It's also indicating that it'll more closely scrutinize mergers in the tech sector, particularly when established players buy up new competitors and when those deals might affect consumer data and consumer privacy. Many of the directives would be enforced by the Federal Trade Commission, which is now led by Lina Khan. She's a high-profile critic of big tech companies. KING: Thinking back to the last Democratic presidential administration, didn't the Obama White House try to get some of this done? KHALID: You know, the White House says there was a nascent effort toward the end of the Obama administration to deal with some of these issues. But it takes a while to write rules. And frankly, some of those ideas didn't get off the ground. Some of them were also rolled back by the Trump administration. But by doing this in the first year of the Biden White House, you know, the president is signaling that it's a priority. And he's also creating time for agencies to write these rules. The White House is also launching a White House Competition Council to monitor progress on all these initiatives. I will say, though, Noel, really, the efficacy of all of this is going to come down to how the rules are written, how they're actually enforced and whether or not they're able to withstand legal challenges. KING: NPR's Asma Khalid. Thank you, Asma. KHALID: My pleasure. (SOUNDBITE OF OATMELLO AND LATE ERA'S \"GOOD NIGHT\") NOEL KING, HOST:   President Biden will issue an executive order today to promote competition across a bunch of industries, including farming, airlines, prescription drugs and Internet service providers. NPR White House correspondent Asma Khalid got an early look at the executive order and is with us now. Good morning, Asma. ASMA KHALID, BYLINE: Good morning, Noel. KING: So this order is very consumer and worker-oriented. KHALID: That's right. The White House believes that it'll lead to lower prices for consumers, better wages for employees and, eventually, more durable, long-term economic growth. The goal is to tilt markets more in favor of workers and consumers over big, powerful companies. And in total, it includes some 20 - 72 - I'm sorry - different initiatives. It really is an indication of how this White House is thinking about economic policy and its hopes for kicking off a new era of enforcement of antitrust laws. KING: The aims are impressive. Among those 72 measures, what stood out to you? KHALID: Well, the order directs the Federal Trade Commission to limit non-competes. Those prevent a lot of workers, you know, from quitting one job to go to a better one. I spoke with Jason Furman. He was a chair of the Council of Economic Advisers during the Obama administration. And he said some of these ideas might seem small. But collectively, they could really transform the economy. And the example he gave me was this part of the order that would enable more hearing aids to be sold at pharmacies instead of having to go through a doctor. JASON FURMAN: There's no reason that hearing aids shouldn't be more like, you know, over-the-counter reading glasses. It's a lot of people who just can't believe how much they have to spend for these devices. They don't cost that much to make. KHALID: And the order that the president is going to be signing today envisions a proposal for this in the next few months. There's also a nugget in the order about airline fees and issuing rules to require refunds if you say, you know, pay for a check bag and it ends up delayed. KING: That would be nice. You mentioned we're getting some hints about how this administration thinks about antitrust. I would imagine a big part of this, then, is aimed at the tech sector. KHALID: Exactly, quite a bit. I mean, I would say some of the more sweeping changes really do target the tech sector. You know, the White House wants Obama-era net neutrality rules to be restored. It's also indicating that it'll more closely scrutinize mergers in the tech sector, particularly when established players buy up new competitors and when those deals might affect consumer data and consumer privacy. Many of the directives would be enforced by the Federal Trade Commission, which is now led by Lina Khan. She's a high-profile critic of big tech companies. KING: Thinking back to the last Democratic presidential administration, didn't the Obama White House try to get some of this done? KHALID: You know, the White House says there was a nascent effort toward the end of the Obama administration to deal with some of these issues. But it takes a while to write rules. And frankly, some of those ideas didn't get off the ground. Some of them were also rolled back by the Trump administration. But by doing this in the first year of the Biden White House, you know, the president is signaling that it's a priority. And he's also creating time for agencies to write these rules. The White House is also launching a White House Competition Council to monitor progress on all these initiatives. I will say, though, Noel, really, the efficacy of all of this is going to come down to how the rules are written, how they're actually enforced and whether or not they're able to withstand legal challenges. KING: NPR's Asma Khalid. Thank you, Asma. KHALID: My pleasure. (SOUNDBITE OF OATMELLO AND LATE ERA'S \"GOOD NIGHT\")", "section": "Politics", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-07-11-1009560739": {"title": "Black Blogger Talks About Racism In Geocaching : NPR", "url": "https://www.npr.org/2021/07/11/1009560739/geocaching-while-black-outdoor-pastime-reveals-racism-and-bias", "author": "No author found", "published_date": "2021-07-11", "content": "LULU GARCIA-NAVARRO, HOST:  Over the past year, many people have taken up activities they can do outdoors. And one that's become popular is geocaching. It's a high-tech treasure hunt using GPS coordinates for hidden containers called caches. And there are more than a million of them across the United States. Sarah Kate Kramer brings us the story of one geocacher who, in his searches, has had to navigate more than just the terrain. SARAH KATE KRAMER, BYLINE: Since he started geocaching three years ago, Marcellus Cadd has found a cache every day. On his best day, he found 274. Recently, he went hunting for a geocache in Austin. And I asked him to record himself on his phone. MARCELLUS CADD: Right now, we're supposed to be about 22 feet away from it. GEMMA: We're in an open field except for, like, some trees. KRAMER: That's Cadd's 12-year-old daughter Gemma, who is helping him find a cache in the 90-degree Texas heat. They didn't know exactly what it would look like. The cache might be a film canister, an ammo can. Suddenly, Gemma spotted a little orange container nestled at the bottom of a tree. GEMMA: Oh, is that it down there? CADD: Oh, yeah. That's totally it. KRAMER: Cadd's 10-year-old daughter Zoe opened the cache. ZOE: There's some hand sanitizer in here, a lollipop, yellow star stickers and the log, of course. GEMMA: And the log, of course. CADD: Do you ladies want to sign the log? KRAMER: Cadd likes taking his daughters geocaching. But most of the time, he does it solo. His favorite part is how geocaching is a way to explore the country. CADD: I have seen so many things. And I have been to so many places, places that I wouldn't have gone on my own. I get to have a little miniature treasure hunt every day. KRAMER: But soon after he started, Cadd realized that he was having a different experience than the majority of geocachers in the U. S. , who are white. CADD: I was reading a forum post where somebody asked, how many times have you guys been stopped by cops? KRAMER: Most geocachers said they were rarely, if ever bothered by the police. CADD: And I was thinking to myself, man, I've been doing this six months. And I've been stopped seven times. KRAMER: And it's not only the police who question Cadd. Strangers, almost always white, often ask why he's poking around their neighborhood. So he's developed some tricks to avoid attention. Here he is looking for a cache in a downtown Austin. CADD: I'm carrying a clipboard with me. So, you know, they might think that I'm working here. If you look like you're working, then people don't tend to pay attention to you. KRAMER: You had started a blog called Geocaching While Black to document his experiences dealing with racism during his travels. He's been to every county in Texas. And once he ended up in a park dedicated to the memory of the Confederacy. The geocache was hidden in the bottom of the flagpole. CADD: And I'm like, I'm going to have to get this thing out from under the Confederate flag. And I signed it. And I put it back, so I could get the heck out of there. KRAMER: But Cadd is actually hoping his blog will encourage more people of color to geocache. CADD: There's a certain joy in being Black and basically going out into places where you don't see a lot of Black people and being able to say, I am here whether you like it or not. KRAMER: Marcellus Cadd. his goal is to find a geocache in every county in the United States. For NPR News, I'm Sarah Kate Kramer. CADD: I'm reaching. Bingo. I got it. LULU GARCIA-NAVARRO, HOST:   Over the past year, many people have taken up activities they can do outdoors. And one that's become popular is geocaching. It's a high-tech treasure hunt using GPS coordinates for hidden containers called caches. And there are more than a million of them across the United States. Sarah Kate Kramer brings us the story of one geocacher who, in his searches, has had to navigate more than just the terrain. SARAH KATE KRAMER, BYLINE: Since he started geocaching three years ago, Marcellus Cadd has found a cache every day. On his best day, he found 274. Recently, he went hunting for a geocache in Austin. And I asked him to record himself on his phone. MARCELLUS CADD: Right now, we're supposed to be about 22 feet away from it. GEMMA: We're in an open field except for, like, some trees. KRAMER: That's Cadd's 12-year-old daughter Gemma, who is helping him find a cache in the 90-degree Texas heat. They didn't know exactly what it would look like. The cache might be a film canister, an ammo can. Suddenly, Gemma spotted a little orange container nestled at the bottom of a tree. GEMMA: Oh, is that it down there? CADD: Oh, yeah. That's totally it. KRAMER: Cadd's 10-year-old daughter Zoe opened the cache. ZOE: There's some hand sanitizer in here, a lollipop, yellow star stickers and the log, of course. GEMMA: And the log, of course. CADD: Do you ladies want to sign the log? KRAMER: Cadd likes taking his daughters geocaching. But most of the time, he does it solo. His favorite part is how geocaching is a way to explore the country. CADD: I have seen so many things. And I have been to so many places, places that I wouldn't have gone on my own. I get to have a little miniature treasure hunt every day. KRAMER: But soon after he started, Cadd realized that he was having a different experience than the majority of geocachers in the U. S. , who are white. CADD: I was reading a forum post where somebody asked, how many times have you guys been stopped by cops? KRAMER: Most geocachers said they were rarely, if ever bothered by the police. CADD: And I was thinking to myself, man, I've been doing this six months. And I've been stopped seven times. KRAMER: And it's not only the police who question Cadd. Strangers, almost always white, often ask why he's poking around their neighborhood. So he's developed some tricks to avoid attention. Here he is looking for a cache in a downtown Austin. CADD: I'm carrying a clipboard with me. So, you know, they might think that I'm working here. If you look like you're working, then people don't tend to pay attention to you. KRAMER: You had started a blog called Geocaching While Black to document his experiences dealing with racism during his travels. He's been to every county in Texas. And once he ended up in a park dedicated to the memory of the Confederacy. The geocache was hidden in the bottom of the flagpole. CADD: And I'm like, I'm going to have to get this thing out from under the Confederate flag. And I signed it. And I put it back, so I could get the heck out of there. KRAMER: But Cadd is actually hoping his blog will encourage more people of color to geocache. CADD: There's a certain joy in being Black and basically going out into places where you don't see a lot of Black people and being able to say, I am here whether you like it or not. KRAMER: Marcellus Cadd. his goal is to find a geocache in every county in the United States. For NPR News, I'm Sarah Kate Kramer. CADD: I'm reaching. Bingo. I got it.", "section": "National", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-07-11-1014581747": {"title": "Richard Branson Goes To Space On A Virgin Galactic Flight : NPR", "url": "https://www.npr.org/2021/07/11/1014581747/bezos-vs-branson-the-billionaire-space-race-lifts-off", "author": "No author found", "published_date": "2021-07-11", "content": "", "section": "Space", "disclaimer": ""}, "2021-07-12-1015224321": {"title": "In 'The Startup Wife,' Tahmima Anam Satirizes Tech Culture And Boardroom Sexism : NPR", "url": "https://www.npr.org/2021/07/12/1015224321/the-startup-wife-tahmima-anam-novel", "author": "No author found", "published_date": "2021-07-12", "content": "TERRY GROSS, HOST:  I'm Terry Gross. A new social media platform that customizes rituals and ceremonies for people who aren't religious is at the center of the new novel \"The Startup Wife\" by my guest Tahmima Anam. Also at the center of the story is the marriage between the two main characters, Asha and Cyrus, who co-found the app at the same time they fall in love. Asha came up with the idea for the app and designed it, but because her husband Cyrus is considered more charismatic and because he's a man, he becomes the head of the new company. He gives daily talks to the app's followers, offering his thoughts about ritual and the meaning of life, and the followers start to think of him as a messiah. As the title of Chapter 14 says, nobody wants to be married to the Messiah. Some of the novel is based on what Tahmima Anam observed in the tech world when she served on the board of her husband's music tech startup. Anam is also the author of a trilogy of novels set during and after the Bangladesh Liberation War, in which Bangladesh won its independence from Pakistan in 1971. Her parents fought for independence in that war. Her father went on to work for the U. N. and then started a widely read newspaper in Bangladesh, which he still runs. Anam's mother runs a human rights organization. Tahmima Anam now lives in London with her husband and their two children. She's the recipient of a Commonwealth Writers' Prize and an O. Henry Award and was named one of Granta's best young British novelists. Her new novel has been recommended on a lot of summer reading lists, including in The Washington Post. Tahmima Anam, welcome to FRESH AIR. I really enjoyed your book. And I'd like to start with asking you to read a short passage that I think will set the scene that the social media world is set in. So this takes place when the main characters are making their opening pitch to be part of Utopia, the startup incubator. TAHMIMA ANAM: Thank you so much, Terry. I'm thrilled to be here so. I'm just going to read from the beginning of the book. (Reading) Why don't we introduce ourselves? Leann (ph) says. I'm the head of innovation here at Utopia. Hey, I'm Marco (ph), says a man with deep-set eyes and a sharply trimmed beard. I created obit. ly (ph), a platform that manages all the social and public aspects of death. A woman with bright pink hair waves hello. I'm destiny. I'm the founder of Consentify (ph), a way to make every sexual encounter safe, traceable and consensual. A thin, stern man in a lab coat leans against the table. My name is Rory (ph). I run Lone Star (ph). He speaks with a clipped Scandinavian accent. I want every single person in the world to stop eating animals. We would never fit in. First of all, it would be impossible to find a cute, vitamin-gummy way to describe the platform. And then the rest of it - the confidence, the hair, the way they all look as if they slid into place like a synchronized swim team - I cannot imagine ever being that comfortable in my skin. GROSS: So thanks for reading that passage from your novel \"The Startup Wife. \" So now you should introduce us to the platform that your main characters create. ANAM: So the platform is called WAI. It's pronounced why, obviously, as in why are we here? But it's spelled W-A-I, which stands for We Are Infinite. And what it is is a way for people to connect via rituals. So you go on the app, and you tell it the things that mean something to you - your favorite cartoons, your - the food that you love, important experiences that happened to you in childhood. And then you ask for a ritual. You say, I want to get married, and I'm a - you know, for instance, in the book, there are these two classicists that get married, so they have a Homerian (ph) wedding ceremony. And that's what the platform gives you, and then you get to connect to other people via those rituals. So it's kind of an antisocial media social media in the sense that you're not talking about superficial things; you're connecting via the rituals that give your life meaning. GROSS: And this is a platform that creates rituals without the baggage of religion. So it's a kind of - secular rituals for people who don't have religion in their life but still want ceremonies. Do you relate to that? ANAM: I do, actually, because I'm not a religious person myself, but I can see how having a kind of organizing construct can be so relaxing in the world, where there are so many uncertainties. And giving people something to hold on to, giving these kind of moments of punctuation in your life, where you're looking forward to something - the baptism of your child, a bar mitzvah - you know, we don't have that as people who don't necessarily adhere to a particular form of religion. So I thought, wouldn't it be great if we could give atheists the same kind of scaffolding that religious people have? GROSS: Of course, things go terribly wrong in your book with this app. (LAUGHTER)GROSS: I'll leave that to readers to find out exactly what happens. But how did you come up with the idea for this app? I mean, we'll get into this later, but you're on the board of directors of an app that your husband created, so you know something about the social media world. ANAM: That's right. So, I mean, in a way, it was a literary device because I wanted to give the two main characters, Asha and Cyrus, a startup that was very unconventional because neither of them are your typical startup founders. They don't come from Silicon Valley. They're not natural entrepreneurs. And so I wanted to give them something that, to them, felt very countercultural. And the fact that it becomes a startup is almost accidental. And that does mirror my own life. So my husband and I were going to be academics. I mean, I was going to write novels, and he was going to be a professor of Chinese philosophy. And then he invented this thing which is, in fact, an app that works with a keyboard, and he started this company. And I feel like the whole journey has been one of kind of discovering the world of startups sort of from an outsider's perspective. And that's exactly what Cyrus and Asha do. GROSS: So the startup incubator they become part of, Utopia, is - among other things - a way to attract funding from venture capitalists. But Utopia is especially interested in apps for the post-world world. In other words, they're preparing for some kind of apocalypse. It could be climate change. It could be war. It could be anything that would end the world as we know it. I understand that you started a fake website for Utopia while you were writing the novel, and you actually got interest from people. Tell us more. ANAM: So one of the really fun things about writing this book is that I got to make up all these sort of crazy startups that would probably - I mean, I don't know. Some of them might exist in the world, and some of them might not. And then once I had done that, I got a designer friend of mine to create this website. And occasionally, when I'd been talking to people in the startup world, as a joke I will just give them the website address and not tell them that it's fake, and there has been some interest. And the company that gets the most interest is the one that's called Empty (ph), where rather farcically you subscribe to nothing. You get an empty box every month, and you get to put your baggage into the box and send it back to this company, and they get rid of it in a responsible way. So let's say you're getting divorced. You put your wedding ring in it, and they kind of, you know, incinerate it for you. So for some reason, that has been the one that people are most interested in investing. But yeah, that's kind of, like, a little joke that I sometimes like to play on people. GROSS: That's crazy you could just give it away to the Salvation Army or your local thrift store or throw it away, and. . . (LAUGHTER)ANAM: Well, I think that you're touching on something, which is that one of the things that startup culture does is that it takes something that is very familiar to you, that you feel that you already know what to do - you know, you know you can send your junk to the Salvation Army or put it in recycling. But it somehow is there to create an idea that you can make things in your life easier or more seamless or more meaningful by in somehow engaging in the startup. So, you know, there's all kinds of apps that have - there's one where they send you laundry capsules in your letter box. Putting things in letter boxes is, like, a big thing right now - so flowers in your letter box, your laundry detergent, your tampons, you know. So we know that we can just go out and buy them, but there are startups that are devoted to packaging your everyday activities in slightly different ways and creating businesses out of them. GROSS: So are you interested in the postapocalypse world? ANAM: Well, I think right now we're all interested in the postapocalyptic world because we're kind of living in it. You know, I wanted to give Utopia a slightly different sort of flavor than most tech incubators. And I've been to some of these co-working spaces and to some of these incubators, and there was a lot of hype and a lot of promise and a lot of talk about community. And I just wanted to give it that edge, which was, you know, they were thinking about this other world, and that was kind of bringing them all together. And Utopia is also a place where Asha gets to meet other female founders, and she builds these friendships with these other women who are coming up with all kinds of businesses. There's the silent vibrator. There's Consentify, which is about, you know, pre-agreeing to all your sexual activity before you engage in it. So I wanted to give her that, and I - so I put her in this place which is called Utopia and has a lot of the elements of what you might imagine is, like, a perfect world - is imagining a world that is better than the one that sort of gets obliterated by an apocalypse. GROSS: But I am wondering if you grew up with a fear of the end of the world or of war. I mean, your parents fought in the Bangladesh war of liberation, so war was the memory background of your life. I don't know how much they told you about it. And your father worked for the U. N. for years, and the U. N. is all about creating peace because there's so much war. So I'm just wondering if that was a part of your - you know, your nightmares or your fears or if you read a lot of postapocalyptic fiction. ANAM: Yeah. That's a really good question, Terry, and I hadn't really thought of it that way. So I grew up hearing stories about the Bangladesh War. It was very much the thing that we talked about around the dinner table all the time. My parents had been in the war. It was the sort of organizing principle of their lives. And the other thing is I come from a country where this kind of sense of apocalyptic possibility is always in the air because the climate is so extreme. And so it feels - it has always felt very much like a fragile place that was born out of this brutal war, you know, that it sort of barely survived, and then trying to beat the odds. And now, obviously, that big sense of apocalyptic change is climate change, which is going to affect Bangladesh more than many other countries in the world in a really extreme way. So for sure, I mean, I hadn't thought of it that way, but the sense of the end of the world being very close has certainly been something that I've grown up with. GROSS: Yeah. That was probably a part of your life even in your early childhood. ANAM: Yes. I mean, my parents - you know, so I was born four years after the war ended, and my parents both came into political consciousness in the '60s. They were revolutionaries. They were nationalists. My father fought in the war. And it was definitely something that played a huge part in the way that I was raised. And then we left Bangladesh when I was 2 years old because my father got a job with the U. N. , and I think that because we were far from home, I heard those stories even more. And I think that people who stayed in Bangladesh possibly were more on the sort of, well, this war happened; we need to move on and try to sort of get over the past. But for them, it was something that they really held onto and they talked about a lot. And they didn't just talk about it in sort of tragic terms and saying, you know, how awful it was - which it was. It was an extremely brutal war. And millions of people were killed, and millions of women were raped. But they also talked about it as this moment where they, as young people, got to imagine a country into being, and that was incredibly inspiring and important for them. And it was - like I said, it was the sort of foundational moment of their lives. And so I think a lot of the way they brought me up and a lot of the things they talked about and their relationship to each other was kind of built around that experience. GROSS: Let's take a short break, and then we'll talk some more. If you're just joining us, my guest is Tahmima Anam. Her new novel is called \"The Startup Wife. \" She's the author of an earlier trilogy of novels that have to do with the war for independence in Bangladesh. We'll be right back. This is FRESH AIR. (SOUNDBITE OF THIRD WORLD LOVE'S \"SEFARAD\")GROSS: This is FRESH AIR. Let's get back to my interview with Tahmima Anam, author of the new novel \"The Startup Wife. \" It's about a startup co-founded by a couple. The app's surprising success leads to trouble, including in their marriage. She's also the author of a trilogy of novels set during and after the Bangladesh Liberation War, which her parents fought in. Can you tell us, as briefly as you can - and this is an impossible question, and I apologize for asking it this way - what the war was about? ANAM: So when the British left India in 1947, they left behind two countries - Pakistan and India. And Pakistan was divided into two. Pakistan was in two halves on either side of India, divided by 3,000 miles of India. There was West Pakistan, which is the country that we now know as modern-day Pakistan, and there was East Pakistan. And it was very clear from the beginning that this was not going to work because the only reason these two regions were put together as one country was because they had a majority-Muslim population. But they were culturally and politically and socially and linguistically, very importantly, completely different. So this came to a head, and in 1971, you know, we had a war of independence, which was brutally suppressed by Pakistan. You know, there was a genocide, and, like I said, millions of people were killed. You know, they obviously didn't want the two countries to split. But after nine months, India intervened, and Bangladesh became independent. That's the sort of potted history, and I would say that that history and that split comes from a sense that after the British left, they - you know, the Bengalis of East Pakistan were subjected to a second rule of colonialism by West Pakistan rather than feeling that they were now part of an independent country. And so that sort of spirit of independence that started with the independence of India and Pakistan then sort of continued. And now in the subcontinent, we have three countries. And I was born into the independent country of Bangladesh. But my parents were born in Pakistan and in East Pakistan. GROSS: And we'll talk more about this later. But in terms of the apocalypse, in terms of, like, anything can happen, Bangladesh gets its independence. But eventually, there's, like, a military coup and, you know, a repressive government. So even after fighting for independence, things go bad. ANAM: Absolutely. So this is also kind of a big shadow that was sort of hanging over my head as I was growing up. And one of the great tragedies of the war was that after it was won, within four years, the person who sort of led the independence movement was assassinated along with 14 members of his family in this terrible tragedy that was happening to a country that was barely getting on its feet. And it took - I mean, I really don't think those early wounds, the war, the assassination of Sheikh Mujib, I don't think those things have ever really been reckoned with. But I think it's only now that we're starting to come out of those sort of long shadows. GROSS: So getting back to the app in your book, you know, it's an app for creating rituals and ceremonies for people who are not religious. But it draws on religion. It draws on myth. It draws on various cultures to create these rituals. So since you grew up in the background of a war for independence that was in part a religious war in the sense that Pakistan was formed because it was majority Muslim, and a lot of Muslims who were living in India moved voluntarily or felt forced to flee to Pakistan - did that color your family's sense of religion? ANAM: Absolutely. So my father, when I was growing up, was an atheist. I was not raised with any form of religion. And partly, I think that was because of the politics of the time, and specifically because, you know, Pakistan was a repressive regime that was forcing us to stay, you know, part of this union on the basis of religion. And the Bengali people were saying, no. We have cultural and linguistic rights, you know? They imposed Urdu as the official language of both Pakistans even though nobody in Bengal spoke Urdu. We all spoke Bengali. Bengali people have a fierce attachment to their language, to their culture, to the music of Rabindranath Tagore. I mean, that is - you know, if ever there was a poet who basically defined a country, he defined so much of who we are in Bangladesh. So it was that sense of rejecting religion in favor of a secular cultural identity, and that is why I was raised without religion, because my parents sort of grew up in that movement. GROSS: So you know, getting back again to the app that's created in your book that - you know, that the main characters created, it's an app for rituals and ceremonies for people who don't have religion to provide that because they don't believe in any religion. But (laughter) the startup is created by Asha, who's married to Cyrus. She creates the app. She does all the coding for it. He becomes the head of the startup because he's the man and he's good at promoting things. He's good - he's really good at selling himself or selling his ideas or - so he becomes the head of it. And he's also the one who talks to people every day about life and, you know, the importance of ceremony and the meaning of life because he has, basically, his own channel to talk to the followers of this app. And he becomes this, like, messiah figure, which is really interesting because I think you've hit on something really interesting - because people who don't have religion in their life in this book create a messiah figure of their own in the head of this app that's not about religion. ANAM: Yes. There is a real irony there because people are obviously, you know, joining - why? - because they want an alternative to organized religion. And then, there they are worshipping a male visionary messiah, you know, prophet, basically. And I think the other irony is that Asha, who falls madly in love with Cyrus, you know, he's her high school sweetheart, she meets him again after many years. And she kind of feels this triumphant sense when she meets him again and he loves her back. And the other irony is that Asha, who creates the app and who does all the coding and it's really her idea, when it comes down to it, she says to Cyrus, oh, no you be the CEO. I'm just a coder. I'm going to sit in the background. And she lifts him up. And she thinks to herself, you know, towards the end of the book, I literally created a platform that makes the entire world worship my husband. (LAUGHTER)ANAM: She does that. I mean - you know, and this is an - it's an exaggeration of what we all sometimes do. When we love someone, we lift them up. But she just does it to an absolutely intense, kind of huge, massive, exaggerated scale. GROSS: Well, I think we need to take another break here. So let me reintroduce you. If you're just joining us, my guest is Tahmima Anam. Her new novel is called \"The Startup Wife. \" We'll be right back after a short break. I'm Terry Gross. And this is FRESH AIR. (SOUNDBITE OF PAUL SHAW QUINTET'S \"PEEKABOO\")GROSS: This is FRESH AIR. I'm Terry Gross. Let's get back to my interview with Tahmima Anam, author of the new novel \"The Startup Wife. \" It's about a startup co-founded by a newly married couple. The app customizes rituals and ceremonies for people who aren't religious but want the sense of community and ritual that others find in religion. So your husband founded a startup. It's a music startup that from what I can tell creates, like, software that's music related. Like, there's a colored keyboard to help people learn how to play songs. There is an app that creates notes in the space between the keys of the piano - things along those lines. So it's really, like, for people who want to learn more about music or want to do music production. So the startup was founded at about the same time you got married, so your marriage and the startup were kind of on a parallel track. Did you draw from your own experiences to write this book? And is there an experience that you found confusing that you needed to, like, work out in the book? ANAM: (Laughter) That's a great question. Well, I'll tell you first the ways in which it's not the same, which is that I had nothing to do. . . GROSS: You're married. You're married. (LAUGHTER)ANAM: I mean, I didn't come up with the idea for Roli, which is my husband's startup. It was all his idea. I can't take any credit for that. The ways in which I think I did draw from my experience were in two ways. The first was that, as I said to you before, neither of us expected to be involved in the startup world, and so it was a very interesting journey to meet someone who, for all intents and purposes, we were going to lead these lives of both being academics and artists, and to watch him then have to raise money, to be the boss of a hundred people - I mean, that really has a big impact on a person. So having that much sort of power and being the boss, I think that definitely was something that I didn't - that we both - neither of us expected. And I think that there were some changes that were quite surprising that we both had to kind of work out. So there was definitely that. And the other thing was that I was on the board of - I've been on the board of the company from the very beginning, and I had obviously no experience of the boardroom. And I really enjoyed thinking about writing this book the entire time that I was on that board because one of the great pleasures of being a writer is that you get to put all of your experiences somewhere. So anytime someone cut me off or ignored me or didn't take me seriously, I thought, I'm going to write that down. (LAUGHTER)ANAM: So it was a way of processing that experience which was very new for me and sometimes quite challenging because my - the other half of my life was, you know, sitting quietly in a room and writing books, which had nothing to do with the startup world until I wrote this book. So yes, it was definitely thinking about - imagining this novel was a great way of processing the actual experience I was having both sitting on the board, watching people interact with me, but also watching the changes that my husband was going through as he went from being a sort of quiet academic to being everyone's boss. GROSS: In your Twitter bio, one of the things you say to describe yourself is feminist killjoy. (LAUGHTER)GROSS: Did you feel like a feminist killjoy on the board? ANAM: You know, Terry, I wish I was more of a feminist killjoy. And one of my goals for the next, you know, however many years of my life is to call people out a little bit more because there is so much sexist language embedded in probably any kind of business environment. But because I don't come from a business environment, I'd never heard it before. So for instance, people will commonly - men will commonly say, well, they're already pregnant, they might as well have the baby, when they're talking about someone who's so invested in you they're just going to give you more money or something like that. Or they'll say, we should open the full kimono (laughter), which is both sexist and kind of racist. But I think in a lot of those situations, I just kind of sat there and was like, ha-ha (ph), you know? I kind of. . . GROSS: I can use this (laughter). ANAM: Yeah. Yeah, exactly. I'm just going to put it in my book. But. . . GROSS: But not say anything. ANAM: But not say anything. And I think we need to be able to say out loud that language means something, and a joke, you know, even in the most kind of flippant way, is a representation of our actual values. So I hope that I can be more like Asha and less like the me that was just silently filing things away for my book. GROSS: There's a joke in the book about post-IPO wives. In other words, after the husband starts a successful startup, he sometimes trades in his wife for a newer wife. Is that something that you've actually witnessed in the tech world? ANAM: So I haven't witnessed it myself, but it was relayed to me by a close friend of mine who does a lot of executive recruiting. So she meets a lot of founders, and she sees companies from the sort of very beginnings of when they are just a few people, and she helps them hire executives to when they IPO. And I sort of floated the idea of this book to her, and I said, well, you know, I'm going to write this book, and what do you think of startup marriages? And she says, well, if they succeed, they almost always get divorced because either the woman says - and she's talking about a heterosexual relationship where the man is the CEO. Either the woman says, I'm really tired of you now; I just want half of everything you've got, and I'm out of here. Or the man says, more likely, well, thanks for helping me get through all the challenges of the last 10 years; I'm going to trade you in for someone who hasn't been through that with me, and we can just start afresh and enjoy all this wealth, I guess. So she was pretty pessimistic about it. GROSS: So I want to get back to your childhood and growing up in the shadow of the Bangladesh war for liberation, which your parents fought in. What did your parents do in the war? ANAM: So it was very interesting. My mother stayed in Dhaka throughout the war, and her home and my grandmother's home was used as a refuge for the guerrilla fighters who were coming back and forth from across the border. So they were being trained in India, and then they were, you know, doing their kind of guerrilla warfare against - so the war was essentially an army against an unarmed civilian population. And a lot of young men ran away from home and joined this guerrilla army so they could fight this - the Pakistani army. And so my grandmother's home became a hideout for those guerrilla fighters. So they would come back to the city, and they would hide in her house. And my mother kind of witnessed all of that, and my grandmother sort of sheltered these - basically, these guerrilla fighters. My father spent part of the war going to India and trying to drum up support for the independence war. He was a debate champion before the war started. He was three times the all-Pakistan debate champion, which made it very difficult for me to argue with him when I was growing up, just as an aside. But so he went around and basically did a lot of propaganda for the war. And then, he joined the army and was in training. And then by the time he finished his training, the war was over. GROSS: Was anyone in your family injured? ANAM: No one in my family was killed or injured, but many of their friends who had joined the guerrilla army were captured by the army, killed by the army, tortured and survived but were never the same. So that sort of generational trauma was definitely present. GROSS: Your grandfather was in Congress. Was this when India was a colony of Britain? ANAM: No. My grandfather was a minister in the Pakistan government. So after the independence of India in 1947, when there was - Pakistan and India were two independent countries, my grandfather was a member of Parliament. And he had a really interesting story because he was born in a village in what is now Bangladesh, which was then colonial India. None of his family were educated. They were tenant farmers, basically. But he was very, very bright, and he somehow, you know, educated himself and became a politician and quite a prominent journalist and political satirist. So he had a very exceptional trajectory in his life. And I think when I was growing up, that was also kind of one of the things that my parents talked about a lot was how this person who was a very unlikely politician - he didn't come from a sort of political background or from a family where you would expect someone to become a politician - he became a member of Parliament. GROSS: And your father became a diplomat after the war. He worked for the U. N. , for UNESCO, the U. N. Educational, Social and Cultural Organization. So he was, like, a media spokesperson. So you were raised in Paris, New York and Bangkok. It's hard for kids to change schools. You had to keep changing countries. What was that like for you? ANAM: If you had asked me this, I don't know, 30 years ago, I would have said it was really awful because I could never maintain friendships for more than a few years. I think, looking back, it was such a formative experience for me. And I would say the experience that was the most meaningful was when we moved back to Bangladesh. So my parents - you know, it was so interesting. We were living in all these countries, and they kept saying to me, we're just going to go home. We're not going to stay here. We're not going to stay in New York. We're not going to stay in Paris. We're going to go home. We're nationalists. We have to go back and do something for our country. And when I was 14, we did exactly that. We went home, and my father started an independent English daily newspaper, sort of not politically affiliated, which was very unusual at the time. It was almost - it was 30 years ago. So it was very tricky to not ever be in one place for very long. But I think it certainly had a lot to do with why I became a writer. So I can't really knock it in retrospect. GROSS: How old were you when your family moved from Bangladesh? ANAM: I was only 2 years old, so I really have no memories of growing up there. GROSS: So Bangladesh - going home so to speak - was like going to another foreign country. ANAM: Yeah, it was almost worse than going to a foreign country because at least when I was going to a foreign country, I was expected not to know anything. And there was this - there was a lot of hype about going home, and I felt just as unfamiliar there as I had felt when we moved to New York or to Thailand. I was just expected not to. So that was a tricky moment. GROSS: How did you know you wanted to be a writer? ANAM: I cannot ever remember wanting to be anything else, but I also remember feeling completely paralyzed by the fear of failure. And so I wanted to be a writer, but I had no idea if I could do it. And that's the thing about writing is you just don't know until you do it many, many times whether - even now, if you ask me, you know, do you feel like you know how to be a writer? I would say, definitely not. Every time I do it, it's like starting from the beginning. So I really wanted to do it. I knew I had some stories to tell, but I was also - as many writers are - you know, plagued with insecurity and a desire to succeed. GROSS: My guest is Tahmima Anam. Her new novel is called \"The Startup Wife. \" We'll talk more after a break. This is FRESH AIR. (SOUNDBITE OF NAOMI MOON SIEGEL'S \"IT'S NOT SAFE\")GROSS: This is FRESH AIR. Let's get back to my interview with Tahmima Anam. Her new novel, \"The Startup Wife,\" is about a startup co-founded by a married couple. The app's surprising success leads to trouble, including in their marriage. You've been a judge for the Man Booker Prize, which is Britain's most prestigious literary award. Is it hard to sit in judgment of fellow writers? And I'm wondering if you ever meet any writers who you voted against (laughter) for the prize. And they wouldn't know - necessarily know that, but I could see how awkward it would be for you. ANAM: Well, luckily, I judge the Man Booker International, which is for novels in translation. And so I. . . GROSS: Oh, God. Yeah, you're lucky (laughter). ANAM: I didn't know a lot of those writers. But I can tell you, Terry, when I - being on the other side of that and having, you know, other friends who are on judging panels and - it certainly is part of that world, which can be very awkward. And I remember sitting in that room judging that prize and feeling extremely passionate about the kind of book that I wanted to win. And it gave me a little bit of perspective on, you know, why I hadn't ever been on one of those lists or sort of what happens behind the scenes. So in a way, it was - made me feel a little bit better about possibly the times when I hadn't appeared on any of those lists. GROSS: So why do you think you were not on those lists? ANAM: (Laughter) Well, because it's a very subjective thing, judging. You know, what is brilliant to one person is, you know, not brilliant to another person. One of the - you know, I'm talking a lot about anxieties and insecurities, but I think one of the concerns that I had when I sat down to write this book was that it wasn't serious enough, that I had written a trilogy of novels that were, in a way, the kinds of books that you would expect from a person that comes from where I come from - you know, dealing with the big historical ideas of religion, talking about social change, talking about revolutions. You know, this is the kind of story - those are the kinds of stories that I feel I was expected to write. And I'm really proud of them. And I didn't feel that there was anything more urgent that I had to say. But when I sat down to write this book - and I knew it was going to be a satire, I knew it was going to be a comedy - I thought, gosh, will anyone ever take me seriously again. And, you know, will I be one of those people that wins prizes? Or will I be one of those people where it's like, well, she wrote something. And it was light-hearted and joyful. But it's not serious. And that was something I really had to overcome. In fact, I asked my agent to send the book out under a pseudonym. GROSS: Why did you end up not using the pseudonym? ANAM: Well, she persuaded me not to. And my editor persuaded me not to. And I just kind of had to own what I had done, you know? I had to decide that it was serious and that I was tackling all these issues of, you know, sexism in the workplace and the future of technology and what happens to a marriage when the man gets celebrated and the woman gets left behind. And these are all things that have preoccupied me. I am a feminist killjoy. (LAUGHTER)ANAM: And these are things that preoccupied me in my whole writing life. They're just told in a slightly different tone. And I just had to become comfortable with that, I guess. GROSS: What was the name you were going to use if you used a pseudonym? ANAM: Oh, I'm glad you asked. So everyone in Bangladesh has a nickname. People have these very serious, you know, Arabic, proper names that are on their passports. And then there's something that people call them at home. And my father named me after the Rosetta Stone. And in Bangladesh, everyone calls me Rose. So I was going to call myself Rose Lanam. And Lanam is the name that Roland and I gave to our children because it's a combination between our last name - our two last names. So Lamb - he's Lamb. I'm Anam. So our kids are Lanam. So I was going to call myself Rose Lanam. And she was my alter ego. I didn't just think of her as a pseudonym. I thought of her as the person I had to become in order to write that book. GROSS: Why did you have to become somebody else? Because, let me just say, I think, in some ways, this might be your most autobiographical book because your other books are more about people who lived in Bangladesh. One of the books was more about your father's generation. But this is about - it's about your generation. It's about a woman of Bangladeshi descent, the daughter of Bangladeshi immigrants who grows up in America, who was married to somebody that have a startup like your family does. I mean, there's so many similarities. ANAM: Yes. I agree with that. But I had to summon Rose Lanam so that I could write all the dirty jokes, Terry. (LAUGHTER)GROSS: Really? ANAM: They don't come easily to me. I mean, I - you know, I had Asian parents. And I think that sort of loose, confident, sassy, lots of F words - that kind of language does not come easily to me in a sort of public way. You know, if you and I were just hanging out and having dinner, I would certainly speak in Rose Lanam's voice. And so in a way, you're right. She is much more me. But to summon her in a public way, to bring out all of that, it just took - for me to have the confidence to put into writing what I was putting into, like, my text messages to my girlfriends, you know, that sort of tone, that sort of satirical, funny, irreverent tone, it took a little bit of unlearning some of the - maybe some of the limitations I felt that I had in presenting a public self. GROSS: Does this mean you're concerned about anybody in your family reading it? ANAM: I'm not concerned. Although, my mother said to me, because I had put - I had written to some friends - or I put in a Facebook post, you know, this book has a lot of curse words in it. And she said - she literally said, what is Boro Mama (ph) going to say? Boro Mama is my eldest uncle. And I said to her, if I sat down and thought about what Boro Mama was going to say, I would never write another word ever again. GROSS: (Laughter). ANAM: I mean, it is a little bit of that, Terry. But it's also that I - you know, when I was growing up, my father - the term third world country was very much an OK thing to say in the '70s when I was growing up. And my father would say to me, you come from a third world country. You have to get people to take you seriously. Everyone's going to not want to take you seriously. And your job is to get people to take you seriously. And I think I - you know, part of wanting to do a Ph. D. even though I knew I wasn't going to be an academic, it was about that wanting to bring a kind of gravity to my self-presentation. And I had to slightly unlearn that when I was writing this book. And then I had to have the confidence to say, OK, this is still serious even though it's full of jokes. GROSS: Well, I'm glad you unlearned what you had to unlearn (laughter). ANAM: Thank you, Terry. GROSS: So let's take another break here. If you're just joining us, my guest is Tahmima Anam. Her new novel is called \"The Startup Wife. \" We'll be right back. This is FRESH AIR. (SOUNDBITE OF JAMES HUNTER BAND SONG, \"I WANNA GET OLD WITH YOU\")GROSS: This is FRESH AIR. Let's get back to my interview with Tahmima Anam. Her new novel is called \"The Startup Wife. \"You've referred to finding your voice and power as a woman. Were you encouraged to do that by your parents? ANAM: I definitely was. And they were way ahead of their time. I was the first girl born into my dad's family for three generations. So there had only been boys. And my father tells the story of how, you know, when people would come and see me as a baby, they would say, oh, we have to find her a prince or something to marry. And he basically banned that. He said, when you look at my nephews, why do you say, oh, he's going to grow up and be a barrister? Because, you know, at the time, in Bangladesh, being a barrister was, like, the highest thing you could aspire to. He's going to be a barrister or a doctor - why don't you say that to my daughter? And he really angered a lot of the relatives who would come and see me because he was so - you know, he basically put a ban on talking about things like marriage as something that I should aspire to. And my mother has been a lifelong feminist activist. So I think that I had the privilege of growing up in a family where these things were absolutely taken for granted and where conversations about equality and about feminism were right at the forefront of - you know, so present in our lives. And I'm deeply grateful for that. GROSS: I want to get back to something in your novel. In the book, the parents of the main character are from Bangladesh. They're now immigrants in America. They both are not religious. But as they got older, the mother starts saying, inshallah - God willing - in her sentences. The daughter sees her, like, kneeling on a rug, and it appears the mother is praying. And the daughter thinks, like, this is what happens when people get older (laughter). So I'm wondering if you've observed that in your parents, in spite of their atheism. ANAM: Yes, I definitely have. And certainly among the people of their generation, who grew up in the shadow of this war, there has been as they've gotten older - and also, I think as the society has taken decidedly more of a turn towards religion, I've sort of seen that in my family. I've seen it among their friends. My mother certainly has - practices more. And - but the interesting thing is that it hasn't at all affected her politics, and she is just as opposed to the hijab now as she was 20 years ago, before she started becoming a more practicing Muslim. So I think it hasn't had an effect on their politics, but certainly, in the privacy of their home, I wouldn't say so much with my father, but certainly with my mother, I have seen those changes. GROSS: I think I read that your mother told you that it's important to learn some verses from the Quran. In case. . . ANAM: (Laughter). GROSS: . . . You're attacked by Muslim extremists, you can quote the Quran, and it will help save you. ANAM: There was a time in Bangladesh where there were a lot of attacks against writers. It was a really dark moment. It was very recent, you know, in the last 10 years. And I was having this conversation - I can't remember if it was with my mother - where people were saying to me, you need to be able to prove that you're a Muslim. And I have no way of doing that because I'm a completely nonpracticing Muslim. And I have to say, of all the sort of threads of my identity, it's the one that I have rejected the most. And the reason is that I don't have role models for deeply religious Muslims who share my interest in gender equality. I just don't have those role models. And I think that when the feminist imams and when the feminist Muslims come out and become the leaders of the Muslim community and I can look up to them and say to my daughter, hey, you know what, this religion is going to embrace all sides of you and embrace your kind of independence and power as a woman, I think that is the moment where I'm going to be able to embrace that identity. But perhaps because I haven't done enough learning or reading on my own, it's something that I haven't quite come to yet. GROSS: Have you memorized verses in spite of that, in case you need to recite them? ANAM: (Laughter) No. Don't tell anyone. GROSS: (Laughter) I won't. No one will hear this. (LAUGHTER)GROSS: It's been such a pleasure to talk with you. I really want to thank you so much for doing this interview. ANAM: Thank you, Terry. It's been an absolute thrill. I'm so grateful to you. GROSS: Tahmima Anam spoke to us from London. Her new satirical novel is called \"The Startup Wife. \"Tomorrow on FRESH AIR, we'll talk about Facebook - the problems it's created and the problems it's facing. My guests will be new York Times reporters Sheera Frenkel and Cecilia Kang, authors of the new book \"An Ugly Truth: Inside Facebook's Battle For Domination. \" They write, Facebook's problems have been features, not bugs. I hope you'll join us. (SOUNDBITE OF TODD GARFINKLE'S \"VULGARITY IN TROPICAL LIVING\")GROSS: FRESH AIR's executive producer is Danny Miller. Our technical director and engineer is Audrey Bentham. Our interviews and reviews are produced and edited by Amy Salit, Phyllis Myers, Sam Briger, Lauren Krenzel, Heidi Saman, Therese Madden, Ann Marie Baldonado, Thea Chaloner, Seth Kelley and Kayla Lattimore. Our associate producer of digital media is Molly Seavy-Nesper. Roberta Shorrock directs the show. I'm Terry Gross. (SOUNDBITE OF TODD GARFINKLE'S \"VULGARITY IN TROPICAL LIVING\") TERRY GROSS, HOST:   I'm Terry Gross. A new social media platform that customizes rituals and ceremonies for people who aren't religious is at the center of the new novel \"The Startup Wife\" by my guest Tahmima Anam. Also at the center of the story is the marriage between the two main characters, Asha and Cyrus, who co-found the app at the same time they fall in love. Asha came up with the idea for the app and designed it, but because her husband Cyrus is considered more charismatic and because he's a man, he becomes the head of the new company. He gives daily talks to the app's followers, offering his thoughts about ritual and the meaning of life, and the followers start to think of him as a messiah. As the title of Chapter 14 says, nobody wants to be married to the Messiah. Some of the novel is based on what Tahmima Anam observed in the tech world when she served on the board of her husband's music tech startup. Anam is also the author of a trilogy of novels set during and after the Bangladesh Liberation War, in which Bangladesh won its independence from Pakistan in 1971. Her parents fought for independence in that war. Her father went on to work for the U. N. and then started a widely read newspaper in Bangladesh, which he still runs. Anam's mother runs a human rights organization. Tahmima Anam now lives in London with her husband and their two children. She's the recipient of a Commonwealth Writers' Prize and an O. Henry Award and was named one of Granta's best young British novelists. Her new novel has been recommended on a lot of summer reading lists, including in The Washington Post. Tahmima Anam, welcome to FRESH AIR. I really enjoyed your book. And I'd like to start with asking you to read a short passage that I think will set the scene that the social media world is set in. So this takes place when the main characters are making their opening pitch to be part of Utopia, the startup incubator. TAHMIMA ANAM: Thank you so much, Terry. I'm thrilled to be here so. I'm just going to read from the beginning of the book. (Reading) Why don't we introduce ourselves? Leann (ph) says. I'm the head of innovation here at Utopia. Hey, I'm Marco (ph), says a man with deep-set eyes and a sharply trimmed beard. I created obit. ly (ph), a platform that manages all the social and public aspects of death. A woman with bright pink hair waves hello. I'm destiny. I'm the founder of Consentify (ph), a way to make every sexual encounter safe, traceable and consensual. A thin, stern man in a lab coat leans against the table. My name is Rory (ph). I run Lone Star (ph). He speaks with a clipped Scandinavian accent. I want every single person in the world to stop eating animals. We would never fit in. First of all, it would be impossible to find a cute, vitamin-gummy way to describe the platform. And then the rest of it - the confidence, the hair, the way they all look as if they slid into place like a synchronized swim team - I cannot imagine ever being that comfortable in my skin. GROSS: So thanks for reading that passage from your novel \"The Startup Wife. \" So now you should introduce us to the platform that your main characters create. ANAM: So the platform is called WAI. It's pronounced why, obviously, as in why are we here? But it's spelled W-A-I, which stands for We Are Infinite. And what it is is a way for people to connect via rituals. So you go on the app, and you tell it the things that mean something to you - your favorite cartoons, your - the food that you love, important experiences that happened to you in childhood. And then you ask for a ritual. You say, I want to get married, and I'm a - you know, for instance, in the book, there are these two classicists that get married, so they have a Homerian (ph) wedding ceremony. And that's what the platform gives you, and then you get to connect to other people via those rituals. So it's kind of an antisocial media social media in the sense that you're not talking about superficial things; you're connecting via the rituals that give your life meaning. GROSS: And this is a platform that creates rituals without the baggage of religion. So it's a kind of - secular rituals for people who don't have religion in their life but still want ceremonies. Do you relate to that? ANAM: I do, actually, because I'm not a religious person myself, but I can see how having a kind of organizing construct can be so relaxing in the world, where there are so many uncertainties. And giving people something to hold on to, giving these kind of moments of punctuation in your life, where you're looking forward to something - the baptism of your child, a bar mitzvah - you know, we don't have that as people who don't necessarily adhere to a particular form of religion. So I thought, wouldn't it be great if we could give atheists the same kind of scaffolding that religious people have? GROSS: Of course, things go terribly wrong in your book with this app. (LAUGHTER) GROSS: I'll leave that to readers to find out exactly what happens. But how did you come up with the idea for this app? I mean, we'll get into this later, but you're on the board of directors of an app that your husband created, so you know something about the social media world. ANAM: That's right. So, I mean, in a way, it was a literary device because I wanted to give the two main characters, Asha and Cyrus, a startup that was very unconventional because neither of them are your typical startup founders. They don't come from Silicon Valley. They're not natural entrepreneurs. And so I wanted to give them something that, to them, felt very countercultural. And the fact that it becomes a startup is almost accidental. And that does mirror my own life. So my husband and I were going to be academics. I mean, I was going to write novels, and he was going to be a professor of Chinese philosophy. And then he invented this thing which is, in fact, an app that works with a keyboard, and he started this company. And I feel like the whole journey has been one of kind of discovering the world of startups sort of from an outsider's perspective. And that's exactly what Cyrus and Asha do. GROSS: So the startup incubator they become part of, Utopia, is - among other things - a way to attract funding from venture capitalists. But Utopia is especially interested in apps for the post-world world. In other words, they're preparing for some kind of apocalypse. It could be climate change. It could be war. It could be anything that would end the world as we know it. I understand that you started a fake website for Utopia while you were writing the novel, and you actually got interest from people. Tell us more. ANAM: So one of the really fun things about writing this book is that I got to make up all these sort of crazy startups that would probably - I mean, I don't know. Some of them might exist in the world, and some of them might not. And then once I had done that, I got a designer friend of mine to create this website. And occasionally, when I'd been talking to people in the startup world, as a joke I will just give them the website address and not tell them that it's fake, and there has been some interest. And the company that gets the most interest is the one that's called Empty (ph), where rather farcically you subscribe to nothing. You get an empty box every month, and you get to put your baggage into the box and send it back to this company, and they get rid of it in a responsible way. So let's say you're getting divorced. You put your wedding ring in it, and they kind of, you know, incinerate it for you. So for some reason, that has been the one that people are most interested in investing. But yeah, that's kind of, like, a little joke that I sometimes like to play on people. GROSS: That's crazy you could just give it away to the Salvation Army or your local thrift store or throw it away, and. . . (LAUGHTER) ANAM: Well, I think that you're touching on something, which is that one of the things that startup culture does is that it takes something that is very familiar to you, that you feel that you already know what to do - you know, you know you can send your junk to the Salvation Army or put it in recycling. But it somehow is there to create an idea that you can make things in your life easier or more seamless or more meaningful by in somehow engaging in the startup. So, you know, there's all kinds of apps that have - there's one where they send you laundry capsules in your letter box. Putting things in letter boxes is, like, a big thing right now - so flowers in your letter box, your laundry detergent, your tampons, you know. So we know that we can just go out and buy them, but there are startups that are devoted to packaging your everyday activities in slightly different ways and creating businesses out of them. GROSS: So are you interested in the postapocalypse world? ANAM: Well, I think right now we're all interested in the postapocalyptic world because we're kind of living in it. You know, I wanted to give Utopia a slightly different sort of flavor than most tech incubators. And I've been to some of these co-working spaces and to some of these incubators, and there was a lot of hype and a lot of promise and a lot of talk about community. And I just wanted to give it that edge, which was, you know, they were thinking about this other world, and that was kind of bringing them all together. And Utopia is also a place where Asha gets to meet other female founders, and she builds these friendships with these other women who are coming up with all kinds of businesses. There's the silent vibrator. There's Consentify, which is about, you know, pre-agreeing to all your sexual activity before you engage in it. So I wanted to give her that, and I - so I put her in this place which is called Utopia and has a lot of the elements of what you might imagine is, like, a perfect world - is imagining a world that is better than the one that sort of gets obliterated by an apocalypse. GROSS: But I am wondering if you grew up with a fear of the end of the world or of war. I mean, your parents fought in the Bangladesh war of liberation, so war was the memory background of your life. I don't know how much they told you about it. And your father worked for the U. N. for years, and the U. N. is all about creating peace because there's so much war. So I'm just wondering if that was a part of your - you know, your nightmares or your fears or if you read a lot of postapocalyptic fiction. ANAM: Yeah. That's a really good question, Terry, and I hadn't really thought of it that way. So I grew up hearing stories about the Bangladesh War. It was very much the thing that we talked about around the dinner table all the time. My parents had been in the war. It was the sort of organizing principle of their lives. And the other thing is I come from a country where this kind of sense of apocalyptic possibility is always in the air because the climate is so extreme. And so it feels - it has always felt very much like a fragile place that was born out of this brutal war, you know, that it sort of barely survived, and then trying to beat the odds. And now, obviously, that big sense of apocalyptic change is climate change, which is going to affect Bangladesh more than many other countries in the world in a really extreme way. So for sure, I mean, I hadn't thought of it that way, but the sense of the end of the world being very close has certainly been something that I've grown up with. GROSS: Yeah. That was probably a part of your life even in your early childhood. ANAM: Yes. I mean, my parents - you know, so I was born four years after the war ended, and my parents both came into political consciousness in the '60s. They were revolutionaries. They were nationalists. My father fought in the war. And it was definitely something that played a huge part in the way that I was raised. And then we left Bangladesh when I was 2 years old because my father got a job with the U. N. , and I think that because we were far from home, I heard those stories even more. And I think that people who stayed in Bangladesh possibly were more on the sort of, well, this war happened; we need to move on and try to sort of get over the past. But for them, it was something that they really held onto and they talked about a lot. And they didn't just talk about it in sort of tragic terms and saying, you know, how awful it was - which it was. It was an extremely brutal war. And millions of people were killed, and millions of women were raped. But they also talked about it as this moment where they, as young people, got to imagine a country into being, and that was incredibly inspiring and important for them. And it was - like I said, it was the sort of foundational moment of their lives. And so I think a lot of the way they brought me up and a lot of the things they talked about and their relationship to each other was kind of built around that experience. GROSS: Let's take a short break, and then we'll talk some more. If you're just joining us, my guest is Tahmima Anam. Her new novel is called \"The Startup Wife. \" She's the author of an earlier trilogy of novels that have to do with the war for independence in Bangladesh. We'll be right back. This is FRESH AIR. (SOUNDBITE OF THIRD WORLD LOVE'S \"SEFARAD\") GROSS: This is FRESH AIR. Let's get back to my interview with Tahmima Anam, author of the new novel \"The Startup Wife. \" It's about a startup co-founded by a couple. The app's surprising success leads to trouble, including in their marriage. She's also the author of a trilogy of novels set during and after the Bangladesh Liberation War, which her parents fought in. Can you tell us, as briefly as you can - and this is an impossible question, and I apologize for asking it this way - what the war was about? ANAM: So when the British left India in 1947, they left behind two countries - Pakistan and India. And Pakistan was divided into two. Pakistan was in two halves on either side of India, divided by 3,000 miles of India. There was West Pakistan, which is the country that we now know as modern-day Pakistan, and there was East Pakistan. And it was very clear from the beginning that this was not going to work because the only reason these two regions were put together as one country was because they had a majority-Muslim population. But they were culturally and politically and socially and linguistically, very importantly, completely different. So this came to a head, and in 1971, you know, we had a war of independence, which was brutally suppressed by Pakistan. You know, there was a genocide, and, like I said, millions of people were killed. You know, they obviously didn't want the two countries to split. But after nine months, India intervened, and Bangladesh became independent. That's the sort of potted history, and I would say that that history and that split comes from a sense that after the British left, they - you know, the Bengalis of East Pakistan were subjected to a second rule of colonialism by West Pakistan rather than feeling that they were now part of an independent country. And so that sort of spirit of independence that started with the independence of India and Pakistan then sort of continued. And now in the subcontinent, we have three countries. And I was born into the independent country of Bangladesh. But my parents were born in Pakistan and in East Pakistan. GROSS: And we'll talk more about this later. But in terms of the apocalypse, in terms of, like, anything can happen, Bangladesh gets its independence. But eventually, there's, like, a military coup and, you know, a repressive government. So even after fighting for independence, things go bad. ANAM: Absolutely. So this is also kind of a big shadow that was sort of hanging over my head as I was growing up. And one of the great tragedies of the war was that after it was won, within four years, the person who sort of led the independence movement was assassinated along with 14 members of his family in this terrible tragedy that was happening to a country that was barely getting on its feet. And it took - I mean, I really don't think those early wounds, the war, the assassination of Sheikh Mujib, I don't think those things have ever really been reckoned with. But I think it's only now that we're starting to come out of those sort of long shadows. GROSS: So getting back to the app in your book, you know, it's an app for creating rituals and ceremonies for people who are not religious. But it draws on religion. It draws on myth. It draws on various cultures to create these rituals. So since you grew up in the background of a war for independence that was in part a religious war in the sense that Pakistan was formed because it was majority Muslim, and a lot of Muslims who were living in India moved voluntarily or felt forced to flee to Pakistan - did that color your family's sense of religion? ANAM: Absolutely. So my father, when I was growing up, was an atheist. I was not raised with any form of religion. And partly, I think that was because of the politics of the time, and specifically because, you know, Pakistan was a repressive regime that was forcing us to stay, you know, part of this union on the basis of religion. And the Bengali people were saying, no. We have cultural and linguistic rights, you know? They imposed Urdu as the official language of both Pakistans even though nobody in Bengal spoke Urdu. We all spoke Bengali. Bengali people have a fierce attachment to their language, to their culture, to the music of Rabindranath Tagore. I mean, that is - you know, if ever there was a poet who basically defined a country, he defined so much of who we are in Bangladesh. So it was that sense of rejecting religion in favor of a secular cultural identity, and that is why I was raised without religion, because my parents sort of grew up in that movement. GROSS: So you know, getting back again to the app that's created in your book that - you know, that the main characters created, it's an app for rituals and ceremonies for people who don't have religion to provide that because they don't believe in any religion. But (laughter) the startup is created by Asha, who's married to Cyrus. She creates the app. She does all the coding for it. He becomes the head of the startup because he's the man and he's good at promoting things. He's good - he's really good at selling himself or selling his ideas or - so he becomes the head of it. And he's also the one who talks to people every day about life and, you know, the importance of ceremony and the meaning of life because he has, basically, his own channel to talk to the followers of this app. And he becomes this, like, messiah figure, which is really interesting because I think you've hit on something really interesting - because people who don't have religion in their life in this book create a messiah figure of their own in the head of this app that's not about religion. ANAM: Yes. There is a real irony there because people are obviously, you know, joining - why? - because they want an alternative to organized religion. And then, there they are worshipping a male visionary messiah, you know, prophet, basically. And I think the other irony is that Asha, who falls madly in love with Cyrus, you know, he's her high school sweetheart, she meets him again after many years. And she kind of feels this triumphant sense when she meets him again and he loves her back. And the other irony is that Asha, who creates the app and who does all the coding and it's really her idea, when it comes down to it, she says to Cyrus, oh, no you be the CEO. I'm just a coder. I'm going to sit in the background. And she lifts him up. And she thinks to herself, you know, towards the end of the book, I literally created a platform that makes the entire world worship my husband. (LAUGHTER) ANAM: She does that. I mean - you know, and this is an - it's an exaggeration of what we all sometimes do. When we love someone, we lift them up. But she just does it to an absolutely intense, kind of huge, massive, exaggerated scale. GROSS: Well, I think we need to take another break here. So let me reintroduce you. If you're just joining us, my guest is Tahmima Anam. Her new novel is called \"The Startup Wife. \" We'll be right back after a short break. I'm Terry Gross. And this is FRESH AIR. (SOUNDBITE OF PAUL SHAW QUINTET'S \"PEEKABOO\") GROSS: This is FRESH AIR. I'm Terry Gross. Let's get back to my interview with Tahmima Anam, author of the new novel \"The Startup Wife. \" It's about a startup co-founded by a newly married couple. The app customizes rituals and ceremonies for people who aren't religious but want the sense of community and ritual that others find in religion. So your husband founded a startup. It's a music startup that from what I can tell creates, like, software that's music related. Like, there's a colored keyboard to help people learn how to play songs. There is an app that creates notes in the space between the keys of the piano - things along those lines. So it's really, like, for people who want to learn more about music or want to do music production. So the startup was founded at about the same time you got married, so your marriage and the startup were kind of on a parallel track. Did you draw from your own experiences to write this book? And is there an experience that you found confusing that you needed to, like, work out in the book? ANAM: (Laughter) That's a great question. Well, I'll tell you first the ways in which it's not the same, which is that I had nothing to do. . . GROSS: You're married. You're married. (LAUGHTER) ANAM: I mean, I didn't come up with the idea for Roli, which is my husband's startup. It was all his idea. I can't take any credit for that. The ways in which I think I did draw from my experience were in two ways. The first was that, as I said to you before, neither of us expected to be involved in the startup world, and so it was a very interesting journey to meet someone who, for all intents and purposes, we were going to lead these lives of both being academics and artists, and to watch him then have to raise money, to be the boss of a hundred people - I mean, that really has a big impact on a person. So having that much sort of power and being the boss, I think that definitely was something that I didn't - that we both - neither of us expected. And I think that there were some changes that were quite surprising that we both had to kind of work out. So there was definitely that. And the other thing was that I was on the board of - I've been on the board of the company from the very beginning, and I had obviously no experience of the boardroom. And I really enjoyed thinking about writing this book the entire time that I was on that board because one of the great pleasures of being a writer is that you get to put all of your experiences somewhere. So anytime someone cut me off or ignored me or didn't take me seriously, I thought, I'm going to write that down. (LAUGHTER) ANAM: So it was a way of processing that experience which was very new for me and sometimes quite challenging because my - the other half of my life was, you know, sitting quietly in a room and writing books, which had nothing to do with the startup world until I wrote this book. So yes, it was definitely thinking about - imagining this novel was a great way of processing the actual experience I was having both sitting on the board, watching people interact with me, but also watching the changes that my husband was going through as he went from being a sort of quiet academic to being everyone's boss. GROSS: In your Twitter bio, one of the things you say to describe yourself is feminist killjoy. (LAUGHTER) GROSS: Did you feel like a feminist killjoy on the board? ANAM: You know, Terry, I wish I was more of a feminist killjoy. And one of my goals for the next, you know, however many years of my life is to call people out a little bit more because there is so much sexist language embedded in probably any kind of business environment. But because I don't come from a business environment, I'd never heard it before. So for instance, people will commonly - men will commonly say, well, they're already pregnant, they might as well have the baby, when they're talking about someone who's so invested in you they're just going to give you more money or something like that. Or they'll say, we should open the full kimono (laughter), which is both sexist and kind of racist. But I think in a lot of those situations, I just kind of sat there and was like, ha-ha (ph), you know? I kind of. . . GROSS: I can use this (laughter). ANAM: Yeah. Yeah, exactly. I'm just going to put it in my book. But. . . GROSS: But not say anything. ANAM: But not say anything. And I think we need to be able to say out loud that language means something, and a joke, you know, even in the most kind of flippant way, is a representation of our actual values. So I hope that I can be more like Asha and less like the me that was just silently filing things away for my book. GROSS: There's a joke in the book about post-IPO wives. In other words, after the husband starts a successful startup, he sometimes trades in his wife for a newer wife. Is that something that you've actually witnessed in the tech world? ANAM: So I haven't witnessed it myself, but it was relayed to me by a close friend of mine who does a lot of executive recruiting. So she meets a lot of founders, and she sees companies from the sort of very beginnings of when they are just a few people, and she helps them hire executives to when they IPO. And I sort of floated the idea of this book to her, and I said, well, you know, I'm going to write this book, and what do you think of startup marriages? And she says, well, if they succeed, they almost always get divorced because either the woman says - and she's talking about a heterosexual relationship where the man is the CEO. Either the woman says, I'm really tired of you now; I just want half of everything you've got, and I'm out of here. Or the man says, more likely, well, thanks for helping me get through all the challenges of the last 10 years; I'm going to trade you in for someone who hasn't been through that with me, and we can just start afresh and enjoy all this wealth, I guess. So she was pretty pessimistic about it. GROSS: So I want to get back to your childhood and growing up in the shadow of the Bangladesh war for liberation, which your parents fought in. What did your parents do in the war? ANAM: So it was very interesting. My mother stayed in Dhaka throughout the war, and her home and my grandmother's home was used as a refuge for the guerrilla fighters who were coming back and forth from across the border. So they were being trained in India, and then they were, you know, doing their kind of guerrilla warfare against - so the war was essentially an army against an unarmed civilian population. And a lot of young men ran away from home and joined this guerrilla army so they could fight this - the Pakistani army. And so my grandmother's home became a hideout for those guerrilla fighters. So they would come back to the city, and they would hide in her house. And my mother kind of witnessed all of that, and my grandmother sort of sheltered these - basically, these guerrilla fighters. My father spent part of the war going to India and trying to drum up support for the independence war. He was a debate champion before the war started. He was three times the all-Pakistan debate champion, which made it very difficult for me to argue with him when I was growing up, just as an aside. But so he went around and basically did a lot of propaganda for the war. And then, he joined the army and was in training. And then by the time he finished his training, the war was over. GROSS: Was anyone in your family injured? ANAM: No one in my family was killed or injured, but many of their friends who had joined the guerrilla army were captured by the army, killed by the army, tortured and survived but were never the same. So that sort of generational trauma was definitely present. GROSS: Your grandfather was in Congress. Was this when India was a colony of Britain? ANAM: No. My grandfather was a minister in the Pakistan government. So after the independence of India in 1947, when there was - Pakistan and India were two independent countries, my grandfather was a member of Parliament. And he had a really interesting story because he was born in a village in what is now Bangladesh, which was then colonial India. None of his family were educated. They were tenant farmers, basically. But he was very, very bright, and he somehow, you know, educated himself and became a politician and quite a prominent journalist and political satirist. So he had a very exceptional trajectory in his life. And I think when I was growing up, that was also kind of one of the things that my parents talked about a lot was how this person who was a very unlikely politician - he didn't come from a sort of political background or from a family where you would expect someone to become a politician - he became a member of Parliament. GROSS: And your father became a diplomat after the war. He worked for the U. N. , for UNESCO, the U. N. Educational, Social and Cultural Organization. So he was, like, a media spokesperson. So you were raised in Paris, New York and Bangkok. It's hard for kids to change schools. You had to keep changing countries. What was that like for you? ANAM: If you had asked me this, I don't know, 30 years ago, I would have said it was really awful because I could never maintain friendships for more than a few years. I think, looking back, it was such a formative experience for me. And I would say the experience that was the most meaningful was when we moved back to Bangladesh. So my parents - you know, it was so interesting. We were living in all these countries, and they kept saying to me, we're just going to go home. We're not going to stay here. We're not going to stay in New York. We're not going to stay in Paris. We're going to go home. We're nationalists. We have to go back and do something for our country. And when I was 14, we did exactly that. We went home, and my father started an independent English daily newspaper, sort of not politically affiliated, which was very unusual at the time. It was almost - it was 30 years ago. So it was very tricky to not ever be in one place for very long. But I think it certainly had a lot to do with why I became a writer. So I can't really knock it in retrospect. GROSS: How old were you when your family moved from Bangladesh? ANAM: I was only 2 years old, so I really have no memories of growing up there. GROSS: So Bangladesh - going home so to speak - was like going to another foreign country. ANAM: Yeah, it was almost worse than going to a foreign country because at least when I was going to a foreign country, I was expected not to know anything. And there was this - there was a lot of hype about going home, and I felt just as unfamiliar there as I had felt when we moved to New York or to Thailand. I was just expected not to. So that was a tricky moment. GROSS: How did you know you wanted to be a writer? ANAM: I cannot ever remember wanting to be anything else, but I also remember feeling completely paralyzed by the fear of failure. And so I wanted to be a writer, but I had no idea if I could do it. And that's the thing about writing is you just don't know until you do it many, many times whether - even now, if you ask me, you know, do you feel like you know how to be a writer? I would say, definitely not. Every time I do it, it's like starting from the beginning. So I really wanted to do it. I knew I had some stories to tell, but I was also - as many writers are - you know, plagued with insecurity and a desire to succeed. GROSS: My guest is Tahmima Anam. Her new novel is called \"The Startup Wife. \" We'll talk more after a break. This is FRESH AIR. (SOUNDBITE OF NAOMI MOON SIEGEL'S \"IT'S NOT SAFE\") GROSS: This is FRESH AIR. Let's get back to my interview with Tahmima Anam. Her new novel, \"The Startup Wife,\" is about a startup co-founded by a married couple. The app's surprising success leads to trouble, including in their marriage. You've been a judge for the Man Booker Prize, which is Britain's most prestigious literary award. Is it hard to sit in judgment of fellow writers? And I'm wondering if you ever meet any writers who you voted against (laughter) for the prize. And they wouldn't know - necessarily know that, but I could see how awkward it would be for you. ANAM: Well, luckily, I judge the Man Booker International, which is for novels in translation. And so I. . . GROSS: Oh, God. Yeah, you're lucky (laughter). ANAM: I didn't know a lot of those writers. But I can tell you, Terry, when I - being on the other side of that and having, you know, other friends who are on judging panels and - it certainly is part of that world, which can be very awkward. And I remember sitting in that room judging that prize and feeling extremely passionate about the kind of book that I wanted to win. And it gave me a little bit of perspective on, you know, why I hadn't ever been on one of those lists or sort of what happens behind the scenes. So in a way, it was - made me feel a little bit better about possibly the times when I hadn't appeared on any of those lists. GROSS: So why do you think you were not on those lists? ANAM: (Laughter) Well, because it's a very subjective thing, judging. You know, what is brilliant to one person is, you know, not brilliant to another person. One of the - you know, I'm talking a lot about anxieties and insecurities, but I think one of the concerns that I had when I sat down to write this book was that it wasn't serious enough, that I had written a trilogy of novels that were, in a way, the kinds of books that you would expect from a person that comes from where I come from - you know, dealing with the big historical ideas of religion, talking about social change, talking about revolutions. You know, this is the kind of story - those are the kinds of stories that I feel I was expected to write. And I'm really proud of them. And I didn't feel that there was anything more urgent that I had to say. But when I sat down to write this book - and I knew it was going to be a satire, I knew it was going to be a comedy - I thought, gosh, will anyone ever take me seriously again. And, you know, will I be one of those people that wins prizes? Or will I be one of those people where it's like, well, she wrote something. And it was light-hearted and joyful. But it's not serious. And that was something I really had to overcome. In fact, I asked my agent to send the book out under a pseudonym. GROSS: Why did you end up not using the pseudonym? ANAM: Well, she persuaded me not to. And my editor persuaded me not to. And I just kind of had to own what I had done, you know? I had to decide that it was serious and that I was tackling all these issues of, you know, sexism in the workplace and the future of technology and what happens to a marriage when the man gets celebrated and the woman gets left behind. And these are all things that have preoccupied me. I am a feminist killjoy. (LAUGHTER) ANAM: And these are things that preoccupied me in my whole writing life. They're just told in a slightly different tone. And I just had to become comfortable with that, I guess. GROSS: What was the name you were going to use if you used a pseudonym? ANAM: Oh, I'm glad you asked. So everyone in Bangladesh has a nickname. People have these very serious, you know, Arabic, proper names that are on their passports. And then there's something that people call them at home. And my father named me after the Rosetta Stone. And in Bangladesh, everyone calls me Rose. So I was going to call myself Rose Lanam. And Lanam is the name that Roland and I gave to our children because it's a combination between our last name - our two last names. So Lamb - he's Lamb. I'm Anam. So our kids are Lanam. So I was going to call myself Rose Lanam. And she was my alter ego. I didn't just think of her as a pseudonym. I thought of her as the person I had to become in order to write that book. GROSS: Why did you have to become somebody else? Because, let me just say, I think, in some ways, this might be your most autobiographical book because your other books are more about people who lived in Bangladesh. One of the books was more about your father's generation. But this is about - it's about your generation. It's about a woman of Bangladeshi descent, the daughter of Bangladeshi immigrants who grows up in America, who was married to somebody that have a startup like your family does. I mean, there's so many similarities. ANAM: Yes. I agree with that. But I had to summon Rose Lanam so that I could write all the dirty jokes, Terry. (LAUGHTER) GROSS: Really? ANAM: They don't come easily to me. I mean, I - you know, I had Asian parents. And I think that sort of loose, confident, sassy, lots of F words - that kind of language does not come easily to me in a sort of public way. You know, if you and I were just hanging out and having dinner, I would certainly speak in Rose Lanam's voice. And so in a way, you're right. She is much more me. But to summon her in a public way, to bring out all of that, it just took - for me to have the confidence to put into writing what I was putting into, like, my text messages to my girlfriends, you know, that sort of tone, that sort of satirical, funny, irreverent tone, it took a little bit of unlearning some of the - maybe some of the limitations I felt that I had in presenting a public self. GROSS: Does this mean you're concerned about anybody in your family reading it? ANAM: I'm not concerned. Although, my mother said to me, because I had put - I had written to some friends - or I put in a Facebook post, you know, this book has a lot of curse words in it. And she said - she literally said, what is Boro Mama (ph) going to say? Boro Mama is my eldest uncle. And I said to her, if I sat down and thought about what Boro Mama was going to say, I would never write another word ever again. GROSS: (Laughter). ANAM: I mean, it is a little bit of that, Terry. But it's also that I - you know, when I was growing up, my father - the term third world country was very much an OK thing to say in the '70s when I was growing up. And my father would say to me, you come from a third world country. You have to get people to take you seriously. Everyone's going to not want to take you seriously. And your job is to get people to take you seriously. And I think I - you know, part of wanting to do a Ph. D. even though I knew I wasn't going to be an academic, it was about that wanting to bring a kind of gravity to my self-presentation. And I had to slightly unlearn that when I was writing this book. And then I had to have the confidence to say, OK, this is still serious even though it's full of jokes. GROSS: Well, I'm glad you unlearned what you had to unlearn (laughter). ANAM: Thank you, Terry. GROSS: So let's take another break here. If you're just joining us, my guest is Tahmima Anam. Her new novel is called \"The Startup Wife. \" We'll be right back. This is FRESH AIR. (SOUNDBITE OF JAMES HUNTER BAND SONG, \"I WANNA GET OLD WITH YOU\") GROSS: This is FRESH AIR. Let's get back to my interview with Tahmima Anam. Her new novel is called \"The Startup Wife. \" You've referred to finding your voice and power as a woman. Were you encouraged to do that by your parents? ANAM: I definitely was. And they were way ahead of their time. I was the first girl born into my dad's family for three generations. So there had only been boys. And my father tells the story of how, you know, when people would come and see me as a baby, they would say, oh, we have to find her a prince or something to marry. And he basically banned that. He said, when you look at my nephews, why do you say, oh, he's going to grow up and be a barrister? Because, you know, at the time, in Bangladesh, being a barrister was, like, the highest thing you could aspire to. He's going to be a barrister or a doctor - why don't you say that to my daughter? And he really angered a lot of the relatives who would come and see me because he was so - you know, he basically put a ban on talking about things like marriage as something that I should aspire to. And my mother has been a lifelong feminist activist. So I think that I had the privilege of growing up in a family where these things were absolutely taken for granted and where conversations about equality and about feminism were right at the forefront of - you know, so present in our lives. And I'm deeply grateful for that. GROSS: I want to get back to something in your novel. In the book, the parents of the main character are from Bangladesh. They're now immigrants in America. They both are not religious. But as they got older, the mother starts saying, inshallah - God willing - in her sentences. The daughter sees her, like, kneeling on a rug, and it appears the mother is praying. And the daughter thinks, like, this is what happens when people get older (laughter). So I'm wondering if you've observed that in your parents, in spite of their atheism. ANAM: Yes, I definitely have. And certainly among the people of their generation, who grew up in the shadow of this war, there has been as they've gotten older - and also, I think as the society has taken decidedly more of a turn towards religion, I've sort of seen that in my family. I've seen it among their friends. My mother certainly has - practices more. And - but the interesting thing is that it hasn't at all affected her politics, and she is just as opposed to the hijab now as she was 20 years ago, before she started becoming a more practicing Muslim. So I think it hasn't had an effect on their politics, but certainly, in the privacy of their home, I wouldn't say so much with my father, but certainly with my mother, I have seen those changes. GROSS: I think I read that your mother told you that it's important to learn some verses from the Quran. In case. . . ANAM: (Laughter). GROSS: . . . You're attacked by Muslim extremists, you can quote the Quran, and it will help save you. ANAM: There was a time in Bangladesh where there were a lot of attacks against writers. It was a really dark moment. It was very recent, you know, in the last 10 years. And I was having this conversation - I can't remember if it was with my mother - where people were saying to me, you need to be able to prove that you're a Muslim. And I have no way of doing that because I'm a completely nonpracticing Muslim. And I have to say, of all the sort of threads of my identity, it's the one that I have rejected the most. And the reason is that I don't have role models for deeply religious Muslims who share my interest in gender equality. I just don't have those role models. And I think that when the feminist imams and when the feminist Muslims come out and become the leaders of the Muslim community and I can look up to them and say to my daughter, hey, you know what, this religion is going to embrace all sides of you and embrace your kind of independence and power as a woman, I think that is the moment where I'm going to be able to embrace that identity. But perhaps because I haven't done enough learning or reading on my own, it's something that I haven't quite come to yet. GROSS: Have you memorized verses in spite of that, in case you need to recite them? ANAM: (Laughter) No. Don't tell anyone. GROSS: (Laughter) I won't. No one will hear this. (LAUGHTER) GROSS: It's been such a pleasure to talk with you. I really want to thank you so much for doing this interview. ANAM: Thank you, Terry. It's been an absolute thrill. I'm so grateful to you. GROSS: Tahmima Anam spoke to us from London. Her new satirical novel is called \"The Startup Wife. \" Tomorrow on FRESH AIR, we'll talk about Facebook - the problems it's created and the problems it's facing. My guests will be new York Times reporters Sheera Frenkel and Cecilia Kang, authors of the new book \"An Ugly Truth: Inside Facebook's Battle For Domination. \" They write, Facebook's problems have been features, not bugs. I hope you'll join us. (SOUNDBITE OF TODD GARFINKLE'S \"VULGARITY IN TROPICAL LIVING\") GROSS: FRESH AIR's executive producer is Danny Miller. Our technical director and engineer is Audrey Bentham. Our interviews and reviews are produced and edited by Amy Salit, Phyllis Myers, Sam Briger, Lauren Krenzel, Heidi Saman, Therese Madden, Ann Marie Baldonado, Thea Chaloner, Seth Kelley and Kayla Lattimore. Our associate producer of digital media is Molly Seavy-Nesper. Roberta Shorrock directs the show. I'm Terry Gross. (SOUNDBITE OF TODD GARFINKLE'S \"VULGARITY IN TROPICAL LIVING\")", "section": "Author Interviews", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-07-13-1015483097": {"title": "Book Reveals The 'Ugly Truth' Of How Facebook Enables Hate And Disinformation : NPR", "url": "https://www.npr.org/2021/07/13/1015483097/an-ugly-truth-how-facebook-enables-hate-and-disinformation", "author": "No author found", "published_date": "2021-07-13", "content": "TERRY GROSS, HOST:  This is FRESH AIR. I'm Terry Gross. A new book investigates Facebook's failure to protect against spreading hate speech, disinformation, conspiracy theories and calls to violence. The book also shows how Facebook became an advertising company, monetizing its users and their data. The book is called \"An Ugly Truth: Inside Facebook's Battle For Domination. \" My guests are the authors, Sheera Frenkel and Cecilia Kang, who are reporters for The New York Times. Frenkel covers cybersecurity and is based in San Francisco and covers technology and regulatory policy and is based in Washington, D. C. The book focuses on the period between the 2016 presidential campaign and the January 6 insurrection, a period in which Trump became one of Facebook's most profitable users and his campaign became one of the platforms most profitable advertisers. The authors say it was also the period in which it became clear Facebook was unprepared to deal with a political leader like Trump, who used the platform to spread misleading and false information. We recorded our interview yesterday morning. Sheera Frenkel, Cecilia Kang, welcome to FRESH AIR. And congratulations on the book. CECILIA KANG: Thank you. SHEERA FRENKEL: Thank you, Terry. GROSS: So Trump and his followers created many headaches and nightmares for Facebook, which Facebook was unprepared for an American president spreading these falsehoods. But Trump was also a gold mine. So how did Facebook profit from Trump's falsehoods spread on Facebook? FRENKEL: Well, Trump had over 30 million followers by the time he was kicked off Facebook. He was a major draw for people all over the world to come to Facebook and hear what he had to say about the day's news. He not only managed to bring audience and relevancy to Facebook, he created this constant sort of churning stream of information that people couldn't help take their eyes off of. And ultimately, that's what Facebook needs to stay relevant. GROSS: Even if you repost one of Trump's messages and add a critical comment, you're still amplifying his post. KANG: Absolutely. What you're doing is doing what Facebook wants, which is you're engaging with his content and you're engaging with the website. And that's really the core of the business there is to get people's attention and to engage and to be active. GROSS: So Facebook profited enormously from Trump's campaign spending. How did the campaign use Facebook tools to maximize its reach? FRENKEL: This is Sheera. The Trump campaign really used Facebook in unusual and unprecedented ways for a political campaign. They did something that had previously not been done by politicians in using Facebook's incredibly targeted advertisement, both to reach people and to sort of do an AB testing of what messages worked best. So, for instance, they would send out two, three, four versions of the same message and then whichever one they saw in real time reaching people and being amplified by people, that's the one they would double down on and put more money into. Once Trump did this, I would note that politicians all over the world followed suit. And they discovered that Facebook was an incredible way in telling people exactly what they wanted to hear. GROSS: Now, you write that Facebook employees were embedded in Trump's New York City campaign headquarters to help riff on Hillary's daily speeches and target negative ads to specific audiences. Facebook employees were embedded in the Trump campaign? FRENKEL: So interestingly, this is something Facebook actually offered both campaigns. The Hillary Clinton campaign just turned them down and said that they didn't want that kind of assistance. And so, yes, the Trump campaign ended up with Facebook employees in their offices advising them on how to best use Facebook tools, much like you would a major advertiser like Pepsi-Cola. They, in real time, could tell them this tool is working for you, this one is not - this messaging is working for you and this one is not. And because Facebook's algorithms are so sensitive and because Facebook's tools are so precise, they could even tell them things like, well, we think that this is playing well in this demographic or in that part of the country. And that trove of data was so important to the Trump campaign in understanding who their voters were. GROSS: So do you think Facebook employees helped the Trump campaign amplify misleading or outright false information in Trump campaign ads? FRENKEL: You know, Facebook is always really careful in saying that they're a neutral platform, as are their own employees. And so whatever the content was that Trump was amplifying, whether it was misinformation, conspiracies, just, you know, outright false, you know, false information, Facebook employees helped it regardless of what the content was. And often they don't even look at the content themselves. They just give them the data. This messaging is working and that messaging is not. GROSS: Tell us more about the rationale behind that policy of not fact-checking political ads when you know that some of that information is outright false. And what was the debate within Facebook about fact-checking political ads? KANG: I think you have to actually go back to the creation of Facebook to understand their policies on speech and the belief that the CEO and co-founder Mark Zuckerberg had from the founding of the company that more expression, that freedom of expression was going to be the bedrock policy for the company. And he also understood that engagement was really important. And from the earliest days, when he was at Harvard, he would - he told people he really wants to create a site where people just sort of mindlessly scroll, and they're online, constantly posting and reading each other's posts. He understood the power of attention and engagement. And Mark Zuckerberg also - he does truly believe in the idea of freedom of expression. And what we've seen and what we reveal in this book is that that policy and his philosophy towards speech has really evolved and that Donald Trump really tested him. And he was, in many ways - Donald Trump - the person that surfaced all of the things that were embedded and core to the platform and the business that were problematic. FRENKEL: I just wanted to add one thing, which is that if anyone listening remembers MTV and how popular that was in the 1990s, that's what Zuckerberg was really basing this idea on. The same way that you would sit and for hours with your friends watch MTV, he wanted people on Facebook. Only here, Facebook was collecting data about them in real time. And as they mindlessly scrolled, Facebook was amassing more and more information about them. GROSS: So has the policy about political advertising changed? Is there any fact-checking on Facebook now? FRENKEL: Facebook still allowed politicians to post ads without being fact-checked. And in fact, politicians could say things in advertisements that the average Facebook user could not. They did change other things in the platform. For instance, they created an ad library where you could search for ads and see what politicians were posting. And that was a level of transparency they hadn't previously had. However, they did double down, and they did maintain firm in their belief that politicians could say things in ads without the benefit of a fact-check. GROSS: Sheryl Sandberg was first brought on to help grow and monetize Facebook. What had she done when she was at Google to maximize advertising growth there? KANG: Sheryl Sandberg was an incredible success at Google. She created what was really one of the earliest big behavioral advertising business models that became known as AdWord (ph) and AdSense at Google. She created a multibillion-dollar business for Google. So she was well-known by the time Mark Zuckerberg was looking for a partner to really build the business and expand it and to refine it. So when he met - when Mark Zuckerberg met Sheryl Sandberg in December 2007, there was a real meeting of minds. They both had looked at each other with a lot of interest because they knew that they could offer the other one something different, which was Mark Zuckerberg was a technology visionary, and Sheryl Sandberg was absolutely the business erudite and visionary for the company. Sheryl Sandberg came in, and within her first weeks, she had called a couple meetings with some of the biggest executives at Facebook at the time. And they refined the business. And they realized from that moment forward that they would pursue a behavioral advertising business. GROSS: let me reintroduce you here. If you're just joining us, my guests are Sheera Frenkel and Cecilia Kang, authors of the new book \"An Ugly Truth: Inside Facebook's Battle For Domination. \" They're both reporters for The New York Times. We'll be right back. This is FRESH AIR. (SOUNDBITE OF JAKE MASON TRIO'S \"THE STRANGER IN THE MIRROR\")GROSS: This is FRESH AIR. Let's get back to my interview with the authors of the new book \"An Ugly Truth: Inside Facebook's Battle For Domination. \" Cecilia Kang and Sheera Frenkel are reporters for The New York Times. Kang covers technology and regulatory policy. Frenkel covers tech and cybersecurity. So Donald Trump, as both candidate and president, challenged Facebook's standards of speech because there were so many mistruths and out and out falsehoods or lies that Trump posted. So what were the standards before Trump for taking down a post? FRENKEL: Before Trump, Facebook tried to implement fairly universal standards about what it would take down. It created rules in its content moderation policy that applied to everyone evenly, or so it declared. And we saw Trump really at the beginning of his candidacy when he was first running for president, run up against those rules and post something on Facebook, a ban, he said, that would make sure that all Muslims did not enter the United States that within Facebook was seen as possible hate speech. Facebook's own employees went to Mark Zuckerberg and Sheryl Sandberg and said, you know, we think this violates our policies. Shouldn't we be taking this down? And at that moment, when Facebook decided to leave up his post and start to carve out a new policy for Trump, they were essentially creating a separate class of user on Facebook. Now, it would take years for them to come around and kind of declare this officially and to formalize it. But that first step showed that Facebook was really carving out something for important people, for VIPs on the platform that the average user didn't get. GROSS: Once that policy was formalized, what was it, and what was the justification they offered for it? KANG: So they called it the newsworthy exemption. The way that Facebook and Mark Zuckerberg described it is that political figures deserved this special class of, really, an exemption from the other hate speech and other speech policies they had because political speech was of public interest and importance for the world to know. So - and Mark Zuckerberg said in a speech at Georgetown in 2019 that he believed that political speech was the most scrutinized speech. Mark Zuckerberg, in his view of expression and free expression, has a belief that more speech will actually drown out bad speech. So his view was that even if there were lies, lies from a politician such as Donald Trump, that the public would respond with their own fact checks of the president and that the fact checks would rise to the top. And that would, in a sense, neutralize any of the problems with political figures. GROSS: But I'm sure the people at Facebook saw it wasn't working out that way. So how did they respond to the fact that lies were often winning out? FRENKEL: That was so difficult for Facebook and specifically Mark Zuckerberg to contend with. And that's something that for us was really interesting in writing this book and showing repeatedly over and over again, despite their ideas really being disproven. You know, this idea that people would reject falsehoods. They would reject misinformation. They would reject conspiracies, despite Facebook's own algorithms showing that that wasn't happening - they continued to persist in this idea. And really, up until the end of Trump's presidency, Mark Zuckerberg and Sheryl Sandberg were still defending the idea that Trump and, really, political leaders all over the world could and should say things on the platform as they wished. And people could and should respond as they wished. They failed to see what their own employees were telling us. And that - for us In, the book, one of the most fascinating thing was talking to employees within Facebook who were raising the alarm again and again and again and saying, this is a problem. You know, we are spreading misinformation. We are letting the president spread misinformation. And it's being amplified by our own algorithms. Our systems aren't working the way we predicted, and we should do something. And yet, you know, Mark Zuckerberg and Sheryl Sandberg stay the course. GROSS: Well, you have a lot of insights into this, but I'm not sure you can actually answer it. But I'll ask, what - do you think that Sandberg and Zuckerberg were defending their ideal of what free speech should mean on Facebook? Or do you think they were trying to protect Facebook's profits? FRENKEL: You know, our sources admit it's a little bit of both. I think publicly Mark Zuckerberg and Sheryl Sandberg really hold tight to this idea of defending basic, you know, free expression, freedom of speech. That's a really strong public position for them to take, especially here in the United States, where that's core to our identity as Americans. But when you talk to people within the company that are part of that business arm and part of that policy arm, they say there was also a political calculus and, really, a monetary calculus of this just being good business for them. GROSS: What was the Facebook policy about hate speech, and how was that tested during the Trump years? FRENKEL: You know, what's interesting is that Trump brought home the problems of hate speech that Facebook had been facing all over the world. Here in America, we might forget, but in India, in Myanmar, in the Philippines, in Sri Lanka, people have been dying because of hate speech on Facebook for years. It has led to real-life consequences and real deaths. Here in the United States, we only began to see how that hate speech could lead to a growth in extremist movements and fringe groups with the Trump presidency because the president himself was amplifying hate speech. He was pointing to militia movements. He was pointing to theories by QAnon, the conspiracy group. And it was being amplified on Facebook. And within Facebook's own security team, the experts who study extremism were saying over and over again, we are seeing extraordinary growth of these movements. We are ourselves frightened by the way the far right has grown on Facebook during these years. GROSS: Were the algorithms failing to detect hate speech? Was that the problem? KANG: The algorithms are catching up. We have to remember that the scale of Facebook is 3 - nearly 3 billion users around the world. The amount of content that courses through the platform every day is just so enormous. Facebook has put in AI, artificial intelligence, as well as hired thousands of content moderators to try to detect this. But they're really far behind, and they've only really started taking this seriously since public scrutiny has shed a light, a spotlight on the company. And there is demand for change within the company. So our reporting shows and from the people inside that they really do feel like they are racing to catch up. FRENKEL: And I would just add that a lot of this hate speech is happening in private groups. This is something Facebook launched just a few years ago, this push towards privacy, this push towards private groups. The idea being is that people wanted to be in small, intimate groups with like-minded people. But what happens when those small, intimate groups are QAnon or when they're militias? Everyone is like-minded, and so no one is reporting the content. In some cases, it's not a matter of Facebook's algorithms not finding things. It's a matter of Facebook creating these kind of secluded, private walled gardens where this kind of talk can happen, where hate speech can happen and it's not being found. GROSS: But were the tech people aware of what was happening with hate speech? FRENKEL: They were. I mean, Facebook has a really fantastic security team. These are experts. They hire from the NSA. They hire from the FBI. They hire people who are really at the forefront of their fields. And in reporting the book, so many of the people I spoke to said, you know, in government intelligence, we only wish we had the kind of insight that Facebook has. We collect more intelligence and more data at Facebook than any government official could possibly hope for. So it wasn't that Facebook's engineers, their security team didn't see the growth of these movements. It's just that, really, Facebook's own policies kind of tied their hands behind their backs in terms of what they could do. GROSS: What were the policies that tied the hands? FRENKEL: So when it comes to hate speech, there's not a firm line in the sand of what hate speech is. It's a very nebulous and ever-changing thing. One person might say something and it might be seen as a joke, and another person might say it and it's hate speech. It's meant to inspire hatred. It's something that really needs to be looked at by human beings to understand. And Facebook overwhelmingly relies on algorithms and AI to find things. And when you're training your systems on AI, you're building an inherent sort of flaw in that AI is just not going to find everything. And Facebook itself acknowledges that, that its AI isn't effective with hate speech. KANG: The other thing I would add, Terry, is that these policies are being created oftentimes on the fly. Facebook has not looked around the corner at things such as doctored videos, deepfakes. They are creating policies in real time. And one example that we really spool out in the book is when Speaker House Speaker Nancy Pelosi spoke at a conference and somebody posted a doctored video of her where she appeared intoxicated. And within Facebook - we take people inside the room when there is much debate within the policy team, the executive ranks, with engineers as well over, what should the policy be for a doctored video which is obviously false, but according to the broad umbrella definition of free expression that the company abides by, could be permitted? I mean, there were discussions about whether this looks like an \"SNL\" parody, whether this is actually going to lead to disinformation related to politics in the election. And ultimately, which I think is a really important pattern that we discovered and we have in our book, is that often Mark Zuckerberg is the one who makes the final call on these important policy decisions. GROSS: So the decision that was made by Zuckerberg, you say, is to leave up doctored videos. Is that still the policy? KANG: That's a great question, because it's unclear. They make these very ad hoc decisions. And in the case of Pelosi, Mark Zuckerberg did decide to leave up that doctored video, but he made this kind of strange distinction between deepfakes and doctored videos, which his own team is still struggling to answer. Where is the line between something that has been altered enough that it is not reality versus something that has just been doctored? They've essentially set the stage for them to have to make these one-off decisions over and over and over again. GROSS: So after Pelosi and her team asked Facebook to take down this doctored video and Facebook declined to do that, that's when Pelosi stopped talking to Sheryl Sandberg. KANG: Yes, the - from what I understand, there is a moratorium on talking to Facebook at all within the speaker's office. There is a lot of deep resentment about these policies that don't have a clear throughline. They don't have consistency from the point of view of many political leaders. GROSS: So what was Facebook's final resolution about how to deal with the Pelosi doctored video? KANG: After 48 hours, Facebook decided to slow the spread of the video. That was their resolution, their remedy. They decided that to essentially suppress the rankings of the video so that it wouldn't spread too quickly across the internet. GROSS: Let me reintroduce you both. If you're just joining us, my guests are Sheera Frenkel and Cecilia Kang, authors of the new book \"An Ugly Truth: Inside Facebook's Battle For Domination. \" They're both reporters for The New York Times. We'll be back after we take a short break. I'm Terry Gross, and this is FRESH AIR. (SOUNDBITE OF MUSIC)GROSS: This is FRESH AIR. I'm Terry Gross. Let's get back to my interview with New York Times reporters Cecilia Kang and Sheera Frenkel, authors of the new book \"An Ugly Truth: Inside Facebook's Battle For Domination. \" It investigates Facebook's failure to protect against becoming a platform spreading hate speech, disinformation, conspiracy theories and calls to violence. The book also shows how Facebook became an advertising company, monetizing its users and their data. Less than three months before the election, one of Facebook's cybersecurity experts, Ned Moran, discovered the DCLeaks page created by Russians - a page on Facebook created by Russians. Describe the page and Moran's reaction when he found it. KANG: Ned Moran was someone who came from government intelligence, and he was someone who was trained to look for specifically Russian operations. And yet, when he found the DCLeaks page, he was surprised. He had thought that Russia might be interested in trying to do something during the 2016 presidential elections, but he was surprised it was so blatant. And in the weeks that followed, he watched in real time as Russian agents tried to feed emails from the Clinton campaign to American reporters and took even a step further to try to influence their coverage. He, in this book, described as watching as what he knew to be a Russian agent tried to shape that coverage and say, well, you know, Clinton's going to give a rally on this day. If you drop the story right before she goes onstage, it might affect her. It might affect her polling numbers. Reporters might have to ask her about it. So you really saw an incredibly strategic and aggressive campaign by the Russians on Facebook using Facebook. GROSS: And he also found that Fancy Bear hackers from Russia had stolen 2,500 documents by hacking into the Soros Foundation, and he was trying to get journalists to publish those. And then in the summer of 2017, the cybersecurity team at Facebook discovered that the Russian Internet Research Agency - and it had, like, thousands of bots - right? - and fake pages. KANG: Yes. I mean, I think people forget that there are really two separate things that happened during those elections. One was the Russian hackers who were working for the government and who were stealing those Clinton emails and getting American journalists to write about them. Separately, the IRA, the Internet Research Agency, was running a number of bots and buying advertisements on Facebook's own platform to create really divisive emotional content meant to divide Americans. Facebook had been hearing for nearly a year at that point that Russia was buying ads, but they had not been able to find them. And it took until that summer, the summer of 2017, that Facebook was able to finally find those ads. I think in one of the more memorable scenes in our book, we have a Facebook PR person telling journalists that there were no Russian ads bought on the platform during the elections at the same time that just down the hallway, the security team was starting to find those ads. GROSS: So what was Facebook's reaction? What was the executive leadership at Facebook's reaction when the cybersecurity team reported what they were finding about Russian hacks and Russian bots and Russian disinformation campaigns? KANG: At this point, you know, I think people know that Facebook took a long time to inform the U. S. public about what they knew. They took almost a year to tell the American public what they knew about Russian election interference. We were shocked, to be honest, when we were reporting at how often they delayed going public and how often they went back to their security team and said, well, let's dig around more. Let's find more. Let's wait a little bit longer. They did not reveal the extent of what Russia had done until September 2017, even when six, seven months earlier, their own security team was urging them to go public and tell people what had happened. GROSS: Well, you report that Facebook removed the Russian section from a security report. What did they remove, and why? KANG: This was personally an interesting reporting point for me because I had written about the white paper that Facebook published in the winter of 2017 for The New York Times. At that point, I had heard from sources within Facebook that there had once been an entire section of that report which touched on Russia and which revealed that Russia had, in fact, interfered in the elections. And I went to Facebook. I asked for comment. And I said, you know, I'm hearing these things; did you take out a Russia section? And I was emphatically told that that was not the case, that there was never anything about Russia in the white paper. And it was only in reporting this book that we discovered there were multiple drafts of the paper that had very long sections on Russia. And in fact, there was a great amount of debate within the company about whether or not to include it. GROSS: So what was taken out, and what was the rationale for it? KANG: They took out the paragraphs that dealt with Russia. They took out the implications that Russia had been involved in election interference. And the rationale was, well, we don't know enough yet, and this isn't the right form in which we should go out with what we do know, and we should brief members of Congress first, we should perhaps brief intelligence officials first. And so it was, again, a case of Facebook really kicking the can down the road and telling its security team, why don't you go back and find more first? FRENKEL: I would just add that Facebook today also emphatically says that they did include Russia because they note there is a footnote in the white paper where they link to a DNI report which has a reference to Russian interference. But nowhere in the white paper is the word Russia mentioned. GROSS: At some point, Zuckerberg said he'd work with Congress in its investigation into Russia and turn over Russian ads that were on Facebook and that he didn't want to use Facebook tools to undermine democracy. That's not what Facebook stands for. What did he actually hand over? And was that everything? KANG: So Facebook does eventually hand over more than 3,000 ads that were purchased by IRA-connected entities on Facebook. And they are all meant to sort of cause chaos and discord around the election. And they find - they give these ads and these images to a committee that's investigating election interference. The - what's really notable in the book is that the lobbyists who hand over this information, they initially really try to show political neutrality among the ads. They're trying to actually curate the ads and give the impression that the Russians who did buy these ads were not really particularly favoring one candidate over another, but that they were neutral in this, which the people in the committee, the committee investigators, found ludicrous. It was that kind of controlling of the message that I think has really quite angered members of Congress. GROSS: At some point, Twitter started fact-checking Trump tweets and putting warning labels on false messages or, you know, totally misleading messages. And this was around the time of the election. How did that affect Facebook 'cause, you know, Twitter is a competitor of Facebook? FRENKEL: Twitter doing that somewhat forced Facebook's hand to become more aggressive in their labeling. For a little while, Facebook had been experimenting with these labels that often directed people to an information center where they were trying to provide more accurate information about the elections or about COVID. But the labels themselves were often confusing. People didn't know what to make of a label that said, for more information about the election, please visit our - you know, and then a link. It didn't say something was false. It didn't really clearly state that something was misleading the way that Twitter's labels did. And so after Twitter really became more aggressive in labeling the Trump posts, we saw Facebook start to change their labels as well. And the language of those labels started to really shift to say this is actually misleading content. There's information provided here that isn't accurate. GROSS: Let's take another break here, and then we'll talk some more. If you're just joining us, my guests are Sheera Frenkel and Cecilia Kang, authors of the new book \"An Ugly Truth: Inside Facebook's Battle For Domination. \" They're both reporters for The New York Times. We'll be right back. This is FRESH AIR. (SOUNDBITE OF AMY RIGBY'S \"PLAYING PITTSBURGH\")GROSS: This is FRESH AIR. Let's get back to my interview with the authors of the new book \"An Ugly Truth: Inside Facebook's Battle For Domination. \" Cecilia Kang and Sheera Frenkel are reporters for The New York Times. Kang covers technology and regulatory policy. Frenkel covers technology and cybersecurity. January 6 was a very violent day in the Capitol. And so many people could see what was leading up to that, and they could see it on Facebook and on other social media. How was Facebook used by the people who planned January 6 and by those who joined in or led the riot and broke into the Capitol building? FRENKEL: The seeds for what happened on January 6 were sown very early on - really, I would say, the day after the elections. There were people forming Facebook groups called Stop the Steal. We, as reporters, were watching those groups, and we were astounded. I had never seen a Facebook group grow so quickly, adding thousands of users within hours to this group in which they were sharing all sorts of falsified videos and documents about election fraud and really, really churning up anger around this idea that the election had been somehow stolen from Donald Trump. While Facebook took action on some of those groups, some of the stop-the-steal groups, they allowed others to persist. And, of course, Donald Trump was still on the platform using that moniker, saying stop the steal and claiming the election had been stolen from him. And so within Facebook, they were seeing that they were really not that effective in stopping that idea from spreading and that in the lead-up to January 6, people were getting more and more and more angry. And they were organizing themselves to come to Washington and to march. Facebook security officials the day before were warned by reporters that there were Facebook groups in which people were posting photos of assault rifles and openly discussing how they were going to bring guns to Washington for this march. And they knew the potential for violence was very, very real, which is why, on that day, Facebook officials gathered to watch what was happening in Washington and to monitor those very groups. They even discussed at one point whether Zuckerberg should call Trump ahead of time. Ultimately, they decided not to because they were worried that it was going to leak to the press that they might do so. But it's very clear from our reporting that Facebook knew the potential for explosive violence was very real that day. GROSS: Was there a debate within Facebook about whether to do anything to stop this kind of potentially violent organizing on Facebook? FRENKEL: There was. The security team was constantly debating with other parts of the company about what should be done. And I would note that with their QAnon policy, for instance - I think that's a very interesting one to look at, QAnon obviously being a conspiracy group here in the United States, which has really taken off during the Trump presidency, has millions of people who believe in this idea of a vast sort of ring of cabal of global elites that are really controlling the world. And while they started to make moves towards banning them - they took down some of the groups; they took down some of the accounts - it took several months of seeing that the group was still spreading before Facebook actually took action to ban the group entirely. And even then, things slipped through. And Facebook's security team was telling its own officials, well, we're not being effective. We're letting them continue to spread and recruit new members. And in these months that are going by, they're organizing on other platforms. They're telling their own Facebook groups, hey, if we get taken down here, come follow us over here on YouTube, or come follow us over here on a messaging app like Telegram. And so they were organizing ahead of time for the planned removal. GROSS: After January 6, when executives at Facebook saw what happened at the Capitol and saw that Capitol Police were killed by the mob and that the mob breached the Capitol, that they were saying, hang Mike Pence, that they were going after Nancy Pelosi and others - what was the conversation like inside Facebook, and what action did Facebook take? FRENKEL: There was immediate sort of understanding that this was a watershed moment and that they were going to have to have the discussion they've dreaded having for a very long time, which is, do they remove Donald Trump? And we see them debate that. We see them go back and forth. And really, it's not until Twitter takes action to ban Trump that Facebook sort of makes its announcement, at first that it's a temporary suspension. It's very unclear and muddled. Their messaging is, well, we're removing him for now, but we're going to reevaluate. And ultimately, it's finally announced that they're going to suspend the account, but they're going to refer it to the Facebook oversight board. They were essentially really, again, kicking the can to someone else and saying, we've created this outside body. I'm going to allow them to rule on whether or not we should have removed Donald Trump. GROSS: And at first, the ban was, like, for a couple of weeks. Right? And then that was extended. KANG: That's right. The ban was was for a couple weeks. The language was quite interesting. It was indefinite and temporary is the way they described it. They referred it to this body that they describe as a Supreme Court, third-party body that makes decisions on content. Interestingly, months later, the body, the Facebook oversight board, kicked it back, that decision on Trump, to Facebook. And they said, Facebook, you don't have policies that are clear enough on this kind of political speech and taking down an account like Trump, you have to write those policies. It was actually a pretty smart move by the Facebook oversight board. So currently, the final decision on Trump is in the hands of Facebook. They have said that for at least two years, Trump will be banned, and that two years expires, essentially, ahead of his ability to campaign again for the 2024 campaigns. GROSS: Has Facebook clarified its policy on political speech that is not true, that is inflammatory, that is hate speech, and also its policy on people who amplify that and who threaten to show up with guns and, you know, breach the Capitol building? I mean, Trump might have, you know, started the fire, but people were stoking it. FRENKEL: They have not clarified that policy. And really, Trump stepping down from office has helped them avoid discussing it. The daily questions that they used to get from reporters are no longer being received by Facebook executives, but that's really just here in the United States. We have to remember that in countries all over the world, this is still a huge problem. There are elections coming up in India. There are elections coming up in a number of countries where the current head of state is very active on Facebook and uses Facebook much in the way that was modeled by Donald Trump. And so by avoiding answering this, by avoiding coming up with a cohesive policy, they've - you know, they've extended the problem. And millions of people all over the world are being affected in democracies that are being threatened by populist leaders using Facebook. GROSS: What are the changes to Facebook policy that have happened since the Trump administration? KANG: Facebook now is coordinating much more with governments and with intelligence officials within governments. Every month, they report about disinformation and what they found, and they report to the public. They're trying to be more public, and they're trying to also coordinate with other technology companies to see - for what they're seeing and coordinate on what those other companies are seeing as well on the internet. FRENKEL: While Facebook has made huge strides in how it reports publicly and transparently about disinformation and has hired, as they say, more than 30,000 people to work in their security apparatus, they still struggle with misinformation, which - the difference there is really interesting, right? One is spread intentionally by a government or by another body to try and influence people. Misinformation is really just bad information shared among people, Americans telling other Americans that the vote has been stolen. And on that, they still don't know what to do, and that's really what's becoming prevalent not just here in the United States but in countries all over the world. GROSS: Is there a precedent from another social media company about how to deal with that? KANG: The social media companies are all struggling, and they're creating policies as we go. I will say that Twitter, though it's much smaller, we do have to remember, compared to Facebook, especially when you put Facebook together with its other apps - WhatsApp and Instagram - Twitter's willing to be more experimental. It's quite public in its approach and writing of its policies. I'm not saying that they've got it completely right. YouTube is still very far behind. These social media companies are all struggling with how to handle misinformation and disinformation. And along the lines of misinformation, it is a very current and present danger in that just recently, the chief of staff of the White House, Ron Klain, was saying that when he talks to - when the White House reaches out to Americans and asks why aren't they getting vaccinated, they hear misinformation about dangers with the vaccine. And they - and he said that the No. 1 place where they find that misinformation is on Facebook. GROSS: Is Facebook trying to do anything about that? FRENKEL: Facebook and Mark Zuckerberg himself have said that they will not tolerate misinformation about COVID. However, I will note that just today I was curious, and I went to Facebook, and I checked a couple of different groups which I am a part of and which I track for misinformation, and I saw quite a few conspiracies shared about vaccines causing all sorts of problems, whether fertility or otherwise. I will note that scientists say that none of those problems are being documented. And they were sharing videos which had obviously been doctored. They were sharing very experimental information about what could cure COVID. And so just today I saw that the very type of misinformation that Mark Zuckerberg and Sheryl Sandberg said they wouldn't tolerate about COVID is still online and very active on Facebook. GROSS: Let me reintroduce you both. If you're just joining us, my guests are Sheera Frenkel and Cecilia Kang, authors of the new book, \"An Ugly Truth: Inside Facebook's Battle For Domination. \" They're both reporters for The New York Times. We'll be right back. This is FRESH AIR. (SOUNDBITE OF HIOR CHRONIK'S \"WE ARE ALL SNOWFLAKES\")GROSS: This is FRESH AIR. Let's get back to my interview with the authors of the new book, \"An Ugly Truth: Inside Facebook's Battle For Domination. \" Cecilia Kang and Sheera Frenkel are reporters for The New York Times. Kang covers technology and regulatory policy; Frenkel covers technology and cybersecurity. So as you were wrapping up your investigation for this book, there were several suits filed against Facebook, one from the Federal Trade Commission. There was a group of over 40 state attorneys general which filed suit against Facebook. What were these suits about? KANG: Just recently, a federal court threw out the lawsuits by the Federal Trade Commission in more than 40 states and jurisdictions, and those lawsuits were seeking to break up Facebook. There were competition lawsuits. The feeling - I mean, there is, Terry, very few things right now in Washington that unite Democrats and Republicans than the idea that Facebook is too big and too powerful. So these lawsuits were attempting to address the size and the dominance of Facebook. The Federal Trade Commission does have the ability. The judge in this case said come back to us and do a better job essentially of writing your lawsuit. But it was a big step back for any sort of regulatory pressure on the company. The company's stock soared after the announcement. It now - right after the announcement, the stock soared so much that the company was valued at over $1 trillion. GROSS: You've been reporting on Facebook for years, so this book is kind of like the culmination of your Facebook reporting. Facebook was not always happy with your reports. What did you hear from Facebook when you reported something that made the leadership unhappy and that they wanted to criticize? FRENKEL: Facebook is very controlling of their message, and they're always concerned about what journalists uncover that is not sanctioned by the company. And, of course, as journalists, that's what we're most interested in. We're most interested in hearing the unfiltered ideas and the raw discussions, what's happening behind the scenes that isn't the polished sort of formal thought that they present to the public but that where they got there. And that's what we want to do with this book is show people how Facebook got here. How did we arrive at our present moment? We went through a very thorough fact-checking process with Facebook for this book. It took several months. We went through every scene. We went through really every detail and gave them a chance to respond and correct anything that they might find inaccurate, because we want this to be a very thorough understanding of the company and the decisions made by its top leadership. GROSS: What difficulty did you have getting people in Facebook to talk with you? What were they risking? Had they signed nondisclosure agreements about what happens inside Facebook? KANG: Of the more than 400 people we interviewed for this book, many currently still are at Facebook. Many are former employees, and many did sign NDAs. So they spoke to us at risk. We are grateful that they spoke to us. I think that that speaks to the fact that they wanted their story to be told as they understood it from inside. It was not easy. This is a project that took over two years as a book, and our reporting has extended even further than that. But we just dug and dug and dug because we knew that there was more than just the sort of curated and scripted talking points that the company espouses. We wanted to take people behind the scenes. And the people who did speak to us spoke to us, and they put their trust in us. And we are so grateful. FRENKEL: I would add that there's sometimes a notion that the people we spoke to were somehow disillusioned, disenfranchised or were coming to us as reporters because they were mad at Facebook. And that's not what we found. We found the vast majority of people still work there. And they actually love the company. And they care about the company, and they want it to do better. Their motivation for speaking to us was often wanting things to come to light publicly so that the company could change. GROSS: Two people from Facebook who did not give you interviews were Mark Zuckerberg and Sheryl Sandberg. FRENKEL: Yes. At the start of this book, we asked Mark Zuckerberg and Sheryl Sandberg to sit with us - an interview, and they declined. We repeated our request multiple times, and they continued to decline. GROSS: Well, I thank you so much for your reporting and for joining us today. Sheera Frenkel, Cecilia Kang, thank you. KANG: Thank you, Terry. FRENKEL: Thank you so much for having us. GROSS: Sheera Frenkel and Cecilia Kang are reporters for The New York Times. Their new book is called \"An Ugly Truth: Inside Facebook's Battle For Domination. \" Facebook contacted us with this statement in response to the book. Quote, \"every day we make difficult decisions on where to draw the line between free expression and harmful speech on privacy, security and other issues. And we have expert leaders who engage outside stakeholders as we craft our policies. But we should not be making these decisions on our own and have for years advocated for updated regulations where democratic governments set industry standards to which we can all adhere,\" unquote. Tomorrow on FRESH AIR, how long can an athlete perform at a high level while being an active alcoholic? Our guest will be big-league pitcher CC Sabathia. They'll talk about drinking heavily through 15 seasons, including his most dominating years on the mound, and about getting sober. He's written a new memoir called \"Till The End. \" I hope you'll join us. (SOUNDBITE OF MUSIC)GROSS: FRESH AIR's executive producer is Danny Miller. Our technical director and engineer is Audrey Bentham. Our interviews and reviews are produced and edited by Amy Salit, Phyllis Myers, Sam Briger, Lauren Krenzel, Heidi Saman, Therese Madden, Ann Marie Baldonado, Thea Chaloner, Seth Kelley and Kayla Lattimore. Our associate producer of digital media is Molly Seavy-Nesper. Roberta Shorrock directs the show. I'm Terry Gross. [POST-BROADCAST CORRECTION: A question in this interview attributed the death of Capitol Police officers to the mob which attacked the Capitol on January 6.  Officer Brian Sicknick was physically attacked by rioters in the Capitol and sprayed in the face with a chemical substance. Later that day, Officer Sicknick collapsed at the Capitol and was taken to the hospital.  He died the next day after suffering two strokes.  The US Capitol Police have said that Sicknick died in the line of duty.  However, the DC Medical Examiner has ruled that the death was due to natural causes. ] TERRY GROSS, HOST:   This is FRESH AIR. I'm Terry Gross. A new book investigates Facebook's failure to protect against spreading hate speech, disinformation, conspiracy theories and calls to violence. The book also shows how Facebook became an advertising company, monetizing its users and their data. The book is called \"An Ugly Truth: Inside Facebook's Battle For Domination. \" My guests are the authors, Sheera Frenkel and Cecilia Kang, who are reporters for The New York Times. Frenkel covers cybersecurity and is based in San Francisco and covers technology and regulatory policy and is based in Washington, D. C. The book focuses on the period between the 2016 presidential campaign and the January 6 insurrection, a period in which Trump became one of Facebook's most profitable users and his campaign became one of the platforms most profitable advertisers. The authors say it was also the period in which it became clear Facebook was unprepared to deal with a political leader like Trump, who used the platform to spread misleading and false information. We recorded our interview yesterday morning. Sheera Frenkel, Cecilia Kang, welcome to FRESH AIR. And congratulations on the book. CECILIA KANG: Thank you. SHEERA FRENKEL: Thank you, Terry. GROSS: So Trump and his followers created many headaches and nightmares for Facebook, which Facebook was unprepared for an American president spreading these falsehoods. But Trump was also a gold mine. So how did Facebook profit from Trump's falsehoods spread on Facebook? FRENKEL: Well, Trump had over 30 million followers by the time he was kicked off Facebook. He was a major draw for people all over the world to come to Facebook and hear what he had to say about the day's news. He not only managed to bring audience and relevancy to Facebook, he created this constant sort of churning stream of information that people couldn't help take their eyes off of. And ultimately, that's what Facebook needs to stay relevant. GROSS: Even if you repost one of Trump's messages and add a critical comment, you're still amplifying his post. KANG: Absolutely. What you're doing is doing what Facebook wants, which is you're engaging with his content and you're engaging with the website. And that's really the core of the business there is to get people's attention and to engage and to be active. GROSS: So Facebook profited enormously from Trump's campaign spending. How did the campaign use Facebook tools to maximize its reach? FRENKEL: This is Sheera. The Trump campaign really used Facebook in unusual and unprecedented ways for a political campaign. They did something that had previously not been done by politicians in using Facebook's incredibly targeted advertisement, both to reach people and to sort of do an AB testing of what messages worked best. So, for instance, they would send out two, three, four versions of the same message and then whichever one they saw in real time reaching people and being amplified by people, that's the one they would double down on and put more money into. Once Trump did this, I would note that politicians all over the world followed suit. And they discovered that Facebook was an incredible way in telling people exactly what they wanted to hear. GROSS: Now, you write that Facebook employees were embedded in Trump's New York City campaign headquarters to help riff on Hillary's daily speeches and target negative ads to specific audiences. Facebook employees were embedded in the Trump campaign? FRENKEL: So interestingly, this is something Facebook actually offered both campaigns. The Hillary Clinton campaign just turned them down and said that they didn't want that kind of assistance. And so, yes, the Trump campaign ended up with Facebook employees in their offices advising them on how to best use Facebook tools, much like you would a major advertiser like Pepsi-Cola. They, in real time, could tell them this tool is working for you, this one is not - this messaging is working for you and this one is not. And because Facebook's algorithms are so sensitive and because Facebook's tools are so precise, they could even tell them things like, well, we think that this is playing well in this demographic or in that part of the country. And that trove of data was so important to the Trump campaign in understanding who their voters were. GROSS: So do you think Facebook employees helped the Trump campaign amplify misleading or outright false information in Trump campaign ads? FRENKEL: You know, Facebook is always really careful in saying that they're a neutral platform, as are their own employees. And so whatever the content was that Trump was amplifying, whether it was misinformation, conspiracies, just, you know, outright false, you know, false information, Facebook employees helped it regardless of what the content was. And often they don't even look at the content themselves. They just give them the data. This messaging is working and that messaging is not. GROSS: Tell us more about the rationale behind that policy of not fact-checking political ads when you know that some of that information is outright false. And what was the debate within Facebook about fact-checking political ads? KANG: I think you have to actually go back to the creation of Facebook to understand their policies on speech and the belief that the CEO and co-founder Mark Zuckerberg had from the founding of the company that more expression, that freedom of expression was going to be the bedrock policy for the company. And he also understood that engagement was really important. And from the earliest days, when he was at Harvard, he would - he told people he really wants to create a site where people just sort of mindlessly scroll, and they're online, constantly posting and reading each other's posts. He understood the power of attention and engagement. And Mark Zuckerberg also - he does truly believe in the idea of freedom of expression. And what we've seen and what we reveal in this book is that that policy and his philosophy towards speech has really evolved and that Donald Trump really tested him. And he was, in many ways - Donald Trump - the person that surfaced all of the things that were embedded and core to the platform and the business that were problematic. FRENKEL: I just wanted to add one thing, which is that if anyone listening remembers MTV and how popular that was in the 1990s, that's what Zuckerberg was really basing this idea on. The same way that you would sit and for hours with your friends watch MTV, he wanted people on Facebook. Only here, Facebook was collecting data about them in real time. And as they mindlessly scrolled, Facebook was amassing more and more information about them. GROSS: So has the policy about political advertising changed? Is there any fact-checking on Facebook now? FRENKEL: Facebook still allowed politicians to post ads without being fact-checked. And in fact, politicians could say things in advertisements that the average Facebook user could not. They did change other things in the platform. For instance, they created an ad library where you could search for ads and see what politicians were posting. And that was a level of transparency they hadn't previously had. However, they did double down, and they did maintain firm in their belief that politicians could say things in ads without the benefit of a fact-check. GROSS: Sheryl Sandberg was first brought on to help grow and monetize Facebook. What had she done when she was at Google to maximize advertising growth there? KANG: Sheryl Sandberg was an incredible success at Google. She created what was really one of the earliest big behavioral advertising business models that became known as AdWord (ph) and AdSense at Google. She created a multibillion-dollar business for Google. So she was well-known by the time Mark Zuckerberg was looking for a partner to really build the business and expand it and to refine it. So when he met - when Mark Zuckerberg met Sheryl Sandberg in December 2007, there was a real meeting of minds. They both had looked at each other with a lot of interest because they knew that they could offer the other one something different, which was Mark Zuckerberg was a technology visionary, and Sheryl Sandberg was absolutely the business erudite and visionary for the company. Sheryl Sandberg came in, and within her first weeks, she had called a couple meetings with some of the biggest executives at Facebook at the time. And they refined the business. And they realized from that moment forward that they would pursue a behavioral advertising business. GROSS: let me reintroduce you here. If you're just joining us, my guests are Sheera Frenkel and Cecilia Kang, authors of the new book \"An Ugly Truth: Inside Facebook's Battle For Domination. \" They're both reporters for The New York Times. We'll be right back. This is FRESH AIR. (SOUNDBITE OF JAKE MASON TRIO'S \"THE STRANGER IN THE MIRROR\") GROSS: This is FRESH AIR. Let's get back to my interview with the authors of the new book \"An Ugly Truth: Inside Facebook's Battle For Domination. \" Cecilia Kang and Sheera Frenkel are reporters for The New York Times. Kang covers technology and regulatory policy. Frenkel covers tech and cybersecurity. So Donald Trump, as both candidate and president, challenged Facebook's standards of speech because there were so many mistruths and out and out falsehoods or lies that Trump posted. So what were the standards before Trump for taking down a post? FRENKEL: Before Trump, Facebook tried to implement fairly universal standards about what it would take down. It created rules in its content moderation policy that applied to everyone evenly, or so it declared. And we saw Trump really at the beginning of his candidacy when he was first running for president, run up against those rules and post something on Facebook, a ban, he said, that would make sure that all Muslims did not enter the United States that within Facebook was seen as possible hate speech. Facebook's own employees went to Mark Zuckerberg and Sheryl Sandberg and said, you know, we think this violates our policies. Shouldn't we be taking this down? And at that moment, when Facebook decided to leave up his post and start to carve out a new policy for Trump, they were essentially creating a separate class of user on Facebook. Now, it would take years for them to come around and kind of declare this officially and to formalize it. But that first step showed that Facebook was really carving out something for important people, for VIPs on the platform that the average user didn't get. GROSS: Once that policy was formalized, what was it, and what was the justification they offered for it? KANG: So they called it the newsworthy exemption. The way that Facebook and Mark Zuckerberg described it is that political figures deserved this special class of, really, an exemption from the other hate speech and other speech policies they had because political speech was of public interest and importance for the world to know. So - and Mark Zuckerberg said in a speech at Georgetown in 2019 that he believed that political speech was the most scrutinized speech. Mark Zuckerberg, in his view of expression and free expression, has a belief that more speech will actually drown out bad speech. So his view was that even if there were lies, lies from a politician such as Donald Trump, that the public would respond with their own fact checks of the president and that the fact checks would rise to the top. And that would, in a sense, neutralize any of the problems with political figures. GROSS: But I'm sure the people at Facebook saw it wasn't working out that way. So how did they respond to the fact that lies were often winning out? FRENKEL: That was so difficult for Facebook and specifically Mark Zuckerberg to contend with. And that's something that for us was really interesting in writing this book and showing repeatedly over and over again, despite their ideas really being disproven. You know, this idea that people would reject falsehoods. They would reject misinformation. They would reject conspiracies, despite Facebook's own algorithms showing that that wasn't happening - they continued to persist in this idea. And really, up until the end of Trump's presidency, Mark Zuckerberg and Sheryl Sandberg were still defending the idea that Trump and, really, political leaders all over the world could and should say things on the platform as they wished. And people could and should respond as they wished. They failed to see what their own employees were telling us. And that - for us In, the book, one of the most fascinating thing was talking to employees within Facebook who were raising the alarm again and again and again and saying, this is a problem. You know, we are spreading misinformation. We are letting the president spread misinformation. And it's being amplified by our own algorithms. Our systems aren't working the way we predicted, and we should do something. And yet, you know, Mark Zuckerberg and Sheryl Sandberg stay the course. GROSS: Well, you have a lot of insights into this, but I'm not sure you can actually answer it. But I'll ask, what - do you think that Sandberg and Zuckerberg were defending their ideal of what free speech should mean on Facebook? Or do you think they were trying to protect Facebook's profits? FRENKEL: You know, our sources admit it's a little bit of both. I think publicly Mark Zuckerberg and Sheryl Sandberg really hold tight to this idea of defending basic, you know, free expression, freedom of speech. That's a really strong public position for them to take, especially here in the United States, where that's core to our identity as Americans. But when you talk to people within the company that are part of that business arm and part of that policy arm, they say there was also a political calculus and, really, a monetary calculus of this just being good business for them. GROSS: What was the Facebook policy about hate speech, and how was that tested during the Trump years? FRENKEL: You know, what's interesting is that Trump brought home the problems of hate speech that Facebook had been facing all over the world. Here in America, we might forget, but in India, in Myanmar, in the Philippines, in Sri Lanka, people have been dying because of hate speech on Facebook for years. It has led to real-life consequences and real deaths. Here in the United States, we only began to see how that hate speech could lead to a growth in extremist movements and fringe groups with the Trump presidency because the president himself was amplifying hate speech. He was pointing to militia movements. He was pointing to theories by QAnon, the conspiracy group. And it was being amplified on Facebook. And within Facebook's own security team, the experts who study extremism were saying over and over again, we are seeing extraordinary growth of these movements. We are ourselves frightened by the way the far right has grown on Facebook during these years. GROSS: Were the algorithms failing to detect hate speech? Was that the problem? KANG: The algorithms are catching up. We have to remember that the scale of Facebook is 3 - nearly 3 billion users around the world. The amount of content that courses through the platform every day is just so enormous. Facebook has put in AI, artificial intelligence, as well as hired thousands of content moderators to try to detect this. But they're really far behind, and they've only really started taking this seriously since public scrutiny has shed a light, a spotlight on the company. And there is demand for change within the company. So our reporting shows and from the people inside that they really do feel like they are racing to catch up. FRENKEL: And I would just add that a lot of this hate speech is happening in private groups. This is something Facebook launched just a few years ago, this push towards privacy, this push towards private groups. The idea being is that people wanted to be in small, intimate groups with like-minded people. But what happens when those small, intimate groups are QAnon or when they're militias? Everyone is like-minded, and so no one is reporting the content. In some cases, it's not a matter of Facebook's algorithms not finding things. It's a matter of Facebook creating these kind of secluded, private walled gardens where this kind of talk can happen, where hate speech can happen and it's not being found. GROSS: But were the tech people aware of what was happening with hate speech? FRENKEL: They were. I mean, Facebook has a really fantastic security team. These are experts. They hire from the NSA. They hire from the FBI. They hire people who are really at the forefront of their fields. And in reporting the book, so many of the people I spoke to said, you know, in government intelligence, we only wish we had the kind of insight that Facebook has. We collect more intelligence and more data at Facebook than any government official could possibly hope for. So it wasn't that Facebook's engineers, their security team didn't see the growth of these movements. It's just that, really, Facebook's own policies kind of tied their hands behind their backs in terms of what they could do. GROSS: What were the policies that tied the hands? FRENKEL: So when it comes to hate speech, there's not a firm line in the sand of what hate speech is. It's a very nebulous and ever-changing thing. One person might say something and it might be seen as a joke, and another person might say it and it's hate speech. It's meant to inspire hatred. It's something that really needs to be looked at by human beings to understand. And Facebook overwhelmingly relies on algorithms and AI to find things. And when you're training your systems on AI, you're building an inherent sort of flaw in that AI is just not going to find everything. And Facebook itself acknowledges that, that its AI isn't effective with hate speech. KANG: The other thing I would add, Terry, is that these policies are being created oftentimes on the fly. Facebook has not looked around the corner at things such as doctored videos, deepfakes. They are creating policies in real time. And one example that we really spool out in the book is when Speaker House Speaker Nancy Pelosi spoke at a conference and somebody posted a doctored video of her where she appeared intoxicated. And within Facebook - we take people inside the room when there is much debate within the policy team, the executive ranks, with engineers as well over, what should the policy be for a doctored video which is obviously false, but according to the broad umbrella definition of free expression that the company abides by, could be permitted? I mean, there were discussions about whether this looks like an \"SNL\" parody, whether this is actually going to lead to disinformation related to politics in the election. And ultimately, which I think is a really important pattern that we discovered and we have in our book, is that often Mark Zuckerberg is the one who makes the final call on these important policy decisions. GROSS: So the decision that was made by Zuckerberg, you say, is to leave up doctored videos. Is that still the policy? KANG: That's a great question, because it's unclear. They make these very ad hoc decisions. And in the case of Pelosi, Mark Zuckerberg did decide to leave up that doctored video, but he made this kind of strange distinction between deepfakes and doctored videos, which his own team is still struggling to answer. Where is the line between something that has been altered enough that it is not reality versus something that has just been doctored? They've essentially set the stage for them to have to make these one-off decisions over and over and over again. GROSS: So after Pelosi and her team asked Facebook to take down this doctored video and Facebook declined to do that, that's when Pelosi stopped talking to Sheryl Sandberg. KANG: Yes, the - from what I understand, there is a moratorium on talking to Facebook at all within the speaker's office. There is a lot of deep resentment about these policies that don't have a clear throughline. They don't have consistency from the point of view of many political leaders. GROSS: So what was Facebook's final resolution about how to deal with the Pelosi doctored video? KANG: After 48 hours, Facebook decided to slow the spread of the video. That was their resolution, their remedy. They decided that to essentially suppress the rankings of the video so that it wouldn't spread too quickly across the internet. GROSS: Let me reintroduce you both. If you're just joining us, my guests are Sheera Frenkel and Cecilia Kang, authors of the new book \"An Ugly Truth: Inside Facebook's Battle For Domination. \" They're both reporters for The New York Times. We'll be back after we take a short break. I'm Terry Gross, and this is FRESH AIR. (SOUNDBITE OF MUSIC) GROSS: This is FRESH AIR. I'm Terry Gross. Let's get back to my interview with New York Times reporters Cecilia Kang and Sheera Frenkel, authors of the new book \"An Ugly Truth: Inside Facebook's Battle For Domination. \" It investigates Facebook's failure to protect against becoming a platform spreading hate speech, disinformation, conspiracy theories and calls to violence. The book also shows how Facebook became an advertising company, monetizing its users and their data. Less than three months before the election, one of Facebook's cybersecurity experts, Ned Moran, discovered the DCLeaks page created by Russians - a page on Facebook created by Russians. Describe the page and Moran's reaction when he found it. KANG: Ned Moran was someone who came from government intelligence, and he was someone who was trained to look for specifically Russian operations. And yet, when he found the DCLeaks page, he was surprised. He had thought that Russia might be interested in trying to do something during the 2016 presidential elections, but he was surprised it was so blatant. And in the weeks that followed, he watched in real time as Russian agents tried to feed emails from the Clinton campaign to American reporters and took even a step further to try to influence their coverage. He, in this book, described as watching as what he knew to be a Russian agent tried to shape that coverage and say, well, you know, Clinton's going to give a rally on this day. If you drop the story right before she goes onstage, it might affect her. It might affect her polling numbers. Reporters might have to ask her about it. So you really saw an incredibly strategic and aggressive campaign by the Russians on Facebook using Facebook. GROSS: And he also found that Fancy Bear hackers from Russia had stolen 2,500 documents by hacking into the Soros Foundation, and he was trying to get journalists to publish those. And then in the summer of 2017, the cybersecurity team at Facebook discovered that the Russian Internet Research Agency - and it had, like, thousands of bots - right? - and fake pages. KANG: Yes. I mean, I think people forget that there are really two separate things that happened during those elections. One was the Russian hackers who were working for the government and who were stealing those Clinton emails and getting American journalists to write about them. Separately, the IRA, the Internet Research Agency, was running a number of bots and buying advertisements on Facebook's own platform to create really divisive emotional content meant to divide Americans. Facebook had been hearing for nearly a year at that point that Russia was buying ads, but they had not been able to find them. And it took until that summer, the summer of 2017, that Facebook was able to finally find those ads. I think in one of the more memorable scenes in our book, we have a Facebook PR person telling journalists that there were no Russian ads bought on the platform during the elections at the same time that just down the hallway, the security team was starting to find those ads. GROSS: So what was Facebook's reaction? What was the executive leadership at Facebook's reaction when the cybersecurity team reported what they were finding about Russian hacks and Russian bots and Russian disinformation campaigns? KANG: At this point, you know, I think people know that Facebook took a long time to inform the U. S. public about what they knew. They took almost a year to tell the American public what they knew about Russian election interference. We were shocked, to be honest, when we were reporting at how often they delayed going public and how often they went back to their security team and said, well, let's dig around more. Let's find more. Let's wait a little bit longer. They did not reveal the extent of what Russia had done until September 2017, even when six, seven months earlier, their own security team was urging them to go public and tell people what had happened. GROSS: Well, you report that Facebook removed the Russian section from a security report. What did they remove, and why? KANG: This was personally an interesting reporting point for me because I had written about the white paper that Facebook published in the winter of 2017 for The New York Times. At that point, I had heard from sources within Facebook that there had once been an entire section of that report which touched on Russia and which revealed that Russia had, in fact, interfered in the elections. And I went to Facebook. I asked for comment. And I said, you know, I'm hearing these things; did you take out a Russia section? And I was emphatically told that that was not the case, that there was never anything about Russia in the white paper. And it was only in reporting this book that we discovered there were multiple drafts of the paper that had very long sections on Russia. And in fact, there was a great amount of debate within the company about whether or not to include it. GROSS: So what was taken out, and what was the rationale for it? KANG: They took out the paragraphs that dealt with Russia. They took out the implications that Russia had been involved in election interference. And the rationale was, well, we don't know enough yet, and this isn't the right form in which we should go out with what we do know, and we should brief members of Congress first, we should perhaps brief intelligence officials first. And so it was, again, a case of Facebook really kicking the can down the road and telling its security team, why don't you go back and find more first? FRENKEL: I would just add that Facebook today also emphatically says that they did include Russia because they note there is a footnote in the white paper where they link to a DNI report which has a reference to Russian interference. But nowhere in the white paper is the word Russia mentioned. GROSS: At some point, Zuckerberg said he'd work with Congress in its investigation into Russia and turn over Russian ads that were on Facebook and that he didn't want to use Facebook tools to undermine democracy. That's not what Facebook stands for. What did he actually hand over? And was that everything? KANG: So Facebook does eventually hand over more than 3,000 ads that were purchased by IRA-connected entities on Facebook. And they are all meant to sort of cause chaos and discord around the election. And they find - they give these ads and these images to a committee that's investigating election interference. The - what's really notable in the book is that the lobbyists who hand over this information, they initially really try to show political neutrality among the ads. They're trying to actually curate the ads and give the impression that the Russians who did buy these ads were not really particularly favoring one candidate over another, but that they were neutral in this, which the people in the committee, the committee investigators, found ludicrous. It was that kind of controlling of the message that I think has really quite angered members of Congress. GROSS: At some point, Twitter started fact-checking Trump tweets and putting warning labels on false messages or, you know, totally misleading messages. And this was around the time of the election. How did that affect Facebook 'cause, you know, Twitter is a competitor of Facebook? FRENKEL: Twitter doing that somewhat forced Facebook's hand to become more aggressive in their labeling. For a little while, Facebook had been experimenting with these labels that often directed people to an information center where they were trying to provide more accurate information about the elections or about COVID. But the labels themselves were often confusing. People didn't know what to make of a label that said, for more information about the election, please visit our - you know, and then a link. It didn't say something was false. It didn't really clearly state that something was misleading the way that Twitter's labels did. And so after Twitter really became more aggressive in labeling the Trump posts, we saw Facebook start to change their labels as well. And the language of those labels started to really shift to say this is actually misleading content. There's information provided here that isn't accurate. GROSS: Let's take another break here, and then we'll talk some more. If you're just joining us, my guests are Sheera Frenkel and Cecilia Kang, authors of the new book \"An Ugly Truth: Inside Facebook's Battle For Domination. \" They're both reporters for The New York Times. We'll be right back. This is FRESH AIR. (SOUNDBITE OF AMY RIGBY'S \"PLAYING PITTSBURGH\") GROSS: This is FRESH AIR. Let's get back to my interview with the authors of the new book \"An Ugly Truth: Inside Facebook's Battle For Domination. \" Cecilia Kang and Sheera Frenkel are reporters for The New York Times. Kang covers technology and regulatory policy. Frenkel covers technology and cybersecurity. January 6 was a very violent day in the Capitol. And so many people could see what was leading up to that, and they could see it on Facebook and on other social media. How was Facebook used by the people who planned January 6 and by those who joined in or led the riot and broke into the Capitol building? FRENKEL: The seeds for what happened on January 6 were sown very early on - really, I would say, the day after the elections. There were people forming Facebook groups called Stop the Steal. We, as reporters, were watching those groups, and we were astounded. I had never seen a Facebook group grow so quickly, adding thousands of users within hours to this group in which they were sharing all sorts of falsified videos and documents about election fraud and really, really churning up anger around this idea that the election had been somehow stolen from Donald Trump. While Facebook took action on some of those groups, some of the stop-the-steal groups, they allowed others to persist. And, of course, Donald Trump was still on the platform using that moniker, saying stop the steal and claiming the election had been stolen from him. And so within Facebook, they were seeing that they were really not that effective in stopping that idea from spreading and that in the lead-up to January 6, people were getting more and more and more angry. And they were organizing themselves to come to Washington and to march. Facebook security officials the day before were warned by reporters that there were Facebook groups in which people were posting photos of assault rifles and openly discussing how they were going to bring guns to Washington for this march. And they knew the potential for violence was very, very real, which is why, on that day, Facebook officials gathered to watch what was happening in Washington and to monitor those very groups. They even discussed at one point whether Zuckerberg should call Trump ahead of time. Ultimately, they decided not to because they were worried that it was going to leak to the press that they might do so. But it's very clear from our reporting that Facebook knew the potential for explosive violence was very real that day. GROSS: Was there a debate within Facebook about whether to do anything to stop this kind of potentially violent organizing on Facebook? FRENKEL: There was. The security team was constantly debating with other parts of the company about what should be done. And I would note that with their QAnon policy, for instance - I think that's a very interesting one to look at, QAnon obviously being a conspiracy group here in the United States, which has really taken off during the Trump presidency, has millions of people who believe in this idea of a vast sort of ring of cabal of global elites that are really controlling the world. And while they started to make moves towards banning them - they took down some of the groups; they took down some of the accounts - it took several months of seeing that the group was still spreading before Facebook actually took action to ban the group entirely. And even then, things slipped through. And Facebook's security team was telling its own officials, well, we're not being effective. We're letting them continue to spread and recruit new members. And in these months that are going by, they're organizing on other platforms. They're telling their own Facebook groups, hey, if we get taken down here, come follow us over here on YouTube, or come follow us over here on a messaging app like Telegram. And so they were organizing ahead of time for the planned removal. GROSS: After January 6, when executives at Facebook saw what happened at the Capitol and saw that Capitol Police were killed by the mob and that the mob breached the Capitol, that they were saying, hang Mike Pence, that they were going after Nancy Pelosi and others - what was the conversation like inside Facebook, and what action did Facebook take? FRENKEL: There was immediate sort of understanding that this was a watershed moment and that they were going to have to have the discussion they've dreaded having for a very long time, which is, do they remove Donald Trump? And we see them debate that. We see them go back and forth. And really, it's not until Twitter takes action to ban Trump that Facebook sort of makes its announcement, at first that it's a temporary suspension. It's very unclear and muddled. Their messaging is, well, we're removing him for now, but we're going to reevaluate. And ultimately, it's finally announced that they're going to suspend the account, but they're going to refer it to the Facebook oversight board. They were essentially really, again, kicking the can to someone else and saying, we've created this outside body. I'm going to allow them to rule on whether or not we should have removed Donald Trump. GROSS: And at first, the ban was, like, for a couple of weeks. Right? And then that was extended. KANG: That's right. The ban was was for a couple weeks. The language was quite interesting. It was indefinite and temporary is the way they described it. They referred it to this body that they describe as a Supreme Court, third-party body that makes decisions on content. Interestingly, months later, the body, the Facebook oversight board, kicked it back, that decision on Trump, to Facebook. And they said, Facebook, you don't have policies that are clear enough on this kind of political speech and taking down an account like Trump, you have to write those policies. It was actually a pretty smart move by the Facebook oversight board. So currently, the final decision on Trump is in the hands of Facebook. They have said that for at least two years, Trump will be banned, and that two years expires, essentially, ahead of his ability to campaign again for the 2024 campaigns. GROSS: Has Facebook clarified its policy on political speech that is not true, that is inflammatory, that is hate speech, and also its policy on people who amplify that and who threaten to show up with guns and, you know, breach the Capitol building? I mean, Trump might have, you know, started the fire, but people were stoking it. FRENKEL: They have not clarified that policy. And really, Trump stepping down from office has helped them avoid discussing it. The daily questions that they used to get from reporters are no longer being received by Facebook executives, but that's really just here in the United States. We have to remember that in countries all over the world, this is still a huge problem. There are elections coming up in India. There are elections coming up in a number of countries where the current head of state is very active on Facebook and uses Facebook much in the way that was modeled by Donald Trump. And so by avoiding answering this, by avoiding coming up with a cohesive policy, they've - you know, they've extended the problem. And millions of people all over the world are being affected in democracies that are being threatened by populist leaders using Facebook. GROSS: What are the changes to Facebook policy that have happened since the Trump administration? KANG: Facebook now is coordinating much more with governments and with intelligence officials within governments. Every month, they report about disinformation and what they found, and they report to the public. They're trying to be more public, and they're trying to also coordinate with other technology companies to see - for what they're seeing and coordinate on what those other companies are seeing as well on the internet. FRENKEL: While Facebook has made huge strides in how it reports publicly and transparently about disinformation and has hired, as they say, more than 30,000 people to work in their security apparatus, they still struggle with misinformation, which - the difference there is really interesting, right? One is spread intentionally by a government or by another body to try and influence people. Misinformation is really just bad information shared among people, Americans telling other Americans that the vote has been stolen. And on that, they still don't know what to do, and that's really what's becoming prevalent not just here in the United States but in countries all over the world. GROSS: Is there a precedent from another social media company about how to deal with that? KANG: The social media companies are all struggling, and they're creating policies as we go. I will say that Twitter, though it's much smaller, we do have to remember, compared to Facebook, especially when you put Facebook together with its other apps - WhatsApp and Instagram - Twitter's willing to be more experimental. It's quite public in its approach and writing of its policies. I'm not saying that they've got it completely right. YouTube is still very far behind. These social media companies are all struggling with how to handle misinformation and disinformation. And along the lines of misinformation, it is a very current and present danger in that just recently, the chief of staff of the White House, Ron Klain, was saying that when he talks to - when the White House reaches out to Americans and asks why aren't they getting vaccinated, they hear misinformation about dangers with the vaccine. And they - and he said that the No. 1 place where they find that misinformation is on Facebook. GROSS: Is Facebook trying to do anything about that? FRENKEL: Facebook and Mark Zuckerberg himself have said that they will not tolerate misinformation about COVID. However, I will note that just today I was curious, and I went to Facebook, and I checked a couple of different groups which I am a part of and which I track for misinformation, and I saw quite a few conspiracies shared about vaccines causing all sorts of problems, whether fertility or otherwise. I will note that scientists say that none of those problems are being documented. And they were sharing videos which had obviously been doctored. They were sharing very experimental information about what could cure COVID. And so just today I saw that the very type of misinformation that Mark Zuckerberg and Sheryl Sandberg said they wouldn't tolerate about COVID is still online and very active on Facebook. GROSS: Let me reintroduce you both. If you're just joining us, my guests are Sheera Frenkel and Cecilia Kang, authors of the new book, \"An Ugly Truth: Inside Facebook's Battle For Domination. \" They're both reporters for The New York Times. We'll be right back. This is FRESH AIR. (SOUNDBITE OF HIOR CHRONIK'S \"WE ARE ALL SNOWFLAKES\") GROSS: This is FRESH AIR. Let's get back to my interview with the authors of the new book, \"An Ugly Truth: Inside Facebook's Battle For Domination. \" Cecilia Kang and Sheera Frenkel are reporters for The New York Times. Kang covers technology and regulatory policy; Frenkel covers technology and cybersecurity. So as you were wrapping up your investigation for this book, there were several suits filed against Facebook, one from the Federal Trade Commission. There was a group of over 40 state attorneys general which filed suit against Facebook. What were these suits about? KANG: Just recently, a federal court threw out the lawsuits by the Federal Trade Commission in more than 40 states and jurisdictions, and those lawsuits were seeking to break up Facebook. There were competition lawsuits. The feeling - I mean, there is, Terry, very few things right now in Washington that unite Democrats and Republicans than the idea that Facebook is too big and too powerful. So these lawsuits were attempting to address the size and the dominance of Facebook. The Federal Trade Commission does have the ability. The judge in this case said come back to us and do a better job essentially of writing your lawsuit. But it was a big step back for any sort of regulatory pressure on the company. The company's stock soared after the announcement. It now - right after the announcement, the stock soared so much that the company was valued at over $1 trillion. GROSS: You've been reporting on Facebook for years, so this book is kind of like the culmination of your Facebook reporting. Facebook was not always happy with your reports. What did you hear from Facebook when you reported something that made the leadership unhappy and that they wanted to criticize? FRENKEL: Facebook is very controlling of their message, and they're always concerned about what journalists uncover that is not sanctioned by the company. And, of course, as journalists, that's what we're most interested in. We're most interested in hearing the unfiltered ideas and the raw discussions, what's happening behind the scenes that isn't the polished sort of formal thought that they present to the public but that where they got there. And that's what we want to do with this book is show people how Facebook got here. How did we arrive at our present moment? We went through a very thorough fact-checking process with Facebook for this book. It took several months. We went through every scene. We went through really every detail and gave them a chance to respond and correct anything that they might find inaccurate, because we want this to be a very thorough understanding of the company and the decisions made by its top leadership. GROSS: What difficulty did you have getting people in Facebook to talk with you? What were they risking? Had they signed nondisclosure agreements about what happens inside Facebook? KANG: Of the more than 400 people we interviewed for this book, many currently still are at Facebook. Many are former employees, and many did sign NDAs. So they spoke to us at risk. We are grateful that they spoke to us. I think that that speaks to the fact that they wanted their story to be told as they understood it from inside. It was not easy. This is a project that took over two years as a book, and our reporting has extended even further than that. But we just dug and dug and dug because we knew that there was more than just the sort of curated and scripted talking points that the company espouses. We wanted to take people behind the scenes. And the people who did speak to us spoke to us, and they put their trust in us. And we are so grateful. FRENKEL: I would add that there's sometimes a notion that the people we spoke to were somehow disillusioned, disenfranchised or were coming to us as reporters because they were mad at Facebook. And that's not what we found. We found the vast majority of people still work there. And they actually love the company. And they care about the company, and they want it to do better. Their motivation for speaking to us was often wanting things to come to light publicly so that the company could change. GROSS: Two people from Facebook who did not give you interviews were Mark Zuckerberg and Sheryl Sandberg. FRENKEL: Yes. At the start of this book, we asked Mark Zuckerberg and Sheryl Sandberg to sit with us - an interview, and they declined. We repeated our request multiple times, and they continued to decline. GROSS: Well, I thank you so much for your reporting and for joining us today. Sheera Frenkel, Cecilia Kang, thank you. KANG: Thank you, Terry. FRENKEL: Thank you so much for having us. GROSS: Sheera Frenkel and Cecilia Kang are reporters for The New York Times. Their new book is called \"An Ugly Truth: Inside Facebook's Battle For Domination. \" Facebook contacted us with this statement in response to the book. Quote, \"every day we make difficult decisions on where to draw the line between free expression and harmful speech on privacy, security and other issues. And we have expert leaders who engage outside stakeholders as we craft our policies. But we should not be making these decisions on our own and have for years advocated for updated regulations where democratic governments set industry standards to which we can all adhere,\" unquote. Tomorrow on FRESH AIR, how long can an athlete perform at a high level while being an active alcoholic? Our guest will be big-league pitcher CC Sabathia. They'll talk about drinking heavily through 15 seasons, including his most dominating years on the mound, and about getting sober. He's written a new memoir called \"Till The End. \" I hope you'll join us. (SOUNDBITE OF MUSIC) GROSS: FRESH AIR's executive producer is Danny Miller. Our technical director and engineer is Audrey Bentham. Our interviews and reviews are produced and edited by Amy Salit, Phyllis Myers, Sam Briger, Lauren Krenzel, Heidi Saman, Therese Madden, Ann Marie Baldonado, Thea Chaloner, Seth Kelley and Kayla Lattimore. Our associate producer of digital media is Molly Seavy-Nesper. Roberta Shorrock directs the show. I'm Terry Gross. [POST-BROADCAST CORRECTION: A question in this interview attributed the death of Capitol Police officers to the mob which attacked the Capitol on January 6.  Officer Brian Sicknick was physically attacked by rioters in the Capitol and sprayed in the face with a chemical substance. Later that day, Officer Sicknick collapsed at the Capitol and was taken to the hospital.  He died the next day after suffering two strokes.  The US Capitol Police have said that Sicknick died in the line of duty.  However, the DC Medical Examiner has ruled that the death was due to natural causes. ]", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-07-15-1016607246": {"title": "Amazon Driver Kills Spider And TikTok Video Goes Viral : NPR", "url": "https://www.npr.org/2021/07/15/1016607246/an-amazon-delivery-driver-killed-a-spider-for-a-grateful-customer-theres-a-video", "author": "No author found", "published_date": "2021-07-15", "content": "", "section": "Technology", "disclaimer": ""}, "2021-07-15-1016572979": {"title": "Companies May Be Flagging Themselves For Hackers By Buying Cybersecurity Insurance : NPR", "url": "https://www.npr.org/2021/07/15/1016572979/companies-may-be-flagging-themselves-for-hackers-by-buying-cybersecurity-insuran", "author": "No author found", "published_date": "2021-07-15", "content": "AILSA CHANG, HOST:  Ransomware attacks have hit the U. S. food supply, the health care system, the pipelines that carry fuel up and down the East Coast. And companies are worried about being attacked. More of them are buying what's called cyber insurance, but that demand has led to higher prices and to coverage that is less comprehensive. NPR's David Gura joins us now with more. Hey, David. DAVID GURA, BYLINE: Hey, Ailsa. CHANG: OK, so just give us a primer first. How does cyber insurance work exactly? GURA: Yeah. Let's take ransomware, for example. It's been in the news lately. There have been these big attacks. Colonial Pipeline is one of them. JBS, the meat processor, is another one. You know, they can cause a lot of disruption, cause a lot of damage. And the ransom demands can be sizable, as we've seen. Colonial Pipeline paid $4. 4 million. Well, a company can buy an insurance policy not just to cover the ransom payment itself but also the fallout from an attack. A company may have to hire a consultant to negotiate and make a payment. There's forensics work - trying to figure out what happened, what was taken. All of that's expensive. And then there's the notification part of this, Ailsa - how much it costs a company to tell its customers, and sometimes its investors, about what damage took place. CHANG: OK, so it sounds like cyber insurance is a good idea. But are a lot of companies actually buying it? GURA: We have some new data on this from the federal government. In 2020, half the companies that bought insurance had cyber coverage. In 2016, four years earlier, it was just a quarter of them. So it is becoming more popular, and we're seeing the costs creep up for coverage. I think this uptick in demand for coverage says something about how normal these attacks have become. Companies are buying insurance for cyberattacks just like they buy insurance for fires and for earthquakes. That's made it become a regular part of doing business. And it's happening even as the federal government tells companies it doesn't want them to pay ransoms, that paying ransoms incentivizes more attacks. CHANG: Well, given all these recent cyberattacks, is the thinking now that all companies should be buying cyber insurance? GURA: Well, experts told me yes. It's becoming increasingly clear companies could benefit from this kind of insurance. But there's a catch. There's this concern that companies that buy cyber coverage could be targeted as a result. James Turgal helped run the FBI's information and technology branch. Now he's with the security company Optiv, and he consults with large companies. He told me some hackers actually scour IT systems as part of an attack to learn about the kind of insurance a company has. And then these bad actors will use that information as leverage. JAMES TURGAL: They will actually put up a piece of that cyber insurance policy to show you that, one, they've infiltrated your system and they have exfiltrated data but also to let you know they know about the cyber insurance. CHANG: That's scary. GURA: Another cybersecurity consultant said she has heard of hackers figuring out what to ask for, how big a ransom to ask for based on what a policy says an insurer would cover. CHANG: OK. Well, what about the insurance side of things? Like, how is the growing popularity of cyber insurance affecting the overall business of insurance? GURA: Well, insurers are forcing companies to do more to improve their IT infrastructure. They're also making more of an effort to verify a company's defenses are, in fact, as good as the company says they are. And that's part of what determines the premium. Daniel Soo is a cybersecurity consultant with Deloitte, and he says this is an approach you see with other kinds of insurance, like with car insurance, for instance. DANIEL SOO: To get different safety features on your car has an impact on your premium. It's going to be the same thing with cyber insurance. GURA: Now, something else that's happening is insurers are denying claims if a company's systems are not as secure as it claimed. And one last point here - ransomware isn't new. It's been around for decades. But this kind of standalone cyber coverage, Ailsa, is fairly new. And because of that, policies vary. This could make it get more standardized as time passes. CHANG: That is NPR's David Gura. Thank you, David. GURA: Thank you. (SOUNDBITE OF SALLY SHAPIRO SONG, \"STARMAN\") AILSA CHANG, HOST:   Ransomware attacks have hit the U. S. food supply, the health care system, the pipelines that carry fuel up and down the East Coast. And companies are worried about being attacked. More of them are buying what's called cyber insurance, but that demand has led to higher prices and to coverage that is less comprehensive. NPR's David Gura joins us now with more. Hey, David. DAVID GURA, BYLINE: Hey, Ailsa. CHANG: OK, so just give us a primer first. How does cyber insurance work exactly? GURA: Yeah. Let's take ransomware, for example. It's been in the news lately. There have been these big attacks. Colonial Pipeline is one of them. JBS, the meat processor, is another one. You know, they can cause a lot of disruption, cause a lot of damage. And the ransom demands can be sizable, as we've seen. Colonial Pipeline paid $4. 4 million. Well, a company can buy an insurance policy not just to cover the ransom payment itself but also the fallout from an attack. A company may have to hire a consultant to negotiate and make a payment. There's forensics work - trying to figure out what happened, what was taken. All of that's expensive. And then there's the notification part of this, Ailsa - how much it costs a company to tell its customers, and sometimes its investors, about what damage took place. CHANG: OK, so it sounds like cyber insurance is a good idea. But are a lot of companies actually buying it? GURA: We have some new data on this from the federal government. In 2020, half the companies that bought insurance had cyber coverage. In 2016, four years earlier, it was just a quarter of them. So it is becoming more popular, and we're seeing the costs creep up for coverage. I think this uptick in demand for coverage says something about how normal these attacks have become. Companies are buying insurance for cyberattacks just like they buy insurance for fires and for earthquakes. That's made it become a regular part of doing business. And it's happening even as the federal government tells companies it doesn't want them to pay ransoms, that paying ransoms incentivizes more attacks. CHANG: Well, given all these recent cyberattacks, is the thinking now that all companies should be buying cyber insurance? GURA: Well, experts told me yes. It's becoming increasingly clear companies could benefit from this kind of insurance. But there's a catch. There's this concern that companies that buy cyber coverage could be targeted as a result. James Turgal helped run the FBI's information and technology branch. Now he's with the security company Optiv, and he consults with large companies. He told me some hackers actually scour IT systems as part of an attack to learn about the kind of insurance a company has. And then these bad actors will use that information as leverage. JAMES TURGAL: They will actually put up a piece of that cyber insurance policy to show you that, one, they've infiltrated your system and they have exfiltrated data but also to let you know they know about the cyber insurance. CHANG: That's scary. GURA: Another cybersecurity consultant said she has heard of hackers figuring out what to ask for, how big a ransom to ask for based on what a policy says an insurer would cover. CHANG: OK. Well, what about the insurance side of things? Like, how is the growing popularity of cyber insurance affecting the overall business of insurance? GURA: Well, insurers are forcing companies to do more to improve their IT infrastructure. They're also making more of an effort to verify a company's defenses are, in fact, as good as the company says they are. And that's part of what determines the premium. Daniel Soo is a cybersecurity consultant with Deloitte, and he says this is an approach you see with other kinds of insurance, like with car insurance, for instance. DANIEL SOO: To get different safety features on your car has an impact on your premium. It's going to be the same thing with cyber insurance. GURA: Now, something else that's happening is insurers are denying claims if a company's systems are not as secure as it claimed. And one last point here - ransomware isn't new. It's been around for decades. But this kind of standalone cyber coverage, Ailsa, is fairly new. And because of that, policies vary. This could make it get more standardized as time passes. CHANG: That is NPR's David Gura. Thank you, David. GURA: Thank you. (SOUNDBITE OF SALLY SHAPIRO SONG, \"STARMAN\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-07-15-1013777482": {"title": "Emoji Use Makes People Feel More Connected On The Job, A Survey Says : NPR", "url": "https://www.npr.org/2021/07/15/1013777482/emoji-use-at-work-survey-says-thumbs-up-a", "author": "No author found", "published_date": "2021-07-15", "content": "", "section": "Business", "disclaimer": ""}, "2021-07-15-1016224865": {"title": "The White House Announces Additional Steps To Combat Ransomware : NPR", "url": "https://www.npr.org/2021/07/15/1016224865/the-white-house-announces-additional-steps-to-combat-ransomware", "author": "No author found", "published_date": "2021-07-15", "content": "", "section": "National Security", "disclaimer": ""}, "2021-07-16-1016838329": {"title": "Virginia Will Invest $700 Million To Boost State's Broadband : NPR", "url": "https://www.npr.org/2021/07/16/1016838329/virginia-shifts-700-million-in-relief-funds-to-boost-rural-broadband-access", "author": "No author found", "published_date": "2021-07-16", "content": "", "section": "Politics", "disclaimer": ""}, "2021-07-16-1016953132": {"title": "Hobbled Hubble Telescope Springs Back To Life On Its Backup System : NPR", "url": "https://www.npr.org/2021/07/16/1016953132/hobbled-hubble-telescope-springs-back-to-life-on-its-backup-system", "author": "No author found", "published_date": "2021-07-16", "content": "", "section": "Space", "disclaimer": ""}, "2021-07-16-1016901447": {"title": "Dictionary.com Adds Over 300 New Words And Definitions : NPR", "url": "https://www.npr.org/2021/07/16/1016901447/oof-yall-dictionary-com-just-added-over-300-new-words-and-definitions", "author": "No author found", "published_date": "2021-07-16", "content": "", "section": "Pop Culture", "disclaimer": ""}, "2021-07-19-1013793067": {"title": "How Ben Shapiro Is Using Facebook To Build A Business Empire : NPR", "url": "https://www.npr.org/2021/07/19/1013793067/outrage-as-a-business-model-how-ben-shapiro-is-using-facebook-to-build-an-empire", "author": "No author found", "published_date": "2021-07-19", "content": "AILSA CHANG, HOST:  Outrage does really well on social media. Posts that make people angry or upset or any other strong emotion get more likes, shares and comments. And a new NPR analysis shows how one conservative website, The Daily Wire, is taking advantage of that more than any other news source. NPR's Miles Parks did that analysis and joins us now. Hey, Miles. MILES PARKS, BYLINE: Hey, Ailsa. CHANG: Hey. So I know that quantifying what's happening on social media is really difficult, but can you just talk about this analysis that you did? Like, what were you able to find? PARKS: So what we really wanted to find out was which news publishers were doing the best at generating engagement on Facebook. Like you said, this is likes, shares and comments. And it's really the best way we can see - publicly available way that we can see, I should say - what's actually happening on Facebook. So we looked at each month's engagement numbers for a bunch of different news outlets for the last year using data from this company NewsWhip. And what we found was that The Daily Wire, which is this conservative news site founded by podcast host and author Ben Shapiro - the site is dominating Facebook in first place basically every month. CHANG: Wow. PARKS: In May, for instance, a couple months ago, The Daily Wire generated more Facebook engagement than The New York Times, The Washington Post, CNN and NBC News combined. Those are companies that are, you know, 10, 20, 30 times the size of The Daily Wire. CHANG: Yeah. Wow, that's fascinating. So can you just talk a little more about what kind of content is on The Daily Wire? Like, do they have their own journalists who report out news stories? PARKS: Not really - so the site mostly aggregates stories from other news outlets. And these are all stories that either bolster the conservative agenda, or they focus on polarizing topics. There's lots of stories, for instance, on, like, cancel culture and critical race theory. It's not usually false information. It's just extremely biased, which the site admittedly does say on their website. They openly admit to being a biased news source. It's not hidden at all. But I talked to Jaime Settle, who's a social networks researcher at William and Mary, and here's how she explained it. JAIME SETTLE: They tend to not provide very much context for the information that they are providing. And so if you strip enough context away, any piece of truth can become a piece of misinformation. PARKS: COVID coverage is a good example. You know, the website does not ever publish an article that says, don't get vaccinated, or, the vaccines will kill you, or something. It's just all stories that glorify either vaccine freedom or talk about potential side effects. So it kind of furthers this narrative that the vaccines are something to be wary about without ever, you know, coming out and saying that. CHANG: Right. And this content is getting the most engagement on Facebook, you say. So what does the success of this site say about Facebook, do you think? PARKS: It's another example of polarizing content doing really well on the site. I talked to Deen Freelon, who's a communications expert at the University of North Carolina Asheville. What he said is it's also a testament to Shapiro for being able to appeal to this Republican base without going so far as to break the rules of the social media platforms. DEEN FREELON: One of the big, you know, things about the blogosphere initially was, oh, anybody can do this. And while that's true in a sense, you know, it's no small feat to do it well. Regardless of whatever you think of Ben Shapiro's ideological leanings, it's hard to deny that he is doing what he's doing well. PARKS: Every single expert I talked to had a similar response that was kind of like, it's unfortunate that this website is the most engaged with content on Facebook, but you also have to hand it to Shapiro. He's doing something right. CHANG: (Laughter) Congrats, Shapiro. OK, so what about the news industry? I mean, what does this study tell us about the information that people, especially people with conservative viewpoints, want right now? PARKS: That's a really good question. Broadly, conservatives over the last 20 years have been growing more and more distrustful of mainstream news sources, which does help a newer site like The Daily Wire. But also, people just have less options when it comes to local news sources. That's something Monica Stevens, who's a social media expert at the University of Buffalo, told me. So we're seeing this shift from people getting information tailored on where they've - tailored to where they live, I should say, towards this situation where people are getting information tailored to their ideology. MONICA STEVENS: So you're more likely to read the same news as somebody who lives a thousand miles away from you but holds the same perspective than share news and share information with your next-door neighbor. PARKS: The problem, Stevens says, is that that sort of news consumption can lead to more division and more polarization. CHANG: That is NPR's Miles Parks. Thank you, Miles. PARKS: Thank you so much. AILSA CHANG, HOST:   Outrage does really well on social media. Posts that make people angry or upset or any other strong emotion get more likes, shares and comments. And a new NPR analysis shows how one conservative website, The Daily Wire, is taking advantage of that more than any other news source. NPR's Miles Parks did that analysis and joins us now. Hey, Miles. MILES PARKS, BYLINE: Hey, Ailsa. CHANG: Hey. So I know that quantifying what's happening on social media is really difficult, but can you just talk about this analysis that you did? Like, what were you able to find? PARKS: So what we really wanted to find out was which news publishers were doing the best at generating engagement on Facebook. Like you said, this is likes, shares and comments. And it's really the best way we can see - publicly available way that we can see, I should say - what's actually happening on Facebook. So we looked at each month's engagement numbers for a bunch of different news outlets for the last year using data from this company NewsWhip. And what we found was that The Daily Wire, which is this conservative news site founded by podcast host and author Ben Shapiro - the site is dominating Facebook in first place basically every month. CHANG: Wow. PARKS: In May, for instance, a couple months ago, The Daily Wire generated more Facebook engagement than The New York Times, The Washington Post, CNN and NBC News combined. Those are companies that are, you know, 10, 20, 30 times the size of The Daily Wire. CHANG: Yeah. Wow, that's fascinating. So can you just talk a little more about what kind of content is on The Daily Wire? Like, do they have their own journalists who report out news stories? PARKS: Not really - so the site mostly aggregates stories from other news outlets. And these are all stories that either bolster the conservative agenda, or they focus on polarizing topics. There's lots of stories, for instance, on, like, cancel culture and critical race theory. It's not usually false information. It's just extremely biased, which the site admittedly does say on their website. They openly admit to being a biased news source. It's not hidden at all. But I talked to Jaime Settle, who's a social networks researcher at William and Mary, and here's how she explained it. JAIME SETTLE: They tend to not provide very much context for the information that they are providing. And so if you strip enough context away, any piece of truth can become a piece of misinformation. PARKS: COVID coverage is a good example. You know, the website does not ever publish an article that says, don't get vaccinated, or, the vaccines will kill you, or something. It's just all stories that glorify either vaccine freedom or talk about potential side effects. So it kind of furthers this narrative that the vaccines are something to be wary about without ever, you know, coming out and saying that. CHANG: Right. And this content is getting the most engagement on Facebook, you say. So what does the success of this site say about Facebook, do you think? PARKS: It's another example of polarizing content doing really well on the site. I talked to Deen Freelon, who's a communications expert at the University of North Carolina Asheville. What he said is it's also a testament to Shapiro for being able to appeal to this Republican base without going so far as to break the rules of the social media platforms. DEEN FREELON: One of the big, you know, things about the blogosphere initially was, oh, anybody can do this. And while that's true in a sense, you know, it's no small feat to do it well. Regardless of whatever you think of Ben Shapiro's ideological leanings, it's hard to deny that he is doing what he's doing well. PARKS: Every single expert I talked to had a similar response that was kind of like, it's unfortunate that this website is the most engaged with content on Facebook, but you also have to hand it to Shapiro. He's doing something right. CHANG: (Laughter) Congrats, Shapiro. OK, so what about the news industry? I mean, what does this study tell us about the information that people, especially people with conservative viewpoints, want right now? PARKS: That's a really good question. Broadly, conservatives over the last 20 years have been growing more and more distrustful of mainstream news sources, which does help a newer site like The Daily Wire. But also, people just have less options when it comes to local news sources. That's something Monica Stevens, who's a social media expert at the University of Buffalo, told me. So we're seeing this shift from people getting information tailored on where they've - tailored to where they live, I should say, towards this situation where people are getting information tailored to their ideology. MONICA STEVENS: So you're more likely to read the same news as somebody who lives a thousand miles away from you but holds the same perspective than share news and share information with your next-door neighbor. PARKS: The problem, Stevens says, is that that sort of news consumption can lead to more division and more polarization. CHANG: That is NPR's Miles Parks. Thank you, Miles. PARKS: Thank you so much.", "section": "Untangling Disinformation", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-07-20-1018373645": {"title": "WeWork Prepares For A Second Act \u2014 Banking Its Future On The Rise Of Remote Work : NPR", "url": "https://www.npr.org/2021/07/20/1018373645/wework-prepares-for-a-second-act-banking-its-future-on-the-rise-of-remote-work", "author": "No author found", "published_date": "2021-07-20", "content": "MARY LOUISE KELLY, HOST:  Office sharing company WeWork was once the darling of Silicon Valley. In 2019, though, it went from the second most valuable U. S. startup to the brink of collapse. Now as remote work grows, the company is launching its second act. NPR's Bobby Allyn reports. BOBBY ALLYN, BYLINE: Say WeWork, and one person comes to mind - Adam Neumann, the lanky former CEO with flowing black hair who went all woo-woo about the energy of the company's workspaces, like here at a 2017 conference in Washington. (SOUNDBITE OF ARCHIVED RECORDING)ADAM NEUMANN: And it's an energy of people doing their own thing while actually still being part of something greater than themselves. We like to call it the we generation. ALLYN: Sounds wacky, but established investors believed it and wrote him checks for billions. Neumann had another side, too, says journalist Eliot Brown. He wrote about it recently in his new book, \"The Cult Of We. \"ELIOT BROWN: He really embraced the party boy lifestyle. With investors, he would - at 9, 10, 11 a. m. when they'd come in, he'd immediately offer them shots of tequila. He had a cigar bar-type vent installed in his office to suck out the marijuana smoke. ALLYN: What emerged out of the weed smoke? A company investors pegged at $47 billion. BROWN: He created the country's most valuable startup, but it was essentially just a mirage. ALLYN: Here's how the business model was supposed to work. Get good deals on long-term office leases, and then make a profit by subleasing them on short-term contracts. Inside, WeWork spaces had the look and feel of a hip Brooklyn cafe. But was there any assurance all of this office space would be occupied for years to come? What if a recession hit? Those questions went unanswered. Eventually, WeWork hit the skids. Its plans to go public went out the window. Neumann was ousted. The company nearly went bankrupt. Now WeWork has a new boss, former real estate executive Sandeep Mathrani. He's trying to clean up a Silicon Valley mess. But when asked about Neumann on CNBC, he replied. . . (SOUNDBITE OF ARCHIVED RECORDING)SANDEEP MATHRANI: It's noise in the background as far as I'm concerned. My focus is to right this ship. ALLYN: But he's trying to right the ship during a time when the future of the office is very much up for debate. BARBARA DENHAM: It's one of the most uncertain times for the office market probably since the '70s, when so many corporations left major cities. ALLYN: That's Barbara Denham. She's an economist at Oxford Economics. She says the popularity of remote work since the pandemic has companies canceling office leases and downsizing others. She says that could be good for WeWork, which offers office space literally by the hour. DENHAM: The demand for the WeWorks of the world, the coworking space, the flexible office lease market is huge. ALLYN: If office life springs back, though, author Brown says WeWork might have some trouble with its hundreds of leases around the world. BROWN: WeWork is positioning itself as the company that's going to capitalize on the changing world of office space. But they really don't know, and neither do we. ALLYN: Outside of a downtown San Francisco skyscraper, Samir Kapoor is leaving a WeWork to grab lunch. He says the space is better than any office he's ever worked in - stunning views, kombucha on tap, even nooks to nap in. Kapoor is a startup founder. SAMIR KAPOOR: You get to see other founders, get to see other people who are working, never know who you're going to meet. That's kind of an added plus. ALLYN: But if something more affordable came along, Kapoor says he'd be fine to ditch WeWork. KAPOOR: It's not hard to replicate what WeWork has done. I mean, it's just kind of some nice modern furniture, some nice desks and some great coffee, and you got it. And so I don't have any brand loyalty for sure. And so if there's a cheaper alternative with just as many locations, I'd be happy to go with them. ALLYN: WeWork is still reeling from the high-flying Neumann era. It says it left 17 buildings and renegotiated leases on more than 50 others in the past two months alone. Another change - it's no longer saying its goal is to, quote, \"elevate the world's consciousness. \" It now says it's a real estate company. Bobby Allyn, NPR News, San Francisco. (SOUNDBITE OF DAPHNI'S \"LIFE'S WHAT YOU MAKE IT\") MARY LOUISE KELLY, HOST:   Office sharing company WeWork was once the darling of Silicon Valley. In 2019, though, it went from the second most valuable U. S. startup to the brink of collapse. Now as remote work grows, the company is launching its second act. NPR's Bobby Allyn reports. BOBBY ALLYN, BYLINE: Say WeWork, and one person comes to mind - Adam Neumann, the lanky former CEO with flowing black hair who went all woo-woo about the energy of the company's workspaces, like here at a 2017 conference in Washington. (SOUNDBITE OF ARCHIVED RECORDING) ADAM NEUMANN: And it's an energy of people doing their own thing while actually still being part of something greater than themselves. We like to call it the we generation. ALLYN: Sounds wacky, but established investors believed it and wrote him checks for billions. Neumann had another side, too, says journalist Eliot Brown. He wrote about it recently in his new book, \"The Cult Of We. \" ELIOT BROWN: He really embraced the party boy lifestyle. With investors, he would - at 9, 10, 11 a. m. when they'd come in, he'd immediately offer them shots of tequila. He had a cigar bar-type vent installed in his office to suck out the marijuana smoke. ALLYN: What emerged out of the weed smoke? A company investors pegged at $47 billion. BROWN: He created the country's most valuable startup, but it was essentially just a mirage. ALLYN: Here's how the business model was supposed to work. Get good deals on long-term office leases, and then make a profit by subleasing them on short-term contracts. Inside, WeWork spaces had the look and feel of a hip Brooklyn cafe. But was there any assurance all of this office space would be occupied for years to come? What if a recession hit? Those questions went unanswered. Eventually, WeWork hit the skids. Its plans to go public went out the window. Neumann was ousted. The company nearly went bankrupt. Now WeWork has a new boss, former real estate executive Sandeep Mathrani. He's trying to clean up a Silicon Valley mess. But when asked about Neumann on CNBC, he replied. . . (SOUNDBITE OF ARCHIVED RECORDING) SANDEEP MATHRANI: It's noise in the background as far as I'm concerned. My focus is to right this ship. ALLYN: But he's trying to right the ship during a time when the future of the office is very much up for debate. BARBARA DENHAM: It's one of the most uncertain times for the office market probably since the '70s, when so many corporations left major cities. ALLYN: That's Barbara Denham. She's an economist at Oxford Economics. She says the popularity of remote work since the pandemic has companies canceling office leases and downsizing others. She says that could be good for WeWork, which offers office space literally by the hour. DENHAM: The demand for the WeWorks of the world, the coworking space, the flexible office lease market is huge. ALLYN: If office life springs back, though, author Brown says WeWork might have some trouble with its hundreds of leases around the world. BROWN: WeWork is positioning itself as the company that's going to capitalize on the changing world of office space. But they really don't know, and neither do we. ALLYN: Outside of a downtown San Francisco skyscraper, Samir Kapoor is leaving a WeWork to grab lunch. He says the space is better than any office he's ever worked in - stunning views, kombucha on tap, even nooks to nap in. Kapoor is a startup founder. SAMIR KAPOOR: You get to see other founders, get to see other people who are working, never know who you're going to meet. That's kind of an added plus. ALLYN: But if something more affordable came along, Kapoor says he'd be fine to ditch WeWork. KAPOOR: It's not hard to replicate what WeWork has done. I mean, it's just kind of some nice modern furniture, some nice desks and some great coffee, and you got it. And so I don't have any brand loyalty for sure. And so if there's a cheaper alternative with just as many locations, I'd be happy to go with them. ALLYN: WeWork is still reeling from the high-flying Neumann era. It says it left 17 buildings and renegotiated leases on more than 50 others in the past two months alone. Another change - it's no longer saying its goal is to, quote, \"elevate the world's consciousness. \" It now says it's a real estate company. Bobby Allyn, NPR News, San Francisco. (SOUNDBITE OF DAPHNI'S \"LIFE'S WHAT YOU MAKE IT\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-07-20-1018381462": {"title": "Here's How Fast-Fashion Brands Can Legally Copy Indie Designers : NPR", "url": "https://www.npr.org/2021/07/20/1018381462/why-indie-brands-are-at-war-with-shein-and-other-fast-fashion-companies", "author": "No author found", "published_date": "2021-07-20", "content": "", "section": "Business", "disclaimer": ""}, "2021-07-20-1018414444": {"title": "Jeff Bezos Gives Millions To Van Jones, Jos\u00e9 Andr\u00e9s After Spaceflight : NPR", "url": "https://www.npr.org/2021/07/20/1018414444/bezos-landed-thanked-amazon-workers-and-shoppers-for-paying-gave-away-200-millio", "author": "No author found", "published_date": "2021-07-20", "content": "", "section": "Business", "disclaimer": ""}, "2021-07-20-1018283149": {"title": "China Accuses U.S. Of Cyberattacks; Says It Had No Role In Microsoft Hack : NPR", "url": "https://www.npr.org/2021/07/20/1018283149/china-blames-united-states-for-cyberattacks", "author": "No author found", "published_date": "2021-07-20", "content": "", "section": "National Security", "disclaimer": ""}, "2021-07-20-1018279093": {"title": "Jeff Bezos Travels To Space And Back On Blue Origin Rocket  : NPR", "url": "https://www.npr.org/2021/07/20/1018279093/jeff-bezos-blue-origin-space-flight", "author": "No author found", "published_date": "2021-07-20", "content": "", "section": "Space", "disclaimer": ""}, "2021-07-20-1018226161": {"title": "Former U.N. Adviser Says Global Spyware Is A Threat To Democracy : NPR", "url": "https://www.npr.org/2021/07/20/1018226161/global-spyware-is-a-threat-to-democracy-former-u-n-advocate-says", "author": "No author found", "published_date": "2021-07-20", "content": "NOEL KING, HOST:  Two years ago, a free speech advocate working for the United Nations started warning people about spyware. He said it was being marketed to fight crime. But governments could abuse it and use the software to track critics and dissenters. Within the past few days, we learned that Pegasus spyware has been used to spy on rights activists, opposition politicians and journalists. David Kaye, the man who sounded that first warning, is now a professor at UC Irvine. And he has written in The Washington Post that this kind of spyware is a threat to democracy. Professor Kaye, thanks for being with us. DAVID KAYE: Thanks for having me. KING: Let me just start with what spyware was originally for. The name itself would make me think it's something that was used to spy on people. But you point out that it was marketed as something different in the beginning. KAYE: That's true. I mean, we use the term spyware as a kind of colloquialism to refer to this. But basically, we're talking about technology that is used for surveillance purposes. And, I think, as either the companies in the industry will argue, they created this in order to track terrorists and criminals and others. And the problem is that it's not used for those purposes alone. It's used, as you indicated, for all sorts of purposes, to target journalists and activists and others. KING: It is illegal, as I understand it, for the U. S. government to spy on Americans. Is it illegal for other countries to do the same? KAYE: That's a really great question. This gets at the fundamental problem. There is no international law that governs the use of this technology across borders. There have been cases where foreign governments have conducted spying of people in the United States. So for example, the Ethiopian government several years ago conducted a spying operation against an Ethiopian American in Maryland. And yet, this individual had no tools to fight back. And that's the kind of problem that we're seeing here right now - essentially, transnational repression. But we lack the tools to fight it. KING: We know now that The Washington Post and other media organizations got tens of thousands of phone numbers belonging to potential targets of Pegasus software from Mexico to the Middle East. We had a Post reporter, Craig Timberg, on the show yesterday. Let me play a little bit of what he said. (SOUNDBITE OF ARCHIVED NPR BROADCAST)CRAIG TIMBERG: We're talking about business executives and academics and human rights activists and journalists. It's easy to understand why a spy would want to know what they know. KING: And I think what Craig Timberg is saying is that this is a widespread problem. KAYE: Yeah. Absolutely. I mean, if you think about the kind of surveillance that we're talking about, you know, talking about, you know, foreign governments having access to individual journalists or activists or others, that in itself is a kind of direct threat to individuals. But it goes even beyond that. I mean, there are many, many cases that show that this kind of surveillance technology has been used against individuals or the circle of individuals who then face some serious consequence, some of whom have been arrested - even to, you know, suffer the worst consequence, such as murder, as there's actually indication that people around The Washington Post journalist Jamal Khashoggi were surveilled both before and after his disappearance and murdered by the Saudi government a few years back. KING: Lastly, you write in The Washington Post that spyware is a threat to democracy. What do you mean by that? KAYE: Yeah. I mean, it's just that. I mean, spyware is aimed, in many of these situations, at the very pillars of democratic life. I mean, it's aimed at the journalists and the opposition figures, those in dissent that we've been talking about. And yet there's this very significant problem that it's lawless. I mean, it's taking place in a context without governance by the rule of law. And that's, essentially, what we're calling for. We're calling for this kind of industry to finally be placed under export control standards, under other kinds of standards, so that its tools not only, you know, are more difficult to transfer, but are also used in a way that is consistent with fundamental, rule-of-law standards. KING: David Kaye is a professor of law at UC Irvine and a former U. N. special rapporteur on freedom of expression. Professor, thank you so much for being with us. We really appreciate it. KAYE: Thanks for having me. NOEL KING, HOST:   Two years ago, a free speech advocate working for the United Nations started warning people about spyware. He said it was being marketed to fight crime. But governments could abuse it and use the software to track critics and dissenters. Within the past few days, we learned that Pegasus spyware has been used to spy on rights activists, opposition politicians and journalists. David Kaye, the man who sounded that first warning, is now a professor at UC Irvine. And he has written in The Washington Post that this kind of spyware is a threat to democracy. Professor Kaye, thanks for being with us. DAVID KAYE: Thanks for having me. KING: Let me just start with what spyware was originally for. The name itself would make me think it's something that was used to spy on people. But you point out that it was marketed as something different in the beginning. KAYE: That's true. I mean, we use the term spyware as a kind of colloquialism to refer to this. But basically, we're talking about technology that is used for surveillance purposes. And, I think, as either the companies in the industry will argue, they created this in order to track terrorists and criminals and others. And the problem is that it's not used for those purposes alone. It's used, as you indicated, for all sorts of purposes, to target journalists and activists and others. KING: It is illegal, as I understand it, for the U. S. government to spy on Americans. Is it illegal for other countries to do the same? KAYE: That's a really great question. This gets at the fundamental problem. There is no international law that governs the use of this technology across borders. There have been cases where foreign governments have conducted spying of people in the United States. So for example, the Ethiopian government several years ago conducted a spying operation against an Ethiopian American in Maryland. And yet, this individual had no tools to fight back. And that's the kind of problem that we're seeing here right now - essentially, transnational repression. But we lack the tools to fight it. KING: We know now that The Washington Post and other media organizations got tens of thousands of phone numbers belonging to potential targets of Pegasus software from Mexico to the Middle East. We had a Post reporter, Craig Timberg, on the show yesterday. Let me play a little bit of what he said. (SOUNDBITE OF ARCHIVED NPR BROADCAST) CRAIG TIMBERG: We're talking about business executives and academics and human rights activists and journalists. It's easy to understand why a spy would want to know what they know. KING: And I think what Craig Timberg is saying is that this is a widespread problem. KAYE: Yeah. Absolutely. I mean, if you think about the kind of surveillance that we're talking about, you know, talking about, you know, foreign governments having access to individual journalists or activists or others, that in itself is a kind of direct threat to individuals. But it goes even beyond that. I mean, there are many, many cases that show that this kind of surveillance technology has been used against individuals or the circle of individuals who then face some serious consequence, some of whom have been arrested - even to, you know, suffer the worst consequence, such as murder, as there's actually indication that people around The Washington Post journalist Jamal Khashoggi were surveilled both before and after his disappearance and murdered by the Saudi government a few years back. KING: Lastly, you write in The Washington Post that spyware is a threat to democracy. What do you mean by that? KAYE: Yeah. I mean, it's just that. I mean, spyware is aimed, in many of these situations, at the very pillars of democratic life. I mean, it's aimed at the journalists and the opposition figures, those in dissent that we've been talking about. And yet there's this very significant problem that it's lawless. I mean, it's taking place in a context without governance by the rule of law. And that's, essentially, what we're calling for. We're calling for this kind of industry to finally be placed under export control standards, under other kinds of standards, so that its tools not only, you know, are more difficult to transfer, but are also used in a way that is consistent with fundamental, rule-of-law standards. KING: David Kaye is a professor of law at UC Irvine and a former U. N. special rapporteur on freedom of expression. Professor, thank you so much for being with us. We really appreciate it. KAYE: Thanks for having me.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-07-20-1017945718": {"title": "Jeff Bezos' Completes His Blue Origin Flight To Space : NPR", "url": "https://www.npr.org/2021/07/20/1017945718/jeff-bezos-and-blue-origin-will-try-to-travel-deeper-into-space-than-richard-bra", "author": "No author found", "published_date": "2021-07-20", "content": "", "section": "Space", "disclaimer": ""}, "2021-07-20-1017962403": {"title": "Dating Searches On Google Reach 5-Year High : NPR", "url": "https://www.npr.org/2021/07/20/1017962403/google-searches-for-dating-reached-5-year-high", "author": "No author found", "published_date": "2021-07-20", "content": "", "section": "Technology", "disclaimer": ""}, "2021-07-22-1019346177": {"title": "Democrats Seek To Pare Back Section 230 Over Health Falsehoods : NPR", "url": "https://www.npr.org/2021/07/22/1019346177/democrats-want-to-hold-social-media-companies-responsible-for-health-misinformat", "author": "No author found", "published_date": "2021-07-22", "content": "", "section": "Untangling Disinformation", "disclaimer": ""}, "2021-07-22-1019333663": {"title": "Internet Outage That Crashed Dozens Of Websites Caused By Software Update : NPR", "url": "https://www.npr.org/2021/07/22/1019333663/internet-outage-dns", "author": "No author found", "published_date": "2021-07-22", "content": "", "section": "Technology", "disclaimer": ""}, "2021-07-22-1019293032": {"title": "Suit Claims Sexual Harassment, Discrimination At Game Studio Activision Blizzard : NPR", "url": "https://www.npr.org/2021/07/22/1019293032/activision-blizzard-lawsuit-unequal-pay-sexual-harassment-video-games", "author": "No author found", "published_date": "2021-07-22", "content": "", "section": "Business", "disclaimer": ""}, "2021-07-22-1018944791": {"title": "Review: 'Legend Of Zelda: Skyward Sword HD\" : NPR", "url": "https://www.npr.org/2021/07/22/1018944791/nintendo-skyward-sword-hd-review", "author": "No author found", "published_date": "2021-07-22", "content": "", "section": "Gaming", "disclaimer": ""}, "2021-07-22-1019130188": {"title": "'Hot Vax Summer' Is Here And People Are Ready To Date : NPR", "url": "https://www.npr.org/2021/07/22/1019130188/hot-vax-summer-is-here-and-people-are-ready-to-date", "author": "No author found", "published_date": "2021-07-22", "content": "NOEL KING, HOST:  Good morning. I'm Noel King. Hot vax summer is here, and people are ready to date. Google tweeted that search interest in dating is at a five-year high in the U. S. Lots of people are Googling virtual first date ideas. And how to date was the most Googled question in Washington, D. C. , earlier this month. NPR's Life Kit podcast has some advice - open with a question. Even a simple question works. All I do is ask questions, Life Kit, so why am I single? It's MORNING EDITION. NOEL KING, HOST:   Good morning. I'm Noel King. Hot vax summer is here, and people are ready to date. Google tweeted that search interest in dating is at a five-year high in the U. S. Lots of people are Googling virtual first date ideas. And how to date was the most Googled question in Washington, D. C. , earlier this month. NPR's Life Kit podcast has some advice - open with a question. Even a simple question works. All I do is ask questions, Life Kit, so why am I single? It's MORNING EDITION.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-07-23-1019382485": {"title": "Jimmy Wales: How Can Wikipedia Ensure A Safe And Shared Online Space?  : NPR", "url": "https://www.npr.org/2021/07/23/1019382485/jimmy-wales-how-can-wikipedia-ensure-a-safe-and-shared-online-space", "author": "No author found", "published_date": "2021-07-23", "content": "MANOUSH ZOMORODI, HOST:  It's the TED Radio Hour from NPR. I'm Manoush Zomorodi. And on the show today, the public commons - building more democratic, more civil public places, whether it's a library, a city council budget meeting or the online platforms we use every day. That online part, as we've heard, is particularly tricky. But there is one place that's an example of a public commons on the web that mostly works with robust rules and norms, run almost entirely by volunteers. JAKE ORLOWITZ: I saw an article about a young man probably not much younger than when I was at the time. His name was Khalid Saeed, and he had been beaten horrifically to death by Egyptian police. ZOMORODI: This is Jake Orlowitz. ORLOWITZ: And it was the photograph of his face, at the time called the face that sparked a revolution. And I put the photograph of his battered face in the article. And I thought, you know, as an information activist, when there's something like this, the world needs to see it. ZOMORODI: Titled \"Death Of Khaled Mohamed Saeed,\" the article was - is - part of Wikipedia's coverage of the Arab Spring. Jake was one of the page's editors. ORLOWITZ: So I'm editing this article. And then the crowds start gathering. . . (SOUNDBITE OF PROTEST AMBIENCE)ORLOWITZ: . . . In Tahrir Square, which is Cairo's central square. And I am glued. I have Al Jazeera livestreaming into the bathroom. Every 20 seconds, 30 seconds, I'm typing in, you know, Egypt, Cairo, uprising, revolution. I'm gathering sources. And as I'm gathering sources, another editor had started the article, which at the time was called \"2011 Protests In Egypt. \"ZOMORODI: Jake worked out of his parents' home in Philadelphia as part of a small team of Wikipedia editors. Based around the globe, they updated the page constantly, keeping tabs on the enormous flow of information and rumors coming out of Cairo. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED REPORTER #1: And people now are pouring into the square. ORLOWITZ: You have reports coming in from various news agencies. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED REPORTER #2: Taking you live to Cairo. ORLOWITZ: And someone needs to say, these sources are good sources. These sources are not good sources. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED REPORTER #3: They're battling for territory and also for political control. ORLOWITZ: Someone needs to say, this breaking news event has now been reported in enough papers that we can consider it dependable. There are sections that need to be added explaining the background causes. You're starting to get international reactions, and different heads of state are commenting. And all of this is being organized by four or five really core editors. It's me. It's a European who is really interested in politics. It's an Egyptian who's on the ground in Egypt. We're walking this fine line between rooting for the revolution and making sure the Wikipedia article does its job, which is to report neutrally. ZOMORODI: Maybe you've gotten a breaking news alert on your phone. It could be a massive revolution or a celebrity wardrobe malfunction. And you go to Wikipedia, and you find that it's already been updated with the latest details. It can feel like magic. But the over 6 million English language articles - from the Egyptian revolution to Bennifer - are almost all written, edited and fact-checked by a small army of volunteer editors who call themselves Wikipedians. ORLOWITZ: Writing a new article - it's a lot of fun because you get to shape what comes next. Wikipedians build in layers. And if you put down that first layer, that scaffolding, someone else will hopefully come by and put up a wall here or a window there. ZOMORODI: Ideally, copy editors and researchers come in and make that scaffolding stronger, supported by verified information. ORLOWITZ: Because at the core of Wikipedia's ethos is that you don't write your own knowledge. You're merely summarizing other good sources because if I don't do that, someone is likely to come by and say, I recommend this article be deleted. And then you have to have a debate about it for a whole week about whether or not the article can exist at all. ZOMORODI: All these layers and debates, the whole open-source ethos - Jake says that's why Wikipedia is different than other places online. ORLOWITZ: And I think that's what readers love because everywhere else you look when you're trying to get news, there's so much noise that comes with that. Jimmy Wales, the founder of Wikipedia, said that Wikipedia is like a temple for the mind. You go to a Wikipedia page, and you're not going to get bombarded by an ad. You're not going to have to see threads of comments. It's just quiet. And we don't have a lot of quiet digital spaces anymore. JIMMY WALES: You know, when most people first got on the internet, one of the first thoughts that people would have is, like, wow, this is amazing. Like, everyone in the world can communicate. And so I just thought, OK, why don't we just use the internet for that? We've got this great tool for sharing knowledge, so why don't we just share knowledge? ZOMORODI: This is Jimmy Wales. You could call him the original Wikipedian. He co-founded the website back in 2001. And even then, he had big ideas for the platform. WALES: The original vision for Wikipedia is to imagine a world in which every single person on the planet is given free access to the sum of all human knowledge. ZOMORODI: But to create a digital public space that could even begin to deliver on those ambitions, it required a set of founding values. Here's Jimmy Wales on the TED stage back in 2005. (SOUNDBITE OF TED TALK)WALES: So the biggest and the most important thing is our neutral point of view policy. This is something that I set down from the very beginning as a core principle of the community that's completely not debatable. It's a social concept of cooperation. So we don't talk a lot about truth and objectivity. Anytime there's a controversial issue, Wikipedia itself should not take a stand on the issue. We should merely report on what reputable parties have said about it. So this neutrality policy is really important for us because it empowers the community to come together and actually get some work done. By having this firm neutrality policy, which is non-negotiable from the beginning, we ensure that people can work together and that the entries don't become simply a war back and forth between the left and the right. If you engage in that type of behavior, you'll be asked to leave the community. (SOUNDBITE OF MUSIC)ZOMORODI: Jimmy, you have always emphasized the importance of neutrality. But, I mean, let's be honest, it's hard to build utopia, right? I mean, Wikipedia has gotten a fair amount of criticism over the years about who gets an entry and who doesn't. Representation continues to be a problem. Like, for example, there are very few entries about notable women, especially women of color, female scientists. And so therefore, what is on Wikipedia is not entirely neutral, no? WALES: Yeah. I mean, that is definitely exactly the heart of what we have to strive for. So we have groups like Women in Red who say, OK, we're going to look into, you know, where are there problems in the coverage of Wikipedia where we have incomplete coverage of people who should be here who are women. And I can say, having chatted with thousands of Wikipedians (ph) over the years, like, people first and foremost write about what they know about. They write about what they're interested in. And it turns out that a lot of what people are interested in, there is - that gender is reflected in that. So as a community, we need to bring in more people. We need to bring in a more diverse bunch of contributors. And then we can ask ourselves, OK, how can we make that happen? What are the barriers to making that happen? And this is a huge body of thinking and talking and working that we do within the community. ZOMORODI: You know, we actually talked to Eli Pariser about that earlier, that perhaps we need to design platforms to be welcoming, to be more civil. But also, you know, it makes me wonder, does it come back to the business model? Like, how much did making Wikipedia a nonprofit factor into it being a place where people wanted to share knowledge, not a place to chase clicks and to sell more ads? WALES: I would say one of the first things I would suggest is to move away from this, in my view, false dichotomy that you can either do something good for the public space or you can make a lot of money. You know, you can do something that's powerfully ethical, very interesting, makes money, but doesn't involve promoting conspiracy theories and nonsense and creating unhealthy spaces. You know, it's like the local pub or coffee shop. And they're there to make money, and they have a business. But it's also - in many cases, it's the heart of a community. And that's great. ZOMORODI: But that doesn't always happen with these profit-driven platforms. They are not just virtual coffee shops where people gather together benignly. A lot of the time, people end up in much darker, more profane places and getting bad information. WALES: I mean, it's really interesting because if you think about two places you can go where it's quite easy to get sucked in and spend hours and hours - so one is Wikipedia and then YouTube. But the difference is, at YouTube, the videos that are shown to you next tend to be videos that keep you on the site longer. ZOMORODI: Right. WALES: Oftentimes, something outrageous, something, you know, wrong is more likely to keep you on the site than otherwise. And so they promote that. At Wikipedia, there is no algorithm. Humans wrote at all. They link to things they think are interesting. They link to background information. And that just gives you a completely different and opposite result. It doesn't lead you down this unhealthy path to dark places. And I think that's interesting. And, you know, it's hard. It's hard for an advertising-based system to do that. And I think that difference is really what explains a lot that's going on on the internet. (SOUNDBITE OF MUSIC)ZOMORODI: As we wrap up, I just want to read you a quote that I understand a lot of Wikipedians like, or a phrase. Thank God our little enterprise works in practice because it could never work in theory. WALES: (Laughter). ZOMORODI: Do you abide by that? WALES: I don't. ZOMORODI: No (laughter)? WALES: I think it really is a system that's designed. I always compare it to a good municipal government. What do you want from a good municipal government? Well, you want to be able to criticize and complain about the administrators or, you know, the police or whatever without getting thrown in jail. So you don't want to be treated in an arbitrary fashion. But at the same time, you also want your children to be able to play in the park and not get accosted and attacked and so on. And so that balance between having rules, creating a safe environment while at the same time saying let's not be overcontrolling and so on, it's an art, and it's a bit messy, but it does work. ZOMORODI: Jimmy Wales is the co-founder of Wikipedia and a Wikimedia board member. You can see his talk at ted. com. Also, many thanks to Jake Orlowitz, founder of the Wikipedia Library, a project that helps Wikipedians find reliable sources. MANOUSH ZOMORODI, HOST:   It's the TED Radio Hour from NPR. I'm Manoush Zomorodi. And on the show today, the public commons - building more democratic, more civil public places, whether it's a library, a city council budget meeting or the online platforms we use every day. That online part, as we've heard, is particularly tricky. But there is one place that's an example of a public commons on the web that mostly works with robust rules and norms, run almost entirely by volunteers. JAKE ORLOWITZ: I saw an article about a young man probably not much younger than when I was at the time. His name was Khalid Saeed, and he had been beaten horrifically to death by Egyptian police. ZOMORODI: This is Jake Orlowitz. ORLOWITZ: And it was the photograph of his face, at the time called the face that sparked a revolution. And I put the photograph of his battered face in the article. And I thought, you know, as an information activist, when there's something like this, the world needs to see it. ZOMORODI: Titled \"Death Of Khaled Mohamed Saeed,\" the article was - is - part of Wikipedia's coverage of the Arab Spring. Jake was one of the page's editors. ORLOWITZ: So I'm editing this article. And then the crowds start gathering. . . (SOUNDBITE OF PROTEST AMBIENCE) ORLOWITZ: . . . In Tahrir Square, which is Cairo's central square. And I am glued. I have Al Jazeera livestreaming into the bathroom. Every 20 seconds, 30 seconds, I'm typing in, you know, Egypt, Cairo, uprising, revolution. I'm gathering sources. And as I'm gathering sources, another editor had started the article, which at the time was called \"2011 Protests In Egypt. \" ZOMORODI: Jake worked out of his parents' home in Philadelphia as part of a small team of Wikipedia editors. Based around the globe, they updated the page constantly, keeping tabs on the enormous flow of information and rumors coming out of Cairo. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED REPORTER #1: And people now are pouring into the square. ORLOWITZ: You have reports coming in from various news agencies. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED REPORTER #2: Taking you live to Cairo. ORLOWITZ: And someone needs to say, these sources are good sources. These sources are not good sources. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED REPORTER #3: They're battling for territory and also for political control. ORLOWITZ: Someone needs to say, this breaking news event has now been reported in enough papers that we can consider it dependable. There are sections that need to be added explaining the background causes. You're starting to get international reactions, and different heads of state are commenting. And all of this is being organized by four or five really core editors. It's me. It's a European who is really interested in politics. It's an Egyptian who's on the ground in Egypt. We're walking this fine line between rooting for the revolution and making sure the Wikipedia article does its job, which is to report neutrally. ZOMORODI: Maybe you've gotten a breaking news alert on your phone. It could be a massive revolution or a celebrity wardrobe malfunction. And you go to Wikipedia, and you find that it's already been updated with the latest details. It can feel like magic. But the over 6 million English language articles - from the Egyptian revolution to Bennifer - are almost all written, edited and fact-checked by a small army of volunteer editors who call themselves Wikipedians. ORLOWITZ: Writing a new article - it's a lot of fun because you get to shape what comes next. Wikipedians build in layers. And if you put down that first layer, that scaffolding, someone else will hopefully come by and put up a wall here or a window there. ZOMORODI: Ideally, copy editors and researchers come in and make that scaffolding stronger, supported by verified information. ORLOWITZ: Because at the core of Wikipedia's ethos is that you don't write your own knowledge. You're merely summarizing other good sources because if I don't do that, someone is likely to come by and say, I recommend this article be deleted. And then you have to have a debate about it for a whole week about whether or not the article can exist at all. ZOMORODI: All these layers and debates, the whole open-source ethos - Jake says that's why Wikipedia is different than other places online. ORLOWITZ: And I think that's what readers love because everywhere else you look when you're trying to get news, there's so much noise that comes with that. Jimmy Wales, the founder of Wikipedia, said that Wikipedia is like a temple for the mind. You go to a Wikipedia page, and you're not going to get bombarded by an ad. You're not going to have to see threads of comments. It's just quiet. And we don't have a lot of quiet digital spaces anymore. JIMMY WALES: You know, when most people first got on the internet, one of the first thoughts that people would have is, like, wow, this is amazing. Like, everyone in the world can communicate. And so I just thought, OK, why don't we just use the internet for that? We've got this great tool for sharing knowledge, so why don't we just share knowledge? ZOMORODI: This is Jimmy Wales. You could call him the original Wikipedian. He co-founded the website back in 2001. And even then, he had big ideas for the platform. WALES: The original vision for Wikipedia is to imagine a world in which every single person on the planet is given free access to the sum of all human knowledge. ZOMORODI: But to create a digital public space that could even begin to deliver on those ambitions, it required a set of founding values. Here's Jimmy Wales on the TED stage back in 2005. (SOUNDBITE OF TED TALK) WALES: So the biggest and the most important thing is our neutral point of view policy. This is something that I set down from the very beginning as a core principle of the community that's completely not debatable. It's a social concept of cooperation. So we don't talk a lot about truth and objectivity. Anytime there's a controversial issue, Wikipedia itself should not take a stand on the issue. We should merely report on what reputable parties have said about it. So this neutrality policy is really important for us because it empowers the community to come together and actually get some work done. By having this firm neutrality policy, which is non-negotiable from the beginning, we ensure that people can work together and that the entries don't become simply a war back and forth between the left and the right. If you engage in that type of behavior, you'll be asked to leave the community. (SOUNDBITE OF MUSIC) ZOMORODI: Jimmy, you have always emphasized the importance of neutrality. But, I mean, let's be honest, it's hard to build utopia, right? I mean, Wikipedia has gotten a fair amount of criticism over the years about who gets an entry and who doesn't. Representation continues to be a problem. Like, for example, there are very few entries about notable women, especially women of color, female scientists. And so therefore, what is on Wikipedia is not entirely neutral, no? WALES: Yeah. I mean, that is definitely exactly the heart of what we have to strive for. So we have groups like Women in Red who say, OK, we're going to look into, you know, where are there problems in the coverage of Wikipedia where we have incomplete coverage of people who should be here who are women. And I can say, having chatted with thousands of Wikipedians (ph) over the years, like, people first and foremost write about what they know about. They write about what they're interested in. And it turns out that a lot of what people are interested in, there is - that gender is reflected in that. So as a community, we need to bring in more people. We need to bring in a more diverse bunch of contributors. And then we can ask ourselves, OK, how can we make that happen? What are the barriers to making that happen? And this is a huge body of thinking and talking and working that we do within the community. ZOMORODI: You know, we actually talked to Eli Pariser about that earlier, that perhaps we need to design platforms to be welcoming, to be more civil. But also, you know, it makes me wonder, does it come back to the business model? Like, how much did making Wikipedia a nonprofit factor into it being a place where people wanted to share knowledge, not a place to chase clicks and to sell more ads? WALES: I would say one of the first things I would suggest is to move away from this, in my view, false dichotomy that you can either do something good for the public space or you can make a lot of money. You know, you can do something that's powerfully ethical, very interesting, makes money, but doesn't involve promoting conspiracy theories and nonsense and creating unhealthy spaces. You know, it's like the local pub or coffee shop. And they're there to make money, and they have a business. But it's also - in many cases, it's the heart of a community. And that's great. ZOMORODI: But that doesn't always happen with these profit-driven platforms. They are not just virtual coffee shops where people gather together benignly. A lot of the time, people end up in much darker, more profane places and getting bad information. WALES: I mean, it's really interesting because if you think about two places you can go where it's quite easy to get sucked in and spend hours and hours - so one is Wikipedia and then YouTube. But the difference is, at YouTube, the videos that are shown to you next tend to be videos that keep you on the site longer. ZOMORODI: Right. WALES: Oftentimes, something outrageous, something, you know, wrong is more likely to keep you on the site than otherwise. And so they promote that. At Wikipedia, there is no algorithm. Humans wrote at all. They link to things they think are interesting. They link to background information. And that just gives you a completely different and opposite result. It doesn't lead you down this unhealthy path to dark places. And I think that's interesting. And, you know, it's hard. It's hard for an advertising-based system to do that. And I think that difference is really what explains a lot that's going on on the internet. (SOUNDBITE OF MUSIC) ZOMORODI: As we wrap up, I just want to read you a quote that I understand a lot of Wikipedians like, or a phrase. Thank God our little enterprise works in practice because it could never work in theory. WALES: (Laughter). ZOMORODI: Do you abide by that? WALES: I don't. ZOMORODI: No (laughter)? WALES: I think it really is a system that's designed. I always compare it to a good municipal government. What do you want from a good municipal government? Well, you want to be able to criticize and complain about the administrators or, you know, the police or whatever without getting thrown in jail. So you don't want to be treated in an arbitrary fashion. But at the same time, you also want your children to be able to play in the park and not get accosted and attacked and so on. And so that balance between having rules, creating a safe environment while at the same time saying let's not be overcontrolling and so on, it's an art, and it's a bit messy, but it does work. ZOMORODI: Jimmy Wales is the co-founder of Wikipedia and a Wikimedia board member. You can see his talk at ted. com. Also, many thanks to Jake Orlowitz, founder of the Wikipedia Library, a project that helps Wikipedians find reliable sources.", "section": "TED Radio Hour", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-07-27-1020753541": {"title": "Instagram Debuts New Safety Settings For Teenagers : NPR", "url": "https://www.npr.org/2021/07/27/1020753541/instagram-debuts-new-safety-settings-for-teenagers", "author": "No author found", "published_date": "2021-07-27", "content": "", "section": "Technology", "disclaimer": ""}, "2021-07-27-1018393765": {"title": "Who Will Pay To Protect Tech Giants From Rising Seas?  : NPR", "url": "https://www.npr.org/2021/07/27/1018393765/sea-level-rise-silicon-valley", "author": "No author found", "published_date": "2021-07-27", "content": "", "section": "Climate", "disclaimer": ""}, "2021-07-28-1021904271": {"title": "The Robinhood IPO Is Here. But There Are Doubts About Its Future : NPR", "url": "https://www.npr.org/2021/07/28/1021904271/exploitative-or-revolutionary-questions-swirl-as-robinhood-makes-wall-street-deb", "author": "No author found", "published_date": "2021-07-28", "content": "STEVE INSKEEP, HOST:  Depending on who you ask, the stock trading app Robinhood has democratized Wall Street trading or captured nonsavvy investors who are hooked on making quick cash. Today, the company makes its debut on Nasdaq, just as regulators challenge its core business practices. Here's NPR's Bobby Allyn. BOBBY ALLYN, BYLINE: When college student Jacob Frueh opens up Robinhood, he sees neon-colored charts on how his stock is trading. He can invite a friend to the app and get a free stock. But right now he's curious about his Airbnb investment, so he takes a look. JACOB FRUEH: It's down 0. 53% today and is currently trading at $138. 51. ALLYN: Frueh is a business major at Northeastern University. But from the classroom, the world of finance was daunting. Robinhood broke down all the barriers. FRUEH: And it seemed like this just crazy career where you had to know so much, and Robinhood allowed me to begin trading without, you know, learning how to use a Bloomberg terminal. ALLYN: Robinhood has made trading stocks as easy as buying a credit on \"Candy Crush,\" so much so that Frueh is among the 22 million users who now trade stocks on the app. That's up from 7 million just last year. Here's Robinhood CEO Vlad Tenev speaking on Bloomberg. (SOUNDBITE OF ARCHIVED RECORDING)VLAD TENEV: Investing should be as ubiquitous as shopping online. It should just be something that people do. ALLYN: Robinhood has introduced droves of new people to the stock market. Tapping into online forums like Reddit at a time when everyone spent more time home, the company has assembled a new generation of mostly young, inexperienced investors who now have the power to move markets. But is Robinhood exploiting these people? Massachusetts Secretary of State William Galvin thinks so. He says Robinhood has gamified trading, and that's led to catastrophic losses for some. WILLIAM GALVIN: They deliberately go out to entice their customers and rely upon their lack of experience to entice them into buying things that they may not understand. ALLYN: Galvin's office is suing to have Robinhood banned in the state. Robinhood is also facing nearly 50 other lawsuits stemming from this moment. (SOUNDBITE OF MONTAGE)UNIDENTIFIED REPORTER #1: Reddit users have been driving Wall Street crazy, investing in certain stocks like GameStop to force up the price. UNIDENTIFIED REPORTER #2: Video game retailer GameStop is set to continue their head-spinning ascent today. Shares are now up more than 60% free market. UNIDENTIFIED REPORTER #3: The video game retailer has soared about 800% in the last week. ALLYN: And behind that surge were people tapping away at their Robinhood apps, some of them fueled by an internet joke or a way to stick it to the man. Well, it worked. It shocked Wall Street and created market turmoil. To slow down the rally, Robinhood restricted the ability to buy shares of GameStop. Critics said that hurt Robinhood users and benefited the Wall Street firms it does business with. SINAN ARAL: They earn a significant fraction of their revenue from being a middleman. ALLYN: Sinan Aral leads MIT's Initiative on the Digital Economy. He says when you buy a stock on Robinhood, it's sent to big institutions like Citadel Securities to actually complete the transaction, and Robinhood gets a kickback. Robinhood also sells its trading data about its users to these very same firms. ARAL: I think those conflicts of interest are real and should be scrutinized. ALLYN: Which is exactly what the Securities and Exchange Commission is doing. It could be an existential threat to Robinhood. But Robinhood hopes that investors see the probe as nothing more than a speed bump. In an unorthodox move, Robinhood is letting its users purchase up to a third of its stock. Will college student Frueh be opening up Robinhood to buy some Robinhood? FRUEH: I honestly have not decided quite yet. ALLYN: He says he loves the app, but he doesn't see it as the safest bet. Bobby Allyn, NPR News, San Francisco. (SOUNDBITE OF MARLEY CARROLL'S \"FIREFLIES\") STEVE INSKEEP, HOST:   Depending on who you ask, the stock trading app Robinhood has democratized Wall Street trading or captured nonsavvy investors who are hooked on making quick cash. Today, the company makes its debut on Nasdaq, just as regulators challenge its core business practices. Here's NPR's Bobby Allyn. BOBBY ALLYN, BYLINE: When college student Jacob Frueh opens up Robinhood, he sees neon-colored charts on how his stock is trading. He can invite a friend to the app and get a free stock. But right now he's curious about his Airbnb investment, so he takes a look. JACOB FRUEH: It's down 0. 53% today and is currently trading at $138. 51. ALLYN: Frueh is a business major at Northeastern University. But from the classroom, the world of finance was daunting. Robinhood broke down all the barriers. FRUEH: And it seemed like this just crazy career where you had to know so much, and Robinhood allowed me to begin trading without, you know, learning how to use a Bloomberg terminal. ALLYN: Robinhood has made trading stocks as easy as buying a credit on \"Candy Crush,\" so much so that Frueh is among the 22 million users who now trade stocks on the app. That's up from 7 million just last year. Here's Robinhood CEO Vlad Tenev speaking on Bloomberg. (SOUNDBITE OF ARCHIVED RECORDING) VLAD TENEV: Investing should be as ubiquitous as shopping online. It should just be something that people do. ALLYN: Robinhood has introduced droves of new people to the stock market. Tapping into online forums like Reddit at a time when everyone spent more time home, the company has assembled a new generation of mostly young, inexperienced investors who now have the power to move markets. But is Robinhood exploiting these people? Massachusetts Secretary of State William Galvin thinks so. He says Robinhood has gamified trading, and that's led to catastrophic losses for some. WILLIAM GALVIN: They deliberately go out to entice their customers and rely upon their lack of experience to entice them into buying things that they may not understand. ALLYN: Galvin's office is suing to have Robinhood banned in the state. Robinhood is also facing nearly 50 other lawsuits stemming from this moment. (SOUNDBITE OF MONTAGE) UNIDENTIFIED REPORTER #1: Reddit users have been driving Wall Street crazy, investing in certain stocks like GameStop to force up the price. UNIDENTIFIED REPORTER #2: Video game retailer GameStop is set to continue their head-spinning ascent today. Shares are now up more than 60% free market. UNIDENTIFIED REPORTER #3: The video game retailer has soared about 800% in the last week. ALLYN: And behind that surge were people tapping away at their Robinhood apps, some of them fueled by an internet joke or a way to stick it to the man. Well, it worked. It shocked Wall Street and created market turmoil. To slow down the rally, Robinhood restricted the ability to buy shares of GameStop. Critics said that hurt Robinhood users and benefited the Wall Street firms it does business with. SINAN ARAL: They earn a significant fraction of their revenue from being a middleman. ALLYN: Sinan Aral leads MIT's Initiative on the Digital Economy. He says when you buy a stock on Robinhood, it's sent to big institutions like Citadel Securities to actually complete the transaction, and Robinhood gets a kickback. Robinhood also sells its trading data about its users to these very same firms. ARAL: I think those conflicts of interest are real and should be scrutinized. ALLYN: Which is exactly what the Securities and Exchange Commission is doing. It could be an existential threat to Robinhood. But Robinhood hopes that investors see the probe as nothing more than a speed bump. In an unorthodox move, Robinhood is letting its users purchase up to a third of its stock. Will college student Frueh be opening up Robinhood to buy some Robinhood? FRUEH: I honestly have not decided quite yet. ALLYN: He says he loves the app, but he doesn't see it as the safest bet. Bobby Allyn, NPR News, San Francisco. (SOUNDBITE OF MARLEY CARROLL'S \"FIREFLIES\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-07-28-1021828155": {"title": "Activision Blizzard Workers Walk Out Following Harassment Suit : NPR", "url": "https://www.npr.org/2021/07/28/1021828155/activision-blizzard-workers-are-walking-out-after-the-studios-sexual-harassment-", "author": "No author found", "published_date": "2021-07-28", "content": "", "section": "Business", "disclaimer": ""}, "2021-07-28-1021798222": {"title": "Google And Facebook Mandate Vaccines For Employees At U.S. Offices  : NPR", "url": "https://www.npr.org/2021/07/28/1021798222/google-mandates-vaccines-for-workers-pushes-back-return-to-office-date", "author": "No author found", "published_date": "2021-07-28", "content": "", "section": "Technology", "disclaimer": ""}, "2021-07-28-1021742325": {"title": "Biden Aims To Boost Cybersecurity For Critical Infrastructure After Hacks : NPR", "url": "https://www.npr.org/2021/07/28/1021742325/biden-pushes-cybersecurity-upgrades-for-critical-infrastructure-after-recent-hac", "author": "No author found", "published_date": "2021-07-28", "content": "", "section": "Morning Edition Live Blog", "disclaimer": ""}, "2021-07-29-1022409865": {"title": "NSO Group Blocks Some Governments From Using Its Spyware Over Misuse Claims : NPR", "url": "https://www.npr.org/2021/07/29/1022409865/nso-suspended-govvernment-contracts-spyware-pegasus-project", "author": "No author found", "published_date": "2021-07-29", "content": "", "section": "Technology", "disclaimer": ""}, "2021-07-29-1022214491": {"title": "Leaks Reveal Spyware Meant To Track Criminals Targeted Activists Instead : NPR", "url": "https://www.npr.org/2021/07/29/1022214491/leaks-reveal-spyware-meant-to-track-criminals-targeted-activists-instead", "author": "No author found", "published_date": "2021-07-29", "content": "TERRY GROSS, HOST:  This is FRESH AIR. I'm Terry Gross. Your worst nightmare about how a smartphone can be hacked to spy on its owner became a reality for 37 people around the world whose phones were infected by spyware or whose phones had an attempted penetration. These people included journalists, activists, business executives and two women close to the murdered Saudi journalist Jamal Khashoggi. A forensic analysis revealed that the phones had been penetrated by military-grade spyware called Pegasus, which had been licensed to governments by the private Israeli security company NSO Group. The company says that the Pegasus spyware it sells to governments is intended to collect data from suspected criminals and terrorists. But apparently, the reality is that the spyware was widely misused. The human rights group Amnesty International and a Paris-based journalism nonprofit called Forbidden Stories shared the forensic analysis of these devices with a consortium of more than 80 reporters from media organizations around the world, including The Washington Post. My guest, Craig Timberg, was one of the two coordinators of the project at the Post and one of its lead reporters. He covers technology for the Post, specializing in privacy, security and surveillance. This year, he's also been reporting on QAnon and the forum TheDonald. win, whose chatter about how to come prepared with weapons and build a gallows at the Capitol on January 6 should've been sufficient warning to the FBI and police about what to expect. Craig Timberg, welcome back to FRESH AIR. I want to start by saying that the NSO Group refutes a lot of what The Washington Post has reported, and we'll get to those denials a little bit later. But first, let's talk a little bit about your reporting. What is this spyware that we're talking about - Pegasus - capable of doing? CRAIG TIMBERG: Pegasus can do anything on your smartphone that you can do. It can read all of your communications. It can see where you've been in the world. It can see who you've called. It can see your social media posts. It can grab your passwords and usernames and grab all of your contacts. And in a particularly creepy twist, it can flip on your microphone and your camera without you knowing it and start recording what you're saying and take images of what you're doing. GROSS: Yeah, I want to refer to two of the people quoted in the article. One is a journalist who said it's a tool that destroys the essential codes of civilization. It comes to your office, your home, your bed, every corner of your existence. This is from a dissident journalist who was targeted. And another journalist who was targeted talked about how really disturbing it was to know that this device could've been listening or shooting video every time this person went to a bathroom, no matter where the bathroom was. TIMBERG: It takes a story like this to help people understand how deeply enmeshed these tiny, little computers have gotten into our - in our lives, right? I mean, I cover surveillance and privacy and have been reporting on this for pretty close to a decade. I still carry my iPhone everywhere I go, right? It's in the room with me. It's - you know, I have a thousand different conversations on it any given day. And the reality of that is that every time I do that, I'm exposing not just myself, but everyone I deal with to the possibility of spying, you know, by governments all over the world. GROSS: Now, I mentioned 37 people who were targeted, but you also had a list of 50,000 people or phones. What is that list of 50,000? TIMBERG: The list of 50,000, you know, includes some verified surveillance targets. And unfortunately, I have to be careful here about how I depict exactly what all is on there. But you think about it as kind of was the soup bones of the project in that we had this huge number of phone numbers, and we didn't at first know who they belonged to, and we didn't know exactly what we would find when we started running around the world and asking people to turn over their iPhones to us to be analyzed. So, you know, it would be nice to know who every single person on that list was, but even with the extraordinary resources of this project, we just couldn't get through a number that large. What I can tell you is that when we dug in, we found lots of evidence of interesting things that really gave us insight into the way governments use spyware that we just have never had before. GROSS: Can you be more specific about that? TIMBERG: It's worth understanding that NSO Group has a lot of customers, and they're not all the same. And to be clear, as the company has pointed out to us in a hundred different ways and a hundred different times, like, they don't run this system. What they do is they license this system to, you know, intelligence agencies and police departments in 40 different countries around the world. And it's clear that in some of them, there just aren't meaningful guardrails against abuse of this technology. I just described how powerful it was, right? They're in your device. They can do what you can do and probably some things you don't know how to do on your smartphone or your Android device. And it's clear that in at least some of these countries, this very powerful tool is used to pry into the lives of all sorts of people who never should've been the targets of a government intelligence or law enforcement agency - you know, as you've mentioned, journalists, human rights activists, lawyers, academics, businesspeople. It's clear that on some level, the use of this technology in some countries went way beyond the bounds of what it's supposed to be used for. GROSS: Did you recognize any of the names on the list of 37? TIMBERG: On the list of 37, these were largely but not exclusively journalists, and they were based predominantly in other countries. So, no, I didn't know them upfront. But interestingly, I knew some of them by the time it came to write the stories 'cause in some cases, it was reporters working on this very project. So just imagine you're a journalist from India or Hungary. You're in a country that you know there's a pretty high degree of surveillance going on. You start working on this project that has all these phone numbers and all of - you know, all this effort to sort of figure out who might be on this list, and your own number pops up. And then you turn over your device to some technician who, you know, downloads the data and discovers that not only were you infected by Pegasus, but, I mean, you might've been infected for months, in some cases years, which means every single conversation you've had, every email, every time you've tweeted or done something that you thought was private, like chatting on encrypted channels like Signal, every single one of those things now is in the hands of some government official who you probably will never meet. GROSS: And everyone you know might be endangered as a result. TIMBERG: Exactly. I mean, people are endangered, but it's worth being careful with the vocabulary here. And we spent a lot of time at the Post and, you know, with our partner organizations trying to get the language right. I mean, being infected by Pegasus is not like, you know, being shot by a gun or taken out by a drone strike or anything like that. What this is is spying. It's extremely sophisticated spying. And, you know, another kind of language issue we ran into - a lot of people want to call this bugging or wiretapping. And we all have this understanding, mainly based on police shows, of, you know, guys in white vans clipping alligator clips onto telephone wires and listening to a call. I mean, the - you know, the brilliant show \"The Wire\" is sort of all built around this concept that police in certain circumstances can listen into the conversations - in that case, drug dealers. But this kind of technology is like a thousand times more intrusive because it can get all of this retrospective information of what you said and where you've been and who you've said it to and where you said it. And that completeness of information and granularity of information is something that, A, never existed before smartphones became so prominent. And secondly, the laws around this are poorly constructed and poorly enforced in most parts of the world. And so that means that if you're living in a country whose government hasn't built guardrails, and very few have built guardrails, it's really open season with this stuff. It's just - it's simple. It's easy. It's incredibly powerful. GROSS: Is this why you write that critics say that the widespread use of this spyware has emerged as a leading threat to democracies around the world? TIMBERG: Exactly. To use the example of someone like me, you know, when I was overseas, I was based in Johannesburg. I used to go in and out of Zimbabwe, you know, all the time. It was at that point the country was closed to foreign correspondents. There was all of this repression and sometimes violence happening. If every time I went in there, every single conversation I had with an opposition politician or a rights group or even an ordinary citizen who I may be interviewing, you know, in their home - if all those were available to the Zimbabwean government - and for the record, I have no reason to believe at that time that was the case. But imagine both the real impact on those people, but also the impact on me attempting to gather news 'cause I can tell you, when you're a working journalist, you worry a little about yourself, but what you really worry about are the people you're interviewing because they are almost in every case much more vulnerable to being jailed, being investigated, being beaten. In Zimbabwe, people's homes would be burned out, all that kind of thing, after journalists interviewed them. So, you know, if you have to live in fear that the tool that you use to communicate with your subjects is actually, you know, a sort of a pipeline back to the authorities, that's incredibly chilling. But beyond that, you know, if you're a human rights investigator and you're looking into abuses in a community, it's hard to get people to talk. It's hard to get people to share their stories. And some degree of protection of anonymity is essential to that. Again, you - let's say you work for Human Rights Watch. You go into a community, you think your phone is turned into a spying device, how do you do your work? And the next level would be, what if you're a politician who's not in power or, as we found in some cases, a politician who is in power but maybe isn't the actual president of that country? Having these computers spying on us all the time makes it incredibly hard for this whole group of people to do their jobs within a democracy. That means criticizing the ruling power. That means exposing abuses. That means simple newsgathering or even just going about your life. GROSS: Well, let me reintroduce you here. If you're just joining us, my guest is Craig Timberg, a national reporter covering technology for The Washington Post. We'll talk more after we take a short break. This is FRESH AIR. (SOUNDBITE OF ALEXANDRE DESPLAT'S \"SPY MEETING\")GROSS: This is FRESH AIR. Let's get back to my interview with Washington Post reporter Craig Timberg. He's been investigating how a private Israeli cybersecurity company called NSO Group licensed military-grade spyware called Pegasus to governments that were supposed to use it only for tracking terrorists and criminals, but some of those governments used it to hack the phones of journalists, human rights activists, business executives and others. What if you turn off your phone? TIMBERG: So people take all sorts of measures to protect themselves from, you know, the knowledge that your iPhone or your Android device can be turned against you. You know, you can turn off your phone. You can put it in the microwave and, like, walk outside. And people do that. The United States doesn't really have the same kind of problem with this a lot of other countries do. The NSO Group in particular says, oh, no, no. No device in the U. S. can possibly be targeted. No device with a U. S. country code can be targeted. And that may be true. We don't really know. But I can tell you that there are a lot of spyware companies. So, you know, one company's rules are not necessarily another company's rules. But additionally, let's say you've, you know, put your phone in your freezer and you meet with your other opposition folks, and then you come back and you take your phone out of the freezer and, assuming it's not an ice block at that point, you resume using it. You still are having all this incidental contact. Your device is still logging where you are. It's logging what you're saying in encrypted chats. It's capable of mapping out essentially every relationship in your life. And you could be careful. And I'm careful. Like, I - and I was particularly careful over the last few months to be as safe as I could be. You know, I turned off certain things on my device. I locked down all this stuff. The reality is that I caught myself slipping all the time. It's just - it's extremely hard to navigate your life in 2021 without one of these devices helping you navigate it while, at the same time, tracking you as well. GROSS: But just technologically, if you turn off your phone, can you still be spied on through your phone? TIMBERG: Probably. You know, you all probably recall the days when you could, like, pop your battery out of your device. And this was my era when I was a foreign correspondent. You know, I'd go into Zimbabwe, and people would pop their phones out and put them away, and they felt safer, and they were safer. I can't get into my iPhone and remove that battery. I don't think that - I don't think the modern smartphone really is ever all the way off. And so I don't know enough about the coding in Pegasus to say that they can turn your phone on, but I would not be surprised at all if there was spyware that was capable of activating things on your device even when it's off - or when you think of it as off, meaning the screen's blank and it is acting like, you know, a paperweight as opposed to a computer, 'cause these things, on some level, are always on. GROSS: Tell us about the company that sold this spyware, NSO Group. What do you know about them? TIMBERG: This is a group that was started by some Israeli friends who were, you know, were trying to make it in the world of internet startups in Israel, which is quite a robust world. But they also had backgrounds, you know, in cybersecurity. And they started this company because they were approached by authorities who - in Israel who, you know, helped them understand that if they could use their technological chops in the right way, that they could help the government do things that were important to it. And to be fair to NSO, a lot of what they do is important. I mean, and I hope that no one who reads our articles discounts the importance of, for example, tracking pedophiles and drug lords and terrorists. I think we all agree that the people in charge of combating those evils have resources at their disposal to allow them to do it. GROSS: So do any of the people in NSO Group have experience with Israeli military intelligence? TIMBERG: The NSO Group, like similar companies around the world, is heavily staffed by former spies. And this is true for a lot of cybersecurity companies in the United States. You get through the NSA, and you're ready to leave or retire, and there's lots of opportunities for people who have this kind of skill set, people who know how to build software that hacks into things. And so this whole world - and this is true at the NSO Group, as well - is full of these former military spies who did this work, you know, for their governments for many years. GROSS: Craig, the NSO has been in touch with you, the company that leases this spyware, with many objections to your reporting, and this has been an ongoing process for you and the other reporters at the Post covering this story. What have their objections been, and how has that affected what you've reported? TIMBERG: It's been interesting to watch this process play out because in terms of communication with the company, I feel like this was a prepublication phase where, you know, they hired a lawyer, a defamation lawyer in Virginia, and sent aggressive letters to all of us, essentially threatening to sue the Post and its partners and put us on watch, you know, to essentially, you know, make sure we got everything right, which we're supposed to anyway. But it does focus the mind when you get letters like that. But in the prepublication phase, NSO Group really disputed almost every claim that we made. And they claimed that our forensics didn't work. They claimed that our reporting was just full of, you know, scurrilous lies and exaggerations. They in particular challenged and continue to challenge the idea that the list of 50,000 phone numbers is in any way affiliated with their company. But the tone began to be different as our stories started getting published around the world. And, you know, a few hours after the first batch of stories ran - you know, about 10, 11 days ago - I got a call from Shalev Hulio, the chief executive of NSO Group, and he wanted to make sure that I knew that - and that we knew - that he still thought our reporting was wrong in five different ways. But he did make a real point of saying, you know, I need to tell you that some of the stuff I've read about journalists and human rights activists really bothers me, and we're going to look into it. We're going to investigate. And he said, you know, if we investigate, you know, there's a chance we'll find some problems. We've found problems in the past. We've terminated contracts in the past with countries that are problematic, and we're prepared to do that again. Now, that process is ongoing, but the company has shown a willingness to engage with us on the matters we've been raising. And, you know, who knows what that investigation should look like, but it was clear that he was troubled by some of what he had read. GROSS: What are their objections to what you actually published 'cause I want to represent them in the story, too? TIMBERG: NSO Group has several kinds of objections. They believe that it's impossible that so many people were potentially surveilled. They argue that - you know, when it comes right down to it, they're kind of making a bad apples argument. In their view, they're doing all of these wonderful things to target, you know, drug lords and pedophiles. And in their view, what we're unearthing - either we've got it wrong, which they say in some cases, or what we're looking at are really extreme kind of misuse cases that don't really shed that much light on the larger - what the company mainly does, which in their minds is fight terrorists and criminals. So, you know, they've objected strongly in a number of cases. At the same time, though, they also share some revealing facts about their ability to monitor this. And in a way, this goes to the heart of the problem. You know, NSO Group provides a service. Government agencies buy that service or license that service. And then once these systems are installed in - you know, in some secret police, you know, headquarters in some capital in some part of the world, NSO Group doesn't run it anymore - at least that's what they tell us. You know, the operators of the systems, you know, basically do what they want, and if they're caught doing something problematic, they might indeed get their contract pulled. At the same time, there's no real mechanism to catch anybody. You know, we're talking about operators in a room entering phone numbers, gathering data, but no one's watching them - no one from the company, no one from the U. N. , no one with any kind of independent authority to say, oh, no, no, there you went over the line. These hundred queries are fine, but these 20 queries are not fine. There's no real mechanism that would catch abuses as they were happening. GROSS: I think it's time for another break, so let me reintroduce you. My guest is Washington Post national technology reporter Craig Timberg. We'll talk more about spyware after we take a short break. I'm Terry Gross, and this is FRESH AIR. (SOUNDBITE OF MUSIC)GROSS: This is FRESH AIR. I'm Terry Gross. Let's get back to my interview with Craig Timberg. He covers technology for The Washington Post and specializes in privacy, security and surveillance. He's been investigating how the private Israeli spyware company called NSO Group licensed military-grade spyware called Pegasus to governments that were supposed to use it only for tracking terrorists and criminals. But some governments used it to hack the phones of journalists, human rights activists, business executives and others. So what is the relationship between the Israeli government and Israeli private companies that do espionage and that sell or lease spyware? TIMBERG: I think we don't really know. A couple of my colleagues looked very carefully at this question about, you know, whether the Israeli government has some sort of access to the data that NSO clients collect. The company says, absolutely, positively not. The U. S. intelligence community and their partners in other parts of the world certainly believe that the Israelis have some sort of access to the data that NSO Group collects. Whether that's periodic or episodic or whatever, we don't know. But it is generally the case that troves of valuable information that are sitting, you know, to be collected tend to get collected fairly often. These intelligence agencies are very sophisticated. Their jobs are serious. And so there's certainly persistent suspicions that some of the data that's collected ends up in the hands of the Israeli government and maybe other governments in the world, too. GROSS: Does the Israeli government have to give approval before a private Israeli company can license spyware to another government? TIMBERG: Yes. Israel, like the United States and a number of countries, has what's called export controls. And so when it comes to something like this - it is military-grade spyware - it does have to be approved by the government of Israel. And we're told that, you know, if there are abuses, if there are countries that the government views as particularly problematic customers that they can't sell to those places. And I just want to emphasize again here that this isn't just one company. And it's not just Israel. There's other governments around the world that are more lax in their controls. And so even if the Israelis are doing this perfectly, that doesn't mean that people's iPhones aren't getting hacked. GROSS: So are there any national or international laws preventing private companies or governments from misusing spyware? TIMBERG: Lots of governments have laws on the books about wiretapping and require court approval. You know, I'm not an expert on all of them. But I would be willing to guess that almost all of them need updating for the smartphone world and the kinds of surveillance that's happening now. You've seen our U. S. Supreme Court, you know, try to make sense of the ways that these devices collect data and the ways that authorities are allowed to get that data. Something like that needs to happen, probably, in every country in the world. And probably, it needs to be sped up here as well. In terms of international controls, I don't know of anything meaningful that limits this trade. This is a common problem throughout history, right? A new technology, you know, is thrilling. And then we realize we have all these problems. And then it takes a while for societies and governments to really wrestle with these problems or bring these under control. I think we're, like, at Step 2 of that, right? The purpose of this project was to help the world understand how widely this stuff is used, how invasive it is. And we're hoping that, now, there's more meaningful and informed conversation about what can be done to bring it under control and so that it is really used for the purposes it's designed for. GROSS: So you, The Washington Post reporters and the larger consortium of journalists investigating this story, along with Amnesty International, were able to identify 37 people whose phones were targeted through this spyware that we've been talking about. Do you know who targeted them, like, which governments, agencies or police units were behind it? TIMBERG: We don't actually know for sure in any of these cases. We obviously have very strong suspicions. You know, what we had were phone numbers. And from these phone numbers, we were able to identify devices that could then be checked forensically for evidence of infection. But it was an unbelievably painstaking and laborious process to get there. And, you know - and these - you know, you can tell where a victim is by their country code. But, you know, it's not like the list had little flags on it to tell us that a particular government was the one that did the - you know, selected people for surveillance in this way. You know, you look at the data. And certain - you know, obviously, certain things come out and suggest themselves. But we weren't able to get to a point where we were 100% confident - really, in any of the cases - who the surveillor was. GROSS: So without getting too technical, what have you learned about how this spyware penetrates through a phone's defenses? TIMBERG: The most alarming thing about this thing we've learned is that you can be infected without having any idea that anything unusual has happened. GROSS: So you don't even have to, like, click on anything? TIMBERG: Yeah. Exactly. You know, we've all learned over the past decade that, you know, if you get an email from someone saying they're a Nigerian prince and they've left a bunch of gold bullion in your airplane that maybe you don't want to click on that link. Like, that's a cultural learning we've all absorbed. But this kind of spyware is so sophisticated, they can send it to your device in a variety of ways. And you don't even know that you've gotten an unusual communication. In some cases, this comes through iMessage. There was a time when it was - this stuff was coming in through WhatsApp. And then once - you know, once it's sort of had its purchase on your device, you know, nothing happens on your screen. You don't get a little ding. You don't get a little skull and crossbones or anything like that. It's just inside your device, and it's taking over. One of the most startling findings was when we looked at timestamps on the phone list and we looked at forensic records on devices we had - you know, people had shared with us, some cases, you know, the timestamp on the list and the forensic records in the device, you know, just a few seconds had passed. You know, someone had entered a number. And, you know, 14 seconds later, there are these malicious processes happening on someone's iPhone, as Pegasus, you know, is cracking open the device. It's very fast. It's very - and it is invisible. And it's impossible for almost anyone to detect. GROSS: So who needs to worry about having their phone penetrated? Do Americans need to worry about this? Do our listeners need to worry about this? TIMBERG: This is a slightly complicated answer. I mean, NSO Group says very persistently and in court that Americans' phones can't be surveilled using their technology. And so that means if you've got a, you know, +1 country code, whatever area code you are in the U. S. , that you're fine. It also means that if you're a foreigner and you're in the United States, that - you know, that Pegasus supposedly doesn't work. There's a couple of clear problems with efforts to reassure your listeners. One of them is there are other companies that do this, right? So even if the NSO Group has been completely, completely honest and Americans' phones can't be surveilled, it doesn't mean that some other company isn't doing it. Secondly, you know, lots of us travel. You know, when I used to travel around Africa, I would get a SIM card in every country. I would get a phone number. We found lots of journalists and aid workers and diplomats, including American diplomats in other countries, who were using local phones, right? You're based in Bahrain. You don't want every call to go through your Verizon phone number in New York. So you pick up a Bahraini SIM card. At that moment, you know, your nationality is invisible to this technology, right? There's no way to know. Even if you're the secret police and you're operating this Pegasus system, there's no way to know that plus-whatever-whatever in Azerbaijan or India, you know, is a U. S. citizen. So the devices have no nationality. And so while there is some protection for Americans, it's very far from perfect protection. GROSS: Let's take another break here. If you're just joining us, my guest is Craig Timberg, a national reporter covering technology for The Washington Post. We'll talk more about spyware after a break. This is FRESH AIR. (SOUNDBITE OF MUSIC)GROSS: This is FRESH AIR. Let's get back to my interview with Washington Post reporter Craig Timberg. He's been investigating how a private Israeli company called NSO Group licensed military-grade spyware called Pegasus to governments that were supposed to use it only for tracking terrorists and criminals. But some governments used it to hack the phones of journalists, human rights activists, business executives and others. I'm going to change directions a little bit and get to an earlier article you wrote that's seeming very relevant right now. On Tuesday, we heard Capitol Police officers give just incredibly upsetting testimony about what they experienced and how they were attacked on January 6. And you wrote an article about an online forum called thedonald. win that - judging from what you quoted, this forum basically had chats about just about everything that we saw happen in that violent mob. Do you want to talk a little bit about what you found on that forum? TIMBERG: Yeah. This was just startling and troubling stuff. I mean, I've spent most of the last few years of my life looking at troubling stuff on internet forums, and I'm kind of hard to shock at a certain point. But, man, the openness of the conversation around bringing weapons to D. C. , about zip tying the hands of a member of Congress, about shooting or hanging them was - it was really upsetting, frankly. And it was really out in the open. You know, I got a call from a researcher a few days before the January 6 mob attack on the Capitol, and he said to me, you really need to see this stuff. Like, you need to write about this right now. And so I, you know, teamed up with a colleague of mine. And we found, you know, 48 hours out, signs of everything that then came to pass. And then when it all happened on January 6, it was couple of days after. We found even more stuff as more researchers surfaced all these things. And these weren't unencrypted chats. You know, these weren't in, you know, dark rooms or whatever. These were happening on the internet in a place that anyone who knew where to look could find it. And it absolutely foreshadowed the events of that day. Maybe we didn't know exactly what was going to happen. But I can tell you we started that day with a very bad feeling. GROSS: Let me mention a couple of other things that you reported about what was said on this forum, thedonald. win. There was a debate over whether they should build a guillotine or gallows, and it finally got resolved in favor of gallows, which commenters estimated could be built cheaply for just about $200. And it was actually - there was actually a gallows on the National Mall, you know, to hang - well, the chant was, hang Mike Pence. But, you know, who knows what exactly would have happened with those gallows? There's diagrams that were shared on the site of tunnel systems beneath the Capitol complex and then speculation about how pushing the mob from behind could end in a wall of death that would force police officers to abandon their positions. There was advice on how to attack Capitol Police with flagpoles. Check - that was done. It so predicted what happened. That seemed so shocking at the time. And does it make you wonder, like, why weren't the police and the Capitol Police more prepared? What went wrong? TIMBERG: It certainly - I mean, I was wondering exactly that. GROSS: I mean, everybody's wondering that. But you've got these specific details. TIMBERG: That stuff was just so chilling to read in the days before and in the immediate aftermath - just how much of that was, as you say, foreshadowed by things that were said on thedonald. win and some other forums. I thought a lot about this question of how they could have been so unprepared. And I think the answer is probably multilayered. But it's clear that the people who were making decisions at the time didn't want the same sort of optics around, you know, this particular - what at that point looked like was just a protest that they had around, you know, some of the Black Lives Matter protests in Washington, D. C. , and elsewhere over the summer. There was this real sensitivity about, you know, the clashes with police and, you know, National Guardsmen, you know, patrolling the streets of the nation's capital. And they didn't want - that's not the image they wanted to project of themselves of Washington, D. C. , to the world. And it is certainly clear that they were woefully underprepared for what happened. And we know that some authorities, you know, had noticed the same issues that we had noticed and were writing about. But it's - at the same time, the decision-makers clearly didn't take it seriously enough. And this is a persistent problem I've noticed. In the issues I've covered - you know, I cover technology. But I oftentimes joke that I cover technology behaving badly. And, you know, there's just so many things on the Internet that you can kind of keep yourself in a perpetual state of alarm. It's hard to know exactly when to - when a threat has become real enough to kind of leap the bounds and end up in the real world. But I can tell you, this is one that, from the very beginning, looked like - it looked like violence was very possible, if not probable. But I can also understand how - you know, how easy it is to discount stuff that just appears to be only on the Internet. You know, I think you need to live something like January 6 to kind of understand that these two parts of our world that we think of as separate - the online and the offline - actually are - they're more than merely connected. They interact with each other all the time. And they are often kind of part of a seamless whole. GROSS: What is it like for you to live in this really dark space, because you're reporting so frequently on things related to technology that become nightmares? TIMBERG: You know, we have bad days. Everyone I know who has covered this stuff has been, you know, personally threatened at least somewhat, some people much more seriously than I have been. And there's just this kind of, like, gazing into the sewer of humanity quality about the work sometimes. I did some stories a couple of years ago about, you know, YouTube channels that were pushing the idea that Hillary Clinton was, you know, raping and eating children. You know, I can say that. But, man, reading that kind of stuff again and again, these sort of images that get thrown up, it's not fun. I mean, you do really want to look away. And at the same time, you know, if we don't look at it and don't at least write about it, how does the world know that it's a real thing and that it's a serious thing? This goes back to the January 6 problem that I mentioned a minute ago. Like, people don't want to believe this bad stuff that's on the Internet really is part of, you know, the worlds they live in every day as they go about their lives and work and shop and go to little league games and all that stuff. But it's there. It's there. And, you know, we need to take it seriously. We need to look at it with unblinkered eyes and try to make good decisions about how to deal with it. And that is - I do think that's what - one of the things that failed on January 6 is people didn't really, really in their hearts believe that things could get as bad as they did. GROSS: Well, Craig Timberg, thank you so much for your reporting. Thank you for being with us on FRESH AIR. TIMBERG: It's been my pleasure. Thanks for having me. GROSS: Craig Timberg is a national technology reporter for The Washington Post. After we take a short break, Justin Chang will review the new film \"The Green Knight,\" adapted from a legend about a young adventurer from King Arthur's court. This is FRESH AIR. (SOUNDBITE OF DAVID NEWMAN AND RAY CHARLES' \"HARD TIMES\") TERRY GROSS, HOST:   This is FRESH AIR. I'm Terry Gross. Your worst nightmare about how a smartphone can be hacked to spy on its owner became a reality for 37 people around the world whose phones were infected by spyware or whose phones had an attempted penetration. These people included journalists, activists, business executives and two women close to the murdered Saudi journalist Jamal Khashoggi. A forensic analysis revealed that the phones had been penetrated by military-grade spyware called Pegasus, which had been licensed to governments by the private Israeli security company NSO Group. The company says that the Pegasus spyware it sells to governments is intended to collect data from suspected criminals and terrorists. But apparently, the reality is that the spyware was widely misused. The human rights group Amnesty International and a Paris-based journalism nonprofit called Forbidden Stories shared the forensic analysis of these devices with a consortium of more than 80 reporters from media organizations around the world, including The Washington Post. My guest, Craig Timberg, was one of the two coordinators of the project at the Post and one of its lead reporters. He covers technology for the Post, specializing in privacy, security and surveillance. This year, he's also been reporting on QAnon and the forum TheDonald. win, whose chatter about how to come prepared with weapons and build a gallows at the Capitol on January 6 should've been sufficient warning to the FBI and police about what to expect. Craig Timberg, welcome back to FRESH AIR. I want to start by saying that the NSO Group refutes a lot of what The Washington Post has reported, and we'll get to those denials a little bit later. But first, let's talk a little bit about your reporting. What is this spyware that we're talking about - Pegasus - capable of doing? CRAIG TIMBERG: Pegasus can do anything on your smartphone that you can do. It can read all of your communications. It can see where you've been in the world. It can see who you've called. It can see your social media posts. It can grab your passwords and usernames and grab all of your contacts. And in a particularly creepy twist, it can flip on your microphone and your camera without you knowing it and start recording what you're saying and take images of what you're doing. GROSS: Yeah, I want to refer to two of the people quoted in the article. One is a journalist who said it's a tool that destroys the essential codes of civilization. It comes to your office, your home, your bed, every corner of your existence. This is from a dissident journalist who was targeted. And another journalist who was targeted talked about how really disturbing it was to know that this device could've been listening or shooting video every time this person went to a bathroom, no matter where the bathroom was. TIMBERG: It takes a story like this to help people understand how deeply enmeshed these tiny, little computers have gotten into our - in our lives, right? I mean, I cover surveillance and privacy and have been reporting on this for pretty close to a decade. I still carry my iPhone everywhere I go, right? It's in the room with me. It's - you know, I have a thousand different conversations on it any given day. And the reality of that is that every time I do that, I'm exposing not just myself, but everyone I deal with to the possibility of spying, you know, by governments all over the world. GROSS: Now, I mentioned 37 people who were targeted, but you also had a list of 50,000 people or phones. What is that list of 50,000? TIMBERG: The list of 50,000, you know, includes some verified surveillance targets. And unfortunately, I have to be careful here about how I depict exactly what all is on there. But you think about it as kind of was the soup bones of the project in that we had this huge number of phone numbers, and we didn't at first know who they belonged to, and we didn't know exactly what we would find when we started running around the world and asking people to turn over their iPhones to us to be analyzed. So, you know, it would be nice to know who every single person on that list was, but even with the extraordinary resources of this project, we just couldn't get through a number that large. What I can tell you is that when we dug in, we found lots of evidence of interesting things that really gave us insight into the way governments use spyware that we just have never had before. GROSS: Can you be more specific about that? TIMBERG: It's worth understanding that NSO Group has a lot of customers, and they're not all the same. And to be clear, as the company has pointed out to us in a hundred different ways and a hundred different times, like, they don't run this system. What they do is they license this system to, you know, intelligence agencies and police departments in 40 different countries around the world. And it's clear that in some of them, there just aren't meaningful guardrails against abuse of this technology. I just described how powerful it was, right? They're in your device. They can do what you can do and probably some things you don't know how to do on your smartphone or your Android device. And it's clear that in at least some of these countries, this very powerful tool is used to pry into the lives of all sorts of people who never should've been the targets of a government intelligence or law enforcement agency - you know, as you've mentioned, journalists, human rights activists, lawyers, academics, businesspeople. It's clear that on some level, the use of this technology in some countries went way beyond the bounds of what it's supposed to be used for. GROSS: Did you recognize any of the names on the list of 37? TIMBERG: On the list of 37, these were largely but not exclusively journalists, and they were based predominantly in other countries. So, no, I didn't know them upfront. But interestingly, I knew some of them by the time it came to write the stories 'cause in some cases, it was reporters working on this very project. So just imagine you're a journalist from India or Hungary. You're in a country that you know there's a pretty high degree of surveillance going on. You start working on this project that has all these phone numbers and all of - you know, all this effort to sort of figure out who might be on this list, and your own number pops up. And then you turn over your device to some technician who, you know, downloads the data and discovers that not only were you infected by Pegasus, but, I mean, you might've been infected for months, in some cases years, which means every single conversation you've had, every email, every time you've tweeted or done something that you thought was private, like chatting on encrypted channels like Signal, every single one of those things now is in the hands of some government official who you probably will never meet. GROSS: And everyone you know might be endangered as a result. TIMBERG: Exactly. I mean, people are endangered, but it's worth being careful with the vocabulary here. And we spent a lot of time at the Post and, you know, with our partner organizations trying to get the language right. I mean, being infected by Pegasus is not like, you know, being shot by a gun or taken out by a drone strike or anything like that. What this is is spying. It's extremely sophisticated spying. And, you know, another kind of language issue we ran into - a lot of people want to call this bugging or wiretapping. And we all have this understanding, mainly based on police shows, of, you know, guys in white vans clipping alligator clips onto telephone wires and listening to a call. I mean, the - you know, the brilliant show \"The Wire\" is sort of all built around this concept that police in certain circumstances can listen into the conversations - in that case, drug dealers. But this kind of technology is like a thousand times more intrusive because it can get all of this retrospective information of what you said and where you've been and who you've said it to and where you said it. And that completeness of information and granularity of information is something that, A, never existed before smartphones became so prominent. And secondly, the laws around this are poorly constructed and poorly enforced in most parts of the world. And so that means that if you're living in a country whose government hasn't built guardrails, and very few have built guardrails, it's really open season with this stuff. It's just - it's simple. It's easy. It's incredibly powerful. GROSS: Is this why you write that critics say that the widespread use of this spyware has emerged as a leading threat to democracies around the world? TIMBERG: Exactly. To use the example of someone like me, you know, when I was overseas, I was based in Johannesburg. I used to go in and out of Zimbabwe, you know, all the time. It was at that point the country was closed to foreign correspondents. There was all of this repression and sometimes violence happening. If every time I went in there, every single conversation I had with an opposition politician or a rights group or even an ordinary citizen who I may be interviewing, you know, in their home - if all those were available to the Zimbabwean government - and for the record, I have no reason to believe at that time that was the case. But imagine both the real impact on those people, but also the impact on me attempting to gather news 'cause I can tell you, when you're a working journalist, you worry a little about yourself, but what you really worry about are the people you're interviewing because they are almost in every case much more vulnerable to being jailed, being investigated, being beaten. In Zimbabwe, people's homes would be burned out, all that kind of thing, after journalists interviewed them. So, you know, if you have to live in fear that the tool that you use to communicate with your subjects is actually, you know, a sort of a pipeline back to the authorities, that's incredibly chilling. But beyond that, you know, if you're a human rights investigator and you're looking into abuses in a community, it's hard to get people to talk. It's hard to get people to share their stories. And some degree of protection of anonymity is essential to that. Again, you - let's say you work for Human Rights Watch. You go into a community, you think your phone is turned into a spying device, how do you do your work? And the next level would be, what if you're a politician who's not in power or, as we found in some cases, a politician who is in power but maybe isn't the actual president of that country? Having these computers spying on us all the time makes it incredibly hard for this whole group of people to do their jobs within a democracy. That means criticizing the ruling power. That means exposing abuses. That means simple newsgathering or even just going about your life. GROSS: Well, let me reintroduce you here. If you're just joining us, my guest is Craig Timberg, a national reporter covering technology for The Washington Post. We'll talk more after we take a short break. This is FRESH AIR. (SOUNDBITE OF ALEXANDRE DESPLAT'S \"SPY MEETING\") GROSS: This is FRESH AIR. Let's get back to my interview with Washington Post reporter Craig Timberg. He's been investigating how a private Israeli cybersecurity company called NSO Group licensed military-grade spyware called Pegasus to governments that were supposed to use it only for tracking terrorists and criminals, but some of those governments used it to hack the phones of journalists, human rights activists, business executives and others. What if you turn off your phone? TIMBERG: So people take all sorts of measures to protect themselves from, you know, the knowledge that your iPhone or your Android device can be turned against you. You know, you can turn off your phone. You can put it in the microwave and, like, walk outside. And people do that. The United States doesn't really have the same kind of problem with this a lot of other countries do. The NSO Group in particular says, oh, no, no. No device in the U. S. can possibly be targeted. No device with a U. S. country code can be targeted. And that may be true. We don't really know. But I can tell you that there are a lot of spyware companies. So, you know, one company's rules are not necessarily another company's rules. But additionally, let's say you've, you know, put your phone in your freezer and you meet with your other opposition folks, and then you come back and you take your phone out of the freezer and, assuming it's not an ice block at that point, you resume using it. You still are having all this incidental contact. Your device is still logging where you are. It's logging what you're saying in encrypted chats. It's capable of mapping out essentially every relationship in your life. And you could be careful. And I'm careful. Like, I - and I was particularly careful over the last few months to be as safe as I could be. You know, I turned off certain things on my device. I locked down all this stuff. The reality is that I caught myself slipping all the time. It's just - it's extremely hard to navigate your life in 2021 without one of these devices helping you navigate it while, at the same time, tracking you as well. GROSS: But just technologically, if you turn off your phone, can you still be spied on through your phone? TIMBERG: Probably. You know, you all probably recall the days when you could, like, pop your battery out of your device. And this was my era when I was a foreign correspondent. You know, I'd go into Zimbabwe, and people would pop their phones out and put them away, and they felt safer, and they were safer. I can't get into my iPhone and remove that battery. I don't think that - I don't think the modern smartphone really is ever all the way off. And so I don't know enough about the coding in Pegasus to say that they can turn your phone on, but I would not be surprised at all if there was spyware that was capable of activating things on your device even when it's off - or when you think of it as off, meaning the screen's blank and it is acting like, you know, a paperweight as opposed to a computer, 'cause these things, on some level, are always on. GROSS: Tell us about the company that sold this spyware, NSO Group. What do you know about them? TIMBERG: This is a group that was started by some Israeli friends who were, you know, were trying to make it in the world of internet startups in Israel, which is quite a robust world. But they also had backgrounds, you know, in cybersecurity. And they started this company because they were approached by authorities who - in Israel who, you know, helped them understand that if they could use their technological chops in the right way, that they could help the government do things that were important to it. And to be fair to NSO, a lot of what they do is important. I mean, and I hope that no one who reads our articles discounts the importance of, for example, tracking pedophiles and drug lords and terrorists. I think we all agree that the people in charge of combating those evils have resources at their disposal to allow them to do it. GROSS: So do any of the people in NSO Group have experience with Israeli military intelligence? TIMBERG: The NSO Group, like similar companies around the world, is heavily staffed by former spies. And this is true for a lot of cybersecurity companies in the United States. You get through the NSA, and you're ready to leave or retire, and there's lots of opportunities for people who have this kind of skill set, people who know how to build software that hacks into things. And so this whole world - and this is true at the NSO Group, as well - is full of these former military spies who did this work, you know, for their governments for many years. GROSS: Craig, the NSO has been in touch with you, the company that leases this spyware, with many objections to your reporting, and this has been an ongoing process for you and the other reporters at the Post covering this story. What have their objections been, and how has that affected what you've reported? TIMBERG: It's been interesting to watch this process play out because in terms of communication with the company, I feel like this was a prepublication phase where, you know, they hired a lawyer, a defamation lawyer in Virginia, and sent aggressive letters to all of us, essentially threatening to sue the Post and its partners and put us on watch, you know, to essentially, you know, make sure we got everything right, which we're supposed to anyway. But it does focus the mind when you get letters like that. But in the prepublication phase, NSO Group really disputed almost every claim that we made. And they claimed that our forensics didn't work. They claimed that our reporting was just full of, you know, scurrilous lies and exaggerations. They in particular challenged and continue to challenge the idea that the list of 50,000 phone numbers is in any way affiliated with their company. But the tone began to be different as our stories started getting published around the world. And, you know, a few hours after the first batch of stories ran - you know, about 10, 11 days ago - I got a call from Shalev Hulio, the chief executive of NSO Group, and he wanted to make sure that I knew that - and that we knew - that he still thought our reporting was wrong in five different ways. But he did make a real point of saying, you know, I need to tell you that some of the stuff I've read about journalists and human rights activists really bothers me, and we're going to look into it. We're going to investigate. And he said, you know, if we investigate, you know, there's a chance we'll find some problems. We've found problems in the past. We've terminated contracts in the past with countries that are problematic, and we're prepared to do that again. Now, that process is ongoing, but the company has shown a willingness to engage with us on the matters we've been raising. And, you know, who knows what that investigation should look like, but it was clear that he was troubled by some of what he had read. GROSS: What are their objections to what you actually published 'cause I want to represent them in the story, too? TIMBERG: NSO Group has several kinds of objections. They believe that it's impossible that so many people were potentially surveilled. They argue that - you know, when it comes right down to it, they're kind of making a bad apples argument. In their view, they're doing all of these wonderful things to target, you know, drug lords and pedophiles. And in their view, what we're unearthing - either we've got it wrong, which they say in some cases, or what we're looking at are really extreme kind of misuse cases that don't really shed that much light on the larger - what the company mainly does, which in their minds is fight terrorists and criminals. So, you know, they've objected strongly in a number of cases. At the same time, though, they also share some revealing facts about their ability to monitor this. And in a way, this goes to the heart of the problem. You know, NSO Group provides a service. Government agencies buy that service or license that service. And then once these systems are installed in - you know, in some secret police, you know, headquarters in some capital in some part of the world, NSO Group doesn't run it anymore - at least that's what they tell us. You know, the operators of the systems, you know, basically do what they want, and if they're caught doing something problematic, they might indeed get their contract pulled. At the same time, there's no real mechanism to catch anybody. You know, we're talking about operators in a room entering phone numbers, gathering data, but no one's watching them - no one from the company, no one from the U. N. , no one with any kind of independent authority to say, oh, no, no, there you went over the line. These hundred queries are fine, but these 20 queries are not fine. There's no real mechanism that would catch abuses as they were happening. GROSS: I think it's time for another break, so let me reintroduce you. My guest is Washington Post national technology reporter Craig Timberg. We'll talk more about spyware after we take a short break. I'm Terry Gross, and this is FRESH AIR. (SOUNDBITE OF MUSIC) GROSS: This is FRESH AIR. I'm Terry Gross. Let's get back to my interview with Craig Timberg. He covers technology for The Washington Post and specializes in privacy, security and surveillance. He's been investigating how the private Israeli spyware company called NSO Group licensed military-grade spyware called Pegasus to governments that were supposed to use it only for tracking terrorists and criminals. But some governments used it to hack the phones of journalists, human rights activists, business executives and others. So what is the relationship between the Israeli government and Israeli private companies that do espionage and that sell or lease spyware? TIMBERG: I think we don't really know. A couple of my colleagues looked very carefully at this question about, you know, whether the Israeli government has some sort of access to the data that NSO clients collect. The company says, absolutely, positively not. The U. S. intelligence community and their partners in other parts of the world certainly believe that the Israelis have some sort of access to the data that NSO Group collects. Whether that's periodic or episodic or whatever, we don't know. But it is generally the case that troves of valuable information that are sitting, you know, to be collected tend to get collected fairly often. These intelligence agencies are very sophisticated. Their jobs are serious. And so there's certainly persistent suspicions that some of the data that's collected ends up in the hands of the Israeli government and maybe other governments in the world, too. GROSS: Does the Israeli government have to give approval before a private Israeli company can license spyware to another government? TIMBERG: Yes. Israel, like the United States and a number of countries, has what's called export controls. And so when it comes to something like this - it is military-grade spyware - it does have to be approved by the government of Israel. And we're told that, you know, if there are abuses, if there are countries that the government views as particularly problematic customers that they can't sell to those places. And I just want to emphasize again here that this isn't just one company. And it's not just Israel. There's other governments around the world that are more lax in their controls. And so even if the Israelis are doing this perfectly, that doesn't mean that people's iPhones aren't getting hacked. GROSS: So are there any national or international laws preventing private companies or governments from misusing spyware? TIMBERG: Lots of governments have laws on the books about wiretapping and require court approval. You know, I'm not an expert on all of them. But I would be willing to guess that almost all of them need updating for the smartphone world and the kinds of surveillance that's happening now. You've seen our U. S. Supreme Court, you know, try to make sense of the ways that these devices collect data and the ways that authorities are allowed to get that data. Something like that needs to happen, probably, in every country in the world. And probably, it needs to be sped up here as well. In terms of international controls, I don't know of anything meaningful that limits this trade. This is a common problem throughout history, right? A new technology, you know, is thrilling. And then we realize we have all these problems. And then it takes a while for societies and governments to really wrestle with these problems or bring these under control. I think we're, like, at Step 2 of that, right? The purpose of this project was to help the world understand how widely this stuff is used, how invasive it is. And we're hoping that, now, there's more meaningful and informed conversation about what can be done to bring it under control and so that it is really used for the purposes it's designed for. GROSS: So you, The Washington Post reporters and the larger consortium of journalists investigating this story, along with Amnesty International, were able to identify 37 people whose phones were targeted through this spyware that we've been talking about. Do you know who targeted them, like, which governments, agencies or police units were behind it? TIMBERG: We don't actually know for sure in any of these cases. We obviously have very strong suspicions. You know, what we had were phone numbers. And from these phone numbers, we were able to identify devices that could then be checked forensically for evidence of infection. But it was an unbelievably painstaking and laborious process to get there. And, you know - and these - you know, you can tell where a victim is by their country code. But, you know, it's not like the list had little flags on it to tell us that a particular government was the one that did the - you know, selected people for surveillance in this way. You know, you look at the data. And certain - you know, obviously, certain things come out and suggest themselves. But we weren't able to get to a point where we were 100% confident - really, in any of the cases - who the surveillor was. GROSS: So without getting too technical, what have you learned about how this spyware penetrates through a phone's defenses? TIMBERG: The most alarming thing about this thing we've learned is that you can be infected without having any idea that anything unusual has happened. GROSS: So you don't even have to, like, click on anything? TIMBERG: Yeah. Exactly. You know, we've all learned over the past decade that, you know, if you get an email from someone saying they're a Nigerian prince and they've left a bunch of gold bullion in your airplane that maybe you don't want to click on that link. Like, that's a cultural learning we've all absorbed. But this kind of spyware is so sophisticated, they can send it to your device in a variety of ways. And you don't even know that you've gotten an unusual communication. In some cases, this comes through iMessage. There was a time when it was - this stuff was coming in through WhatsApp. And then once - you know, once it's sort of had its purchase on your device, you know, nothing happens on your screen. You don't get a little ding. You don't get a little skull and crossbones or anything like that. It's just inside your device, and it's taking over. One of the most startling findings was when we looked at timestamps on the phone list and we looked at forensic records on devices we had - you know, people had shared with us, some cases, you know, the timestamp on the list and the forensic records in the device, you know, just a few seconds had passed. You know, someone had entered a number. And, you know, 14 seconds later, there are these malicious processes happening on someone's iPhone, as Pegasus, you know, is cracking open the device. It's very fast. It's very - and it is invisible. And it's impossible for almost anyone to detect. GROSS: So who needs to worry about having their phone penetrated? Do Americans need to worry about this? Do our listeners need to worry about this? TIMBERG: This is a slightly complicated answer. I mean, NSO Group says very persistently and in court that Americans' phones can't be surveilled using their technology. And so that means if you've got a, you know, +1 country code, whatever area code you are in the U. S. , that you're fine. It also means that if you're a foreigner and you're in the United States, that - you know, that Pegasus supposedly doesn't work. There's a couple of clear problems with efforts to reassure your listeners. One of them is there are other companies that do this, right? So even if the NSO Group has been completely, completely honest and Americans' phones can't be surveilled, it doesn't mean that some other company isn't doing it. Secondly, you know, lots of us travel. You know, when I used to travel around Africa, I would get a SIM card in every country. I would get a phone number. We found lots of journalists and aid workers and diplomats, including American diplomats in other countries, who were using local phones, right? You're based in Bahrain. You don't want every call to go through your Verizon phone number in New York. So you pick up a Bahraini SIM card. At that moment, you know, your nationality is invisible to this technology, right? There's no way to know. Even if you're the secret police and you're operating this Pegasus system, there's no way to know that plus-whatever-whatever in Azerbaijan or India, you know, is a U. S. citizen. So the devices have no nationality. And so while there is some protection for Americans, it's very far from perfect protection. GROSS: Let's take another break here. If you're just joining us, my guest is Craig Timberg, a national reporter covering technology for The Washington Post. We'll talk more about spyware after a break. This is FRESH AIR. (SOUNDBITE OF MUSIC) GROSS: This is FRESH AIR. Let's get back to my interview with Washington Post reporter Craig Timberg. He's been investigating how a private Israeli company called NSO Group licensed military-grade spyware called Pegasus to governments that were supposed to use it only for tracking terrorists and criminals. But some governments used it to hack the phones of journalists, human rights activists, business executives and others. I'm going to change directions a little bit and get to an earlier article you wrote that's seeming very relevant right now. On Tuesday, we heard Capitol Police officers give just incredibly upsetting testimony about what they experienced and how they were attacked on January 6. And you wrote an article about an online forum called thedonald. win that - judging from what you quoted, this forum basically had chats about just about everything that we saw happen in that violent mob. Do you want to talk a little bit about what you found on that forum? TIMBERG: Yeah. This was just startling and troubling stuff. I mean, I've spent most of the last few years of my life looking at troubling stuff on internet forums, and I'm kind of hard to shock at a certain point. But, man, the openness of the conversation around bringing weapons to D. C. , about zip tying the hands of a member of Congress, about shooting or hanging them was - it was really upsetting, frankly. And it was really out in the open. You know, I got a call from a researcher a few days before the January 6 mob attack on the Capitol, and he said to me, you really need to see this stuff. Like, you need to write about this right now. And so I, you know, teamed up with a colleague of mine. And we found, you know, 48 hours out, signs of everything that then came to pass. And then when it all happened on January 6, it was couple of days after. We found even more stuff as more researchers surfaced all these things. And these weren't unencrypted chats. You know, these weren't in, you know, dark rooms or whatever. These were happening on the internet in a place that anyone who knew where to look could find it. And it absolutely foreshadowed the events of that day. Maybe we didn't know exactly what was going to happen. But I can tell you we started that day with a very bad feeling. GROSS: Let me mention a couple of other things that you reported about what was said on this forum, thedonald. win. There was a debate over whether they should build a guillotine or gallows, and it finally got resolved in favor of gallows, which commenters estimated could be built cheaply for just about $200. And it was actually - there was actually a gallows on the National Mall, you know, to hang - well, the chant was, hang Mike Pence. But, you know, who knows what exactly would have happened with those gallows? There's diagrams that were shared on the site of tunnel systems beneath the Capitol complex and then speculation about how pushing the mob from behind could end in a wall of death that would force police officers to abandon their positions. There was advice on how to attack Capitol Police with flagpoles. Check - that was done. It so predicted what happened. That seemed so shocking at the time. And does it make you wonder, like, why weren't the police and the Capitol Police more prepared? What went wrong? TIMBERG: It certainly - I mean, I was wondering exactly that. GROSS: I mean, everybody's wondering that. But you've got these specific details. TIMBERG: That stuff was just so chilling to read in the days before and in the immediate aftermath - just how much of that was, as you say, foreshadowed by things that were said on thedonald. win and some other forums. I thought a lot about this question of how they could have been so unprepared. And I think the answer is probably multilayered. But it's clear that the people who were making decisions at the time didn't want the same sort of optics around, you know, this particular - what at that point looked like was just a protest that they had around, you know, some of the Black Lives Matter protests in Washington, D. C. , and elsewhere over the summer. There was this real sensitivity about, you know, the clashes with police and, you know, National Guardsmen, you know, patrolling the streets of the nation's capital. And they didn't want - that's not the image they wanted to project of themselves of Washington, D. C. , to the world. And it is certainly clear that they were woefully underprepared for what happened. And we know that some authorities, you know, had noticed the same issues that we had noticed and were writing about. But it's - at the same time, the decision-makers clearly didn't take it seriously enough. And this is a persistent problem I've noticed. In the issues I've covered - you know, I cover technology. But I oftentimes joke that I cover technology behaving badly. And, you know, there's just so many things on the Internet that you can kind of keep yourself in a perpetual state of alarm. It's hard to know exactly when to - when a threat has become real enough to kind of leap the bounds and end up in the real world. But I can tell you, this is one that, from the very beginning, looked like - it looked like violence was very possible, if not probable. But I can also understand how - you know, how easy it is to discount stuff that just appears to be only on the Internet. You know, I think you need to live something like January 6 to kind of understand that these two parts of our world that we think of as separate - the online and the offline - actually are - they're more than merely connected. They interact with each other all the time. And they are often kind of part of a seamless whole. GROSS: What is it like for you to live in this really dark space, because you're reporting so frequently on things related to technology that become nightmares? TIMBERG: You know, we have bad days. Everyone I know who has covered this stuff has been, you know, personally threatened at least somewhat, some people much more seriously than I have been. And there's just this kind of, like, gazing into the sewer of humanity quality about the work sometimes. I did some stories a couple of years ago about, you know, YouTube channels that were pushing the idea that Hillary Clinton was, you know, raping and eating children. You know, I can say that. But, man, reading that kind of stuff again and again, these sort of images that get thrown up, it's not fun. I mean, you do really want to look away. And at the same time, you know, if we don't look at it and don't at least write about it, how does the world know that it's a real thing and that it's a serious thing? This goes back to the January 6 problem that I mentioned a minute ago. Like, people don't want to believe this bad stuff that's on the Internet really is part of, you know, the worlds they live in every day as they go about their lives and work and shop and go to little league games and all that stuff. But it's there. It's there. And, you know, we need to take it seriously. We need to look at it with unblinkered eyes and try to make good decisions about how to deal with it. And that is - I do think that's what - one of the things that failed on January 6 is people didn't really, really in their hearts believe that things could get as bad as they did. GROSS: Well, Craig Timberg, thank you so much for your reporting. Thank you for being with us on FRESH AIR. TIMBERG: It's been my pleasure. Thanks for having me. GROSS: Craig Timberg is a national technology reporter for The Washington Post. After we take a short break, Justin Chang will review the new film \"The Green Knight,\" adapted from a legend about a young adventurer from King Arthur's court. This is FRESH AIR. (SOUNDBITE OF DAVID NEWMAN AND RAY CHARLES' \"HARD TIMES\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-07-31-1023162095": {"title": "DOJ Says Russians Tied To  SolarWinds Hacked Federal Prosecutors : NPR", "url": "https://www.npr.org/2021/07/31/1023162095/russians-hacked-federal-prosecutors-doj-solarwinds", "author": "No author found", "published_date": "2021-07-31", "content": "", "section": "National Security", "disclaimer": ""}, "2021-07-31-1023146051": {"title": "Popular Game Company Activision Blizzard Sued For Sexual Inequality And Harassment : NPR", "url": "https://www.npr.org/2021/07/31/1023146051/popular-game-company-activision-blizzard-sued-for-sexual-inequality-and-harassme", "author": "No author found", "published_date": "2021-07-31", "content": "SCOTT SIMON, HOST:  The maker of popular video games \"World Of Warcraft,\" \"Call Of Duty\" and \"Candy Crush\" is in a crisis. Hundreds of workers at the company known as Activision Blizzard walked off their jobs this week. This followed a lawsuit from California regulators that allege the company's male employees had mistreated their female colleagues for years, and leadership looked the other way. NPR's Bobby Allyn joins us. Bobby, thanks so much for being with us. BOBBY ALLYN, BYLINE: You got it, Scott. SIMON: Tell us more about this lawsuit, if you could, please. ALLYN: Yeah. So California regulators say inside this Southern California company is just a really toxic work environment. The suit describes so-called frat-boy workplace culture where men would regularly make sexual comments about women. They held these so-called cube crawls where men would drink copious amounts of alcohol and grope female employees. And on top of all of these unsettling allegations, Scott, you know, California officials say women were just paid less. And they were denied promotions over their male colleagues. I spoke to an engineer at Blizzard, Valentine Powell, about this. VALENTINE POWELL: At least at this point, 10 women that I valued and respected and saw as mentors and loved and cherished at this company have left because they don't believe it would get better. And I don't blame them. ALLYN: And that's why Powell is one of the hundreds who walked off the job this week. SIMON: What are they demanding? ALLYN: Yeah. They're demanding changes to the culture and pay inequities. You know, this company is 80% male. And workers have said when sexual harassment claims were brought to HR, they weren't taken seriously. And California regulators found this, too, in their investigation that high-ranking executives even engaged in their own blatant sexual harassment and that HR officials were close to the alleged harassers. Now, Powell told me women at the company felt like they were being penalized for their gender. POWELL: Women who take time off from work for pregnancy are not supported when they get back. And when they do get back, they find that their careers have been set back by years. ALLYN: Powell there is talking about women getting demoted and pushed into less technical roles and just watching harassers in the office go unpunished. SIMON: These are certainly some very damning accusations. And I wonder how the company's responded. ALLYN: Yeah. So Bobby Kotick, Blizzard's CEO, has apologized to employees and says the company's initial response to the lawsuit where they were fighting back was, quote, \"tone deaf. \" The company has brought in an outside law firm to investigate the company's policies. There's a manager who was named in the lawsuit as being a harasser. That person has been fired. You know, Kotick says he's committed to long-lasting change and wants to make sure that Blizzard is a more safe and inclusive place to work. SIMON: And Blizzard has an avid base of fans around the world who certainly love the video games that it produces and presents. How have they reacted? ALLYN: Yeah, they sure do. So, you know - but there's been a problem with sexual harassment in the video game world for a very long time, Scott, I mean, going back at least to the Gamergate scandal. These days, gamers are increasingly speaking out against abuse, though. And some now are boycotting Blizzard games and turning to social media and video game streaming site Twitch to say, you know what? We've had it with this company. Liz Tippett, a University of Oregon law professor who studies the #MeToo movement, told me this could be a watershed moment for the video game industry. LIZ TIPPETT: Customers saying they don't want to play the games, workers walking out, Twitch streamers saying they don't want to stream Activision Blizzard games - those things actually could really affect their bottom line. Those are the things that gets executives' attention. ALLYN: You know, Tippett says the troubling accusations have created a PR nightmare for the company, to say the least. And executives are definitely in damage-control mode and now vowing to address some of these issues. And workers right now feel like they have some power to actually hold this company accountable and make some changes to the system. SIMON: NPR's Bobby Allyn, thanks so much for being with us. ALLYN: Thank you, Scott. SCOTT SIMON, HOST:   The maker of popular video games \"World Of Warcraft,\" \"Call Of Duty\" and \"Candy Crush\" is in a crisis. Hundreds of workers at the company known as Activision Blizzard walked off their jobs this week. This followed a lawsuit from California regulators that allege the company's male employees had mistreated their female colleagues for years, and leadership looked the other way. NPR's Bobby Allyn joins us. Bobby, thanks so much for being with us. BOBBY ALLYN, BYLINE: You got it, Scott. SIMON: Tell us more about this lawsuit, if you could, please. ALLYN: Yeah. So California regulators say inside this Southern California company is just a really toxic work environment. The suit describes so-called frat-boy workplace culture where men would regularly make sexual comments about women. They held these so-called cube crawls where men would drink copious amounts of alcohol and grope female employees. And on top of all of these unsettling allegations, Scott, you know, California officials say women were just paid less. And they were denied promotions over their male colleagues. I spoke to an engineer at Blizzard, Valentine Powell, about this. VALENTINE POWELL: At least at this point, 10 women that I valued and respected and saw as mentors and loved and cherished at this company have left because they don't believe it would get better. And I don't blame them. ALLYN: And that's why Powell is one of the hundreds who walked off the job this week. SIMON: What are they demanding? ALLYN: Yeah. They're demanding changes to the culture and pay inequities. You know, this company is 80% male. And workers have said when sexual harassment claims were brought to HR, they weren't taken seriously. And California regulators found this, too, in their investigation that high-ranking executives even engaged in their own blatant sexual harassment and that HR officials were close to the alleged harassers. Now, Powell told me women at the company felt like they were being penalized for their gender. POWELL: Women who take time off from work for pregnancy are not supported when they get back. And when they do get back, they find that their careers have been set back by years. ALLYN: Powell there is talking about women getting demoted and pushed into less technical roles and just watching harassers in the office go unpunished. SIMON: These are certainly some very damning accusations. And I wonder how the company's responded. ALLYN: Yeah. So Bobby Kotick, Blizzard's CEO, has apologized to employees and says the company's initial response to the lawsuit where they were fighting back was, quote, \"tone deaf. \" The company has brought in an outside law firm to investigate the company's policies. There's a manager who was named in the lawsuit as being a harasser. That person has been fired. You know, Kotick says he's committed to long-lasting change and wants to make sure that Blizzard is a more safe and inclusive place to work. SIMON: And Blizzard has an avid base of fans around the world who certainly love the video games that it produces and presents. How have they reacted? ALLYN: Yeah, they sure do. So, you know - but there's been a problem with sexual harassment in the video game world for a very long time, Scott, I mean, going back at least to the Gamergate scandal. These days, gamers are increasingly speaking out against abuse, though. And some now are boycotting Blizzard games and turning to social media and video game streaming site Twitch to say, you know what? We've had it with this company. Liz Tippett, a University of Oregon law professor who studies the #MeToo movement, told me this could be a watershed moment for the video game industry. LIZ TIPPETT: Customers saying they don't want to play the games, workers walking out, Twitch streamers saying they don't want to stream Activision Blizzard games - those things actually could really affect their bottom line. Those are the things that gets executives' attention. ALLYN: You know, Tippett says the troubling accusations have created a PR nightmare for the company, to say the least. And executives are definitely in damage-control mode and now vowing to address some of these issues. And workers right now feel like they have some power to actually hold this company accountable and make some changes to the system. SIMON: NPR's Bobby Allyn, thanks so much for being with us. ALLYN: Thank you, Scott.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-08-01-1023468165": {"title": "Zoom Agrees To Settle A Privacy Lawsuit For $85 Million : NPR", "url": "https://www.npr.org/2021/08/01/1023468165/zoom-agrees-to-settle-a-privacy-lawsuit-for-85-million", "author": "No author found", "published_date": "2021-08-01", "content": "", "section": "Business", "disclaimer": ""}, "2021-08-02-1014632356": {"title": "Amazon Warehouse Workers In Alabama May Get 2nd Chance To Vote For Union : NPR", "url": "https://www.npr.org/2021/08/02/1014632356/amazon-alabama-warehouse-workers-may-get-to-vote-again-on-union", "author": "No author found", "published_date": "2021-08-02", "content": "ARI SHAPIRO, HOST:  Amazon warehouse workers in Alabama may get a second chance to vote on whether to unionize. This is a breaking news development in the saga of a high-profile push to form the first unionized Amazon warehouse in America. NPR's Alina Selyukh is here to tell us about it. Hey, Alina. ALINA SELYUKH, BYLINE: Hello, hello. SHAPIRO: We've got to note that Amazon is one of NPR's financial supporters. Tell us what happened today. SELYUKH: So today, a federal Labor official opened the door to a potential do-over of one of the most closely watched union elections. It happened this spring, you might recall, at an Amazon warehouse in Bessemer, Ala. , right outside Birmingham. And it was huge because it was, by far, the biggest unionization push at Amazon in the U. S. , where Amazon is now the second-largest private employer. It was also huge because the warehouse itself is huge - nearly 6,000 people, potentially a big inroad into this very influential company for the unions. And it was huge because the result was a stunning, overwhelming union defeat. The vote was held by mail because of the pandemic. And more than half of the warehouse staff cast ballots, and they voted against unionizing more than 2-1. But now today, a federal Labor official has found - I shouldn't say today. But now a federal Labor official has found that Amazon illegally pressured workers to vote no, saying that that tainted the previous election enough to scrap its results and let the workers vote again. SHAPIRO: Tell us what led to this reevaluation. SELYUKH: This is a recommendation from the National Labor Relations Board, which had a hearing after the union challenged the results of the vote. The voting in Alabama took several weeks. And then afterward, the union accused Amazon of putting a ton of pressure on workers over that time to vote against unionizing. At the hearing, workers described various mandatory anti-union meetings that Amazon held. But also a lot of focus was on a mail box that Amazon asked the Postal Service to install in the warehouse parking lot. Amazon says it wanted voting to be convenient, but workers testified that it made them feel like their vote was under surveillance. In a statement today, the union president said, quote, \"Amazon cheated, and they got caught. \"SHAPIRO: So what's Amazon's response to this latest development? SELYUKH: Right, so Amazon is denying any wrongdoing. The company says it plans to appeal this recommendation of an election redo. They say workers have already spoken, and they voted overwhelmingly in favor of not having a union, and their voices should be heard above all else. That's a quote from Amazon. This is a really big fight for Amazon, so it's understandable that they will fight against it. Unions are prominent at Amazon in Europe. But so far, the company has fought off labor organizing here in the U. S. This election this year in Bessemer was the first union vote at Amazon since 2014. And back then, workers also voted against unionizing. And this is all happening as Amazon has grown tremendously. It is now, like I said, the second-largest private employer in the U. S. behind Walmart. They have nearly a million employees in the country. SHAPIRO: So what happens next? SELYUKH: Next, we wait a few weeks for a regional National Labor Relations Board director to rule whether to schedule that new election. SHAPIRO: NPR's Alina Selyukh, thanks. SELYUKH: Thank you. ARI SHAPIRO, HOST:   Amazon warehouse workers in Alabama may get a second chance to vote on whether to unionize. This is a breaking news development in the saga of a high-profile push to form the first unionized Amazon warehouse in America. NPR's Alina Selyukh is here to tell us about it. Hey, Alina. ALINA SELYUKH, BYLINE: Hello, hello. SHAPIRO: We've got to note that Amazon is one of NPR's financial supporters. Tell us what happened today. SELYUKH: So today, a federal Labor official opened the door to a potential do-over of one of the most closely watched union elections. It happened this spring, you might recall, at an Amazon warehouse in Bessemer, Ala. , right outside Birmingham. And it was huge because it was, by far, the biggest unionization push at Amazon in the U. S. , where Amazon is now the second-largest private employer. It was also huge because the warehouse itself is huge - nearly 6,000 people, potentially a big inroad into this very influential company for the unions. And it was huge because the result was a stunning, overwhelming union defeat. The vote was held by mail because of the pandemic. And more than half of the warehouse staff cast ballots, and they voted against unionizing more than 2-1. But now today, a federal Labor official has found - I shouldn't say today. But now a federal Labor official has found that Amazon illegally pressured workers to vote no, saying that that tainted the previous election enough to scrap its results and let the workers vote again. SHAPIRO: Tell us what led to this reevaluation. SELYUKH: This is a recommendation from the National Labor Relations Board, which had a hearing after the union challenged the results of the vote. The voting in Alabama took several weeks. And then afterward, the union accused Amazon of putting a ton of pressure on workers over that time to vote against unionizing. At the hearing, workers described various mandatory anti-union meetings that Amazon held. But also a lot of focus was on a mail box that Amazon asked the Postal Service to install in the warehouse parking lot. Amazon says it wanted voting to be convenient, but workers testified that it made them feel like their vote was under surveillance. In a statement today, the union president said, quote, \"Amazon cheated, and they got caught. \" SHAPIRO: So what's Amazon's response to this latest development? SELYUKH: Right, so Amazon is denying any wrongdoing. The company says it plans to appeal this recommendation of an election redo. They say workers have already spoken, and they voted overwhelmingly in favor of not having a union, and their voices should be heard above all else. That's a quote from Amazon. This is a really big fight for Amazon, so it's understandable that they will fight against it. Unions are prominent at Amazon in Europe. But so far, the company has fought off labor organizing here in the U. S. This election this year in Bessemer was the first union vote at Amazon since 2014. And back then, workers also voted against unionizing. And this is all happening as Amazon has grown tremendously. It is now, like I said, the second-largest private employer in the U. S. behind Walmart. They have nearly a million employees in the country. SHAPIRO: So what happens next? SELYUKH: Next, we wait a few weeks for a regional National Labor Relations Board director to rule whether to schedule that new election. SHAPIRO: NPR's Alina Selyukh, thanks. SELYUKH: Thank you.", "section": "Business", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-08-02-1023801277": {"title": "Your Facebook Account Was Hacked. Getting Help May Take Weeks \u2014 Or $299 : NPR", "url": "https://www.npr.org/2021/08/02/1023801277/your-facebook-account-was-hacked-getting-help-may-take-weeks-or-299", "author": "No author found", "published_date": "2021-08-02", "content": "MARY LOUISE KELLY, HOST:  Here at ALL THINGS CONSIDERED, we get all kinds of comments from listeners. They tell us they liked a story, or they didn't like a story or we should cover more news about dinosaurs. Recently, though, we started getting a lot of comments like this. UNIDENTIFIED PERSON #1: I got an email at 5:02 saying somebody was trying to get into my Facebook account. KELLY: And this. UNIDENTIFIED PERSON #2: I was desperate. I had no one else to contact because Facebook didn't have a phone number to call. There was no email to email. KELLY: Their Facebook accounts had been hacked, and they were frustrated. We asked NPR tech correspondent Shannon Bond to investigate. And a note - Facebook is among NPR's financial supporters. SHANNON BOND, BYLINE: One morning back in May, Angela McNamara woke up in Toronto to a foreboding email from Facebook. ANGELA MCNAMARA: And it said, Angela, it appears that somebody is trying to log into your account. If this is not you, don't worry - we're keeping your account safe. BOND: But that wasn't all. MCNAMARA: So that came at, like, let's say 2:58 - 2:59 it says, your password has been changed. Another email, 3:00 a. m. , two-factor authentication has been set up. And then from there, I'm just like, OK, it is gone. BOND: She'd been hacked. She tried to stay calm and started going through Facebook's process to recover her account. She tried getting a backup code, resetting her password. Nothing worked. This has been happening to a lot of people lately. And when it does happen, good luck trying to call up Facebook to fix it. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED PERSON #3: (As automated voice) Thank you for calling Facebook user operations. Unfortunately, we do not offer phone support at this time. BOND: There's no simple way to reach a real person by email, either. Instead, the company tells users to report hacked accounts through its website, where they're asked to upload a copy of a driver's license or passport to prove their identity. And many people who try it say this automated process often just doesn't work, like Jessie Marsala in Chicago. JESSIE MARSALA: I spent hours and hours filling out these request forms. I sent these forms in morning, noon and night, multiple times a day, and nobody got back to me, not once. BOND: Another person I talked to only got Facebook's system to accept her ID after she covered up everything but her name and photo with a Post-it note. Facebook says because of the pandemic, it has fewer people available to confirm IDs. It uses artificial intelligence, too, but it says the process is taking longer than usual. Now, losing Facebook may seem like a minor thing, but Marsala has been using the social network since high school. And every morning she likes to look at its memories feature, which highlights old posts. MARSALA: And that's just a way I used to like to start my day and kind of reflect on, you know, what I did two years ago or what was I thinking seven years ago, just kind of see, you know, are my thoughts still the same? Do I still have the same outlooks on life? Things like that. BOND: So this is a big deal to her, and she and other people in her situation, since they can't turn to Facebook, they're turning to each other. On websites like Twitter and Reddit, lots of people are sharing stories of being hacked and tips about what to do. One of them is Ben Coleman, a teacher in Massachusetts who has a side hustle writing books that teach you how to fold origami bonsai trees. BEN COLEMAN: The very first concern after realizing that I was getting hacked is that these folks might be able to gain access to my business's bank account, and that would be a disaster. BOND: He managed to lock his Facebook account before the hackers could get in, but he wasn't able to unlock it. That is, until after NPR got in touch with Facebook. The company says it has not seen a recent uptick in hacking. And security experts I spoke with say there's lots of reasons hackers target Facebook accounts - selling them on the black market, scamming users' friends for money. Some even use hacked accounts to push out disinformation. But the people I talked to aren't just frustrated with the hackers. They're unhappy with Facebook, too. COLEMAN: I want Facebook to have a customer service department that some old 86-year-old lady can call up and say, my account has been hacked - please help me get back in. I want a human being on the telephone. BOND: A Facebook spokesperson says its online help center is available at any time, but the company knows it needs to improve and plans to invest more in customer support. Meanwhile, some people are going to extreme lengths to get their accounts back. It turns out Facebook does offer better customer service, but to get it, you need to buy a virtual reality headset made by Oculus, a company Facebook owns. Brandon Sherman in California did just that. BRANDON SHERMAN: I ultimately broke down and bought a $300 Oculus Quest 2, have it sitting in the box right here next to me. And as soon as I emailed customer support with the serial number, I got an immediate response. BOND: Sherman plans to return the unopened Oculus. And while he's glad the strategy worked, he doesn't think it's very fair. SHERMAN: Unfortunately, what's happening to a lot of people is, like, the only way you can get any customer service is if you prove that you've actually purchased something from them. BOND: Up in Toronto, Angela McNamara heard about the Oculus trick on Reddit and thought it was a joke, but she figured, why not? So, like Sherman, she ordered an expensive gadget she never planned to use and contacted customer support for Oculus. MCNAMARA: I did kind of what everybody else did - bought it, didn't open it and returned it. BOND: And just like that, she was back on Facebook. Shannon Bond, NPR News. (SOUNDBITE OF MUSIC) MARY LOUISE KELLY, HOST:   Here at ALL THINGS CONSIDERED, we get all kinds of comments from listeners. They tell us they liked a story, or they didn't like a story or we should cover more news about dinosaurs. Recently, though, we started getting a lot of comments like this. UNIDENTIFIED PERSON #1: I got an email at 5:02 saying somebody was trying to get into my Facebook account. KELLY: And this. UNIDENTIFIED PERSON #2: I was desperate. I had no one else to contact because Facebook didn't have a phone number to call. There was no email to email. KELLY: Their Facebook accounts had been hacked, and they were frustrated. We asked NPR tech correspondent Shannon Bond to investigate. And a note - Facebook is among NPR's financial supporters. SHANNON BOND, BYLINE: One morning back in May, Angela McNamara woke up in Toronto to a foreboding email from Facebook. ANGELA MCNAMARA: And it said, Angela, it appears that somebody is trying to log into your account. If this is not you, don't worry - we're keeping your account safe. BOND: But that wasn't all. MCNAMARA: So that came at, like, let's say 2:58 - 2:59 it says, your password has been changed. Another email, 3:00 a. m. , two-factor authentication has been set up. And then from there, I'm just like, OK, it is gone. BOND: She'd been hacked. She tried to stay calm and started going through Facebook's process to recover her account. She tried getting a backup code, resetting her password. Nothing worked. This has been happening to a lot of people lately. And when it does happen, good luck trying to call up Facebook to fix it. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED PERSON #3: (As automated voice) Thank you for calling Facebook user operations. Unfortunately, we do not offer phone support at this time. BOND: There's no simple way to reach a real person by email, either. Instead, the company tells users to report hacked accounts through its website, where they're asked to upload a copy of a driver's license or passport to prove their identity. And many people who try it say this automated process often just doesn't work, like Jessie Marsala in Chicago. JESSIE MARSALA: I spent hours and hours filling out these request forms. I sent these forms in morning, noon and night, multiple times a day, and nobody got back to me, not once. BOND: Another person I talked to only got Facebook's system to accept her ID after she covered up everything but her name and photo with a Post-it note. Facebook says because of the pandemic, it has fewer people available to confirm IDs. It uses artificial intelligence, too, but it says the process is taking longer than usual. Now, losing Facebook may seem like a minor thing, but Marsala has been using the social network since high school. And every morning she likes to look at its memories feature, which highlights old posts. MARSALA: And that's just a way I used to like to start my day and kind of reflect on, you know, what I did two years ago or what was I thinking seven years ago, just kind of see, you know, are my thoughts still the same? Do I still have the same outlooks on life? Things like that. BOND: So this is a big deal to her, and she and other people in her situation, since they can't turn to Facebook, they're turning to each other. On websites like Twitter and Reddit, lots of people are sharing stories of being hacked and tips about what to do. One of them is Ben Coleman, a teacher in Massachusetts who has a side hustle writing books that teach you how to fold origami bonsai trees. BEN COLEMAN: The very first concern after realizing that I was getting hacked is that these folks might be able to gain access to my business's bank account, and that would be a disaster. BOND: He managed to lock his Facebook account before the hackers could get in, but he wasn't able to unlock it. That is, until after NPR got in touch with Facebook. The company says it has not seen a recent uptick in hacking. And security experts I spoke with say there's lots of reasons hackers target Facebook accounts - selling them on the black market, scamming users' friends for money. Some even use hacked accounts to push out disinformation. But the people I talked to aren't just frustrated with the hackers. They're unhappy with Facebook, too. COLEMAN: I want Facebook to have a customer service department that some old 86-year-old lady can call up and say, my account has been hacked - please help me get back in. I want a human being on the telephone. BOND: A Facebook spokesperson says its online help center is available at any time, but the company knows it needs to improve and plans to invest more in customer support. Meanwhile, some people are going to extreme lengths to get their accounts back. It turns out Facebook does offer better customer service, but to get it, you need to buy a virtual reality headset made by Oculus, a company Facebook owns. Brandon Sherman in California did just that. BRANDON SHERMAN: I ultimately broke down and bought a $300 Oculus Quest 2, have it sitting in the box right here next to me. And as soon as I emailed customer support with the serial number, I got an immediate response. BOND: Sherman plans to return the unopened Oculus. And while he's glad the strategy worked, he doesn't think it's very fair. SHERMAN: Unfortunately, what's happening to a lot of people is, like, the only way you can get any customer service is if you prove that you've actually purchased something from them. BOND: Up in Toronto, Angela McNamara heard about the Oculus trick on Reddit and thought it was a joke, but she figured, why not? So, like Sherman, she ordered an expensive gadget she never planned to use and contacted customer support for Oculus. MCNAMARA: I did kind of what everybody else did - bought it, didn't open it and returned it. BOND: And just like that, she was back on Facebook. Shannon Bond, NPR News. (SOUNDBITE OF MUSIC)", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-08-02-1023925008": {"title": "Reddit Can Be More Helpful Than Facebook's Own Customer Service For Hacked Accounts : NPR", "url": "https://www.npr.org/2021/08/02/1023925008/reddit-can-be-more-helpful-than-facebooks-own-customer-service-for-hacked-accoun", "author": "No author found", "published_date": "2021-08-02", "content": "", "section": "Technology", "disclaimer": ""}, "2021-08-02-1023819435": {"title": "Study: Antisemitic Posts Rarely Removed By Social Media Companies : NPR", "url": "https://www.npr.org/2021/08/02/1023819435/antisemitic-posts-are-rarely-removed-by-social-media-companies-a-study-finds", "author": "No author found", "published_date": "2021-08-02", "content": "", "section": "Technology", "disclaimer": ""}, "2021-08-04-1024791053": {"title": "Facebook Boots NYU Disinformation Researchers Off Its Platform : NPR", "url": "https://www.npr.org/2021/08/04/1024791053/facebook-boots-nyu-disinformation-researchers-off-its-platform-and-critics-cry-f", "author": "No author found", "published_date": "2021-08-04", "content": "", "section": "Technology", "disclaimer": ""}, "2021-08-04-1024336757": {"title": "Review: 'NEO: The World Ends With You' : NPR", "url": "https://www.npr.org/2021/08/04/1024336757/this-remake-of-a-beloved-game-has-the-style-but-lacks-a-little-substance", "author": "No author found", "published_date": "2021-08-04", "content": "", "section": "Gaming", "disclaimer": ""}, "2021-08-06-1025402725": {"title": "Apple Will Scan U.S. iPhones For Images Of Child Sexual Abuse : NPR", "url": "https://www.npr.org/2021/08/06/1025402725/apple-iphone-for-child-sexual-abuse-privacy", "author": "No author found", "published_date": "2021-08-06", "content": "", "section": "Technology", "disclaimer": ""}, "2021-08-07-1025534409": {"title": "Lyft And Uber Prices Are High. Wait Times Are Long And Drivers Are Scarce : NPR", "url": "https://www.npr.org/2021/08/07/1025534409/lyft-and-uber-prices-are-high-wait-times-are-long-and-drivers-are-scarce", "author": "No author found", "published_date": "2021-08-07", "content": "", "section": "Technology", "disclaimer": ""}, "2021-08-07-1025507114": {"title": "Opinion: \"Hello? Hello?\" The Pain Of Pandemic Robocalls : NPR", "url": "https://www.npr.org/2021/08/07/1025507114/opinion-hello-hello-the-pain-of-pandemic-robocalls", "author": "No author found", "published_date": "2021-08-07", "content": "SCOTT SIMON, HOST:  Busy week? I had news meetings, family stuff, interviews, of course, and then I got a call from an officious, digitized voice that said they were the IRS. It informed me they've noticed suspicious activity on my account. Not a good start to the day. Soon, more bad news - a call from a similar-sounding robo voice, maybe their sibling, said they've noticed suspicious activity on my credit card account. But good news a minute later - a peppy, friendly, recorded voice told me my spotless driving record entitled me to receive a great new deal on car insurance. Then I remembered. I have no driving record. I have no driver's license, although that did not discourage another genial-recorded voice who called a few minutes later to offer a great new deal on a car warranty because of my immaculate driving history. By the way, I also have a spotless record in performing brain surgery. I take no poetic license when I say that on any given day, I get dozens of calls to say that I've won a vacation, a home-alarm system or discounts on scores of pharmaceuticals. I get calls to warn me of suspicious activities on my Social Security or credit card accounts and calls imploring me to donate to groups that sound faintly familiar but are likely just cleverly monikered scams. Forty percent of robocalls reportedly are. Spam is a unifier in these times of partisan divides. A survey conducted by Business Insider this year reports that 80% of Democrats say they receive spam calls, 79% of Republicans and equal percentages of men, women, rich and poor. Forty-six percent of Americans surveyed said they receive spam calls every day. But like the weather and infrastructure legislation, nobody seems to know what to do about it. Software can dial thousands of random numbers in seconds. All scammers need is a few to answer. But it struck me this week that there may be something especially inconsiderate about these calls during these times. More of us are working at home. So many of us feel isolated and anxious, especially on a week like this when masks are back, infections are on the rise, and the pandemic can seem unremitting. The ring of the phone can be piercing. We answer whatever the number because we worry it could be vital news about family or friends. Or we answer for a chance to hear another human voice. Press pound if you're feeling a little lonely, anxious or overwhelmed. SCOTT SIMON, HOST:   Busy week? I had news meetings, family stuff, interviews, of course, and then I got a call from an officious, digitized voice that said they were the IRS. It informed me they've noticed suspicious activity on my account. Not a good start to the day. Soon, more bad news - a call from a similar-sounding robo voice, maybe their sibling, said they've noticed suspicious activity on my credit card account. But good news a minute later - a peppy, friendly, recorded voice told me my spotless driving record entitled me to receive a great new deal on car insurance. Then I remembered. I have no driving record. I have no driver's license, although that did not discourage another genial-recorded voice who called a few minutes later to offer a great new deal on a car warranty because of my immaculate driving history. By the way, I also have a spotless record in performing brain surgery. I take no poetic license when I say that on any given day, I get dozens of calls to say that I've won a vacation, a home-alarm system or discounts on scores of pharmaceuticals. I get calls to warn me of suspicious activities on my Social Security or credit card accounts and calls imploring me to donate to groups that sound faintly familiar but are likely just cleverly monikered scams. Forty percent of robocalls reportedly are. Spam is a unifier in these times of partisan divides. A survey conducted by Business Insider this year reports that 80% of Democrats say they receive spam calls, 79% of Republicans and equal percentages of men, women, rich and poor. Forty-six percent of Americans surveyed said they receive spam calls every day. But like the weather and infrastructure legislation, nobody seems to know what to do about it. Software can dial thousands of random numbers in seconds. All scammers need is a few to answer. But it struck me this week that there may be something especially inconsiderate about these calls during these times. More of us are working at home. So many of us feel isolated and anxious, especially on a week like this when masks are back, infections are on the rise, and the pandemic can seem unremitting. The ring of the phone can be piercing. We answer whatever the number because we worry it could be vital news about family or friends. Or we answer for a chance to hear another human voice. Press pound if you're feeling a little lonely, anxious or overwhelmed.", "section": "Simon Says", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-08-09-1026249145": {"title": "Research Finds That People Are Willing To Reduce Digital Device Usage  : The Indicator from Planet Money : NPR", "url": "https://www.npr.org/2021/08/09/1026249145/an-economists-advice-on-digital-dependency", "author": "No author found", "published_date": "2021-08-09", "content": "SYLVIE DOUGLIS, BYLINE: NPR. (SOUNDBITE OF DROP ELECTRIC SONG, \"WAKING UP TO THE FIRE\")STACEY VANEK SMITH, HOST:  What's happening? I'm recording. I don't know why. So the other day, Darian, you called me up about an experiment you were doing. DARIAN WOODS, HOST:  All right, so we're going to do a stunt. You know how we kind of do stunts on this show. VANEK SMITH: Yeah. Yeah. WOODS: We do fun things. This one is less fun. VANEK SMITH: Wait. really? WOODS: (Laughter) This one is depriving yourself of things. VANEK SMITH: OK. I mean, then I feel like it's not a stunt. It's more of a trial, but OK. Yeah. Tell me about what's going on. WOODS: This is an experiment around phone addiction. VANEK SMITH: I'm not addicted to my phone. I can quit anytime I want. WOODS: The reason, Stacey, I roped you into this a couple of weeks ago is how much we use our phones and social media is this really controversial topic right now. The average American adult uses their phone four or five hours a day, which is, like, over a quarter of our waking hours. VANEK SMITH: And of course, you know, you have to presume that not all of that is, like, directly related to work or. . . WOODS: Yeah. VANEK SMITH: . . . You know, doomscrolling stuff that we all fall into - I mean, that I've heard that people fall into, Darian. WOODS: Yeah, not you, right? VANEK SMITH: Not me, no. OK, go for it. WOODS: I want you to open up your phone and scroll to the left. And you'll get this little productivity thing. VANEK SMITH: Yeah. Oh, man. WOODS: Click on the chart. VANEK SMITH: What do you want to know? WOODS: This feels like I'm prying. VANEK SMITH: That's fine. Fire away. Fire away. WOODS: It's for science. VANEK SMITH: I'm an open book. WOODS: What is your daily average for the last week? VANEK SMITH: It's high. It's high, Darian. WOODS: It's high. VANEK SMITH: It's four hours and 24 minutes a day. WOODS: Stacey, I'm four hours and 31 minutes. VANEK SMITH: Oh, I feel better. WOODS: (Laughter). VANEK SMITH: OK. I'm already winning. I like this so far. (SOUNDBITE OF MUSIC)VANEK SMITH: (Laughter) I am a noble soul, Darian. This is THE INDICATOR FROM PLANET MONEY. I'm Stacey Vanek Smith. WOODS: And I'm Darian Woods. Today on the show, phone addiction - psychologists, parents, teachers - they've all got views on this. But now economists do, too. VANEK SMITH: And we are turning our INDICATOR studio into its very own behavioral economics lab. And, Darian, we are going to see what it takes to break free, or at least partly break free, from one of our most habit-forming possessions - our phone. As we've been talking, my daily average is now up to four hours and 25 minutes. WOODS: Oh, yeah. That's right. We better finish this conversation. VANEK SMITH: (Laughter). (SOUNDBITE OF MUSIC)WOODS: A couple of weeks ago, when I called Stacey up, I wanted to see how much phone time she could reduce over the week. And I gave her two tools - first, a blocking function. I asked Stacey if she wanted to change any of the phone settings to limit the amount of time she spends on apps. VANEK SMITH: Which I was very excited to do. Aw, man. I'll add a limit of 10. I put a limit on Twitter, Instagram and TikTok. WOODS: Secondly, incentives - I offered to pay you, Stacey, a motivational payment for reducing your phone usage over the next week. I will pay you $2. 50 for every hour. . . VANEK SMITH: OK. WOODS: . . . That you reduce the daily average each day. VANEK SMITH: Oh. WOODS: It's just, like, a little bit of an incentive. You might be able to buy an extra couple of coffees by the week's end from reducing your screen time. VANEK SMITH: OK. WOODS: Let's check back in a week. VANEK SMITH: And, Darian, looming in the background of all this was this question, right? Are phones - is it an actual addiction, you know, or can you just cut down those hours without noticing at all? I mean, is there even such a thing as a digital addiction? This is a big controversy right now. And the big official book on medical disorders, the DSM-5, does not actually recognize digital addiction as a disorder. WOODS: Right, and some experts are making noise about this and calling for some more research. And that phrase, more research needed, was a green light to three behavioral economists - Hunt Allcott, Matthew Gentzkow and Lena Song. They are three economic researchers who love to think about incentives and cause and effect. And they dived right in. They wrote a working paper titled \"Digital Addiction. \"VANEK SMITH: And we spoke to co-author Lena Song. She is a Ph. D. candidate at NYU. WOODS: And what apps or sites do you like to visit the most? LENA SONG: I guess I use some YouTube when I'm just watching videos - something mindless. What about yourself? Do you have a. . . WOODS: Oh, for myself? Oh, the. . . SONG: Yeah. WOODS: For me, it definitely is - my Achilles' heel is Twitter. SONG: Yeah. WOODS: One of the reasons why it's so addictive for me is because, partly, I use it to find story ideas. So part of it is really useful. But then part of it is just - I'm just a black hole, and I'm just wasting time. SONG: That's exactly what we're trying to think about - right? - because we know social media does add tremendous value to our lives. But at the same time, there's other - this other component of addiction that we're trying to study here. So it's not exactly all good or all bad that's relevant here. VANEK SMITH: So research on digital addiction has divided it into two main concepts - habit formation and self-control. What Lena and her co-authors did was look at these two concepts through the lens of behavioral economics. So first, habit formation - so habit formation means wanting to do more of something tomorrow because you did more of it today. So, like, you know, take coffee - if I drink two cups of coffee today, I'm going to want to drink two cups of coffee tomorrow. I mean, it doesn't necessarily mean I'm harming myself - just that more of something today might mean more of something tomorrow. WOODS: And the second concept Lena tested was self-control problems. Now, this is when you know you want to spend the weekend reading books rather than watching Netflix. VANEK SMITH: (Laughter). WOODS: But when the weekend arrives, you think, no. VANEK SMITH: \"Grey's Anatomy,\" Season 7 - it's just the siren song of Shonda Rhimes. WOODS: And it's the classic self-control problem with your virtuous, long-term planning angel on your shoulder is fighting with the short-term devil saying live for now. SONG: I want to quit smoking. But when tomorrow comes, actually, I would continue smoking because I'm using more than what I would like to. VANEK SMITH: And to test these two parts of addiction - habit formation and self-control problems - Lena and her colleagues recruited 2,000 volunteers using Facebook ads, of course. And they put them into groups. So some of them were given $2. 50 each hour they reduced their phone usage, just like I was. And the others used a limiting feature on their phones that basically restricted how much they could use each app - also kind of like I did. WOODS: OK, so you had your 2,000 participants. They're all in treatments and control groups with different levels of incentives and all kinds of stuff. What did you find? What was the big number at the end? SONG: Our main takeaway number is that we find, on average, 31% of people's phone use can be attributed to self-control problems. WOODS: Wow, 31% - I mean, that's not nothing. SONG: Yeah. It really adds up. VANEK SMITH: So that means if you use your phone for three hours a day, that is one hour, on average, that is being wasted on something you don't even want to do. WOODS: And look; this isn't some righteous professor wagging their finger, saying you're using your phone too much. This is people's own preferences. And they're showing that they want to use their phones 31% less. VANEK SMITH: Right after they start flossing and exercising every day - yes. WOODS: Exactly. SONG: We also found that individuals were actually willing to pay money to use the limit function. So people are aware that they have these self-control problems, and they were willing to give up a little bit of money to use these functions as well. WOODS: And that brings us back to you, Stacey, and our experiment. Stacey Vanek Smith, it has been one week. . . VANEK SMITH: It's been a week. WOODS: . . . Since we last spoke. So last week was four hours and 24 minutes that you've been using your phone a day. VANEK SMITH: Try - two hours and 42 minutes is my daily average. WOODS: Oh, that is great. I'm proud of you, Stacey. VANEK SMITH: I know. I mean, you know, I love homework. WOODS: It's about roughly one hour, 40 minutes less per day. VANEK SMITH: Yeah. Wait. How much do you owe me? There's money involved. WOODS: Thirty dollars. VANEK SMITH: Thirty dollars - I mean, that's a lot of coffee. WOODS: It's a lot of coffee and muffins and croissants. VANEK SMITH: That is a lot of pastries. (SOUNDBITE OF MUSIC)WOODS: If you want to add some learning to your social media habit, follow us. We are @theindicator on Twitter. VANEK SMITH: Yeah. We don't count. We don't count toward your screen time. WOODS: Yeah. We're the good kind of screen time. And we sometimes adapt our episodes to Planet Money's TikTok and Instagram. You can find them both @planetmoney. VANEK SMITH: This episode of THE INDICATOR was produced by Julia Ritchey and Brittany Cronin. It was fact-checked by Michael He. Kate Concannon edits the show, and THE INDICATOR is a production of NPR. (SOUNDBITE OF MUSIC) SYLVIE DOUGLIS, BYLINE: NPR. (SOUNDBITE OF DROP ELECTRIC SONG, \"WAKING UP TO THE FIRE\") STACEY VANEK SMITH, HOST:   What's happening? I'm recording. I don't know why. So the other day, Darian, you called me up about an experiment you were doing. DARIAN WOODS, HOST:   All right, so we're going to do a stunt. You know how we kind of do stunts on this show. VANEK SMITH: Yeah. Yeah. WOODS: We do fun things. This one is less fun. VANEK SMITH: Wait. really? WOODS: (Laughter) This one is depriving yourself of things. VANEK SMITH: OK. I mean, then I feel like it's not a stunt. It's more of a trial, but OK. Yeah. Tell me about what's going on. WOODS: This is an experiment around phone addiction. VANEK SMITH: I'm not addicted to my phone. I can quit anytime I want. WOODS: The reason, Stacey, I roped you into this a couple of weeks ago is how much we use our phones and social media is this really controversial topic right now. The average American adult uses their phone four or five hours a day, which is, like, over a quarter of our waking hours. VANEK SMITH: And of course, you know, you have to presume that not all of that is, like, directly related to work or. . . WOODS: Yeah. VANEK SMITH: . . . You know, doomscrolling stuff that we all fall into - I mean, that I've heard that people fall into, Darian. WOODS: Yeah, not you, right? VANEK SMITH: Not me, no. OK, go for it. WOODS: I want you to open up your phone and scroll to the left. And you'll get this little productivity thing. VANEK SMITH: Yeah. Oh, man. WOODS: Click on the chart. VANEK SMITH: What do you want to know? WOODS: This feels like I'm prying. VANEK SMITH: That's fine. Fire away. Fire away. WOODS: It's for science. VANEK SMITH: I'm an open book. WOODS: What is your daily average for the last week? VANEK SMITH: It's high. It's high, Darian. WOODS: It's high. VANEK SMITH: It's four hours and 24 minutes a day. WOODS: Stacey, I'm four hours and 31 minutes. VANEK SMITH: Oh, I feel better. WOODS: (Laughter). VANEK SMITH: OK. I'm already winning. I like this so far. (SOUNDBITE OF MUSIC) VANEK SMITH: (Laughter) I am a noble soul, Darian. This is THE INDICATOR FROM PLANET MONEY. I'm Stacey Vanek Smith. WOODS: And I'm Darian Woods. Today on the show, phone addiction - psychologists, parents, teachers - they've all got views on this. But now economists do, too. VANEK SMITH: And we are turning our INDICATOR studio into its very own behavioral economics lab. And, Darian, we are going to see what it takes to break free, or at least partly break free, from one of our most habit-forming possessions - our phone. As we've been talking, my daily average is now up to four hours and 25 minutes. WOODS: Oh, yeah. That's right. We better finish this conversation. VANEK SMITH: (Laughter). (SOUNDBITE OF MUSIC) WOODS: A couple of weeks ago, when I called Stacey up, I wanted to see how much phone time she could reduce over the week. And I gave her two tools - first, a blocking function. I asked Stacey if she wanted to change any of the phone settings to limit the amount of time she spends on apps. VANEK SMITH: Which I was very excited to do. Aw, man. I'll add a limit of 10. I put a limit on Twitter, Instagram and TikTok. WOODS: Secondly, incentives - I offered to pay you, Stacey, a motivational payment for reducing your phone usage over the next week. I will pay you $2. 50 for every hour. . . VANEK SMITH: OK. WOODS: . . . That you reduce the daily average each day. VANEK SMITH: Oh. WOODS: It's just, like, a little bit of an incentive. You might be able to buy an extra couple of coffees by the week's end from reducing your screen time. VANEK SMITH: OK. WOODS: Let's check back in a week. VANEK SMITH: And, Darian, looming in the background of all this was this question, right? Are phones - is it an actual addiction, you know, or can you just cut down those hours without noticing at all? I mean, is there even such a thing as a digital addiction? This is a big controversy right now. And the big official book on medical disorders, the DSM-5, does not actually recognize digital addiction as a disorder. WOODS: Right, and some experts are making noise about this and calling for some more research. And that phrase, more research needed, was a green light to three behavioral economists - Hunt Allcott, Matthew Gentzkow and Lena Song. They are three economic researchers who love to think about incentives and cause and effect. And they dived right in. They wrote a working paper titled \"Digital Addiction. \" VANEK SMITH: And we spoke to co-author Lena Song. She is a Ph. D. candidate at NYU. WOODS: And what apps or sites do you like to visit the most? LENA SONG: I guess I use some YouTube when I'm just watching videos - something mindless. What about yourself? Do you have a. . . WOODS: Oh, for myself? Oh, the. . . SONG: Yeah. WOODS: For me, it definitely is - my Achilles' heel is Twitter. SONG: Yeah. WOODS: One of the reasons why it's so addictive for me is because, partly, I use it to find story ideas. So part of it is really useful. But then part of it is just - I'm just a black hole, and I'm just wasting time. SONG: That's exactly what we're trying to think about - right? - because we know social media does add tremendous value to our lives. But at the same time, there's other - this other component of addiction that we're trying to study here. So it's not exactly all good or all bad that's relevant here. VANEK SMITH: So research on digital addiction has divided it into two main concepts - habit formation and self-control. What Lena and her co-authors did was look at these two concepts through the lens of behavioral economics. So first, habit formation - so habit formation means wanting to do more of something tomorrow because you did more of it today. So, like, you know, take coffee - if I drink two cups of coffee today, I'm going to want to drink two cups of coffee tomorrow. I mean, it doesn't necessarily mean I'm harming myself - just that more of something today might mean more of something tomorrow. WOODS: And the second concept Lena tested was self-control problems. Now, this is when you know you want to spend the weekend reading books rather than watching Netflix. VANEK SMITH: (Laughter). WOODS: But when the weekend arrives, you think, no. VANEK SMITH: \"Grey's Anatomy,\" Season 7 - it's just the siren song of Shonda Rhimes. WOODS: And it's the classic self-control problem with your virtuous, long-term planning angel on your shoulder is fighting with the short-term devil saying live for now. SONG: I want to quit smoking. But when tomorrow comes, actually, I would continue smoking because I'm using more than what I would like to. VANEK SMITH: And to test these two parts of addiction - habit formation and self-control problems - Lena and her colleagues recruited 2,000 volunteers using Facebook ads, of course. And they put them into groups. So some of them were given $2. 50 each hour they reduced their phone usage, just like I was. And the others used a limiting feature on their phones that basically restricted how much they could use each app - also kind of like I did. WOODS: OK, so you had your 2,000 participants. They're all in treatments and control groups with different levels of incentives and all kinds of stuff. What did you find? What was the big number at the end? SONG: Our main takeaway number is that we find, on average, 31% of people's phone use can be attributed to self-control problems. WOODS: Wow, 31% - I mean, that's not nothing. SONG: Yeah. It really adds up. VANEK SMITH: So that means if you use your phone for three hours a day, that is one hour, on average, that is being wasted on something you don't even want to do. WOODS: And look; this isn't some righteous professor wagging their finger, saying you're using your phone too much. This is people's own preferences. And they're showing that they want to use their phones 31% less. VANEK SMITH: Right after they start flossing and exercising every day - yes. WOODS: Exactly. SONG: We also found that individuals were actually willing to pay money to use the limit function. So people are aware that they have these self-control problems, and they were willing to give up a little bit of money to use these functions as well. WOODS: And that brings us back to you, Stacey, and our experiment. Stacey Vanek Smith, it has been one week. . . VANEK SMITH: It's been a week. WOODS: . . . Since we last spoke. So last week was four hours and 24 minutes that you've been using your phone a day. VANEK SMITH: Try - two hours and 42 minutes is my daily average. WOODS: Oh, that is great. I'm proud of you, Stacey. VANEK SMITH: I know. I mean, you know, I love homework. WOODS: It's about roughly one hour, 40 minutes less per day. VANEK SMITH: Yeah. Wait. How much do you owe me? There's money involved. WOODS: Thirty dollars. VANEK SMITH: Thirty dollars - I mean, that's a lot of coffee. WOODS: It's a lot of coffee and muffins and croissants. VANEK SMITH: That is a lot of pastries. (SOUNDBITE OF MUSIC) WOODS: If you want to add some learning to your social media habit, follow us. We are @theindicator on Twitter. VANEK SMITH: Yeah. We don't count. We don't count toward your screen time. WOODS: Yeah. We're the good kind of screen time. And we sometimes adapt our episodes to Planet Money's TikTok and Instagram. You can find them both @planetmoney. VANEK SMITH: This episode of THE INDICATOR was produced by Julia Ritchey and Brittany Cronin. It was fact-checked by Michael He. Kate Concannon edits the show, and THE INDICATOR is a production of NPR. (SOUNDBITE OF MUSIC)", "section": "An Economist's Advice On Digital Dependency ", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-08-11-1026679111": {"title": "FCC And FEMA To Test Emergency Alert Systems On TVs, Radios And Some Cellphones : NPR", "url": "https://www.npr.org/2021/08/11/1026679111/fema-fcc-nationwide-emergency-alert-test-eas-wea", "author": "No author found", "published_date": "2021-08-11", "content": "", "section": "National", "disclaimer": ""}, "2021-08-11-1026676071": {"title": "Instagram Apologizes After Removing A Movie Poster Because It Shows A Nipple : NPR", "url": "https://www.npr.org/2021/08/11/1026676071/instagram-movie-poster-nipple-penelope-cruz-madres-paralelas", "author": "No author found", "published_date": "2021-08-11", "content": "", "section": "Movies", "disclaimer": ""}, "2021-08-12-1027032293": {"title": "Tesla, Elon Musk At Heart Of Tim Higgins Book Power Play : NPR", "url": "https://www.npr.org/2021/08/12/1027032293/tale-of-tesla-elon-musk-is-inherently-dramatic-and-compellingly-told-in-power-pl", "author": "No author found", "published_date": "2021-08-12", "content": "", "section": "Book Reviews", "disclaimer": ""}, "2021-08-13-1027314728": {"title": "Survivors Laud Apple's New Tool To Spot Child Sex Abuse But The Backlash Is Growing : NPR", "url": "https://www.npr.org/2021/08/13/1027314728/survivors-laud-apples-new-tool-to-spot-child-sex-abuse-but-the-backlash-is-growi", "author": "No author found", "published_date": "2021-08-13", "content": "AUDIE CORNISH, HOST:  This next story may not be suitable for all listeners. Apple says its next iPhone and iPad update will help catch child predators through a sophisticated photo matching system. Privacy advocates worry the system could create a backdoor on all Apple devices. NPR's Bobby Allyn takes a closer look. And we also want to note that Apple is among NPR's financial supporters. Here's Bobby. BOBBY ALLYN, BYLINE: I recently had a conversation with Ann. We're only using Ann's middle name to preserve her family's privacy. About a decade ago, a family member was arrested for taking sexually abusive photos of her child and sharing them online. ANN: Imagine the very worst thing that has ever happened to you was recorded and then it's shared repeatedly for other people's pleasure. ALLYN: Their nightmare didn't end with the arrest. Her child's real name was used with the photos that were circulating. ANN: Ten years later, we still have people trying to find my child, looking for images, wanting new images. It's, you know, a constant, constant battle. ALLYN: Child safety groups have for years pressured Apple to help people like Ann. Finally, the company has done something. Soon, all iPhones and other Apple devices will be scanned for child pornography in an upcoming update to its iOS operating system. ANN: I can't think of a family that I know that is not a fan of companies like Apple stepping up and saying, let's help stop kids from being abused. ALLYN: How it will work is pretty complicated, but it boils down to this. A database of known child abuse images has been distilled down into encrypted bits of code. Apple created an automated process to compare that code to everyone's photos backed up on the cloud. When there's a match, Apple will notify the National Center for Missing and Exploited Children, which works with law enforcement. Longtime tech critic John Gruber has studied Apple's plan and says as long as Apple implements the system as it says it will, it appears secure. JOHN GRUBER: I truly believe that Apple has carved out a very carefully planned position that I think maintains the privacy that people expect from their Apple devices. ALLYN: Gruber admits Apple, which has staked its reputation on privacy, has a lot on the line. If the scanning technology is misused, Gruber says it could be disastrous for Apple. Already, resistance is building. INDIA MCKINNEY: What Apple is doing is they are putting a bunch of scanners in a black box onto your phone. ALLYN: India McKinney is with the Electronic Frontier Foundation. She is among those pushing back. Some Apple employees are, too, and a group of more than 7,000 developers and security and privacy experts have signed a petition asking Apple to drop the plan. They call it a backdoor that threatens the privacy of all users of Apple products. McKinney worries about where this can lead down the road. MCKINNEY: How could this idea be misused by abusive governments or abusive spouses or abusive parents? ALLYN: Critics like McKinney point out that Apple sells iPhones in Saudi Arabia without FaceTime, since local laws prohibit encrypted calls. So the fear is that Apple will make similar concessions with its photo scanning technology. Apple says such a demand would be refused. The company says the tool is built solely to detect images of child sex abuse. People have the ability to opt out by not using iCloud as a backup. Ann says she doesn't think this will keep images of her child off the internet altogether, but it will go a long way in stopping people from seeing them. ANN: I know that my child's images have been identified hundreds of thousands of times, so there's quite a widespread number of them out there. ALLYN: And each time one is found by child safety groups, she's notified. She says it's overwhelming. Bobby Allyn, NPR News, San Francisco. AUDIE CORNISH, HOST:   This next story may not be suitable for all listeners. Apple says its next iPhone and iPad update will help catch child predators through a sophisticated photo matching system. Privacy advocates worry the system could create a backdoor on all Apple devices. NPR's Bobby Allyn takes a closer look. And we also want to note that Apple is among NPR's financial supporters. Here's Bobby. BOBBY ALLYN, BYLINE: I recently had a conversation with Ann. We're only using Ann's middle name to preserve her family's privacy. About a decade ago, a family member was arrested for taking sexually abusive photos of her child and sharing them online. ANN: Imagine the very worst thing that has ever happened to you was recorded and then it's shared repeatedly for other people's pleasure. ALLYN: Their nightmare didn't end with the arrest. Her child's real name was used with the photos that were circulating. ANN: Ten years later, we still have people trying to find my child, looking for images, wanting new images. It's, you know, a constant, constant battle. ALLYN: Child safety groups have for years pressured Apple to help people like Ann. Finally, the company has done something. Soon, all iPhones and other Apple devices will be scanned for child pornography in an upcoming update to its iOS operating system. ANN: I can't think of a family that I know that is not a fan of companies like Apple stepping up and saying, let's help stop kids from being abused. ALLYN: How it will work is pretty complicated, but it boils down to this. A database of known child abuse images has been distilled down into encrypted bits of code. Apple created an automated process to compare that code to everyone's photos backed up on the cloud. When there's a match, Apple will notify the National Center for Missing and Exploited Children, which works with law enforcement. Longtime tech critic John Gruber has studied Apple's plan and says as long as Apple implements the system as it says it will, it appears secure. JOHN GRUBER: I truly believe that Apple has carved out a very carefully planned position that I think maintains the privacy that people expect from their Apple devices. ALLYN: Gruber admits Apple, which has staked its reputation on privacy, has a lot on the line. If the scanning technology is misused, Gruber says it could be disastrous for Apple. Already, resistance is building. INDIA MCKINNEY: What Apple is doing is they are putting a bunch of scanners in a black box onto your phone. ALLYN: India McKinney is with the Electronic Frontier Foundation. She is among those pushing back. Some Apple employees are, too, and a group of more than 7,000 developers and security and privacy experts have signed a petition asking Apple to drop the plan. They call it a backdoor that threatens the privacy of all users of Apple products. McKinney worries about where this can lead down the road. MCKINNEY: How could this idea be misused by abusive governments or abusive spouses or abusive parents? ALLYN: Critics like McKinney point out that Apple sells iPhones in Saudi Arabia without FaceTime, since local laws prohibit encrypted calls. So the fear is that Apple will make similar concessions with its photo scanning technology. Apple says such a demand would be refused. The company says the tool is built solely to detect images of child sex abuse. People have the ability to opt out by not using iCloud as a backup. Ann says she doesn't think this will keep images of her child off the internet altogether, but it will go a long way in stopping people from seeing them. ANN: I know that my child's images have been identified hundreds of thousands of times, so there's quite a widespread number of them out there. ALLYN: And each time one is found by child safety groups, she's notified. She says it's overwhelming. Bobby Allyn, NPR News, San Francisco.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-08-13-1027445578": {"title": "Smartphone Addiction Linked To Habits And Self-Control, Study Finds : NPR", "url": "https://www.npr.org/2021/08/13/1027445578/smartphone-addiction-habits-self-control-behavioral-economics", "author": "No author found", "published_date": "2021-08-13", "content": "", "section": "Technology", "disclaimer": ""}, "2021-08-13-1027317245": {"title": "How Much Phone Time Is Too Much Phone Time? Scientists Research Digital Addiction : NPR", "url": "https://www.npr.org/2021/08/13/1027317245/how-much-phone-time-is-too-much-phone-time-scientists-research-digital-addiction", "author": "No author found", "published_date": "2021-08-13", "content": "NOEL KING, HOST:  The average American adult uses their phone around four to five hours every day. Stacey Vanek Smith and Darian Woods from NPR's Indicator podcast wondered, at what point does this qualify as an addiction? STACEY VANEK SMITH, BYLINE: There is this question looming, right? So is there even such a thing as a digital addiction? This is a big controversy right now. And the big official book on medical disorders, the DSM-5, does not actually recognize digital addiction as a disorder. DARIAN WOODS, BYLINE: Right. And some experts are making noise about this and calling for some more research. And that phrase, more research needed, was a green light to three behavioral economists - Hunt Allcott, Matthew Gentzkow and Lena Song. They wrote a working paper titled \"Digital Addiction. \"VANEK SMITH: And we spoke to co-author Lena Song. She is a Ph. D. candidate at NYU. LENA SONG: We know social media does add tremendous value to our lives. But at the same time, there's other component of addiction that we're trying to study here. So it's not exactly all good or all bad. VANEK SMITH: So research on digital addiction has divided it into two main concepts - habit formation and self-control. What Lena and her co-authors did was look at these two concepts through the lens of behavioral economics. So first, habit formation - so habit formation means wanting to do more of something tomorrow because you did more of it today. So, like, take coffee - if I drink two cups of coffee today, I'm going to want to drink two cups of coffee tomorrow. WOODS: And the second concept Lena tested was self-control problems. Now, this is when you know you want to spend the weekend reading books rather than watching Netflix. . . VANEK SMITH: (Laughter). WOODS: . . . But when the weekend arrives, you think, no. VANEK SMITH: \"Grey's Anatomy\" Season 7 - it's just the siren song of Shonda Rhimes. WOODS: And it's the classic self-control problem with your virtuous, long-term planning angel on your shoulder is fighting with the short-term devil saying live for now. SONG: I want to quit smoking. But when tomorrow comes, actually, I would continue smoking. VANEK SMITH: And to test these two parts of addiction - habit formation and self-control problems - Lena and her colleagues recruited 2,000 volunteers using Facebook ads, of course. And they put them into groups. So some of them were given $2. 50 each hour they reduced their phone usage. And the others used a limiting feature on their phones that basically restricted how much they could use each app. SONG: We find, on average, 31% of people's phone use can be attributed to self-control problems. VANEK SMITH: So that means if you use your phone for three hours a day, that is one hour, on average, that is being wasted on something you don't even want to do. WOODS: And look; this isn't some righteous professor wagging their finger, saying you're using your phone too much. This is people's own preferences. And they're showing that they want to use their phones 31% less. VANEK SMITH: Right after they start flossing and exercising every day? Yes. WOODS: Exactly. SONG: We also found that individuals were actually willing to pay money to use the limit function. So people are aware that they have these self-control problems. And they were willing to give a little bit of money to use these functions as well. VANEK SMITH: Stacey Vanek Smith. WOODS: Darian Woods, NPR News. (SOUNDBITE OF MOKHOV'S \"VIVID SUNSET\") NOEL KING, HOST:   The average American adult uses their phone around four to five hours every day. Stacey Vanek Smith and Darian Woods from NPR's Indicator podcast wondered, at what point does this qualify as an addiction? STACEY VANEK SMITH, BYLINE: There is this question looming, right? So is there even such a thing as a digital addiction? This is a big controversy right now. And the big official book on medical disorders, the DSM-5, does not actually recognize digital addiction as a disorder. DARIAN WOODS, BYLINE: Right. And some experts are making noise about this and calling for some more research. And that phrase, more research needed, was a green light to three behavioral economists - Hunt Allcott, Matthew Gentzkow and Lena Song. They wrote a working paper titled \"Digital Addiction. \" VANEK SMITH: And we spoke to co-author Lena Song. She is a Ph. D. candidate at NYU. LENA SONG: We know social media does add tremendous value to our lives. But at the same time, there's other component of addiction that we're trying to study here. So it's not exactly all good or all bad. VANEK SMITH: So research on digital addiction has divided it into two main concepts - habit formation and self-control. What Lena and her co-authors did was look at these two concepts through the lens of behavioral economics. So first, habit formation - so habit formation means wanting to do more of something tomorrow because you did more of it today. So, like, take coffee - if I drink two cups of coffee today, I'm going to want to drink two cups of coffee tomorrow. WOODS: And the second concept Lena tested was self-control problems. Now, this is when you know you want to spend the weekend reading books rather than watching Netflix. . . VANEK SMITH: (Laughter). WOODS: . . . But when the weekend arrives, you think, no. VANEK SMITH: \"Grey's Anatomy\" Season 7 - it's just the siren song of Shonda Rhimes. WOODS: And it's the classic self-control problem with your virtuous, long-term planning angel on your shoulder is fighting with the short-term devil saying live for now. SONG: I want to quit smoking. But when tomorrow comes, actually, I would continue smoking. VANEK SMITH: And to test these two parts of addiction - habit formation and self-control problems - Lena and her colleagues recruited 2,000 volunteers using Facebook ads, of course. And they put them into groups. So some of them were given $2. 50 each hour they reduced their phone usage. And the others used a limiting feature on their phones that basically restricted how much they could use each app. SONG: We find, on average, 31% of people's phone use can be attributed to self-control problems. VANEK SMITH: So that means if you use your phone for three hours a day, that is one hour, on average, that is being wasted on something you don't even want to do. WOODS: And look; this isn't some righteous professor wagging their finger, saying you're using your phone too much. This is people's own preferences. And they're showing that they want to use their phones 31% less. VANEK SMITH: Right after they start flossing and exercising every day? Yes. WOODS: Exactly. SONG: We also found that individuals were actually willing to pay money to use the limit function. So people are aware that they have these self-control problems. And they were willing to give a little bit of money to use these functions as well. VANEK SMITH: Stacey Vanek Smith. WOODS: Darian Woods, NPR News. (SOUNDBITE OF MOKHOV'S \"VIVID SUNSET\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-08-14-1027370891": {"title": "Climate Change Can Be Stopped, Scientists Say. Computer Models Show How : NPR", "url": "https://www.npr.org/2021/08/14/1027370891/climate-change-solutions-global-warming-computer-models-paris", "author": "No author found", "published_date": "2021-08-14", "content": "SCOTT SIMON, HOST:  There're dire warnings about the planet heating up, especially this week with the world's top climate scientists putting out a big report with grim projections. But a part of that report that got a lot less attention than its predictions of more heat waves, droughts and melting glaciers pointed to a hopeful path that it might still be possible to take. NPR's Dan Charles has that story. DAN CHARLES, BYLINE: This vision of the future in which climate change ends comes from giant computer simulations of the world economy - half a dozen different ones at big research institutes, mostly in Europe, created by scientists like Detlef van Vuuren at the Netherlands Environmental Assessment Agency. DETLEF VAN VUUREN: What we really are mostly doing is trying to explore what is needed to meet the Paris goals. CHARLES: The Paris goals are - keep the world from heating up more than about 3 1/2 degrees Fahrenheit compared to a couple of centuries ago. It'll mean cutting net greenhouse emissions to zero very soon - within about 40 years. It would require profound changes - so profound it's not immediately clear that it's even feasible, which is why van Vuuren and his colleagues turned to their computer models for help. VAN VUUREN: How is it possible to go to zero emissions? So that's for transport. That's for housing. That's for electricity. CHARLES: These models start with data about the world as it is right now - about cars and buses and auto rickshaws, home furnaces and rice paddies, anything that releases greenhouse gases - also what it would cost to do things differently. And then the scientists introduce a new requirement - try to hit that target in a way that's technologically and economically feasible. And the good news is the models found a way. In fact, according to Keywan Riahi at the International Institute for Applied Systems in Austria, they found multiple paths to zero carbon. KEYWAN RIAHI: So the models tell us that there are, first of all, alternative pathways possible, that there are choices available to the decision-maker. CHARLES: Different models show a variety of visions of this future world. But they're all dramatically different from our world today. Some show people responding to higher energy prices or government regulations by changing their lifestyle - living in smaller energy-saving houses or giving up their cars in favor of a new and better kind of public transit, with autonomous vehicles that respond like Uber taking people where they need to go. Others show people still using plenty of energy. Those scenarios require a huge boost in production of clean electricity - 10 or 20 times more land covered with solar and wind farms compared to now, plus more power plants burning wood or other biofuels outfitted with equipment to capture and store the carbon dioxide that's released. Now, Riahi is quick to say what happens in the models may not be feasible in real life. He used to make that mistake. RIAHI: There are phases in a modeler's life (laughter). I would say there's this early phase where you start to believe that the model is the absolute truth. CHARLES: Models can't actually predict the future, Riahi says. They don't account for political obstruction or a lot of human preferences. People may just want to drive an expensive car rather than take public transit. But the models can also be way too pessimistic. Ten years ago, van Vuuren says, they never anticipated the rise of cheap solar power. VAN VUUREN: We have been in the extremely fortunate situation that the cost of renewables have declined rapidly in the last decade. CHARLES: For all their shortcomings, though, these models are still the primary way that scientists and policymakers figure out their options for the future. They're like fuzzy maps showing routes to avoid disaster. Dan Charles, NPR News. (SOUNDBITE OF RAN THE MAN'S \"CIRCUITS\") SCOTT SIMON, HOST:   There're dire warnings about the planet heating up, especially this week with the world's top climate scientists putting out a big report with grim projections. But a part of that report that got a lot less attention than its predictions of more heat waves, droughts and melting glaciers pointed to a hopeful path that it might still be possible to take. NPR's Dan Charles has that story. DAN CHARLES, BYLINE: This vision of the future in which climate change ends comes from giant computer simulations of the world economy - half a dozen different ones at big research institutes, mostly in Europe, created by scientists like Detlef van Vuuren at the Netherlands Environmental Assessment Agency. DETLEF VAN VUUREN: What we really are mostly doing is trying to explore what is needed to meet the Paris goals. CHARLES: The Paris goals are - keep the world from heating up more than about 3 1/2 degrees Fahrenheit compared to a couple of centuries ago. It'll mean cutting net greenhouse emissions to zero very soon - within about 40 years. It would require profound changes - so profound it's not immediately clear that it's even feasible, which is why van Vuuren and his colleagues turned to their computer models for help. VAN VUUREN: How is it possible to go to zero emissions? So that's for transport. That's for housing. That's for electricity. CHARLES: These models start with data about the world as it is right now - about cars and buses and auto rickshaws, home furnaces and rice paddies, anything that releases greenhouse gases - also what it would cost to do things differently. And then the scientists introduce a new requirement - try to hit that target in a way that's technologically and economically feasible. And the good news is the models found a way. In fact, according to Keywan Riahi at the International Institute for Applied Systems in Austria, they found multiple paths to zero carbon. KEYWAN RIAHI: So the models tell us that there are, first of all, alternative pathways possible, that there are choices available to the decision-maker. CHARLES: Different models show a variety of visions of this future world. But they're all dramatically different from our world today. Some show people responding to higher energy prices or government regulations by changing their lifestyle - living in smaller energy-saving houses or giving up their cars in favor of a new and better kind of public transit, with autonomous vehicles that respond like Uber taking people where they need to go. Others show people still using plenty of energy. Those scenarios require a huge boost in production of clean electricity - 10 or 20 times more land covered with solar and wind farms compared to now, plus more power plants burning wood or other biofuels outfitted with equipment to capture and store the carbon dioxide that's released. Now, Riahi is quick to say what happens in the models may not be feasible in real life. He used to make that mistake. RIAHI: There are phases in a modeler's life (laughter). I would say there's this early phase where you start to believe that the model is the absolute truth. CHARLES: Models can't actually predict the future, Riahi says. They don't account for political obstruction or a lot of human preferences. People may just want to drive an expensive car rather than take public transit. But the models can also be way too pessimistic. Ten years ago, van Vuuren says, they never anticipated the rise of cheap solar power. VAN VUUREN: We have been in the extremely fortunate situation that the cost of renewables have declined rapidly in the last decade. CHARLES: For all their shortcomings, though, these models are still the primary way that scientists and policymakers figure out their options for the future. They're like fuzzy maps showing routes to avoid disaster. Dan Charles, NPR News. (SOUNDBITE OF RAN THE MAN'S \"CIRCUITS\")", "section": "Environment", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-08-17-1028402237": {"title": "Yik Yak, The Anonymous Messaging App, Returns  : NPR", "url": "https://www.npr.org/2021/08/17/1028402237/yik-yak-anonymous-app-free-speech-returns", "author": "No author found", "published_date": "2021-08-17", "content": "", "section": "Technology", "disclaimer": ""}, "2021-08-17-1028368018": {"title": "Siblings In Texas Drop Their Lemonade Stand To Mine Cryptocurrency  : NPR", "url": "https://www.npr.org/2021/08/17/1028368018/siblings-in-texas-drop-their-lemonade-stand-to-mine-cryptocurrency", "author": "No author found", "published_date": "2021-08-17", "content": "A MARTINEZ, HOST:  Good morning. I'm A Martinez. A brother and sister in San Francisco used to run a lemonade stand every summer. Now they mine cryptocurrency and earn tens of thousands of dollars every month. As 14-year-old Ishaan Thakur told The Dallas Morning News, most kids like to play games on their computer. We like to build them. He and his little sister, Aanya, have dozens of computers able to make billions of calculations every second, and they say that they're saving up for med school. It's MORNING EDITION. A MARTINEZ, HOST:   Good morning. I'm A Martinez. A brother and sister in San Francisco used to run a lemonade stand every summer. Now they mine cryptocurrency and earn tens of thousands of dollars every month. As 14-year-old Ishaan Thakur told The Dallas Morning News, most kids like to play games on their computer. We like to build them. He and his little sister, Aanya, have dozens of computers able to make billions of calculations every second, and they say that they're saving up for med school. It's MORNING EDITION.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-08-18-1028901574": {"title": "Facebook Reveals Most Viewed Posts To Rebut Claims It's Rife With Disinformation : NPR", "url": "https://www.npr.org/2021/08/18/1028901574/facebook-reveals-most-viewed-posts-to-rebut-claims-its-rife-with-disinformation", "author": "No author found", "published_date": "2021-08-18", "content": "", "section": "Technology", "disclaimer": ""}, "2021-08-18-1028762956": {"title": "T-Mobile Data Breach Exposes Personal Information Of 50 Million People : NPR", "url": "https://www.npr.org/2021/08/18/1028762956/t-mobile-data-breach", "author": "No author found", "published_date": "2021-08-18", "content": "", "section": "National", "disclaimer": ""}, "2021-08-18-1028633650": {"title": "Senators Demand TikTok Reveal How It Plans To Collect Voice And Face Data : NPR", "url": "https://www.npr.org/2021/08/18/1028633650/senators-demand-tiktok-reveal-how-it-plans-to-collect-voice-and-face-data", "author": "No author found", "published_date": "2021-08-18", "content": "", "section": "Technology", "disclaimer": ""}, "2021-08-18-1028527768": {"title": "FBI Often Uses Tips From Sedition Hunters, Others To Find Jan. 6 Capitol Rioters : NPR", "url": "https://www.npr.org/2021/08/18/1028527768/the-fbi-keeps-using-clues-from-volunteer-sleuths-to-find-the-jan-6-capitol-riote", "author": "No author found", "published_date": "2021-08-18", "content": "AILSA CHANG, HOST:  In the aftermath of the January 6 Capitol riots, one of the biggest challenges for the government has been sifting through the mountains of evidence in order to charge those who allegedly broke the law. There are tens of thousands of hours of videos as well as social media posts. A group of volunteer sleuths has stepped in to help the government in an unprecedented way. NPR's Tim Mak has more. TIM MAK, BYLINE: They call themselves by a number of names. Some go by the moniker Sedition Hunters. Others call themselves Deep State Dogs. There are hundreds of people who since January 6 have dedicated themselves to helping law enforcement track down suspects. KAY: I saw an attempted coup happen, and I never want to see that again. So for me, it was, what can I do to help prevent this? MAK: Kay, a 34-year-old stay-at-home mother in Washington state is a Sedition Hunter who asked that her last name not be revealed. KAY: My Twitter account is OSINTyeti - O-S-I-N-T. It stands for open-source intelligence. And yeti is Bigfoot. MAK: She has spent hundreds of hours looking at publicly available or open-source videos from that day. KAY: And, you know, I don't live anywhere near D. C. I have no political power. I'm just an ordinary person, really. But this was something I felt I could do. MAK: Hundreds of volunteers just like Kay got to work, resulting in a spontaneous information collection and analysis effort with no precedent in history. Kay began annotating videos, creating a spreadsheet where things spotted in videos could be listed - a person wearing a pink hat, for example. By using these cues, volunteers could compare different video angles to identify people committing alleged crimes. Tommy Carstensen, a Danish citizen, said he's watched thousands of videos since January. One of the things he did was analyze the music playing in the background of some of these videos. TOMMY CARSTENSEN: Someone later created a playlist. And then, you know, if you heard Elton John, you would know, OK, this is at 2 p. m. , right? And then you could say, OK, this individual was at that location at this time and so forth. MAK: And these sleuths have had some success. For example, the group Deep State Dogs was able to identify the person who allegedly tased Capitol Police Officer Michael Fanone near the Capitol steps. FORREST ROGERS: I then went and looked at all of the footage and single-framed the incident. MAK: That's Forrest Rogers, a member of the Deep State Dogs. Law enforcement later publicly identified that individual as Daniel Rodriguez, who has since been charged with serious offenses such as assaulting a federal officer with a dangerous weapon. ROGERS: We located the suspect throughout that event, where he was carrying the taser in his hand. Also, we found him with a frontal. And then we put it together as a compilation, submitted it to the FBI to make it easier for them to indeed identify. MAK: Crowdsourced information pops up repeatedly in the hundreds of criminal cases filed in response to the January 6 attacks. Sedition Hunters are mentioned by name in at least 13 cases, and many others refer to evidence voluntarily submitted by tipsters, citing information on public platforms like Facebook, YouTube or Parler. It's a new digital twist on a longtime law enforcement tool, Rogers explains. ROGERS: Even if it came back to the Wild West times of wanted posters, that's a form of open-source intelligence, where they just have a sketch of the bank robber. It's just because of the internet that open-source intelligence is becoming much more lucrative when it comes to identifying people. MAK: Some of these volunteer sleuths, such as Carstensen, have also turned to facial recognition software, which he acknowledges has its shortcomings. CARSTENSEN: I don't really like facial recognition when it's put in the hands of, say, governments, say, China monitoring the Uyghurs. But in this case, it's all public video from a public location. MAK: Federal law enforcement is also independently employing this technology in order to make the case against January 6 suspects. But civil liberties advocates like Adam Schwartz of the Electronic Frontier Foundation say that even if the technology can be used for positive ends, the fundamental tool is dangerous. ADAM SCHWARTZ: We know that many politicians and many police departments with this power would be, frankly, more likely to go after Black Lives Matter protesters than to go after insurrectionists. MAK: Schwartz said that it was notable that law enforcement was so openly using facial recognition technology to support criminal cases and that doing so now may be strategic. SCHWARTZ: It is common for the law enforcement community to try to work the public in favor of a surveillance technology by not talking much about the technology until the right sympathetic case comes along. And then they talk about it a lot. MAK: But livestreaming as well as public posts, including videos and photos, are realities of mass political events in our time. So the use of crowdsourcing and facial recognition will likely be used again in the future. Tim Mak, NPR News. (SOUNDBITE OF MUSIC) AILSA CHANG, HOST:   In the aftermath of the January 6 Capitol riots, one of the biggest challenges for the government has been sifting through the mountains of evidence in order to charge those who allegedly broke the law. There are tens of thousands of hours of videos as well as social media posts. A group of volunteer sleuths has stepped in to help the government in an unprecedented way. NPR's Tim Mak has more. TIM MAK, BYLINE: They call themselves by a number of names. Some go by the moniker Sedition Hunters. Others call themselves Deep State Dogs. There are hundreds of people who since January 6 have dedicated themselves to helping law enforcement track down suspects. KAY: I saw an attempted coup happen, and I never want to see that again. So for me, it was, what can I do to help prevent this? MAK: Kay, a 34-year-old stay-at-home mother in Washington state is a Sedition Hunter who asked that her last name not be revealed. KAY: My Twitter account is OSINTyeti - O-S-I-N-T. It stands for open-source intelligence. And yeti is Bigfoot. MAK: She has spent hundreds of hours looking at publicly available or open-source videos from that day. KAY: And, you know, I don't live anywhere near D. C. I have no political power. I'm just an ordinary person, really. But this was something I felt I could do. MAK: Hundreds of volunteers just like Kay got to work, resulting in a spontaneous information collection and analysis effort with no precedent in history. Kay began annotating videos, creating a spreadsheet where things spotted in videos could be listed - a person wearing a pink hat, for example. By using these cues, volunteers could compare different video angles to identify people committing alleged crimes. Tommy Carstensen, a Danish citizen, said he's watched thousands of videos since January. One of the things he did was analyze the music playing in the background of some of these videos. TOMMY CARSTENSEN: Someone later created a playlist. And then, you know, if you heard Elton John, you would know, OK, this is at 2 p. m. , right? And then you could say, OK, this individual was at that location at this time and so forth. MAK: And these sleuths have had some success. For example, the group Deep State Dogs was able to identify the person who allegedly tased Capitol Police Officer Michael Fanone near the Capitol steps. FORREST ROGERS: I then went and looked at all of the footage and single-framed the incident. MAK: That's Forrest Rogers, a member of the Deep State Dogs. Law enforcement later publicly identified that individual as Daniel Rodriguez, who has since been charged with serious offenses such as assaulting a federal officer with a dangerous weapon. ROGERS: We located the suspect throughout that event, where he was carrying the taser in his hand. Also, we found him with a frontal. And then we put it together as a compilation, submitted it to the FBI to make it easier for them to indeed identify. MAK: Crowdsourced information pops up repeatedly in the hundreds of criminal cases filed in response to the January 6 attacks. Sedition Hunters are mentioned by name in at least 13 cases, and many others refer to evidence voluntarily submitted by tipsters, citing information on public platforms like Facebook, YouTube or Parler. It's a new digital twist on a longtime law enforcement tool, Rogers explains. ROGERS: Even if it came back to the Wild West times of wanted posters, that's a form of open-source intelligence, where they just have a sketch of the bank robber. It's just because of the internet that open-source intelligence is becoming much more lucrative when it comes to identifying people. MAK: Some of these volunteer sleuths, such as Carstensen, have also turned to facial recognition software, which he acknowledges has its shortcomings. CARSTENSEN: I don't really like facial recognition when it's put in the hands of, say, governments, say, China monitoring the Uyghurs. But in this case, it's all public video from a public location. MAK: Federal law enforcement is also independently employing this technology in order to make the case against January 6 suspects. But civil liberties advocates like Adam Schwartz of the Electronic Frontier Foundation say that even if the technology can be used for positive ends, the fundamental tool is dangerous. ADAM SCHWARTZ: We know that many politicians and many police departments with this power would be, frankly, more likely to go after Black Lives Matter protesters than to go after insurrectionists. MAK: Schwartz said that it was notable that law enforcement was so openly using facial recognition technology to support criminal cases and that doing so now may be strategic. SCHWARTZ: It is common for the law enforcement community to try to work the public in favor of a surveillance technology by not talking much about the technology until the right sympathetic case comes along. And then they talk about it a lot. MAK: But livestreaming as well as public posts, including videos and photos, are realities of mass political events in our time. So the use of crowdsourcing and facial recognition will likely be used again in the future. Tim Mak, NPR News. (SOUNDBITE OF MUSIC)", "section": "Investigations", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-08-19-1029457359": {"title": "OnlyFans To Ban Sexually Explicit Content Beginning October 1 : NPR", "url": "https://www.npr.org/2021/08/19/1029457359/onlyfans-ban-sexually-explicit-content", "author": "No author found", "published_date": "2021-08-19", "content": "", "section": "Business", "disclaimer": ""}, "2021-08-19-1029310979": {"title": "Federal Trade Commission Renews Claim Facebook Is An Illegal Monopoly : NPR", "url": "https://www.npr.org/2021/08/19/1029310979/federal-trade-commission-refiles-suit-accusing-facebook-of-illegal-monopoly", "author": "No author found", "published_date": "2021-08-19", "content": "", "section": "Technology", "disclaimer": ""}, "2021-08-20-1029822285": {"title": "OnlyFans Says It Will Ban The Content It's Best Known For: Pornography : NPR", "url": "https://www.npr.org/2021/08/20/1029822285/onlyfans-says-it-will-ban-the-content-its-best-known-for-pornography", "author": "No author found", "published_date": "2021-08-20", "content": "AILSA CHANG, HOST:  We'll start this next conversation by noting that it will include mentions of sexual content, so it may not be suitable for all listeners. We're talking about the site OnlyFans. It's become very popular during the pandemic. Users sell access to photos and videos, and a lot of those images are pornography, fetish content and nudes. But now the company says starting in October, it's going to ban sexually explicit material in response to pressure from its banking partners and payment providers. NPR tech correspondent Shannon Bond joins us now to discuss. Hi, Shannon. SHANNON BOND, BYLINE: Hey there. CHANG: All right. So it sounds like OnlyFans is banning the content that it's best known for, right? What's going on here? BOND: Yeah, that's right. I mean, OnlyFans isn't a site just for porn, right? It says it has 2 million creators. There are celebrities like Cardi B and Bella Thorne. There are photographers. There are fitness influencers. And it says it has more than 130 million users who pay these monthly subscriptions. But look, Ailsa. This is the internet. There is a lot of porn. And so adult content is a huge part of OnlyFans' business because it allows nudity and explicitly sexual content that many other platforms, like Instagram, for example, just don't. So it's really exploded in popularity, especially during the pandemic, as you said, when lots of people are spending a lot more time at home and online. CHANG: Right. OK, so why exactly is OnlyFans making this change? BOND: Well, it does run a subscription business. In order to do that, it needs relationships with banks and with payment processors. And OnlyFans says that's who's pushing these changes. It didn't name specific companies. But, you know, of course, there's a lot of stigma around sex work. And the big payment processors, Mastercard and Visa, have recently been distancing themselves from some pornography and explicit content online. Now, last year, both cut ties with the website PornHub after allegations it was hosting illegal content like videos involving children and rape and sex trafficking. And earlier this year, MasterCard announced it's going to tighten its rules around payments for adult content. There have also been concerns raised about illegal content on OnlyFans, which the company says it bans. CHANG: I have to ask, what about the people who've been relying on OnlyFans for an income? BOND: Yeah. It's causing a lot of confusion and frustration because look; OnlyFans has become an important source of income for professional performers like porn actors and strippers and for many people who have lost jobs and income during the pandemic. I spoke with a woman named Morgan Music. She's a single mom in Washington state, and she sells explicit photos and videos on OnlyFans as a side hustle to supplement her day job. MORGAN MUSIC: Like, I didn't have panic attacks in the grocery store checkout aisle - like, all of that anxiety. To have that lifted because I have, like, a savings account for the first time and have a good credit score for the first time in my life, I think it's hard to really convey how much that means to a person's quality of life. BOND: And so now she's just not sure what's going to become of that income stream, which she says has been so helpful for her. CHANG: Right. I mean, do you think people like her will be able to keep making money under these new rules? BOND: Well, that is part of the confusion. It's not entirely clear what exactly OnlyFans is going to allow once these new rules go into effect in October. So the company says that it's going to ban any content containing what it calls sexually explicit conduct. But it also says it will still allow posts containing nudity. But it's not clear at all where it draws that line, right? When does a nude image become sexually explicit? CHANG: A key question yet to be answered. That is NPR's Shannon Bond. Thank you, Shannon. BOND: Thanks, Ailsa. (SOUNDBITE OF DAPHNI'S \"LIFE'S WHAT YOU MAKE IT\") AILSA CHANG, HOST:   We'll start this next conversation by noting that it will include mentions of sexual content, so it may not be suitable for all listeners. We're talking about the site OnlyFans. It's become very popular during the pandemic. Users sell access to photos and videos, and a lot of those images are pornography, fetish content and nudes. But now the company says starting in October, it's going to ban sexually explicit material in response to pressure from its banking partners and payment providers. NPR tech correspondent Shannon Bond joins us now to discuss. Hi, Shannon. SHANNON BOND, BYLINE: Hey there. CHANG: All right. So it sounds like OnlyFans is banning the content that it's best known for, right? What's going on here? BOND: Yeah, that's right. I mean, OnlyFans isn't a site just for porn, right? It says it has 2 million creators. There are celebrities like Cardi B and Bella Thorne. There are photographers. There are fitness influencers. And it says it has more than 130 million users who pay these monthly subscriptions. But look, Ailsa. This is the internet. There is a lot of porn. And so adult content is a huge part of OnlyFans' business because it allows nudity and explicitly sexual content that many other platforms, like Instagram, for example, just don't. So it's really exploded in popularity, especially during the pandemic, as you said, when lots of people are spending a lot more time at home and online. CHANG: Right. OK, so why exactly is OnlyFans making this change? BOND: Well, it does run a subscription business. In order to do that, it needs relationships with banks and with payment processors. And OnlyFans says that's who's pushing these changes. It didn't name specific companies. But, you know, of course, there's a lot of stigma around sex work. And the big payment processors, Mastercard and Visa, have recently been distancing themselves from some pornography and explicit content online. Now, last year, both cut ties with the website PornHub after allegations it was hosting illegal content like videos involving children and rape and sex trafficking. And earlier this year, MasterCard announced it's going to tighten its rules around payments for adult content. There have also been concerns raised about illegal content on OnlyFans, which the company says it bans. CHANG: I have to ask, what about the people who've been relying on OnlyFans for an income? BOND: Yeah. It's causing a lot of confusion and frustration because look; OnlyFans has become an important source of income for professional performers like porn actors and strippers and for many people who have lost jobs and income during the pandemic. I spoke with a woman named Morgan Music. She's a single mom in Washington state, and she sells explicit photos and videos on OnlyFans as a side hustle to supplement her day job. MORGAN MUSIC: Like, I didn't have panic attacks in the grocery store checkout aisle - like, all of that anxiety. To have that lifted because I have, like, a savings account for the first time and have a good credit score for the first time in my life, I think it's hard to really convey how much that means to a person's quality of life. BOND: And so now she's just not sure what's going to become of that income stream, which she says has been so helpful for her. CHANG: Right. I mean, do you think people like her will be able to keep making money under these new rules? BOND: Well, that is part of the confusion. It's not entirely clear what exactly OnlyFans is going to allow once these new rules go into effect in October. So the company says that it's going to ban any content containing what it calls sexually explicit conduct. But it also says it will still allow posts containing nudity. But it's not clear at all where it draws that line, right? When does a nude image become sexually explicit? CHANG: A key question yet to be answered. That is NPR's Shannon Bond. Thank you, Shannon. BOND: Thanks, Ailsa. (SOUNDBITE OF DAPHNI'S \"LIFE'S WHAT YOU MAKE IT\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-08-20-1029378628": {"title": "Elise Hu: The Beauty Ideal : NPR", "url": "https://www.npr.org/2021/08/20/1029378628/elise-hu-the-beauty-ideal", "author": "No author found", "published_date": "2021-08-20", "content": "MANOUSH ZOMORODI, HOST:  It's the TED Radio Hour from NPR. I'm Manoush Zomorodi. And on the show today, ideas about beauty. ELISE HU, BYLINE: I have been thinking about beauty culture and appearance standards a lot these days - how much beauty means to us, not just as women or men, but as society. ZOMORODI: If this voice sounds familiar, it's because you've heard her all over NPR. It's our very own Elise Hu. And in 2015, Elise moved to Korea to open up NPR's bureau in Seoul, a city which, in the past few years, has emerged as a cosmetics and skin care superpower. HU: When I first got to Seoul, the sort of pervasiveness and dominance of a really specific beauty standard and beauty norms was everywhere. The night I got to Seoul, I was staying in Myeong-dong, which happens to be the makeup district, where every store is lit up, up and down the street, by images of skin care products and women with these sort of alabaster skin faces. And every single store is the name of some sort of makeup brand. And so you can have kind of the face shop across from another face shop across from another face shop. And so it's like trick-or-treat, but for skin care products. So it was made very obvious to me as soon as I landed in Korea, the dominance of the skin care industry, but also appearance standards and the importance of looking a certain way. ZOMORODI: Elise wanted to see what it was like to follow all these Korean beauty trends. And so she did in a series called \"Elise Tries. \"(SOUNDBITE OF ARCHIVED RECORDING)HU: Skin care in South Korea is serious business, with South Korean women spending twice as much of their income on beauty products as American women. Really go in for the excavation. Oh, yeah. I think she's getting my nose pores. Mmm hmm. Oh, geez, you can hear it. Oh, dear. Oh, geez. I can actually feel stuff being sucked up. I want this off my face so bad because I feel like I'm, like - I'm feeling a little claustrophobic. Oh, my gosh. ZOMORODI: Today, Elise is writing a book about beauty - particularly K-beauty, as it's called. HU: I'm really fascinated by it. And I'm fascinated by the power of beauty ideals, politically, economically, but most important, culturally. ZOMORODI: Which is why we've invited her to be our guide on this episode. Because not only is she on NPR and researching this topic, Elise also hosts the \"TED Talks Daily\" podcast. So she watches a lot of TED talks. Elise, you are going to take us through a selection of TED talks about beauty norms or questioning the beauty ideal, not just in Korea, but all over the world. And there are so many layers to this topic, right? HU: Yes. Yes. So I went to Korea. I learned all of this stuff. But I didn't want to simply eviscerate Korean beauty because I take the industry and its growth and the influence of beauty really seriously. And I think that the pursuit of beauty is kind of a tentpole of the modern female experience, right? And my hope is just to kind of really take it seriously and make room in our conversations and in our minds for thinking through it and how the so-called beauty industrial complex plays a role in our experiences and our identities, right? We see so many digital images all the time flashing before us. And that kind of helps solidify norms of how we should appear in our sort of consciousness, right? And what I really wanted to dig into is the work that it takes to appear, quote, unquote, \"beautiful. \" It requires a lot of maintenance. It requires a lot of work. And it requires a lot of spending money on products or makeup or procedures. And that's just to kind of keep up with the Joneses - right? - of appearance standards. Because if you don't sort of meet those aesthetic norms, that'll cost you. (SOUNDBITE OF MUSIC)ZOMORODI: So we want to kick off our conversation with a talk about the influence that social media has had on how people think of beauty and also the sort of mental health for mostly young women. So the first talk is by two twins who live in Canada - Teagan and Keisha Simpson. They gave a talk in 2019 called \"Can Our Body Image Handle Social Media? \"(SOUNDBITE OF TEDx TALK)KEISHA SIMPSON: Different ages use and interact with Instagram differently. For example, if we were all to pull out our phones right now, what you would see on your account would be very different from what I would see because it all depends on who you follow. I'm going to take the guess the majority of you don't follow hundreds of young women. TEAGAN SIMPSON: But I do. When I go on Instagram, I'm overwhelmed by photos of girls my age, many of which are posed and perfected versions of my friends and mere acquaintances. What a teenage girl sees on Instagram is drastically different from what the average adult sees. And over time, scrolling through these photos can really take a toll on your self-esteem. With a quick Google search, we found numerous studies that link social media to increasing levels of anxiety, depression, loneliness and body image issues in young women. But could our friends really be feeling this way, too? K SIMPSON: No. No way. There's no way. Because when we go on Instagram, what we see are happy, beautiful and confident people. There's no way that these girls are going through the same thing that we are. Yet the more we researched and Googled, the more concern we felt. ZOMORODI: Elise, just listening to these young women is stressing me out because there are many worrying studies that link social media to depression, even suicidal thoughts, especially for teenage girls. But there might be some people who are thinking, well, then just don't go on social media. How would you explain it to people who maybe just don't understand what young women are dealing with these days? HU: Well, this visual culture doesn't just get propagated on Instagram or on TikTok or places where teenagers spend time, right? How we look and how we're supposed to look is communicated in so many different channels and across so many different ways that we receive images and are bombarded with images. So all of us are part of it universally because all of us are connected to the web, you know, in the developed world. And all of us are kind of being fed images constantly. So even if you think that you are not part of this sort of cycle of imagery and the norm-setting, you are. (SOUNDBITE OF MUSIC)ZOMORODI: OK. So another thing that Teagan and Keisha bring up is just how common it is today to edit and filter yourself - your photos - on social media. (SOUNDBITE OF TEDx TALK)K SIMPSON: The biggest surprise for Teagan and I was how many young women admitted to using Photoshop regularly. I could go on right now, and in a few moments, I could have a photo of myself with longer legs, a thinner waist. I could remove acne, remove a fat roll. Or I could even give myself that perfectly round butt that everyone is talking about. T SIMPSON: Now, these issues aren't new. We've been comparing ourselves to photoshopped images forever. I'm sure many of us have been in a grocery store where we opened up a magazine, scanning through pages of perfectly photoshopped, beautiful people. But what if you opened up these magazines and the photos were of your friends? ZOMORODI: Elise, from what I understand, one of the most popular photo editing apps, Facetune, reportedly had 20% more usage, as they say, at the start of the pandemic, and then - I'll make a little confession here that I was spending so much time on Zoom and was so tired during the pandemic that I did use the Zoom filter to make my skin look a little better. HU: And why not? ZOMORODI: Well, I don't know. It's not - you know, in the name of truth, like, where do we start to draw the line? What have you been hearing about this? Like, and to what extremes will people go to try to make what is fake - let's just call it that - a reality? HU: Yeah. So one of the questions that I'm asking is, A, where do we draw the line when it comes to self-improvement? That's a key question. But B, because the norms that we're seeing on Zoom or on Instagram or on TikTok are so enhanced, then what we start believing is normal becomes more and more narrow, right? Because everybody's skin is enhanced. You know, everybody's chin is a little bit thinner. And researchers say that there's kind of a global mean. There are four aspects of beauty that, irrespective of where you are in the world, people aspire to. And it's smoothness, firmness, thinness and youth. And the thinness can be relative to your population. So thin in Asia is thinner than, say, thin in Northern Europe. And what results is that all women, and increasingly numbers of men, need surgical and non-surgical technical fixes if we are to be perfect like those filters, right? Even just good enough is getting harder to achieve as these norms become more and more dominant because it makes it harder for us to resist. ZOMORODI: You know, it makes me think, like, as with many things with technology, at least here in the U. S. , there is very little oversight. And I read with total fascination that Norway recently passed a law that says influencers and brands must identify photos on social media that have been retouched. And, you know, just to go back to Keisha and Teagan Simpson, they kind of had a similar idea. More of a grassroots way of going about it, but they challenged people to post untouched photos of themselves and to see what that feels like. (SOUNDBITE OF TEDx TALK)K SIMPSON: What if we could improve the Instagram experience? Could we balance the perfected photos with unfiltered ones? Last year, we ran a campaign to do just this. It was called the As She Is challenge, where young women are encouraged to post an unfiltered photo to our hashtag, #AsSheIs. T SIMPSON: This is a typical post from one participant's Instagram account. Clearly, she's beautiful. But on the day of the challenge, this is the photo she chose to post. Vulnerable and courageous, she talks about her facial acne and her use of filters to cover it up. This young woman's willingness to be unfiltered made a real impact on her followers, and admittedly, also herself. From our experience, when young women are willing to be vulnerable, they express a sense of relief, freedom from accepting and admitting that they have insecurities. (SOUNDBITE OF MUSIC)HU: I applaud these women, and I support that they are trying to keep the window of what's normal inclusive of how we really look. Because one of my concerns as somebody who's now researching beauty is that our appearance norms, especially because of filters, become so far removed from actually what we normally look like. And so I love that they are maintaining a space and, in fact, encouraging all of us to show up as we really are. (SOUNDBITE OF MUSIC)ZOMORODI: When we come back, more from Elise Hu on interrogating the beauty ideal. I'm Manoush Zomorodi, and you are listening to the TED Radio Hour from NPR. It's the TED Radio Hour. I'm Manoush Zomorodi, and I am so pleased to be spending the hour with longtime journalist Elise Hu. She is the host of TED Talks Daily, and she is working on a book about beauty norms, beauty standards and why we think someone is beautiful but not someone else and all the work we have to do to be, quote-unquote, \"beautiful,\" right, Elise? HU: That's right. You packed a lot into that, and thank you. ZOMORODI: OK. So the next TED Talk that you have brought us, it's a fascinating one. It is from a woman named Sasha Sarago. She is an Aboriginal writer and model in Australia, and she gave this talk in 2020. And so just let's get right into it. Sasha starts off telling a story from a few decades earlier when she was a preteen at a friend's birthday party, and a friend's sister asked her the question, so what's your background? (SOUNDBITE OF TED TALK)SASHA SARAGO: And, like any proud Aboriginal child would declare, I'm Aboriginal. Given the reaction of the room, being Aboriginal was clearly a dirty word. And at the tender age of 11, I was told by my best friend's adult sister that I was too pretty to be Aboriginal. By this time, my mouth is dry. My blood is boiling. And I'm trying so hard to fight back what feels like an ocean of tears. I calmly join my circle of friends and begin to (laughter) fake laugh at whatever is funny to mask my embarrassment as I clutch on to my newfound complex. And this is why we need to change our perceptions of beauty. And how we do this is by learning from Aboriginal women, their stories and perspectives, because right now pretty hurts. Pretty hurts because you're trying to erase my Aboriginality to applaud my proximity to whiteness. Pretty hurts because, aimed at an Aboriginal woman, it is a weapon loaded in racism, sexual exploitation and cultural genocide. You see; what this woman didn't realize when she declared that I was too pretty to be Aboriginal is that she took something precious from me - pride in my identity. You see; I belong to the oldest living culture in the world, but that day, that legacy, it was replaced with shame. And it's been this filthy stain I've been trying to get rid of for 20 years. (SOUNDBITE OF MUSIC)HU: That really resonates with me so much and is arguably responsible for why I still wrestle with these questions of beauty because when I was a teenager, I remember - I'm an Asian American and so not part of the dominant group, especially not in suburban Texas, where I grew up. And I remember when I was in 9th or 10th grade, a boy said to me, you're pretty hot for an Oriental. So that kind of just backhanded compliment-slash-out-grouping at the same time, you know, it does make you feel and internalize a sense of shame. And that's such a shame, right? ZOMORODI: Yeah. And, actually, Sasha goes right on to say that the way that Aboriginal women define beauty is completely different. She actually goes on to tell a traditional story about a fisherwoman named Barangaroo, a famously defiant female ancestor who lived in the 18th century. (SOUNDBITE OF TED TALK)SARAGO: Barangaroo, like the other Eora women, took pride in their status as being main food providers for their tribe. A skillful and patient fisherwoman, Barangaroo would access Sydney Harbor and its surrounding waters for its abundant food supply, only taking what was needed. So you can just imagine how furious Barangaroo was when she saw British colonists trawl 4,000 salmon off the north shore in just one day, then gifting some of this catch to her husband and some of the other men from her tribe. Barangaroo knew such a wasteful act would threaten the Eora women's cultural authority within the tribe, furthermore destroying their traditional way of life. So Barangaroo rejected British laws and customs, their food, drink and social etiquette, even when her husband decided to conform. When Barangaroo and her husband Bennelong was invited to dine with Governor Philip and the British party, Barangaroo stayed true to who she was. Instead of wearing colonial attire - a tight corset and a gown layered in silk - she came sporting her traditional wears - white ochre and a bone through her nose. What Barangaroo illustrated was Indigenous beauty is authentic. (SOUNDBITE OF MUSIC)ZOMORODI: What a beautiful story. HU: Yeah. ZOMORODI: And I love that it's passed on through the generations as something to sort of hold onto, that beautiful can be defined in different ways by different cultures. Do you know of any other cultures in which, I guess, very specific beauty ideals have held strong in the face of more - sort of the more homogenous, Eurocentric, Western look? HU: Yeah. And, just to be fair, we are seeing a more homogenous look, but it's not necessarily Eurocentric, right? There is a more homogeneous look that - in Asia, that is a competing standard against kind of a real Eurocentric look. So we should note that. But it is harder to find examples of regional or local norms that really hold strong because we are all so connected on this global internet. Local norms still do exist in pockets of the world. I just think what's considered sort of globally beautiful is now something that we see and is becoming more and more flattened. ZOMORODI: Yeah, because, as you say, we're all looking at the same web. . . HU: Exactly. ZOMORODI: . . . Which, actually, I think, is one of the reasons why Sasha, by the way, started what she says is Australia's first Indigenous and ethnic women's lifestyle blog and magazine. HU: Cool. ZOMORODI: But she does say in her talk that it really took her a while to figure out how to appreciate her and her people's roots and their conception of beauty. (SOUNDBITE OF TED TALK)SARAGO: Over the years, my obsession for beauty, it's led me to this truth. You cannot appreciate beauty if you cannot recognize it in yourself. So how do we change our perceptions of beauty? We have to get real with ourselves and start by asking, who am I? Where do I come from? The world that I live in, how did it come to be? And, more importantly, where to from here? You may not like what you discover, but sit with it. Feel the discomfort. Colonization has stolen from us one of the greatest treasures we can obtain - each other. ZOMORODI: That is a big topic. There's lots to unpack here. HU: Yeah. I am actually deep in the research on how colonization really has affected beauty norms. Double eyelid surgery, for example, which is the most popular procedure in South Korea, was brought to South Korea and, arguably, invented by a plastic surgeon named David Millard, who was a U. S. Army physician. . . ZOMORODI: Oh, wow. HU: . . . And plastic surgeon who was stationed on Yongsan, which is the U. S. military base in South Korea following the Korean War. And he originally did this surgery - this is to create a crease in your eyelid if you weren't born with one. And David Millard said it was so that his patients could look more white. ZOMORODI: I mean, that is deeply, deeply troubling in many ways. But what about people, Elise, who are saying, you know what - I'm done with this? Is there a backlash to all of this? HU: In South Korea, there's a movement called Escape the Corset, where women are collectively crushing their makeup compacts on Instagram and on TikTok and shaving their heads or cutting their hair really short. It is their form of resistance and since it has cost them. It's been so costly to try and keep up with appearance standards, not just financially but also emotionally, mentally, intellectually. But the beauty industry seems to be bouncing right back, and so it's really hard to see whether resistance is having an impact. ZOMORODI: You know, I think that's interesting because, in a way, it segues nicely to the next talk that you brought us. . . HU: Yeah. ZOMORODI: . . . Which is about the opposite end of the spectrum. HU: Yes. So one community or a few communities that really celebrate sort of the traditional femme idea of beauty is the transgender community, as well as the drag community, where you can really sort of go after these adornments and wear these adornments and makeup and glitter and what's considered traditionally feminine displays. That's a really powerful way of either coming out or feeling like you can wear on the outside what you feel on the inside. (SOUNDBITE OF MUSIC)ZOMORODI: So the next talk is by the model Hari Nef, and she gave a talk in 2016 called \"The Aesthetics Of Survival. \"(SOUNDBITE OF TEDx TALK)HARI NEF: Remember when Caitlyn Jenner revealed herself on the cover of Vanity Fair? ZOMORODI: She starts her talk by projecting a picture of Caitlyn Jenner on the cover of Vanity Fair. And I don't know if you remember, Elise, but Caitlyn Jenner is looking extremely glamorous - lots of makeup, big hair. . . HU: Oh, the corset. ZOMORODI: The corset, exactly. (SOUNDBITE OF TEDx TALK)NEF: I've got a lot to say about her conservative politics and her bumpy advocacy, but this was cool. ZOMORODI: But it also started a conversation and a lot of pushback because there were some people who felt that this was the ultimate anti-feminist thing to do, to pose like that, because by posing like that, Caitlyn Jenner was just fulfilling stereotypical male fantasies. But Hari disagrees. (SOUNDBITE OF TEDx TALK)NEF: If you ask me, hair, makeup and nails don't make trans women like me - or any woman, for that matter - bad feminists. And, sure, what if Caitlyn had appeared on the cover of Vanity Fair in a pantsuit with no makeup, her hair pulled back, arms crossed? Yes, I think she would have looked really cool. But would we all have accepted her so readily as a woman? Would she have appeared on the cover of Vanity Fair to begin with? It's time for the aesthetics of upwardly mobile feminist respectability to make room for the aesthetics of survival, particularly trans survival. It's time to revise what a feminist looks like, especially if hair, makeup and nails allow her to get jobs, make friends or ride the subway home safely at night. It's time to free the femme because some of us need it or just like it, and that's OK. (SOUNDBITE OF MUSIC)ZOMORODI: OK. So I think it's important that we bring up here why there was such a backlash. And it's - really comes down to the reaction from some second-wave feminists saying, you know, that women don't have to be super glam. They don't have to be super feminine, that this was, you know, taking us backwards by having Caitlyn Jenner look like that. HU: Yeah, so during the sort of consciousness-raising era of the '70s when second-wave feminism was in vogue, the idea was that to look very feminine was also to adhere to traditional gender roles of having to be at home and not having as many paths to economic independence. But yeah, we talk so much - we have had so much of this conversation dominated by sort of critiquing narrow beauty standards. And this is another way to critique narrow beauty standards from Hari here. It's to say that beauty standards should not just be a rejection of what's traditionally femme, but should also include an acceptance of femme if that's what it takes for survival. (SOUNDBITE OF TEDx TALK)NEF: Under patriarchy, money and country inscribe themselves on women's bodies. We look in the mirror, and we ask ourselves, huh, do I look like a rich woman today? We look in the mirror and say, huh, do I look like an American woman today? We look in the mirror and say, huh, do I look like a beautiful woman today? And if I don't look rich, beautiful and American, am I still a woman? Here's a picture of me before I started transitioning - or I had started transitioning, but I hadn't started medical transition yet. At this point in my life, I wore a full face of makeup every day. I shaved my whole body every week, which covered me in these angry red spots. I stopped cutting my hair. I wore dresses to morning classes. I started hormones - pills twice a day and a needle in my leg every week. I started going in for monthly laser hair removal appointments - procedures that were so painful that I had to chug a flask of vodka before every session just so I'd feel it less. I starved myself and abused laxatives so I could fit the clothes I wanted to wear. I did all this 'cause I wanted a body that allowed me to do the things I wanted to do in the way I wanted to do them, things men in this country aren't really allowed to do. I tried to do them in the body I was born with, but people told me, no, you can't. You got to soften up your face, get rid of all your body hair, get breasts, shrink your waist, get a vagina. Of course, I looked them right in the eye, said [expletive] you, turned around and did pretty much all of what they told me to do. (LAUGHTER)NEF: It hurt, and it worked. And if my story or journey sounds difficult or tough, I can guarantee you it's even more difficult and more tough for the vast majority of trans women. ZOMORODI: Oh, that is so hard to hear, especially the part when Hari admits she feels that she needed to suffer all that pain to achieve what she wanted. And then, she alludes to the violence that many trans women also suffer. HU: Yes, yes. According to one study, trans people are four times as likely to have violent crimes perpetrated against them compared to cisgendered people. One in two transgender individuals are sexually abused or assaulted at some point in their lives. Some reports even estimate that transgender survivors may experience rates of sexual assault up to 66%, and that's often coupled with physical assaults or abuse. ZOMORODI: So upsetting. And Hari points out that this idealized version of femininity is essentially meeting a patriarchal standard, standards set by men. But she also says that while meeting those standards, well, that can mean survival for some trans women. For others, it is a goal in and of itself. But the process, whoa - it can be long and extremely tough. (SOUNDBITE OF TEDx TALK)NEF: It is so hard to gain access to hormones, to jump through all the medical hoops. It is so expensive to buy cosmetics, new clothes, healthy food, any number of means towards body feminization. And yeah, even if a trans woman does manage to look or seem femme, her race, her class or her citizenship can place further targets on her back. So when it comes to trans women with limited resources, their femme can be the difference between life and death. So I got to ask, why are we being shamed for our femme? Let femmes be femmes if they want to be femme because some of us need it or just want it, and that's OK. When the aesthetics of feminist respectability exclude and erase the women who need - not just want, need - to give them up, then the aesthetics of feminist respectability need to change. Femme aesthetics aren't bad or good. They just work. They just are. They work for some of us. So chill out. (LAUGHTER)NEF: Let us live. Free the femme. Thank you. (APPLAUSE)ZOMORODI: That was model Hari Nef. You can see her full talk at ted. com. In just a minute, we'll continue our conversation with Elise Hu. On the show today, reflecting on and challenging our beauty norms. I'm Manoush Zomorodi, and you're listening to the TED Radio Hour from NPR. (SOUNDBITE OF MUSIC)ZOMORODI: It's the TED Radio Hour from NPR. I'm a Manoush Zomorodi. And on today's show, the beauty ideal - the beauty ideal. So far, we've heard a TED Talk about Instagram. (SOUNDBITE OF TEDx TALK)K SIMPSON: There's new apps that allow us to digitally alter the way we look. ZOMORODI: How teens feel tremendous pressure to Photoshop themselves to look flawless. (SOUNDBITE OF TEDx TALK)K SIMPSON: And in a few moments, I could have a photo of myself with longer legs, a thinner waist. I could remove acne, remove a fat roll. (SOUNDBITE OF TED TALK)SARAGO: You see, I belong to the oldest living culture in the world. ZOMORODI: We heard from a woman finding strength through her Aboriginal beauty culture. (SOUNDBITE OF TED TALK)SARAGO: When we decolonize beauty, we are reintroduced to our authentic selves. (SOUNDBITE OF TEDx TALK)NEF: It's time to revise what a feminist looks like. ZOMORODI: And we learned that traditional femme standards criticized by some can be a real lifesaver for some trans women. (SOUNDBITE OF TEDx TALK)NEF: Especially if hair, makeup and nails allow her to get jobs, make friends or ride the subway home safely at night. ZOMORODI: Riding shotgun with me is Elise Hu, host of the \"TED Talks Daily\" podcast. She is also writing a book about this subject. Hello, Elise. HU: Hello, Manoush. ZOMORODI: And Elise, a constant theme running throughout our episode so far has been body modification - right? - the good and the bad. HU: One of the biggest questions that I wrestle with as I research and write this book is how do we square the beauty ideal in a virtual world and a real world when the lines between the worlds are getting so blurred? And there's not only the technology of sort of self-surveillance, the idea of sort of cameras in our pockets and us being able to see one another all the time and then surveilling ourselves because we're aware that we're seen all the time. So that's one kind of technology. The other is the technology of self-improvement because there are so many beauty filters that normalize or teach us the ideals. Then, we sort of fall into that, and we start to chase that in a way that appears not only in our images but maybe on the living canvas, maybe on our actual bodies because that's becoming more and more accessible in lots of places in the developed world. ZOMORODI: And I think that also brings us to our final talk. . . HU: Yeah. ZOMORODI: . . . About potentially the future of beauty. And that's gene editing, right? The last Talk that you've brought us from biologist Paul Knoepfler - his talk is called \"The Ethical Dilemma Of Designer Babies. \" And he starts by taking us to the not-so-distant future. (SOUNDBITE OF TEDx TALK)PAUL KNOEPFLER: Let's pretend it's the year 2030, and you're a parent. You have your daughter, Marianne (ph), next to you. And in 2030, she is what we call a natural because she has no genetic modifications. And because you and your partner consciously made that decision, many in your social circle - they kind of look down on you. They think you're, like, a Luddite or a technophobe. Marianne's best friend Jenna (ph), who lives right next door, is a very different story. She was born a genetically modified designer baby with numerous upgrades. And it's become very clear to you that Jenna is extraordinary. She's incredibly intelligent. If you're honest with yourself, she's smarter than you, and she's 5 years old. She's beautiful, tall, athletic, and the list goes on and on. And in fact, there's a whole new generation of these GM kids like Jenna. And so far, it looks like they're healthier than their parents' generation, than your generation. And they have lower health care costs. They're immune to a host of health conditions, including HIV/AIDS and genetic diseases. It all sounds so great. ZOMORODI: It does all sound so great. On the one hand, I'm like, awesome, a healthy child who doesn't have to deal with disastrous illnesses in their lifetime ever. But on the other hand, this idea of, like, an upgraded kid - it is creepy. Elise, like, how far-fetched is this scenario? HU: Yeah, scientists range in their opinions on how far-fetched this is. But Paul is a stem cell researcher, and he spends a lot of time thinking about how we can use gene therapy in a helpful way - right? - gene engineering to really be therapeutic. But he's also worried that this technology, like CRISPR, could be used by families of rich people with deep pockets to alter their future children and give them this advantage that would really create an unfair playing field. This is one of the big ethical questions that comes up when we talk about CRISPR. And we've seen how it could play out in books and movies. . . ZOMORODI: Yes. HU: . . . About the future. (SOUNDBITE OF FILM, \"GATTACA\")UNIDENTIFIED NARRATOR: In the not-too-distant future. . . ZOMORODI: \"Gattaca,\" I'm thinking of. (SOUNDBITE OF FILM, \"GATTACA\")UNIDENTIFIED NARRATOR: . . . Our DNA will determine everything about us. HU: Such a great film. But what I thought was really powerful about it, for those of y'all who haven't seen it, is that we engineer that which we find perfect or ideal at a given time. And when we look back on that film, we have the opportunity to really rethink what they thought was perfect at that time, right? And that ideal is fluid, and it's expansive. So it's worrying to lock ourselves into one ideal of perfection when you have the power to genetically modify babies. ZOMORODI: Yeah. When he was like, she's perfect, she's tall, I was like, hang on a minute. As a short person, who do you get to - I don't - I wouldn't want to have, like, weird extremely tall children. Then they. . . (LAUGHTER)ZOMORODI: . . . As a short person. But OK, so where does the law stand on this? If someone wanted to have a designer baby - I mean, you can certainly pick the sex of your child, and you can screen for certain illnesses. But can you make them tall or beautiful or have a higher IQ? HU: Not right now. Not right now. The U. S. and dozens of other countries around the world have specifically made the implantation of genetically modified human embryos illegal. ZOMORODI: OK. HU: Now, that's different than what's called preimplantation genetic diagnosis. So in the U. S. , couples using in vitro fertilization can utilize tests to find out the sex of their fertilized embryos. And you can test for Down syndrome or dwarfism, for example. I should say, though, that Paul and many other researchers are super excited for the use of CRISPR to heal people from debilitating disorders and to really help people - to help make people healthier. This work to splice genes is really amazing and amazingly inexpensive. But as I learned when I covered the future beat for NPR after I got back from Korea, what happens is, there is kind of an arc to these human enhancement technologies or biotech. They go from assistive and therapeutic or medical, as CRISPR is now. But then they move into augmentive (ph) - right? - to bettering ourselves, making us faster, stronger, smarter, and then could reach a place of adaptive, which is actually changing our very selves. And those in that sort of realm we don't consider enough or we don't consider deeply as a population, I think. ZOMORODI: Yeah. I always think, you know, vanity can also (laughter) be a very slippery slope. Because you think, well. . . HU: (Laughter). ZOMORODI: . . . I'll just tweak that one thing, or I'll just. . . HU: Good point. Good point. ZOMORODI: . . . Dye my hair the one time. And then you're dying it for the rest of your life. HU: Back to the question. ZOMORODI: Exactly. HU: Yeah. ZOMORODI: The maintenance thing. HU: Back to the question; where do we draw the line? (SOUNDBITE OF TED TALK)KNOEPFLER: Maybe even if we just look in the mirror, there might be ways we think, you know, we could be better. You know, I might wish honestly that I had more hair here, you know, instead of baldness. Some people might wish they were taller, have a different weight, you know, a different face. If we could do those things, we could make those things happen or we could make them happen in our children, it would be very seductive. And yet, coming with it would be these risks. This technology is so new and so powerful that by accident, we could make them sicker. You know, that easily could happen. And there's another risk. And that is that all of the legitimate, important genetic modification research going on just in the lab - again, no interest in designer babies - a few people going the designer baby route. Things go badly. That entire field could be damaged. HU: Yeah. So Manoush, you know, you're a longtime tech reporter. ZOMORODI: Yes. HU: I'm sure you remember that in 2019 there was that Chinese scientist who announced he created the first genetically modified baby. ZOMORODI: Oh, yes. Yes. HU: This was big news. I got a bunch of news alerts about it. And his work was really widely panned. Most of his fellow researchers were appalled about this. They said this kind of experimentation was totally unethical and far too irresponsible. ZOMORODI: You know, as is often the case with technology, it's really hard to do studies because it's - you know, it's unethical to. . . HU: Right. ZOMORODI: . . . Test things out on humans. HU: Do it on people. ZOMORODI: You can't have the control group and all of those things. But I can see also, you know, for geneticists and other scientists, you know, you want to be the first. You want to be the one who cracks the code. And then, you know, think of how fearful we were when IVF became a thing, the first IVF baby when I was a kid. And at first, that really freaked people out. And now, millions of babies are born via IVF, and nobody really thinks it's that big a deal. (SOUNDBITE OF TED TALK)KNOEPFLER: Five million IVF babies have been born, bringing immeasurable happiness. A lot of parents now can love those kids. But if you think about it, in four decades, 5 million babies being born from a new technology is pretty remarkable. And the same kind of thing could happen with human genetic modification and designer babies. So depending on the decisions we make in the next few months, the next year or so, if Designer Baby No. 1 is born, within a few decades, there could well be millions of genetically modified humans. And there's a difference there, too. Because if we - you know, you in the audience or I, if we decide to have a designer baby, then their children will also be genetically modified and so on. Because it's heritable. So that's a big difference. ZOMORODI: There's one last thing that Paul says, which I think - as both of us have covered technology, there is that - it brings you back to - the question is, what really makes a human a human? Like, we have to consider that before we start optimizing people to any extent, really. (SOUNDBITE OF TED TALK)KNOEPFLER: Let's pretend we're back in that reality. We're at a park, and our kid is swinging on the swing. Is that kid a regular old kid? Or did we decide to have a designer baby? And let's say we went the sort of traditional route. And there's our kids swinging on the swing. And frankly, you know, they're kind of a mess. You know, their hair's all over the place, like mine. They have a stuffy nose. They're not the best student in the world. They're adorable. You love them. But there on the swing next to them, their best friend is a GM kid. And the two of them are kind of swinging like this, and you can't help but compare them, right? And the GM kid is swinging higher. They look better. They're a better student. They don't have that stuffy nose you need to wipe. You know, how is that going to make you feel? And what decision might you make next time? ZOMORODI: I have to admit, no boogers is pretty appealing. But it. . . (LAUGHTER)ZOMORODI: It does seem like in all the conversations we've had and in all the talks that we've heard, it comes down to people constantly comparing themselves to other people. It's just - I mean, it's exhausting. HU: Absolutely. And it certainly comes into play when it comes to our looks, for sure. But this reminds me - this part of his talk really reminds me of one of the lessons of \"Gattaca,\" the science fiction film that portrays this very idea, which is, you know, that there was - there were two brothers, right? And one was the genetically engineered one and the other one was not. He was the normal human and considered really low-class because he wasn't engineered, but then was able to - I don't know if you remember this, but the big line from \"Gattaca\" was, like, that the brother who wasn't able to swim back from the ocean - he didn't save enough for the swim back. And it was the brother who wasn't engineered who had a humanity about him, who had that sort of fire in his belly that you could not engineer for. And so there is something really valuable about that which makes us deeply human. And there are qualities, no matter what specs that we have on the outside or specs that we think are in vogue in the moment, like height, for example - maybe that's not advantageous. Maybe that's not necessarily optimizing. We don't know really because there is kind of magic to ourselves that's irrespective of how we look or how we perform in various fields. ZOMORODI: Well, you're making me feel better about what I say to my daughter, which is that perfection is so incredibly dull and uninteresting, and it's the weirdness and the flaws and the imperfections that make people strange and interesting and worth getting to know. And so far, she seems to be buying it, Elise (laughter). lease and we're to be fair and I love that. HU: Yeah, and we're - to be fair - and I love that. I think that's beautiful. But to be fair, we are not going to give up the quest for self-improvement. There is something that's deeply human about that. . . ZOMORODI: Sure, yeah. HU: . . . Right? - of potential and wanting to be better. And if how we look is so much a part of our identities and ourselves, then of course we're going to want how we look to appear better. And so what I'm circling around as an argument in my book is that we can strive for something that is more deserving of the men and women who do turn to beauty rituals, whether they're trans or cis, and that we can connect to our identities in these sort of self-care or beauty practices without being, like, too baked into one particular ideal - right? - and without spending that much money. What I want to see is a consumer beauty culture that says that you can look like this or this or this or this or that, right? A wider spectrum can really widen our gaze and our sense of normalcy. And it's going to take, you know, changing the people in charge of these companies. It's going to take really changing the way that we are represented in advertisements and in film and in television and in commercials, right? It's going to take norm-setting of that which is more acceptable and widening our lens in the way that we talked about earlier in the show. So I think it's possible. It's just, we're not quite there yet. (SOUNDBITE OF MUSIC)ZOMORODI: I mean, how much does it come down to, as long as all those different ways of being \"beautiful\" - quote, unquote, \"beautiful\" - are accepted, that it's possible as long as the companies showing the pictures and making the products can continue to make money? Because what we're talking about is also a consumer habit, right? HU: Right. Right. So South Korea for a long time did not offer foundation or any sort of cover up that was dark, right? So I couldn't even get the makeup compact that I liked under a certain brand because I was too tan for it. My skin was too dark for it. And now they are really expanding that because of consumer demand. So we can insist - right? - on some reform. We can insist on more diversity, more variety, more color - more literal color - and more acceptable norms. It's going to take pushing for it and more of the people who are bucking trends, like the Escape the Corset movement. And it's going to take more conversation like the ones we're having. (SOUNDBITE OF MUSIC)ZOMORODI: Elise Hu is host of the \"TED Talks Daily\" podcast. She makes all kinds of cool stuff for NPR. You can see all the talks that we discussed on this episode at ted. com. Elise, thank you so much again. HU: Thank you for having me. You know I love talking to you, so this was fantastic. ZOMORODI: This episode was produced by Sylvie Douglis, James Delahoussaye and Rachel Faulkner. It was also edited by Rachel Faulkner. Our Ted Radio production staff also includes Jeff Rogers, Sanaz Meshkinpour, Diba Mohtasham, Katie Monteleone and Matthew Cloutier. Our audio engineer is Daniel Shukin. Our intern is Harrison Vijay Tsui. Our theme music was written by Ramtin Arablouei. Our partners at TED are Chris Anderson, Colin Helms, Anna Phelan, Michelle Quint and Micah Eames. I'm Manoush Zomorodi, and you've been listening to the TED Radio Hour from NPR. (SOUNDBITE OF MUSIC) MANOUSH ZOMORODI, HOST:   It's the TED Radio Hour from NPR. I'm Manoush Zomorodi. And on the show today, ideas about beauty. ELISE HU, BYLINE: I have been thinking about beauty culture and appearance standards a lot these days - how much beauty means to us, not just as women or men, but as society. ZOMORODI: If this voice sounds familiar, it's because you've heard her all over NPR. It's our very own Elise Hu. And in 2015, Elise moved to Korea to open up NPR's bureau in Seoul, a city which, in the past few years, has emerged as a cosmetics and skin care superpower. HU: When I first got to Seoul, the sort of pervasiveness and dominance of a really specific beauty standard and beauty norms was everywhere. The night I got to Seoul, I was staying in Myeong-dong, which happens to be the makeup district, where every store is lit up, up and down the street, by images of skin care products and women with these sort of alabaster skin faces. And every single store is the name of some sort of makeup brand. And so you can have kind of the face shop across from another face shop across from another face shop. And so it's like trick-or-treat, but for skin care products. So it was made very obvious to me as soon as I landed in Korea, the dominance of the skin care industry, but also appearance standards and the importance of looking a certain way. ZOMORODI: Elise wanted to see what it was like to follow all these Korean beauty trends. And so she did in a series called \"Elise Tries. \" (SOUNDBITE OF ARCHIVED RECORDING) HU: Skin care in South Korea is serious business, with South Korean women spending twice as much of their income on beauty products as American women. Really go in for the excavation. Oh, yeah. I think she's getting my nose pores. Mmm hmm. Oh, geez, you can hear it. Oh, dear. Oh, geez. I can actually feel stuff being sucked up. I want this off my face so bad because I feel like I'm, like - I'm feeling a little claustrophobic. Oh, my gosh. ZOMORODI: Today, Elise is writing a book about beauty - particularly K-beauty, as it's called. HU: I'm really fascinated by it. And I'm fascinated by the power of beauty ideals, politically, economically, but most important, culturally. ZOMORODI: Which is why we've invited her to be our guide on this episode. Because not only is she on NPR and researching this topic, Elise also hosts the \"TED Talks Daily\" podcast. So she watches a lot of TED talks. Elise, you are going to take us through a selection of TED talks about beauty norms or questioning the beauty ideal, not just in Korea, but all over the world. And there are so many layers to this topic, right? HU: Yes. Yes. So I went to Korea. I learned all of this stuff. But I didn't want to simply eviscerate Korean beauty because I take the industry and its growth and the influence of beauty really seriously. And I think that the pursuit of beauty is kind of a tentpole of the modern female experience, right? And my hope is just to kind of really take it seriously and make room in our conversations and in our minds for thinking through it and how the so-called beauty industrial complex plays a role in our experiences and our identities, right? We see so many digital images all the time flashing before us. And that kind of helps solidify norms of how we should appear in our sort of consciousness, right? And what I really wanted to dig into is the work that it takes to appear, quote, unquote, \"beautiful. \" It requires a lot of maintenance. It requires a lot of work. And it requires a lot of spending money on products or makeup or procedures. And that's just to kind of keep up with the Joneses - right? - of appearance standards. Because if you don't sort of meet those aesthetic norms, that'll cost you. (SOUNDBITE OF MUSIC) ZOMORODI: So we want to kick off our conversation with a talk about the influence that social media has had on how people think of beauty and also the sort of mental health for mostly young women. So the first talk is by two twins who live in Canada - Teagan and Keisha Simpson. They gave a talk in 2019 called \"Can Our Body Image Handle Social Media? \" (SOUNDBITE OF TEDx TALK) KEISHA SIMPSON: Different ages use and interact with Instagram differently. For example, if we were all to pull out our phones right now, what you would see on your account would be very different from what I would see because it all depends on who you follow. I'm going to take the guess the majority of you don't follow hundreds of young women. TEAGAN SIMPSON: But I do. When I go on Instagram, I'm overwhelmed by photos of girls my age, many of which are posed and perfected versions of my friends and mere acquaintances. What a teenage girl sees on Instagram is drastically different from what the average adult sees. And over time, scrolling through these photos can really take a toll on your self-esteem. With a quick Google search, we found numerous studies that link social media to increasing levels of anxiety, depression, loneliness and body image issues in young women. But could our friends really be feeling this way, too? K SIMPSON: No. No way. There's no way. Because when we go on Instagram, what we see are happy, beautiful and confident people. There's no way that these girls are going through the same thing that we are. Yet the more we researched and Googled, the more concern we felt. ZOMORODI: Elise, just listening to these young women is stressing me out because there are many worrying studies that link social media to depression, even suicidal thoughts, especially for teenage girls. But there might be some people who are thinking, well, then just don't go on social media. How would you explain it to people who maybe just don't understand what young women are dealing with these days? HU: Well, this visual culture doesn't just get propagated on Instagram or on TikTok or places where teenagers spend time, right? How we look and how we're supposed to look is communicated in so many different channels and across so many different ways that we receive images and are bombarded with images. So all of us are part of it universally because all of us are connected to the web, you know, in the developed world. And all of us are kind of being fed images constantly. So even if you think that you are not part of this sort of cycle of imagery and the norm-setting, you are. (SOUNDBITE OF MUSIC) ZOMORODI: OK. So another thing that Teagan and Keisha bring up is just how common it is today to edit and filter yourself - your photos - on social media. (SOUNDBITE OF TEDx TALK) K SIMPSON: The biggest surprise for Teagan and I was how many young women admitted to using Photoshop regularly. I could go on right now, and in a few moments, I could have a photo of myself with longer legs, a thinner waist. I could remove acne, remove a fat roll. Or I could even give myself that perfectly round butt that everyone is talking about. T SIMPSON: Now, these issues aren't new. We've been comparing ourselves to photoshopped images forever. I'm sure many of us have been in a grocery store where we opened up a magazine, scanning through pages of perfectly photoshopped, beautiful people. But what if you opened up these magazines and the photos were of your friends? ZOMORODI: Elise, from what I understand, one of the most popular photo editing apps, Facetune, reportedly had 20% more usage, as they say, at the start of the pandemic, and then - I'll make a little confession here that I was spending so much time on Zoom and was so tired during the pandemic that I did use the Zoom filter to make my skin look a little better. HU: And why not? ZOMORODI: Well, I don't know. It's not - you know, in the name of truth, like, where do we start to draw the line? What have you been hearing about this? Like, and to what extremes will people go to try to make what is fake - let's just call it that - a reality? HU: Yeah. So one of the questions that I'm asking is, A, where do we draw the line when it comes to self-improvement? That's a key question. But B, because the norms that we're seeing on Zoom or on Instagram or on TikTok are so enhanced, then what we start believing is normal becomes more and more narrow, right? Because everybody's skin is enhanced. You know, everybody's chin is a little bit thinner. And researchers say that there's kind of a global mean. There are four aspects of beauty that, irrespective of where you are in the world, people aspire to. And it's smoothness, firmness, thinness and youth. And the thinness can be relative to your population. So thin in Asia is thinner than, say, thin in Northern Europe. And what results is that all women, and increasingly numbers of men, need surgical and non-surgical technical fixes if we are to be perfect like those filters, right? Even just good enough is getting harder to achieve as these norms become more and more dominant because it makes it harder for us to resist. ZOMORODI: You know, it makes me think, like, as with many things with technology, at least here in the U. S. , there is very little oversight. And I read with total fascination that Norway recently passed a law that says influencers and brands must identify photos on social media that have been retouched. And, you know, just to go back to Keisha and Teagan Simpson, they kind of had a similar idea. More of a grassroots way of going about it, but they challenged people to post untouched photos of themselves and to see what that feels like. (SOUNDBITE OF TEDx TALK) K SIMPSON: What if we could improve the Instagram experience? Could we balance the perfected photos with unfiltered ones? Last year, we ran a campaign to do just this. It was called the As She Is challenge, where young women are encouraged to post an unfiltered photo to our hashtag, #AsSheIs. T SIMPSON: This is a typical post from one participant's Instagram account. Clearly, she's beautiful. But on the day of the challenge, this is the photo she chose to post. Vulnerable and courageous, she talks about her facial acne and her use of filters to cover it up. This young woman's willingness to be unfiltered made a real impact on her followers, and admittedly, also herself. From our experience, when young women are willing to be vulnerable, they express a sense of relief, freedom from accepting and admitting that they have insecurities. (SOUNDBITE OF MUSIC) HU: I applaud these women, and I support that they are trying to keep the window of what's normal inclusive of how we really look. Because one of my concerns as somebody who's now researching beauty is that our appearance norms, especially because of filters, become so far removed from actually what we normally look like. And so I love that they are maintaining a space and, in fact, encouraging all of us to show up as we really are. (SOUNDBITE OF MUSIC) ZOMORODI: When we come back, more from Elise Hu on interrogating the beauty ideal. I'm Manoush Zomorodi, and you are listening to the TED Radio Hour from NPR. It's the TED Radio Hour. I'm Manoush Zomorodi, and I am so pleased to be spending the hour with longtime journalist Elise Hu. She is the host of TED Talks Daily, and she is working on a book about beauty norms, beauty standards and why we think someone is beautiful but not someone else and all the work we have to do to be, quote-unquote, \"beautiful,\" right, Elise? HU: That's right. You packed a lot into that, and thank you. ZOMORODI: OK. So the next TED Talk that you have brought us, it's a fascinating one. It is from a woman named Sasha Sarago. She is an Aboriginal writer and model in Australia, and she gave this talk in 2020. And so just let's get right into it. Sasha starts off telling a story from a few decades earlier when she was a preteen at a friend's birthday party, and a friend's sister asked her the question, so what's your background? (SOUNDBITE OF TED TALK) SASHA SARAGO: And, like any proud Aboriginal child would declare, I'm Aboriginal. Given the reaction of the room, being Aboriginal was clearly a dirty word. And at the tender age of 11, I was told by my best friend's adult sister that I was too pretty to be Aboriginal. By this time, my mouth is dry. My blood is boiling. And I'm trying so hard to fight back what feels like an ocean of tears. I calmly join my circle of friends and begin to (laughter) fake laugh at whatever is funny to mask my embarrassment as I clutch on to my newfound complex. And this is why we need to change our perceptions of beauty. And how we do this is by learning from Aboriginal women, their stories and perspectives, because right now pretty hurts. Pretty hurts because you're trying to erase my Aboriginality to applaud my proximity to whiteness. Pretty hurts because, aimed at an Aboriginal woman, it is a weapon loaded in racism, sexual exploitation and cultural genocide. You see; what this woman didn't realize when she declared that I was too pretty to be Aboriginal is that she took something precious from me - pride in my identity. You see; I belong to the oldest living culture in the world, but that day, that legacy, it was replaced with shame. And it's been this filthy stain I've been trying to get rid of for 20 years. (SOUNDBITE OF MUSIC) HU: That really resonates with me so much and is arguably responsible for why I still wrestle with these questions of beauty because when I was a teenager, I remember - I'm an Asian American and so not part of the dominant group, especially not in suburban Texas, where I grew up. And I remember when I was in 9th or 10th grade, a boy said to me, you're pretty hot for an Oriental. So that kind of just backhanded compliment-slash-out-grouping at the same time, you know, it does make you feel and internalize a sense of shame. And that's such a shame, right? ZOMORODI: Yeah. And, actually, Sasha goes right on to say that the way that Aboriginal women define beauty is completely different. She actually goes on to tell a traditional story about a fisherwoman named Barangaroo, a famously defiant female ancestor who lived in the 18th century. (SOUNDBITE OF TED TALK) SARAGO: Barangaroo, like the other Eora women, took pride in their status as being main food providers for their tribe. A skillful and patient fisherwoman, Barangaroo would access Sydney Harbor and its surrounding waters for its abundant food supply, only taking what was needed. So you can just imagine how furious Barangaroo was when she saw British colonists trawl 4,000 salmon off the north shore in just one day, then gifting some of this catch to her husband and some of the other men from her tribe. Barangaroo knew such a wasteful act would threaten the Eora women's cultural authority within the tribe, furthermore destroying their traditional way of life. So Barangaroo rejected British laws and customs, their food, drink and social etiquette, even when her husband decided to conform. When Barangaroo and her husband Bennelong was invited to dine with Governor Philip and the British party, Barangaroo stayed true to who she was. Instead of wearing colonial attire - a tight corset and a gown layered in silk - she came sporting her traditional wears - white ochre and a bone through her nose. What Barangaroo illustrated was Indigenous beauty is authentic. (SOUNDBITE OF MUSIC) ZOMORODI: What a beautiful story. HU: Yeah. ZOMORODI: And I love that it's passed on through the generations as something to sort of hold onto, that beautiful can be defined in different ways by different cultures. Do you know of any other cultures in which, I guess, very specific beauty ideals have held strong in the face of more - sort of the more homogenous, Eurocentric, Western look? HU: Yeah. And, just to be fair, we are seeing a more homogenous look, but it's not necessarily Eurocentric, right? There is a more homogeneous look that - in Asia, that is a competing standard against kind of a real Eurocentric look. So we should note that. But it is harder to find examples of regional or local norms that really hold strong because we are all so connected on this global internet. Local norms still do exist in pockets of the world. I just think what's considered sort of globally beautiful is now something that we see and is becoming more and more flattened. ZOMORODI: Yeah, because, as you say, we're all looking at the same web. . . HU: Exactly. ZOMORODI: . . . Which, actually, I think, is one of the reasons why Sasha, by the way, started what she says is Australia's first Indigenous and ethnic women's lifestyle blog and magazine. HU: Cool. ZOMORODI: But she does say in her talk that it really took her a while to figure out how to appreciate her and her people's roots and their conception of beauty. (SOUNDBITE OF TED TALK) SARAGO: Over the years, my obsession for beauty, it's led me to this truth. You cannot appreciate beauty if you cannot recognize it in yourself. So how do we change our perceptions of beauty? We have to get real with ourselves and start by asking, who am I? Where do I come from? The world that I live in, how did it come to be? And, more importantly, where to from here? You may not like what you discover, but sit with it. Feel the discomfort. Colonization has stolen from us one of the greatest treasures we can obtain - each other. ZOMORODI: That is a big topic. There's lots to unpack here. HU: Yeah. I am actually deep in the research on how colonization really has affected beauty norms. Double eyelid surgery, for example, which is the most popular procedure in South Korea, was brought to South Korea and, arguably, invented by a plastic surgeon named David Millard, who was a U. S. Army physician. . . ZOMORODI: Oh, wow. HU: . . . And plastic surgeon who was stationed on Yongsan, which is the U. S. military base in South Korea following the Korean War. And he originally did this surgery - this is to create a crease in your eyelid if you weren't born with one. And David Millard said it was so that his patients could look more white. ZOMORODI: I mean, that is deeply, deeply troubling in many ways. But what about people, Elise, who are saying, you know what - I'm done with this? Is there a backlash to all of this? HU: In South Korea, there's a movement called Escape the Corset, where women are collectively crushing their makeup compacts on Instagram and on TikTok and shaving their heads or cutting their hair really short. It is their form of resistance and since it has cost them. It's been so costly to try and keep up with appearance standards, not just financially but also emotionally, mentally, intellectually. But the beauty industry seems to be bouncing right back, and so it's really hard to see whether resistance is having an impact. ZOMORODI: You know, I think that's interesting because, in a way, it segues nicely to the next talk that you brought us. . . HU: Yeah. ZOMORODI: . . . Which is about the opposite end of the spectrum. HU: Yes. So one community or a few communities that really celebrate sort of the traditional femme idea of beauty is the transgender community, as well as the drag community, where you can really sort of go after these adornments and wear these adornments and makeup and glitter and what's considered traditionally feminine displays. That's a really powerful way of either coming out or feeling like you can wear on the outside what you feel on the inside. (SOUNDBITE OF MUSIC) ZOMORODI: So the next talk is by the model Hari Nef, and she gave a talk in 2016 called \"The Aesthetics Of Survival. \" (SOUNDBITE OF TEDx TALK) HARI NEF: Remember when Caitlyn Jenner revealed herself on the cover of Vanity Fair? ZOMORODI: She starts her talk by projecting a picture of Caitlyn Jenner on the cover of Vanity Fair. And I don't know if you remember, Elise, but Caitlyn Jenner is looking extremely glamorous - lots of makeup, big hair. . . HU: Oh, the corset. ZOMORODI: The corset, exactly. (SOUNDBITE OF TEDx TALK) NEF: I've got a lot to say about her conservative politics and her bumpy advocacy, but this was cool. ZOMORODI: But it also started a conversation and a lot of pushback because there were some people who felt that this was the ultimate anti-feminist thing to do, to pose like that, because by posing like that, Caitlyn Jenner was just fulfilling stereotypical male fantasies. But Hari disagrees. (SOUNDBITE OF TEDx TALK) NEF: If you ask me, hair, makeup and nails don't make trans women like me - or any woman, for that matter - bad feminists. And, sure, what if Caitlyn had appeared on the cover of Vanity Fair in a pantsuit with no makeup, her hair pulled back, arms crossed? Yes, I think she would have looked really cool. But would we all have accepted her so readily as a woman? Would she have appeared on the cover of Vanity Fair to begin with? It's time for the aesthetics of upwardly mobile feminist respectability to make room for the aesthetics of survival, particularly trans survival. It's time to revise what a feminist looks like, especially if hair, makeup and nails allow her to get jobs, make friends or ride the subway home safely at night. It's time to free the femme because some of us need it or just like it, and that's OK. (SOUNDBITE OF MUSIC) ZOMORODI: OK. So I think it's important that we bring up here why there was such a backlash. And it's - really comes down to the reaction from some second-wave feminists saying, you know, that women don't have to be super glam. They don't have to be super feminine, that this was, you know, taking us backwards by having Caitlyn Jenner look like that. HU: Yeah, so during the sort of consciousness-raising era of the '70s when second-wave feminism was in vogue, the idea was that to look very feminine was also to adhere to traditional gender roles of having to be at home and not having as many paths to economic independence. But yeah, we talk so much - we have had so much of this conversation dominated by sort of critiquing narrow beauty standards. And this is another way to critique narrow beauty standards from Hari here. It's to say that beauty standards should not just be a rejection of what's traditionally femme, but should also include an acceptance of femme if that's what it takes for survival. (SOUNDBITE OF TEDx TALK) NEF: Under patriarchy, money and country inscribe themselves on women's bodies. We look in the mirror, and we ask ourselves, huh, do I look like a rich woman today? We look in the mirror and say, huh, do I look like an American woman today? We look in the mirror and say, huh, do I look like a beautiful woman today? And if I don't look rich, beautiful and American, am I still a woman? Here's a picture of me before I started transitioning - or I had started transitioning, but I hadn't started medical transition yet. At this point in my life, I wore a full face of makeup every day. I shaved my whole body every week, which covered me in these angry red spots. I stopped cutting my hair. I wore dresses to morning classes. I started hormones - pills twice a day and a needle in my leg every week. I started going in for monthly laser hair removal appointments - procedures that were so painful that I had to chug a flask of vodka before every session just so I'd feel it less. I starved myself and abused laxatives so I could fit the clothes I wanted to wear. I did all this 'cause I wanted a body that allowed me to do the things I wanted to do in the way I wanted to do them, things men in this country aren't really allowed to do. I tried to do them in the body I was born with, but people told me, no, you can't. You got to soften up your face, get rid of all your body hair, get breasts, shrink your waist, get a vagina. Of course, I looked them right in the eye, said [expletive] you, turned around and did pretty much all of what they told me to do. (LAUGHTER) NEF: It hurt, and it worked. And if my story or journey sounds difficult or tough, I can guarantee you it's even more difficult and more tough for the vast majority of trans women. ZOMORODI: Oh, that is so hard to hear, especially the part when Hari admits she feels that she needed to suffer all that pain to achieve what she wanted. And then, she alludes to the violence that many trans women also suffer. HU: Yes, yes. According to one study, trans people are four times as likely to have violent crimes perpetrated against them compared to cisgendered people. One in two transgender individuals are sexually abused or assaulted at some point in their lives. Some reports even estimate that transgender survivors may experience rates of sexual assault up to 66%, and that's often coupled with physical assaults or abuse. ZOMORODI: So upsetting. And Hari points out that this idealized version of femininity is essentially meeting a patriarchal standard, standards set by men. But she also says that while meeting those standards, well, that can mean survival for some trans women. For others, it is a goal in and of itself. But the process, whoa - it can be long and extremely tough. (SOUNDBITE OF TEDx TALK) NEF: It is so hard to gain access to hormones, to jump through all the medical hoops. It is so expensive to buy cosmetics, new clothes, healthy food, any number of means towards body feminization. And yeah, even if a trans woman does manage to look or seem femme, her race, her class or her citizenship can place further targets on her back. So when it comes to trans women with limited resources, their femme can be the difference between life and death. So I got to ask, why are we being shamed for our femme? Let femmes be femmes if they want to be femme because some of us need it or just want it, and that's OK. When the aesthetics of feminist respectability exclude and erase the women who need - not just want, need - to give them up, then the aesthetics of feminist respectability need to change. Femme aesthetics aren't bad or good. They just work. They just are. They work for some of us. So chill out. (LAUGHTER) NEF: Let us live. Free the femme. Thank you. (APPLAUSE) ZOMORODI: That was model Hari Nef. You can see her full talk at ted. com. In just a minute, we'll continue our conversation with Elise Hu. On the show today, reflecting on and challenging our beauty norms. I'm Manoush Zomorodi, and you're listening to the TED Radio Hour from NPR. (SOUNDBITE OF MUSIC) ZOMORODI: It's the TED Radio Hour from NPR. I'm a Manoush Zomorodi. And on today's show, the beauty ideal - the beauty ideal. So far, we've heard a TED Talk about Instagram. (SOUNDBITE OF TEDx TALK) K SIMPSON: There's new apps that allow us to digitally alter the way we look. ZOMORODI: How teens feel tremendous pressure to Photoshop themselves to look flawless. (SOUNDBITE OF TEDx TALK) K SIMPSON: And in a few moments, I could have a photo of myself with longer legs, a thinner waist. I could remove acne, remove a fat roll. (SOUNDBITE OF TED TALK) SARAGO: You see, I belong to the oldest living culture in the world. ZOMORODI: We heard from a woman finding strength through her Aboriginal beauty culture. (SOUNDBITE OF TED TALK) SARAGO: When we decolonize beauty, we are reintroduced to our authentic selves. (SOUNDBITE OF TEDx TALK) NEF: It's time to revise what a feminist looks like. ZOMORODI: And we learned that traditional femme standards criticized by some can be a real lifesaver for some trans women. (SOUNDBITE OF TEDx TALK) NEF: Especially if hair, makeup and nails allow her to get jobs, make friends or ride the subway home safely at night. ZOMORODI: Riding shotgun with me is Elise Hu, host of the \"TED Talks Daily\" podcast. She is also writing a book about this subject. Hello, Elise. HU: Hello, Manoush. ZOMORODI: And Elise, a constant theme running throughout our episode so far has been body modification - right? - the good and the bad. HU: One of the biggest questions that I wrestle with as I research and write this book is how do we square the beauty ideal in a virtual world and a real world when the lines between the worlds are getting so blurred? And there's not only the technology of sort of self-surveillance, the idea of sort of cameras in our pockets and us being able to see one another all the time and then surveilling ourselves because we're aware that we're seen all the time. So that's one kind of technology. The other is the technology of self-improvement because there are so many beauty filters that normalize or teach us the ideals. Then, we sort of fall into that, and we start to chase that in a way that appears not only in our images but maybe on the living canvas, maybe on our actual bodies because that's becoming more and more accessible in lots of places in the developed world. ZOMORODI: And I think that also brings us to our final talk. . . HU: Yeah. ZOMORODI: . . . About potentially the future of beauty. And that's gene editing, right? The last Talk that you've brought us from biologist Paul Knoepfler - his talk is called \"The Ethical Dilemma Of Designer Babies. \" And he starts by taking us to the not-so-distant future. (SOUNDBITE OF TEDx TALK) PAUL KNOEPFLER: Let's pretend it's the year 2030, and you're a parent. You have your daughter, Marianne (ph), next to you. And in 2030, she is what we call a natural because she has no genetic modifications. And because you and your partner consciously made that decision, many in your social circle - they kind of look down on you. They think you're, like, a Luddite or a technophobe. Marianne's best friend Jenna (ph), who lives right next door, is a very different story. She was born a genetically modified designer baby with numerous upgrades. And it's become very clear to you that Jenna is extraordinary. She's incredibly intelligent. If you're honest with yourself, she's smarter than you, and she's 5 years old. She's beautiful, tall, athletic, and the list goes on and on. And in fact, there's a whole new generation of these GM kids like Jenna. And so far, it looks like they're healthier than their parents' generation, than your generation. And they have lower health care costs. They're immune to a host of health conditions, including HIV/AIDS and genetic diseases. It all sounds so great. ZOMORODI: It does all sound so great. On the one hand, I'm like, awesome, a healthy child who doesn't have to deal with disastrous illnesses in their lifetime ever. But on the other hand, this idea of, like, an upgraded kid - it is creepy. Elise, like, how far-fetched is this scenario? HU: Yeah, scientists range in their opinions on how far-fetched this is. But Paul is a stem cell researcher, and he spends a lot of time thinking about how we can use gene therapy in a helpful way - right? - gene engineering to really be therapeutic. But he's also worried that this technology, like CRISPR, could be used by families of rich people with deep pockets to alter their future children and give them this advantage that would really create an unfair playing field. This is one of the big ethical questions that comes up when we talk about CRISPR. And we've seen how it could play out in books and movies. . . ZOMORODI: Yes. HU: . . . About the future. (SOUNDBITE OF FILM, \"GATTACA\") UNIDENTIFIED NARRATOR: In the not-too-distant future. . . ZOMORODI: \"Gattaca,\" I'm thinking of. (SOUNDBITE OF FILM, \"GATTACA\") UNIDENTIFIED NARRATOR: . . . Our DNA will determine everything about us. HU: Such a great film. But what I thought was really powerful about it, for those of y'all who haven't seen it, is that we engineer that which we find perfect or ideal at a given time. And when we look back on that film, we have the opportunity to really rethink what they thought was perfect at that time, right? And that ideal is fluid, and it's expansive. So it's worrying to lock ourselves into one ideal of perfection when you have the power to genetically modify babies. ZOMORODI: Yeah. When he was like, she's perfect, she's tall, I was like, hang on a minute. As a short person, who do you get to - I don't - I wouldn't want to have, like, weird extremely tall children. Then they. . . (LAUGHTER) ZOMORODI: . . . As a short person. But OK, so where does the law stand on this? If someone wanted to have a designer baby - I mean, you can certainly pick the sex of your child, and you can screen for certain illnesses. But can you make them tall or beautiful or have a higher IQ? HU: Not right now. Not right now. The U. S. and dozens of other countries around the world have specifically made the implantation of genetically modified human embryos illegal. ZOMORODI: OK. HU: Now, that's different than what's called preimplantation genetic diagnosis. So in the U. S. , couples using in vitro fertilization can utilize tests to find out the sex of their fertilized embryos. And you can test for Down syndrome or dwarfism, for example. I should say, though, that Paul and many other researchers are super excited for the use of CRISPR to heal people from debilitating disorders and to really help people - to help make people healthier. This work to splice genes is really amazing and amazingly inexpensive. But as I learned when I covered the future beat for NPR after I got back from Korea, what happens is, there is kind of an arc to these human enhancement technologies or biotech. They go from assistive and therapeutic or medical, as CRISPR is now. But then they move into augmentive (ph) - right? - to bettering ourselves, making us faster, stronger, smarter, and then could reach a place of adaptive, which is actually changing our very selves. And those in that sort of realm we don't consider enough or we don't consider deeply as a population, I think. ZOMORODI: Yeah. I always think, you know, vanity can also (laughter) be a very slippery slope. Because you think, well. . . HU: (Laughter). ZOMORODI: . . . I'll just tweak that one thing, or I'll just. . . HU: Good point. Good point. ZOMORODI: . . . Dye my hair the one time. And then you're dying it for the rest of your life. HU: Back to the question. ZOMORODI: Exactly. HU: Yeah. ZOMORODI: The maintenance thing. HU: Back to the question; where do we draw the line? (SOUNDBITE OF TED TALK) KNOEPFLER: Maybe even if we just look in the mirror, there might be ways we think, you know, we could be better. You know, I might wish honestly that I had more hair here, you know, instead of baldness. Some people might wish they were taller, have a different weight, you know, a different face. If we could do those things, we could make those things happen or we could make them happen in our children, it would be very seductive. And yet, coming with it would be these risks. This technology is so new and so powerful that by accident, we could make them sicker. You know, that easily could happen. And there's another risk. And that is that all of the legitimate, important genetic modification research going on just in the lab - again, no interest in designer babies - a few people going the designer baby route. Things go badly. That entire field could be damaged. HU: Yeah. So Manoush, you know, you're a longtime tech reporter. ZOMORODI: Yes. HU: I'm sure you remember that in 2019 there was that Chinese scientist who announced he created the first genetically modified baby. ZOMORODI: Oh, yes. Yes. HU: This was big news. I got a bunch of news alerts about it. And his work was really widely panned. Most of his fellow researchers were appalled about this. They said this kind of experimentation was totally unethical and far too irresponsible. ZOMORODI: You know, as is often the case with technology, it's really hard to do studies because it's - you know, it's unethical to. . . HU: Right. ZOMORODI: . . . Test things out on humans. HU: Do it on people. ZOMORODI: You can't have the control group and all of those things. But I can see also, you know, for geneticists and other scientists, you know, you want to be the first. You want to be the one who cracks the code. And then, you know, think of how fearful we were when IVF became a thing, the first IVF baby when I was a kid. And at first, that really freaked people out. And now, millions of babies are born via IVF, and nobody really thinks it's that big a deal. (SOUNDBITE OF TED TALK) KNOEPFLER: Five million IVF babies have been born, bringing immeasurable happiness. A lot of parents now can love those kids. But if you think about it, in four decades, 5 million babies being born from a new technology is pretty remarkable. And the same kind of thing could happen with human genetic modification and designer babies. So depending on the decisions we make in the next few months, the next year or so, if Designer Baby No. 1 is born, within a few decades, there could well be millions of genetically modified humans. And there's a difference there, too. Because if we - you know, you in the audience or I, if we decide to have a designer baby, then their children will also be genetically modified and so on. Because it's heritable. So that's a big difference. ZOMORODI: There's one last thing that Paul says, which I think - as both of us have covered technology, there is that - it brings you back to - the question is, what really makes a human a human? Like, we have to consider that before we start optimizing people to any extent, really. (SOUNDBITE OF TED TALK) KNOEPFLER: Let's pretend we're back in that reality. We're at a park, and our kid is swinging on the swing. Is that kid a regular old kid? Or did we decide to have a designer baby? And let's say we went the sort of traditional route. And there's our kids swinging on the swing. And frankly, you know, they're kind of a mess. You know, their hair's all over the place, like mine. They have a stuffy nose. They're not the best student in the world. They're adorable. You love them. But there on the swing next to them, their best friend is a GM kid. And the two of them are kind of swinging like this, and you can't help but compare them, right? And the GM kid is swinging higher. They look better. They're a better student. They don't have that stuffy nose you need to wipe. You know, how is that going to make you feel? And what decision might you make next time? ZOMORODI: I have to admit, no boogers is pretty appealing. But it. . . (LAUGHTER) ZOMORODI: It does seem like in all the conversations we've had and in all the talks that we've heard, it comes down to people constantly comparing themselves to other people. It's just - I mean, it's exhausting. HU: Absolutely. And it certainly comes into play when it comes to our looks, for sure. But this reminds me - this part of his talk really reminds me of one of the lessons of \"Gattaca,\" the science fiction film that portrays this very idea, which is, you know, that there was - there were two brothers, right? And one was the genetically engineered one and the other one was not. He was the normal human and considered really low-class because he wasn't engineered, but then was able to - I don't know if you remember this, but the big line from \"Gattaca\" was, like, that the brother who wasn't able to swim back from the ocean - he didn't save enough for the swim back. And it was the brother who wasn't engineered who had a humanity about him, who had that sort of fire in his belly that you could not engineer for. And so there is something really valuable about that which makes us deeply human. And there are qualities, no matter what specs that we have on the outside or specs that we think are in vogue in the moment, like height, for example - maybe that's not advantageous. Maybe that's not necessarily optimizing. We don't know really because there is kind of magic to ourselves that's irrespective of how we look or how we perform in various fields. ZOMORODI: Well, you're making me feel better about what I say to my daughter, which is that perfection is so incredibly dull and uninteresting, and it's the weirdness and the flaws and the imperfections that make people strange and interesting and worth getting to know. And so far, she seems to be buying it, Elise (laughter). lease and we're to be fair and I love that. HU: Yeah, and we're - to be fair - and I love that. I think that's beautiful. But to be fair, we are not going to give up the quest for self-improvement. There is something that's deeply human about that. . . ZOMORODI: Sure, yeah. HU: . . . Right? - of potential and wanting to be better. And if how we look is so much a part of our identities and ourselves, then of course we're going to want how we look to appear better. And so what I'm circling around as an argument in my book is that we can strive for something that is more deserving of the men and women who do turn to beauty rituals, whether they're trans or cis, and that we can connect to our identities in these sort of self-care or beauty practices without being, like, too baked into one particular ideal - right? - and without spending that much money. What I want to see is a consumer beauty culture that says that you can look like this or this or this or this or that, right? A wider spectrum can really widen our gaze and our sense of normalcy. And it's going to take, you know, changing the people in charge of these companies. It's going to take really changing the way that we are represented in advertisements and in film and in television and in commercials, right? It's going to take norm-setting of that which is more acceptable and widening our lens in the way that we talked about earlier in the show. So I think it's possible. It's just, we're not quite there yet. (SOUNDBITE OF MUSIC) ZOMORODI: I mean, how much does it come down to, as long as all those different ways of being \"beautiful\" - quote, unquote, \"beautiful\" - are accepted, that it's possible as long as the companies showing the pictures and making the products can continue to make money? Because what we're talking about is also a consumer habit, right? HU: Right. Right. So South Korea for a long time did not offer foundation or any sort of cover up that was dark, right? So I couldn't even get the makeup compact that I liked under a certain brand because I was too tan for it. My skin was too dark for it. And now they are really expanding that because of consumer demand. So we can insist - right? - on some reform. We can insist on more diversity, more variety, more color - more literal color - and more acceptable norms. It's going to take pushing for it and more of the people who are bucking trends, like the Escape the Corset movement. And it's going to take more conversation like the ones we're having. (SOUNDBITE OF MUSIC) ZOMORODI: Elise Hu is host of the \"TED Talks Daily\" podcast. She makes all kinds of cool stuff for NPR. You can see all the talks that we discussed on this episode at ted. com. Elise, thank you so much again. HU: Thank you for having me. You know I love talking to you, so this was fantastic. ZOMORODI: This episode was produced by Sylvie Douglis, James Delahoussaye and Rachel Faulkner. It was also edited by Rachel Faulkner. Our Ted Radio production staff also includes Jeff Rogers, Sanaz Meshkinpour, Diba Mohtasham, Katie Monteleone and Matthew Cloutier. Our audio engineer is Daniel Shukin. Our intern is Harrison Vijay Tsui. Our theme music was written by Ramtin Arablouei. Our partners at TED are Chris Anderson, Colin Helms, Anna Phelan, Michelle Quint and Micah Eames. I'm Manoush Zomorodi, and you've been listening to the TED Radio Hour from NPR. (SOUNDBITE OF MUSIC)", "section": "TED Radio Hour", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-08-20-1029436872": {"title": "Bitcoin And Cryptocurrencies Will Get Tougher Rules. What To Know : NPR", "url": "https://www.npr.org/2021/08/20/1029436872/tougher-rules-are-coming-for-bitcoin-and-other-cryptocurrencies-heres-what-to-kn", "author": "No author found", "published_date": "2021-08-20", "content": "", "section": "Business", "disclaimer": ""}, "2021-08-21-1030038616": {"title": "Facebook's Most Viewed Article In Early 2021 Raised Doubt About COVID Vaccine : NPR", "url": "https://www.npr.org/2021/08/21/1030038616/facebooks-most-viewed-article-in-early-2021-raised-doubt-about-covid-vaccine", "author": "No author found", "published_date": "2021-08-21", "content": "", "section": "Untangling Disinformation", "disclaimer": ""}, "2021-08-21-1030023077": {"title": "Behind The OnlyFans Ban Of Sexually Explicit Content : NPR", "url": "https://www.npr.org/2021/08/21/1030023077/behind-the-onlyfans-ban-of-sexually-explicit-content", "author": "No author found", "published_date": "2021-08-21", "content": "MICHEL MARTIN, HOST:  We wanted to talk more about the surprise announcement this week by the online subscription service OnlyFans that it will bar sexually explicit content from its site starting in October. OnlyFans said its decision to remove explicit content from the platform was prompted by its, quote, \"banking partners and payout providers,\" unquote, the companies that allow users to pay for their subscriptions. But the announcement was a surprise because OnlyFans is best known precisely for its sexually explicit content, even if its estimated 2 million creators are free to offer other fare. We wanted to hear more about this, so we called Taylor Lorenz, who reports on tech and culture for The New York Times. We wanted her to tell us more about the site and what's behind this change. And I want to note here that because of the nature of the subject matter, this may not be an appropriate conversation for younger listeners. But that being said, Taylor, thanks so much for joining us. TAYLOR LORENZ: Yeah, thanks for having me. MARTIN: So first, for people who don't know or maybe are pretending not to know, could you tell us a bit more about OnlyFans? I just wanted to know if the site's always been known for sexually explicit content, and how big of a player is it in that space? LORENZ: You can think of it sort of as just this subscription site for different creators who create, I mean, a lot of it is what a lot of people would just recognize as porn. A lot of it is potentially more tasteful nudes or feet pics, things like that, sort of for different fetishes. There's about 130 million users, and all of them pay monthly fees to the OnlyFans creators who are the ones creating these photos and videos to get exclusive access or send them direct messages and tips where they can kind of request specific pictures or videos be made on-demand according to their tastes. MARTIN: A hundred - wait. Can I just say that - 130 million users? That's a not-small country. LORENZ: (Laughter) It's really large, and it's growing even rapidly. I mean, the past year, the platform has just seen absolute mega-growth because not only have more people turn to it for entertainment, as you know, strip clubs have closed and things like that, a lot more creators have hopped on the platform and started creating content because they've been using it as sort of a lifeline and an extra income stream during the pandemic while they were - a lot of them were laid off or, you know, they couldn't do more traditional sex work. MARTIN: So, you know, I think it is fair to say that there is a range of content on the site. I mean, there are some well-known celebrities like Cardi B and - who are on the site. But the draw for many of these 130 million users is being able to view sexually explicit content. I mean, that's what sets OnlyFans apart from other video-sharing web sites that have rules that don't allow that. So in your recent story about it, you quoted a creator saying it's like Burger King saying they're not selling burgers anymore. So is it really about the banking partners and payout providers or is there more to this decision by OnlyFans? LORENZ: Well, there's a lot in this decision. I mean, the banking part is absolutely a huge part of it. You know, OnlyFans set out recently to try and find investors. It wanted to raise more money, you know, potentially go public eventually or sell. You know, they're trying to scale as they grow. And they found it really, really, really hard. Any other company with this kind of cash flow and user base would have no problem raising money, but a lot of investors are actually prohibited from investing in what's called vice content so porn would be part of that - because of these guidelines, like, these investing guidelines. And then a lot of other investors are concerned about minors creating subscription access to porn. Just last week, over 100 members of Congress urged the Department of Justice to launch a child abuse investigation into OnlyFans, sort of saying that they didn't believe that the platform was doing enough to protect and make sure that it wasn't hosting any underage child porn on there. So it's a lot of things coming together. And I think the payment processing was maybe the, you know, the biggest issue and definitely maybe the straw that broke the camel's back. But it's this sort of whole confluence of things. MARTIN: Is the concern here that despite whatever controls these companies say that they are imposing that too much illegal content is still getting through? Or is it - you know what I mean? Is there some data that indicates that the fact is that illegal, abusive, you know, content is getting through and that they can't figure out any other way to stop it? Is that part of it? LORENZ: It's hard to know. When OnlyFans, released this announcement on Thursday that included a link to a transparency report from July just showing how much content they had removed. I think trying to make the case that, look, we have a robust moderation system, but we don't know. You know, think of platforms like Facebook - right? - which, as they've scaled, have struggled to contain the child porn problem. I think that it's a technical challenge that is even more pressing on an app like that. MARTIN: I want to ask about the other side of this, though. And increasingly, we are hearing in the wake of this announcement from creators - and I think some of these creators might be surprising to many people - there are a lot of people who say that this has actually - sites like OnlyFans specifically have actually made sex work safer because you don't need an intermediary, that creators can control their own environment. They don't need some intermediary to get the content out there who might be exploiting them, drugging them, physically abusing them. They're controlling it. And I was interested in that, if you think that that's true. LORENZ: Absolutely. I mean, that's what's so heartbreaking about all of this. You know, OnlyFans with such a pioneering platform because it put the control back in the hands of the sex workers and content creators. It allowed them to set boundaries. You know, it allowed them a stable monthly income from the comfort of their home. And especially during the pandemic, you know, they could plan out their revenue streams. And they could really easily say what they would and wouldn't do, you know. These porn companies and porn production companies are notoriously exploitative. And with OnlyFans, you had the creators themselves capturing the majority of the revenue. You know, they're not getting sucked into bad deals necessarily. So I don't know. I do - I don't think it's, like, crazy to say that it was done very badly. And it's sad for people that were relying on it as a lifeline, right? Like, I wish that there was a way that the company had communicated all of this much better. MARTIN: Before we let you go, what do you think that we've learned about all this? Because I feel that 130 million users is a huge amount of users, 2 million creators - this is a big industry. LORENZ: I think we learned exactly how many people would pay and sell and produce porn if there was a clear and easy system to use to do that. This is one of the oldest businesses in the book. You know, pornography has been around for years. And traditionally, the porn industry, you know, has had these intermediaries, right? Like Playboy, you know, you have to audition. And the women don't earn very much or - and it's just sort of this 1% maybe that makes it through the audition and gets in the magazine or gets in some video. OnlyFans showed the diversity of porn creators. You know, there's women, men, trans people, nonbinary people, all different types of people from all different walks of life catering to lots of different types of consumers. You know, it wasn't - a lot of people talk to me about their fans and just the - having that direct relationship with their audience that they would never get if they were doing, you know, a porn video, for instance. So the content creator world is huge, and I think it's affecting people - it's affecting a lot more people than I think you'd think of as just traditional sex workers. MARTIN: That was Taylor Lorenz, who reports on culture and technology for The New York Times. Taylor Lorenz, thank you so much for sharing your reporting with us. LORENZ: Yeah, thank you so much for having me on. MICHEL MARTIN, HOST:   We wanted to talk more about the surprise announcement this week by the online subscription service OnlyFans that it will bar sexually explicit content from its site starting in October. OnlyFans said its decision to remove explicit content from the platform was prompted by its, quote, \"banking partners and payout providers,\" unquote, the companies that allow users to pay for their subscriptions. But the announcement was a surprise because OnlyFans is best known precisely for its sexually explicit content, even if its estimated 2 million creators are free to offer other fare. We wanted to hear more about this, so we called Taylor Lorenz, who reports on tech and culture for The New York Times. We wanted her to tell us more about the site and what's behind this change. And I want to note here that because of the nature of the subject matter, this may not be an appropriate conversation for younger listeners. But that being said, Taylor, thanks so much for joining us. TAYLOR LORENZ: Yeah, thanks for having me. MARTIN: So first, for people who don't know or maybe are pretending not to know, could you tell us a bit more about OnlyFans? I just wanted to know if the site's always been known for sexually explicit content, and how big of a player is it in that space? LORENZ: You can think of it sort of as just this subscription site for different creators who create, I mean, a lot of it is what a lot of people would just recognize as porn. A lot of it is potentially more tasteful nudes or feet pics, things like that, sort of for different fetishes. There's about 130 million users, and all of them pay monthly fees to the OnlyFans creators who are the ones creating these photos and videos to get exclusive access or send them direct messages and tips where they can kind of request specific pictures or videos be made on-demand according to their tastes. MARTIN: A hundred - wait. Can I just say that - 130 million users? That's a not-small country. LORENZ: (Laughter) It's really large, and it's growing even rapidly. I mean, the past year, the platform has just seen absolute mega-growth because not only have more people turn to it for entertainment, as you know, strip clubs have closed and things like that, a lot more creators have hopped on the platform and started creating content because they've been using it as sort of a lifeline and an extra income stream during the pandemic while they were - a lot of them were laid off or, you know, they couldn't do more traditional sex work. MARTIN: So, you know, I think it is fair to say that there is a range of content on the site. I mean, there are some well-known celebrities like Cardi B and - who are on the site. But the draw for many of these 130 million users is being able to view sexually explicit content. I mean, that's what sets OnlyFans apart from other video-sharing web sites that have rules that don't allow that. So in your recent story about it, you quoted a creator saying it's like Burger King saying they're not selling burgers anymore. So is it really about the banking partners and payout providers or is there more to this decision by OnlyFans? LORENZ: Well, there's a lot in this decision. I mean, the banking part is absolutely a huge part of it. You know, OnlyFans set out recently to try and find investors. It wanted to raise more money, you know, potentially go public eventually or sell. You know, they're trying to scale as they grow. And they found it really, really, really hard. Any other company with this kind of cash flow and user base would have no problem raising money, but a lot of investors are actually prohibited from investing in what's called vice content so porn would be part of that - because of these guidelines, like, these investing guidelines. And then a lot of other investors are concerned about minors creating subscription access to porn. Just last week, over 100 members of Congress urged the Department of Justice to launch a child abuse investigation into OnlyFans, sort of saying that they didn't believe that the platform was doing enough to protect and make sure that it wasn't hosting any underage child porn on there. So it's a lot of things coming together. And I think the payment processing was maybe the, you know, the biggest issue and definitely maybe the straw that broke the camel's back. But it's this sort of whole confluence of things. MARTIN: Is the concern here that despite whatever controls these companies say that they are imposing that too much illegal content is still getting through? Or is it - you know what I mean? Is there some data that indicates that the fact is that illegal, abusive, you know, content is getting through and that they can't figure out any other way to stop it? Is that part of it? LORENZ: It's hard to know. When OnlyFans, released this announcement on Thursday that included a link to a transparency report from July just showing how much content they had removed. I think trying to make the case that, look, we have a robust moderation system, but we don't know. You know, think of platforms like Facebook - right? - which, as they've scaled, have struggled to contain the child porn problem. I think that it's a technical challenge that is even more pressing on an app like that. MARTIN: I want to ask about the other side of this, though. And increasingly, we are hearing in the wake of this announcement from creators - and I think some of these creators might be surprising to many people - there are a lot of people who say that this has actually - sites like OnlyFans specifically have actually made sex work safer because you don't need an intermediary, that creators can control their own environment. They don't need some intermediary to get the content out there who might be exploiting them, drugging them, physically abusing them. They're controlling it. And I was interested in that, if you think that that's true. LORENZ: Absolutely. I mean, that's what's so heartbreaking about all of this. You know, OnlyFans with such a pioneering platform because it put the control back in the hands of the sex workers and content creators. It allowed them to set boundaries. You know, it allowed them a stable monthly income from the comfort of their home. And especially during the pandemic, you know, they could plan out their revenue streams. And they could really easily say what they would and wouldn't do, you know. These porn companies and porn production companies are notoriously exploitative. And with OnlyFans, you had the creators themselves capturing the majority of the revenue. You know, they're not getting sucked into bad deals necessarily. So I don't know. I do - I don't think it's, like, crazy to say that it was done very badly. And it's sad for people that were relying on it as a lifeline, right? Like, I wish that there was a way that the company had communicated all of this much better. MARTIN: Before we let you go, what do you think that we've learned about all this? Because I feel that 130 million users is a huge amount of users, 2 million creators - this is a big industry. LORENZ: I think we learned exactly how many people would pay and sell and produce porn if there was a clear and easy system to use to do that. This is one of the oldest businesses in the book. You know, pornography has been around for years. And traditionally, the porn industry, you know, has had these intermediaries, right? Like Playboy, you know, you have to audition. And the women don't earn very much or - and it's just sort of this 1% maybe that makes it through the audition and gets in the magazine or gets in some video. OnlyFans showed the diversity of porn creators. You know, there's women, men, trans people, nonbinary people, all different types of people from all different walks of life catering to lots of different types of consumers. You know, it wasn't - a lot of people talk to me about their fans and just the - having that direct relationship with their audience that they would never get if they were doing, you know, a porn video, for instance. So the content creator world is huge, and I think it's affecting people - it's affecting a lot more people than I think you'd think of as just traditional sex workers. MARTIN: That was Taylor Lorenz, who reports on culture and technology for The New York Times. Taylor Lorenz, thank you so much for sharing your reporting with us. LORENZ: Yeah, thank you so much for having me on.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-08-21-1029958780": {"title": "Tech Platforms Try To Limit The Taliban's Social Media Propaganda, But Won't Ban Them : NPR", "url": "https://www.npr.org/2021/08/21/1029958780/talibans-use-of-social-media", "author": "No author found", "published_date": "2021-08-21", "content": "SCOTT SIMON, HOST:  With the Taliban now in power in Afghanistan, should they control the country's official Twitter and Facebook accounts? That's a question social media companies are confronting just as the international community weighs how they should view the Taliban. NPR tech reporter Bobby Allyn reports. BOBBY ALLYN, BYLINE: The last time the Taliban were in power 20 years ago was before Facebook, Twitter and YouTube. The group sent reporters videotaped statements recorded in caves. Now they turn to YouTube, Instagram and Facebook to spread the word. The platforms ban Taliban content, but sometimes not before it's viewed by thousands. The Taliban also use encrypted messaging apps Signal and Telegram. RAFFAELLO PANTUCCI: They have found ways of, you know, mastering current social media and the current media environment in such a way to ensure that when people hear what the Taliban want to say, they hear it in the way that the Taliban wanted it to be heard. ALLYN: That's Raffaello Pantucci. He's a fellow at the British think tank the Royal United Services Institute. He says the Taliban of the '90s went around the country destroying television sets. Today, the spokesman for the Taliban has more than 300,000 followers on Twitter. Unlike other platforms, Twitter hasn't banned the Taliban but says it will crack down on glorifications of violence. Afghanistan's official presidential account on Twitter has been suspended and not handed over to the Taliban. That could change. Emerson Brooking of the Atlantic Council says the social media platforms are in a tricky position. EMERSON BROOKING: The platforms would desperately like the international community to act first. Facebook, YouTube and Twitter don't want to be setting international precedent when it comes to recognizing or not recognizing the Taliban. ALLYN: When the U. S. invaded Afghanistan in 2001, the internet barely existed there. A recent survey found that now 40% of residents have internet access and 90% have mobile phones. Pantucci says it's unclear if the Taliban will eventually crack down on Afghans' connection to the rest of the world. PANTUCCI: So will we see sort of bans on, you know, faces, on soap operas, on sex and stuff like this? Music, for example, is something that the group is not particularly a fan of unless it's religious music. ALLYN: Pantucci says the Taliban hasn't changed its fundamental belief system just because it's on Twitter. He says the Taliban's goal on social media right now is to try to appear legitimate. But if it wants, it could eventually cut the internet off completely. Bobby Allyn, NPR News, San Francisco. SCOTT SIMON, HOST:   With the Taliban now in power in Afghanistan, should they control the country's official Twitter and Facebook accounts? That's a question social media companies are confronting just as the international community weighs how they should view the Taliban. NPR tech reporter Bobby Allyn reports. BOBBY ALLYN, BYLINE: The last time the Taliban were in power 20 years ago was before Facebook, Twitter and YouTube. The group sent reporters videotaped statements recorded in caves. Now they turn to YouTube, Instagram and Facebook to spread the word. The platforms ban Taliban content, but sometimes not before it's viewed by thousands. The Taliban also use encrypted messaging apps Signal and Telegram. RAFFAELLO PANTUCCI: They have found ways of, you know, mastering current social media and the current media environment in such a way to ensure that when people hear what the Taliban want to say, they hear it in the way that the Taliban wanted it to be heard. ALLYN: That's Raffaello Pantucci. He's a fellow at the British think tank the Royal United Services Institute. He says the Taliban of the '90s went around the country destroying television sets. Today, the spokesman for the Taliban has more than 300,000 followers on Twitter. Unlike other platforms, Twitter hasn't banned the Taliban but says it will crack down on glorifications of violence. Afghanistan's official presidential account on Twitter has been suspended and not handed over to the Taliban. That could change. Emerson Brooking of the Atlantic Council says the social media platforms are in a tricky position. EMERSON BROOKING: The platforms would desperately like the international community to act first. Facebook, YouTube and Twitter don't want to be setting international precedent when it comes to recognizing or not recognizing the Taliban. ALLYN: When the U. S. invaded Afghanistan in 2001, the internet barely existed there. A recent survey found that now 40% of residents have internet access and 90% have mobile phones. Pantucci says it's unclear if the Taliban will eventually crack down on Afghans' connection to the rest of the world. PANTUCCI: So will we see sort of bans on, you know, faces, on soap operas, on sex and stuff like this? Music, for example, is something that the group is not particularly a fan of unless it's religious music. ALLYN: Pantucci says the Taliban hasn't changed its fundamental belief system just because it's on Twitter. He says the Taliban's goal on social media right now is to try to appear legitimate. But if it wants, it could eventually cut the internet off completely. Bobby Allyn, NPR News, San Francisco.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-08-25-1030949680": {"title": "OnlyFans Will Allow Pornography On Its Site After All : NPR", "url": "https://www.npr.org/2021/08/25/1030949680/onlyfans-explicit-content-pornography-sex-workers-reverses-ban", "author": "No author found", "published_date": "2021-08-25", "content": "", "section": "Business", "disclaimer": ""}, "2021-08-26-1013501080": {"title": "Data Stolen in Microsoft Exchange Hack May Have Helped Feed China's AI Project : NPR", "url": "https://www.npr.org/2021/08/26/1013501080/chinas-microsoft-hack-may-have-had-a-bigger-purpose-than-just-spying", "author": "No author found", "published_date": "2021-08-26", "content": "AUDIE CORNISH, HOST:  Earlier this year, Chinese government hackers stole tens of thousands of emails by slipping into a Microsoft Exchange email server - a breach serious enough for the White House and the FBI to take notice. Dina Temple-Raston of NPR's investigations team reports the attack went far beyond stolen correspondence. DINA TEMPLE-RASTON, BYLINE: Steven Adair noticed back in January something suspicious in one of his client's servers. Someone appeared to be stealing emails. STEVEN ADAIR: Kind of like a, you know, my hair is almost raising on my arms. And I think, you know, this feeling of, like, oh, crap, this is not what should be going on. TEMPLE-RASTON: Adair is the president of a cybersecurity firm called Volexity. And he could see that intruders had actually taken control of the server linked to the Microsoft Exchange program. And whoever it was was asking for access to specific emails and the local Exchange server was just giving it to them - no passwords needed. ADAIR: The attackers basically figured out how to trick the Exchange server into making requests. The receiving server goes, oh, you're the Exchange server. You're a trusted entity. You're allowed to do this. I mean, basically, it doesn't check that this is a completely unauthentic (ph) request. TEMPLE-RASTON: Now, at first blush, swiping emails may seem like a small thing. But they actually contain really valuable information that can be combined with other data to provide a great deal of intelligence. And we'll get to that in a minute. Initially, when Steven Adair's team alerted Microsoft, the company wasn't all that worried. TOM BURT: At the time, it was perceived as a relatively routine report of a couple of vulnerabilities, I think one of which had already been discovered. TEMPLE-RASTON: Tom Burt is a vice president at Microsoft. And among other things, he manages the digital crime unit there. And his team thought that what Adair and Volexity had uncovered was a simple espionage operation. BURT: When we saw them using this vulnerability, it was in just a couple of dozen entities worldwide and just a handful in the U. S. And we and the rest of the defender community see this activity happening all the time. TEMPLE-RASTON: Microsoft has a threat intelligence center that tracks dozens of nation-state hackers, so it didn't take them long to determine that Chinese government hackers known as Hafnium were the ones poking around those Microsoft Exchange servers. BURT: This is a group that's relatively newer on the scene. We've been tracking them for about a year and a half now. TEMPLE-RASTON: Hafnium has an M. O. that gave them away. It tends to target government agencies, medical facilities, NGOs, academics and law firms. The Microsoft team also noticed that the hack had a twist. In order to work, it needed a weirdly specific piece of information - the exact email address of the person running the local Exchange server. BURT: That would be different for every single company and organization around the world. And it's not public information. And so we actually - when we looked at this, we thought, well, how is this happening? TEMPLE-RASTON: As they were trying to figure that out, they discovered something else. The hackers had found a coding error in the Microsoft Exchange software. And to fix it, Microsoft would need to send customers a piece of code called a patch. And that happens all the time. So that might well have been the end of it, were it not for one thing - the little, tiny hack went viral. Suddenly, the hackers were everywhere. BURT: All the sudden, we saw hundreds a day. And then that continued to escalate until, I think, we were seeing north of several thousand a day. And so it was a very significant and noisy escalation. TEMPLE-RASTON: The attackers compromised tens of thousands of servers, and there appeared to be no rhyme or reason to the targets. (SOUNDBITE OF MONTAGE)UNIDENTIFIED REPORTER #1: The U. S. and key allies are blaming China for a massive cyberattack against Microsoft last March. UNIDENTIFIED REPORTER #2: As many as 30,000 entities inside the United States have been impacted by this security flaw in that Microsoft software. JEN PSAKI: This is an active threat. Everyone running these servers - government, private sector, academia - needs to act now to patch them. TEMPLE-RASTON: That's Jen Psaki, the White House press secretary. (SOUNDBITE OF ARCHIVED RECORDING)PSAKI: We are concerned that there are a large number of victims and are working with our partners to understand the scope of this. So it's. . . CHANG KAWAGUCHI: I think this was probably the first time a tool we built was specifically pointed to in a White House press release. TEMPLE-RASTON: That's Chang Kawaguchi. He heads a team that writes those software patches. And he said that while patching allows people to protect their systems, it also tells criminals around the world what to look for. KAWAGUCHI: One of the things about going public is that you can't just tell the good guys, right? When we release a patch, the bad guys start reverse engineering it immediately. And so we always know when we're releasing, that that's the starting gun of a race. TEMPLE-RASTON: It isn't a race between the bad guys and Microsoft. It's a race between the bad guys and local IT departments who have to apply the patch. The White House was so concerned, it convened a task force - in fact, Tom Burt was on it - to figure out ways to explain to people how serious this all was. What the task force didn't say publicly was that it was worried that the email theft was just the beginning. BURT: The concern was whether ransomware criminals were going to use this vulnerability to attack broad swaths of the economy in the United States or anywhere else around the world. TEMPLE-RASTON: That's why the FBI stepped in. A judge cleared the way for the bureau to scan the internet, find what the Chinese had planted in the individual Exchange servers and then remove it without informing the victims first. It was a controversial move. Though, Kiersten Todt, the managing director of the Cyber Readiness Institute, said they had little choice. KIERSTEN TODT: You were seeing schools being affected, state and local governments, underresourced entities that didn't have the resources to respond. TEMPLE-RASTON: The variety of targets, she believes, wasn't an accident. TODT: This is very much along the M. O. that they use, which is to gather and aggregate data as much as possible and not discriminating where that data comes from. TEMPLE-RASTON: Vacuuming up any and all information could end up coming in handy later, as it did in the Exchange hack. Tom Burt thinks the Chinese probably got the specific email addresses they needed from an earlier operation. BURT: And what we've heard directly is they've accumulated vast quantities of data about American and other enterprises and individuals. And they must have created a massive database that included the actual email of tens of thousands of individuals who are the Exchange server administrators. TEMPLE-RASTON: But weaponizing information for cyberattacks may be just a short-term goal. Kiersten Todt thinks this is really about China trying to become the world leader in artificial intelligence or AI. TODT: There is a long-term project underway, and we don't know what they're building. But what we do know is that diversity of data, quantity of data, aggregation, accumulation of data is going to be critical to its success. TEMPLE-RASTON: To be successful, AI needs information to learn from. The more information it has, the better chance it has of discovering things. China has built-in advantages. It has a billion people it can collect information from. And reportedly, it's been stealing from others to get even more. But there's more at stake here than just crime. TODT: Artificial intelligence is going to be a model and a mechanism by which insurance rates will be calculated, health care data will be calculated, arguably how we take care of each other, how the banks operate, how we get credit. TEMPLE-RASTON: Todt says we should ask whether we feel comfortable with China building AI for the rest of us. TODT: And you can social engineer to the culture. What China is looking at as it builds out its AI is it can social engineer to its priorities, to its mission, to those traits and qualities that are important to that country versus those which may be different represented in other countries. TEMPLE-RASTON: Countries, for example, like ours. China, for its part, denies any of this is going on. In fact, it said that it has nothing to do with the attack on Microsoft Exchange. Dina Temple-Raston, NPR News. (SOUNDBITE OF MUSIC) AUDIE CORNISH, HOST:   Earlier this year, Chinese government hackers stole tens of thousands of emails by slipping into a Microsoft Exchange email server - a breach serious enough for the White House and the FBI to take notice. Dina Temple-Raston of NPR's investigations team reports the attack went far beyond stolen correspondence. DINA TEMPLE-RASTON, BYLINE: Steven Adair noticed back in January something suspicious in one of his client's servers. Someone appeared to be stealing emails. STEVEN ADAIR: Kind of like a, you know, my hair is almost raising on my arms. And I think, you know, this feeling of, like, oh, crap, this is not what should be going on. TEMPLE-RASTON: Adair is the president of a cybersecurity firm called Volexity. And he could see that intruders had actually taken control of the server linked to the Microsoft Exchange program. And whoever it was was asking for access to specific emails and the local Exchange server was just giving it to them - no passwords needed. ADAIR: The attackers basically figured out how to trick the Exchange server into making requests. The receiving server goes, oh, you're the Exchange server. You're a trusted entity. You're allowed to do this. I mean, basically, it doesn't check that this is a completely unauthentic (ph) request. TEMPLE-RASTON: Now, at first blush, swiping emails may seem like a small thing. But they actually contain really valuable information that can be combined with other data to provide a great deal of intelligence. And we'll get to that in a minute. Initially, when Steven Adair's team alerted Microsoft, the company wasn't all that worried. TOM BURT: At the time, it was perceived as a relatively routine report of a couple of vulnerabilities, I think one of which had already been discovered. TEMPLE-RASTON: Tom Burt is a vice president at Microsoft. And among other things, he manages the digital crime unit there. And his team thought that what Adair and Volexity had uncovered was a simple espionage operation. BURT: When we saw them using this vulnerability, it was in just a couple of dozen entities worldwide and just a handful in the U. S. And we and the rest of the defender community see this activity happening all the time. TEMPLE-RASTON: Microsoft has a threat intelligence center that tracks dozens of nation-state hackers, so it didn't take them long to determine that Chinese government hackers known as Hafnium were the ones poking around those Microsoft Exchange servers. BURT: This is a group that's relatively newer on the scene. We've been tracking them for about a year and a half now. TEMPLE-RASTON: Hafnium has an M. O. that gave them away. It tends to target government agencies, medical facilities, NGOs, academics and law firms. The Microsoft team also noticed that the hack had a twist. In order to work, it needed a weirdly specific piece of information - the exact email address of the person running the local Exchange server. BURT: That would be different for every single company and organization around the world. And it's not public information. And so we actually - when we looked at this, we thought, well, how is this happening? TEMPLE-RASTON: As they were trying to figure that out, they discovered something else. The hackers had found a coding error in the Microsoft Exchange software. And to fix it, Microsoft would need to send customers a piece of code called a patch. And that happens all the time. So that might well have been the end of it, were it not for one thing - the little, tiny hack went viral. Suddenly, the hackers were everywhere. BURT: All the sudden, we saw hundreds a day. And then that continued to escalate until, I think, we were seeing north of several thousand a day. And so it was a very significant and noisy escalation. TEMPLE-RASTON: The attackers compromised tens of thousands of servers, and there appeared to be no rhyme or reason to the targets. (SOUNDBITE OF MONTAGE) UNIDENTIFIED REPORTER #1: The U. S. and key allies are blaming China for a massive cyberattack against Microsoft last March. UNIDENTIFIED REPORTER #2: As many as 30,000 entities inside the United States have been impacted by this security flaw in that Microsoft software. JEN PSAKI: This is an active threat. Everyone running these servers - government, private sector, academia - needs to act now to patch them. TEMPLE-RASTON: That's Jen Psaki, the White House press secretary. (SOUNDBITE OF ARCHIVED RECORDING) PSAKI: We are concerned that there are a large number of victims and are working with our partners to understand the scope of this. So it's. . . CHANG KAWAGUCHI: I think this was probably the first time a tool we built was specifically pointed to in a White House press release. TEMPLE-RASTON: That's Chang Kawaguchi. He heads a team that writes those software patches. And he said that while patching allows people to protect their systems, it also tells criminals around the world what to look for. KAWAGUCHI: One of the things about going public is that you can't just tell the good guys, right? When we release a patch, the bad guys start reverse engineering it immediately. And so we always know when we're releasing, that that's the starting gun of a race. TEMPLE-RASTON: It isn't a race between the bad guys and Microsoft. It's a race between the bad guys and local IT departments who have to apply the patch. The White House was so concerned, it convened a task force - in fact, Tom Burt was on it - to figure out ways to explain to people how serious this all was. What the task force didn't say publicly was that it was worried that the email theft was just the beginning. BURT: The concern was whether ransomware criminals were going to use this vulnerability to attack broad swaths of the economy in the United States or anywhere else around the world. TEMPLE-RASTON: That's why the FBI stepped in. A judge cleared the way for the bureau to scan the internet, find what the Chinese had planted in the individual Exchange servers and then remove it without informing the victims first. It was a controversial move. Though, Kiersten Todt, the managing director of the Cyber Readiness Institute, said they had little choice. KIERSTEN TODT: You were seeing schools being affected, state and local governments, underresourced entities that didn't have the resources to respond. TEMPLE-RASTON: The variety of targets, she believes, wasn't an accident. TODT: This is very much along the M. O. that they use, which is to gather and aggregate data as much as possible and not discriminating where that data comes from. TEMPLE-RASTON: Vacuuming up any and all information could end up coming in handy later, as it did in the Exchange hack. Tom Burt thinks the Chinese probably got the specific email addresses they needed from an earlier operation. BURT: And what we've heard directly is they've accumulated vast quantities of data about American and other enterprises and individuals. And they must have created a massive database that included the actual email of tens of thousands of individuals who are the Exchange server administrators. TEMPLE-RASTON: But weaponizing information for cyberattacks may be just a short-term goal. Kiersten Todt thinks this is really about China trying to become the world leader in artificial intelligence or AI. TODT: There is a long-term project underway, and we don't know what they're building. But what we do know is that diversity of data, quantity of data, aggregation, accumulation of data is going to be critical to its success. TEMPLE-RASTON: To be successful, AI needs information to learn from. The more information it has, the better chance it has of discovering things. China has built-in advantages. It has a billion people it can collect information from. And reportedly, it's been stealing from others to get even more. But there's more at stake here than just crime. TODT: Artificial intelligence is going to be a model and a mechanism by which insurance rates will be calculated, health care data will be calculated, arguably how we take care of each other, how the banks operate, how we get credit. TEMPLE-RASTON: Todt says we should ask whether we feel comfortable with China building AI for the rest of us. TODT: And you can social engineer to the culture. What China is looking at as it builds out its AI is it can social engineer to its priorities, to its mission, to those traits and qualities that are important to that country versus those which may be different represented in other countries. TEMPLE-RASTON: Countries, for example, like ours. China, for its part, denies any of this is going on. In fact, it said that it has nothing to do with the attack on Microsoft Exchange. Dina Temple-Raston, NPR News. (SOUNDBITE OF MUSIC)", "section": "Investigations", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-08-27-1031253065": {"title": "First 3D Printed Footbridge In Amsterdam Revealed To The Public : NPR", "url": "https://www.npr.org/2021/08/27/1031253065/first-3d-printed-steel-bridge-in-europe", "author": "No author found", "published_date": "2021-08-27", "content": "", "section": "Architecture", "disclaimer": ""}, "2021-08-27-1031674883": {"title": "Martin Luther King, Jr. Fortnite New Game: I Have A Dream Speech : NPR", "url": "https://www.npr.org/2021/08/27/1031674883/fortnite-mlk-i-have-a-dream-speech-martin-luther-king", "author": "No author found", "published_date": "2021-08-27", "content": "", "section": "History", "disclaimer": ""}, "2021-08-28-1031965208": {"title": "Why Apple's Anti-Child Sex Abuse Features Could Be Dangerous : NPR", "url": "https://www.npr.org/2021/08/28/1031965208/why-apples-anti-child-sex-abuse-features-could-be-dangerous", "author": "No author found", "published_date": "2021-08-28", "content": "(SOUNDBITE OF AD)UNIDENTIFIED PERSON: When you're using apps on your iPhone, you may start to see this. SCOTT SIMON, HOST:  That's from Apple's ad campaign touting its commitment to privacy. In this case, it's an option to ask apps not to track your activity online. Companies do track you to create an online profile and sell it to others to target ads. (SOUNDBITE OF AD)UNIDENTIFIED PERSON: This has been happening without your knowledge or permission. SIMON: Apple also announced it would scan photos uploaded to its iCloud for child sex abuse material. Just this week, the company confirmed it's been scanning iCloud mail for child exploitation since 2019. While the goal of protecting children isn't controversial, there are concerns. Jonathan Mayer teaches computer science at Princeton. He and a colleague created a system similar to Apple's. We should say here that Apple is a financial supporter of NPR. Professor Mayer joins us. Thanks so much for being with us. JONATHAN MAYER: Thanks for having me. SIMON: What are your concerns about this system? MAYER: My introduction to this space was, as a computer scientist, trying to build a system very similar to Apple's. And what we found was we could solve the hard technical problem of matching known child sexual abuse materials that a user sent or stored in a way where the user wouldn't know if there was a match and the user wouldn't know the database's note of materials, which is an important property for protecting law enforcement methods and making it difficult to evade the system. What we didn't see how to solve was the follow-on problems. I think there are very serious concerns about the system that Apple needs to address. And I think Apple has been very irresponsible in not clearly addressing them from the get-go and not engaging with stakeholders in the relevant communities in privacy, in civil liberties. SIMON: Mr. Mayer, I think a lot of people just have this simple worry. If a loving couple takes a picture of their 18-month-old child in the bathtub on their iPhone, are they going to hear a heavy knock on their door from the police investigating child abuse? MAYER: They're not. These systems do not depend on detecting nudity, detecting children. SIMON: So you're concerned but not calling for it to be overhauled. MAYER: I think if Apple moves forward, there are absolutely some technical changes they need to make and some process changes they need to make, right? So, you know, this is a path forward for society - balancing security as against other security concerns, privacy concerns and free speech concerns. SIMON: But, I mean, that, again, raises the question, their priority is rooting out child abuse, and that certainly is laudable. But their priority is not civil liberties. MAYER: That's correct. SIMON: When they say they'll protect children, you can win any argument that way. But what about the possibility that this technology can be misused to not protect children at all but to identify political dissidents, to identify ethnic minorities and put them in camps? I could go on with other ugly examples. MAYER: This is why it's so puzzling that Apple didn't have good answers to those questions. That was the takeaway from our academic research, that we could answer an initial hard technical question, but we couldn't answer hard follow-on questions like what happens when the Chinese government comes knocking. And Apple just doesn't seem to have had its act together in developing firm answers to those questions beyond, you should trust Apple. SIMON: Well, maybe - forgive me. Maybe they don't want a firm answer. Maybe they just want to go ahead with this system. Maybe they don't want to say no to the Chinese government if it comes to that. MAYER: It's certainly the case that Apple has had trouble saying no to the Chinese government in past. And it does a lot of business in China. It's their No. 2 market. It's been an engine of growth for the company's stock. It's where they build a large number of their devices. And so, you know, again, Apple is making a big bet that it, as a company, can withstand some possible very serious pressure from that government given all of the leverage that government has. SIMON: Forgive me. You say they're making a bet. I don't see where they're making a bet at all. What I see is that they're leaving them a big, fat out to say, yeah, we would've preferred the Chinese government not do it, but, you know, in the end, it's not up to us to decide what a government should do. And besides, look at the number of child pornographers we've been able to identify. MAYER: I think that that's a. . . SIMON: I say this with an iPhone in my hand. MAYER: I at least have been very much willing to take at face value that Apple's incentives start from protecting children, just like ours did in our research project, but that they didn't think through the very serious consequences of what they were building. There's that old adage of, you know, not attributing to malice what you might attribute to incompetence. And there are a bunch of factors specific to Apple that explain this in my mind much more persuasively than, you know, they're building some new capacity for the Chinese government. So I'm not that cynical about it. SIMON: Jonathan Mayer, a Princeton University professor, thanks so much for being with us. MAYER: Thank you. (SOUNDBITE OF AD) UNIDENTIFIED PERSON: When you're using apps on your iPhone, you may start to see this. SCOTT SIMON, HOST:   That's from Apple's ad campaign touting its commitment to privacy. In this case, it's an option to ask apps not to track your activity online. Companies do track you to create an online profile and sell it to others to target ads. (SOUNDBITE OF AD) UNIDENTIFIED PERSON: This has been happening without your knowledge or permission. SIMON: Apple also announced it would scan photos uploaded to its iCloud for child sex abuse material. Just this week, the company confirmed it's been scanning iCloud mail for child exploitation since 2019. While the goal of protecting children isn't controversial, there are concerns. Jonathan Mayer teaches computer science at Princeton. He and a colleague created a system similar to Apple's. We should say here that Apple is a financial supporter of NPR. Professor Mayer joins us. Thanks so much for being with us. JONATHAN MAYER: Thanks for having me. SIMON: What are your concerns about this system? MAYER: My introduction to this space was, as a computer scientist, trying to build a system very similar to Apple's. And what we found was we could solve the hard technical problem of matching known child sexual abuse materials that a user sent or stored in a way where the user wouldn't know if there was a match and the user wouldn't know the database's note of materials, which is an important property for protecting law enforcement methods and making it difficult to evade the system. What we didn't see how to solve was the follow-on problems. I think there are very serious concerns about the system that Apple needs to address. And I think Apple has been very irresponsible in not clearly addressing them from the get-go and not engaging with stakeholders in the relevant communities in privacy, in civil liberties. SIMON: Mr. Mayer, I think a lot of people just have this simple worry. If a loving couple takes a picture of their 18-month-old child in the bathtub on their iPhone, are they going to hear a heavy knock on their door from the police investigating child abuse? MAYER: They're not. These systems do not depend on detecting nudity, detecting children. SIMON: So you're concerned but not calling for it to be overhauled. MAYER: I think if Apple moves forward, there are absolutely some technical changes they need to make and some process changes they need to make, right? So, you know, this is a path forward for society - balancing security as against other security concerns, privacy concerns and free speech concerns. SIMON: But, I mean, that, again, raises the question, their priority is rooting out child abuse, and that certainly is laudable. But their priority is not civil liberties. MAYER: That's correct. SIMON: When they say they'll protect children, you can win any argument that way. But what about the possibility that this technology can be misused to not protect children at all but to identify political dissidents, to identify ethnic minorities and put them in camps? I could go on with other ugly examples. MAYER: This is why it's so puzzling that Apple didn't have good answers to those questions. That was the takeaway from our academic research, that we could answer an initial hard technical question, but we couldn't answer hard follow-on questions like what happens when the Chinese government comes knocking. And Apple just doesn't seem to have had its act together in developing firm answers to those questions beyond, you should trust Apple. SIMON: Well, maybe - forgive me. Maybe they don't want a firm answer. Maybe they just want to go ahead with this system. Maybe they don't want to say no to the Chinese government if it comes to that. MAYER: It's certainly the case that Apple has had trouble saying no to the Chinese government in past. And it does a lot of business in China. It's their No. 2 market. It's been an engine of growth for the company's stock. It's where they build a large number of their devices. And so, you know, again, Apple is making a big bet that it, as a company, can withstand some possible very serious pressure from that government given all of the leverage that government has. SIMON: Forgive me. You say they're making a bet. I don't see where they're making a bet at all. What I see is that they're leaving them a big, fat out to say, yeah, we would've preferred the Chinese government not do it, but, you know, in the end, it's not up to us to decide what a government should do. And besides, look at the number of child pornographers we've been able to identify. MAYER: I think that that's a. . . SIMON: I say this with an iPhone in my hand. MAYER: I at least have been very much willing to take at face value that Apple's incentives start from protecting children, just like ours did in our research project, but that they didn't think through the very serious consequences of what they were building. There's that old adage of, you know, not attributing to malice what you might attribute to incompetence. And there are a bunch of factors specific to Apple that explain this in my mind much more persuasively than, you know, they're building some new capacity for the Chinese government. So I'm not that cynical about it. SIMON: Jonathan Mayer, a Princeton University professor, thanks so much for being with us. MAYER: Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-08-28-1031961327": {"title": "Elizabeth Holmes Plans To Accuse Ex-Boyfriend Of Abuse At Trial : NPR", "url": "https://www.npr.org/2021/08/28/1031961327/elizabeth-holmes-theranos-trial-boyfriend-balwani-emotional-sexual-abuse", "author": "No author found", "published_date": "2021-08-28", "content": "", "section": "Technology", "disclaimer": ""}, "2021-08-30-1032489883": {"title": "Kids In China Now Allowed Only 3 Hours Of Video Games On Weekends Only : NPR", "url": "https://www.npr.org/2021/08/30/1032489883/china-kids-video-games-limits", "author": "No author found", "published_date": "2021-08-30", "content": "", "section": "Technology", "disclaimer": ""}, "2021-08-30-1031314018": {"title": "Theranos' Elizabeth Holmes Goes On Trial On Fraud Charges : NPR", "url": "https://www.npr.org/2021/08/30/1031314018/elizabeth-holmes-theranos-fraud-trial", "author": "No author found", "published_date": "2021-08-30", "content": "NOEL KING, HOST:  Elizabeth Holmes' trial starts today. She's the founder of the blood testing company Theranos, which imploded in a spectacular corporate scandal. Prosecutors say she misled investors and patients and that she deserves to go to prison. Elizabeth Holmes says she's innocent. Here's NPR's Bobby Allyn. BOBBY ALLYN, BYLINE: She wore black turtlenecks, spoke in a deep voice and was seen as the next Steve Jobs. In 2015, everyone was celebrating Elizabeth Holmes, including former President Bill Clinton, who joined her on stage for an event. (SOUNDBITE OF ARCHIVED RECORDING)BILL CLINTON: You founded this company 12 years ago, right? Tell them how old you were. ELIZABETH HOLMES: I was 19. ALLYN: A Stanford dropout, Holmes dazzled Silicon Valley with the promise of a blood testing company that could revolutionize laboratory medicine. She said Theranos technology could screen patients for hundreds of diseases with just a finger prick of blood. Here's how former Fox News anchor Adam Shapiro ended an interview with her at the time. (SOUNDBITE OF ARCHIVED RECORDING)ADAM SHAPIRO: There are people in this world who revolutionize our lives - Coco Chanel, Steve Jobs, Bill Gates, Walt Disney and Elizabeth Holmes. Mark my words. ALLYN: But the promises fell apart after a series of stories from journalist John Carreyrou in The Wall Street Journal. The reporting showed that Theranos wasn't using some new breakthrough equipment. Instead, it relied mostly on traditional blood-processing machines. And Carreyrou found results had a pattern of being flawed and inaccurate. JOHN CARREYROU: There's an expression that's become synonymous with the business culture of Silicon Valley, which is fake it until you make it. And she thought it was OK to behave that way. ALLYN: But despite a $9 billion valuation, Theranos began to sink. Walgreens stores in Arizona and California stopped letting patients get Theranos tests, and expansion plans were scrapped. Holmes was defiant, taking to CNBC wearing her signature black turtleneck. (SOUNDBITE OF ARCHIVED RECORDING)HOLMES: This is what happens when you work to change things. And first they think you're crazy, then they fight you, and then all of a sudden you change the world. ALLYN: But federal prosecutors say she wasn't changing the world, but committing a fraud, pushing a technology that gave false results to patients and left investors holding the bag. In 2015, investor Eileen Lepera remembers talking to a big-name venture capitalist. EILEEN LEPERA: He did say to me that he thinks it was the next Apple and that I should buy as much as I could get. ALLYN: She put in more than $100,000 - more than she's ever invested. LEPERA: Everybody kind of assumed that someone else had done due diligence and that these machines, in fact, did work. So it was a con on a grand scale. ALLYN: Holmes' legal team sees it differently. In newly unsealed court documents, Holmes' lawyers say she was physically and emotionally abused by her ex-boyfriend Sunny Balwani. He was a top executive at Theranos. He's also charged but will have a separate trial next year. The documents say Holmes plans to argue that the abuse altered her mental state during the period of the alleged fraud. Holmes' attorneys also said in filings that she's likely to take the stand herself to testify under oath. Well, UC Davis law professor Thomas Joo says if the jury doesn't think the government has enough evidence to show Holmes had criminal intent, she could be acquitted. THOMAS JOO: They may have thought that she mistakenly had too much faith in her product. She said false things, but if you say them unintentionally, it's not a crime. ALLYN: On the prosecution witness list are big-name backers of Theranos, like Rupert Murdoch and Henry Kissinger, but also patients who were wrongly diagnosed with being HIV-positive and a woman who was incorrectly told her healthy pregnancy had miscarried. Investor Lepera says she and the hundreds of other people who poured money into Theranos are hoping the jury convicts Holmes. LEPERA: I would feel good if justice was served. I pretty much gave up on getting that money back years ago. But, of course, it would be wonderful if it happened. ALLYN: The trial's expected to last four months. Bobby Allyn, NPR News, San Jose. (SOUNDBITE OF ROHNE'S \"TWELVE\") NOEL KING, HOST:   Elizabeth Holmes' trial starts today. She's the founder of the blood testing company Theranos, which imploded in a spectacular corporate scandal. Prosecutors say she misled investors and patients and that she deserves to go to prison. Elizabeth Holmes says she's innocent. Here's NPR's Bobby Allyn. BOBBY ALLYN, BYLINE: She wore black turtlenecks, spoke in a deep voice and was seen as the next Steve Jobs. In 2015, everyone was celebrating Elizabeth Holmes, including former President Bill Clinton, who joined her on stage for an event. (SOUNDBITE OF ARCHIVED RECORDING) BILL CLINTON: You founded this company 12 years ago, right? Tell them how old you were. ELIZABETH HOLMES: I was 19. ALLYN: A Stanford dropout, Holmes dazzled Silicon Valley with the promise of a blood testing company that could revolutionize laboratory medicine. She said Theranos technology could screen patients for hundreds of diseases with just a finger prick of blood. Here's how former Fox News anchor Adam Shapiro ended an interview with her at the time. (SOUNDBITE OF ARCHIVED RECORDING) ADAM SHAPIRO: There are people in this world who revolutionize our lives - Coco Chanel, Steve Jobs, Bill Gates, Walt Disney and Elizabeth Holmes. Mark my words. ALLYN: But the promises fell apart after a series of stories from journalist John Carreyrou in The Wall Street Journal. The reporting showed that Theranos wasn't using some new breakthrough equipment. Instead, it relied mostly on traditional blood-processing machines. And Carreyrou found results had a pattern of being flawed and inaccurate. JOHN CARREYROU: There's an expression that's become synonymous with the business culture of Silicon Valley, which is fake it until you make it. And she thought it was OK to behave that way. ALLYN: But despite a $9 billion valuation, Theranos began to sink. Walgreens stores in Arizona and California stopped letting patients get Theranos tests, and expansion plans were scrapped. Holmes was defiant, taking to CNBC wearing her signature black turtleneck. (SOUNDBITE OF ARCHIVED RECORDING) HOLMES: This is what happens when you work to change things. And first they think you're crazy, then they fight you, and then all of a sudden you change the world. ALLYN: But federal prosecutors say she wasn't changing the world, but committing a fraud, pushing a technology that gave false results to patients and left investors holding the bag. In 2015, investor Eileen Lepera remembers talking to a big-name venture capitalist. EILEEN LEPERA: He did say to me that he thinks it was the next Apple and that I should buy as much as I could get. ALLYN: She put in more than $100,000 - more than she's ever invested. LEPERA: Everybody kind of assumed that someone else had done due diligence and that these machines, in fact, did work. So it was a con on a grand scale. ALLYN: Holmes' legal team sees it differently. In newly unsealed court documents, Holmes' lawyers say she was physically and emotionally abused by her ex-boyfriend Sunny Balwani. He was a top executive at Theranos. He's also charged but will have a separate trial next year. The documents say Holmes plans to argue that the abuse altered her mental state during the period of the alleged fraud. Holmes' attorneys also said in filings that she's likely to take the stand herself to testify under oath. Well, UC Davis law professor Thomas Joo says if the jury doesn't think the government has enough evidence to show Holmes had criminal intent, she could be acquitted. THOMAS JOO: They may have thought that she mistakenly had too much faith in her product. She said false things, but if you say them unintentionally, it's not a crime. ALLYN: On the prosecution witness list are big-name backers of Theranos, like Rupert Murdoch and Henry Kissinger, but also patients who were wrongly diagnosed with being HIV-positive and a woman who was incorrectly told her healthy pregnancy had miscarried. Investor Lepera says she and the hundreds of other people who poured money into Theranos are hoping the jury convicts Holmes. LEPERA: I would feel good if justice was served. I pretty much gave up on getting that money back years ago. But, of course, it would be wonderful if it happened. ALLYN: The trial's expected to last four months. Bobby Allyn, NPR News, San Jose. (SOUNDBITE OF ROHNE'S \"TWELVE\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-09-02-1033675691": {"title": "Apple Introduces Digital Driver's Licenses Coming To 8 States : NPR", "url": "https://www.npr.org/2021/09/02/1033675691/drivers-license-apple-iphone-apple-watch-tsa", "author": "No author found", "published_date": "2021-09-02", "content": "", "section": "Technology", "disclaimer": ""}, "2021-09-03-1034188184": {"title": "GoDaddy Is Booting A Site That Sought Anonymous Tips About Texas Abortions : NPR", "url": "https://www.npr.org/2021/09/03/1034188184/texas-abortions-godaddy-website-anonymous-tips", "author": "No author found", "published_date": "2021-09-03", "content": "", "section": "Technology", "disclaimer": ""}, "2021-09-03-1034140480": {"title": "Lyft And Uber Will Pay Drivers' Legal Fees If They're Sued Under Texas Abortion Law : NPR", "url": "https://www.npr.org/2021/09/03/1034140480/lyft-and-uber-will-pay-drivers-legal-fees-if-theyre-sued-under-texas-abortion-la", "author": "No author found", "published_date": "2021-09-03", "content": "AUDIE CORNISH, HOST:  The restrictive new abortion law that went into effect last week in Texas lets private citizens sue anyone who helps someone obtain an abortion, including by providing financial assistance or transportation to a clinic. Now some businesses are preparing for the possible impact. NPR's tech correspondent Shannon Bond has more. SHANNON BOND, BYLINE: People who successfully sue under the new Texas law can win thousands of dollars in damages from anyone involved in providing an abortion or even just driving someone to a clinic. Here's University of Texas law professor Elizabeth Sepper on NPR's Weekend Edition Sunday. (SOUNDBITE OF ARCHIVED NPR BROADCAST)ELIZABETH SEPPER: It's $10,000 per person per abortion, so you could imagine a doctor, a nurse, a receptionist, a Uber driver. So the bounty adds up rather quickly. BOND: That's alarming ride-hailing companies like Lyft and Uber and the people who drive for them Lyft's top lawyer Kristin Sverchek told CNN. . . (SOUNDBITE OF ARCHIVED RECORDING)KRISTIN SVERCHEK: We were also hearing from our drivers who are very concerned about what this means for them. Are they under some obligation to monitor where their riders are going and why? BOND: Now Lyft says it will cover all legal fees for drivers if they're sued under the new Texas law. (SOUNDBITE OF ARCHIVED RECORDING)SVERCHEK: We both wanted to come out strongly in support of a woman's right to choose as well as make our drivers feel OK. We did not want them being in this untenable position of not knowing whether their behavior was OK or not. BOND: Sverchek says Lyft will offer the same protection to its drivers in any state that passes a similar law. Rival Uber quickly followed, with CEO Dara Khosrowshahi saying his company would also cover drivers' legal fees. So far, there have not yet been any reports that drivers are being sued in Texas. Uber and Lyft, both based in San Francisco, are two of just a handful of companies to speak out so far about the Texas abortion ban. The dating app Bumble, which is headquartered in Austin, is creating a fund to support reproductive rights and help people seeking abortions. The Match Group, which owns Tinder, is also based in Texas. Its CEO is personally offering financial help for employees and their dependents who are affected by the law. Shannon Bond, NPR News. AUDIE CORNISH, HOST:   The restrictive new abortion law that went into effect last week in Texas lets private citizens sue anyone who helps someone obtain an abortion, including by providing financial assistance or transportation to a clinic. Now some businesses are preparing for the possible impact. NPR's tech correspondent Shannon Bond has more. SHANNON BOND, BYLINE: People who successfully sue under the new Texas law can win thousands of dollars in damages from anyone involved in providing an abortion or even just driving someone to a clinic. Here's University of Texas law professor Elizabeth Sepper on NPR's Weekend Edition Sunday. (SOUNDBITE OF ARCHIVED NPR BROADCAST) ELIZABETH SEPPER: It's $10,000 per person per abortion, so you could imagine a doctor, a nurse, a receptionist, a Uber driver. So the bounty adds up rather quickly. BOND: That's alarming ride-hailing companies like Lyft and Uber and the people who drive for them Lyft's top lawyer Kristin Sverchek told CNN. . . (SOUNDBITE OF ARCHIVED RECORDING) KRISTIN SVERCHEK: We were also hearing from our drivers who are very concerned about what this means for them. Are they under some obligation to monitor where their riders are going and why? BOND: Now Lyft says it will cover all legal fees for drivers if they're sued under the new Texas law. (SOUNDBITE OF ARCHIVED RECORDING) SVERCHEK: We both wanted to come out strongly in support of a woman's right to choose as well as make our drivers feel OK. We did not want them being in this untenable position of not knowing whether their behavior was OK or not. BOND: Sverchek says Lyft will offer the same protection to its drivers in any state that passes a similar law. Rival Uber quickly followed, with CEO Dara Khosrowshahi saying his company would also cover drivers' legal fees. So far, there have not yet been any reports that drivers are being sued in Texas. Uber and Lyft, both based in San Francisco, are two of just a handful of companies to speak out so far about the Texas abortion ban. The dating app Bumble, which is headquartered in Austin, is creating a fund to support reproductive rights and help people seeking abortions. The Match Group, which owns Tinder, is also based in Texas. Its CEO is personally offering financial help for employees and their dependents who are affected by the law. Shannon Bond, NPR News.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-09-03-1034008380": {"title": "TikTok Activists Troll Reporting Website After Texas' New Abortion Ban : NPR", "url": "https://www.npr.org/2021/09/03/1034008380/tiktok-texas-abortion-ban-spam-website-activists", "author": "No author found", "published_date": "2021-09-03", "content": "", "section": "National", "disclaimer": ""}, "2021-09-03-1033996602": {"title": "Apple Is Delaying Its Plan To Scan U.S. iPhones For Images Of Child Sex Abuse : NPR", "url": "https://www.npr.org/2021/09/03/1033996602/apple-is-delaying-its-plan-to-scan-u-s-iphones-for-images-of-child-sexual-abuse", "author": "No author found", "published_date": "2021-09-03", "content": "", "section": "Technology", "disclaimer": ""}, "2021-09-04-1034368231": {"title": "Facebook Apologizes For \"Primates\" Label On Video Of Black Men : NPR", "url": "https://www.npr.org/2021/09/04/1034368231/facebook-apologizes-ai-labels-black-men-primates-racial-bias", "author": "No author found", "published_date": "2021-09-04", "content": "", "section": "Race", "disclaimer": ""}, "2021-09-07-1034838909": {"title": "Bitcoin Is Now Legal Tender In El Salvador : NPR", "url": "https://www.npr.org/2021/09/07/1034838909/bitcoin-el-salvador-legal-tender-official-currency-cryptocurrency", "author": "No author found", "published_date": "2021-09-07", "content": "", "section": "Business", "disclaimer": ""}, "2021-09-08-1035035043": {"title": "Prosecutors Call Theranos Ex-CEO Elizabeth Holmes A Liar And A Cheat As Trial Opens  : NPR", "url": "https://www.npr.org/2021/09/08/1035035043/prosecutors-call-theranos-ex-ceo-elizabeth-holmes-a-liar-and-a-cheat-as-trial-op", "author": "No author found", "published_date": "2021-09-08", "content": "RACHEL MARTIN, HOST:  A greedy villain, that's how prosecutors described Elizabeth Holmes at the beginning of her trial yesterday. Holmes is the founder of Theranos, a biotech company that promised a blood test that would transform the industry. She stands accused of defrauding investors of millions of dollars and of deceiving patients. Holmes maintains her innocence, however. NPR's Bobby Allyn was in the courtroom. And he joins us now. Bobby, thanks for being here. BOBBY ALLYN, BYLINE: You got it. MARTIN: Tell us about Elizabeth Holmes' defense. ALLYN: Yeah. In opening statements, her defense team said, basically, being a startup CEO is a tough job. You know, Holmes is working 12 hours a day, seven days a week. She thought of herself as this big visionary. And she founded this company when she was 19 as a Stanford dropout. You know, she hustled for 15 years to grow it into a $9 billion company. Then it imploded. When it comes to the fraud she's accused of, her defense lawyers did some wide-ranging finger-pointing. They said the No. 2 at the company, this guy Sonny Balwani, who is her ex-boyfriend, had more oversight than she did over some of the more dubious parts of the company, and that laboratory managers, not her, were ultimately responsible for the company's blood testing, which was exposed to be flawed and sometimes downright inaccurate. One of her defense lawyers, Lance Wade, said, quote, \"Ms. Holmes made mistakes. But mistakes are not crimes. A failed business does not make a CEO a criminal. \"MARTIN: OK. So that's the framework for the defense. How did prosecutors describe their case? ALLYN: Yeah. They zeroed in on a moment when Theranos was burning cash and on the verge of bankruptcy. Prosecutors said Holmes got really desperate. They said she forged a document from Pfizer that made it look like the drug company was approving of Theranos, written even on Pfizer letterhead, when in fact, Pfizer had not said those things and actually said the opposite. Holmes used this document nonetheless to raise millions of dollars and to land all sorts of glowing media coverage, including landing on the cover of Fortune magazine. Meanwhile, prosecutors say Holmes' technology was a total myth. Prosecutor Robert Leach told the jury that Holmes lied and cheated to get money, and quote, \"it's a crime on Main Street, and it's a crime in Silicon Valley. \"MARTIN: So, I mean, the Holmes story has been everywhere - right? - I mean, intense media scrutiny, a bestselling book about all this. But what is, Bobby, the larger significance of this trial, do you think? ALLYN: Yeah. Look; millionaires are minted all the time in Silicon Valley. And many who are chasing that kind of money do it by telling a story, you know, about themselves, about their products that they hope will change the world for the better. And sometimes that puts them at odds with regulators and the law. There's a sense out here that it's OK to push against boundaries. And Elizabeth Holmes was very much doing that. But prosecutors say the key difference here is she broke the law in the process. Traditionally, the norm in Silicon Valley has been move fast and break things. But, you know, maybe this trial, depending on the verdict, will temper some of that behavior. So yeah, Rachel, there's a debate raging out here in Silicon Valley now as people watch this trial. And it's, when does a startup's exaggerated claims potentially veer into the land of being illegal? MARTIN: Any idea how long the trial is supposed to last? ALLYN: Yeah. The judge is expecting this to go for three months. So now we're going to see a parade of witnesses, whistleblowers, experts, patients and even Holmes herself taking the stand. At about - you know, around the end of the year, the jury will start deliberating over Holmes' guilt or innocence. And if convicted, she faces up to two decades behind bars. MARTIN: NPR's Bobby Allyn. Thank you. ALLYN: Thanks, Rachel. RACHEL MARTIN, HOST:   A greedy villain, that's how prosecutors described Elizabeth Holmes at the beginning of her trial yesterday. Holmes is the founder of Theranos, a biotech company that promised a blood test that would transform the industry. She stands accused of defrauding investors of millions of dollars and of deceiving patients. Holmes maintains her innocence, however. NPR's Bobby Allyn was in the courtroom. And he joins us now. Bobby, thanks for being here. BOBBY ALLYN, BYLINE: You got it. MARTIN: Tell us about Elizabeth Holmes' defense. ALLYN: Yeah. In opening statements, her defense team said, basically, being a startup CEO is a tough job. You know, Holmes is working 12 hours a day, seven days a week. She thought of herself as this big visionary. And she founded this company when she was 19 as a Stanford dropout. You know, she hustled for 15 years to grow it into a $9 billion company. Then it imploded. When it comes to the fraud she's accused of, her defense lawyers did some wide-ranging finger-pointing. They said the No. 2 at the company, this guy Sonny Balwani, who is her ex-boyfriend, had more oversight than she did over some of the more dubious parts of the company, and that laboratory managers, not her, were ultimately responsible for the company's blood testing, which was exposed to be flawed and sometimes downright inaccurate. One of her defense lawyers, Lance Wade, said, quote, \"Ms. Holmes made mistakes. But mistakes are not crimes. A failed business does not make a CEO a criminal. \" MARTIN: OK. So that's the framework for the defense. How did prosecutors describe their case? ALLYN: Yeah. They zeroed in on a moment when Theranos was burning cash and on the verge of bankruptcy. Prosecutors said Holmes got really desperate. They said she forged a document from Pfizer that made it look like the drug company was approving of Theranos, written even on Pfizer letterhead, when in fact, Pfizer had not said those things and actually said the opposite. Holmes used this document nonetheless to raise millions of dollars and to land all sorts of glowing media coverage, including landing on the cover of Fortune magazine. Meanwhile, prosecutors say Holmes' technology was a total myth. Prosecutor Robert Leach told the jury that Holmes lied and cheated to get money, and quote, \"it's a crime on Main Street, and it's a crime in Silicon Valley. \" MARTIN: So, I mean, the Holmes story has been everywhere - right? - I mean, intense media scrutiny, a bestselling book about all this. But what is, Bobby, the larger significance of this trial, do you think? ALLYN: Yeah. Look; millionaires are minted all the time in Silicon Valley. And many who are chasing that kind of money do it by telling a story, you know, about themselves, about their products that they hope will change the world for the better. And sometimes that puts them at odds with regulators and the law. There's a sense out here that it's OK to push against boundaries. And Elizabeth Holmes was very much doing that. But prosecutors say the key difference here is she broke the law in the process. Traditionally, the norm in Silicon Valley has been move fast and break things. But, you know, maybe this trial, depending on the verdict, will temper some of that behavior. So yeah, Rachel, there's a debate raging out here in Silicon Valley now as people watch this trial. And it's, when does a startup's exaggerated claims potentially veer into the land of being illegal? MARTIN: Any idea how long the trial is supposed to last? ALLYN: Yeah. The judge is expecting this to go for three months. So now we're going to see a parade of witnesses, whistleblowers, experts, patients and even Holmes herself taking the stand. At about - you know, around the end of the year, the jury will start deliberating over Holmes' guilt or innocence. And if convicted, she faces up to two decades behind bars. MARTIN: NPR's Bobby Allyn. Thank you. ALLYN: Thanks, Rachel.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-09-08-1035135008": {"title": "Howard University Partially Reopens After Ransomware Attack : NPR", "url": "https://www.npr.org/2021/09/08/1035135008/howard-university-partially-reopens-as-it-investigates-a-cyberattack", "author": "No author found", "published_date": "2021-09-08", "content": "", "section": "Education", "disclaimer": ""}, "2021-09-09-1035559330": {"title": "Amazon Slammed For Promoting False COVID Cures And Anti-Vaccine Claims : NPR", "url": "https://www.npr.org/2021/09/09/1035559330/democrats-slam-amazon-for-promoting-false-covid-cures-and-anti-vaccine-claims", "author": "No author found", "published_date": "2021-09-09", "content": "", "section": "Untangling Disinformation", "disclaimer": ""}, "2021-09-09-1035418788": {"title": "Over the Summer, Sammy Salvano Created A Prosthetic Hand For A Friend  : NPR", "url": "https://www.npr.org/2021/09/09/1035418788/over-the-summer-sammy-salvano-created-a-prosthetic-hand-for-a-friend", "author": "No author found", "published_date": "2021-09-09", "content": "NOEL KING, HOST:  Good morning. I'm Noel King. Sammy Salvano has always been a bit of an inventor. His most recent creation took him all summer long. With the help of a 3D printer, 14-year-old Sammy built a prosthetic hand for his friend Ewan Kirby. Ewan is missing fingers on one hand. The new prosthetic fits well. Ewan tested it by picking up his mom's car keys. Sammy wants to be an engineer, and it looks like he's off to a good start. It's MORNING EDITION. NOEL KING, HOST:   Good morning. I'm Noel King. Sammy Salvano has always been a bit of an inventor. His most recent creation took him all summer long. With the help of a 3D printer, 14-year-old Sammy built a prosthetic hand for his friend Ewan Kirby. Ewan is missing fingers on one hand. The new prosthetic fits well. Ewan tested it by picking up his mom's car keys. Sammy wants to be an engineer, and it looks like he's off to a good start. It's MORNING EDITION.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-09-10-1036043886": {"title": "Epic Games V. Apple: A Breakdown Of The Split Ruling : NPR", "url": "https://www.npr.org/2021/09/10/1036043886/apple-fortnite-epic-games-ruling-explained", "author": "No author found", "published_date": "2021-09-10", "content": "AILSA CHANG, HOST:  Epic Games, the maker of the video game Fortnite, and Apple have been locked in a legal battle. Epic sued Apple over some of its App Store policies. You see; Apple charges developers like Epic a fee every time someone downloads their apps or buy something within them. A federal judge has ruled on the case and largely said Apple's actions were just fine with one critical exception. NPR's Bobby Allyn joins us now to explain, and we should note Apple is among NPR's financial supporters. Hey, Bobby. BOBBY ALLYN, BYLINE: Hey there, Ailsa. CHANG: All right, so can you just break down exactly what this ruling said? ALLYN: Yeah. So Apple, of course, as we all know, you know, makes a lot of money by selling computers, phones and other physical stuff. But as iPhone sales flatline, Apple is trying to make a lot more money off things like fees and subscriptions. And on iPhones and iPads, that's big business. I mean, the mobile gaming market alone is a $100 billion industry. So - OK, so every time you use Candy Crush, say, want to buy a cool outfit for your avatar on Roblox - whatever you're doing on your iPhone, you know, Apple is taking a 30% cut. It's sort of invisible, but it's happening. And the judge here said Apple is making money there but that, quote, \"success is not a crime. \" But the judge did say Apple needs to give people options before they buy that outfit on Roblox. So that could look like, do you want to buy it through Apple, or do you want to use Roblox's own processor? And it's a subtle thing, Ailsa, but it's actually a really big deal. CHANG: Right. OK. Tell us a little more about that. Like, what makes it such a big deal? ALLYN: Right. So let me just use a personal example. So I'm training for a marathon now, and every time I go on a run, I use the app Strava to record my runs, right? CHANG: Yeah. ALLYN: I think I pay, like, five bucks a month for a fancier version of the app. Baked into that price is Apple's 30% commission. Now, the judge in this case, Yvonne Gonzalez Rogers, basically said before I buy that Strava subscription, I shouldn't be forced to complete my payment through Apple. Strava should be giving me more options here. And if I did have an option, say, to process it through Strava, it might be cheaper to me, and Strava might make more money off it. And for years, you know, developers - if they had one complaint about Apple, it's that the App Store is just too tightly controlled by Apple. And, you know, Stanford law professor Mark Lemley told me Apple giving up even a little bit of its gatekeeper role here means there might be more to come. MARK LEMLEY: Big Tech has come under a lot of antitrust scrutiny in the last several years, but Apple has so far mostly gotten a pass. And I think this suit, even the way it resolves, is maybe an indication that that's not going to continue. CHANG: Interesting. OK, Bobby, so what happens next in this case? ALLYN: You can probably guess - an appeals process. But the battle lines are actually kind of interesting because both sides are appealing. Nobody here is happy. Epic is appealing because Apple was not declared an illegal monopoly as they had hoped, and Apple is appealing because they don't want to make the changes to its payment system that the judge is ordering. They're really holding on tight to its 30% arrangement. CHANG: OK, so any changes will have to wait on those appeals. But if this ruling does stand, will iPhone and iPad users notice anything different? ALLYN: Yeah, yeah. So in theory, yes, if there are more payment options, Ailsa, for you and I every time we buy something on our iPhone or iPad, you know, prices could get cheaper. You know, analysts say those lower prices could also force Apple to drop its commission just to stay competitive, right? That's how markets work. But also, developers could just pocket the extra money, so we shall see. We don't know yet for sure how it's going to play out for consumers. But, you know, the most optimistic take is if this does survive the appeals process, yes, this could mean consumers will save a little bit of money when you're buying things in Apple's App Store. CHANG: That is NPR's Bobby Allyn. Thank you, Bobby. ALLYN: Thanks, Ailsa. (SOUNDBITE OF GIRLPOOL SONG, \"IDEAL WORLD\") AILSA CHANG, HOST:   Epic Games, the maker of the video game Fortnite, and Apple have been locked in a legal battle. Epic sued Apple over some of its App Store policies. You see; Apple charges developers like Epic a fee every time someone downloads their apps or buy something within them. A federal judge has ruled on the case and largely said Apple's actions were just fine with one critical exception. NPR's Bobby Allyn joins us now to explain, and we should note Apple is among NPR's financial supporters. Hey, Bobby. BOBBY ALLYN, BYLINE: Hey there, Ailsa. CHANG: All right, so can you just break down exactly what this ruling said? ALLYN: Yeah. So Apple, of course, as we all know, you know, makes a lot of money by selling computers, phones and other physical stuff. But as iPhone sales flatline, Apple is trying to make a lot more money off things like fees and subscriptions. And on iPhones and iPads, that's big business. I mean, the mobile gaming market alone is a $100 billion industry. So - OK, so every time you use Candy Crush, say, want to buy a cool outfit for your avatar on Roblox - whatever you're doing on your iPhone, you know, Apple is taking a 30% cut. It's sort of invisible, but it's happening. And the judge here said Apple is making money there but that, quote, \"success is not a crime. \" But the judge did say Apple needs to give people options before they buy that outfit on Roblox. So that could look like, do you want to buy it through Apple, or do you want to use Roblox's own processor? And it's a subtle thing, Ailsa, but it's actually a really big deal. CHANG: Right. OK. Tell us a little more about that. Like, what makes it such a big deal? ALLYN: Right. So let me just use a personal example. So I'm training for a marathon now, and every time I go on a run, I use the app Strava to record my runs, right? CHANG: Yeah. ALLYN: I think I pay, like, five bucks a month for a fancier version of the app. Baked into that price is Apple's 30% commission. Now, the judge in this case, Yvonne Gonzalez Rogers, basically said before I buy that Strava subscription, I shouldn't be forced to complete my payment through Apple. Strava should be giving me more options here. And if I did have an option, say, to process it through Strava, it might be cheaper to me, and Strava might make more money off it. And for years, you know, developers - if they had one complaint about Apple, it's that the App Store is just too tightly controlled by Apple. And, you know, Stanford law professor Mark Lemley told me Apple giving up even a little bit of its gatekeeper role here means there might be more to come. MARK LEMLEY: Big Tech has come under a lot of antitrust scrutiny in the last several years, but Apple has so far mostly gotten a pass. And I think this suit, even the way it resolves, is maybe an indication that that's not going to continue. CHANG: Interesting. OK, Bobby, so what happens next in this case? ALLYN: You can probably guess - an appeals process. But the battle lines are actually kind of interesting because both sides are appealing. Nobody here is happy. Epic is appealing because Apple was not declared an illegal monopoly as they had hoped, and Apple is appealing because they don't want to make the changes to its payment system that the judge is ordering. They're really holding on tight to its 30% arrangement. CHANG: OK, so any changes will have to wait on those appeals. But if this ruling does stand, will iPhone and iPad users notice anything different? ALLYN: Yeah, yeah. So in theory, yes, if there are more payment options, Ailsa, for you and I every time we buy something on our iPhone or iPad, you know, prices could get cheaper. You know, analysts say those lower prices could also force Apple to drop its commission just to stay competitive, right? That's how markets work. But also, developers could just pocket the extra money, so we shall see. We don't know yet for sure how it's going to play out for consumers. But, you know, the most optimistic take is if this does survive the appeals process, yes, this could mean consumers will save a little bit of money when you're buying things in Apple's App Store. CHANG: That is NPR's Bobby Allyn. Thank you, Bobby. ALLYN: Thanks, Ailsa. (SOUNDBITE OF GIRLPOOL SONG, \"IDEAL WORLD\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-09-10-1033247833": {"title": "U.S. Senators Call On EEOC To Probe Amazon's Treatment Of Pregnant Workers : NPR", "url": "https://www.npr.org/2021/09/10/1033247833/u-s-senators-call-for-probe-of-amazons-approach-to-pregnant-workers", "author": "No author found", "published_date": "2021-09-10", "content": "", "section": "Business", "disclaimer": ""}, "2021-09-10-1023834758": {"title": "Apple Must Change Its Tightly Controlled App Store, Judge Rules in Epic Lawsuit : NPR", "url": "https://www.npr.org/2021/09/10/1023834758/apple-app-store-epic-games-fortnite-verdict", "author": "No author found", "published_date": "2021-09-10", "content": "", "section": "Technology", "disclaimer": ""}, "2021-09-14-1037139358": {"title": "The New iPhone 13 Has 1-Terabyte Storage Option : NPR", "url": "https://www.npr.org/2021/09/14/1037139358/iphone-13-terabyte-storage-new-apple", "author": "No author found", "published_date": "2021-09-14", "content": "", "section": "Business", "disclaimer": ""}, "2021-09-14-1037132503": {"title": "Former U.S. Intelligence Operatives Admit Hacking For UAE : NPR", "url": "https://www.npr.org/2021/09/14/1037132503/us-charges-former-intelligence-operatives-hacking-for-uae", "author": "No author found", "published_date": "2021-09-14", "content": "", "section": "National Security", "disclaimer": ""}, "2021-09-14-1037096404": {"title": "Latest Apple Software Update Will Fix A Security Flaw Spyware Used To Access Devices : NPR", "url": "https://www.npr.org/2021/09/14/1037096404/latest-apple-software-update-will-fix-a-security-flaw-spyware-used-to-access-dev", "author": "No author found", "published_date": "2021-09-14", "content": "MARY LOUISE KELLY, HOST:  And if you have an iPhone or iPad, you are likely among the 1 1/2 billion people who should download an emergency software update to your device. Apple issued the update to its iOS yesterday because devices were vulnerable to a military-grade spyware that could infiltrate devices even without users clicking on a link or downloading malicious software. AILSA CHANG, HOST:  This zero-click technology is employed by spyware called Pegasus. It's made by an Israeli-based company called NSO Group. And needless to say, Apple consumers are worried. DREW HARWELL: It's a big blow. Like, Apple has been marketing that they are the privacy company for years. CHANG: Drew Harwell covers tech for The Washington Post, and he says Apple's update advisory was shocking given how much money the company invests in security. HARWELL: If you're a $2 trillion company and you are advertising yourself as the choice for privacy for people around the world, you've got to wonder, should they be spending more toward keeping people's phones safe and secure? KELLY: NSO Group was able to market its Pegasus software to governments and law enforcement groups to help combat terrorism and crime. But as Harwell and a consortium of journalists have reported, researchers at the University of Toronto found out about these zero-click hacks because they targeted people who shouldn't have been under this kind of surveillance. HARWELL: The people we've seen that have been targeted by this spyware have been human rights activists, lawyers, dissidents, journalists. CHANG: While not everyone with an iPhone or Apple device has been hacked, Harwell says this spyware is still targeting people. HARWELL: We did some reporting that found, you know, a list of tens of thousands of numbers that may have been, you know, potentially targeted by Pegasus spyware. And it's really changed their life. I mean, it's gathered sensitive data about them. It scares them even to this day, so. . . CHANG: So if you haven't already, you can download Apple's patch under settings, then go to general, then software update. Harwell says it may take a few minutes, but it will likely be a few minutes well-spent. MARY LOUISE KELLY, HOST:   And if you have an iPhone or iPad, you are likely among the 1 1/2 billion people who should download an emergency software update to your device. Apple issued the update to its iOS yesterday because devices were vulnerable to a military-grade spyware that could infiltrate devices even without users clicking on a link or downloading malicious software. AILSA CHANG, HOST:   This zero-click technology is employed by spyware called Pegasus. It's made by an Israeli-based company called NSO Group. And needless to say, Apple consumers are worried. DREW HARWELL: It's a big blow. Like, Apple has been marketing that they are the privacy company for years. CHANG: Drew Harwell covers tech for The Washington Post, and he says Apple's update advisory was shocking given how much money the company invests in security. HARWELL: If you're a $2 trillion company and you are advertising yourself as the choice for privacy for people around the world, you've got to wonder, should they be spending more toward keeping people's phones safe and secure? KELLY: NSO Group was able to market its Pegasus software to governments and law enforcement groups to help combat terrorism and crime. But as Harwell and a consortium of journalists have reported, researchers at the University of Toronto found out about these zero-click hacks because they targeted people who shouldn't have been under this kind of surveillance. HARWELL: The people we've seen that have been targeted by this spyware have been human rights activists, lawyers, dissidents, journalists. CHANG: While not everyone with an iPhone or Apple device has been hacked, Harwell says this spyware is still targeting people. HARWELL: We did some reporting that found, you know, a list of tens of thousands of numbers that may have been, you know, potentially targeted by Pegasus spyware. And it's really changed their life. I mean, it's gathered sensitive data about them. It scares them even to this day, so. . . CHANG: So if you haven't already, you can download Apple's patch under settings, then go to general, then software update. Harwell says it may take a few minutes, but it will likely be a few minutes well-spent.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-09-14-1036835868": {"title": "A 'Concerned' Elizabeth Holmes Trial Observer Has Secret Identity : NPR", "url": "https://www.npr.org/2021/09/14/1036835868/elizabeth-holmes-trial-hotelier-bill-evans-goes-incognito", "author": "No author found", "published_date": "2021-09-14", "content": "SCOTT SIMON, HOST:  The Elizabeth Holmes trial has wrapped up its second week. Of course, she's the former CEO of Theranos, the startup that promised a miracle blood test that could screen for hundreds of diseases with a pinprick of blood. The company imploded in 2015 after investigation showed the technology just did not work as promised. NPR's Bobby Allyn has been covering the trial and joins us. Bobby, thanks so much for being with us. BOBBY ALLYN, BYLINE: Thanks, Scott. SIMON: What happened this week? ALLYN: Well, the prosecution outlined its case against Holmes. They said just as the startup was burning cash and up against a wall, she resorted to lying to investors. Prosecutors say she forged documents and made false claims, like that she was working with the military when she wasn't, basically in order to rescue this startup that was on the verge of bankruptcy. When the defense responded, they said, you know, Elizabeth Holmes may have ran this startup into the ground, but failing is not a crime. We now move to the witness phase of the trial. We're hearing from former Theranos scientists, accountants and other insiders with direct knowledge of the company and who had a lot of time talking to Elizabeth Holmes. SIMON: Bobby, based on the testimony so far, has anybody suggested this technology worked? ALLYN: So the question boils down to, how much did it work? People who worked in the Theranos lab said, indeed, some tests did come out with accurate results. That said, Elizabeth Holmes was on the cover of Fortune magazine. She was talking to investors. She was telling anyone who would listen that her little device, this micro-analyzer called the Edison, could scan for hundreds of diseases with a pinprick of blood. And what we found out during this trial is that really what was happening is blood tests were being sent to sort of traditional blood-testing machines to get results, not her miracle device. And when results were coming out of this Edison device, they were often flawed. They were often inaccurate. The Wall Street Journal reported on this in 2015. And now we're getting more detail just about how sketchy and dubious the results of these tests really were. SIMON: Bobby, we have to ask you about a mystery man you spent some time sitting next to in the courtroom. And he turns out to have a story. Who is he? ALLYN: Yeah. So at the start of the trial, the courthouse was quite a scene. It was, you know, packed with TV cameras, teeming with random people. But, you know, there was one person who really stood out. He was there, the first person in line wearing a Patagonia jacket, a baseball cap. He told me his name was Hanson and that he just fixed up old cars for a living. He said he had no connection to Holmes. You know, during jury selection, I sat next to him for seven hours. And he would whisper to me about what he thought about the judge. He criticized the media coverage of Theranos. You know, every reporter in the courtroom was sort of fascinated by this guy. We were unsure why he was there. And, you know, basically, he was saying - he was just a mechanic, this average guy who had a curiosity about criminal trials. Well, the following week, Elizabeth Holmes walks into the courtroom with her entourage. And who is accompanying her but this individual who said his name was Hanson? In fact, he is Bill Evans, the wealthy hotel magnate in San Diego, who is the father of Billy Evans, Elizabeth Holmes' partner and the father of her newborn baby boy. So just a bit of a strange, bizarre twist in the early weeks of the Elizabeth Holmes trial. SIMON: What's coming up next in the trial, Bobby, as the weeks proceed? ALLYN: We've got three or four months left of this trial, Scott, so a long road ahead. A major question to look out for is, will Elizabeth Holmes herself take the stand and respond to these fraud charges? Her lawyers put her on the potential witness list. So, you know, there's a strong possibility we'll be hearing directly from her. But we will just have to see. SIMON: NPR's Bobby Allyn, thanks so much for being with us. ALLYN: Thanks, Scott. SCOTT SIMON, HOST:   The Elizabeth Holmes trial has wrapped up its second week. Of course, she's the former CEO of Theranos, the startup that promised a miracle blood test that could screen for hundreds of diseases with a pinprick of blood. The company imploded in 2015 after investigation showed the technology just did not work as promised. NPR's Bobby Allyn has been covering the trial and joins us. Bobby, thanks so much for being with us. BOBBY ALLYN, BYLINE: Thanks, Scott. SIMON: What happened this week? ALLYN: Well, the prosecution outlined its case against Holmes. They said just as the startup was burning cash and up against a wall, she resorted to lying to investors. Prosecutors say she forged documents and made false claims, like that she was working with the military when she wasn't, basically in order to rescue this startup that was on the verge of bankruptcy. When the defense responded, they said, you know, Elizabeth Holmes may have ran this startup into the ground, but failing is not a crime. We now move to the witness phase of the trial. We're hearing from former Theranos scientists, accountants and other insiders with direct knowledge of the company and who had a lot of time talking to Elizabeth Holmes. SIMON: Bobby, based on the testimony so far, has anybody suggested this technology worked? ALLYN: So the question boils down to, how much did it work? People who worked in the Theranos lab said, indeed, some tests did come out with accurate results. That said, Elizabeth Holmes was on the cover of Fortune magazine. She was talking to investors. She was telling anyone who would listen that her little device, this micro-analyzer called the Edison, could scan for hundreds of diseases with a pinprick of blood. And what we found out during this trial is that really what was happening is blood tests were being sent to sort of traditional blood-testing machines to get results, not her miracle device. And when results were coming out of this Edison device, they were often flawed. They were often inaccurate. The Wall Street Journal reported on this in 2015. And now we're getting more detail just about how sketchy and dubious the results of these tests really were. SIMON: Bobby, we have to ask you about a mystery man you spent some time sitting next to in the courtroom. And he turns out to have a story. Who is he? ALLYN: Yeah. So at the start of the trial, the courthouse was quite a scene. It was, you know, packed with TV cameras, teeming with random people. But, you know, there was one person who really stood out. He was there, the first person in line wearing a Patagonia jacket, a baseball cap. He told me his name was Hanson and that he just fixed up old cars for a living. He said he had no connection to Holmes. You know, during jury selection, I sat next to him for seven hours. And he would whisper to me about what he thought about the judge. He criticized the media coverage of Theranos. You know, every reporter in the courtroom was sort of fascinated by this guy. We were unsure why he was there. And, you know, basically, he was saying - he was just a mechanic, this average guy who had a curiosity about criminal trials. Well, the following week, Elizabeth Holmes walks into the courtroom with her entourage. And who is accompanying her but this individual who said his name was Hanson? In fact, he is Bill Evans, the wealthy hotel magnate in San Diego, who is the father of Billy Evans, Elizabeth Holmes' partner and the father of her newborn baby boy. So just a bit of a strange, bizarre twist in the early weeks of the Elizabeth Holmes trial. SIMON: What's coming up next in the trial, Bobby, as the weeks proceed? ALLYN: We've got three or four months left of this trial, Scott, so a long road ahead. A major question to look out for is, will Elizabeth Holmes herself take the stand and respond to these fraud charges? Her lawyers put her on the potential witness list. So, you know, there's a strong possibility we'll be hearing directly from her. But we will just have to see. SIMON: NPR's Bobby Allyn, thanks so much for being with us. ALLYN: Thanks, Scott.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-09-14-1036869715": {"title": "Apple Releases Patch To Fix Security Vulnerability : NPR", "url": "https://www.npr.org/2021/09/14/1036869715/apple-issues-critical-patch-to-fix-security-hole-exploited-by-spyware-company", "author": "No author found", "published_date": "2021-09-14", "content": "", "section": "Technology", "disclaimer": ""}, "2021-09-15-1037222495": {"title": "Lawmakers Push Facebook To Abandon Instagram For Kids, Citing Mental Health Concerns : NPR", "url": "https://www.npr.org/2021/09/15/1037222495/lawmakers-push-facebook-to-abandon-instagram-for-kids-citing-mental-health-conce", "author": "No author found", "published_date": "2021-09-15", "content": "", "section": "Technology", "disclaimer": ""}, "2021-09-16-1037902314": {"title": "UN Report Warns Artificial Intelligence Can Threaten Human Rights : NPR", "url": "https://www.npr.org/2021/09/16/1037902314/the-u-n-warns-that-ai-can-pose-a-threat-to-human-rights", "author": "No author found", "published_date": "2021-09-16", "content": "", "section": "Technology", "disclaimer": ""}, "2021-09-16-1037845545": {"title": "Passwords No Longer Required To Sign Into Microsoft Accounts : NPR", "url": "https://www.npr.org/2021/09/16/1037845545/password-microsoft-outlook-consumer-accounts", "author": "No author found", "published_date": "2021-09-16", "content": "", "section": "Technology", "disclaimer": ""}, "2021-09-16-1037626859": {"title": "Review: 'Eastward,' For The Nintendo Switch : NPR", "url": "https://www.npr.org/2021/09/16/1037626859/review-eastward-pixpil-switch", "author": "No author found", "published_date": "2021-09-16", "content": "", "section": "Games", "disclaimer": ""}, "2021-09-17-1037911107": {"title": "Remembering Jerry Lawson, The Black Engineer Who Changed Video Games : NPR", "url": "https://www.npr.org/2021/09/17/1037911107/jerry-lawson-video-game-fairchild-channel-f-black-engineer", "author": "No author found", "published_date": "2021-09-17", "content": "(SOUNDBITE OF MUSIC)NOEL KING, HOST:  Time now for StoryCorps. Gerald Lawson was an engineer who specialized in making video games in the 1970s. His kids, Karen and Anderson, remember growing up with him in Silicon Valley. ANDERSON LAWSON: He was 6'6\" and almost 300 pounds. KAREN LAWSON: His size was intimidating. The guy walks into the room and he's filling up the doorway. A LAWSON: And no matter where you were in the house, you can hear the keys jingle. And when - as soon as you hear that, we would just get up from wherever we're at and run to the door and hug Dad. He'd pick us up, and he would pretend like he was King Kong and go (imitating King Kong). You remember that? K LAWSON: (Laughter) Yes. A LAWSON: And he had this huge lab in the garage. If you ever saw a episode of \"Star Trek,\" we see everyone sitting around the consoles, right? K LAWSON: Consoles, yeah. A LAWSON: That's what that lab looked like to me. There might be eight to 10 different computers about the size of a refrigerator all networked together. And I remember walking around and stepping on some of the electronic components and hurting my foot. K LAWSON: Yeah. A LAWSON: Like, if you didn't have shoes on, you were screwed. K LAWSON: It was a death route. (LAUGHTER)A LAWSON: Some of my earliest memories are of us playing his video games. K LAWSON: And which we didn't know at the time is that we were checking out bugs in the games. A LAWSON: Right. And he just got some free labor out of us (laughter). K LAWSON: That was it. We played video games so much that Mom and Dad used to put us outside. . . A LAWSON: Yeah. K LAWSON: . . . And Dad used to say, give it a rest. A LAWSON: Give it a rest. I remember that. K LAWSON: (Laughter). A LAWSON: And remember our cousin Manny (ph) who came to visit? K LAWSON: Yes. A LAWSON: He gave Manny and I a book, \"101 Basic Computer Games. \" And he forced us to figure out how to make our own games. So Manny and I made a game on one of the computers Dad had. I had so much fun doing it. That influenced me in my decision to become a computer scientist. It changed the whole trajectory of my life. K LAWSON: His influence speaks to his personality and who he was. Dad was a man without limitations as far as what he felt he could do or accomplish. So when he did pass, as sad as it was, you and I both know that he lived a full life. A LAWSON: He was a man that went his own path. If everyone was going right, he'd figure out a good reason to go left. and. . . K LAWSON: Yes. A LAWSON: . . . That was just him. He created his own destiny. KING: Anderson and Karen Lawson remembering their dad, Gerald, who died in 2011. That conversation will be archived at the Library of Congress. (SOUNDBITE OF BRYAN COPELAND'S \"ELEGIAC\") (SOUNDBITE OF MUSIC) NOEL KING, HOST:   Time now for StoryCorps. Gerald Lawson was an engineer who specialized in making video games in the 1970s. His kids, Karen and Anderson, remember growing up with him in Silicon Valley. ANDERSON LAWSON: He was 6'6\" and almost 300 pounds. KAREN LAWSON: His size was intimidating. The guy walks into the room and he's filling up the doorway. A LAWSON: And no matter where you were in the house, you can hear the keys jingle. And when - as soon as you hear that, we would just get up from wherever we're at and run to the door and hug Dad. He'd pick us up, and he would pretend like he was King Kong and go (imitating King Kong). You remember that? K LAWSON: (Laughter) Yes. A LAWSON: And he had this huge lab in the garage. If you ever saw a episode of \"Star Trek,\" we see everyone sitting around the consoles, right? K LAWSON: Consoles, yeah. A LAWSON: That's what that lab looked like to me. There might be eight to 10 different computers about the size of a refrigerator all networked together. And I remember walking around and stepping on some of the electronic components and hurting my foot. K LAWSON: Yeah. A LAWSON: Like, if you didn't have shoes on, you were screwed. K LAWSON: It was a death route. (LAUGHTER) A LAWSON: Some of my earliest memories are of us playing his video games. K LAWSON: And which we didn't know at the time is that we were checking out bugs in the games. A LAWSON: Right. And he just got some free labor out of us (laughter). K LAWSON: That was it. We played video games so much that Mom and Dad used to put us outside. . . A LAWSON: Yeah. K LAWSON: . . . And Dad used to say, give it a rest. A LAWSON: Give it a rest. I remember that. K LAWSON: (Laughter). A LAWSON: And remember our cousin Manny (ph) who came to visit? K LAWSON: Yes. A LAWSON: He gave Manny and I a book, \"101 Basic Computer Games. \" And he forced us to figure out how to make our own games. So Manny and I made a game on one of the computers Dad had. I had so much fun doing it. That influenced me in my decision to become a computer scientist. It changed the whole trajectory of my life. K LAWSON: His influence speaks to his personality and who he was. Dad was a man without limitations as far as what he felt he could do or accomplish. So when he did pass, as sad as it was, you and I both know that he lived a full life. A LAWSON: He was a man that went his own path. If everyone was going right, he'd figure out a good reason to go left. and. . . K LAWSON: Yes. A LAWSON: . . . That was just him. He created his own destiny. KING: Anderson and Karen Lawson remembering their dad, Gerald, who died in 2011. That conversation will be archived at the Library of Congress. (SOUNDBITE OF BRYAN COPELAND'S \"ELEGIAC\")", "section": "StoryCorps", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-09-21-1039313011": {"title": "TikTok Users Watch Nancy Pelosi For Stock Trade Tips From Congress Disclosures : NPR", "url": "https://www.npr.org/2021/09/21/1039313011/tiktokers-are-trading-stocks-by-watching-what-members-of-congress-do", "author": "No author found", "published_date": "2021-09-21", "content": "AUDIE CORNISH, HOST:  During the pandemic, beginner investors jumped into the market, fueled by new apps and widely available data. And they've got a new strategy - taking stock tips from sitting members of Congress. NPR investigative correspondent Tim Mak has more. TIM MAK, BYLINE: Among a group of retail investors on TikTok, Speaker Nancy Pelosi's stock trading disclosures are a treasure trove. (SOUNDBITE OF MONTAGE)UNIDENTIFIED PERSON #1: Shouts out to Nancy Pelosi, the stock market's biggest whale. UNIDENTIFIED PERSON #2: So I've come to the conclusion that Nancy Pelosi is a psychic and she can guess when a stock is going to pop. CHRIS JOSEPHS: She knew. And you would have known if you followed her portfolio on Iris. Come do it. I have a group chat going. . . MAK: That last voice was Chris Josephs, the co-founder of a company that shows other people's stock trades. In the last year and a half, he's been taking advantage of a law requiring lawmakers to disclose their stock trades and those of their spouses within 45 days. It's called the Stock Act. JOSEPHS: When Nancy Pelosi started being right on everything, it started with CrowdStrike. Then she made a big - or her husband made big bets on Tesla and then Google. MAK: In 2020, Josephs noticed that the trades, actually made by Pelosi's investor husband and disclosed by the speaker, were really good. Now on the platform he's created, you can get a push notification every time Pelosi's stock disclosures are released. Josephs plans to track a large variety of federal politicians. JOSEPHS: We don't want this to obviously be a left versus right thing. We don't really care. We just want to make money. MAK: A Pelosi spokesperson said that she does not personally own any stocks and that the transactions are made by her husband. She's not the only lawmaker who is filing these disclosures. So far this year, Senate and House members have filed more than 4,000 financial trading disclosures, with at least $315 million of stocks and bonds bought or sold. Both investors and government watchdogs are interested in these trades because lawmakers could use information they get on the job to make lucrative stock decisions. NPR, for example, reported how Senate Intelligence Committee Chairman Richard Burr privately warned a small group of well-connected constituents back in February 2020 about the dire effects of the coming pandemic. (SOUNDBITE OF ARCHIVED RECORDING)RICHARD BURR: There's one thing that I can tell you about this. It is much more aggressive in its transmission than anything that we have seen in recent history. MAK: He also sold up to $1. 72 million worth of personal stocks on a single day that February. Other senators soon came under suspicion. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED PERSON #3: Dianne Feinstein and James Inhofe and Georgia Senator Kelly Loeffler allegedly sold off stocks within days of a classified briefing about the coronavirus. MAK: But after investigations by federal law enforcement, none were charged with insider trading. It's a very difficult charge to make against a sitting lawmaker. James Kardatzke is the CEO of Quiver Quantitative, a data platform which has also started collecting and presenting details from congressional trading disclosures. JAMES KARDATZKE: Obviously our lawmakers have access to a lot of information that isn't readily available to all of us, and I think it's only natural to assume that some of them may be using that to drive their own investment decisions. MAK: There's a deep cynicism that forms the foundation for this trading strategy. Politicians are corrupt, and you can't trust them not to engage in insider trading. If the information is public, you might as well trade what they're trading. RAJA KRISHNAMOORTHI: In this country, people already are deeply alienated from our economic system, and they're increasingly alienated from our political system. MAK: That's Congressman Raja Krishnamoorthi, a Democrat from Illinois. Along with a bipartisan group in the House and Senate, he has introduced legislation banning lawmakers from owning individual stocks. He's run up against a lot of opposition to the idea. KRISHNAMOORTHI: As I understand it, one of the perks of being a member of Congress, especially from the late 1800s on, was to be able to trade on insider information. And that has got to come to an end. MAK: According to a survey done this year by Data for Progress, 67% of Americans believe federal lawmakers should not own individual stocks. But while lawmakers can, the public is taking advantage of the situation. Professor Dinesh Hasija is an assistant professor at Augusta University, and he's been researching whether the market moves based on congressional disclosures. DINESH HASIJA: We see an abnormal positive returns when there's a disclosure by a senator. MAK: After the disclosures come out, there's a bump in the price of stocks bought by lawmakers. We even spoke to one financial services consultant planning to set up a financial instrument that automatically tracks congressional stock picks. But for all the cynicism about politicians, academic studies over the last few years have suggested lawmakers are not so good at picking stocks. Here's Professor Hasija again. HASIJA: Those papers have found that in fact, the trades made by senators have underperformed. MAK: Which means if you ever take stock tips from a member of Congress, cynicism aside, it might not be a very good trade. Tim Mak, NPR News. (SOUNDBITE OF THE BLACK KEYS SONG, \"SO HE WON'T BREAK\") AUDIE CORNISH, HOST:   During the pandemic, beginner investors jumped into the market, fueled by new apps and widely available data. And they've got a new strategy - taking stock tips from sitting members of Congress. NPR investigative correspondent Tim Mak has more. TIM MAK, BYLINE: Among a group of retail investors on TikTok, Speaker Nancy Pelosi's stock trading disclosures are a treasure trove. (SOUNDBITE OF MONTAGE) UNIDENTIFIED PERSON #1: Shouts out to Nancy Pelosi, the stock market's biggest whale. UNIDENTIFIED PERSON #2: So I've come to the conclusion that Nancy Pelosi is a psychic and she can guess when a stock is going to pop. CHRIS JOSEPHS: She knew. And you would have known if you followed her portfolio on Iris. Come do it. I have a group chat going. . . MAK: That last voice was Chris Josephs, the co-founder of a company that shows other people's stock trades. In the last year and a half, he's been taking advantage of a law requiring lawmakers to disclose their stock trades and those of their spouses within 45 days. It's called the Stock Act. JOSEPHS: When Nancy Pelosi started being right on everything, it started with CrowdStrike. Then she made a big - or her husband made big bets on Tesla and then Google. MAK: In 2020, Josephs noticed that the trades, actually made by Pelosi's investor husband and disclosed by the speaker, were really good. Now on the platform he's created, you can get a push notification every time Pelosi's stock disclosures are released. Josephs plans to track a large variety of federal politicians. JOSEPHS: We don't want this to obviously be a left versus right thing. We don't really care. We just want to make money. MAK: A Pelosi spokesperson said that she does not personally own any stocks and that the transactions are made by her husband. She's not the only lawmaker who is filing these disclosures. So far this year, Senate and House members have filed more than 4,000 financial trading disclosures, with at least $315 million of stocks and bonds bought or sold. Both investors and government watchdogs are interested in these trades because lawmakers could use information they get on the job to make lucrative stock decisions. NPR, for example, reported how Senate Intelligence Committee Chairman Richard Burr privately warned a small group of well-connected constituents back in February 2020 about the dire effects of the coming pandemic. (SOUNDBITE OF ARCHIVED RECORDING) RICHARD BURR: There's one thing that I can tell you about this. It is much more aggressive in its transmission than anything that we have seen in recent history. MAK: He also sold up to $1. 72 million worth of personal stocks on a single day that February. Other senators soon came under suspicion. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED PERSON #3: Dianne Feinstein and James Inhofe and Georgia Senator Kelly Loeffler allegedly sold off stocks within days of a classified briefing about the coronavirus. MAK: But after investigations by federal law enforcement, none were charged with insider trading. It's a very difficult charge to make against a sitting lawmaker. James Kardatzke is the CEO of Quiver Quantitative, a data platform which has also started collecting and presenting details from congressional trading disclosures. JAMES KARDATZKE: Obviously our lawmakers have access to a lot of information that isn't readily available to all of us, and I think it's only natural to assume that some of them may be using that to drive their own investment decisions. MAK: There's a deep cynicism that forms the foundation for this trading strategy. Politicians are corrupt, and you can't trust them not to engage in insider trading. If the information is public, you might as well trade what they're trading. RAJA KRISHNAMOORTHI: In this country, people already are deeply alienated from our economic system, and they're increasingly alienated from our political system. MAK: That's Congressman Raja Krishnamoorthi, a Democrat from Illinois. Along with a bipartisan group in the House and Senate, he has introduced legislation banning lawmakers from owning individual stocks. He's run up against a lot of opposition to the idea. KRISHNAMOORTHI: As I understand it, one of the perks of being a member of Congress, especially from the late 1800s on, was to be able to trade on insider information. And that has got to come to an end. MAK: According to a survey done this year by Data for Progress, 67% of Americans believe federal lawmakers should not own individual stocks. But while lawmakers can, the public is taking advantage of the situation. Professor Dinesh Hasija is an assistant professor at Augusta University, and he's been researching whether the market moves based on congressional disclosures. DINESH HASIJA: We see an abnormal positive returns when there's a disclosure by a senator. MAK: After the disclosures come out, there's a bump in the price of stocks bought by lawmakers. We even spoke to one financial services consultant planning to set up a financial instrument that automatically tracks congressional stock picks. But for all the cynicism about politicians, academic studies over the last few years have suggested lawmakers are not so good at picking stocks. Here's Professor Hasija again. HASIJA: Those papers have found that in fact, the trades made by senators have underperformed. MAK: Which means if you ever take stock tips from a member of Congress, cynicism aside, it might not be a very good trade. Tim Mak, NPR News. (SOUNDBITE OF THE BLACK KEYS SONG, \"SO HE WON'T BREAK\")", "section": "Investigations", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-09-23-1039915145": {"title": "A New NASA Telescope Will Scour Distant Solar Systems For Signs Of Life : NPR", "url": "https://www.npr.org/2021/09/23/1039915145/nasa-life-planets-telescope", "author": "No author found", "published_date": "2021-09-23", "content": "AUDIE CORNISH, HOST:  Where else might life have evolved besides Earth? Scientists are about to get a new shot at answering that question because in December, NASA plans to launch the most powerful telescope ever put into space. NPR's Nell Greenfieldboyce reports that we'll spend a lot of time studying planets outside our solar system. NELL GREENFIELDBOYCE, BYLINE: Laura Kreidberg studies planets that orbit distant stars. She's an astronomer at the Max Planck Institute for Astronomy in Germany. And she says for her entire career, she's been waiting for the James Webb Space Telescope. LAURA KREIDBERG: I think the earliest discussions about James Webb were happening in the 1990s, when I was in elementary school. GREENFIELDBOYCE: Astronomers wanted to build a huge telescope that could capture light from some of the earliest galaxies to appear after the Big Bang. This telescope has been a long time coming. KREIDBERG: It has been something that has been looming on the horizon. Every year, it's, you know, one more year. GREENFIELDBOYCE: Finally it's scheduled to launch this December. The James Webb Space Telescope is named after a former NASA administrator. And once it's in space, one of its major activities will be studying planets beyond our solar system. Kreidberg says that was never part of its original mission. When this telescope was first proposed, such planets had only just started to be discovered. KREIDBERG: Now, 25 years after the first planet was discovered around another star, we know that pretty much every star on average has at least one planet. GREENFIELDBOYCE: The trouble is it's difficult to know what these far-off planets are really like. Scientists usually never see the planet; they detect it indirectly by watching how the planet affects its star. Lisa Kaltenegger is an astronomer at Cornell University. She says it is sometimes possible to learn a bit about a planet's atmosphere by analyzing starlight that filters through it. LISA KALTENEGGER: We can do this analysis right now for the big, hot planets with lots of gas that the light shines through. But for the small planets, like the Earth, with a little bit of an atmosphere, we need to catch more light to do the same thing. GREENFIELDBOYCE: Because James Webb is huge, it can catch enough light to let scientists analyze the chemical makeup of small, rocky planets' atmospheres. That's important because if any of those planets has life, you'd expect to see certain combinations of different gases in the air, like oxygen plus methane. Nikole Lewis, another astronomer at Cornell, says these telltale gas mixtures are called biosignatures. NIKOLE LEWIS: The James Webb Space Telescope does have the capability to measure those key biosignatures. GREENFIELDBOYCE: One intriguing planetary system that James Webb will study is about 40 light years away. There's a small, cool star that's orbited by seven Earth-sized planets. Three of them orbit in a zone where temperatures should be mild enough to have water in liquid form. Lewis says the first question scientists want to answer is, do these planets have air? LEWIS: And then we're going to go from there. OK, what's that air made of? And is the air the same for planets that are close to the star or planets that are far from the star? And so it's a perfect little laboratory that, you know, nobody expected we would find. And it's a perfect target for the James Webb Space Telescope. GREENFIELDBOYCE: Still, trying to tease out subtle combinations of gases that might mean life is a really, really hard thing to do. And remember, James Webb was never designed with this in mind. That's why, even as scientists are excited for it to launch later this year, many are also pushing for future space telescopes that will be designed from the start to search other planets for signs of life. Nell Greenfieldboyce, NPR News. (SOUNDBITE OF BAHAMAS SONG, \"CAUGHT ME THINKIN'\") AUDIE CORNISH, HOST:   Where else might life have evolved besides Earth? Scientists are about to get a new shot at answering that question because in December, NASA plans to launch the most powerful telescope ever put into space. NPR's Nell Greenfieldboyce reports that we'll spend a lot of time studying planets outside our solar system. NELL GREENFIELDBOYCE, BYLINE: Laura Kreidberg studies planets that orbit distant stars. She's an astronomer at the Max Planck Institute for Astronomy in Germany. And she says for her entire career, she's been waiting for the James Webb Space Telescope. LAURA KREIDBERG: I think the earliest discussions about James Webb were happening in the 1990s, when I was in elementary school. GREENFIELDBOYCE: Astronomers wanted to build a huge telescope that could capture light from some of the earliest galaxies to appear after the Big Bang. This telescope has been a long time coming. KREIDBERG: It has been something that has been looming on the horizon. Every year, it's, you know, one more year. GREENFIELDBOYCE: Finally it's scheduled to launch this December. The James Webb Space Telescope is named after a former NASA administrator. And once it's in space, one of its major activities will be studying planets beyond our solar system. Kreidberg says that was never part of its original mission. When this telescope was first proposed, such planets had only just started to be discovered. KREIDBERG: Now, 25 years after the first planet was discovered around another star, we know that pretty much every star on average has at least one planet. GREENFIELDBOYCE: The trouble is it's difficult to know what these far-off planets are really like. Scientists usually never see the planet; they detect it indirectly by watching how the planet affects its star. Lisa Kaltenegger is an astronomer at Cornell University. She says it is sometimes possible to learn a bit about a planet's atmosphere by analyzing starlight that filters through it. LISA KALTENEGGER: We can do this analysis right now for the big, hot planets with lots of gas that the light shines through. But for the small planets, like the Earth, with a little bit of an atmosphere, we need to catch more light to do the same thing. GREENFIELDBOYCE: Because James Webb is huge, it can catch enough light to let scientists analyze the chemical makeup of small, rocky planets' atmospheres. That's important because if any of those planets has life, you'd expect to see certain combinations of different gases in the air, like oxygen plus methane. Nikole Lewis, another astronomer at Cornell, says these telltale gas mixtures are called biosignatures. NIKOLE LEWIS: The James Webb Space Telescope does have the capability to measure those key biosignatures. GREENFIELDBOYCE: One intriguing planetary system that James Webb will study is about 40 light years away. There's a small, cool star that's orbited by seven Earth-sized planets. Three of them orbit in a zone where temperatures should be mild enough to have water in liquid form. Lewis says the first question scientists want to answer is, do these planets have air? LEWIS: And then we're going to go from there. OK, what's that air made of? And is the air the same for planets that are close to the star or planets that are far from the star? And so it's a perfect little laboratory that, you know, nobody expected we would find. And it's a perfect target for the James Webb Space Telescope. GREENFIELDBOYCE: Still, trying to tease out subtle combinations of gases that might mean life is a really, really hard thing to do. And remember, James Webb was never designed with this in mind. That's why, even as scientists are excited for it to launch later this year, many are also pushing for future space telescopes that will be designed from the start to search other planets for signs of life. Nell Greenfieldboyce, NPR News. (SOUNDBITE OF BAHAMAS SONG, \"CAUGHT ME THINKIN'\")", "section": "Space", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-09-23-1040081678": {"title": "What Leaked Internal Documents Reveal About The Damage Facebook Has Caused : NPR", "url": "https://www.npr.org/2021/09/23/1040081678/what-leaked-internal-documents-reveal-about-the-damage-facebook-has-caused", "author": "No author found", "published_date": "2021-09-23", "content": "TERRY GROSS, HOST:  This is FRESH AIR. I'm Terry Gross. Internal Facebook documents were leaked by a whistleblower and acquired by my guest Jeff Horwitz, a technology reporter for The Wall Street Journal. He's the lead reporter for The Journal's new series of articles called \"The Facebook Files. \" This series details how Facebook executives are aware of the ways the platform causes harm, but executives often lack the will or the ability to address them. The series reveals how a separate set of rules has been applied to VIP users like celebrities and politicians, allowing them to at least briefly escape restrictions and penalties that are applied to other users. Facebook's own researchers are aware that Instagram, which is owned by Facebook, has negative effects on the self-image and mental health of many teenage girls. Internal documents also reveal that Facebook researchers have warned the company's executives that the platform is used in developing countries for human trafficking, drug-dealing and to promote ethnic violence. The company's CEO, Mark Zuckerberg, has made it a goal to promote the COVID-19 vaccine, but his researchers have pointed out that that effort is being undermined by commenters spreading misinformation. At least some of the leaked internal documents have been turned over by the whistleblower to the Securities and Exchange Commission and to Congress. Jeff Horwitz, welcome to FRESH AIR. Congratulations on the series, which isn't over yet (laughter). You're still - there's more to come. So what are these internal documents that were leaked? JEFF HORWITZ: So this is a collection of internal research notes, executive presentations, in some cases company audits of its own practices that provide a pretty clear sense of how Facebook sees itself and the company's awareness of its own problems. And I think that's something that sort of separates it from a lot of other really good reporting on the company, which is that instead of this being outside voices asking questions about whether or not Facebook is being detrimental to the world, this is Facebook asking those questions and answering them and sometimes finding that the answer is very much yes. GROSS: And what you're talking about is researchers from Facebook who report to executives and tell them what's going on. And often what they've told them is that this platform is backfiring. It's causing harm for these and these reasons. HORWITZ: Yeah, exactly. I think it's important to draw a distinction between sort of irate watercooler chat and people letting off steam about things that don't really involve them at the company versus this stuff, which is these are the people that Facebook has hired to inform it of reality and to help it address problems. And in many cases, they are finding some really unpleasant things and then running into obstacles in trying to fix them. GROSS: Now, are the obstacles a lack of will? Or are the obstacles that Facebook is so big and there are so many users that it is hard to control, even if you want to? HORWITZ: I think that the premise that the company is just too big to be - to regulate itself isn't correct. There are - yes, having nearly 3 billion users is quite a lot of users to have to be in charge of. But what our reporting seems to indicate is that the company's complexity has become a big problem, as well as just kind of a lack of will and lack of interest in some instances. So it's not that a platform couldn't be made to work for this many users in a sort of simpler and safer way. It's that you can't have all the bells and whistles, and you can't maximize engagement in the way that Facebook would like to and not have that come at a cost. GROSS: Let's look at the first program you reported on, which is a VIP program called XCheck. This is a program that basically created separate rules for VIPs and for everybody else who uses Facebook. What VIPs have been exempt from certain rules? What kinds of people? HORWITZ: Oh, a lot of them. So Facebook has talked in the past about providing some - a little bit of extra leeway for politicians and fact-checking and misinformation - right? - the idea being that, you know, in an election, candidates should have the right to say whatever they want to say even if those things aren't strictly true. And the thing we found is that the protections Facebook offers to powerful users go far, far beyond that. So they include celebrities. They include journalists. I have no doubt that you should qualify. I most certainly should qualify. They include athletes and just sort of people who are famous for being famous, influencers. They include animal influencers. So you know, just, like, literally, the account Doug the Pug is actually covered by XCheck, which was the program. So basically, the idea is - the commonality among all these people and entities and animals is that they are big enough and prominent enough, they could cause problems for the platform. The way that this program was designed very explicitly internally was to avoid, quote-unquote, \"PR fires. \" And I think that's something that kind of sticks out in general in this reporting, is that the thing that makes Facebook scared more so than harm that it might be causing is the risk of public embarrassment. GROSS: What kind of public embarrassment? What kind of PR fire? HORWITZ: So this can be everything from making a mistake and tangling with, you know, the singer Rihanna's account because she posted a risque French magazine cover to, you know, making an error on something Donald Trump said to, you know, anything that basically would result in the company receiving widespread public criticism. And I think this is something that is kind of - exists throughout the series, is that Facebook really likes to stay in the background. They really would like to be kind of viewed as this neutral platform in which just kind of life plays out online. And as you know, what our reporting tends to show is that that is not the case. The company is actively making a lot of choices, is determining which interests benefit and at what expense. And I think XCheck is kind of a perfect example of that, which is that the whole idea is to never publicly tangle with anyone who is influential enough to do you harm. GROSS: Can you give us an example of a post that caused harm or could potentially cause harm that was allowed to stay up for a long time or a brief time because this person was a VIP? HORWITZ: Sure. And there are - so there are a lot of them. Facebook's own analysis of XCheck found that 16. 4 billion views of violating content occurred solely because of the lag time in taking down stuff from VIPs that shouldn't have been up in the first place. But I think the example I would give for how this program can cause harm and does sort of run against Facebook's sort of basic ethos of fairness is the Brazilian soccer player Neymar, who, in 2019, was accused by a Brazilian woman of rape. And he, to defend himself, took to Instagram and took to Facebook in a live video. And he showed pictures of this - of his WhatsApp chats with this woman, his messages with this woman. And those messages included not just her name, but also nude photos of her that she had shared with him. And this is just a complete no-go on Facebook. You are not allowed to broadcast people's naked pictures without their consent. It is called nonconsensual nude imagery at Facebook. It's called revenge porn everywhere else. And the appropriate response, per Facebook's own rules, is to immediately take down the post and delete the account that posted it. So that was kind of what would have happened. A Facebook employee did catch this, you know, pretty early on and tried to delete it. But the problem was Neymar's account was cross-checked. So it didn't come down. In fact, it stayed up for 36 hours, during which it racked up 56 million views. And this resulted in extensive harassment of the woman who had accused him of sexual assault. There were thousands and thousands of impersonators of her. And the video was reposted just all over the Internet. And basically, Facebook acknowledged internally that it had just completely failed to protect this woman. And this happened because of XCheck. Now, I think another part of the program that is important is that it really does and is intentionally designed to allow executives, communications and sort of public affairs people to weigh in on punishments that would otherwise be doled out. And that's what happened in this instance is that Neymar, who is one of the top 20 accounts on Instagram - like, this is a guy who is probably more famous for social media than he is for soccer. Facebook just simply wasn't willing to lose him. And so this got bumped all the way up to senior leadership of the company. And they determined that rather removing him from the platform, even though that was the absolute standard rule for this situation, they were going to kind of let it slide. So they took down the post in the end. But they didn't punish his account in the way they normally would. And I think it's kind of representative of the dual-class - or even more than dual-class system that Facebook created, in some ways, reinforcing power structures that, you know, the company has said it was supposed to kind of overthrow. GROSS: There was a 2019 internal review of the XCheck program. What did that review say? HORWITZ: I think people inside Facebook did have, on a long-term basis, a sense that exempting users from enforcement and from punishment on the platform was just, like, clearly not the right thing to do. This is not what Facebook was set to do. This isn't democratic. It isn't fair. And in 2019, an internal review of the XCheck program found a few things. The first one is that it was completely widespread, that there were dozens and dozens of teams that were enrolling users in various protections and that, in fact, pretty much any employee had been allowed to enter people into the XCheck program in the first place. The second thing is that it was just deeply mismanaged and unorganized. And no one really even knew how these lists were getting pulled together. They weren't being reviewed by lawyers. There was just sort of, kind of this ad hoc process where people would just put in names. And the final thing is that they found that this was just completely indefensible. This was a breach of trust with users. It was putting users in risk of harm. And it was clearly unfair. And as they noted, this was publicly indefensible and simply something that, you know, was completely at odds with the company's own sense of its legitimacy as an overseer of its own platform. GROSS: What was Facebook executives' reactions after getting this report? HORWITZ: Facebook - I mean, no one disputed that XCheck was a mess and that the program was unseemly and was in, you know, direct conflict with what the company had said publicly its rules are. That said, they really weren't willing to take on the mess of just simply doing away with it, particularly with the 2020 election coming up. I think this is something that - you know, over the period of time that the documents we reviewed cover, this company was paranoid about the possibility that it might be blamed for something in relation to the 2020 election. And so they desperately wanted to keep a low profile. And there was no way that they were going to rein the program in because this was kind of one of their main methods of trying to avoid criticism from high-profile people. GROSS: Let's talk about anti-vax posts on Facebook. Mark Zuckerberg has made it a priority to promote vaccines and facts about vaccines. But at the same time, Facebook has been used widely to convey anti-vax falsehoods. And you found that internal documents reveal that the anti-vax comments were mostly coming not from the original post, but from commenters. Would you describe what happened with that? HORWITZ: Sure. And I think a important place to start here is what you said about Mark Zuckerberg and his goals. This is something - fighting COVID was something that Facebook was, perhaps, uniquely inclined and positioned to do. They early on recognized the threat of the public health crisis back when a lot of other people were poo-pooing the possibility of the global pandemic. They sent all their moderators home, content moderators home, with pay. You know, they sort of really reframed and sort of sprinted to provide new tools, to provide information, to, you know, help out with public health efforts. They really were focused on this. And this was something that came from Mark Zuckerberg personally. I mean, this was kind of going to be Facebook's moment. And I think the interesting thing about this is that there were, you know, sort of all these resources and good intentions put into it, and yet also this kind of failure by the company to recognize the risks that its own platform could pose. And it's not as if Facebook hadn't had plenty of warnings that the anti-vaccine movement was very active on its platform. If you remember the, you know, measles outbreaks back in 2019 at Disneyland and things like that, there was a very, very aggressive community of anti-vaccine activists that have been active on the platform, had gotten really sophisticated in terms of their methods and their approach. And so the company sort of focused on the positive and all the things it could do that would be helpful and really didn't pay much attention to the, I think, fairly obvious threat that a small band of people who were extremely dedicated could pose if they correctly harnessed Facebook's tools, which they did. GROSS: Well, let's take a short break here. And then we'll talk some more. If you're just joining us, my guest is Jeff Horwitz, who is the lead reporter for The Wall Street Journal's new and ongoing series of articles called \"The Facebook Files. \" We'll be right back after a short break. This is FRESH AIR. (SOUNDBITE OF OF MONTREAL SONG, \"GRONLANDIC EDIT\")GROSS: This is FRESH AIR. Let's get back to my interview with Jeff Horwitz, who is the lead reporter on a new and ongoing Wall Street Journal series called \"The Facebook Files,\" based on a series of leaked documents from Facebook. These documents detail how Facebook executives are aware of the ways the platform causes harm, but executives often lack the will or the ability to address them. Is it harder to oversee or to apply rules to commenters than it is with people doing the original posts on Facebook? HORWITZ: This was a bit of a blind spot for the company. They hadn't really ever put that much resources into trying to understand comments, which is kind of funny because Facebook really did engineer its platform to produce a ton of comments. And they - what they realized early in 2021 was that, you know, as the vaccine was rolling out - was that all of the authoritative sources of information about it - right? - the World Health Organization, UNICEF and so on - all of their posts were just getting swamped by anti-vaccine advocates who were, you know, producing, at extremely high volume, content in the form of comments that was kind of just hitchhiking around. And I think the company understood this, to its credit, at that point as being a real threat because, you know, it's one thing to see something authoritative from UNICEF, and it's another thing to see that same thing and then a whole bunch of people saying don't believe it, right? And that's kind of the style of comment that was rising to the top of Facebook's own systems. So they realized that basically all of the things they were doing to try to promote authoritative information were in some ways being harnessed by the people who were trying to promote the exact opposite. GROSS: Internal documents also show that Facebook knew - that it was really a small group responsible for most of the COVID misinformation on Facebook. So what was Facebook's response to this research that was delivered to executives? HORWITZ: Yeah. So the initial response was just basically horror because they realized that, you know, there were just a very high proportion, not only of comments but also posts in general, that seemed to be - vaccine-hesitant was the company's phrase - so not necessarily straight misinformation - you know, false things like saying vaccines cause autism or make you sterile - but people who simply were exercising their right to speak on the platform as often as possible and in just extremely coordinated, almost cut-and-paste-style ways. And they were creating, basically, a false sense that there was a large public debate about the safety of vaccines, when there really isn't. So the initial response was just, uh-oh, this is a huge problem. We've got to fix it. And then the second response was, OK, how do we do that because they didn't really have the tools in place. They hadn't planned for this. And so they had to kind of make do with a whole bunch of kind of ad hoc interventions and try to sort of start getting public discourse to be at least somewhat representative - right? - so that any time someone who was, you know, encouraging about vaccinations wouldn't just get dogpiled by a - you know, a very, very dedicated group of anti-vaccine advocates. GROSS: Were these changes effective in stopping misinformation about the vaccine? HORWITZ: I think it's kind of too soon to tell how well they did. Certainly in terms of preventing this stuff from getting traction in the first place, they failed - right? - means that there were, you know - the whole problem and the thing that kicked this - kicked Facebook's response into gear was that public debate on the platform about this thing was skewed. It was getting sort of manipulated by anti-vaccine advocates. And, I mean, the fact that this was happening in 2021, as the vaccine was getting rolled out, you know, from, you know, the initial sort of first responders and medical officials to the broader population, certainly seems like it could have had an impact. And I think, you know, the company would note that it's not the only source of vaccine misinformation in the world by any means, right? There's plenty of stuff on cable TV that would have you believe bad things about the efficacy, safety and utility of the vaccine. But certainly, it's a remarkable thing for a company that really saw itself as being, you know, in the vanguard of solving a public health crisis that, you know, they're basically having to go back and fight with this highly active, somewhat ridiculous community that is just spamming their platform with bad information. GROSS: Let's take another break here, and then we'll talk some more. If you're just joining us, my guest is Jeff Horwitz, a technology reporter for The Wall Street Journal who's the lead reporter for The Journal's new series of articles called \"The Facebook Files,\" based on internal Facebook documents that were leaked to The Journal. We'll be back after we take a short break. I'm Terry Gross, and this is FRESH AIR. (SOUNDBITE OF CHARLIE HUNTER AND LEON PARKER'S \"THE LAST TIME\")GROSS: This is FRESH AIR. I'm Terry Gross. Let's get back to my interview with Jeff Horwitz, a technology reporter for The Wall Street Journal who's the lead reporter for the Journal's new series of articles called \"The Facebook Files,\" which detail how Facebook executives are aware of the ways the platform causes harm but executives often lack the will or the ability to address them. The series is based on internal Facebook documents that were leaked by a whistleblower to Jeff Horwitz. Let's talk about Instagram, which is owned by Facebook. Internal research from Facebook shows that Instagram could have a very damaging impact on teenage girls' self-image, their anxiety, depression. Why does Instagram sometimes have that effect on teenage girls? - 'cause you write that the algorithms on Instagram create a perfect storm for many teenage girls. HORWITZ: Yeah. So body image issues and social comparison obviously didn't originate with the internet. That said, Facebook's own research found that Instagram had some uniquely harmful features in terms of encouraging young women in particular to compare themselves with others and to think about the flaws of their bodies in relation to others. And, you know, this wasn't intentional. The company certainly hadn't meant to design something that did this. But, you know, there was no question in their own findings that, you know, compared to even other social media products, Instagram was worse in this respect - that it was very focused on the body as opposed to the face or performance and that, for users who arrived at the platform in not the best mental place, it could really have a big impact on them. GROSS: What is the way in which algorithms create a perfect storm for teenagers? - 'cause you say that in the article. HORWITZ: Right, right. So I think there's some core product mechanics here, which is that Instagram will always show you the most popular and successful posts from your friends and the people you follow and - whereas you're comparing that to your regular posts and your regular life. So there's kind of this kind of highlight reel ethos to it that tends to lead users to think that everyone else is living their best life while, you know, they're not. And so that's part of it. Another part of it is just simply that people tend to be attracted to content that sort of really resonates with them. And if you have body image issues already, Instagram - and you are engaged with sort of looking at people who are prettier than you are on the platform, Instagram's going to keep on doing that. If you have concerns about diet and fitness and you think you might be overweight, Instagram is likely going to pick up on that and feed you a ton of dieting and fitness content. And so they're kind of this - there's this feedback loop that the platform can create. And it turns out for people who are in a vulnerable place in the first place, it can be really damaging and, in some ways, lead to almost addictive-type behavior per Instagram's own analysis. GROSS: So what you've just described is reported in documents that were written by Facebook researchers and then delivered to Facebook executives. So executives knew what you just told us, right? HORWITZ: Absolutely. And Adam Mosseri, who's the head of Instagram, in fact, commissioned a lot of this research in the first place. So, you know, I think there's some credit that should go to the company for determining that - given the extensive external criticism of the company on these fronts, that perhaps it should at least get to the bottom of them. And it did. I mean, I think there's no question that what it found, you know, was convincing. As the company's own presentation - one of the presentations to executives notes, we make body image issues worse in 1 in 3 teen girls. GROSS: But you write that this represents one of the clearest gaps revealed in these internal documents, gaps between Facebook's understanding of itself and its public position. HORWITZ: Yeah. Look; I can understand why someone in corporate communications isn't eager to make the sentence, we make body image issues worse in 1 in 3 teen girls, public, much less some of the other things in these findings which included that young women who had thought about self-harm or suicide in the last month - that a not-tiny fraction of them traced those feelings directly back to Instagram's platform. So think potentially life-threatening effects. And I can understand why the company wouldn't want to acknowledge that publicly, you know, or wouldn't want to talk about it much. I think what's interesting is the company did talk about these issues. They just didn't say that. What they said is that there were perhaps small effects, that the research was inconclusive, that, you know, there wasn't any, you know - that, you know, if there was an issue, it was bidirectional, so it was good for some users and bad for some users - basically really downplayed the clarity that they had internally about what was going on and the effect of their product. GROSS: What was Facebook's reaction to your article about teenagers and Instagram? HORWITZ: They defended the research and keeping the research private as necessary for, you know, honest internal discussion. And they, I think, tried to argue a bit with whether or not the conclusions of causality that seem to be very present within their own - how their own researchers discussed this stuff even with management - they sort of tried to undermine, you know, the certainty that it really sort of feels like pervades the presentations that the company's researchers gave to executives. But, you know, I don't think they disagree with the issues. They sort of defended the things that they have said previously about there being relatively small effects. And, you know, I've noted that for many users and users who are in sort of a healthy emotional place, Instagram is a lot more beneficial than it is harmful, all of which is true. None of that is wrong. It's just that the question is, at what cost to vulnerable users? GROSS: Well, let's take another short break here. If you're just joining us, my guest is Jeff Horwitz, who is the lead reporter for The Wall Street Journal's new series of articles called \"The Facebook Files. \" We'll be right back after a break. This is FRESH AIR. (SOUNDBITE OF SOLANGE SONG, \"WEARY\")GROSS: This is FRESH AIR. Let's get back to my interview with Jeff Horwitz, a technology reporter for The Wall Street Journal. He's the lead reporter for The Journal's new series of articles called \"The Facebook Files,\" which detail how Facebook executives are aware of the ways the platform causes harm, but executives often lack the will or the ability to address them. The series is based on internal Facebook documents that were leaked by a whistleblower to Jeff Horwitz. One of the articles in the series is headlined \"Facebook Tried To Make Its Platform A Healthier Place. It Got Angrier Instead. \" And this article is about a change that was made in 2018 that rewarded outrage. What was the change? HORWITZ: Facebook promoted something in 2018 called meaningful social interaction. And the idea was that passively scrolling through content wasn't good for people - you know, it just turned them into zombies - and that what Facebook should be doing is encouraging people to sort of connect and engage with each other and with Facebook content more often. And there were two parts to this. One part was promoting content from people's friends and families, which was kind of a throwback to kind of an earlier era of Facebook where it was much more about that stuff than it was about kind of a constant stream of information and content. The second part, though, was rewarding content that did really well on engagement, meaning things that got a lot of likes, but even more important than likes, things that got a lot of emoji responses, comments, re-shares, direct message shares and things like that - so basically things that made users kind of pound the keyboard a bit and, you know, share and engage as much as possible. And you know, nothing about that seems, you know, atrocious in sort of a general high-level view. But it turns out, as Facebook realized down the road, that the effect that had was privileging angry, incendiary conflict because there is nothing more engaging than a fight. GROSS: And news publications, as a result, found that a lot of their traffic was decreasing dramatically. What was the connection? HORWITZ: So there was some element of this where they were just kind of reducing news overall in feed at the - you know, in other words - and to boost the stuff from friends and family. But I think the type of content that succeeded changed. And one thing we found was that BuzzFeed's - the head of BuzzFeed, Jonah Peretti, who is - you know, no one could accuse this guy of being unsophisticated when it comes to social media - was actually figured out that something had changed materially when Facebook rolled out this stuff and that, essentially, a type of content that was succeeding was - on the platform, was, like, sensationalistic, incendiary. Gross medical stuff was doing well - you know, things that sort of got a response. And you know, his point to Facebook when he got in touch was that, look, like, you guys are forcing us to produce worse content. And the same thing was true of political parties. They also picked up on what had changed, and they started adjusting accordingly. And so parties told Facebook that because of, literally, this algorithm change - like, some reweighting, some math - that they were shifting not just their communication strategy for the internet but, in some instances, their actual platform. GROSS: Once this was reported to Facebook executives, what actions did the executives take? HORWITZ: Facebook's attraction to meaningful social interaction as a metric wasn't just that they thought it would be good for people. It's also - they thought it would be good for Facebook. They really needed people to be engaging with content more because they'd been in decline in commenting and interaction in a way that was threatening to the future of a social network dependent on user-generated content. And so this had been really successful in terms of getting engagement back up and getting people to comment more. And the problem was that doing the things that researchers said would be necessary to sort of correct the amplified anger issue was going to come at the expense of some of the growth metrics that Facebook was pursuing. And that's always a hard sell inside that company. GROSS: What was Facebook's response to this article? HORWITZ: So Facebook noted that they had made some changes, which is true. I think the thing that we were very focused on is that people up to and including Mark Zuckerberg kind of resisted anything that was going to cause sacrifices in user growth numbers and in user engagement numbers for the purpose of improving the quality of discourse on the platform. So they told us on this one that basically any engagement-based ranking system or any ranking system is going to have problems - right? - that yes, they acknowledged that incendiary content did benefit from what they'd done, but, you know, that's not to say that there aren't disadvantages to other systems as well. GROSS: So one of your articles in The Journal reports that in developing countries, Facebook was often used by drug cartels, human traffickers, used to promote violence against ethnic groups. And developing countries are actually very important to Facebook now. And why is that? HORWITZ: People in poorer countries - they don't provide Facebook much money, but they do provide it with a lot of growth. The Facebook has basically stalled out in developed economies. I mean, there isn't really many - there isn't much in the way of new user growth to be achieved in the U. S. , Canada, Europe and wealthier nations. So this is kind of where pretty much all of the company's growth has been coming in recent years. And you know, that makes them kind of - places like India are sort of the company's future. And at the same time, though, Facebook has never really invested much in safety in those environments. And you know, they had, for example, a team of just a few people trying to focus on human trafficking across the globe. That includes sex trafficking, labor trafficking, organ trafficking. And they were clearly overwhelmed. And there were some, I think, serious issues of the company just simply not really caring all that much. I think one instance we found was that the company had identified sort of wide-scale human trafficking occurring, in which people from the Philippines and Africa were kind of indenturing themselves into domestic labor in the Gulf states. And they were - once there, kind of lost all autonomy. They could literally be resold without their permission. And Facebook actually had - first of all, had allowed this for a long time. Like, up until 2019, it was actually OK for people to be sold on Facebook so long as the selling was happening through brick-and-mortar establishments, as long as, you know, there was - it was in a country where this was allowed. And then I think more broadly, Facebook had just kind of turned a blind eye to this whole practice. One thing, you know, that I think was - really stood out to me just in terms of demonstrating the company's lack of will on some of these things is that Facebook, while it had identified widespread human trafficking, hadn't done anything about it - and in some instances for years. The thing that Facebook - moved Facebook in 2019 to take aggressive action on this was Apple. You know, maker of my iPhone told Facebook that it was going to take away - it was going to remove Instagram and Facebook from its App Store, basically make it so that people couldn't download the apps unless Facebook got its human trafficking problem under control. And boom, that was it, right? Actually, understanding human trafficking was happening on its platform wasn't enough to get Facebook's attention - what did was the threat that Apple might take an action that would severely damage its business. So Facebook, literally within days, was just pulling down content all over the place. And the crisis passed. And then, as we found, things went back to normal. And normal means that human trafficking is happening on a pretty widespread scale on the platform. GROSS: Another obstacle that you report is Facebook doesn't have enough people monitoring posts who speak the dialect needed to identify dangerous or criminal uses of Facebook. HORWITZ: Yeah. And this is something that I think - look; like, I think we're all familiar with Facebook's apologies right now, right? Like every couple of months or weeks or days, depending on how closely you're monitoring it, the company ends up saying that it's sorry that something happened. And particularly overseas, it seems like there's just this kind of succession of inadvertent oversights that come with large human consequences. And the thing we found is that these aren't accidents. These aren't due to the company, you know, just simply having too much to possibly do. These are issues of direct neglect. So for example, with Arabic, it's the third - world's third most commonly spoken language. It has many dialects that are mutually incomprehensible. Facebook literally can't - doesn't have anyone who can speak most of them or can understand most of them in terms of sort of the vernacular. And it also doesn't have a system to route content in those dialects to the right people. So when something happens like the Israeli-Palestinian violence earlier this year, the company is just sort of woefully unprepared to deal with it. They can't process content. They don't have people on staff. And, I mean, one of the things that's kind of tragic that we could see inside the documents was that you had all of these people who work for Facebook with Middle Eastern backgrounds who were just desperately trying to, like, kick in ad hoc to try to, like, help steer the company in a better direction because it was just screwing up so much at a time that was, like, so crucial on its platform. GROSS: Nick Clegg, who's the Facebook vice president of global affairs, recently published a blog post saying that The Wall Street Journal articles have contained deliberate mischaracterizations of what Facebook is trying to do and conferred egregiously false motives to Facebook's leadership and employees. What's your reaction to that? HORWITZ: My reaction is that Facebook has the right to say whatever they would like to say in response to our reporting. I think the more useful reaction to that isn't mine. It's that there actually have been in recent days a large number of former Facebook employees who have directly taken issue with what Mr. Clegg and what the company has said on these subjects. And I mean, these are people who actually were doing the work. Like, there are names that are popping up on Twitter that are the names that were sort of protagonists, I suppose, in some of the stories I could see playing out inside of the company. And what they've said very clearly is that - you know, one, that the things that we're raising are pretty much correct and, two, that there is, in fact, this history of kind of disregarding the work of the people Facebook's asked to do integrity work - integrity just being platform safety and content quality stuff. And so, you know, I think there's something really encouraging about some of these voices coming to the fore because these are people who sort of pioneered not just the ways to measure problems on the platform, but also ways to address them. And so the idea that they might be able to come out and talk more about the work they did is, I think, really interesting to me and, in some ways, would be very healthy for the company. GROSS: My guest is Jeff Horwitz, who is the lead reporter for The Wall Street Journal's new and ongoing series called \"The Facebook Files. \" This is FRESH AIR. (SOUNDBITE OF YO LA TENGO'S \"WEATHER SHY\")GROSS: This is FRESH AIR. Let's get back to my interview with Jeff Horwitz, a technology reporter for The Wall Street Journal, who's the lead reporter for the Journal's new series of articles called \"The Facebook Files. \" The series details how Facebook executives are aware of the ways the platform causes harm. But the series also says executives have often lacked the will or the ability to address those problems. The series is based on internal Facebook documents that were leaked by a whistleblower to Jeff Horwitz. What are some of the suggestions current or former Facebook employees have made, that you're aware of, of how to improve some of the problems that you've reported on? HORWITZ: Yeah, I think Facebook tends to treat social media as if it's - you know, Facebook is the only way in which it could possibly exist - right? - kind of a love-it-or-leave-it approach. And that, for their own - per their own employees, is absolutely not true. There are a number of things that can be changed, right? So in addition to just simply the question of resources, which would address a lot of problems, there are also ways in which the platform perhaps has grown too complex to be safe. So, for example, in developing countries, is it really a good idea for things to be able to go viral in a matter of minutes? Maybe that's not good if you're worried about information quality. So virality restrictions is one thing. There's other work that I think seems like it would be really promising, such as trying to give more prominence to voices that seem to have respectful conversations. It's the - the concept is called earned voice. And rather than just sort of rewarding the biggest loudmouth, this would reward people who tend to be able to have conversations with people who aren't necessarily exactly like them that are nonetheless respectful and, you know, mutually satisfying. Now, that's not, of course, the way you get the most engagement, but it is something that could potentially provide a different style of conversation that would be, I think, recognized by most people outside the company as healthier. GROSS: Recently, Facebook created what's been described as a Supreme Court for Facebook, an outside entity of experts who would help Facebook make complicated decisions about content. How has that been actually functioning? HORWITZ: So this came up in the XCheck story that we did about the sort of special protections for VIPs. Facebook spent $130 million creating the Oversight Board and - with the stated purpose of providing transparency and accountability into its operations. And one of the powers it gave the Oversight Board was the ability to ask Facebook questions that Facebook would then have to answer, assuming that they were relevant. And in the case of XCheck, the board asked the right questions. In relation to Donald Trump's suspension from the platform, the board asked, very specifically, for data about the program and for the XCheck program and about protections for VIP users. And Facebook said it didn't exist. And this is obviously awkward, given the stuff we've seen, because, you know, we can actually see there were internal dashboards of metrics as well as just voluminous documentation of the program's problems, of the number of accounts, of how many bad views of content occurred as a result of the lag in review times. You know, this is a pretty well-documented program internally, and Facebook told its supposed overseers that it just simply didn't have the information and couldn't possibly gather it. And the Oversight Board has, at this point, issued some pretty strong statements of discontent with that situation. But I think it does seem like a bit of a crisis in the sense that, you know, oversight does imply the ability to actually see what's going on inside the company. And I think the Oversight Board has, to its credit, recognized that that isn't something that Facebook is readily willing to provide. So what their role is, I think, going forward is going to be an interesting question, because they're, - you know, they're kind of being asked to play a self-regulatory role for Facebook. At the same time, they are fully independent, and they also seem to not have much trust in Facebook and whether Facebook's going to give them the truth about what Facebook is itself doing. GROSS: Well, Jeff Horwitz, thank you for your reporting, and thank you for coming on our show. HORWITZ: Thank you so much, Terry. GROSS: Jeff Horwitz is the lead reporter on The Wall Street Journal series \"The Facebook Files. \" If you'd like to catch up on FRESH AIR interviews you missed, like this week's interviews with B. J. Novak, who played Ryan in \"The Office\" and has a new TV series, or Max Chafkin, author of a new book about the controversial co-founder of PayPal, Peter Thiel, check out our podcast. You'll find lots of FRESH AIR interviews. (SOUNDBITE OF JOHN COLTRANE'S \"GIANT STEPS\")GROSS: FRESH AIR'S executive producer is Danny Miller. Our technical director and engineer is Audrey Bentham. Our interviews and reviews are produced and edited by Amy Salit, Phyllis Myers, Roberta Shorrock, Sam Briger, Lauren Krenzel, Heidi Saman, Ann Marie Baldonado, Thea Chaloner, Seth Kelley and Kayla Lattimore. Our digital media producer is Molly Seavy-Nesper. Therese Madden directed today's show. I'm Terry Gross. (SOUNDBITE OF JOHN COLTRANE'S \"GIANT STEPS\") TERRY GROSS, HOST:   This is FRESH AIR. I'm Terry Gross. Internal Facebook documents were leaked by a whistleblower and acquired by my guest Jeff Horwitz, a technology reporter for The Wall Street Journal. He's the lead reporter for The Journal's new series of articles called \"The Facebook Files. \" This series details how Facebook executives are aware of the ways the platform causes harm, but executives often lack the will or the ability to address them. The series reveals how a separate set of rules has been applied to VIP users like celebrities and politicians, allowing them to at least briefly escape restrictions and penalties that are applied to other users. Facebook's own researchers are aware that Instagram, which is owned by Facebook, has negative effects on the self-image and mental health of many teenage girls. Internal documents also reveal that Facebook researchers have warned the company's executives that the platform is used in developing countries for human trafficking, drug-dealing and to promote ethnic violence. The company's CEO, Mark Zuckerberg, has made it a goal to promote the COVID-19 vaccine, but his researchers have pointed out that that effort is being undermined by commenters spreading misinformation. At least some of the leaked internal documents have been turned over by the whistleblower to the Securities and Exchange Commission and to Congress. Jeff Horwitz, welcome to FRESH AIR. Congratulations on the series, which isn't over yet (laughter). You're still - there's more to come. So what are these internal documents that were leaked? JEFF HORWITZ: So this is a collection of internal research notes, executive presentations, in some cases company audits of its own practices that provide a pretty clear sense of how Facebook sees itself and the company's awareness of its own problems. And I think that's something that sort of separates it from a lot of other really good reporting on the company, which is that instead of this being outside voices asking questions about whether or not Facebook is being detrimental to the world, this is Facebook asking those questions and answering them and sometimes finding that the answer is very much yes. GROSS: And what you're talking about is researchers from Facebook who report to executives and tell them what's going on. And often what they've told them is that this platform is backfiring. It's causing harm for these and these reasons. HORWITZ: Yeah, exactly. I think it's important to draw a distinction between sort of irate watercooler chat and people letting off steam about things that don't really involve them at the company versus this stuff, which is these are the people that Facebook has hired to inform it of reality and to help it address problems. And in many cases, they are finding some really unpleasant things and then running into obstacles in trying to fix them. GROSS: Now, are the obstacles a lack of will? Or are the obstacles that Facebook is so big and there are so many users that it is hard to control, even if you want to? HORWITZ: I think that the premise that the company is just too big to be - to regulate itself isn't correct. There are - yes, having nearly 3 billion users is quite a lot of users to have to be in charge of. But what our reporting seems to indicate is that the company's complexity has become a big problem, as well as just kind of a lack of will and lack of interest in some instances. So it's not that a platform couldn't be made to work for this many users in a sort of simpler and safer way. It's that you can't have all the bells and whistles, and you can't maximize engagement in the way that Facebook would like to and not have that come at a cost. GROSS: Let's look at the first program you reported on, which is a VIP program called XCheck. This is a program that basically created separate rules for VIPs and for everybody else who uses Facebook. What VIPs have been exempt from certain rules? What kinds of people? HORWITZ: Oh, a lot of them. So Facebook has talked in the past about providing some - a little bit of extra leeway for politicians and fact-checking and misinformation - right? - the idea being that, you know, in an election, candidates should have the right to say whatever they want to say even if those things aren't strictly true. And the thing we found is that the protections Facebook offers to powerful users go far, far beyond that. So they include celebrities. They include journalists. I have no doubt that you should qualify. I most certainly should qualify. They include athletes and just sort of people who are famous for being famous, influencers. They include animal influencers. So you know, just, like, literally, the account Doug the Pug is actually covered by XCheck, which was the program. So basically, the idea is - the commonality among all these people and entities and animals is that they are big enough and prominent enough, they could cause problems for the platform. The way that this program was designed very explicitly internally was to avoid, quote-unquote, \"PR fires. \" And I think that's something that kind of sticks out in general in this reporting, is that the thing that makes Facebook scared more so than harm that it might be causing is the risk of public embarrassment. GROSS: What kind of public embarrassment? What kind of PR fire? HORWITZ: So this can be everything from making a mistake and tangling with, you know, the singer Rihanna's account because she posted a risque French magazine cover to, you know, making an error on something Donald Trump said to, you know, anything that basically would result in the company receiving widespread public criticism. And I think this is something that is kind of - exists throughout the series, is that Facebook really likes to stay in the background. They really would like to be kind of viewed as this neutral platform in which just kind of life plays out online. And as you know, what our reporting tends to show is that that is not the case. The company is actively making a lot of choices, is determining which interests benefit and at what expense. And I think XCheck is kind of a perfect example of that, which is that the whole idea is to never publicly tangle with anyone who is influential enough to do you harm. GROSS: Can you give us an example of a post that caused harm or could potentially cause harm that was allowed to stay up for a long time or a brief time because this person was a VIP? HORWITZ: Sure. And there are - so there are a lot of them. Facebook's own analysis of XCheck found that 16. 4 billion views of violating content occurred solely because of the lag time in taking down stuff from VIPs that shouldn't have been up in the first place. But I think the example I would give for how this program can cause harm and does sort of run against Facebook's sort of basic ethos of fairness is the Brazilian soccer player Neymar, who, in 2019, was accused by a Brazilian woman of rape. And he, to defend himself, took to Instagram and took to Facebook in a live video. And he showed pictures of this - of his WhatsApp chats with this woman, his messages with this woman. And those messages included not just her name, but also nude photos of her that she had shared with him. And this is just a complete no-go on Facebook. You are not allowed to broadcast people's naked pictures without their consent. It is called nonconsensual nude imagery at Facebook. It's called revenge porn everywhere else. And the appropriate response, per Facebook's own rules, is to immediately take down the post and delete the account that posted it. So that was kind of what would have happened. A Facebook employee did catch this, you know, pretty early on and tried to delete it. But the problem was Neymar's account was cross-checked. So it didn't come down. In fact, it stayed up for 36 hours, during which it racked up 56 million views. And this resulted in extensive harassment of the woman who had accused him of sexual assault. There were thousands and thousands of impersonators of her. And the video was reposted just all over the Internet. And basically, Facebook acknowledged internally that it had just completely failed to protect this woman. And this happened because of XCheck. Now, I think another part of the program that is important is that it really does and is intentionally designed to allow executives, communications and sort of public affairs people to weigh in on punishments that would otherwise be doled out. And that's what happened in this instance is that Neymar, who is one of the top 20 accounts on Instagram - like, this is a guy who is probably more famous for social media than he is for soccer. Facebook just simply wasn't willing to lose him. And so this got bumped all the way up to senior leadership of the company. And they determined that rather removing him from the platform, even though that was the absolute standard rule for this situation, they were going to kind of let it slide. So they took down the post in the end. But they didn't punish his account in the way they normally would. And I think it's kind of representative of the dual-class - or even more than dual-class system that Facebook created, in some ways, reinforcing power structures that, you know, the company has said it was supposed to kind of overthrow. GROSS: There was a 2019 internal review of the XCheck program. What did that review say? HORWITZ: I think people inside Facebook did have, on a long-term basis, a sense that exempting users from enforcement and from punishment on the platform was just, like, clearly not the right thing to do. This is not what Facebook was set to do. This isn't democratic. It isn't fair. And in 2019, an internal review of the XCheck program found a few things. The first one is that it was completely widespread, that there were dozens and dozens of teams that were enrolling users in various protections and that, in fact, pretty much any employee had been allowed to enter people into the XCheck program in the first place. The second thing is that it was just deeply mismanaged and unorganized. And no one really even knew how these lists were getting pulled together. They weren't being reviewed by lawyers. There was just sort of, kind of this ad hoc process where people would just put in names. And the final thing is that they found that this was just completely indefensible. This was a breach of trust with users. It was putting users in risk of harm. And it was clearly unfair. And as they noted, this was publicly indefensible and simply something that, you know, was completely at odds with the company's own sense of its legitimacy as an overseer of its own platform. GROSS: What was Facebook executives' reactions after getting this report? HORWITZ: Facebook - I mean, no one disputed that XCheck was a mess and that the program was unseemly and was in, you know, direct conflict with what the company had said publicly its rules are. That said, they really weren't willing to take on the mess of just simply doing away with it, particularly with the 2020 election coming up. I think this is something that - you know, over the period of time that the documents we reviewed cover, this company was paranoid about the possibility that it might be blamed for something in relation to the 2020 election. And so they desperately wanted to keep a low profile. And there was no way that they were going to rein the program in because this was kind of one of their main methods of trying to avoid criticism from high-profile people. GROSS: Let's talk about anti-vax posts on Facebook. Mark Zuckerberg has made it a priority to promote vaccines and facts about vaccines. But at the same time, Facebook has been used widely to convey anti-vax falsehoods. And you found that internal documents reveal that the anti-vax comments were mostly coming not from the original post, but from commenters. Would you describe what happened with that? HORWITZ: Sure. And I think a important place to start here is what you said about Mark Zuckerberg and his goals. This is something - fighting COVID was something that Facebook was, perhaps, uniquely inclined and positioned to do. They early on recognized the threat of the public health crisis back when a lot of other people were poo-pooing the possibility of the global pandemic. They sent all their moderators home, content moderators home, with pay. You know, they sort of really reframed and sort of sprinted to provide new tools, to provide information, to, you know, help out with public health efforts. They really were focused on this. And this was something that came from Mark Zuckerberg personally. I mean, this was kind of going to be Facebook's moment. And I think the interesting thing about this is that there were, you know, sort of all these resources and good intentions put into it, and yet also this kind of failure by the company to recognize the risks that its own platform could pose. And it's not as if Facebook hadn't had plenty of warnings that the anti-vaccine movement was very active on its platform. If you remember the, you know, measles outbreaks back in 2019 at Disneyland and things like that, there was a very, very aggressive community of anti-vaccine activists that have been active on the platform, had gotten really sophisticated in terms of their methods and their approach. And so the company sort of focused on the positive and all the things it could do that would be helpful and really didn't pay much attention to the, I think, fairly obvious threat that a small band of people who were extremely dedicated could pose if they correctly harnessed Facebook's tools, which they did. GROSS: Well, let's take a short break here. And then we'll talk some more. If you're just joining us, my guest is Jeff Horwitz, who is the lead reporter for The Wall Street Journal's new and ongoing series of articles called \"The Facebook Files. \" We'll be right back after a short break. This is FRESH AIR. (SOUNDBITE OF OF MONTREAL SONG, \"GRONLANDIC EDIT\") GROSS: This is FRESH AIR. Let's get back to my interview with Jeff Horwitz, who is the lead reporter on a new and ongoing Wall Street Journal series called \"The Facebook Files,\" based on a series of leaked documents from Facebook. These documents detail how Facebook executives are aware of the ways the platform causes harm, but executives often lack the will or the ability to address them. Is it harder to oversee or to apply rules to commenters than it is with people doing the original posts on Facebook? HORWITZ: This was a bit of a blind spot for the company. They hadn't really ever put that much resources into trying to understand comments, which is kind of funny because Facebook really did engineer its platform to produce a ton of comments. And they - what they realized early in 2021 was that, you know, as the vaccine was rolling out - was that all of the authoritative sources of information about it - right? - the World Health Organization, UNICEF and so on - all of their posts were just getting swamped by anti-vaccine advocates who were, you know, producing, at extremely high volume, content in the form of comments that was kind of just hitchhiking around. And I think the company understood this, to its credit, at that point as being a real threat because, you know, it's one thing to see something authoritative from UNICEF, and it's another thing to see that same thing and then a whole bunch of people saying don't believe it, right? And that's kind of the style of comment that was rising to the top of Facebook's own systems. So they realized that basically all of the things they were doing to try to promote authoritative information were in some ways being harnessed by the people who were trying to promote the exact opposite. GROSS: Internal documents also show that Facebook knew - that it was really a small group responsible for most of the COVID misinformation on Facebook. So what was Facebook's response to this research that was delivered to executives? HORWITZ: Yeah. So the initial response was just basically horror because they realized that, you know, there were just a very high proportion, not only of comments but also posts in general, that seemed to be - vaccine-hesitant was the company's phrase - so not necessarily straight misinformation - you know, false things like saying vaccines cause autism or make you sterile - but people who simply were exercising their right to speak on the platform as often as possible and in just extremely coordinated, almost cut-and-paste-style ways. And they were creating, basically, a false sense that there was a large public debate about the safety of vaccines, when there really isn't. So the initial response was just, uh-oh, this is a huge problem. We've got to fix it. And then the second response was, OK, how do we do that because they didn't really have the tools in place. They hadn't planned for this. And so they had to kind of make do with a whole bunch of kind of ad hoc interventions and try to sort of start getting public discourse to be at least somewhat representative - right? - so that any time someone who was, you know, encouraging about vaccinations wouldn't just get dogpiled by a - you know, a very, very dedicated group of anti-vaccine advocates. GROSS: Were these changes effective in stopping misinformation about the vaccine? HORWITZ: I think it's kind of too soon to tell how well they did. Certainly in terms of preventing this stuff from getting traction in the first place, they failed - right? - means that there were, you know - the whole problem and the thing that kicked this - kicked Facebook's response into gear was that public debate on the platform about this thing was skewed. It was getting sort of manipulated by anti-vaccine advocates. And, I mean, the fact that this was happening in 2021, as the vaccine was getting rolled out, you know, from, you know, the initial sort of first responders and medical officials to the broader population, certainly seems like it could have had an impact. And I think, you know, the company would note that it's not the only source of vaccine misinformation in the world by any means, right? There's plenty of stuff on cable TV that would have you believe bad things about the efficacy, safety and utility of the vaccine. But certainly, it's a remarkable thing for a company that really saw itself as being, you know, in the vanguard of solving a public health crisis that, you know, they're basically having to go back and fight with this highly active, somewhat ridiculous community that is just spamming their platform with bad information. GROSS: Let's take another break here, and then we'll talk some more. If you're just joining us, my guest is Jeff Horwitz, a technology reporter for The Wall Street Journal who's the lead reporter for The Journal's new series of articles called \"The Facebook Files,\" based on internal Facebook documents that were leaked to The Journal. We'll be back after we take a short break. I'm Terry Gross, and this is FRESH AIR. (SOUNDBITE OF CHARLIE HUNTER AND LEON PARKER'S \"THE LAST TIME\") GROSS: This is FRESH AIR. I'm Terry Gross. Let's get back to my interview with Jeff Horwitz, a technology reporter for The Wall Street Journal who's the lead reporter for the Journal's new series of articles called \"The Facebook Files,\" which detail how Facebook executives are aware of the ways the platform causes harm but executives often lack the will or the ability to address them. The series is based on internal Facebook documents that were leaked by a whistleblower to Jeff Horwitz. Let's talk about Instagram, which is owned by Facebook. Internal research from Facebook shows that Instagram could have a very damaging impact on teenage girls' self-image, their anxiety, depression. Why does Instagram sometimes have that effect on teenage girls? - 'cause you write that the algorithms on Instagram create a perfect storm for many teenage girls. HORWITZ: Yeah. So body image issues and social comparison obviously didn't originate with the internet. That said, Facebook's own research found that Instagram had some uniquely harmful features in terms of encouraging young women in particular to compare themselves with others and to think about the flaws of their bodies in relation to others. And, you know, this wasn't intentional. The company certainly hadn't meant to design something that did this. But, you know, there was no question in their own findings that, you know, compared to even other social media products, Instagram was worse in this respect - that it was very focused on the body as opposed to the face or performance and that, for users who arrived at the platform in not the best mental place, it could really have a big impact on them. GROSS: What is the way in which algorithms create a perfect storm for teenagers? - 'cause you say that in the article. HORWITZ: Right, right. So I think there's some core product mechanics here, which is that Instagram will always show you the most popular and successful posts from your friends and the people you follow and - whereas you're comparing that to your regular posts and your regular life. So there's kind of this kind of highlight reel ethos to it that tends to lead users to think that everyone else is living their best life while, you know, they're not. And so that's part of it. Another part of it is just simply that people tend to be attracted to content that sort of really resonates with them. And if you have body image issues already, Instagram - and you are engaged with sort of looking at people who are prettier than you are on the platform, Instagram's going to keep on doing that. If you have concerns about diet and fitness and you think you might be overweight, Instagram is likely going to pick up on that and feed you a ton of dieting and fitness content. And so they're kind of this - there's this feedback loop that the platform can create. And it turns out for people who are in a vulnerable place in the first place, it can be really damaging and, in some ways, lead to almost addictive-type behavior per Instagram's own analysis. GROSS: So what you've just described is reported in documents that were written by Facebook researchers and then delivered to Facebook executives. So executives knew what you just told us, right? HORWITZ: Absolutely. And Adam Mosseri, who's the head of Instagram, in fact, commissioned a lot of this research in the first place. So, you know, I think there's some credit that should go to the company for determining that - given the extensive external criticism of the company on these fronts, that perhaps it should at least get to the bottom of them. And it did. I mean, I think there's no question that what it found, you know, was convincing. As the company's own presentation - one of the presentations to executives notes, we make body image issues worse in 1 in 3 teen girls. GROSS: But you write that this represents one of the clearest gaps revealed in these internal documents, gaps between Facebook's understanding of itself and its public position. HORWITZ: Yeah. Look; I can understand why someone in corporate communications isn't eager to make the sentence, we make body image issues worse in 1 in 3 teen girls, public, much less some of the other things in these findings which included that young women who had thought about self-harm or suicide in the last month - that a not-tiny fraction of them traced those feelings directly back to Instagram's platform. So think potentially life-threatening effects. And I can understand why the company wouldn't want to acknowledge that publicly, you know, or wouldn't want to talk about it much. I think what's interesting is the company did talk about these issues. They just didn't say that. What they said is that there were perhaps small effects, that the research was inconclusive, that, you know, there wasn't any, you know - that, you know, if there was an issue, it was bidirectional, so it was good for some users and bad for some users - basically really downplayed the clarity that they had internally about what was going on and the effect of their product. GROSS: What was Facebook's reaction to your article about teenagers and Instagram? HORWITZ: They defended the research and keeping the research private as necessary for, you know, honest internal discussion. And they, I think, tried to argue a bit with whether or not the conclusions of causality that seem to be very present within their own - how their own researchers discussed this stuff even with management - they sort of tried to undermine, you know, the certainty that it really sort of feels like pervades the presentations that the company's researchers gave to executives. But, you know, I don't think they disagree with the issues. They sort of defended the things that they have said previously about there being relatively small effects. And, you know, I've noted that for many users and users who are in sort of a healthy emotional place, Instagram is a lot more beneficial than it is harmful, all of which is true. None of that is wrong. It's just that the question is, at what cost to vulnerable users? GROSS: Well, let's take another short break here. If you're just joining us, my guest is Jeff Horwitz, who is the lead reporter for The Wall Street Journal's new series of articles called \"The Facebook Files. \" We'll be right back after a break. This is FRESH AIR. (SOUNDBITE OF SOLANGE SONG, \"WEARY\") GROSS: This is FRESH AIR. Let's get back to my interview with Jeff Horwitz, a technology reporter for The Wall Street Journal. He's the lead reporter for The Journal's new series of articles called \"The Facebook Files,\" which detail how Facebook executives are aware of the ways the platform causes harm, but executives often lack the will or the ability to address them. The series is based on internal Facebook documents that were leaked by a whistleblower to Jeff Horwitz. One of the articles in the series is headlined \"Facebook Tried To Make Its Platform A Healthier Place. It Got Angrier Instead. \" And this article is about a change that was made in 2018 that rewarded outrage. What was the change? HORWITZ: Facebook promoted something in 2018 called meaningful social interaction. And the idea was that passively scrolling through content wasn't good for people - you know, it just turned them into zombies - and that what Facebook should be doing is encouraging people to sort of connect and engage with each other and with Facebook content more often. And there were two parts to this. One part was promoting content from people's friends and families, which was kind of a throwback to kind of an earlier era of Facebook where it was much more about that stuff than it was about kind of a constant stream of information and content. The second part, though, was rewarding content that did really well on engagement, meaning things that got a lot of likes, but even more important than likes, things that got a lot of emoji responses, comments, re-shares, direct message shares and things like that - so basically things that made users kind of pound the keyboard a bit and, you know, share and engage as much as possible. And you know, nothing about that seems, you know, atrocious in sort of a general high-level view. But it turns out, as Facebook realized down the road, that the effect that had was privileging angry, incendiary conflict because there is nothing more engaging than a fight. GROSS: And news publications, as a result, found that a lot of their traffic was decreasing dramatically. What was the connection? HORWITZ: So there was some element of this where they were just kind of reducing news overall in feed at the - you know, in other words - and to boost the stuff from friends and family. But I think the type of content that succeeded changed. And one thing we found was that BuzzFeed's - the head of BuzzFeed, Jonah Peretti, who is - you know, no one could accuse this guy of being unsophisticated when it comes to social media - was actually figured out that something had changed materially when Facebook rolled out this stuff and that, essentially, a type of content that was succeeding was - on the platform, was, like, sensationalistic, incendiary. Gross medical stuff was doing well - you know, things that sort of got a response. And you know, his point to Facebook when he got in touch was that, look, like, you guys are forcing us to produce worse content. And the same thing was true of political parties. They also picked up on what had changed, and they started adjusting accordingly. And so parties told Facebook that because of, literally, this algorithm change - like, some reweighting, some math - that they were shifting not just their communication strategy for the internet but, in some instances, their actual platform. GROSS: Once this was reported to Facebook executives, what actions did the executives take? HORWITZ: Facebook's attraction to meaningful social interaction as a metric wasn't just that they thought it would be good for people. It's also - they thought it would be good for Facebook. They really needed people to be engaging with content more because they'd been in decline in commenting and interaction in a way that was threatening to the future of a social network dependent on user-generated content. And so this had been really successful in terms of getting engagement back up and getting people to comment more. And the problem was that doing the things that researchers said would be necessary to sort of correct the amplified anger issue was going to come at the expense of some of the growth metrics that Facebook was pursuing. And that's always a hard sell inside that company. GROSS: What was Facebook's response to this article? HORWITZ: So Facebook noted that they had made some changes, which is true. I think the thing that we were very focused on is that people up to and including Mark Zuckerberg kind of resisted anything that was going to cause sacrifices in user growth numbers and in user engagement numbers for the purpose of improving the quality of discourse on the platform. So they told us on this one that basically any engagement-based ranking system or any ranking system is going to have problems - right? - that yes, they acknowledged that incendiary content did benefit from what they'd done, but, you know, that's not to say that there aren't disadvantages to other systems as well. GROSS: So one of your articles in The Journal reports that in developing countries, Facebook was often used by drug cartels, human traffickers, used to promote violence against ethnic groups. And developing countries are actually very important to Facebook now. And why is that? HORWITZ: People in poorer countries - they don't provide Facebook much money, but they do provide it with a lot of growth. The Facebook has basically stalled out in developed economies. I mean, there isn't really many - there isn't much in the way of new user growth to be achieved in the U. S. , Canada, Europe and wealthier nations. So this is kind of where pretty much all of the company's growth has been coming in recent years. And you know, that makes them kind of - places like India are sort of the company's future. And at the same time, though, Facebook has never really invested much in safety in those environments. And you know, they had, for example, a team of just a few people trying to focus on human trafficking across the globe. That includes sex trafficking, labor trafficking, organ trafficking. And they were clearly overwhelmed. And there were some, I think, serious issues of the company just simply not really caring all that much. I think one instance we found was that the company had identified sort of wide-scale human trafficking occurring, in which people from the Philippines and Africa were kind of indenturing themselves into domestic labor in the Gulf states. And they were - once there, kind of lost all autonomy. They could literally be resold without their permission. And Facebook actually had - first of all, had allowed this for a long time. Like, up until 2019, it was actually OK for people to be sold on Facebook so long as the selling was happening through brick-and-mortar establishments, as long as, you know, there was - it was in a country where this was allowed. And then I think more broadly, Facebook had just kind of turned a blind eye to this whole practice. One thing, you know, that I think was - really stood out to me just in terms of demonstrating the company's lack of will on some of these things is that Facebook, while it had identified widespread human trafficking, hadn't done anything about it - and in some instances for years. The thing that Facebook - moved Facebook in 2019 to take aggressive action on this was Apple. You know, maker of my iPhone told Facebook that it was going to take away - it was going to remove Instagram and Facebook from its App Store, basically make it so that people couldn't download the apps unless Facebook got its human trafficking problem under control. And boom, that was it, right? Actually, understanding human trafficking was happening on its platform wasn't enough to get Facebook's attention - what did was the threat that Apple might take an action that would severely damage its business. So Facebook, literally within days, was just pulling down content all over the place. And the crisis passed. And then, as we found, things went back to normal. And normal means that human trafficking is happening on a pretty widespread scale on the platform. GROSS: Another obstacle that you report is Facebook doesn't have enough people monitoring posts who speak the dialect needed to identify dangerous or criminal uses of Facebook. HORWITZ: Yeah. And this is something that I think - look; like, I think we're all familiar with Facebook's apologies right now, right? Like every couple of months or weeks or days, depending on how closely you're monitoring it, the company ends up saying that it's sorry that something happened. And particularly overseas, it seems like there's just this kind of succession of inadvertent oversights that come with large human consequences. And the thing we found is that these aren't accidents. These aren't due to the company, you know, just simply having too much to possibly do. These are issues of direct neglect. So for example, with Arabic, it's the third - world's third most commonly spoken language. It has many dialects that are mutually incomprehensible. Facebook literally can't - doesn't have anyone who can speak most of them or can understand most of them in terms of sort of the vernacular. And it also doesn't have a system to route content in those dialects to the right people. So when something happens like the Israeli-Palestinian violence earlier this year, the company is just sort of woefully unprepared to deal with it. They can't process content. They don't have people on staff. And, I mean, one of the things that's kind of tragic that we could see inside the documents was that you had all of these people who work for Facebook with Middle Eastern backgrounds who were just desperately trying to, like, kick in ad hoc to try to, like, help steer the company in a better direction because it was just screwing up so much at a time that was, like, so crucial on its platform. GROSS: Nick Clegg, who's the Facebook vice president of global affairs, recently published a blog post saying that The Wall Street Journal articles have contained deliberate mischaracterizations of what Facebook is trying to do and conferred egregiously false motives to Facebook's leadership and employees. What's your reaction to that? HORWITZ: My reaction is that Facebook has the right to say whatever they would like to say in response to our reporting. I think the more useful reaction to that isn't mine. It's that there actually have been in recent days a large number of former Facebook employees who have directly taken issue with what Mr. Clegg and what the company has said on these subjects. And I mean, these are people who actually were doing the work. Like, there are names that are popping up on Twitter that are the names that were sort of protagonists, I suppose, in some of the stories I could see playing out inside of the company. And what they've said very clearly is that - you know, one, that the things that we're raising are pretty much correct and, two, that there is, in fact, this history of kind of disregarding the work of the people Facebook's asked to do integrity work - integrity just being platform safety and content quality stuff. And so, you know, I think there's something really encouraging about some of these voices coming to the fore because these are people who sort of pioneered not just the ways to measure problems on the platform, but also ways to address them. And so the idea that they might be able to come out and talk more about the work they did is, I think, really interesting to me and, in some ways, would be very healthy for the company. GROSS: My guest is Jeff Horwitz, who is the lead reporter for The Wall Street Journal's new and ongoing series called \"The Facebook Files. \" This is FRESH AIR. (SOUNDBITE OF YO LA TENGO'S \"WEATHER SHY\") GROSS: This is FRESH AIR. Let's get back to my interview with Jeff Horwitz, a technology reporter for The Wall Street Journal, who's the lead reporter for the Journal's new series of articles called \"The Facebook Files. \" The series details how Facebook executives are aware of the ways the platform causes harm. But the series also says executives have often lacked the will or the ability to address those problems. The series is based on internal Facebook documents that were leaked by a whistleblower to Jeff Horwitz. What are some of the suggestions current or former Facebook employees have made, that you're aware of, of how to improve some of the problems that you've reported on? HORWITZ: Yeah, I think Facebook tends to treat social media as if it's - you know, Facebook is the only way in which it could possibly exist - right? - kind of a love-it-or-leave-it approach. And that, for their own - per their own employees, is absolutely not true. There are a number of things that can be changed, right? So in addition to just simply the question of resources, which would address a lot of problems, there are also ways in which the platform perhaps has grown too complex to be safe. So, for example, in developing countries, is it really a good idea for things to be able to go viral in a matter of minutes? Maybe that's not good if you're worried about information quality. So virality restrictions is one thing. There's other work that I think seems like it would be really promising, such as trying to give more prominence to voices that seem to have respectful conversations. It's the - the concept is called earned voice. And rather than just sort of rewarding the biggest loudmouth, this would reward people who tend to be able to have conversations with people who aren't necessarily exactly like them that are nonetheless respectful and, you know, mutually satisfying. Now, that's not, of course, the way you get the most engagement, but it is something that could potentially provide a different style of conversation that would be, I think, recognized by most people outside the company as healthier. GROSS: Recently, Facebook created what's been described as a Supreme Court for Facebook, an outside entity of experts who would help Facebook make complicated decisions about content. How has that been actually functioning? HORWITZ: So this came up in the XCheck story that we did about the sort of special protections for VIPs. Facebook spent $130 million creating the Oversight Board and - with the stated purpose of providing transparency and accountability into its operations. And one of the powers it gave the Oversight Board was the ability to ask Facebook questions that Facebook would then have to answer, assuming that they were relevant. And in the case of XCheck, the board asked the right questions. In relation to Donald Trump's suspension from the platform, the board asked, very specifically, for data about the program and for the XCheck program and about protections for VIP users. And Facebook said it didn't exist. And this is obviously awkward, given the stuff we've seen, because, you know, we can actually see there were internal dashboards of metrics as well as just voluminous documentation of the program's problems, of the number of accounts, of how many bad views of content occurred as a result of the lag in review times. You know, this is a pretty well-documented program internally, and Facebook told its supposed overseers that it just simply didn't have the information and couldn't possibly gather it. And the Oversight Board has, at this point, issued some pretty strong statements of discontent with that situation. But I think it does seem like a bit of a crisis in the sense that, you know, oversight does imply the ability to actually see what's going on inside the company. And I think the Oversight Board has, to its credit, recognized that that isn't something that Facebook is readily willing to provide. So what their role is, I think, going forward is going to be an interesting question, because they're, - you know, they're kind of being asked to play a self-regulatory role for Facebook. At the same time, they are fully independent, and they also seem to not have much trust in Facebook and whether Facebook's going to give them the truth about what Facebook is itself doing. GROSS: Well, Jeff Horwitz, thank you for your reporting, and thank you for coming on our show. HORWITZ: Thank you so much, Terry. GROSS: Jeff Horwitz is the lead reporter on The Wall Street Journal series \"The Facebook Files. \" If you'd like to catch up on FRESH AIR interviews you missed, like this week's interviews with B. J. Novak, who played Ryan in \"The Office\" and has a new TV series, or Max Chafkin, author of a new book about the controversial co-founder of PayPal, Peter Thiel, check out our podcast. You'll find lots of FRESH AIR interviews. (SOUNDBITE OF JOHN COLTRANE'S \"GIANT STEPS\") GROSS: FRESH AIR'S executive producer is Danny Miller. Our technical director and engineer is Audrey Bentham. Our interviews and reviews are produced and edited by Amy Salit, Phyllis Myers, Roberta Shorrock, Sam Briger, Lauren Krenzel, Heidi Saman, Ann Marie Baldonado, Thea Chaloner, Seth Kelley and Kayla Lattimore. Our digital media producer is Molly Seavy-Nesper. Therese Madden directed today's show. I'm Terry Gross. (SOUNDBITE OF JOHN COLTRANE'S \"GIANT STEPS\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-09-23-1040035430": {"title": "Smallest-Ever Human-Made Flying Structure Is A Winged Microchip, Scientists Say : NPR", "url": "https://www.npr.org/2021/09/23/1040035430/flying-microchip-sand-grain-northwestern-winged", "author": "No author found", "published_date": "2021-09-23", "content": "", "section": "Technology", "disclaimer": ""}, "2021-09-23-1040040098": {"title": "European Union Wants Universal Charger For Cell Phones, Other Electronic Devices : NPR", "url": "https://www.npr.org/2021/09/23/1040040098/eu-european-union-universal-common-charger-apple", "author": "No author found", "published_date": "2021-09-23", "content": "", "section": "World", "disclaimer": ""}, "2021-09-23-1040033127": {"title": "James Mattis Describes In Court How He Lost Faith In Elizabeth Holmes : NPR", "url": "https://www.npr.org/2021/09/23/1040033127/mattis-elizabeth-holmes-theranos-trial", "author": "No author found", "published_date": "2021-09-23", "content": "", "section": "Law", "disclaimer": ""}, "2021-09-24-1040550224": {"title": "Canadians Are Released After A Chinese Executive Resolves U.S. Criminal Charges : NPR", "url": "https://www.npr.org/2021/09/24/1040550224/a-huawei-executive-held-in-canada-resolves-criminal-charges-in-a-deal-with-the-u", "author": "No author found", "published_date": "2021-09-24", "content": "SCOTT SIMON, HOST:  Late last night, China released two Canadian businessmen who had been imprisoned in China for more than a thousand days at almost the same moment Canada released an executive of the Chinese company Huawei Technologies. NPR's Emily Feng joins us now from Beijing. Emily, thanks for being with us. EMILY FENG, BYLINE: Thanks for having me, Scott. SIMON: Of course, you've been covering this story from the beginning. But let's remind ourselves, how did this Chinese executive and these two Canadian men wind up being detained? And how did their cases become mixed? FENG: It all started December 2018. That's when Canada arrested Meng Wanzhou, who is the chief financial officer for Huawei. The U. S. suspected her of violating Iran sanctions, so they asked Canada to arrest Meng because she was flying through the country. She was later arraigned for committing bank and wire fraud. Since then, the U. S. has been fighting this legal battle to have her extradited from Canada to the U. S. to stand trial. But in December, within days of Meng being detained, China then took Michael Kovrig in Beijing and Michael Spavor in Dandong - which is a Chinese border city with North Korea - into detention. These two men were later charged with espionage, and they were tried in closed trials, which I tried to go to and was not allowed to attend. Spavor got an 11-year sentence. So the two cases seemed very connected, but China repeatedly denied that they had any connection to one another. But as you point out, basically, precisely the same time Meng was released Friday U. S. time, she boarded a plane back to China, and then two Michaels, as they're now called, were released from China. SIMON: How did Canada, China and the U. S. wind up apparently resolving this? FENG: Canadian diplomats tell me they've been negotiating for the two Michaels release since last November. They essentially were arranging a hostage swap. They had the U. S. Department of Justice step in, who helped broker this deal. And as part of their agreement, Meng confessed in court this week to misleading banks so that Huawei, the Chinese telecom firm she works for and which her father founded, could sell equipment to Iran in violation of American sanctions. But as soon as she confessed to this, the U. S. Department of Justice dropped its extradition request. It agreed that as long as she does not commit wire or bank fraud in the near future, the charges against her will be dropped within a year. Then Meng could go home, China would have to release the two Michaels, and that is precisely what's happened today. SIMON: What effect did this have on relations between China, the U. S. and Canada? And where does the Huawei investigation go from here? FENG: These detentions really kicked off a low point in China's relations with the U. S. and China and also - I'm sorry, China's relations with the U. S. and also China's relations with Canada, which got mixed up in all of this. It also marked this technology rivalry between the U. S. and China over dominance in 5G technology, which is the next generation of mobile communications, and also semiconductor chips, these tiny components that go into all of our electronic devices. The U. S. continues to apply sanctions on Huawei that denied access to technological components. And although Meng will not have charges against her in the future, she did sign off on what's called a deferred prosecution agreement, admitting that she lied to banks. And so that information will be used in future cases against Huawei. SIMON: NPR's Emily Feng speaking with us from Beijing. Emily, thanks so much for being with us. FENG: Thanks, Scott. (SOUNDBITE OF MUSIC) SCOTT SIMON, HOST:   Late last night, China released two Canadian businessmen who had been imprisoned in China for more than a thousand days at almost the same moment Canada released an executive of the Chinese company Huawei Technologies. NPR's Emily Feng joins us now from Beijing. Emily, thanks for being with us. EMILY FENG, BYLINE: Thanks for having me, Scott. SIMON: Of course, you've been covering this story from the beginning. But let's remind ourselves, how did this Chinese executive and these two Canadian men wind up being detained? And how did their cases become mixed? FENG: It all started December 2018. That's when Canada arrested Meng Wanzhou, who is the chief financial officer for Huawei. The U. S. suspected her of violating Iran sanctions, so they asked Canada to arrest Meng because she was flying through the country. She was later arraigned for committing bank and wire fraud. Since then, the U. S. has been fighting this legal battle to have her extradited from Canada to the U. S. to stand trial. But in December, within days of Meng being detained, China then took Michael Kovrig in Beijing and Michael Spavor in Dandong - which is a Chinese border city with North Korea - into detention. These two men were later charged with espionage, and they were tried in closed trials, which I tried to go to and was not allowed to attend. Spavor got an 11-year sentence. So the two cases seemed very connected, but China repeatedly denied that they had any connection to one another. But as you point out, basically, precisely the same time Meng was released Friday U. S. time, she boarded a plane back to China, and then two Michaels, as they're now called, were released from China. SIMON: How did Canada, China and the U. S. wind up apparently resolving this? FENG: Canadian diplomats tell me they've been negotiating for the two Michaels release since last November. They essentially were arranging a hostage swap. They had the U. S. Department of Justice step in, who helped broker this deal. And as part of their agreement, Meng confessed in court this week to misleading banks so that Huawei, the Chinese telecom firm she works for and which her father founded, could sell equipment to Iran in violation of American sanctions. But as soon as she confessed to this, the U. S. Department of Justice dropped its extradition request. It agreed that as long as she does not commit wire or bank fraud in the near future, the charges against her will be dropped within a year. Then Meng could go home, China would have to release the two Michaels, and that is precisely what's happened today. SIMON: What effect did this have on relations between China, the U. S. and Canada? And where does the Huawei investigation go from here? FENG: These detentions really kicked off a low point in China's relations with the U. S. and China and also - I'm sorry, China's relations with the U. S. and also China's relations with Canada, which got mixed up in all of this. It also marked this technology rivalry between the U. S. and China over dominance in 5G technology, which is the next generation of mobile communications, and also semiconductor chips, these tiny components that go into all of our electronic devices. The U. S. continues to apply sanctions on Huawei that denied access to technological components. And although Meng will not have charges against her in the future, she did sign off on what's called a deferred prosecution agreement, admitting that she lied to banks. And so that information will be used in future cases against Huawei. SIMON: NPR's Emily Feng speaking with us from Beijing. Emily, thanks so much for being with us. FENG: Thanks, Scott. (SOUNDBITE OF MUSIC)", "section": "Business", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-09-24-1040353540": {"title": "The Elizabeth Holmes Trial Is Sparking A Gender Debate In Silicon Valley : NPR", "url": "https://www.npr.org/2021/09/24/1040353540/the-elizabeth-holmes-trial-is-sparking-a-gender-debate", "author": "No author found", "published_date": "2021-09-24", "content": "RACHEL MARTIN, HOST:  As you may be following, Elizabeth Holmes is facing possible prison time over fraud charges tied to her former blood testing company, Theranos. So why haven't other tech startup CEOs who've been accused of wrongdoing ever faced criminal charges? NPR's Bobby Allyn has more. BOBBY ALLYN, BYLINE: Selling an idea in Silicon Valley takes a big vision, charisma and something else. MARGARET O'MARA: A certain amount of swagger and bluster. ALLYN: That's Margaret O'Mara, longtime historian of the tech industry at the University of Washington. O'MARA: And being able to tell a good story is part of being a successful founder, being able to persuade investors to put money into your company. ALLYN: O'Mara says when Elizabeth Holmes promised to revolutionize health care with a portable blood testing machine that could scan a finger prick of blood for hundreds of diseases, she was doing just that - drumming up investment with a big dream. But in doing so, prosecutors say she broke the law by deceiving investors about how well the business was doing and providing false or flawed test results to patients. As Silicon Valley focuses on Holmes' trial, there's another debate swirling - why Elizabeth Holmes? Ellen Pao is the former CEO of Reddit who now works to fight gender discrimination in tech. She says sexism is partially to blame. ELLEN PAO: So when you see which CEOs get to continue to wreak havoc on consumers and in the market, it's people who look like the venture capitalists, who are mostly white men. ALLYN: She points to Adam Neumann, who drove WeWork into the ground; Uber's former CEO Travis Kalanick, who resigned after a sexual harassment scandal; and Juul's Kevin Burns, who stepped down amid questions over the company's role in stoking the youth vaping epidemic. There were lawsuits and settlements and fallout, but Pao says, notably, no criminal prosecutions. PAO: That all these people continue to lead their lives and have not been held accountable for all the harm that they've caused, it does send a message. ALLYN: Historian O'Mara says Elizabeth Holmes did follow a Silicon Valley playbook of being a young, enthusiastic founder who leaned into bold claims about changing mankind. But it's almost become a trend for industry players to now say her case was a one-off. O'MARA: The gap between what she and her colleagues were saying Theranos was doing and what it actually was doing was so vast (laughter) that, you know, it's very easy for Silicon Valley to just say, you know, this isn't us. ALLYN: Former prosecutors who have tried white-collar crimes say there are several reasons why Holmes' case stands out among disgraced CEOs. First, the alleged fraudulent behavior was egregious. Holmes said she had a miracle machine, and prosecutors say it barely did anything at all. Mark MacDougall, a former federal prosecutor, says Theranos being a biotech company in the health care world raised the stakes. MARK MACDOUGALL: It allows the government to contend with some evidence that the health of, you know, private citizens, the health of innocent people was put at risk. ALLYN: Another reason Holmes was charged was prosecutors say they have evidence that she acted intentionally, which is sometimes hard to find in a fraud case. That's according to Hartley West. She used to be a top prosecutor in the U. S. Attorney's Office for the Northern District of California, which polices Silicon Valley. HARTLEY WEST: It is one of the elements of the offense that if not proved deserves an acquittal. It is that that is frequently the most difficult part of any white-collar case to prove. ALLYN: Pao, meanwhile, says she is not defending Holmes. She says prosecutors should be charging her, but she wants to see a wider conversation about why other CEOs accused of wrongdoing haven't faced criminal cases. PAO: That's what my message is. Why aren't we holding other people accountable so we can avoid all the harm that is happening in the tech industry? ALLYN: Holmes' trial is expected to last until later this year. If convicted, she could go to prison for years. Bobby Allyn, NPR News, San Francisco. (SOUNDBITE OF TIM SCHAUFERT'S \"UNTOUCHABLE [PITCHED INSTRUMENTAL]\") RACHEL MARTIN, HOST:   As you may be following, Elizabeth Holmes is facing possible prison time over fraud charges tied to her former blood testing company, Theranos. So why haven't other tech startup CEOs who've been accused of wrongdoing ever faced criminal charges? NPR's Bobby Allyn has more. BOBBY ALLYN, BYLINE: Selling an idea in Silicon Valley takes a big vision, charisma and something else. MARGARET O'MARA: A certain amount of swagger and bluster. ALLYN: That's Margaret O'Mara, longtime historian of the tech industry at the University of Washington. O'MARA: And being able to tell a good story is part of being a successful founder, being able to persuade investors to put money into your company. ALLYN: O'Mara says when Elizabeth Holmes promised to revolutionize health care with a portable blood testing machine that could scan a finger prick of blood for hundreds of diseases, she was doing just that - drumming up investment with a big dream. But in doing so, prosecutors say she broke the law by deceiving investors about how well the business was doing and providing false or flawed test results to patients. As Silicon Valley focuses on Holmes' trial, there's another debate swirling - why Elizabeth Holmes? Ellen Pao is the former CEO of Reddit who now works to fight gender discrimination in tech. She says sexism is partially to blame. ELLEN PAO: So when you see which CEOs get to continue to wreak havoc on consumers and in the market, it's people who look like the venture capitalists, who are mostly white men. ALLYN: She points to Adam Neumann, who drove WeWork into the ground; Uber's former CEO Travis Kalanick, who resigned after a sexual harassment scandal; and Juul's Kevin Burns, who stepped down amid questions over the company's role in stoking the youth vaping epidemic. There were lawsuits and settlements and fallout, but Pao says, notably, no criminal prosecutions. PAO: That all these people continue to lead their lives and have not been held accountable for all the harm that they've caused, it does send a message. ALLYN: Historian O'Mara says Elizabeth Holmes did follow a Silicon Valley playbook of being a young, enthusiastic founder who leaned into bold claims about changing mankind. But it's almost become a trend for industry players to now say her case was a one-off. O'MARA: The gap between what she and her colleagues were saying Theranos was doing and what it actually was doing was so vast (laughter) that, you know, it's very easy for Silicon Valley to just say, you know, this isn't us. ALLYN: Former prosecutors who have tried white-collar crimes say there are several reasons why Holmes' case stands out among disgraced CEOs. First, the alleged fraudulent behavior was egregious. Holmes said she had a miracle machine, and prosecutors say it barely did anything at all. Mark MacDougall, a former federal prosecutor, says Theranos being a biotech company in the health care world raised the stakes. MARK MACDOUGALL: It allows the government to contend with some evidence that the health of, you know, private citizens, the health of innocent people was put at risk. ALLYN: Another reason Holmes was charged was prosecutors say they have evidence that she acted intentionally, which is sometimes hard to find in a fraud case. That's according to Hartley West. She used to be a top prosecutor in the U. S. Attorney's Office for the Northern District of California, which polices Silicon Valley. HARTLEY WEST: It is one of the elements of the offense that if not proved deserves an acquittal. It is that that is frequently the most difficult part of any white-collar case to prove. ALLYN: Pao, meanwhile, says she is not defending Holmes. She says prosecutors should be charging her, but she wants to see a wider conversation about why other CEOs accused of wrongdoing haven't faced criminal cases. PAO: That's what my message is. Why aren't we holding other people accountable so we can avoid all the harm that is happening in the tech industry? ALLYN: Holmes' trial is expected to last until later this year. If convicted, she could go to prison for years. Bobby Allyn, NPR News, San Francisco. (SOUNDBITE OF TIM SCHAUFERT'S \"UNTOUCHABLE [PITCHED INSTRUMENTAL]\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-09-25-1040683057": {"title": "Crypto-Trading Hamster Performs Better Than Warren Buffett And The S&P 500 : NPR", "url": "https://www.npr.org/2021/09/25/1040683057/crypto-trading-hamster-goxx-warren-buffet-s-p-500", "author": "No author found", "published_date": "2021-09-25", "content": "", "section": "Animals", "disclaimer": ""}, "2021-09-25-1040442689": {"title": "The Elizabeth Holmes Trial Sparks A Silicon Valley Debate: Why Not Other Tech CEOs? : NPR", "url": "https://www.npr.org/2021/09/25/1040442689/elizabeth-holmes-trial-why-her-not-other-ceos", "author": "No author found", "published_date": "2021-09-25", "content": "", "section": "Technology", "disclaimer": ""}, "2021-09-27-1040889789": {"title": "Google Is Appealing A $5 Billion Antitrust Fine In The EU : NPR", "url": "https://www.npr.org/2021/09/27/1040889789/google-eu-android-appeal-antitrust", "author": "No author found", "published_date": "2021-09-27", "content": "", "section": "Law", "disclaimer": ""}, "2021-09-27-1040857033": {"title": "Instagram Is Pausing Its Plan To Develop A Platform For Kids  : NPR", "url": "https://www.npr.org/2021/09/27/1040857033/instagram-kids-pausing-plan-develop-platform-criticism", "author": "No author found", "published_date": "2021-09-27", "content": "", "section": "Business", "disclaimer": ""}, "2021-09-27-1040795026": {"title": "The National Inventors Hall Of Fame Will Induct Its First 2 Black Women In May : NPR", "url": "https://www.npr.org/2021/09/27/1040795026/patricia-bath-marian-croak-national-inventors-hall-of-fame-first-black-women", "author": "No author found", "published_date": "2021-09-27", "content": "", "section": "Science", "disclaimer": ""}, "2021-09-29-1041625310": {"title": "YouTube Is Cracking Down On Videos And Creators Sharing COVID Vaccine Misinformation : NPR", "url": "https://www.npr.org/2021/09/29/1041625310/youtube-is-cracking-down-on-videos-and-creators-sharing-covid-vaccine-misinforma", "author": "No author found", "published_date": "2021-09-29", "content": "LEILA FADEL, HOST: Video streaming platform YouTube announced today that it is expanding its ban on vaccine misinformation. The company now says all false information about approved vaccines will be removed from its platform. NPR science correspondent Geoff Brumfiel has been tracking vaccine misinformation and joins us now to talk about what this ban will mean. Hey, Jeff. GEOFF BRUMFIEL, BYLINE: Hi there, Leila. FADEL: So let's start with today's announcement. What's YouTube actually doing here? BRUMFIEL: So it's basically expanding what it defines as vaccine misinformation. Up until now, many social media platforms have really been focused on COVID-19 vaccines. But, of course, anti-vaccine activism predates COVID by many decades, actually. And before COVID, it was very much focused on stopping childhood vaccination against things like measles and chickenpox. Now, YouTube says it's noticed more false claims about those childhood vaccinations in recent months, and so it's decided that those sorts of videos should be taken down as well. And, by the way, we should mention that YouTube's parent company, Google, is a financial supporter of NPR. FADEL: So what does this mean in practical terms? BRUMFIEL: Well, it's caused some of the biggest promoters of vaccine misinformation to be completely kicked off YouTube, basically - in particular, a gentleman by the name of Joseph Mercola, who runs a multimillion-dollar natural supplements business, and Robert F. Kennedy Jr. , who for years now has been a pretty major anti-vaccine activist. The Center for Countering Digital Hate, which tracks vaccine misinformation, has had these two at the top of their Disinformation Dozen, a list of some of the worst spreaders of these bad vaccine takes. And that group, the Center for Countering Digital Hate, announced that around half a million subscribers are no longer going to see anti-vaccine content as a result of YouTube's move here. FADEL: So that sounds like pretty good news for anyone concerned about making sure scientifically accurate information about vaccines reaches the public, right? BRUMFIEL: Yeah, yeah. I mean, I spoke to Imran Ahmed. He's chief executive of the center. And he says that he really applauds YouTube's announcement. IMRAN AHMED: It's the right moral decision to take as a company that profits from content. BRUMFIEL: And beyond that, he expects this is going to have a real impact on those who've lost YouTube today as a platform. AHMED: It's damaged their ability to spread their message, to grow their audiences and, more importantly for them, to make money. BRUMFIEL: But he also says this is really far from the end of this whole situation. Anti-vaccine advocates still have plenty of ways to spread misinformation. FADEL: And what ways are those? BRUMFIEL: Well, while YouTube took action for - while YouTube took action today, the Center for Countering Digital Hate says Facebook and Instagram are still hosting some pretty big accounts. They estimate the Disinformation Dozen has millions of followers on those two platforms. And then there are a whole bunch of other less-regulated platforms out there - places like Gab and Parler and Telegram. And these folks are still finding an audience there. But an even bigger outlet might be right-wing media. So, for example, Mercola has made some recent appearances on the show of former Trump adviser Steve Bannon. He's made a whole bunch of false claims about vaccines there. And both Joseph Mercola and RFK Jr. said in statements to NPR that they are absolutely going to keep spreading their message any way they can. For them, this is really a free speech issue. FADEL: So what's the consequence of anti-vaccine advocates being able to flourish in these other spaces? BRUMFIEL: Imran Ahmed and others say it's a lot better than allowing these folks to continue to grab really huge audiences on major platforms like YouTube. But I think there's something else happening, and that's that people who spend time in these alternate spaces on the internet, and particularly on politically conservative spaces in the internet, are being bombarded with more of the stuff than ever before. And the consequences of that are real. According to polling from Kaiser, Democrats are now the most vaccinated group in America, and Republicans are second to last, just ahead of the uninsured. So it's created this situation where how you vote is most likely to determine whether you're vaccinated. FADEL: NPR's science correspondent Geoff Brumfiel, thank you. BRUMFIEL: Thank you very much. (SOUNDBITE OF MUSIC) LEILA FADEL, HOST:  Video streaming platform YouTube announced today that it is expanding its ban on vaccine misinformation. The company now says all false information about approved vaccines will be removed from its platform. NPR science correspondent Geoff Brumfiel has been tracking vaccine misinformation and joins us now to talk about what this ban will mean. Hey, Jeff. GEOFF BRUMFIEL, BYLINE: Hi there, Leila. FADEL: So let's start with today's announcement. What's YouTube actually doing here? BRUMFIEL: So it's basically expanding what it defines as vaccine misinformation. Up until now, many social media platforms have really been focused on COVID-19 vaccines. But, of course, anti-vaccine activism predates COVID by many decades, actually. And before COVID, it was very much focused on stopping childhood vaccination against things like measles and chickenpox. Now, YouTube says it's noticed more false claims about those childhood vaccinations in recent months, and so it's decided that those sorts of videos should be taken down as well. And, by the way, we should mention that YouTube's parent company, Google, is a financial supporter of NPR. FADEL: So what does this mean in practical terms? BRUMFIEL: Well, it's caused some of the biggest promoters of vaccine misinformation to be completely kicked off YouTube, basically - in particular, a gentleman by the name of Joseph Mercola, who runs a multimillion-dollar natural supplements business, and Robert F. Kennedy Jr. , who for years now has been a pretty major anti-vaccine activist. The Center for Countering Digital Hate, which tracks vaccine misinformation, has had these two at the top of their Disinformation Dozen, a list of some of the worst spreaders of these bad vaccine takes. And that group, the Center for Countering Digital Hate, announced that around half a million subscribers are no longer going to see anti-vaccine content as a result of YouTube's move here. FADEL: So that sounds like pretty good news for anyone concerned about making sure scientifically accurate information about vaccines reaches the public, right? BRUMFIEL: Yeah, yeah. I mean, I spoke to Imran Ahmed. He's chief executive of the center. And he says that he really applauds YouTube's announcement. IMRAN AHMED: It's the right moral decision to take as a company that profits from content. BRUMFIEL: And beyond that, he expects this is going to have a real impact on those who've lost YouTube today as a platform. AHMED: It's damaged their ability to spread their message, to grow their audiences and, more importantly for them, to make money. BRUMFIEL: But he also says this is really far from the end of this whole situation. Anti-vaccine advocates still have plenty of ways to spread misinformation. FADEL: And what ways are those? BRUMFIEL: Well, while YouTube took action for - while YouTube took action today, the Center for Countering Digital Hate says Facebook and Instagram are still hosting some pretty big accounts. They estimate the Disinformation Dozen has millions of followers on those two platforms. And then there are a whole bunch of other less-regulated platforms out there - places like Gab and Parler and Telegram. And these folks are still finding an audience there. But an even bigger outlet might be right-wing media. So, for example, Mercola has made some recent appearances on the show of former Trump adviser Steve Bannon. He's made a whole bunch of false claims about vaccines there. And both Joseph Mercola and RFK Jr. said in statements to NPR that they are absolutely going to keep spreading their message any way they can. For them, this is really a free speech issue. FADEL: So what's the consequence of anti-vaccine advocates being able to flourish in these other spaces? BRUMFIEL: Imran Ahmed and others say it's a lot better than allowing these folks to continue to grab really huge audiences on major platforms like YouTube. But I think there's something else happening, and that's that people who spend time in these alternate spaces on the internet, and particularly on politically conservative spaces in the internet, are being bombarded with more of the stuff than ever before. And the consequences of that are real. According to polling from Kaiser, Democrats are now the most vaccinated group in America, and Republicans are second to last, just ahead of the uninsured. So it's created this situation where how you vote is most likely to determine whether you're vaccinated. FADEL: NPR's science correspondent Geoff Brumfiel, thank you. BRUMFIEL: Thank you very much. (SOUNDBITE OF MUSIC)", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-09-29-1041493544": {"title": "YouTube Issues Ban Against Videos That Spread Vaccine Misinformation : NPR", "url": "https://www.npr.org/2021/09/29/1041493544/youtube-vaccine-misinformation-ban", "author": "No author found", "published_date": "2021-09-29", "content": "", "section": "Health", "disclaimer": ""}, "2021-09-30-1042012393": {"title": "Facebook whistleblower isn't protected from possible company retaliation, experts say : NPR", "url": "https://www.npr.org/2021/09/30/1042012393/facebook-whistleblower-retaliation", "author": "No author found", "published_date": "2021-09-30", "content": "", "section": "Technology", "disclaimer": ""}, "2021-09-30-1042008518": {"title": "Facebook's Own Research Says Its Apps Can Harm Mental Health. Senators Have Questions : NPR", "url": "https://www.npr.org/2021/09/30/1042008518/facebooks-own-research-says-its-apps-can-harm-mental-health-senators-have-questi", "author": "No author found", "published_date": "2021-09-30", "content": "LEILA FADEL, HOST:  Facebook's global head of safety fielded tough questions on Capitol Hill today as senators accused the company of concealing data that confirmed Facebook and Instagram harms some young people's mental health. Here's Senator Richard Blumenthal. (SOUNDBITE OF ARCHIVED RECORDING)RICHARD BLUMENTHAL: It has weaponized childhood vulnerabilities against children themselves. It's chosen growth over children's mental health and well-being, greed over preventing the suffering of children. FADEL: The hearing comes after a Wall Street Journal investigation uncovered Facebook's own research, which showed that the photo sharing app led to body image issues or worse in many teens. In response, Facebook has said the research was taken out of context. Jeff Horwitz is part of the team that reported that investigation, and he joins us now. Hi, Jeff. JEFF HORWITZ: Hello. FADEL: So before we get started, I should note that Facebook is an NPR sponsor. But let's start with what your investigation found about the impact of Facebook and Instagram on teens and mental health. What did you learn? HORWITZ: So the company's been looking at this for a number of years. And what they found is that for most users, Instagram is perfectly fine. However, for users who come to the platform with some level of mental vulnerability, which is to say a lot of teenagers, it can be really problematic. And in particular for teenage girls, it can make body image issues worse. And in fact, they found that there were - among users who they surveyed who had thought about harming themselves in the last month, that a non-trivial percentage - 6% in the U. S. , 13% of British teenagers - trace the desire to kill themselves back to the app itself. FADEL: Wow. Wow. And you've been following the hearing today. What's been happening? HORWITZ: Well, Facebook, last night in advance of this, released a couple of the slide decks that - from the researchers that we had cited in our reporting. We then released another four. And the interesting thing is Facebook kind of undercut the legitimacy and value of its own research in a really kind of surprising way. They basically said that it did not show the things that the researchers said and that the researchers had kind of overstated the value, I suppose, of their own work in these presentations to executives. So they defended themselves by saying simply that it had been misconstrued. Obviously, members of the Senate on both sides did not see it that way. FADEL: Tell us about the choice that Facebook made. Who did they send to this hearing today? HORWITZ: So they sent Antigone Davis, a woman who is in charge of their safety efforts. She's not someone who would have been kind of responsible for the things that - the problems that are alleged here. She would be the person who would be kind of trying to work on fixing them. So it was kind of an unusual choice, shall we say, for the company to send her out. FADEL: And ultimately, what were the big questions she was facing? HORWITZ: The major questions were why Facebook hadn't disclosed this and also why it wasn't doing more as a result of this work. So I think the senators considered this to be proof that the company's products were in fact harmful, and they believed that Facebook had an obligation to do far more than it has to figure out how to keep young people either off its platform entirely if it's not safe, or to figure out how to make it safe for them. And they certainly did not like the idea of Facebook resurrecting an idea that was quite live until the beginning of this week, which was an Instagram platform meant for children under the age of 13. They considered it just to be reckless and irresponsible to proceed, given what Facebook knows of its own work. FADEL: And that's on indefinite pause right now, right? HORWITZ: Yeah, they've said that they will bring it back and that this will move forward, but they are taking a break to consult with everyone and sort of try to make clear why they believe this is a good thing for the world and a good thing for children. FADEL: So what happens next? HORWITZ: Well, there was a bipartisan agreement that Facebook did not acquit itself well. And so there was also talk about changing the laws related to children's safety on the internet, which, you know, go back to the '90s and, candidly, don't really seem to contemplate the existence of social media in its current form. And, you know, I think some of the senators talked about how this had been a frustration, that it hadn't happened yet, and they've been working on this for a long time. But, you know, they suggested that perhaps there might be an impetus at this point and a momentum to get it done. FADEL: So rare to hear the term bipartisan agreement these days. That was Wall Street Journal reporter Jeff Horwitz. Thank you so much for your reporting. HORWITZ: Thank you. FADEL: If you or someone you know may be considering suicide, contact the National Suicide Prevention Lifeline at 1-800-273-8255. (SOUNDBITE OF MUSIC) LEILA FADEL, HOST:   Facebook's global head of safety fielded tough questions on Capitol Hill today as senators accused the company of concealing data that confirmed Facebook and Instagram harms some young people's mental health. Here's Senator Richard Blumenthal. (SOUNDBITE OF ARCHIVED RECORDING) RICHARD BLUMENTHAL: It has weaponized childhood vulnerabilities against children themselves. It's chosen growth over children's mental health and well-being, greed over preventing the suffering of children. FADEL: The hearing comes after a Wall Street Journal investigation uncovered Facebook's own research, which showed that the photo sharing app led to body image issues or worse in many teens. In response, Facebook has said the research was taken out of context. Jeff Horwitz is part of the team that reported that investigation, and he joins us now. Hi, Jeff. JEFF HORWITZ: Hello. FADEL: So before we get started, I should note that Facebook is an NPR sponsor. But let's start with what your investigation found about the impact of Facebook and Instagram on teens and mental health. What did you learn? HORWITZ: So the company's been looking at this for a number of years. And what they found is that for most users, Instagram is perfectly fine. However, for users who come to the platform with some level of mental vulnerability, which is to say a lot of teenagers, it can be really problematic. And in particular for teenage girls, it can make body image issues worse. And in fact, they found that there were - among users who they surveyed who had thought about harming themselves in the last month, that a non-trivial percentage - 6% in the U. S. , 13% of British teenagers - trace the desire to kill themselves back to the app itself. FADEL: Wow. Wow. And you've been following the hearing today. What's been happening? HORWITZ: Well, Facebook, last night in advance of this, released a couple of the slide decks that - from the researchers that we had cited in our reporting. We then released another four. And the interesting thing is Facebook kind of undercut the legitimacy and value of its own research in a really kind of surprising way. They basically said that it did not show the things that the researchers said and that the researchers had kind of overstated the value, I suppose, of their own work in these presentations to executives. So they defended themselves by saying simply that it had been misconstrued. Obviously, members of the Senate on both sides did not see it that way. FADEL: Tell us about the choice that Facebook made. Who did they send to this hearing today? HORWITZ: So they sent Antigone Davis, a woman who is in charge of their safety efforts. She's not someone who would have been kind of responsible for the things that - the problems that are alleged here. She would be the person who would be kind of trying to work on fixing them. So it was kind of an unusual choice, shall we say, for the company to send her out. FADEL: And ultimately, what were the big questions she was facing? HORWITZ: The major questions were why Facebook hadn't disclosed this and also why it wasn't doing more as a result of this work. So I think the senators considered this to be proof that the company's products were in fact harmful, and they believed that Facebook had an obligation to do far more than it has to figure out how to keep young people either off its platform entirely if it's not safe, or to figure out how to make it safe for them. And they certainly did not like the idea of Facebook resurrecting an idea that was quite live until the beginning of this week, which was an Instagram platform meant for children under the age of 13. They considered it just to be reckless and irresponsible to proceed, given what Facebook knows of its own work. FADEL: And that's on indefinite pause right now, right? HORWITZ: Yeah, they've said that they will bring it back and that this will move forward, but they are taking a break to consult with everyone and sort of try to make clear why they believe this is a good thing for the world and a good thing for children. FADEL: So what happens next? HORWITZ: Well, there was a bipartisan agreement that Facebook did not acquit itself well. And so there was also talk about changing the laws related to children's safety on the internet, which, you know, go back to the '90s and, candidly, don't really seem to contemplate the existence of social media in its current form. And, you know, I think some of the senators talked about how this had been a frustration, that it hadn't happened yet, and they've been working on this for a long time. But, you know, they suggested that perhaps there might be an impetus at this point and a momentum to get it done. FADEL: So rare to hear the term bipartisan agreement these days. That was Wall Street Journal reporter Jeff Horwitz. Thank you so much for your reporting. HORWITZ: Thank you. FADEL: If you or someone you know may be considering suicide, contact the National Suicide Prevention Lifeline at 1-800-273-8255. (SOUNDBITE OF MUSIC)", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-09-30-1041864356": {"title": "Senators Blast Facebook For Concealing Instagram's Risks To Kids : NPR", "url": "https://www.npr.org/2021/09/30/1041864356/instagram-kids-safety-congress-hearing", "author": "No author found", "published_date": "2021-09-30", "content": "", "section": "Technology", "disclaimer": ""}, "2021-09-30-1040999446": {"title": "Despite Security Concerns, Online Voting Gets $10 Million Push : NPR", "url": "https://www.npr.org/2021/09/30/1040999446/internet-voting-phones-tusk-grant", "author": "No author found", "published_date": "2021-09-30", "content": "", "section": "Politics", "disclaimer": ""}, "2021-09-30-1041793686": {"title": "Facebook Will Be Back On Capitol Hill To Face Senators' Questions : NPR", "url": "https://www.npr.org/2021/09/30/1041793686/facebook-will-be-back-on-capitol-hill-to-face-senators-questions", "author": "No author found", "published_date": "2021-09-30", "content": "A MARTINEZ, HOST:  Facebook faces a Senate committee today as it pauses plans to build a version of Instagram aimed at kids 10 to 12 years old. It's the latest in a long list of public crises for the company, which, we should note, is a financial supporter of NPR. And this report from tech correspondent Shannon Bond includes topics that might be inappropriate for children. SHANNON BOND, BYLINE: For Facebook, it's a big concession to put Instagram Kids on hold. Here's what the app's head, Adam Mosseri, told NBC's \"Today\" show. (SOUNDBITE OF TV SHOW, \"TODAY\")ADAM MOSSERI: I still firmly believe that it's a good thing to build a version of Instagram that's designed to be safe for tweens. But we want to take the time to talk to parents and researchers and safety experts and get to more consensus about how to move forward. BOND: For months, Facebook brushed off concerns from critics about kids' privacy and mental health. It says kids are already on Instagram, despite its age limit of 13, so it would be better to build a version just for them. So why did it back off? (SOUNDBITE OF ARCHIVED RECORDING)MARSHA BLACKBURN: What we know is a lot of this anecdotal information that we had from parents, teachers, pediatricians about the harms of social media to children that Facebook was aware of this. BOND: That's Republican Senator Marsha Blackburn of Tennessee speaking to CNBC. This crisis was ignited by a Facebook whistleblower who turned over a trove of internal documents to the Wall Street Journal. It exposed how Facebook's own researchers found Instagram is deeply toxic to some of its youngest users. One in 3 teenage girls said Instagram makes their body image issues worse. A small number of teens even trace their suicidal thoughts directly to the app. But the journal reported when Facebook's growth collides with its own research, growth usually wins. (SOUNDBITE OF ARCHIVED RECORDING)BLACKBURN: You know what? In pursuit of the dollar, they did it anyway. BOND: And the leaked documents make clear Facebook knows how harmful its platform can be, including how it's used by human traffickers to sell people. Now Blackburn and her colleagues, Democrats and Republicans, will demand answers at today's hearing. (SOUNDBITE OF ARCHIVED RECORDING)BLACKBURN: It is time for them to engage with us and say, these are going to be the guardrails; this is how we're going to prevent drug traffickers, sex traffickers, human traffickers from using our platforms to conduct their business. BOND: Facebook says it rejects the claim that it's ignoring its own research, which it says The Wall Street Journal mischaracterized, and says it welcomes regulation. Still, the company is facing a lot of heat right now. There's pressure from the White House over vaccine misinformation, a federal antitrust lawsuit, a congressional probe of social media's role in the January 6 Capitol insurrection. KATIE HARBATH: Facebook's brand is bad. And I think Facebook, you know, would freely admit that. BOND: Katie Harbath is a former public policy director at the company. She says that's why Facebook has stopped apologizing and started hitting back at critics. HARBATH: You know, nobody else is going to come and defend the company besides themselves. BOND: And Facebook doesn't want to just play defense. It also wants to turn the page to Silicon Valley's new favorite buzzword, the metaverse. Here's Facebook CEO Mark Zuckerberg in an interview this summer with tech journalist Casey Newton. (SOUNDBITE OF ARCHIVED RECORDING)MARK ZUCKERBERG: You can kind of think about the metaverse as an embodied internet. BOND: If that sounds like science fiction, well, that's exactly where the idea came from. The metaverse is an ambitious effort to move more of what we do every day in the physical world into a shared digital world, where people's avatars go to work, play games, even attend concerts, all in virtual reality. Zuckerberg says, it's Facebook's future. (SOUNDBITE OF ARCHIVED RECORDING)ZUCKERBERG: In this next chapter of our company, you know, I think we'll - we will, I think, effectively transition from, you know, people seeing us as primarily being a social media company to being a metaverse company. BOND: But critics say, before Facebook creates a new digital world, it needs to fix its current social network. Yael Eisenstat, who worked at Facebook on elections integrity for political advertising in 2018, says the company may be miscalculating this moment. YAEL EISENSTAT: They have been able to weather these storms over and over again. What I think is different this time is that I don't think they're fully understanding that internal employees have questions now. BOND: Because this crisis stems from Facebook's own research, it's harder to dismiss. Today, senators get a chance to grill the company about these issues. Next week, the same committee will hear from a Facebook whistleblower. Shannon Bond, NPR News. (SOUNDBITE OF AMBINATE'S \"DIVIDE\") A MARTINEZ, HOST:   Facebook faces a Senate committee today as it pauses plans to build a version of Instagram aimed at kids 10 to 12 years old. It's the latest in a long list of public crises for the company, which, we should note, is a financial supporter of NPR. And this report from tech correspondent Shannon Bond includes topics that might be inappropriate for children. SHANNON BOND, BYLINE: For Facebook, it's a big concession to put Instagram Kids on hold. Here's what the app's head, Adam Mosseri, told NBC's \"Today\" show. (SOUNDBITE OF TV SHOW, \"TODAY\") ADAM MOSSERI: I still firmly believe that it's a good thing to build a version of Instagram that's designed to be safe for tweens. But we want to take the time to talk to parents and researchers and safety experts and get to more consensus about how to move forward. BOND: For months, Facebook brushed off concerns from critics about kids' privacy and mental health. It says kids are already on Instagram, despite its age limit of 13, so it would be better to build a version just for them. So why did it back off? (SOUNDBITE OF ARCHIVED RECORDING) MARSHA BLACKBURN: What we know is a lot of this anecdotal information that we had from parents, teachers, pediatricians about the harms of social media to children that Facebook was aware of this. BOND: That's Republican Senator Marsha Blackburn of Tennessee speaking to CNBC. This crisis was ignited by a Facebook whistleblower who turned over a trove of internal documents to the Wall Street Journal. It exposed how Facebook's own researchers found Instagram is deeply toxic to some of its youngest users. One in 3 teenage girls said Instagram makes their body image issues worse. A small number of teens even trace their suicidal thoughts directly to the app. But the journal reported when Facebook's growth collides with its own research, growth usually wins. (SOUNDBITE OF ARCHIVED RECORDING) BLACKBURN: You know what? In pursuit of the dollar, they did it anyway. BOND: And the leaked documents make clear Facebook knows how harmful its platform can be, including how it's used by human traffickers to sell people. Now Blackburn and her colleagues, Democrats and Republicans, will demand answers at today's hearing. (SOUNDBITE OF ARCHIVED RECORDING) BLACKBURN: It is time for them to engage with us and say, these are going to be the guardrails; this is how we're going to prevent drug traffickers, sex traffickers, human traffickers from using our platforms to conduct their business. BOND: Facebook says it rejects the claim that it's ignoring its own research, which it says The Wall Street Journal mischaracterized, and says it welcomes regulation. Still, the company is facing a lot of heat right now. There's pressure from the White House over vaccine misinformation, a federal antitrust lawsuit, a congressional probe of social media's role in the January 6 Capitol insurrection. KATIE HARBATH: Facebook's brand is bad. And I think Facebook, you know, would freely admit that. BOND: Katie Harbath is a former public policy director at the company. She says that's why Facebook has stopped apologizing and started hitting back at critics. HARBATH: You know, nobody else is going to come and defend the company besides themselves. BOND: And Facebook doesn't want to just play defense. It also wants to turn the page to Silicon Valley's new favorite buzzword, the metaverse. Here's Facebook CEO Mark Zuckerberg in an interview this summer with tech journalist Casey Newton. (SOUNDBITE OF ARCHIVED RECORDING) MARK ZUCKERBERG: You can kind of think about the metaverse as an embodied internet. BOND: If that sounds like science fiction, well, that's exactly where the idea came from. The metaverse is an ambitious effort to move more of what we do every day in the physical world into a shared digital world, where people's avatars go to work, play games, even attend concerts, all in virtual reality. Zuckerberg says, it's Facebook's future. (SOUNDBITE OF ARCHIVED RECORDING) ZUCKERBERG: In this next chapter of our company, you know, I think we'll - we will, I think, effectively transition from, you know, people seeing us as primarily being a social media company to being a metaverse company. BOND: But critics say, before Facebook creates a new digital world, it needs to fix its current social network. Yael Eisenstat, who worked at Facebook on elections integrity for political advertising in 2018, says the company may be miscalculating this moment. YAEL EISENSTAT: They have been able to weather these storms over and over again. What I think is different this time is that I don't think they're fully understanding that internal employees have questions now. BOND: Because this crisis stems from Facebook's own research, it's harder to dismiss. Today, senators get a chance to grill the company about these issues. Next week, the same committee will hear from a Facebook whistleblower. Shannon Bond, NPR News. (SOUNDBITE OF AMBINATE'S \"DIVIDE\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-10-01-1042477486": {"title": "What the hack of Epik reveals about the world of far-right extremism : NPR", "url": "https://www.npr.org/2021/10/01/1042477486/what-the-hack-of-epik-reveals-about-the-world-of-far-right-extremism", "author": "No author found", "published_date": "2021-10-01", "content": "ARI SHAPIRO, HOST:  This week saw a second and bigger public release of data from Epik, a web hosting service favored by the far-right. It offers an unprecedented glimpse into the world of extremism but comes with cautions. NPR's Odette Yousef covers domestic extremism and is here to tell us more. Hi, Odette. ODETTE YOUSEF, BYLINE: Hi. SHAPIRO: Tell us more about this hack and what was involved. YOUSEF: So, Ari, the Epik web host has been called the web host of last resort. It's hosted sites like Gab, Parler, BitChute, 8Chan. The hacktivists behind this leak has called it the - you know, the web host for the, quote, \"fascist side of the internet. \" And the data that's been released is enormous. It includes tons of personally identifying information, such as usernames, passwords, financials, including current credit card numbers, all these pieces that researchers say can really help fill out the puzzle on who's involved in far-right movements, how they're connected to each other and where the money's coming from. You know, to get a sense of how stunning it is, I want you to hear this cut from Heidi Beirich. She's co-founder of the Global Project Against Hate and Extremism. HEIDI BEIRICH: You know, I'm not justifying hacking here, but the - this is a decision to expose who are behind anti-vax information, racism, hatred, neo-Nazi-ism. And it's kind of overwhelming. YOUSEF: You know, overwhelming because it's, like, 10 years' worth of data, Ari, and it's going to take several years to extract, you know, all of the information contained within it. SHAPIRO: What was behind this hack and the public release of the information? Why are we seeing it now? YOUSEF: Well, you know, it's been an interesting week because, you know, we didn't just see this second Epik hack get leaked, but there was also a separate release of data of the Oath Keepers militia group. What seems to be happening is the hacktivist community is increasingly targeting sites after the events of January 6 at the U. S. Capitol and after the Texas abortion bill passed. But, you know, this is a dangerous iceberg as well. You know, some of the people, like Heidi Beirich and some journalists that have covered the hack so far, are getting threatened. Some of them have been doxed, which means that they and their family members' personal identifying information has been made public. SHAPIRO: Yeah, I'm struck by Beirich saying, I'm not justifying hacking here, but - tell us about the concerns, the dangers, of this information being public and people using it. YOUSEF: Yeah. So pretty much everybody said, you know, there are a lot of landmines in using the data from these leaks. One of the most cautious people, actually, that I spoke to is Brian Levin. He is the director of the Center for the Study of Hate and Extremism at California State University. And he was warning that there aren't just pitfalls to using the data, but there are also ethical concerns around these leaks and using the information in them. This is what he told me. BRIAN LEVIN: Where does it stop? Who gets targeted? And is there going to be some kind of unintended consequence? Is there some investigation that's being thwarted or breached? Or is there someone who's no longer associated getting caught up in this or someone who has a similar name? You get the idea. I think one type of vigilantism can encourage others. YOUSEF: So, you know, don't mistake him. You know, Levin does see that this - these leaks are a potential gold mine but that, you know, they require care. When it comes to journalists on this topic, you know, he says we continually will have to weigh whether what we publish is, in fact, a matter of public interest and the harm that could come from it. So, you know, we'll have to see for years to come what we learn from everything that's been leaked. SHAPIRO: NPR's Odette Yousef, thanks a lot. YOUSEF: Thank you. ARI SHAPIRO, HOST:   This week saw a second and bigger public release of data from Epik, a web hosting service favored by the far-right. It offers an unprecedented glimpse into the world of extremism but comes with cautions. NPR's Odette Yousef covers domestic extremism and is here to tell us more. Hi, Odette. ODETTE YOUSEF, BYLINE: Hi. SHAPIRO: Tell us more about this hack and what was involved. YOUSEF: So, Ari, the Epik web host has been called the web host of last resort. It's hosted sites like Gab, Parler, BitChute, 8Chan. The hacktivists behind this leak has called it the - you know, the web host for the, quote, \"fascist side of the internet. \" And the data that's been released is enormous. It includes tons of personally identifying information, such as usernames, passwords, financials, including current credit card numbers, all these pieces that researchers say can really help fill out the puzzle on who's involved in far-right movements, how they're connected to each other and where the money's coming from. You know, to get a sense of how stunning it is, I want you to hear this cut from Heidi Beirich. She's co-founder of the Global Project Against Hate and Extremism. HEIDI BEIRICH: You know, I'm not justifying hacking here, but the - this is a decision to expose who are behind anti-vax information, racism, hatred, neo-Nazi-ism. And it's kind of overwhelming. YOUSEF: You know, overwhelming because it's, like, 10 years' worth of data, Ari, and it's going to take several years to extract, you know, all of the information contained within it. SHAPIRO: What was behind this hack and the public release of the information? Why are we seeing it now? YOUSEF: Well, you know, it's been an interesting week because, you know, we didn't just see this second Epik hack get leaked, but there was also a separate release of data of the Oath Keepers militia group. What seems to be happening is the hacktivist community is increasingly targeting sites after the events of January 6 at the U. S. Capitol and after the Texas abortion bill passed. But, you know, this is a dangerous iceberg as well. You know, some of the people, like Heidi Beirich and some journalists that have covered the hack so far, are getting threatened. Some of them have been doxed, which means that they and their family members' personal identifying information has been made public. SHAPIRO: Yeah, I'm struck by Beirich saying, I'm not justifying hacking here, but - tell us about the concerns, the dangers, of this information being public and people using it. YOUSEF: Yeah. So pretty much everybody said, you know, there are a lot of landmines in using the data from these leaks. One of the most cautious people, actually, that I spoke to is Brian Levin. He is the director of the Center for the Study of Hate and Extremism at California State University. And he was warning that there aren't just pitfalls to using the data, but there are also ethical concerns around these leaks and using the information in them. This is what he told me. BRIAN LEVIN: Where does it stop? Who gets targeted? And is there going to be some kind of unintended consequence? Is there some investigation that's being thwarted or breached? Or is there someone who's no longer associated getting caught up in this or someone who has a similar name? You get the idea. I think one type of vigilantism can encourage others. YOUSEF: So, you know, don't mistake him. You know, Levin does see that this - these leaks are a potential gold mine but that, you know, they require care. When it comes to journalists on this topic, you know, he says we continually will have to weigh whether what we publish is, in fact, a matter of public interest and the harm that could come from it. So, you know, we'll have to see for years to come what we learn from everything that's been leaked. SHAPIRO: NPR's Odette Yousef, thanks a lot. YOUSEF: Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-10-02-1042667303": {"title": "Companies are using a growing number of tracking services as employees work from home : NPR", "url": "https://www.npr.org/2021/10/02/1042667303/companies-are-using-a-growing-number-of-tracking-services-as-employees-work-from", "author": "No author found", "published_date": "2021-10-02", "content": "SCOTT SIMON, HOST:  Do you ever feel like somebody's watching you always? May not be just your imagination. Companies are using a growing number of technologies to monitor - notice they don't say snoop on - you, their employees, during these work from home days. Companies like Teramind, InterGuard, ActivTrak, Hubstaff and TimeCamp track everything from how long it takes to respond to an email to periodically taking screenshots of your desktop. If you're uncomfortable with this kind of tracking, you know, there just may not be much to do about it under the law. Alexandra Reeve Givens is president of the Center for Democracy and Technology and joins us now. Ms. Givens, thanks so much for being with us. ALEXANDRA REEVE GIVENS: Thanks for having me. SIMON: We've listed a couple of things, but I wonder if you could tell us about a couple that particularly concern, even chill you. GIVENS: Yes. And we're certainly seeing an increase of the sale of these tools during the pandemic. So we read and hear about tools that track every keystroke that a remote worker's making on their computer, some that take periodic screenshots of a worker's computer screen or check in on their microphone or their webcam to monitor their physical movements. I remember reading one story about a company that marketed this suite of strategies to basically generate a timecard every 10 minutes. It would capture what the employee was doing at exactly that point. And one of their workers gave an interview saying that he had to time his bathroom breaks. . . GIVENS: . . . So that he wouldn't get caught away from his computer and docked pay for the time during that 10 minutes if he'd stepped away. SIMON: Forgive me - what if somebody is picking their nose? GIVENS: Right. Exactly. I mean, this raises big privacy questions, right? If you think about the perspective of an employee, you're being asked to do work for a company. One hopes that comes with some trust about what you're able to do. But also, I think about all of those workers who aren't working in a private space during the pandemic. They might have family in the background when you're taking that picture from a webcam. SIMON: What do employers want? What do they do with this information? GIVENS: So a lot of them, I think, are trying to track productivity. Some of them aggregate that information. So they're just trying to understand at a more macro level, what apps are employees using? What are some of the trends we're seeing? And they think, OK, well, that makes us feel more comfortable because we're just looking at big picture patterns as opposed to, say, an individual disciplinary decision. But even if this is useful for tracking broader trends, it still really erodes respect for workers. And creating examples like people rushing or feeling bad that they can't take a bathroom break has health and safety concerns, as well. SIMON: What do you think is necessary to end this? Or do companies really want to end it? New laws, new policies? GIVENS: I think one thing is talking about it in fora like this. So employers get a gut check for a moment on what they're really asking of their employees. Sadly, right now the law doesn't have all that much to say about these tools. There are, of course, workplace safety laws, so to the extent that this impacts people's ability to go to the bathroom or for somebody with disabilities, if they're not being accommodated because of the surveillance in their space, there's a potential legal violation there that employers do need to pay attention to. Right now we don't think about the home as a workplace that much. After often times, OSHA, as it's called, focuses much more on factory settings, et cetera. But we need to update that for the 21st century and make sure that workers are protected wherever they're doing the work. SIMON: Should people occasionally cover the eye of the camera, the microphone on their laptop when they're not working? GIVENS: Yeah, I mean, I think in instances where technology. . . SIMON: Even where they are, I suppose, yeah. GIVENS: Right. So you - one does have the choice to do that. I think in those inside environments where a tracking tool has been deployed or you think a tracking tool might have been deployed, there the workers really do need to be asking questions of their employers to the extent that they can, challenging, what is this information being collected for and why? But also, that's just the tip of the iceberg in terms of worker privacy issues. We can think about different instances of employers looking at workers' social media feeds, for example, to see what they're talking about outside of work. And you think about the impact that has on people's free expression or the ability to organize as a union, for example. You can think about instances where employers have gotten access to people's Fitbit information and their health tracking information. There are a lot of companies that have incentive programs for people to share that data with their bosses. All of those help, again, reflect this imbalance of power between employers and workers and just how much we can be quantified and tracked. And we really need to raise more awareness about this, help workers push back and hopefully fight for some legal interventions, too. SIMON: Alexandra Reeve Givens is president of the Center for Democracy and Technology. Thank you so much for being with us. GIVENS: Thank you. SCOTT SIMON, HOST:   Do you ever feel like somebody's watching you always? May not be just your imagination. Companies are using a growing number of technologies to monitor - notice they don't say snoop on - you, their employees, during these work from home days. Companies like Teramind, InterGuard, ActivTrak, Hubstaff and TimeCamp track everything from how long it takes to respond to an email to periodically taking screenshots of your desktop. If you're uncomfortable with this kind of tracking, you know, there just may not be much to do about it under the law. Alexandra Reeve Givens is president of the Center for Democracy and Technology and joins us now. Ms. Givens, thanks so much for being with us. ALEXANDRA REEVE GIVENS: Thanks for having me. SIMON: We've listed a couple of things, but I wonder if you could tell us about a couple that particularly concern, even chill you. GIVENS: Yes. And we're certainly seeing an increase of the sale of these tools during the pandemic. So we read and hear about tools that track every keystroke that a remote worker's making on their computer, some that take periodic screenshots of a worker's computer screen or check in on their microphone or their webcam to monitor their physical movements. I remember reading one story about a company that marketed this suite of strategies to basically generate a timecard every 10 minutes. It would capture what the employee was doing at exactly that point. And one of their workers gave an interview saying that he had to time his bathroom breaks. . . GIVENS: . . . So that he wouldn't get caught away from his computer and docked pay for the time during that 10 minutes if he'd stepped away. SIMON: Forgive me - what if somebody is picking their nose? GIVENS: Right. Exactly. I mean, this raises big privacy questions, right? If you think about the perspective of an employee, you're being asked to do work for a company. One hopes that comes with some trust about what you're able to do. But also, I think about all of those workers who aren't working in a private space during the pandemic. They might have family in the background when you're taking that picture from a webcam. SIMON: What do employers want? What do they do with this information? GIVENS: So a lot of them, I think, are trying to track productivity. Some of them aggregate that information. So they're just trying to understand at a more macro level, what apps are employees using? What are some of the trends we're seeing? And they think, OK, well, that makes us feel more comfortable because we're just looking at big picture patterns as opposed to, say, an individual disciplinary decision. But even if this is useful for tracking broader trends, it still really erodes respect for workers. And creating examples like people rushing or feeling bad that they can't take a bathroom break has health and safety concerns, as well. SIMON: What do you think is necessary to end this? Or do companies really want to end it? New laws, new policies? GIVENS: I think one thing is talking about it in fora like this. So employers get a gut check for a moment on what they're really asking of their employees. Sadly, right now the law doesn't have all that much to say about these tools. There are, of course, workplace safety laws, so to the extent that this impacts people's ability to go to the bathroom or for somebody with disabilities, if they're not being accommodated because of the surveillance in their space, there's a potential legal violation there that employers do need to pay attention to. Right now we don't think about the home as a workplace that much. After often times, OSHA, as it's called, focuses much more on factory settings, et cetera. But we need to update that for the 21st century and make sure that workers are protected wherever they're doing the work. SIMON: Should people occasionally cover the eye of the camera, the microphone on their laptop when they're not working? GIVENS: Yeah, I mean, I think in instances where technology. . . SIMON: Even where they are, I suppose, yeah. GIVENS: Right. So you - one does have the choice to do that. I think in those inside environments where a tracking tool has been deployed or you think a tracking tool might have been deployed, there the workers really do need to be asking questions of their employers to the extent that they can, challenging, what is this information being collected for and why? But also, that's just the tip of the iceberg in terms of worker privacy issues. We can think about different instances of employers looking at workers' social media feeds, for example, to see what they're talking about outside of work. And you think about the impact that has on people's free expression or the ability to organize as a union, for example. You can think about instances where employers have gotten access to people's Fitbit information and their health tracking information. There are a lot of companies that have incentive programs for people to share that data with their bosses. All of those help, again, reflect this imbalance of power between employers and workers and just how much we can be quantified and tracked. And we really need to raise more awareness about this, help workers push back and hopefully fight for some legal interventions, too. SIMON: Alexandra Reeve Givens is president of the Center for Democracy and Technology. Thank you so much for being with us. GIVENS: Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-10-03-1042908136": {"title": "Ex-Facebook manager alleges the social network fed the Capitol riot : NPR", "url": "https://www.npr.org/2021/10/03/1042908136/facebook-whistleblower-frances-haugen-social-network-capitol-riot", "author": "No author found", "published_date": "2021-10-03", "content": "", "section": "Technology", "disclaimer": ""}, "2021-10-04-1043150167": {"title": "What Sen. Blumenthal's 'finsta' flub says about Congress' grasp of Big Tech : NPR", "url": "https://www.npr.org/2021/10/04/1043150167/sen-blumenthals-finsta-flub-renews-questions-about-congress-grasp-of-big-tech", "author": "No author found", "published_date": "2021-10-04", "content": "", "section": "Politics", "disclaimer": ""}, "2021-10-04-1043145219": {"title": "Facebook responds to whistleblower's claim that company chose profits over the public : NPR", "url": "https://www.npr.org/2021/10/04/1043145219/facebook-responds-to-whistleblowers-claim-that-company-chose-profits-over-the-pu", "author": "No author found", "published_date": "2021-10-04", "content": "ARI SHAPIRO, HOST:  First came documents - tens of thousands of pages of internal Facebook files. They show Facebook knows its algorithms promote hate and misinformation and that content keeps people engaged. They also contain internal research showing that Facebook's Instagram app hurts some teens' mental health and exacerbates body issues. Now the whistleblower who leaked those documents is speaking out. Frances Haugen is a former Facebook employee who spoke to \"60 Minutes\" last night. (SOUNDBITE OF TV SHOW, \"60 MINUTES\")FRANCES HAUGEN: The thing I saw on Facebook over and over again was there were conflicts of interest between what was good for the public and what was good for Facebook. And Facebook over and over again chose to optimize for its own interests, like making more money. SHAPIRO: We'll note that the company is among NPR's financial supporters. And we're joined now by Facebook executive Neil Potts. He is vice president for trust and safety. Welcome to ALL THINGS CONSIDERED. NEIL POTTS: Hey, Ari. How are you? Neil Potts. Thank you. SHAPIRO: All right - good to have you here. So how can explain Facebook's calculus this way? If the company changed the algorithm to make people safer and deprioritized hateful and divisive posts, then people would spend less time on the site, click on fewer ads. The company would make less money. Do you agree that polarization leads to engagement, which translates to money for Facebook? POTTS: I think I would categorically deny that. I think that accusation is just a bit unfounded. At Facebook, what we are designing our products to do is to increase meaningful experiences. So whether those are meaningful social interactions - I think that is the change that the leaker mentions in her \"60 Minutes\" interview - or having just positive social experience on the platform, that is what we want the product ultimately to provide. That makes a environment where people will come to Facebook, where they will come to Instagram and have a - just a better time. And that's really our bottom line. SHAPIRO: So I just want to be clear. Are you saying it may be the case that polarization leads to more engagement, but we're not trying to polarize our users, so that's not what we want the algorithm to do? Or are you saying, no, the premise that more extreme views will lead people to engage more is just fundamentally wrong? POTTS: I think just taking a step back on that question of polarization - I think polarization has, you know, existed long before Facebook and will exist long after, perhaps, that we're all no longer here. That being said, at Facebook, we're not designing anything to be for the sensational or clickbait-y (ph) or engagement bait-y (ph) ways that polarization may be seen. And that, I think, was being accused of Facebook and the leadership decisions on the product. Our products are designed to have more meaningful social interactions - those interactions with your friends, your loved ones, your close-knit groups to ensure that you're coming to the platform to have a - just a positive social experience, one that you can have not only just meaningful experiences but things that you will find perhaps unfettered positive values in. SHAPIRO: Well, let's talk specifically about some of the safeguards that were put in place after - in the run up to the 2020 election. These were to reduce misinformation, and Haugen says many of those protections went away after the election. We now see indictments against some of the January 6 rioters that cite Facebook posts. So how does Facebook defend its decision to dissolve its Civic Integrity Unit now that you know what happened just after the election, when some of those safeguards were no longer in place? POTTS: Thanks, Ari. I think I want to make sure that we're very clear here. The Civic Integrity Unit has not been dissolved in any ways. Actually, it has been, in many ways, promoted throughout the company. The team is now sitting with other teams so that we can take lessons learned about elections. SHAPIRO: So this was a centralized team, and now its individual responsibilities have been farmed out to other teams. POTTS: It's still within our centralized integrity team, the broader team to focus on other issues, including civic integrity but also issues that are, I think, at the top of everyone's mind, including issues around health and COVID-19. You can see a lot of the similarities between the way that we've treated elections on a platform of our elections hub as well as what we are doing around COVID-19 and the COVID-19 hub. So those teams are still in practice, doing work and actually working on civic issues in elections across the globe. SHAPIRO: Let me turn to Instagram and how it affects young people. Here's how Haugen characterized the company's research last night on \"60 Minutes. \"(SOUNDBITE OF TV SHOW, \"60 MINUTES\")HAUGEN: Facebook's own research says it is not just that Instagram is dangerous for teenagers, that it harms teenagers. It's that it is distinctly worse than other forms of social media. SHAPIRO: And she says that research found 13. 5% of teen girls said Instagram makes thoughts of suicide worse. Seventeen percent said it worsened eating disorders. And when Congress asked about this, CEO Mark Zuckerberg misstated the company's research and then withheld the damaging information that came out in this leak. How does Facebook justify that? POTTS: I don't think Mark withheld any of the research. I think one of the issues here - we're, you know, very committed to doing research. We recognize the value so we can close the gaps or reduce the gaps. But I want to put a bit of the context of this research into the field as well. This research was done over a - for boys and girls of teenage years over 12 different areas. And the majority actually - the majority of respondents, who were both boys and girls, said that Facebook has - Facebook and Instagram have a net positive on their mental health in these areas. And for a subset of people who already were struggling with things like anxiety, nervousness - excuse me - depression, coming to Facebook, on 11 out of 12, they actually felt better leaving Facebook and Instagram after engaging. On body images, I think that was one of the issues raised last week. There is a subset of people who - of girls who felt worse leaving. We recognize that, and we'll use that research to try to close those gaps. That's why I say we do that research. SHAPIRO: You say you want to do this research to close these gaps. In another part of the program, I speak with a 21-year-old journalist about these issues, and she's been using these platforms since she was a teen. I asked her whether she believes Facebook's assurances that it can use these research, close these gaps, do better, fix these problems. And here's what she said. NINA ROEHL: Well, if they could have, why haven't they already, right? This is not new. So I would love to say yes, that they can clean it up themselves. But my question then is, why haven't they already? SHAPIRO: Neil Potts, what would you say to her? POTTS: I would say to her, we're investing millions of dollars, billions of dollars on these issues to make sure that we are arriving at the right solutions. For any one person that experiences these, we want to make sure that we try to eliminate that. But on balance, we are doing the work, doing investing in the research so we know how to approach these issues and really even sending interventions to people who may be impacted by such harms. SHAPIRO: All right. Neil Potts is vice president for trust and safety policy at Facebook. Thank you for speaking with us. POTTS: Thank you. SHAPIRO: NPR tech correspondent Shannon Bond has been listening in to that interview with us. And, Shannon, what stood out to you from what we just heard? SHANNON BOND, BYLINE: Well, you know, ever since all of this broke with Haugen's claims and the reporting in The Wall Street Journal, you know, we've been hearing Facebook push really hard against what she's saying and what these documents seem to reveal, especially this core premise - right? - that the company is putting profit ahead of safety. So we just heard Neil Potts say, you know, those are unfounded accusations. But I think the real question here is, you know, maybe Facebook wasn't designed that way. You know, it wasn't designed, for example, for - to make, you know, engaging in negative content, you know, go viral. But if that is happening, what is Facebook doing about it? I think it gets at that last question you asked him, right? What is Facebook doing? And that's why we're seeing so much more pressure right now on the company about transparency. SHAPIRO: I also just need to ask you briefly about the worldwide outage that we've seen today across many of Facebook's platforms. BOND: That's right. I mean, the company says this is a network issue they're trying to fix. But Facebook, Instagram, WhatsApp - they've all been down since before noon Eastern. That's long, a long time. That's many hours. It's not really clear what is going on here. And certainly, you know, this sort of timing is leading a lot of people to make a lot of jokes about this. But, you know, it just shows you how reliant we all are on these platforms. SHAPIRO: NPR tech correspondent Shannon Bond following the story of Facebook. And we will be following tomorrow's testimony before the Senate panel as well. Thanks for your coverage. BOND: Thanks, Ari. ARI SHAPIRO, HOST:   First came documents - tens of thousands of pages of internal Facebook files. They show Facebook knows its algorithms promote hate and misinformation and that content keeps people engaged. They also contain internal research showing that Facebook's Instagram app hurts some teens' mental health and exacerbates body issues. Now the whistleblower who leaked those documents is speaking out. Frances Haugen is a former Facebook employee who spoke to \"60 Minutes\" last night. (SOUNDBITE OF TV SHOW, \"60 MINUTES\") FRANCES HAUGEN: The thing I saw on Facebook over and over again was there were conflicts of interest between what was good for the public and what was good for Facebook. And Facebook over and over again chose to optimize for its own interests, like making more money. SHAPIRO: We'll note that the company is among NPR's financial supporters. And we're joined now by Facebook executive Neil Potts. He is vice president for trust and safety. Welcome to ALL THINGS CONSIDERED. NEIL POTTS: Hey, Ari. How are you? Neil Potts. Thank you. SHAPIRO: All right - good to have you here. So how can explain Facebook's calculus this way? If the company changed the algorithm to make people safer and deprioritized hateful and divisive posts, then people would spend less time on the site, click on fewer ads. The company would make less money. Do you agree that polarization leads to engagement, which translates to money for Facebook? POTTS: I think I would categorically deny that. I think that accusation is just a bit unfounded. At Facebook, what we are designing our products to do is to increase meaningful experiences. So whether those are meaningful social interactions - I think that is the change that the leaker mentions in her \"60 Minutes\" interview - or having just positive social experience on the platform, that is what we want the product ultimately to provide. That makes a environment where people will come to Facebook, where they will come to Instagram and have a - just a better time. And that's really our bottom line. SHAPIRO: So I just want to be clear. Are you saying it may be the case that polarization leads to more engagement, but we're not trying to polarize our users, so that's not what we want the algorithm to do? Or are you saying, no, the premise that more extreme views will lead people to engage more is just fundamentally wrong? POTTS: I think just taking a step back on that question of polarization - I think polarization has, you know, existed long before Facebook and will exist long after, perhaps, that we're all no longer here. That being said, at Facebook, we're not designing anything to be for the sensational or clickbait-y (ph) or engagement bait-y (ph) ways that polarization may be seen. And that, I think, was being accused of Facebook and the leadership decisions on the product. Our products are designed to have more meaningful social interactions - those interactions with your friends, your loved ones, your close-knit groups to ensure that you're coming to the platform to have a - just a positive social experience, one that you can have not only just meaningful experiences but things that you will find perhaps unfettered positive values in. SHAPIRO: Well, let's talk specifically about some of the safeguards that were put in place after - in the run up to the 2020 election. These were to reduce misinformation, and Haugen says many of those protections went away after the election. We now see indictments against some of the January 6 rioters that cite Facebook posts. So how does Facebook defend its decision to dissolve its Civic Integrity Unit now that you know what happened just after the election, when some of those safeguards were no longer in place? POTTS: Thanks, Ari. I think I want to make sure that we're very clear here. The Civic Integrity Unit has not been dissolved in any ways. Actually, it has been, in many ways, promoted throughout the company. The team is now sitting with other teams so that we can take lessons learned about elections. SHAPIRO: So this was a centralized team, and now its individual responsibilities have been farmed out to other teams. POTTS: It's still within our centralized integrity team, the broader team to focus on other issues, including civic integrity but also issues that are, I think, at the top of everyone's mind, including issues around health and COVID-19. You can see a lot of the similarities between the way that we've treated elections on a platform of our elections hub as well as what we are doing around COVID-19 and the COVID-19 hub. So those teams are still in practice, doing work and actually working on civic issues in elections across the globe. SHAPIRO: Let me turn to Instagram and how it affects young people. Here's how Haugen characterized the company's research last night on \"60 Minutes. \" (SOUNDBITE OF TV SHOW, \"60 MINUTES\") HAUGEN: Facebook's own research says it is not just that Instagram is dangerous for teenagers, that it harms teenagers. It's that it is distinctly worse than other forms of social media. SHAPIRO: And she says that research found 13. 5% of teen girls said Instagram makes thoughts of suicide worse. Seventeen percent said it worsened eating disorders. And when Congress asked about this, CEO Mark Zuckerberg misstated the company's research and then withheld the damaging information that came out in this leak. How does Facebook justify that? POTTS: I don't think Mark withheld any of the research. I think one of the issues here - we're, you know, very committed to doing research. We recognize the value so we can close the gaps or reduce the gaps. But I want to put a bit of the context of this research into the field as well. This research was done over a - for boys and girls of teenage years over 12 different areas. And the majority actually - the majority of respondents, who were both boys and girls, said that Facebook has - Facebook and Instagram have a net positive on their mental health in these areas. And for a subset of people who already were struggling with things like anxiety, nervousness - excuse me - depression, coming to Facebook, on 11 out of 12, they actually felt better leaving Facebook and Instagram after engaging. On body images, I think that was one of the issues raised last week. There is a subset of people who - of girls who felt worse leaving. We recognize that, and we'll use that research to try to close those gaps. That's why I say we do that research. SHAPIRO: You say you want to do this research to close these gaps. In another part of the program, I speak with a 21-year-old journalist about these issues, and she's been using these platforms since she was a teen. I asked her whether she believes Facebook's assurances that it can use these research, close these gaps, do better, fix these problems. And here's what she said. NINA ROEHL: Well, if they could have, why haven't they already, right? This is not new. So I would love to say yes, that they can clean it up themselves. But my question then is, why haven't they already? SHAPIRO: Neil Potts, what would you say to her? POTTS: I would say to her, we're investing millions of dollars, billions of dollars on these issues to make sure that we are arriving at the right solutions. For any one person that experiences these, we want to make sure that we try to eliminate that. But on balance, we are doing the work, doing investing in the research so we know how to approach these issues and really even sending interventions to people who may be impacted by such harms. SHAPIRO: All right. Neil Potts is vice president for trust and safety policy at Facebook. Thank you for speaking with us. POTTS: Thank you. SHAPIRO: NPR tech correspondent Shannon Bond has been listening in to that interview with us. And, Shannon, what stood out to you from what we just heard? SHANNON BOND, BYLINE: Well, you know, ever since all of this broke with Haugen's claims and the reporting in The Wall Street Journal, you know, we've been hearing Facebook push really hard against what she's saying and what these documents seem to reveal, especially this core premise - right? - that the company is putting profit ahead of safety. So we just heard Neil Potts say, you know, those are unfounded accusations. But I think the real question here is, you know, maybe Facebook wasn't designed that way. You know, it wasn't designed, for example, for - to make, you know, engaging in negative content, you know, go viral. But if that is happening, what is Facebook doing about it? I think it gets at that last question you asked him, right? What is Facebook doing? And that's why we're seeing so much more pressure right now on the company about transparency. SHAPIRO: I also just need to ask you briefly about the worldwide outage that we've seen today across many of Facebook's platforms. BOND: That's right. I mean, the company says this is a network issue they're trying to fix. But Facebook, Instagram, WhatsApp - they've all been down since before noon Eastern. That's long, a long time. That's many hours. It's not really clear what is going on here. And certainly, you know, this sort of timing is leading a lot of people to make a lot of jokes about this. But, you know, it just shows you how reliant we all are on these platforms. SHAPIRO: NPR tech correspondent Shannon Bond following the story of Facebook. And we will be following tomorrow's testimony before the Senate panel as well. Thanks for your coverage. BOND: Thanks, Ari.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-10-04-1043098635": {"title": "Facebook, WhatsApp, Instagram suffer worldwide outage : NPR", "url": "https://www.npr.org/2021/10/04/1043098635/facebook-whatsapp-instagram-outage", "author": "No author found", "published_date": "2021-10-04", "content": "", "section": "Technology", "disclaimer": ""}, "2021-10-04-1043093307": {"title": "Facebook asks court to toss FTC lawsuit over its buys of Instagram and WhatsApp : NPR", "url": "https://www.npr.org/2021/10/04/1043093307/facebook-asks-dismiss-ftc-complaint-instagram-whatsapp", "author": "No author found", "published_date": "2021-10-04", "content": "", "section": "Technology", "disclaimer": ""}, "2021-10-04-1042921981": {"title": "Facebook whistleblower renews scrutiny of the social media giant : NPR", "url": "https://www.npr.org/2021/10/04/1042921981/facebook-whistleblower-renewing-scrutiny-of-social-media-giant", "author": "No author found", "published_date": "2021-10-04", "content": "", "section": "Technology", "disclaimer": ""}, "2021-10-04-1042969584": {"title": "Facebook whistleblower says the social media giant is putting profit over user safety : NPR", "url": "https://www.npr.org/2021/10/04/1042969584/facebook-whistleblower-says-the-social-media-giant-is-putting-profit-over-user-s", "author": "No author found", "published_date": "2021-10-04", "content": "RACHEL MARTIN, HOST:  A Facebook whistleblower says the social network puts profits over public safety. The former Facebook employee has handed over thousands of pages of internal Facebook documents to federal law enforcement. With more, NPR's Bobby Allyn joins us this morning. Hi, Bobby. BOBBY ALLYN, BYLINE: Good morning, Rachel. MARTIN: First off, who is this Facebook whistleblower? ALLYN: Her name is Frances Haugen. She's something of a specialist in how algorithms affect what we see on social media. She formerly worked at Google and Pinterest. During her two years at Facebook, though, she was on a team focused on figuring out how election-related misinformation spreads. But she became disillusioned. She felt like the team was understaffed, that Facebook wasn't taking seriously how its platform was affecting societies around the world. Then Facebook disbanded her team altogether. Weeks later, the Capitol riots happened. And she says Facebook underplayed how the platform was used to organize the riots. She was having a crisis of conscience. Here's how Haugen described it on CBS' \"60 Minutes. \" It aired Sunday. (SOUNDBITE OF TV SHOW, \"60 MINUTES\")FRANCES HAUGEN: The thing I saw at Facebook over and over again was there were conflicts of interest between what was good for the public and what was good for Facebook. And Facebook, over and over again, chose to optimize for its own interests, like making more money. MARTIN: Which is, frankly, the objective of any company - right? - to prioritize profits. But is she saying Facebook broke the law in this? ALLYN: Yeah. Yeah. She is. So I talked to her lawyer, John Tye, who said she filed at least eight complaints with the Securities and Exchange Commission. And the allegations involve the difference between what Facebook knew privately about its platform and what it was saying publicly. Specifically, the complaints are focused on the prevalence of hate speech on Facebook, alleged misrepresentations about Facebook's role in the Capitol siege, how Facebook hid its own research that showed Instagram is toxic for teen girls' mental health. Lawyer Tye says misleading investors is a crime under U. S. securities law. JOHN TYE: You can't lie to your investors. You can't withhold important information that would help them decide whether to invest in the company. And we certainly allege that Facebook has done exactly that on a very wide scale, on a whole lot of different particular issues. MARTIN: What's Facebook saying about these allegations? ALLYN: Yeah, Rachel. You know, this document leak has created what's maybe the biggest crisis in the company's history. So the company is putting a lot of energy into pushing back. And it's saying, basically, that the representations are incorrect. Facebook cites 40,000 people who work on safety and security, and that the company says, you know, the whistleblower and the media are giving too much attention to what they call an incomplete look at its internal research. Should note here that Facebook is among NPR's financial supporters. MARTIN: So let's just explain what the whistleblower did here - right? - taking confidential documents from Facebook without permission, sharing them with law enforcement. Explain whether or not that is legal, Bobby. ALLYN: Sure. So the SEC does have a special whistleblower program that allows someone like Haugen to expose a company and be provided with a legal shield. Her disclosures to Congress are also protected. That said, Rachel, her leaking these documents to the media does put a target on her back. There are no legal safeguards for going to the press with confidential documents. She could be sued by Facebook for a breach of contract. Now, I asked Facebook whether they're considering that. And they wouldn't say, you know, whether they are or not. But it's definitely a possibility. And it's something we'll be keeping an eye on. MARTIN: NPR's Bobby Allyn reporting this morning. Thank you. ALLYN: Thank you, Rachel. RACHEL MARTIN, HOST:   A Facebook whistleblower says the social network puts profits over public safety. The former Facebook employee has handed over thousands of pages of internal Facebook documents to federal law enforcement. With more, NPR's Bobby Allyn joins us this morning. Hi, Bobby. BOBBY ALLYN, BYLINE: Good morning, Rachel. MARTIN: First off, who is this Facebook whistleblower? ALLYN: Her name is Frances Haugen. She's something of a specialist in how algorithms affect what we see on social media. She formerly worked at Google and Pinterest. During her two years at Facebook, though, she was on a team focused on figuring out how election-related misinformation spreads. But she became disillusioned. She felt like the team was understaffed, that Facebook wasn't taking seriously how its platform was affecting societies around the world. Then Facebook disbanded her team altogether. Weeks later, the Capitol riots happened. And she says Facebook underplayed how the platform was used to organize the riots. She was having a crisis of conscience. Here's how Haugen described it on CBS' \"60 Minutes. \" It aired Sunday. (SOUNDBITE OF TV SHOW, \"60 MINUTES\") FRANCES HAUGEN: The thing I saw at Facebook over and over again was there were conflicts of interest between what was good for the public and what was good for Facebook. And Facebook, over and over again, chose to optimize for its own interests, like making more money. MARTIN: Which is, frankly, the objective of any company - right? - to prioritize profits. But is she saying Facebook broke the law in this? ALLYN: Yeah. Yeah. She is. So I talked to her lawyer, John Tye, who said she filed at least eight complaints with the Securities and Exchange Commission. And the allegations involve the difference between what Facebook knew privately about its platform and what it was saying publicly. Specifically, the complaints are focused on the prevalence of hate speech on Facebook, alleged misrepresentations about Facebook's role in the Capitol siege, how Facebook hid its own research that showed Instagram is toxic for teen girls' mental health. Lawyer Tye says misleading investors is a crime under U. S. securities law. JOHN TYE: You can't lie to your investors. You can't withhold important information that would help them decide whether to invest in the company. And we certainly allege that Facebook has done exactly that on a very wide scale, on a whole lot of different particular issues. MARTIN: What's Facebook saying about these allegations? ALLYN: Yeah, Rachel. You know, this document leak has created what's maybe the biggest crisis in the company's history. So the company is putting a lot of energy into pushing back. And it's saying, basically, that the representations are incorrect. Facebook cites 40,000 people who work on safety and security, and that the company says, you know, the whistleblower and the media are giving too much attention to what they call an incomplete look at its internal research. Should note here that Facebook is among NPR's financial supporters. MARTIN: So let's just explain what the whistleblower did here - right? - taking confidential documents from Facebook without permission, sharing them with law enforcement. Explain whether or not that is legal, Bobby. ALLYN: Sure. So the SEC does have a special whistleblower program that allows someone like Haugen to expose a company and be provided with a legal shield. Her disclosures to Congress are also protected. That said, Rachel, her leaking these documents to the media does put a target on her back. There are no legal safeguards for going to the press with confidential documents. She could be sued by Facebook for a breach of contract. Now, I asked Facebook whether they're considering that. And they wouldn't say, you know, whether they are or not. But it's definitely a possibility. And it's something we'll be keeping an eye on. MARTIN: NPR's Bobby Allyn reporting this morning. Thank you. ALLYN: Thank you, Rachel.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-10-05-1043377310": {"title": "4 takeaways from Facebook whistleblower Frances Haugen's testimony : NPR", "url": "https://www.npr.org/2021/10/05/1043377310/facebook-whistleblower-frances-haugen-congress", "author": "No author found", "published_date": "2021-10-05", "content": "", "section": "Technology", "disclaimer": ""}, "2021-10-05-1043194385": {"title": "Whistleblower's testimony has resurfaced Facebook's Instagram problem  : NPR", "url": "https://www.npr.org/2021/10/05/1043194385/whistleblowers-testimony-facebook-instagram", "author": "No author found", "published_date": "2021-10-05", "content": "", "section": "Technology", "disclaimer": ""}, "2021-10-05-1043458047": {"title": "Facebook whistleblower testifies before a Senate panel : NPR", "url": "https://www.npr.org/2021/10/05/1043458047/facebook-whistleblower-testifies-before-a-senate-panel", "author": "No author found", "published_date": "2021-10-05", "content": "AILSA CHANG, HOST:  Addictive, disastrous, putting profits before people - these are words that a former Facebook employee used today in testimony before Congress about the social media company. (SOUNDBITE OF ARCHIVED RECORDING)FRANCES HAUGEN: Facebook knows that when they pick out the content that we focus on using computers, we spend more time on their platform; they make more money. CHANG: Former Facebook product manager Frances Haugen alleges that the company knows its platforms can hurt younger users especially, but does little about it. (SOUNDBITE OF ARCHIVED RECORDING)HAUGEN: They shouldn't get a free pass on that because they're paying for their profits right now with our safety. CHANG: We should note that Facebook is among NPR's financial supporters. And NPR's Shannon Bond covers the company. She joins us now. Hi, Shannon. SHANNON BOND, BYLINE: Hi, Ailsa. CHANG: So Haugen has been known for several weeks now as the Facebook whistleblower - right? - because she leaked thousands of pages of documents. Can you just quickly catch us up on how we even got to this moment today, why she ended up getting called by lawmakers to testify? BOND: That's right. I mean, she - as you said, she leaked tens of thousands of pages of internal documents to the press, to Congress, to the SEC. And those - they detailed, among other things, how Instagram makes eating disorders, depression and other problems worse for some teenagers - lots of other problems, too. And so she came to Congress as a former Facebook insider who could offer real insight into how the company works, armed with its own research. And she painted a picture of a company that, as she puts it, puts profit and growth ahead of safety. CHANG: And what was the reaction today from lawmakers to all of this? Like, how did they respond to her testimony? BOND: Yeah, I mean, one called her an American hero. They said they would try to protect her from any retaliation by Facebook. This was a very receptive audience. I mean, just for an example, there was an exchange about Instagram. Now, Haugen's documents have already led to, actually, a major concession from Facebook. It said it would pause work on a version of Instagram for 10- to 12-year-olds. But Haugen told Democrat Brian Schatz of Hawaii that she'd actually be shocked if Facebook entirely stopped working on the project. (SOUNDBITE OF ARCHIVED RECORDING)HAUGEN: Facebook understands that if they want to continue to grow, they have to find new users. They have to make sure that the next generation is just as engaged with Instagram as the current one. And the way they'll do that is by making sure that children establish habits before they have good self-regulation. BRIAN SCHATZ: By hooking kids. HAUGEN: By hooking kids. BOND: And there was bipartisan praise for Haugen. And, you know, that's pretty rare these days, Ailsa. CHANG: Right. Well, I mean, it does sound like Democrats and Republicans are pretty united about the problems, but what are they proposing to do about the problems? And are they united on those possible solutions? BOND: Well, Haugen pleaded with Congress to regulate Facebook. She says it's clear it's not going to change on its own. She compared it to big tobacco and says, you know, it's time for the government to step in with regulation. And so today we did hear calls from both sides of the aisle for tightening privacy protections for kids online, changing a law that shields tech companies from liability for much of what's posted on their platform. And there are bills, both from Republicans and Democrats, on the table right now in Congress. The question is - is this the moment that finally spurs action? CHANG: Right. Is this the moment? BOND: Right. CHANG: OK. That's what lawmakers are saying, but what have we heard so far from Facebook? BOND: Well, Facebook says it doesn't agree with Haugen characterizations. It denies it puts profit over safety. And just after the hearing, a Facebook executive accused her of stealing these documents. The company has tried to cast doubt on her. It says she was only there for less than two years. She wasn't in the room where executives made decisions. She didn't work on some of these topics, like Instagram and child safety. Senator Marsha Blackburn actually called out a Facebook spokesman who was tweeting about Haugen. (SOUNDBITE OF ARCHIVED RECORDING)MARSHA BLACKBURN: If Facebook wants to discuss their targeting of children, if they want to discuss their practices of privacy invasion or violations of the Children Online Privacy Act, I am extending to you an invitation to step forward, be sworn in and testify before this committee. BOND: And I think it's a real indication lawmakers are not going to stop here. You know, they are already now putting pressure on CEO Mark Zuckerberg to appear before Congress. After the hearing, Senator Richard Blumenthal told reporters there are a lot of questions that he wants Zuckerberg to come and answer. CHANG: That is NPR's Shannon Bond. Thank you, Shannon. BOND: Thanks, Ailsa. AILSA CHANG, HOST:   Addictive, disastrous, putting profits before people - these are words that a former Facebook employee used today in testimony before Congress about the social media company. (SOUNDBITE OF ARCHIVED RECORDING) FRANCES HAUGEN: Facebook knows that when they pick out the content that we focus on using computers, we spend more time on their platform; they make more money. CHANG: Former Facebook product manager Frances Haugen alleges that the company knows its platforms can hurt younger users especially, but does little about it. (SOUNDBITE OF ARCHIVED RECORDING) HAUGEN: They shouldn't get a free pass on that because they're paying for their profits right now with our safety. CHANG: We should note that Facebook is among NPR's financial supporters. And NPR's Shannon Bond covers the company. She joins us now. Hi, Shannon. SHANNON BOND, BYLINE: Hi, Ailsa. CHANG: So Haugen has been known for several weeks now as the Facebook whistleblower - right? - because she leaked thousands of pages of documents. Can you just quickly catch us up on how we even got to this moment today, why she ended up getting called by lawmakers to testify? BOND: That's right. I mean, she - as you said, she leaked tens of thousands of pages of internal documents to the press, to Congress, to the SEC. And those - they detailed, among other things, how Instagram makes eating disorders, depression and other problems worse for some teenagers - lots of other problems, too. And so she came to Congress as a former Facebook insider who could offer real insight into how the company works, armed with its own research. And she painted a picture of a company that, as she puts it, puts profit and growth ahead of safety. CHANG: And what was the reaction today from lawmakers to all of this? Like, how did they respond to her testimony? BOND: Yeah, I mean, one called her an American hero. They said they would try to protect her from any retaliation by Facebook. This was a very receptive audience. I mean, just for an example, there was an exchange about Instagram. Now, Haugen's documents have already led to, actually, a major concession from Facebook. It said it would pause work on a version of Instagram for 10- to 12-year-olds. But Haugen told Democrat Brian Schatz of Hawaii that she'd actually be shocked if Facebook entirely stopped working on the project. (SOUNDBITE OF ARCHIVED RECORDING) HAUGEN: Facebook understands that if they want to continue to grow, they have to find new users. They have to make sure that the next generation is just as engaged with Instagram as the current one. And the way they'll do that is by making sure that children establish habits before they have good self-regulation. BRIAN SCHATZ: By hooking kids. HAUGEN: By hooking kids. BOND: And there was bipartisan praise for Haugen. And, you know, that's pretty rare these days, Ailsa. CHANG: Right. Well, I mean, it does sound like Democrats and Republicans are pretty united about the problems, but what are they proposing to do about the problems? And are they united on those possible solutions? BOND: Well, Haugen pleaded with Congress to regulate Facebook. She says it's clear it's not going to change on its own. She compared it to big tobacco and says, you know, it's time for the government to step in with regulation. And so today we did hear calls from both sides of the aisle for tightening privacy protections for kids online, changing a law that shields tech companies from liability for much of what's posted on their platform. And there are bills, both from Republicans and Democrats, on the table right now in Congress. The question is - is this the moment that finally spurs action? CHANG: Right. Is this the moment? BOND: Right. CHANG: OK. That's what lawmakers are saying, but what have we heard so far from Facebook? BOND: Well, Facebook says it doesn't agree with Haugen characterizations. It denies it puts profit over safety. And just after the hearing, a Facebook executive accused her of stealing these documents. The company has tried to cast doubt on her. It says she was only there for less than two years. She wasn't in the room where executives made decisions. She didn't work on some of these topics, like Instagram and child safety. Senator Marsha Blackburn actually called out a Facebook spokesman who was tweeting about Haugen. (SOUNDBITE OF ARCHIVED RECORDING) MARSHA BLACKBURN: If Facebook wants to discuss their targeting of children, if they want to discuss their practices of privacy invasion or violations of the Children Online Privacy Act, I am extending to you an invitation to step forward, be sworn in and testify before this committee. BOND: And I think it's a real indication lawmakers are not going to stop here. You know, they are already now putting pressure on CEO Mark Zuckerberg to appear before Congress. After the hearing, Senator Richard Blumenthal told reporters there are a lot of questions that he wants Zuckerberg to come and answer. CHANG: That is NPR's Shannon Bond. Thank you, Shannon. BOND: Thanks, Ailsa.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-10-05-1043211171": {"title": "Why Facebook and Instagram went down for hours yesterday : NPR", "url": "https://www.npr.org/2021/10/05/1043211171/facebook-instagram-whatsapp-outage-business-impact", "author": "No author found", "published_date": "2021-10-05", "content": "", "section": "Technology", "disclaimer": ""}, "2021-10-05-1043294896": {"title": "Facebook whistleblower Frances Haugen will testify before the Senate today : NPR", "url": "https://www.npr.org/2021/10/05/1043294896/facebook-whistleblower-frances-haugen-will-testify-before-the-senate-today", "author": "No author found", "published_date": "2021-10-05", "content": "STEVE INSKEEP, HOST:  OK, the Facebook whistleblower, Francis Haugen, is right now testifying before a Senate subcommittee? A little bit earlier this morning, we spoke with Senator Richard Blumenthal, who is the chair of that subcommittee. And we asked what he made of Facebook's defense. RICHARD BLUMENTHAL: You know, I'm tempted to do as I often did with a jury and say come back to Facebook's own words, the documents that tell its own story, the research it did, and the surveys that show it is polarizing, its algorithms have a divisive effect on people who use it, and the algorithms maximize that effect because it increases the number of users, which in turn maximizes profit. So it's a business model that Mark Zuckerberg has implemented very effectively and efficiently. He's the one who's making decisions here, with all due respect to others who may be spokesmen for the company. And he is the one who really should be looking in the mirror or more likely facing the public, coming to Congress and acknowledging the effect that Facebook is having. But their new policy, as has been reported, is no apologies, no acknowledgement and full speed ahead. INSKEEP: I'm glad that you used the phrase looking in the mirror, because today you're going to ask about other leaked documents about Instagram, which is controlled by Facebook. There was a study, an internal study, that showed some people looked in the mirror and felt worse about themselves after staring at glamorous images on Instagram. And the study went on to say it's worse in this way in - on Instagram than other platforms. Let's listen to a little bit of Monika Bickert's response to that. (SOUNDBITE OF ARCHIVED RECORDING)MONIKA BICKERT: Anybody who thinks that we are prioritizing profits over safety should be asking themselves, why would we do research like this? The only reason is so that we can understand and do better. INSKEEP: She said it's good they're doing this research and finding out these things. Do you see evidence, Senator, that Facebook is following up? BLUMENTHAL: Facebook sought to conceal, absolutely hide the results of this research. It still is refusing to disclose it. The only reason we have it is because a whistleblower stepped forward bravely and courageously to speak truth to one of the most powerful, implacable corporate giants in the world that embarked on a policy of cover-up. So the research shows that Facebook not only made money from causing harm to children. It continued to do it after it learned of the harm, and it put its profit ahead of the pain it caused to people whose self-image, negative feelings about themselves, even suicidal tendencies were the result of these accounts on eating disorders, online bullying, self-injury, even suicide. And that is a searing indictment from their own words, their own research. And parents have written to me with heartbreaking stories, spine-chilling accounts of children who were pushed into eating disorders and bullied into threatening or even taking their own lives because of the algorithms pushing them to these recommended accounts. INSKEEP: Senator, in just a few seconds here, Monika Bickert did say, we can't solve this problem alone. We welcome regulation. Do you plan to deliver regulation? BLUMENTHAL: We will make every effort to pass a privacy bill, a bill that gives more tools to parents to protect their children, a bill that imposes legal accountability on Facebook and other tech platforms for the harm they cause and a bill also that enforces a larger social responsibility on companies that seem very much to fail to acknowledge that responsibility. INSKEEP: Senator Richard Blumenthal of Connecticut, thanks so much. BLUMENTHAL: Thank you. STEVE INSKEEP, HOST:   OK, the Facebook whistleblower, Francis Haugen, is right now testifying before a Senate subcommittee? A little bit earlier this morning, we spoke with Senator Richard Blumenthal, who is the chair of that subcommittee. And we asked what he made of Facebook's defense. RICHARD BLUMENTHAL: You know, I'm tempted to do as I often did with a jury and say come back to Facebook's own words, the documents that tell its own story, the research it did, and the surveys that show it is polarizing, its algorithms have a divisive effect on people who use it, and the algorithms maximize that effect because it increases the number of users, which in turn maximizes profit. So it's a business model that Mark Zuckerberg has implemented very effectively and efficiently. He's the one who's making decisions here, with all due respect to others who may be spokesmen for the company. And he is the one who really should be looking in the mirror or more likely facing the public, coming to Congress and acknowledging the effect that Facebook is having. But their new policy, as has been reported, is no apologies, no acknowledgement and full speed ahead. INSKEEP: I'm glad that you used the phrase looking in the mirror, because today you're going to ask about other leaked documents about Instagram, which is controlled by Facebook. There was a study, an internal study, that showed some people looked in the mirror and felt worse about themselves after staring at glamorous images on Instagram. And the study went on to say it's worse in this way in - on Instagram than other platforms. Let's listen to a little bit of Monika Bickert's response to that. (SOUNDBITE OF ARCHIVED RECORDING) MONIKA BICKERT: Anybody who thinks that we are prioritizing profits over safety should be asking themselves, why would we do research like this? The only reason is so that we can understand and do better. INSKEEP: She said it's good they're doing this research and finding out these things. Do you see evidence, Senator, that Facebook is following up? BLUMENTHAL: Facebook sought to conceal, absolutely hide the results of this research. It still is refusing to disclose it. The only reason we have it is because a whistleblower stepped forward bravely and courageously to speak truth to one of the most powerful, implacable corporate giants in the world that embarked on a policy of cover-up. So the research shows that Facebook not only made money from causing harm to children. It continued to do it after it learned of the harm, and it put its profit ahead of the pain it caused to people whose self-image, negative feelings about themselves, even suicidal tendencies were the result of these accounts on eating disorders, online bullying, self-injury, even suicide. And that is a searing indictment from their own words, their own research. And parents have written to me with heartbreaking stories, spine-chilling accounts of children who were pushed into eating disorders and bullied into threatening or even taking their own lives because of the algorithms pushing them to these recommended accounts. INSKEEP: Senator, in just a few seconds here, Monika Bickert did say, we can't solve this problem alone. We welcome regulation. Do you plan to deliver regulation? BLUMENTHAL: We will make every effort to pass a privacy bill, a bill that gives more tools to parents to protect their children, a bill that imposes legal accountability on Facebook and other tech platforms for the harm they cause and a bill also that enforces a larger social responsibility on companies that seem very much to fail to acknowledge that responsibility. INSKEEP: Senator Richard Blumenthal of Connecticut, thanks so much. BLUMENTHAL: Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-10-05-1043294730": {"title": "Facebook pushes back on whistleblower claims it's endangering users : NPR", "url": "https://www.npr.org/2021/10/05/1043294730/facebook-pushes-back-on-whistleblower-claims-its-endangering-users", "author": "No author found", "published_date": "2021-10-05", "content": "STEVE INSKEEP, HOST:  How does Facebook defend itself against revelations from inside the company? A former employee is testifying before a Senate committee today. Frances Haugen left the company with documents in hand. We have reported how those documents reflected the concerns of Facebook employees. They questioned whether their company was doing enough to stop the spread of extremism or misinformation, among other things. Facebook is an NPR sponsor, which we cover like any other company, and we begin our coverage this morning with Monika Bickert, the company's vice president of content policy. MONIKA BICKERT: The documents that were taken by this employee and the way that they're being portrayed, it just is not an accurate representation of the work that this company does every day to ensure safety on our sites. INSKEEP: Let me ask about election information or misinformation - political conversations. Frances Haugen spoke to this on \"60 Minutes,\" and let's listen to a little bit of what she had to say. (SOUNDBITE OF TV SHOW, \"60 MINUTES\")FRANCES HAUGEN: But its own research is showing that content that is hateful, that is divisive, that is polarizing - it's easier to inspire people to anger than it is to other emotions. INSKEEP: Monika Bickert, do you face a fundamental business problem, or moral problem, really? Facebook is built on encouraging more interactions, and it's easier to encourage interactions when you give people content that makes them angry. BICKERT: Our business interest is in making sure that people have a good experience so that they want to stay with these sites and use them over the long term. And in fact, when we changed our News Feed algorithm in January of 2018, we expected that engagement would go down, and we knew we would take a hit, and that all happened. And that's because what we were doing was promoting meaningful social interactions. That means content from family and friends that is likely to help people have conversations about things that are important to them rather than prioritizing public content. INSKEEP: I want to grant some of the efforts that you've just highlighted there, but we have some of the quotes now from some of these internal memos suggesting that something else was happening after that change of the algorithm in 2018. The Wall Street Journal quotes an internal memo saying, \"misinformation, toxicity and violent content are inordinately prevalent among reshares. \" We have, in 2019, political party in Poland saying that they discovered, after the change in the algorithm, they had to share more negative content in order to get engagement. In April 2020, there was an internal memo about a presentation to Mark Zuckerberg about proposals to address this problem, and Zuckerberg seems to resist this because it would damage meaningful social interactions. In other words, he is concerned about cutting down traffic on the site. What is going on there? BICKERT: Well, let me also remind you that anecdotes about, you know, people being concerned about how their posts are getting engagement or not getting engagement - those are certainly things to look into. That's not the same thing as a deliberate move to prioritize, you know, engagement bait. In fact, we do the opposite. And if you have any doubt about whether or not we would prioritize engagement or profits over safety, look at what we did with political ads around the 2020 election. We paused all ads on political or social issues before the election, even though we got criticism about it, because, of course, people wanted to be able to advertise on those issues. We kept that pause in place through March. So we were directly sacrificing revenue and getting complaints about it. We were doing that because we wanted to err on the side of safety. INSKEEP: I would grant you that people complained about your ad policy, but this April 2020 memo appears to show Mark Zuckerberg himself weighing an additional safety measure and saying, I don't want to do this if it costs us too many interactions. BICKERT: Meaningful social interactions was about prioritizing family and friends' conversations, so those interactions are interactions that the research tells us are good for well-being. INSKEEP: Frances Haugen argues ultimately that Facebook is making dangerous trade-offs between speech and your business and safety. Would you agree that that is the trade-off you have to make in order to stay in business in a free society? BICKERT: Even the nature of social media itself requires balancing issues like freedom of expression, an important value, with other values like privacy, like safety. Those are all issues that we take very seriously and, frankly, that we think shouldn't be ours to decide alone. And that's why, for more than 2 1/2 years, we have been asking governments to play a role by passing regulation. And we're happy to be a part of that effort, but we think that it needs to happen. INSKEEP: Your company, Facebook, is without a doubt the largest medium for public discourse in the world. Facebook is not the whole public discourse. It's not the only thing influencing public discourse. But you're huge, and you have been huge for more than 15 years. Would you argue that public discourse is better now than it was 15 years ago? BICKERT: It depends on what you mean by public discourse, Steve. I mean, on a number of issues, I think the ability of people to reach out online - you know, we see this especially with people who are dealing with health issues or other wellness issues - to be able to get support can be just so meaningful. On political issues, polarization in the United States has been on a steady increase since the late '70s or early '80s, and that's decades before social media, so very important to keep that in mind. The other thing to keep in mind is that, in other Western democracies that have as high of social media usage rates and Facebook rates as the United States, we see polarization declining. So as tempting as it may be to want to blame social media or Facebook for issues like polarization, I think we as a society have to look deeper if we want to solve those issues. INSKEEP: Do you worry that, on some level, for some people, Facebook may be like a bartender who says, you're drinking too much, have another drink? BICKERT: I actually think we do a very good job of trying to make the experience good for people but also being mindful of the wellness concerns. We are being thoughtful about these issues and doing the best we can to give people a healthy and positive experience, and we'll keep doing that. INSKEEP: Monika Bickert, thanks for taking the questions. BICKERT: Thanks very much, Steve. STEVE INSKEEP, HOST:   How does Facebook defend itself against revelations from inside the company? A former employee is testifying before a Senate committee today. Frances Haugen left the company with documents in hand. We have reported how those documents reflected the concerns of Facebook employees. They questioned whether their company was doing enough to stop the spread of extremism or misinformation, among other things. Facebook is an NPR sponsor, which we cover like any other company, and we begin our coverage this morning with Monika Bickert, the company's vice president of content policy. MONIKA BICKERT: The documents that were taken by this employee and the way that they're being portrayed, it just is not an accurate representation of the work that this company does every day to ensure safety on our sites. INSKEEP: Let me ask about election information or misinformation - political conversations. Frances Haugen spoke to this on \"60 Minutes,\" and let's listen to a little bit of what she had to say. (SOUNDBITE OF TV SHOW, \"60 MINUTES\") FRANCES HAUGEN: But its own research is showing that content that is hateful, that is divisive, that is polarizing - it's easier to inspire people to anger than it is to other emotions. INSKEEP: Monika Bickert, do you face a fundamental business problem, or moral problem, really? Facebook is built on encouraging more interactions, and it's easier to encourage interactions when you give people content that makes them angry. BICKERT: Our business interest is in making sure that people have a good experience so that they want to stay with these sites and use them over the long term. And in fact, when we changed our News Feed algorithm in January of 2018, we expected that engagement would go down, and we knew we would take a hit, and that all happened. And that's because what we were doing was promoting meaningful social interactions. That means content from family and friends that is likely to help people have conversations about things that are important to them rather than prioritizing public content. INSKEEP: I want to grant some of the efforts that you've just highlighted there, but we have some of the quotes now from some of these internal memos suggesting that something else was happening after that change of the algorithm in 2018. The Wall Street Journal quotes an internal memo saying, \"misinformation, toxicity and violent content are inordinately prevalent among reshares. \" We have, in 2019, political party in Poland saying that they discovered, after the change in the algorithm, they had to share more negative content in order to get engagement. In April 2020, there was an internal memo about a presentation to Mark Zuckerberg about proposals to address this problem, and Zuckerberg seems to resist this because it would damage meaningful social interactions. In other words, he is concerned about cutting down traffic on the site. What is going on there? BICKERT: Well, let me also remind you that anecdotes about, you know, people being concerned about how their posts are getting engagement or not getting engagement - those are certainly things to look into. That's not the same thing as a deliberate move to prioritize, you know, engagement bait. In fact, we do the opposite. And if you have any doubt about whether or not we would prioritize engagement or profits over safety, look at what we did with political ads around the 2020 election. We paused all ads on political or social issues before the election, even though we got criticism about it, because, of course, people wanted to be able to advertise on those issues. We kept that pause in place through March. So we were directly sacrificing revenue and getting complaints about it. We were doing that because we wanted to err on the side of safety. INSKEEP: I would grant you that people complained about your ad policy, but this April 2020 memo appears to show Mark Zuckerberg himself weighing an additional safety measure and saying, I don't want to do this if it costs us too many interactions. BICKERT: Meaningful social interactions was about prioritizing family and friends' conversations, so those interactions are interactions that the research tells us are good for well-being. INSKEEP: Frances Haugen argues ultimately that Facebook is making dangerous trade-offs between speech and your business and safety. Would you agree that that is the trade-off you have to make in order to stay in business in a free society? BICKERT: Even the nature of social media itself requires balancing issues like freedom of expression, an important value, with other values like privacy, like safety. Those are all issues that we take very seriously and, frankly, that we think shouldn't be ours to decide alone. And that's why, for more than 2 1/2 years, we have been asking governments to play a role by passing regulation. And we're happy to be a part of that effort, but we think that it needs to happen. INSKEEP: Your company, Facebook, is without a doubt the largest medium for public discourse in the world. Facebook is not the whole public discourse. It's not the only thing influencing public discourse. But you're huge, and you have been huge for more than 15 years. Would you argue that public discourse is better now than it was 15 years ago? BICKERT: It depends on what you mean by public discourse, Steve. I mean, on a number of issues, I think the ability of people to reach out online - you know, we see this especially with people who are dealing with health issues or other wellness issues - to be able to get support can be just so meaningful. On political issues, polarization in the United States has been on a steady increase since the late '70s or early '80s, and that's decades before social media, so very important to keep that in mind. The other thing to keep in mind is that, in other Western democracies that have as high of social media usage rates and Facebook rates as the United States, we see polarization declining. So as tempting as it may be to want to blame social media or Facebook for issues like polarization, I think we as a society have to look deeper if we want to solve those issues. INSKEEP: Do you worry that, on some level, for some people, Facebook may be like a bartender who says, you're drinking too much, have another drink? BICKERT: I actually think we do a very good job of trying to make the experience good for people but also being mindful of the wellness concerns. We are being thoughtful about these issues and doing the best we can to give people a healthy and positive experience, and we'll keep doing that. INSKEEP: Monika Bickert, thanks for taking the questions. BICKERT: Thanks very much, Steve.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-10-05-1043207218": {"title": "Facebook whistleblower tells Congress products hurt kids and weaken democracy : NPR", "url": "https://www.npr.org/2021/10/05/1043207218/whistleblower-to-congress-facebook-products-harm-children-and-weaken-democracy", "author": "No author found", "published_date": "2021-10-05", "content": "", "section": "Technology", "disclaimer": ""}, "2021-10-05-1043017903": {"title": "Snapchat adds 'Run for Office' feature to help potential candidates : NPR", "url": "https://www.npr.org/2021/10/05/1043017903/snapchat-is-adding-a-feature-to-help-young-users-run-for-political-office", "author": "No author found", "published_date": "2021-10-05", "content": "RACHEL MARTIN, HOST:  Young voters did a lot of voting in last year's election, with a record 53% of 18- to 29-year-olds casting ballots. Now one of the giants in social media is encouraging these young voters to get into the game themselves as candidates. Here's NPR's Juana Summers. JUANA SUMMERS, BYLINE: If you've used Snapchat, you might think it's just an app to share photos that quickly disappear. SOFIA GROSS: And whenever I'm explaining this to, you know, my grandfather, I really help him understand that instead of telling you where I am or what I'm up to, it's sending a photo or a video to someone close to you to really help them feel like they are with you in that moment, experiencing whatever it is that you're experiencing. SUMMERS: That's Sofia Gross. She works for Snapchat's parent company, Snap. The company is making a major push to have a more lasting impact on Snapchat's passionate, largely young user base. It's encouraging them to consider running for local offices. GROSS: So Snapchatters can come to the app to learn more about this initiative by simply typing in run for office. SUMMERS: It starts off with one piece of information - where a user lives. GROSS: We're going to look for opportunities in the ZIP code 65201. SUMMERS: By way of explanation, Gross picked that ZIP code because it's where I went to college in Missouri. After a user enters a ZIP code, they're presented with a whole list of different issues - things like the environment, education, jobs. The idea is that they pick a couple areas that matter to them, and that helps populate a list of elected positions. Gross tapped on one of them. GROSS: This will then bring you to a position profile so you can learn more about what this job actually entails, whether or not it's for you. You might take a look at this position and say, oh, that's super interesting. Local school board is in line with my background and my interests. And you may decide to run. SUMMERS: Snap partnered with BallotReady to provide users with information about the offices they could run for. They can learn things like who currently holds the office or what's required to run. Once a user indicates that they want to take the plunge and run for an office, the app provides an option to connect with some partner organizations for a little guidance. A'shanti Gholar is the executive director of Emerge, a group focused on recruiting Democratic women candidates. A'SHANTI GHOLAR: One of the things that I love about the youngest generation of voters, especially when it comes to running for office, being politically engaged, making their voices heard, is that they're not asking for permission, that they are just doing it. And those are the people of the Snapchat generation. SUMMERS: That generation is pretty young. Officials from the company say the app reaches 90% of people in the U. S. between the ages of 13 and 24 - 90% - a lot of them too young to run for office right now, or even vote. All of this, of course, raises some obvious questions about privacy. Snap says its candidate recruitment partners receive limited, self-submitted information from users, including their first and last name, email address and ZIP code. No other data is shared. Candidate recruitment organizations see a lot of opportunity in this partnership. One of the elected officials that Snap consulted with is Iowa State Rep. Joe Mitchell. He's a Republican who was first elected to office at age 21, and he's a co-founder of Run GenZ. JOE MITCHELL: There's so many people like myself and like my co-founders that are out there that just need a little nudge, need a little encouragement. SUMMERS: Mitchell uses Snapchat every day and says it makes a lot of sense as a place to reach more young conservatives. MITCHELL: What I think is important about it, though, is that, No. 1, the age demographic, but then No. 2, it's going to be tailored and catered towards, you know, algorithms which can send folks that are interested in, you know, Ben Shapiro or some of these other conservative organizations on Snapchat our way. SUMMERS: Snap says that once a potential candidate selects a group as a partner and provides their contact information, the goal is to get them connected outside of the app within a matter of days. Users and potential candidates will also see a digital version of a familiar campaign tool - campaign stickers. GROSS: So if you tap one of these stickers, we can then take a photo and send it to close friends, letting them know that you're running for office. So that way you can get out the vote on Snapchat. SUMMERS: The hope is that this generation of Americans will see running for office as a way to get involved in their communities the same way they voted at historic levels last year. Juana Summers, NPR News. RACHEL MARTIN, HOST:   Young voters did a lot of voting in last year's election, with a record 53% of 18- to 29-year-olds casting ballots. Now one of the giants in social media is encouraging these young voters to get into the game themselves as candidates. Here's NPR's Juana Summers. JUANA SUMMERS, BYLINE: If you've used Snapchat, you might think it's just an app to share photos that quickly disappear. SOFIA GROSS: And whenever I'm explaining this to, you know, my grandfather, I really help him understand that instead of telling you where I am or what I'm up to, it's sending a photo or a video to someone close to you to really help them feel like they are with you in that moment, experiencing whatever it is that you're experiencing. SUMMERS: That's Sofia Gross. She works for Snapchat's parent company, Snap. The company is making a major push to have a more lasting impact on Snapchat's passionate, largely young user base. It's encouraging them to consider running for local offices. GROSS: So Snapchatters can come to the app to learn more about this initiative by simply typing in run for office. SUMMERS: It starts off with one piece of information - where a user lives. GROSS: We're going to look for opportunities in the ZIP code 65201. SUMMERS: By way of explanation, Gross picked that ZIP code because it's where I went to college in Missouri. After a user enters a ZIP code, they're presented with a whole list of different issues - things like the environment, education, jobs. The idea is that they pick a couple areas that matter to them, and that helps populate a list of elected positions. Gross tapped on one of them. GROSS: This will then bring you to a position profile so you can learn more about what this job actually entails, whether or not it's for you. You might take a look at this position and say, oh, that's super interesting. Local school board is in line with my background and my interests. And you may decide to run. SUMMERS: Snap partnered with BallotReady to provide users with information about the offices they could run for. They can learn things like who currently holds the office or what's required to run. Once a user indicates that they want to take the plunge and run for an office, the app provides an option to connect with some partner organizations for a little guidance. A'shanti Gholar is the executive director of Emerge, a group focused on recruiting Democratic women candidates. A'SHANTI GHOLAR: One of the things that I love about the youngest generation of voters, especially when it comes to running for office, being politically engaged, making their voices heard, is that they're not asking for permission, that they are just doing it. And those are the people of the Snapchat generation. SUMMERS: That generation is pretty young. Officials from the company say the app reaches 90% of people in the U. S. between the ages of 13 and 24 - 90% - a lot of them too young to run for office right now, or even vote. All of this, of course, raises some obvious questions about privacy. Snap says its candidate recruitment partners receive limited, self-submitted information from users, including their first and last name, email address and ZIP code. No other data is shared. Candidate recruitment organizations see a lot of opportunity in this partnership. One of the elected officials that Snap consulted with is Iowa State Rep. Joe Mitchell. He's a Republican who was first elected to office at age 21, and he's a co-founder of Run GenZ. JOE MITCHELL: There's so many people like myself and like my co-founders that are out there that just need a little nudge, need a little encouragement. SUMMERS: Mitchell uses Snapchat every day and says it makes a lot of sense as a place to reach more young conservatives. MITCHELL: What I think is important about it, though, is that, No. 1, the age demographic, but then No. 2, it's going to be tailored and catered towards, you know, algorithms which can send folks that are interested in, you know, Ben Shapiro or some of these other conservative organizations on Snapchat our way. SUMMERS: Snap says that once a potential candidate selects a group as a partner and provides their contact information, the goal is to get them connected outside of the app within a matter of days. Users and potential candidates will also see a digital version of a familiar campaign tool - campaign stickers. GROSS: So if you tap one of these stickers, we can then take a photo and send it to close friends, letting them know that you're running for office. So that way you can get out the vote on Snapchat. SUMMERS: The hope is that this generation of Americans will see running for office as a way to get involved in their communities the same way they voted at historic levels last year. Juana Summers, NPR News.", "section": "Politics", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-10-06-1043803529": {"title": "Google Flights will show carbon emissions in flight results : NPR", "url": "https://www.npr.org/2021/10/06/1043803529/google-flights-carbon-emissions-air-travel", "author": "No author found", "published_date": "2021-10-06", "content": "", "section": "Climate", "disclaimer": ""}, "2021-10-06-1043788263": {"title": "More than social media: The WhatsApp outage affected small businesses worldwide : NPR", "url": "https://www.npr.org/2021/10/06/1043788263/more-than-social-media-the-whatsapp-outage-affected-small-businesses-worldwide", "author": "No author found", "published_date": "2021-10-06", "content": "AUDIE CORNISH, HOST:  When WhatsApp and other apps owned by Facebook went down earlier this week, tens of millions of people worldwide struggled to communicate and many to run their businesses. Lydia Mutune Osewe owns a plant shop in Nairobi, Kenya, and it's entirely on Facebook, WhatsApp and Instagram. And she says clients couldn't reach them. LYDIA MUTUNE OSEWE: They couldn't place their orders. We couldn't even do our deliveries because most of our deliveries, we rely on the information they sent to WhatsApp. For example, they have to drop their pin to their location on WhatsApp numbers, but we were not getting all this information. CORNISH: In Tanzania, the spokesperson for the government took to another social media app, Twitter, to urge people to be patient. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED PERSON: (Non-English language spoken). CORNISH: He assured people that government services would remain available through other channels - Twitter, email, YouTube - and that the outage would eventually come to an end, which it did about six hours later. We spoke about what happened with Ayman El Tarabishy. He's a professor at George Washington School of Business and heads the International Council for Small Businesses. Welcome to the program. AYMAN EL TARABISHY: Thank you. Thank you. Nice to be here. CORNISH: I'm not sure people totally appreciate just the parts of the world where WhatsApp in particular or Instagram are a part of the way people actually do business on a local level. When the outage happened, what did you hear from some of your contacts around the world? Do you have an example? EL TARABISHY: Yes. Well, what I didn't hear - let's start with that - because when it went down, nobody knew it was down. And we just didn't know if it was the internet connection or the Wi-Fi. And that was one of the big problems. Nobody knew it was down. CORNISH: Can you give me two small stories that you've heard from business owners or people who really rely on these programs of what happened to them because of the outage? EL TARABISHY: Yes. So I'll give you an example here. One comes from Panama. In Panama, and they have rolled out this campaign where health providers can - using WhatsApp - can come to your house to do COVID testing. So imagine when it went down for the four or five hours or six hours it was down, everybody that was using WhatsApp to make their reservations, to confirm the reservation for people to come - right? - the whole system went down. The other example, when it came to deliveries of orders and stuff like that, where people are saying, I'm coming. I'm going to this delivery first, then this delivery and this delivery. When everything went down and you're talking to a different team members across - right? - everybody was confused as where everything was, basically. CORNISH: Did you hear from anyone who said, I lost a lot of money yesterday because X, or a lot of business? EL TARABISHY: Yeah. What I heard is, well, I didn't make any money today because everything was down. I didn't have my store. CORNISH: Just for a little bit of context, just how popular is WhatsApp, for example, as a tool for conducting business? And which parts of the world do you see it having kind of a central role? EL TARABISHY: Absolutely. So my area of focus is on small business and microbusinesses. It is extremely important and very popular with small businesses, microbusinesses and actually users of it in communication across the world. Statistics show it's very popular in India, Brazil, the United States and Russia, Mexico, Germany, Italy, you know, Latin American countries. It's extremely popular across the world for a platform to communicate - that's WhatsApp. In terms of Instagram and Facebook, that's more of ecommerce and business for small businesses and microbusinesses. CORNISH: What is it about microbusinesses, meaning various kind of small vendors - what is it about the way they do business that lends itself to this kind of use of social media? Because now everyone's sort of used to the idea of this. The pandemic put a lot of people into ecommerce. But for the parts of the world you're talking about, what role did it play? EL TARABISHY: It is extremely important. They are a utility that people use, like electricity, like, you know, rent and everything to do business. So these small businesses use these platforms as a utility, right? So therefore, if you take away a utility that's indispensable for their business, they don't do any more business. It stops right in there. CORNISH: That's Ayman El Tarabishy, a professor at George Washington School of Business. And we should note that Facebook is one of NPR's financial supporters. (SOUNDBITE OF MUSIC) AUDIE CORNISH, HOST:   When WhatsApp and other apps owned by Facebook went down earlier this week, tens of millions of people worldwide struggled to communicate and many to run their businesses. Lydia Mutune Osewe owns a plant shop in Nairobi, Kenya, and it's entirely on Facebook, WhatsApp and Instagram. And she says clients couldn't reach them. LYDIA MUTUNE OSEWE: They couldn't place their orders. We couldn't even do our deliveries because most of our deliveries, we rely on the information they sent to WhatsApp. For example, they have to drop their pin to their location on WhatsApp numbers, but we were not getting all this information. CORNISH: In Tanzania, the spokesperson for the government took to another social media app, Twitter, to urge people to be patient. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED PERSON: (Non-English language spoken). CORNISH: He assured people that government services would remain available through other channels - Twitter, email, YouTube - and that the outage would eventually come to an end, which it did about six hours later. We spoke about what happened with Ayman El Tarabishy. He's a professor at George Washington School of Business and heads the International Council for Small Businesses. Welcome to the program. AYMAN EL TARABISHY: Thank you. Thank you. Nice to be here. CORNISH: I'm not sure people totally appreciate just the parts of the world where WhatsApp in particular or Instagram are a part of the way people actually do business on a local level. When the outage happened, what did you hear from some of your contacts around the world? Do you have an example? EL TARABISHY: Yes. Well, what I didn't hear - let's start with that - because when it went down, nobody knew it was down. And we just didn't know if it was the internet connection or the Wi-Fi. And that was one of the big problems. Nobody knew it was down. CORNISH: Can you give me two small stories that you've heard from business owners or people who really rely on these programs of what happened to them because of the outage? EL TARABISHY: Yes. So I'll give you an example here. One comes from Panama. In Panama, and they have rolled out this campaign where health providers can - using WhatsApp - can come to your house to do COVID testing. So imagine when it went down for the four or five hours or six hours it was down, everybody that was using WhatsApp to make their reservations, to confirm the reservation for people to come - right? - the whole system went down. The other example, when it came to deliveries of orders and stuff like that, where people are saying, I'm coming. I'm going to this delivery first, then this delivery and this delivery. When everything went down and you're talking to a different team members across - right? - everybody was confused as where everything was, basically. CORNISH: Did you hear from anyone who said, I lost a lot of money yesterday because X, or a lot of business? EL TARABISHY: Yeah. What I heard is, well, I didn't make any money today because everything was down. I didn't have my store. CORNISH: Just for a little bit of context, just how popular is WhatsApp, for example, as a tool for conducting business? And which parts of the world do you see it having kind of a central role? EL TARABISHY: Absolutely. So my area of focus is on small business and microbusinesses. It is extremely important and very popular with small businesses, microbusinesses and actually users of it in communication across the world. Statistics show it's very popular in India, Brazil, the United States and Russia, Mexico, Germany, Italy, you know, Latin American countries. It's extremely popular across the world for a platform to communicate - that's WhatsApp. In terms of Instagram and Facebook, that's more of ecommerce and business for small businesses and microbusinesses. CORNISH: What is it about microbusinesses, meaning various kind of small vendors - what is it about the way they do business that lends itself to this kind of use of social media? Because now everyone's sort of used to the idea of this. The pandemic put a lot of people into ecommerce. But for the parts of the world you're talking about, what role did it play? EL TARABISHY: It is extremely important. They are a utility that people use, like electricity, like, you know, rent and everything to do business. So these small businesses use these platforms as a utility, right? So therefore, if you take away a utility that's indispensable for their business, they don't do any more business. It stops right in there. CORNISH: That's Ayman El Tarabishy, a professor at George Washington School of Business. And we should note that Facebook is one of NPR's financial supporters. (SOUNDBITE OF MUSIC)", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-10-06-1043735239": {"title": "It's unclear just how bad the Twitch data leak is : NPR", "url": "https://www.npr.org/2021/10/06/1043735239/twitch-data-breach-hack", "author": "No author found", "published_date": "2021-10-06", "content": "", "section": "Technology", "disclaimer": ""}, "2021-10-06-1043666017": {"title": "More than one in three rural Black southerners lack home internet access : NPR", "url": "https://www.npr.org/2021/10/06/1043666017/internet-access-rural-black-southerners-digital-infrastructure-divide", "author": "No author found", "published_date": "2021-10-06", "content": "", "section": "National", "disclaimer": ""}, "2021-10-06-1043138622": {"title": "The impact of Facebook and Instagram on teens isn't so clear : NPR", "url": "https://www.npr.org/2021/10/06/1043138622/facebook-instagram-teens-mental-health", "author": "No author found", "published_date": "2021-10-06", "content": "", "section": "Education", "disclaimer": ""}, "2021-10-06-1043600094": {"title": "Ex-Facebook employee Frances Haugen testifies before Senate panel : NPR", "url": "https://www.npr.org/2021/10/06/1043600094/ex-facebook-employee-frances-haugen-testifies-before-senate-panel", "author": "No author found", "published_date": "2021-10-06", "content": "STEVE INSKEEP, HOST:  How could action by Congress bring changes to Facebook? Former employee Frances Haugen told her story before a Senate committee yesterday. As we've heard all week, she left the company with documents showing Facebook's internal concerns about their products. (SOUNDBITE OF ARCHIVED RECORDING)FRANCES HAUGEN: The choices being made inside of Facebook are disastrous - for our children, for our public safety, for our privacy and for our democracy. And that is why we must demand Facebook make changes. INSKEEP: Now, Facebook has rejected that portrayal. But this week on NPR, we have heard a U. S. senator talk of regulating the company and a Facebook executive saying they would welcome regulation. NPR's Shannon Bond covers Facebook, which is - we should disclose - among NPR's financial supporters. We cover them like any other company. And so Shannon is here. Good morning. SHANNON BOND, BYLINE: Good morning, Steve. INSKEEP: What is the basic problem as Haugen sees it? BOND: Well, she says Facebook consistently makes choices in the pursuit of growth, even when that risks harming its own users. (SOUNDBITE OF ARCHIVED RECORDING)HAUGEN: It is about Facebook choosing to grow at all costs, becoming an almost trillion-dollar company by buying its profits with our safety. BOND: And, you know, Steve, we have heard from Facebook critics before, but I think what makes Haugen different is that, you know, she came to this committee armed with inside knowledge and this huge trove of internal research with some, you know, troubling findings, including surveys of some teen users of Instagram who say, you know, the app exacerbates problems like depression and eating disorders. And then she used these documents to make the case - it's time to regulate Facebook as a matter of public safety, like Big Tobacco, which is a comparison that lots of lawmakers jumped on. INSKEEP: Now, we should mention - she said, Facebook growing at all costs. Facebook, when they were on the program, were pointing out there have been occasions where they've restrained some of their growth in ways that they said would be less harmful, would be helpful to people. But still, they grow. Still, they use what they use. What causes these bad decisions by Facebook, as Haugen would describe them? BOND: Well, she focused in on Facebook's engagement-based algorithms. That's her area of expertise. You know, the way that works is, when you're on Facebook or Instagram, if a post gets a lot of interactions, comments, likes, it's spread more widely. It's featured more prominently, the idea being that keeps people interested in using the apps. But Haugen cited Facebook's own research showing that focusing on engagement also tends to amp up the most sensational and extreme posts. So, for example, people might be looking for healthy recipes, but then they start seeing posts about anorexia. She says it's even fueling ethnic violence in places like Ethiopia. And she says Facebook needs to be pressured to fix it. (SOUNDBITE OF ARCHIVED RECORDING)HAUGEN: They have 100% control over their algorithms, and Facebook should not get a free pass on choices it makes to prioritize growth and virality and reactiveness over public safety. INSKEEP: But now we get to the complicated part. What might action from Congress look like that could have a practical effect? BOND: Well, senators asked Haugen what they should do. She says they should focus on these algorithms and holding the company responsible for their impacts. She also says they should demand more transparency. But the question is, you know, did any of these proposals actually move forward? INSKEEP: Well, as we wait to find out, what is Facebook saying? BOND: Well, hours after the hearing, we finally heard from CEO Mark Zuckerberg. He hasn't spoken about this before. In an email to staff, he didn't mention Haugen by name, but he said many of her claims don't make sense and that Facebook cares deeply about these issues, like safety and mental health, and he repeated his own calls for updated regulations. We also heard a spokesman during the hearing sort of downplaying Haugen's role, so that's another pushback we've heard from the company. INSKEEP: Shannon, thanks so much. Really appreciate it. BOND: Thanks, Steve. INSKEEP: That's NPR's Shannon Bond. STEVE INSKEEP, HOST:   How could action by Congress bring changes to Facebook? Former employee Frances Haugen told her story before a Senate committee yesterday. As we've heard all week, she left the company with documents showing Facebook's internal concerns about their products. (SOUNDBITE OF ARCHIVED RECORDING) FRANCES HAUGEN: The choices being made inside of Facebook are disastrous - for our children, for our public safety, for our privacy and for our democracy. And that is why we must demand Facebook make changes. INSKEEP: Now, Facebook has rejected that portrayal. But this week on NPR, we have heard a U. S. senator talk of regulating the company and a Facebook executive saying they would welcome regulation. NPR's Shannon Bond covers Facebook, which is - we should disclose - among NPR's financial supporters. We cover them like any other company. And so Shannon is here. Good morning. SHANNON BOND, BYLINE: Good morning, Steve. INSKEEP: What is the basic problem as Haugen sees it? BOND: Well, she says Facebook consistently makes choices in the pursuit of growth, even when that risks harming its own users. (SOUNDBITE OF ARCHIVED RECORDING) HAUGEN: It is about Facebook choosing to grow at all costs, becoming an almost trillion-dollar company by buying its profits with our safety. BOND: And, you know, Steve, we have heard from Facebook critics before, but I think what makes Haugen different is that, you know, she came to this committee armed with inside knowledge and this huge trove of internal research with some, you know, troubling findings, including surveys of some teen users of Instagram who say, you know, the app exacerbates problems like depression and eating disorders. And then she used these documents to make the case - it's time to regulate Facebook as a matter of public safety, like Big Tobacco, which is a comparison that lots of lawmakers jumped on. INSKEEP: Now, we should mention - she said, Facebook growing at all costs. Facebook, when they were on the program, were pointing out there have been occasions where they've restrained some of their growth in ways that they said would be less harmful, would be helpful to people. But still, they grow. Still, they use what they use. What causes these bad decisions by Facebook, as Haugen would describe them? BOND: Well, she focused in on Facebook's engagement-based algorithms. That's her area of expertise. You know, the way that works is, when you're on Facebook or Instagram, if a post gets a lot of interactions, comments, likes, it's spread more widely. It's featured more prominently, the idea being that keeps people interested in using the apps. But Haugen cited Facebook's own research showing that focusing on engagement also tends to amp up the most sensational and extreme posts. So, for example, people might be looking for healthy recipes, but then they start seeing posts about anorexia. She says it's even fueling ethnic violence in places like Ethiopia. And she says Facebook needs to be pressured to fix it. (SOUNDBITE OF ARCHIVED RECORDING) HAUGEN: They have 100% control over their algorithms, and Facebook should not get a free pass on choices it makes to prioritize growth and virality and reactiveness over public safety. INSKEEP: But now we get to the complicated part. What might action from Congress look like that could have a practical effect? BOND: Well, senators asked Haugen what they should do. She says they should focus on these algorithms and holding the company responsible for their impacts. She also says they should demand more transparency. But the question is, you know, did any of these proposals actually move forward? INSKEEP: Well, as we wait to find out, what is Facebook saying? BOND: Well, hours after the hearing, we finally heard from CEO Mark Zuckerberg. He hasn't spoken about this before. In an email to staff, he didn't mention Haugen by name, but he said many of her claims don't make sense and that Facebook cares deeply about these issues, like safety and mental health, and he repeated his own calls for updated regulations. We also heard a spokesman during the hearing sort of downplaying Haugen's role, so that's another pushback we've heard from the company. INSKEEP: Shannon, thanks so much. Really appreciate it. BOND: Thanks, Steve. INSKEEP: That's NPR's Shannon Bond.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-10-07-1044049793": {"title": "Facebook's Week Of Twin Crises Reveal The Company's Power : Consider This from NPR : NPR", "url": "https://www.npr.org/2021/10/07/1044049793/for-facebook-a-week-of-upheaval-unlike-any-other", "author": "No author found", "published_date": "2021-10-07", "content": "AUDIE CORNISH, HOST:  Facebook whistleblower Frances Haugen told a Senate subcommittee this week she didn't know why the company's servers had gone offline for more than five hours the day before. (SOUNDBITE OF ARCHIVED RECORDING)FRANCES HAUGEN: But I know that for more than five hours, Facebook wasn't used to deepen divides, destabilize democracies and make young girls and women feel bad about their bodies. CORNISH: Haugen was there to tell lawmakers more about documents she'd obtained as a Facebook employee, documents that reveal the company's internal concerns about its products; concerns that they could harm teenagers, amplify extremism and lead to violence; concerns that Haugen claimed Facebook is concealing from the public and its shareholders. (SOUNDBITE OF ARCHIVED RECORDING)HAUGEN: When we realized Big Tobacco was hiding the harms it caused, the government took action. When we figured out cars were safer with seatbelts, the government took action. And when our government learned that opioids were taking lives, the government took action. I implore you to do the same here. CORNISH: But despite a lot of talk about more regulation of Facebook, it's not clear the talk will translate to action in Congress, at least not anytime soon. For now, the company will be judged in the court of public opinion - global public opinion. Facebook has 2. 8 billion users around the world. And for a lot of those people, the company's products, which include Instagram and WhatsApp, are a crucial part of their livelihoods. AYMAN EL TARABISHY: What I heard is, well, I didn't make any money today because (laughter) everything was down. I didn't have my store. CORNISH: Ayman El Tarabishy heads the International Council for Small Businesses, millions of which felt the pain of Facebook's outage this weekEL TARABISHY: In India, Brazil, the United States, Russia, Mexico, Germany, Italy and, you know, Latin American countries, they are a utility that people use like electricity. (SOUNDBITE OF MUSIC)CORNISH: CONSIDER THIS - it's been a week of twin crises for Facebook, but both of them reveal the same thing - just how powerful Facebook really is. From NPR, I'm Audie Cornish. It's Thursday, October 7. It's CONSIDER THIS FROM NPR. And we need to say here that Facebook is among NPR's financial sponsors. We cover them just like any other company. But Facebook is not like any other company. It's worth nearly a trillion dollars, and its users account for 60% of all the internet-connected people on Earth. Facebook achieved that level of growth, Frances Haugen claims this week, at the expense of its users' safety. (SOUNDBITE OF ARCHIVED RECORDING)HAUGEN: During my time at Facebook, I came to realize the devastating truth - almost no one outside of Facebook knows what happens inside of Facebook. CORNISH: What happens inside of Facebook? Well, documents leaked by Haugen to The Wall Street Journal include an internal memo from 2018 that said, quote, \"misinformation, toxicity and violent content are inordinately prevalent among reshares. \" That's just one example of what Haugen said is a pattern. Facebook is aware that its most engaging content is often the most divisive and harmful. NEIL POTTS: I think that accusation is just a bit unfounded. At Facebook. . . CORNISH: Neil Potts is vice president for trust and safety policy at Facebook. He spoke to NPR this week. POTTS: We're not designing anything to be for the sensational or clickbait-y (ph) or engagement bait-y (ph) ways that polarization may be seen and that I think was being accused of Facebook and leadership decisions on the product. CORNISH: But whether Facebook designed its platforms to reward polarizing content, documents show an awareness that that's what's happening. In memos described by the Wall Street Journal, company researchers shared concerns about a change in 2018 to the Facebook News Feed algorithm. Data scientists flagged that publishers and political parties were reorienting their posts toward outrage and sensationalism. They wrote, quote, \"our approach has had unhealthy side effects on important slices of public content, such as politics and news. This is an increasing liability. \"Additional memos suggest top leadership, including CEO Mark Zuckerberg, decided not to take additional steps that would have addressed the problem. Here's whistleblower Frances Haugen again. (SOUNDBITE OF ARCHIVED RECORDING)HAUGEN: This is not simply a matter of certain social media users being angry or unstable or about one side being radicalized against the other. It is about Facebook choosing to grow at all costs, becoming an almost trillion dollar company by buying its profits with our safety. CORNISH: Now, Facebook's Neil Potts told NPR the company is investing a lot of money to fight misinformation and harmful content on its platforms and pointed to the decision during the 2020 presidential campaign to pause all political advertising. POTTS: You can see a lot of the similarities between the way that we've treated elections on the platform with our elections hub as well as what we are doing around COVID-19 and the COVID-19 hub. So those teams are still in practice, doing work and actually working on civic issues in elections across the globe. CORNISH: Facebook has responded similarly to another set of accusations about Instagram, which it owns. Internal research obtained by Haugen shows that in one survey, 13. 5% of teen girls in the U. K. said Instagram worsens suicidal thoughts. Another survey found 17% of girls saying that Instagram contributes to their eating disorders. (SOUNDBITE OF ARCHIVED RECORDING)HAUGEN: There are going to be women walking around this planet in 60 years with brittle bones because of choices that Facebook made around emphasizing profit today. Or there are going to be women when they're - in 20 years who want to have babies who can't because they're infertile as a result of eating disorders today. CORNISH: Neil Potts said Facebook's internal research on kids has been mischaracterized, that many kids have positive experiences with Facebook and Instagram and that the company is investing in research to minimize harmful effects on young women. POTTS: We're investing millions of dollars, billions of dollars on these issues to make sure that we are arriving at the right solutions. For any one person that experienced these, we want to make sure that we try to eliminate that. But on balance, we are doing the work, investing in the research so we know how to approach these issues and really even sending interventions to people who may be impacted by such harms. (SOUNDBITE OF MUSIC)CORNISH: So what happens now? Haugen's attorneys have filed whistleblower complaints with the Securities and Exchange Commission. The SEC could investigate, level fines. It's done so in the past against Facebook. So have other government agencies. For instance, in 2019, the FTC fined Facebook $5 billion for consumer privacy violations. It was the largest fine ever imposed by the FTC against a tech company - 5 billion. Now compare that to Facebook's revenue last quarter alone. That was $29 billion, up 56% from the same period last year. (SOUNDBITE OF MUSIC)CORNISH: As we mentioned, Facebook's other big crisis this week was a widespread outage on Monday that brought down the platform - along with its siblings, Instagram and WhatsApp - for nearly six hours. Facebook says it wasn't a hack, just an update to its systems that went wrong. That the outage lasted less than six hours but still caused headaches and lost revenue for businesses around the world reveals just how important Facebook's platforms have become to millions of people. LYDIA MUTUNE OSEWE: Basically, what came out is that our lives revolve around social media platforms because at some point, we felt alone. CORNISH: Lydia Mutune Osewe owns a plant shop in Nairobi, Kenya. She runs it entirely on Facebook, WhatsApp and Instagram. And during the outage this week, clients couldn't reach her and vice versa. OSEWE: They couldn't place their orders. We couldn't even do our deliveries because most of our deliveries, we rely on the information they send to WhatsApp. For example, they have to drop their pin to their location on WhatsApp numbers, but we were not getting all this information. CORNISH: Lydia told NPR one thing she's going to do differently now - create a backup system somewhere other than Facebook of her business contacts. OSEWE: It was a wake-up call to us because we do - we realize that 100% of our clientele details were on the various social media pages. So in case of such a shutdown, maybe if it went on forever, that is how we'd be thrown out of business. (SOUNDBITE OF MUSIC)CORNISH: That value to people's individual livelihoods is part of what makes Facebook so powerful around the world, and we wanted to talk more about that. So we reached out to Ayman El Tarabishy, who you heard near the top of the episode. He's a professor at George Washington School of Business. He heads the International Council for Small Businesses. I'm not sure people totally appreciate just the parts of the world where WhatsApp in particular or Instagram are a part of the way people actually do business on a local level. Just how popular is WhatsApp, for example, as a tool for conducting business? And which parts of the world do you see it having kind of a central role? EL TARABISHY: So my area of focus is on small business and microbusinesses. It is extremely important and very popular with small businesses, microbusinesses, and, actually, users of it in communication are across the world. Statistics show it's very popular in India, Brazil, the United States and Russia, Mexico, you know, Germany, Italy, you know, Latin American countries. It's extremely popular across the world for a platform to communicate. That's WhatsApp. In terms of Instagram and Facebook, that's more of e-commerce and business for small businesses and microbusinesses. CORNISH: What is Facebook - and we are talking about Facebook here - offering in these apps that these people can't access in their home countries in terms of the infrastructure to do commerce? EL TARABISHY: Well, it's the speed, the speed and the convenience and the personalization. So Facebook is offering three things that are indispensable for running small businesses - the speed of communicating to the customers, the convenience because you can - everybody has a cell phone, so they can quickly message and say, I need this, or I want to buy this, or I need you to come here. So there's a convenient aspect, right? And the personalization - you have now a way of connecting to customers on their phones, which is very intimate, having access to someone's telephone number to communicate with them. So Facebook has done a wonderful job of offering speed, convenience and personalization, and they've made it into a money revenue-generating item for small businesses and microbusinesses - and for them as well because they're providing the service. CORNISH: You've helped us understand the reliance. But I don't think I have a sense of then how can people not rely - right? - on a corporation to provide this kind of economic infrastructure? What's the alternative? EL TARABISHY: Well, this is the big question now. Because of what happened, now this is what the question a lot of small business owners and microbusiness owners are saying - what is my option B? Right? If this goes down again, I cannot just rely on one source. Now, you can see now, slowly, a migration to other platforms and also for other entrepreneurs and other companies to come into this area, saying, we are another alternative. And that's what's going to - what we're going to see soon - other providers coming up to speed with this. CORNISH: Facebook has had a pretty bad week, frankly. The whistleblower testimony on Capitol Hill here in the U. S. really revealed a lot about what the company does know about its effect on its users. Did that, in a way, also overshadow this news of the outage and the effects of it abroad? EL TARABISHY: Well, we know it was a bad week for Facebook, right? And I think they just have to understand now there are certain things that they need to work on. For small businesses, Facebook is indispensable. For small businesses, they are a utility that people use, like electricity, like, you know, like rent and everything, to do business. So these small businesses use these platforms as a utility, right? So therefore, if you take away a utility that's indispensable for their business, they don't do any more business. It stops right then, there. (SOUNDBITE OF MUSIC)CORNISH: Ayman El Tarabishy, a professor at George Washington School of Business. Special thanks to our colleagues on NPR's business desk, Emily Kopp and Shannon Bond, for their help with this episode. It's CONSIDER THIS FROM NPR. I'm Audie Cornish. AUDIE CORNISH, HOST:   Facebook whistleblower Frances Haugen told a Senate subcommittee this week she didn't know why the company's servers had gone offline for more than five hours the day before. (SOUNDBITE OF ARCHIVED RECORDING) FRANCES HAUGEN: But I know that for more than five hours, Facebook wasn't used to deepen divides, destabilize democracies and make young girls and women feel bad about their bodies. CORNISH: Haugen was there to tell lawmakers more about documents she'd obtained as a Facebook employee, documents that reveal the company's internal concerns about its products; concerns that they could harm teenagers, amplify extremism and lead to violence; concerns that Haugen claimed Facebook is concealing from the public and its shareholders. (SOUNDBITE OF ARCHIVED RECORDING) HAUGEN: When we realized Big Tobacco was hiding the harms it caused, the government took action. When we figured out cars were safer with seatbelts, the government took action. And when our government learned that opioids were taking lives, the government took action. I implore you to do the same here. CORNISH: But despite a lot of talk about more regulation of Facebook, it's not clear the talk will translate to action in Congress, at least not anytime soon. For now, the company will be judged in the court of public opinion - global public opinion. Facebook has 2. 8 billion users around the world. And for a lot of those people, the company's products, which include Instagram and WhatsApp, are a crucial part of their livelihoods. AYMAN EL TARABISHY: What I heard is, well, I didn't make any money today because (laughter) everything was down. I didn't have my store. CORNISH: Ayman El Tarabishy heads the International Council for Small Businesses, millions of which felt the pain of Facebook's outage this week EL TARABISHY: In India, Brazil, the United States, Russia, Mexico, Germany, Italy and, you know, Latin American countries, they are a utility that people use like electricity. (SOUNDBITE OF MUSIC) CORNISH: CONSIDER THIS - it's been a week of twin crises for Facebook, but both of them reveal the same thing - just how powerful Facebook really is. From NPR, I'm Audie Cornish. It's Thursday, October 7. It's CONSIDER THIS FROM NPR. And we need to say here that Facebook is among NPR's financial sponsors. We cover them just like any other company. But Facebook is not like any other company. It's worth nearly a trillion dollars, and its users account for 60% of all the internet-connected people on Earth. Facebook achieved that level of growth, Frances Haugen claims this week, at the expense of its users' safety. (SOUNDBITE OF ARCHIVED RECORDING) HAUGEN: During my time at Facebook, I came to realize the devastating truth - almost no one outside of Facebook knows what happens inside of Facebook. CORNISH: What happens inside of Facebook? Well, documents leaked by Haugen to The Wall Street Journal include an internal memo from 2018 that said, quote, \"misinformation, toxicity and violent content are inordinately prevalent among reshares. \" That's just one example of what Haugen said is a pattern. Facebook is aware that its most engaging content is often the most divisive and harmful. NEIL POTTS: I think that accusation is just a bit unfounded. At Facebook. . . CORNISH: Neil Potts is vice president for trust and safety policy at Facebook. He spoke to NPR this week. POTTS: We're not designing anything to be for the sensational or clickbait-y (ph) or engagement bait-y (ph) ways that polarization may be seen and that I think was being accused of Facebook and leadership decisions on the product. CORNISH: But whether Facebook designed its platforms to reward polarizing content, documents show an awareness that that's what's happening. In memos described by the Wall Street Journal, company researchers shared concerns about a change in 2018 to the Facebook News Feed algorithm. Data scientists flagged that publishers and political parties were reorienting their posts toward outrage and sensationalism. They wrote, quote, \"our approach has had unhealthy side effects on important slices of public content, such as politics and news. This is an increasing liability. \" Additional memos suggest top leadership, including CEO Mark Zuckerberg, decided not to take additional steps that would have addressed the problem. Here's whistleblower Frances Haugen again. (SOUNDBITE OF ARCHIVED RECORDING) HAUGEN: This is not simply a matter of certain social media users being angry or unstable or about one side being radicalized against the other. It is about Facebook choosing to grow at all costs, becoming an almost trillion dollar company by buying its profits with our safety. CORNISH: Now, Facebook's Neil Potts told NPR the company is investing a lot of money to fight misinformation and harmful content on its platforms and pointed to the decision during the 2020 presidential campaign to pause all political advertising. POTTS: You can see a lot of the similarities between the way that we've treated elections on the platform with our elections hub as well as what we are doing around COVID-19 and the COVID-19 hub. So those teams are still in practice, doing work and actually working on civic issues in elections across the globe. CORNISH: Facebook has responded similarly to another set of accusations about Instagram, which it owns. Internal research obtained by Haugen shows that in one survey, 13. 5% of teen girls in the U. K. said Instagram worsens suicidal thoughts. Another survey found 17% of girls saying that Instagram contributes to their eating disorders. (SOUNDBITE OF ARCHIVED RECORDING) HAUGEN: There are going to be women walking around this planet in 60 years with brittle bones because of choices that Facebook made around emphasizing profit today. Or there are going to be women when they're - in 20 years who want to have babies who can't because they're infertile as a result of eating disorders today. CORNISH: Neil Potts said Facebook's internal research on kids has been mischaracterized, that many kids have positive experiences with Facebook and Instagram and that the company is investing in research to minimize harmful effects on young women. POTTS: We're investing millions of dollars, billions of dollars on these issues to make sure that we are arriving at the right solutions. For any one person that experienced these, we want to make sure that we try to eliminate that. But on balance, we are doing the work, investing in the research so we know how to approach these issues and really even sending interventions to people who may be impacted by such harms. (SOUNDBITE OF MUSIC) CORNISH: So what happens now? Haugen's attorneys have filed whistleblower complaints with the Securities and Exchange Commission. The SEC could investigate, level fines. It's done so in the past against Facebook. So have other government agencies. For instance, in 2019, the FTC fined Facebook $5 billion for consumer privacy violations. It was the largest fine ever imposed by the FTC against a tech company - 5 billion. Now compare that to Facebook's revenue last quarter alone. That was $29 billion, up 56% from the same period last year. (SOUNDBITE OF MUSIC) CORNISH: As we mentioned, Facebook's other big crisis this week was a widespread outage on Monday that brought down the platform - along with its siblings, Instagram and WhatsApp - for nearly six hours. Facebook says it wasn't a hack, just an update to its systems that went wrong. That the outage lasted less than six hours but still caused headaches and lost revenue for businesses around the world reveals just how important Facebook's platforms have become to millions of people. LYDIA MUTUNE OSEWE: Basically, what came out is that our lives revolve around social media platforms because at some point, we felt alone. CORNISH: Lydia Mutune Osewe owns a plant shop in Nairobi, Kenya. She runs it entirely on Facebook, WhatsApp and Instagram. And during the outage this week, clients couldn't reach her and vice versa. OSEWE: They couldn't place their orders. We couldn't even do our deliveries because most of our deliveries, we rely on the information they send to WhatsApp. For example, they have to drop their pin to their location on WhatsApp numbers, but we were not getting all this information. CORNISH: Lydia told NPR one thing she's going to do differently now - create a backup system somewhere other than Facebook of her business contacts. OSEWE: It was a wake-up call to us because we do - we realize that 100% of our clientele details were on the various social media pages. So in case of such a shutdown, maybe if it went on forever, that is how we'd be thrown out of business. (SOUNDBITE OF MUSIC) CORNISH: That value to people's individual livelihoods is part of what makes Facebook so powerful around the world, and we wanted to talk more about that. So we reached out to Ayman El Tarabishy, who you heard near the top of the episode. He's a professor at George Washington School of Business. He heads the International Council for Small Businesses. I'm not sure people totally appreciate just the parts of the world where WhatsApp in particular or Instagram are a part of the way people actually do business on a local level. Just how popular is WhatsApp, for example, as a tool for conducting business? And which parts of the world do you see it having kind of a central role? EL TARABISHY: So my area of focus is on small business and microbusinesses. It is extremely important and very popular with small businesses, microbusinesses, and, actually, users of it in communication are across the world. Statistics show it's very popular in India, Brazil, the United States and Russia, Mexico, you know, Germany, Italy, you know, Latin American countries. It's extremely popular across the world for a platform to communicate. That's WhatsApp. In terms of Instagram and Facebook, that's more of e-commerce and business for small businesses and microbusinesses. CORNISH: What is Facebook - and we are talking about Facebook here - offering in these apps that these people can't access in their home countries in terms of the infrastructure to do commerce? EL TARABISHY: Well, it's the speed, the speed and the convenience and the personalization. So Facebook is offering three things that are indispensable for running small businesses - the speed of communicating to the customers, the convenience because you can - everybody has a cell phone, so they can quickly message and say, I need this, or I want to buy this, or I need you to come here. So there's a convenient aspect, right? And the personalization - you have now a way of connecting to customers on their phones, which is very intimate, having access to someone's telephone number to communicate with them. So Facebook has done a wonderful job of offering speed, convenience and personalization, and they've made it into a money revenue-generating item for small businesses and microbusinesses - and for them as well because they're providing the service. CORNISH: You've helped us understand the reliance. But I don't think I have a sense of then how can people not rely - right? - on a corporation to provide this kind of economic infrastructure? What's the alternative? EL TARABISHY: Well, this is the big question now. Because of what happened, now this is what the question a lot of small business owners and microbusiness owners are saying - what is my option B? Right? If this goes down again, I cannot just rely on one source. Now, you can see now, slowly, a migration to other platforms and also for other entrepreneurs and other companies to come into this area, saying, we are another alternative. And that's what's going to - what we're going to see soon - other providers coming up to speed with this. CORNISH: Facebook has had a pretty bad week, frankly. The whistleblower testimony on Capitol Hill here in the U. S. really revealed a lot about what the company does know about its effect on its users. Did that, in a way, also overshadow this news of the outage and the effects of it abroad? EL TARABISHY: Well, we know it was a bad week for Facebook, right? And I think they just have to understand now there are certain things that they need to work on. For small businesses, Facebook is indispensable. For small businesses, they are a utility that people use, like electricity, like, you know, like rent and everything, to do business. So these small businesses use these platforms as a utility, right? So therefore, if you take away a utility that's indispensable for their business, they don't do any more business. It stops right then, there. (SOUNDBITE OF MUSIC) CORNISH: Ayman El Tarabishy, a professor at George Washington School of Business. Special thanks to our colleagues on NPR's business desk, Emily Kopp and Shannon Bond, for their help with this episode. It's CONSIDER THIS FROM NPR. I'm Audie Cornish.", "section": "For Facebook, A Week Of Upheaval Unlike Any Other", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-10-09-1044682322": {"title": "Facebook whistleblower's testimony spurs calls for regulation : NPR", "url": "https://www.npr.org/2021/10/09/1044682322/facebook-whistleblowers-testimony-spurs-calls-for-regulation", "author": "No author found", "published_date": "2021-10-09", "content": "SCOTT SIMON, HOST:  A Facebook whistleblower told Congress it's time to regulate the social media company. (SOUNDBITE OF ARCHIVED RECORDING)FRANCES HAUGEN: When we realized Big Tobacco was hiding the harms it caused, the government took action. When we figured out cars were safer with seatbelts, the government took action. And when our government learned that opioids were taking lives, the government took action. I implore you to do the same here. SIMON: Frances Haugen left Facebook earlier this year with a trove of internal documents she says show the company knows that its products cause harm, but she says Facebook has hidden those concerns from the public. What action could the government take? NPR tech correspondent Shannon Bond joins us. Let us first note that Facebook is among NPR's financial supporters. Shannon, thanks for being with us. SHANNON BOND, BYLINE: Thanks for having me. SIMON: Lawmakers who heard the testimony seemed riveted on both parties, didn't they? BOND: Yeah, this hearing was really a galvanizing moment. Just listen to what Senator Amy Klobuchar of Minnesota told Haugen. (SOUNDBITE OF ARCHIVED RECORDING)AMY KLOBUCHAR: I think the time has come for action, and I think you are the catalyst for that action. BOND: And she and other lawmakers say, you know, they've been worried about Facebook and the way its algorithms exacerbate things like mental health problems, vaccine misinformation, ethnic violence for a long time. Now, here comes this ex-Facebook employee with tens of thousands of pages of internal research showing Facebook is also concerned about these problems. But, Haugen says, the company hasn't done what it could to fix them because at the end of the day, it's just so focused on growth. So, she says, Facebook is not going to change on its own, so Congress has to be the one to force it. SIMON: And how, she thinks? BOND: Well, the hearing, she floated a couple ideas, including a new agency to regulate tech. But the idea she kept returning to is that Facebook is a black box, right? Outsiders don't know what goes into its decisions, how its systems decide what posts to show people. And that makes it really hard to understand how to fix these problems. (SOUNDBITE OF ARCHIVED RECORDING)HAUGEN: This inability to see into Facebook's actual systems and confirm how they work, as communicated, is like the Department of Transportation regulating cars by only watching them drive down the highway. BOND: So Haugen says we need to be able to look under the hood at Facebook. SIMON: How would you look under the hood? BOND: One idea is to force Facebook and other companies to give outside researchers much more access to its underlying data, right? This is what feeds its algorithms and ultimately its business model. I spoke to Nate Persily. He's a law professor at Stanford who's drafted a law that would do this. NATE PERSILY: The whole point here is that if someone is watching Facebook and has access to their data, that Facebook will change its behavior knowing that it's being watched. BOND: And he says similar models already exist to let researchers examine the raw data from the census, from the IRS, also biomedical research. And what he says is not only would this kind of oversight pressure Facebook to change, but getting a look inside the platform is actually going to be essential to any other regulation Congress might want to pass, whether it's data privacy, rules about algorithms, or breaking up Facebook. SIMON: Hasn't Congress threatened to regulate high tech before? BOND: That's right. I mean, pressure has been building since well before Haugen made these disclosures. One big focus is creating new privacy laws that would limit the amount of data Facebook can collect. And that really gets at the heart of Facebook's business, right? All of the information they have about users, that is what feeds their algorithms. And ultimately, it's how Facebook makes money. It uses this data to target advertising. So for years, there have been proposals for a national privacy law. So far, they have stalled. The question is, is this moment now, with the whistleblower, what breaks that logjam? SIMON: What does Facebook say? BOND: Well, it's been saying for a long time that it welcomes regulations. It's even put out its own proposals. But the company itself says, look; Congress, it's up to you to pass laws. SIMON: NPR's Shannon Bond, thanks so much. BOND: Thank you, Scott. SCOTT SIMON, HOST:   A Facebook whistleblower told Congress it's time to regulate the social media company. (SOUNDBITE OF ARCHIVED RECORDING) FRANCES HAUGEN: When we realized Big Tobacco was hiding the harms it caused, the government took action. When we figured out cars were safer with seatbelts, the government took action. And when our government learned that opioids were taking lives, the government took action. I implore you to do the same here. SIMON: Frances Haugen left Facebook earlier this year with a trove of internal documents she says show the company knows that its products cause harm, but she says Facebook has hidden those concerns from the public. What action could the government take? NPR tech correspondent Shannon Bond joins us. Let us first note that Facebook is among NPR's financial supporters. Shannon, thanks for being with us. SHANNON BOND, BYLINE: Thanks for having me. SIMON: Lawmakers who heard the testimony seemed riveted on both parties, didn't they? BOND: Yeah, this hearing was really a galvanizing moment. Just listen to what Senator Amy Klobuchar of Minnesota told Haugen. (SOUNDBITE OF ARCHIVED RECORDING) AMY KLOBUCHAR: I think the time has come for action, and I think you are the catalyst for that action. BOND: And she and other lawmakers say, you know, they've been worried about Facebook and the way its algorithms exacerbate things like mental health problems, vaccine misinformation, ethnic violence for a long time. Now, here comes this ex-Facebook employee with tens of thousands of pages of internal research showing Facebook is also concerned about these problems. But, Haugen says, the company hasn't done what it could to fix them because at the end of the day, it's just so focused on growth. So, she says, Facebook is not going to change on its own, so Congress has to be the one to force it. SIMON: And how, she thinks? BOND: Well, the hearing, she floated a couple ideas, including a new agency to regulate tech. But the idea she kept returning to is that Facebook is a black box, right? Outsiders don't know what goes into its decisions, how its systems decide what posts to show people. And that makes it really hard to understand how to fix these problems. (SOUNDBITE OF ARCHIVED RECORDING) HAUGEN: This inability to see into Facebook's actual systems and confirm how they work, as communicated, is like the Department of Transportation regulating cars by only watching them drive down the highway. BOND: So Haugen says we need to be able to look under the hood at Facebook. SIMON: How would you look under the hood? BOND: One idea is to force Facebook and other companies to give outside researchers much more access to its underlying data, right? This is what feeds its algorithms and ultimately its business model. I spoke to Nate Persily. He's a law professor at Stanford who's drafted a law that would do this. NATE PERSILY: The whole point here is that if someone is watching Facebook and has access to their data, that Facebook will change its behavior knowing that it's being watched. BOND: And he says similar models already exist to let researchers examine the raw data from the census, from the IRS, also biomedical research. And what he says is not only would this kind of oversight pressure Facebook to change, but getting a look inside the platform is actually going to be essential to any other regulation Congress might want to pass, whether it's data privacy, rules about algorithms, or breaking up Facebook. SIMON: Hasn't Congress threatened to regulate high tech before? BOND: That's right. I mean, pressure has been building since well before Haugen made these disclosures. One big focus is creating new privacy laws that would limit the amount of data Facebook can collect. And that really gets at the heart of Facebook's business, right? All of the information they have about users, that is what feeds their algorithms. And ultimately, it's how Facebook makes money. It uses this data to target advertising. So for years, there have been proposals for a national privacy law. So far, they have stalled. The question is, is this moment now, with the whistleblower, what breaks that logjam? SIMON: What does Facebook say? BOND: Well, it's been saying for a long time that it welcomes regulations. It's even put out its own proposals. But the company itself says, look; Congress, it's up to you to pass laws. SIMON: NPR's Shannon Bond, thanks so much. BOND: Thank you, Scott.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-10-10-1044917871": {"title": "Facebook to add new Instagram safety features for children : NPR", "url": "https://www.npr.org/2021/10/10/1044917871/facebook-instagram-safety-controls-kids", "author": "No author found", "published_date": "2021-10-10", "content": "", "section": "Technology", "disclaimer": ""}, "2021-10-10-1044916925": {"title": "A case for holding tech companies responsible for their algorithms : NPR", "url": "https://www.npr.org/2021/10/10/1044916925/a-case-for-holding-tech-companies-responsible-for-their-algorithms", "author": "No author found", "published_date": "2021-10-10", "content": "MICHEL MARTIN, HOST:  As we just heard, both Democrats and Republicans have started talking about regulating Facebook and other Big Tech companies. We want to talk more about what that could look like. During the Senate hearing, whistleblower Frances Haugen said critics should focus on the company's algorithms. That's the artificial intelligence social media companies use to rank or promote content. Roddy Lindsay agrees. He's a former data scientist who worked on algorithms at Facebook, which, we'll say again, has been a financial supporter of NPR. He wrote an op-ed for The New York Times about how to regulate algorithms. And he began by explaining why they're so dangerous. RODDY LINDSAY: There are some real risks associated with these algorithms that can amplify content that once might have been relegated to a fringe corner of the internet. This type of content can take hold and spread very quickly in a very short period of time. I think as a society, we're grappling with, you know, whether we want these algorithms in our lives and whether they're compatible with democracy. And the good news is that there's a relatively straightforward fix that Congress can make, which basically says if you're in the business of using these algorithms to distribute content, you as a platform need to take responsibility in that. And you could be held liable for that. And I think what that would do is that - it would change the incentives for these companies to change the way they create these feeds and create their products and go more towards a model that puts control back in the hands of users and make it, you know, understandable, the way that they're ordering content and get it out of the hands of these sort of black-box AI algorithms. MARTIN: You've described it as a straightforward reform. If it's straightforward and simple, why do you think it hasn't happened yet? LINDSAY: You know, Congress has grappled with, well, how do you do this in a way that doesn't, you know, run afoul of the First Amendment? You know, you don't want Congress getting - you know, saying this is the type of speech you can host. This is the speech that you can't host. I mean, that would obviously run into the First Amendment issues. But if you just focus on the amplication (ph) part of it, there's some historical precedent for this. You know, in the 1940s, cities around the U. S. were plagued with these sound trucks that would drive around with these huge horns and amplify music and commercials and things like that. And so some cities started passing some laws regulating these sound trucks, saying, you know, you can't drive around and blast this speech into people's homes at this very loud level. And the Supreme Court actually upheld Trenton's - Trenton, N. J. 's law in 1949. So there is some precedent for the Supreme Court saying there are ways in which we can limit the amplification of speech - not the speech itself, but how it's amplified and distributed. MARTIN: But what about the business side of it? I mean, I think critics', like Frances Haugen's, point has been that one of the reasons that Facebook doesn't do this or hasn't done this on its own is that it's been very profitable. The businesses they've conducted, it has been extremely profitable. What is your sense of - and I know you don't speak for Facebook. That's not why we called you. But what effect would this have on their business model? LINDSAY: You know, there's no incentive for them to get rid of these algorithms themselves, which is why it needs to be Congress to step in and say there needs to be a comprehensive regulation that limits these for everybody, not just for one site or another. So even if Facebook or YouTube wanted to do the right thing, they really can't today because of market pressure. And they have shareholders, of course, to report to. So if you were to say, you know what? We're going to unilaterally decrease our revenue by 10 or 20% - your shareholders would yell at you. But if it's Congress that can step in, then everyone's impacted the same. And after that, you know, everyone's - there's this - there's a level playing field. And all the companies can get back to building products that actually benefit their users without relying on these algorithms to be the primary driver of engagement. So I think, you know, while the companies might say that it would be harmful for them, I think that would be very short term. MARTIN: Before we let you go, do you mind if I ask you a question - personal question? LINDSAY: Absolutely. MARTIN: How do you manage your social media diet knowing everything that you know? Knowing everything that you know about the way these algorithms work, how do you manage this for yourself? LINDSAY: Well, actually, on Twitter, I use their chronological feeds, their non-algorithmic feed, which is one of their options. And, you know, what I find is that it lets me discover things that may not be the most polarizing or engaging content. It may be sort of more boring. But I find that it's actually a better reflection of the people in our lives and, you know, what's happening out there. You know, not everything needs to be the - not everything that you'd see on social media needs to be the most engaging content. It might be beneficial to have a more, sort of, boring feed. And it's not something that other people prefer. And I've been using it myself. And I think it'll be totally fine. MARTIN: Roddy Lindsay is a former Facebook data scientist. His New York Times op-ed is titled \"I Designed Algorithms At Facebook. Here's How To Regulate Them. \" Roddy Lindsay, thanks so much for talking with us. LINDSAY: Thanks for having me. (SOUNDBITE OF MUSIC) MICHEL MARTIN, HOST:   As we just heard, both Democrats and Republicans have started talking about regulating Facebook and other Big Tech companies. We want to talk more about what that could look like. During the Senate hearing, whistleblower Frances Haugen said critics should focus on the company's algorithms. That's the artificial intelligence social media companies use to rank or promote content. Roddy Lindsay agrees. He's a former data scientist who worked on algorithms at Facebook, which, we'll say again, has been a financial supporter of NPR. He wrote an op-ed for The New York Times about how to regulate algorithms. And he began by explaining why they're so dangerous. RODDY LINDSAY: There are some real risks associated with these algorithms that can amplify content that once might have been relegated to a fringe corner of the internet. This type of content can take hold and spread very quickly in a very short period of time. I think as a society, we're grappling with, you know, whether we want these algorithms in our lives and whether they're compatible with democracy. And the good news is that there's a relatively straightforward fix that Congress can make, which basically says if you're in the business of using these algorithms to distribute content, you as a platform need to take responsibility in that. And you could be held liable for that. And I think what that would do is that - it would change the incentives for these companies to change the way they create these feeds and create their products and go more towards a model that puts control back in the hands of users and make it, you know, understandable, the way that they're ordering content and get it out of the hands of these sort of black-box AI algorithms. MARTIN: You've described it as a straightforward reform. If it's straightforward and simple, why do you think it hasn't happened yet? LINDSAY: You know, Congress has grappled with, well, how do you do this in a way that doesn't, you know, run afoul of the First Amendment? You know, you don't want Congress getting - you know, saying this is the type of speech you can host. This is the speech that you can't host. I mean, that would obviously run into the First Amendment issues. But if you just focus on the amplication (ph) part of it, there's some historical precedent for this. You know, in the 1940s, cities around the U. S. were plagued with these sound trucks that would drive around with these huge horns and amplify music and commercials and things like that. And so some cities started passing some laws regulating these sound trucks, saying, you know, you can't drive around and blast this speech into people's homes at this very loud level. And the Supreme Court actually upheld Trenton's - Trenton, N. J. 's law in 1949. So there is some precedent for the Supreme Court saying there are ways in which we can limit the amplification of speech - not the speech itself, but how it's amplified and distributed. MARTIN: But what about the business side of it? I mean, I think critics', like Frances Haugen's, point has been that one of the reasons that Facebook doesn't do this or hasn't done this on its own is that it's been very profitable. The businesses they've conducted, it has been extremely profitable. What is your sense of - and I know you don't speak for Facebook. That's not why we called you. But what effect would this have on their business model? LINDSAY: You know, there's no incentive for them to get rid of these algorithms themselves, which is why it needs to be Congress to step in and say there needs to be a comprehensive regulation that limits these for everybody, not just for one site or another. So even if Facebook or YouTube wanted to do the right thing, they really can't today because of market pressure. And they have shareholders, of course, to report to. So if you were to say, you know what? We're going to unilaterally decrease our revenue by 10 or 20% - your shareholders would yell at you. But if it's Congress that can step in, then everyone's impacted the same. And after that, you know, everyone's - there's this - there's a level playing field. And all the companies can get back to building products that actually benefit their users without relying on these algorithms to be the primary driver of engagement. So I think, you know, while the companies might say that it would be harmful for them, I think that would be very short term. MARTIN: Before we let you go, do you mind if I ask you a question - personal question? LINDSAY: Absolutely. MARTIN: How do you manage your social media diet knowing everything that you know? Knowing everything that you know about the way these algorithms work, how do you manage this for yourself? LINDSAY: Well, actually, on Twitter, I use their chronological feeds, their non-algorithmic feed, which is one of their options. And, you know, what I find is that it lets me discover things that may not be the most polarizing or engaging content. It may be sort of more boring. But I find that it's actually a better reflection of the people in our lives and, you know, what's happening out there. You know, not everything needs to be the - not everything that you'd see on social media needs to be the most engaging content. It might be beneficial to have a more, sort of, boring feed. And it's not something that other people prefer. And I've been using it myself. And I think it'll be totally fine. MARTIN: Roddy Lindsay is a former Facebook data scientist. His New York Times op-ed is titled \"I Designed Algorithms At Facebook. Here's How To Regulate Them. \" Roddy Lindsay, thanks so much for talking with us. LINDSAY: Thanks for having me. (SOUNDBITE OF MUSIC)", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-10-11-1045084676": {"title": "Facebook is under new scrutiny for it's role in Ethiopia's conflict : NPR", "url": "https://www.npr.org/2021/10/11/1045084676/facebook-is-under-new-scrutiny-for-its-role-in-ethiopias-conflict", "author": "No author found", "published_date": "2021-10-11", "content": "AUDIE CORNISH, HOST:  Hate and division on Facebook are not just a problem in the U. S. That's one of the messages whistleblower Frances Haugen took to Congress last week, where she accused Facebook's algorithms of quote, \"literally fanning ethnic violence in Ethiopia,\" a country that's endured nearly a year of civil war. (SOUNDBITE OF ARCHIVED RECORDING)FRANCES HAUGEN: My fear is that without action, divisive and extremist behaviors we see today are only the beginning. What we saw in Myanmar and are now seeing in Ethiopia are only the opening chapters of a story so terrifying, no one wants to read the end of it. CORNISH: The United Nations says millions of people have been forced from their homes. Hundreds of thousands are facing famine-like conditions because of the conflict between the Ethiopian government and Tigray rebels. Freelance journalist Zecharias Zelalem has been reporting extensively on Ethiopia, and he says he agrees with Haugen's assessment. And we'll pause here to note that Facebook is among NPR's financial supporters. Now, earlier, Zelalem described the role of social media in the conflict. ZECHARIAS ZELALEM: Just looking at the instances of documented evidence over the course of the past three years in which prominent Facebook posters would post unverified, often inflammatory posts or rhetoric that would then go on to incite mob violence, ethnic clashes, crackdowns on independent press or outspoken voices. CORNISH: Who were some of the perpetrators of this kind of violence? I mean, when you say someone posts misinformation, what could that look like that could start a mob? ZELALEM: Well, in recent times, if we're going to make reference to the ongoing conflict now, prominent members of the Ethiopian government or pro-government activists have been ramping up anti-Tigrayan rhetoric, as well as anti-journalist, anti-activist, inflammatory rhetoric targeting anyone who might be deemed critical of the Ethiopian government or critical of the Ethiopian government's narratives. This has more or less normalized the state violence that's been targeting ethnic Tigrayans over the course of the past 11 months, instilled a degree of fear amongst Ethiopian population. CORNISH: The Ethiopian government has denied ethnic cleansing accusations. Can you talk about how the conflict is upending the lives of civilians? ZELALEM: Well, I mean, the ethnic cleansing accusations are something that are very well-documented and corroborated by dozens of credible media sources and diplomatic sources, human rights organizations. At this point, 11 months into the conflict, it's not really something that's up for - it's not really something that's up for debate anymore. CORNISH: Facebook has responded to Haugen's criticisms by saying, quote, \"to suggest we encourage bad content and do nothing is just not true. \" They also talk about the idea of having to balance freedom of expression in places where people use the platform. What, if anything, is this conversation like in Ethiopia? Is anyone talking about Facebook? From your position, are they doing what they say? ZELALEM: Well, with regards to your second question, Ethiopia being a relatively authoritarian society, critical conversation is not something that's encouraged. It's something that could wind you up behind bars. So there isn't that much of an open societal debate. But I can quite honestly say that Facebook has - if it has done anything, it's not nearly enough, at least, because there have been more than enough documented incidents. I know of a very recent instance where a media outlet posted an inflammatory post blaming members of an ethnic minority for carrying out the murders and kidnappings that took place on September 27. And this Facebook post got hundreds of shares, hundreds of likes, all sorts of reaction. And a day later, on the 28 of September - so just barely two weeks ago - the village cited in the Facebook post was ransacked, burnt to the ground, inhabitants murdered. Like I said, this is very recent. This is barely two weeks ago. And despite multiple efforts to report the post, it remains up and live as of this moment. CORNISH: We've been speaking to journalist Zecharias Zelalem. Thank you for sharing your reporting. ZELALEM: Thank you for having me. CORNISH: We reached out to Facebook. They told NPR that Ethiopia is a company priority and that it has worked to improve proactive detection to remove more harmful content at scale. AUDIE CORNISH, HOST:   Hate and division on Facebook are not just a problem in the U. S. That's one of the messages whistleblower Frances Haugen took to Congress last week, where she accused Facebook's algorithms of quote, \"literally fanning ethnic violence in Ethiopia,\" a country that's endured nearly a year of civil war. (SOUNDBITE OF ARCHIVED RECORDING) FRANCES HAUGEN: My fear is that without action, divisive and extremist behaviors we see today are only the beginning. What we saw in Myanmar and are now seeing in Ethiopia are only the opening chapters of a story so terrifying, no one wants to read the end of it. CORNISH: The United Nations says millions of people have been forced from their homes. Hundreds of thousands are facing famine-like conditions because of the conflict between the Ethiopian government and Tigray rebels. Freelance journalist Zecharias Zelalem has been reporting extensively on Ethiopia, and he says he agrees with Haugen's assessment. And we'll pause here to note that Facebook is among NPR's financial supporters. Now, earlier, Zelalem described the role of social media in the conflict. ZECHARIAS ZELALEM: Just looking at the instances of documented evidence over the course of the past three years in which prominent Facebook posters would post unverified, often inflammatory posts or rhetoric that would then go on to incite mob violence, ethnic clashes, crackdowns on independent press or outspoken voices. CORNISH: Who were some of the perpetrators of this kind of violence? I mean, when you say someone posts misinformation, what could that look like that could start a mob? ZELALEM: Well, in recent times, if we're going to make reference to the ongoing conflict now, prominent members of the Ethiopian government or pro-government activists have been ramping up anti-Tigrayan rhetoric, as well as anti-journalist, anti-activist, inflammatory rhetoric targeting anyone who might be deemed critical of the Ethiopian government or critical of the Ethiopian government's narratives. This has more or less normalized the state violence that's been targeting ethnic Tigrayans over the course of the past 11 months, instilled a degree of fear amongst Ethiopian population. CORNISH: The Ethiopian government has denied ethnic cleansing accusations. Can you talk about how the conflict is upending the lives of civilians? ZELALEM: Well, I mean, the ethnic cleansing accusations are something that are very well-documented and corroborated by dozens of credible media sources and diplomatic sources, human rights organizations. At this point, 11 months into the conflict, it's not really something that's up for - it's not really something that's up for debate anymore. CORNISH: Facebook has responded to Haugen's criticisms by saying, quote, \"to suggest we encourage bad content and do nothing is just not true. \" They also talk about the idea of having to balance freedom of expression in places where people use the platform. What, if anything, is this conversation like in Ethiopia? Is anyone talking about Facebook? From your position, are they doing what they say? ZELALEM: Well, with regards to your second question, Ethiopia being a relatively authoritarian society, critical conversation is not something that's encouraged. It's something that could wind you up behind bars. So there isn't that much of an open societal debate. But I can quite honestly say that Facebook has - if it has done anything, it's not nearly enough, at least, because there have been more than enough documented incidents. I know of a very recent instance where a media outlet posted an inflammatory post blaming members of an ethnic minority for carrying out the murders and kidnappings that took place on September 27. And this Facebook post got hundreds of shares, hundreds of likes, all sorts of reaction. And a day later, on the 28 of September - so just barely two weeks ago - the village cited in the Facebook post was ransacked, burnt to the ground, inhabitants murdered. Like I said, this is very recent. This is barely two weeks ago. And despite multiple efforts to report the post, it remains up and live as of this moment. CORNISH: We've been speaking to journalist Zecharias Zelalem. Thank you for sharing your reporting. ZELALEM: Thank you for having me. CORNISH: We reached out to Facebook. They told NPR that Ethiopia is a company priority and that it has worked to improve proactive detection to remove more harmful content at scale.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-10-11-1045084627": {"title": "A whistleblower spurred new calls for oversight of Facebook. Now what happens? : NPR", "url": "https://www.npr.org/2021/10/11/1045084627/a-whistleblower-spurred-new-calls-for-oversight-of-facebook-now-what-happens", "author": "No author found", "published_date": "2021-10-11", "content": "AUDIE CORNISH, HOST:  Tomorrow marks a week since Facebook whistleblower Frances Haugen testified to Congress, accusing the company of incentivizing the spread of hate and misinformation and failing to share research on its platform's negative impact on kids' mental health. (SOUNDBITE OF ARCHIVED RECORDING)FRANCES HAUGEN: Until the incentives change, Facebook will not change. Left alone, Facebook will continue to make choices that go against the common good, our common good. CORNISH: In the days since that testimony, the years-long drumbeat for Congress to take action and impose stricter regulations on social media and tech giants has grown louder. One plan includes forcing these companies to allow independent researchers to analyze its data from the platforms on which, quote, \"almost all of human experience is now taking place. \" Those are the words of Nathaniel Persily, a professor of law at Stanford Law School and director of the Stanford Cyber Policy Center. Welcome back to the program. NATHANIEL PERSILY: Thanks for having me. CORNISH: So you have actually tried your hand at drafting legislation that would allow the Federal Trade Commission to create a framework for social media companies to hand their data to outside scholars. How would this mitigate the kind of harm that Frances Haugen is describing? PERSILY: Well, we shouldn't have to wait for whistleblowers to blow their whistles before we understand what's happening inside these firms. And so one of the heroic consequences of Frances Haugen's testimony was that we got a window into some of the practices that are happening inside Facebook. But it's a rare window, and it shouldn't just be opened when employees decide to risk their futures by testifying before Congress. We really need a sort of steady stream of data that will be analyzed by independent researchers in a privacy-protected, secure way so we all understand what's actually happening on these platforms. CORNISH: What can third-party investigators do that governments can't? PERSILY: Well, the government can do a lot of this stuff, but we don't trust them to have sort of the keys to the kingdom when it comes to, you know, private posts and the like that are on these platforms. We don't want government to be sort of going into Facebook and essentially surveilling the population. We need to have a system that's set up that keeps the data with the firm, but that the reports, the inferences that are developed can be released by independent researchers who are not beholden either to the government or to Facebook or these other platforms to have that responsibility. CORNISH: The flip side is if we look back to the Cambridge Analytica scandal, that involved a firm that was improperly saving Facebook user data, right? You know, how can the government go about assuring users that none of that data, which you say is private, wouldn't be kind of misused or abused by a third party tasked with analyzing it? PERSILY: That's the key question here. And so that's why it's important that the data remain with the firm and that researchers essentially have to go there and analyze it in clean rooms and not be able to take the data outside of the facility. The data already exists there, as we've seen with Frances Haugen's testimony. The question is whether the only people who are going to be able to analyze it are those who are sort of tied to the profit-maximizing mission of the firm or whether you're going to get some independent sort of auditors or researchers to have the same ability to figure out what's going on on the platform. CORNISH: You know, last week, Facebook CEO Mark Zuckerberg wrote this long denial of Frances Haugen's claims. And part of it, he said, quote, \"The argument that we deliberately push content that makes people angry for profit is deeply illogical. \" What does your research say, and how do you hear the way he's responding to Haugen? PERSILY: Well, this is, as we academics say, an empirical question. And I should say that from the sort of snippets that we've gleaned from the outside, there's a considerable debate about the role that algorithms and that Facebook is playing in things like polarization and harmful content and the like. But we just don't know. And that's because not only are these companies economic monopolies, but they're also data monopolies. Right? They have the unique ability to analyze sort of all human experience that's happening on these platforms. And until we get access to it, we're not going to be able to answer those questions. CORNISH: So what would you do with that third-party investigation, right? Once it happens - if it happens, does the government need regulation with more teeth? Sort of, what do you envision? PERSILY: So as a first stage, we need to really set up the infrastructure for this kind of oversight - making sure that privacy of users is protected, that there's a kind of nonpartisan, vetted way for researchers to get access. And then the hope is that once you sort of unearth what's happening inside the firms, then you can develop sound policy on it, whether it's in the context of content moderation or antitrust or privacy and the like. If we actually understand what's going on in these platforms, we can develop sound policy. CORNISH: With the revelations of the last couple of weeks, we're hearing lawmakers talk about wanting to act. What are you going to be listening for that might indicate they actually are ready to? PERSILY: Well, I really want to see if they're willing to sort of seize the day here and to treat this as the emergency that it is. We can't wait four years to set up a new Cabinet agency or to draft the perfect bill. I think requiring transparency right now is a first step. But I expect that you'll see bills dealing with, you know, antitrust, competition, taxation, privacy, as well as some of the harmful content, particularly as it relates to children, pretty soon. CORNISH: Nathaniel Persily is a professor of law at Stanford Law School and director of Stanford's Cyber Policy Center. Thanks so much for speaking with us. PERSILY: Thank you. AUDIE CORNISH, HOST:   Tomorrow marks a week since Facebook whistleblower Frances Haugen testified to Congress, accusing the company of incentivizing the spread of hate and misinformation and failing to share research on its platform's negative impact on kids' mental health. (SOUNDBITE OF ARCHIVED RECORDING) FRANCES HAUGEN: Until the incentives change, Facebook will not change. Left alone, Facebook will continue to make choices that go against the common good, our common good. CORNISH: In the days since that testimony, the years-long drumbeat for Congress to take action and impose stricter regulations on social media and tech giants has grown louder. One plan includes forcing these companies to allow independent researchers to analyze its data from the platforms on which, quote, \"almost all of human experience is now taking place. \" Those are the words of Nathaniel Persily, a professor of law at Stanford Law School and director of the Stanford Cyber Policy Center. Welcome back to the program. NATHANIEL PERSILY: Thanks for having me. CORNISH: So you have actually tried your hand at drafting legislation that would allow the Federal Trade Commission to create a framework for social media companies to hand their data to outside scholars. How would this mitigate the kind of harm that Frances Haugen is describing? PERSILY: Well, we shouldn't have to wait for whistleblowers to blow their whistles before we understand what's happening inside these firms. And so one of the heroic consequences of Frances Haugen's testimony was that we got a window into some of the practices that are happening inside Facebook. But it's a rare window, and it shouldn't just be opened when employees decide to risk their futures by testifying before Congress. We really need a sort of steady stream of data that will be analyzed by independent researchers in a privacy-protected, secure way so we all understand what's actually happening on these platforms. CORNISH: What can third-party investigators do that governments can't? PERSILY: Well, the government can do a lot of this stuff, but we don't trust them to have sort of the keys to the kingdom when it comes to, you know, private posts and the like that are on these platforms. We don't want government to be sort of going into Facebook and essentially surveilling the population. We need to have a system that's set up that keeps the data with the firm, but that the reports, the inferences that are developed can be released by independent researchers who are not beholden either to the government or to Facebook or these other platforms to have that responsibility. CORNISH: The flip side is if we look back to the Cambridge Analytica scandal, that involved a firm that was improperly saving Facebook user data, right? You know, how can the government go about assuring users that none of that data, which you say is private, wouldn't be kind of misused or abused by a third party tasked with analyzing it? PERSILY: That's the key question here. And so that's why it's important that the data remain with the firm and that researchers essentially have to go there and analyze it in clean rooms and not be able to take the data outside of the facility. The data already exists there, as we've seen with Frances Haugen's testimony. The question is whether the only people who are going to be able to analyze it are those who are sort of tied to the profit-maximizing mission of the firm or whether you're going to get some independent sort of auditors or researchers to have the same ability to figure out what's going on on the platform. CORNISH: You know, last week, Facebook CEO Mark Zuckerberg wrote this long denial of Frances Haugen's claims. And part of it, he said, quote, \"The argument that we deliberately push content that makes people angry for profit is deeply illogical. \" What does your research say, and how do you hear the way he's responding to Haugen? PERSILY: Well, this is, as we academics say, an empirical question. And I should say that from the sort of snippets that we've gleaned from the outside, there's a considerable debate about the role that algorithms and that Facebook is playing in things like polarization and harmful content and the like. But we just don't know. And that's because not only are these companies economic monopolies, but they're also data monopolies. Right? They have the unique ability to analyze sort of all human experience that's happening on these platforms. And until we get access to it, we're not going to be able to answer those questions. CORNISH: So what would you do with that third-party investigation, right? Once it happens - if it happens, does the government need regulation with more teeth? Sort of, what do you envision? PERSILY: So as a first stage, we need to really set up the infrastructure for this kind of oversight - making sure that privacy of users is protected, that there's a kind of nonpartisan, vetted way for researchers to get access. And then the hope is that once you sort of unearth what's happening inside the firms, then you can develop sound policy on it, whether it's in the context of content moderation or antitrust or privacy and the like. If we actually understand what's going on in these platforms, we can develop sound policy. CORNISH: With the revelations of the last couple of weeks, we're hearing lawmakers talk about wanting to act. What are you going to be listening for that might indicate they actually are ready to? PERSILY: Well, I really want to see if they're willing to sort of seize the day here and to treat this as the emergency that it is. We can't wait four years to set up a new Cabinet agency or to draft the perfect bill. I think requiring transparency right now is a first step. But I expect that you'll see bills dealing with, you know, antitrust, competition, taxation, privacy, as well as some of the harmful content, particularly as it relates to children, pretty soon. CORNISH: Nathaniel Persily is a professor of law at Stanford Law School and director of Stanford's Cyber Policy Center. Thanks so much for speaking with us. PERSILY: Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-10-13-1045248842": {"title": "White House brings together 30 nations to combat ransomware  : NPR", "url": "https://www.npr.org/2021/10/13/1045248842/white-house-brings-together-30-nations-to-combat-ransomware", "author": "No author found", "published_date": "2021-10-13", "content": "", "section": "National Security", "disclaimer": ""}, "2021-10-13-1045377132": {"title": "William Shatner is now the oldest person to go to space. Here's what he saw : NPR", "url": "https://www.npr.org/2021/10/13/1045377132/william-shatner-star-trek-captain-kirk-blue-origin-space-flight", "author": "No author found", "published_date": "2021-10-13", "content": "", "section": "Space", "disclaimer": ""}, "2021-10-13-1045547824": {"title": "White House organizes virtual global summit to tackle ransomware : NPR", "url": "https://www.npr.org/2021/10/13/1045547824/white-house-organizes-virtual-global-summit-to-tackle-ransomware", "author": "No author found", "published_date": "2021-10-13", "content": "A MART\u00cdNEZ, HOST:  The White House is hosting a virtual gathering with over 30 countries starting today to address the issue of ransomware. Cyber hackers are stealing and locking up important files owned by everyone from pipeline operators to local libraries. For more on this, we're joined by NPR cybersecurity correspondent Jenna McLaughlin. Jenna, so who exactly is invited to this summit? JENNA MCLAUGHLIN, BYLINE: Hi, A. So it's a big group. You've got everyone from Ukraine and Romania to the United Arab Emirates, Brazil, the list goes on. The White House says they were chosen partially because they've all had issues with ransomware, too. Ukraine, for example, is already helping hunt cybercriminals. Just a few weeks ago, the FBI partnered with international law enforcement to arrest ransomware operators. They posted a video of piles of cash on YouTube. It was a classic sting operation. International law enforcement officials tell me that there's more to come down the line. I also spoke to President Biden's deputy national security advisor for cyber and emerging technology, Anne Neuberger. She says those types of arrests are going to be top of mind this week. ANNE NEUBERGER: One of the panels will focus on disruption. And these are exactly the kinds of efforts that we have in mind. And certainly the partners who join us around the world are those where potentially there are criminal actors who are in those countries where there is experience in criminal cyber activity. MCLAUGHLIN: And, of course, there's the question of Russia, where lots of cybercriminals actually live. The White House says that Russia isn't invited this time. They haven't ruled out including them in future summits. Right now the White House is focusing on a separate channel of communication with Moscow. And they say they're seeing some progress. But they're continuing to put pressure on them. MART\u00cdNEZ: What does the Biden administration want to get out of this meeting? MCLAUGHLIN: So the White House isn't sharing a lot about specific agreements it hopes to reach before Thursday. But part of the plan definitely involves the U. S. and others helping their foreign partners get better at following the money - in this case, cryptocurrency - similar to how the Justice Department a few months ago recovered $2. 3 million from a Bitcoin wallet for Colonial Pipeline back when it got breached by criminal hackers in May. Additionally, while the White House says the meetings are led by the U. S. , other countries are taking point on different sessions. So India is going to lead a panel on digital defense. Australia will take point on the discussion on disrupting criminal hackers - while the UK and Germany will also lead panels. MART\u00cdNEZ: I think if we didn't think so a couple of years ago, this year for sure, I think we know how big of a problem ransomware is. MCLAUGHLIN: Absolutely. It's a huge challenge that everyone's been hearing about. Companies big and small can and have been victims - hospitals, towns, everyone. A recent estimate pegs payments at almost 2 million on average in 2021. And they're going after the big targets, who are the most likely to pay. It's also not the first time that national security officials have gotten interested in seemingly lowly criminals. Back in 2014 the intelligence community got involved in the Sony hack because North Korea was behind it. Now NSA Director General Nakasone is saying that ransomware is a national security threat and that the government is surging against it. MART\u00cdNEZ: Wow. Did Anne Neuberger have those same concerns? MCLAUGHLIN: She did. But she also struck a hopeful tone. She stressed that there's strength in numbers in fighting ransomware. NEUBERGER: Firstly, there's always hope out there. Now, that being said, we fight ransomware day by day. And it's something where we need many partners. We need American individuals, companies, partners around the world to fight it together. MCLAUGHLIN: And one last thing Anne Neuberger said - you should always use multifactor authentication. MART\u00cdNEZ: Not one, two, three, four, exclamation point? MCLAUGHLIN: (Laughter). MART\u00cdNEZ: That's NPR cybersecurity correspondent Jenna McLaughlin. Thanks lot. MCLAUGHLIN: Thank you. A MART\u00cdNEZ, HOST:   The White House is hosting a virtual gathering with over 30 countries starting today to address the issue of ransomware. Cyber hackers are stealing and locking up important files owned by everyone from pipeline operators to local libraries. For more on this, we're joined by NPR cybersecurity correspondent Jenna McLaughlin. Jenna, so who exactly is invited to this summit? JENNA MCLAUGHLIN, BYLINE: Hi, A. So it's a big group. You've got everyone from Ukraine and Romania to the United Arab Emirates, Brazil, the list goes on. The White House says they were chosen partially because they've all had issues with ransomware, too. Ukraine, for example, is already helping hunt cybercriminals. Just a few weeks ago, the FBI partnered with international law enforcement to arrest ransomware operators. They posted a video of piles of cash on YouTube. It was a classic sting operation. International law enforcement officials tell me that there's more to come down the line. I also spoke to President Biden's deputy national security advisor for cyber and emerging technology, Anne Neuberger. She says those types of arrests are going to be top of mind this week. ANNE NEUBERGER: One of the panels will focus on disruption. And these are exactly the kinds of efforts that we have in mind. And certainly the partners who join us around the world are those where potentially there are criminal actors who are in those countries where there is experience in criminal cyber activity. MCLAUGHLIN: And, of course, there's the question of Russia, where lots of cybercriminals actually live. The White House says that Russia isn't invited this time. They haven't ruled out including them in future summits. Right now the White House is focusing on a separate channel of communication with Moscow. And they say they're seeing some progress. But they're continuing to put pressure on them. MART\u00cdNEZ: What does the Biden administration want to get out of this meeting? MCLAUGHLIN: So the White House isn't sharing a lot about specific agreements it hopes to reach before Thursday. But part of the plan definitely involves the U. S. and others helping their foreign partners get better at following the money - in this case, cryptocurrency - similar to how the Justice Department a few months ago recovered $2. 3 million from a Bitcoin wallet for Colonial Pipeline back when it got breached by criminal hackers in May. Additionally, while the White House says the meetings are led by the U. S. , other countries are taking point on different sessions. So India is going to lead a panel on digital defense. Australia will take point on the discussion on disrupting criminal hackers - while the UK and Germany will also lead panels. MART\u00cdNEZ: I think if we didn't think so a couple of years ago, this year for sure, I think we know how big of a problem ransomware is. MCLAUGHLIN: Absolutely. It's a huge challenge that everyone's been hearing about. Companies big and small can and have been victims - hospitals, towns, everyone. A recent estimate pegs payments at almost 2 million on average in 2021. And they're going after the big targets, who are the most likely to pay. It's also not the first time that national security officials have gotten interested in seemingly lowly criminals. Back in 2014 the intelligence community got involved in the Sony hack because North Korea was behind it. Now NSA Director General Nakasone is saying that ransomware is a national security threat and that the government is surging against it. MART\u00cdNEZ: Wow. Did Anne Neuberger have those same concerns? MCLAUGHLIN: She did. But she also struck a hopeful tone. She stressed that there's strength in numbers in fighting ransomware. NEUBERGER: Firstly, there's always hope out there. Now, that being said, we fight ransomware day by day. And it's something where we need many partners. We need American individuals, companies, partners around the world to fight it together. MCLAUGHLIN: And one last thing Anne Neuberger said - you should always use multifactor authentication. MART\u00cdNEZ: Not one, two, three, four, exclamation point? MCLAUGHLIN: (Laughter). MART\u00cdNEZ: That's NPR cybersecurity correspondent Jenna McLaughlin. Thanks lot. MCLAUGHLIN: Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-10-14-1046140249": {"title": "How social media has changed migration to the United States : NPR", "url": "https://www.npr.org/2021/10/14/1046140249/how-social-media-has-changed-migration-to-the-united-states", "author": "No author found", "published_date": "2021-10-14", "content": "AILSA CHANG, HOST:  For migrants traveling north to the U. S. -Mexico border from countries like Chile and Brazil, the trip has become virtually impossible without two things - a smuggler and social media. And that's where we begin this hour - with freelance reporter Luis Chaparro, who just returned from assignment on the border between Colombia and Panama. LUIS CHAPARRO: One of the craziest things was that the migrants basically board these Colombian government-sponsored boats, which are, like, huge ferries. CHANG: The migrants are on these boats because usually that's the only choice. You see; at the northern edge of Colombia, the road for tens of thousands of migrants headed to the U. S. -Mexico border - that road - it literally stops. It hits a thick jungle called the Darien Gap that was once considered impenetrable. And to get around a section of the Darien Gap, migrants pack into boats and are taken out to sea. CHAPARRO: And right in the middle of the sea, these small boats, like, fishing boats controlled by people from Clan del Golfo - you can totally tell they are smugglers. So they start taking the migrants out from the official ferry and into these fishing boats. We're talking about maybe 40 to 50 people, which is extremely dangerous to do in one of these fishing boats. CHANG: From there, Chaparro says, migrants are in the hands of the Clan Del Golfo, an organized crime group in Colombia that controls human smuggling in the area. Chaparro says to get through the rest of the dense jungle of the Darien Gap, the clan charges for everything. CHAPARRO: They charge for the water. If they get tired and they need to carry one of their backpacks. they charge for that. They charge for tents. They charge for a pair of boots to go through the Darien. They even charge for these little plastic bags to secure their passports or their important documents. CHANG: And Chaparro says in one camp he visited, the Clan del Golfo had rigged up a hot spot and charged $50 an hour for Wi-Fi, which is a ton of money, obviously, for most of these migrants. But that Wi-Fi, that smartphone - it's essential. It's like a lifeline for these migrants. Their phones are how they ask their families to send them money. They're how migrants navigate the journey. And they make sure that they always have enough money to buy new phones in case they lose their current phones. CHAPARRO: Otherwise, they're going to be stuck in the middle of ugly places like the Darien Gap. As soon as they go out, they getting in touch with the next smuggler up on the route and they say, like, OK, we're going to get - we're going to hit Guatemala in the next five days. Can you host me through Guatemala into Mexico? CHANG: In fact, the cellphone is also how migrants find these smugglers, mostly via Facebook and WhatsApp. CHAPARRO: In Facebook, they mostly use groups, finding information about the route, about if someone died or sharing U. S. news, like if Biden said something about the border, about if it's open or if it's closed or if they're taking in families. CHANG: And Chaparro says he even saw migrants recording pieces of their journey and posting them on YouTube. CHAPARRO: So they're recording most of their path through all of the country they're going through. That's how other people start watching their trek and decide, like, all right, so this was his trek. It was kind of hard, but it was doable. And I saw him on YouTube, so I'll go. CHANG: And for long stretches on the way north, these kinds of videos and messages on WhatsApp - they essentially play the role of the smuggler. Migrants often travel on their own, and smugglers will send them occasional text messages via WhatsApp to guide them remotely. Well, we're going to hear more now about how these smuggling groups use social media. And to do that, we're joined now by Nilda Garcia, who's an assistant professor at Texas A&M University. Welcome. NILDA GARCIA: Thank you. Thank you for having me. CHANG: So, Nilda, we just heard Chaparro say that migrants find smugglers via Facebook. But can you just explain exactly how do they find these smugglers? Like, say I'm in Chile, and I want to head to the U. S. Where do I even begin to look for a smuggler to help me make that journey? GARCIA: I started doing my research, and I have the same question. How do I start looking for groups if I was an immigrant? So I just went to Facebook. I started looking at groups, and it was very straightforward. If you look at groups and you describe (speaking Spanish), I want to cross the border - or you can type, trips to the United States, (speaking Spanish). Some of these groups have titles that are very straightforward. You're going to find them, right? And it is an entire business that they actually have within these groups in Facebook. CHANG: And I'm just curious. Are there literally, like, reviews posted of these groups, people offering feedback on their own experiences working with these various smugglers? GARCIA: Yes. They have different dynamics. One of them is actually someone that wants to migrate into the United States, or they want to cross the border. They're going to ask for someone, or they're going to ask for references. So a lot of people that have crossed - maybe they're going to actually say, oh, this is a guide, or, this was my guide, or, this is how I do it, or, this is how my family's doing it. And also, you cannot find people advertising their services. You're going to find people actually luring clients, right? And they're going to be advertising packages, for example, in where you can either start with the lowest one or the lowest price until a very higher price or even VIP packages. CHANG: Oh, so there's a variation of packages. So, like, the more expensive packages mean more comfortable journeys. How do the packages differ? GARCIA: Exactly. It depends also in the commodities they're going to have during this trip, right? Some of them is you have to walk maybe five days, and there's ones you'll have to walk through the desert. If you are from Central America, South America, the prices are going to go up. And the services that they provide are also different because they can either fly you in a private plane into Mexico and then smuggle you into the United States. And the further you want to go in the United States, the higher the price is going to be as well. CHANG: Right. I mean, is it even a feasible option for people to make this journey on their own, or does having the assistance of a smuggler group change the journey dramatically for these people? GARCIA: Yeah. Actually, if you look into the history of smuggling, during the '70s, it was very, like, family-based. It's small groups of people that actually were - they made a business out of this. And a lot of people did the journey by themselves. Now because of these policies of reinforcing the border, it's very, very hard for people to actually be able to cross by themselves. CHANG: Well, you know, we heard from a Border Patrol agent a few months ago who said a lot of smugglers - they guide people via WhatsApp. They don't physically accompany them. And the agents said that was actually leading to more rescues along the U. S. -Mexico border because people were ending up in these really dangerous locations. I wonder, how are you seeing the use of social media by migrants and smuggling groups - how are you seeing that use change migration? GARCIA: This is a good question. And actually, I'm writing a paper, actually, to try to find out this - like, how the dynamics have changed, if this is something that is actually increasing migration in this border. So that's a very good question. But what I see is that it has facilitated the contact of people, and I think Facebook gives them an opportunity and a bigger platform in order for them to reach more immigrants. And for immigrants, it's easier for them to connect with people that are actually offering their services. CHANG: Right. Nilda Garcia is an assistant professor at Texas A&M University. Thank you so much for joining us today. GARCIA: Thank you so much. CHANG: And just one note - Facebook is one of NPR's financial supporters. AILSA CHANG, HOST:   For migrants traveling north to the U. S. -Mexico border from countries like Chile and Brazil, the trip has become virtually impossible without two things - a smuggler and social media. And that's where we begin this hour - with freelance reporter Luis Chaparro, who just returned from assignment on the border between Colombia and Panama. LUIS CHAPARRO: One of the craziest things was that the migrants basically board these Colombian government-sponsored boats, which are, like, huge ferries. CHANG: The migrants are on these boats because usually that's the only choice. You see; at the northern edge of Colombia, the road for tens of thousands of migrants headed to the U. S. -Mexico border - that road - it literally stops. It hits a thick jungle called the Darien Gap that was once considered impenetrable. And to get around a section of the Darien Gap, migrants pack into boats and are taken out to sea. CHAPARRO: And right in the middle of the sea, these small boats, like, fishing boats controlled by people from Clan del Golfo - you can totally tell they are smugglers. So they start taking the migrants out from the official ferry and into these fishing boats. We're talking about maybe 40 to 50 people, which is extremely dangerous to do in one of these fishing boats. CHANG: From there, Chaparro says, migrants are in the hands of the Clan Del Golfo, an organized crime group in Colombia that controls human smuggling in the area. Chaparro says to get through the rest of the dense jungle of the Darien Gap, the clan charges for everything. CHAPARRO: They charge for the water. If they get tired and they need to carry one of their backpacks. they charge for that. They charge for tents. They charge for a pair of boots to go through the Darien. They even charge for these little plastic bags to secure their passports or their important documents. CHANG: And Chaparro says in one camp he visited, the Clan del Golfo had rigged up a hot spot and charged $50 an hour for Wi-Fi, which is a ton of money, obviously, for most of these migrants. But that Wi-Fi, that smartphone - it's essential. It's like a lifeline for these migrants. Their phones are how they ask their families to send them money. They're how migrants navigate the journey. And they make sure that they always have enough money to buy new phones in case they lose their current phones. CHAPARRO: Otherwise, they're going to be stuck in the middle of ugly places like the Darien Gap. As soon as they go out, they getting in touch with the next smuggler up on the route and they say, like, OK, we're going to get - we're going to hit Guatemala in the next five days. Can you host me through Guatemala into Mexico? CHANG: In fact, the cellphone is also how migrants find these smugglers, mostly via Facebook and WhatsApp. CHAPARRO: In Facebook, they mostly use groups, finding information about the route, about if someone died or sharing U. S. news, like if Biden said something about the border, about if it's open or if it's closed or if they're taking in families. CHANG: And Chaparro says he even saw migrants recording pieces of their journey and posting them on YouTube. CHAPARRO: So they're recording most of their path through all of the country they're going through. That's how other people start watching their trek and decide, like, all right, so this was his trek. It was kind of hard, but it was doable. And I saw him on YouTube, so I'll go. CHANG: And for long stretches on the way north, these kinds of videos and messages on WhatsApp - they essentially play the role of the smuggler. Migrants often travel on their own, and smugglers will send them occasional text messages via WhatsApp to guide them remotely. Well, we're going to hear more now about how these smuggling groups use social media. And to do that, we're joined now by Nilda Garcia, who's an assistant professor at Texas A&M University. Welcome. NILDA GARCIA: Thank you. Thank you for having me. CHANG: So, Nilda, we just heard Chaparro say that migrants find smugglers via Facebook. But can you just explain exactly how do they find these smugglers? Like, say I'm in Chile, and I want to head to the U. S. Where do I even begin to look for a smuggler to help me make that journey? GARCIA: I started doing my research, and I have the same question. How do I start looking for groups if I was an immigrant? So I just went to Facebook. I started looking at groups, and it was very straightforward. If you look at groups and you describe (speaking Spanish), I want to cross the border - or you can type, trips to the United States, (speaking Spanish). Some of these groups have titles that are very straightforward. You're going to find them, right? And it is an entire business that they actually have within these groups in Facebook. CHANG: And I'm just curious. Are there literally, like, reviews posted of these groups, people offering feedback on their own experiences working with these various smugglers? GARCIA: Yes. They have different dynamics. One of them is actually someone that wants to migrate into the United States, or they want to cross the border. They're going to ask for someone, or they're going to ask for references. So a lot of people that have crossed - maybe they're going to actually say, oh, this is a guide, or, this was my guide, or, this is how I do it, or, this is how my family's doing it. And also, you cannot find people advertising their services. You're going to find people actually luring clients, right? And they're going to be advertising packages, for example, in where you can either start with the lowest one or the lowest price until a very higher price or even VIP packages. CHANG: Oh, so there's a variation of packages. So, like, the more expensive packages mean more comfortable journeys. How do the packages differ? GARCIA: Exactly. It depends also in the commodities they're going to have during this trip, right? Some of them is you have to walk maybe five days, and there's ones you'll have to walk through the desert. If you are from Central America, South America, the prices are going to go up. And the services that they provide are also different because they can either fly you in a private plane into Mexico and then smuggle you into the United States. And the further you want to go in the United States, the higher the price is going to be as well. CHANG: Right. I mean, is it even a feasible option for people to make this journey on their own, or does having the assistance of a smuggler group change the journey dramatically for these people? GARCIA: Yeah. Actually, if you look into the history of smuggling, during the '70s, it was very, like, family-based. It's small groups of people that actually were - they made a business out of this. And a lot of people did the journey by themselves. Now because of these policies of reinforcing the border, it's very, very hard for people to actually be able to cross by themselves. CHANG: Well, you know, we heard from a Border Patrol agent a few months ago who said a lot of smugglers - they guide people via WhatsApp. They don't physically accompany them. And the agents said that was actually leading to more rescues along the U. S. -Mexico border because people were ending up in these really dangerous locations. I wonder, how are you seeing the use of social media by migrants and smuggling groups - how are you seeing that use change migration? GARCIA: This is a good question. And actually, I'm writing a paper, actually, to try to find out this - like, how the dynamics have changed, if this is something that is actually increasing migration in this border. So that's a very good question. But what I see is that it has facilitated the contact of people, and I think Facebook gives them an opportunity and a bigger platform in order for them to reach more immigrants. And for immigrants, it's easier for them to connect with people that are actually offering their services. CHANG: Right. Nilda Garcia is an assistant professor at Texas A&M University. Thank you so much for joining us today. GARCIA: Thank you so much. CHANG: And just one note - Facebook is one of NPR's financial supporters.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-10-14-1045889624": {"title": "Facebook is adopting new policies to address harassment against public figures : NPR", "url": "https://www.npr.org/2021/10/14/1045889624/facebook-harassment-bullying-public-figures", "author": "No author found", "published_date": "2021-10-14", "content": "", "section": "Technology", "disclaimer": ""}, "2021-10-15-1046542295": {"title": "Netflix fires employee amidst tensions over Dave Chappelle's latest special : NPR", "url": "https://www.npr.org/2021/10/15/1046542295/netflix-fires-employee-as-internal-conflicts-over-latest-dave-chappelle-special-", "author": "No author found", "published_date": "2021-10-15", "content": "", "section": "Culture", "disclaimer": ""}, "2021-10-15-1046386968": {"title": "Apple fires #AppleToo leader as part of leak probe. She says it's retaliation : NPR", "url": "https://www.npr.org/2021/10/15/1046386968/apple-fires-appletoo-leader-amid-leak-investigation", "author": "No author found", "published_date": "2021-10-15", "content": "", "section": "Technology", "disclaimer": ""}, "2021-10-15-1046106922": {"title": "Facebook accused of 'fanning ethnic violence' in Ethiopian civil war : NPR", "url": "https://www.npr.org/2021/10/15/1046106922/social-media-misinformation-stokes-a-worsening-civil-war-in-ethiopia", "author": "No author found", "published_date": "2021-10-15", "content": "", "section": "Africa", "disclaimer": ""}, "2021-10-16-1046752123": {"title": "Self-driving cars mysteriously gather in a San Francisco neighborhood : NPR", "url": "https://www.npr.org/2021/10/16/1046752123/self-driving-cars-waymo-san-francisco", "author": "No author found", "published_date": "2021-10-16", "content": "", "section": "Technology", "disclaimer": ""}, "2021-10-16-1046472928": {"title": "Salesforce CEO Marc Benioff wants companies to promote social change : NPR", "url": "https://www.npr.org/2021/10/16/1046472928/salesforce-ceo-marc-benioff-stakeholder-capitalism", "author": "No author found", "published_date": "2021-10-16", "content": "", "section": "Business", "disclaimer": ""}, "2021-10-18-1047033994": {"title": "Facebook will hire 10,000 workers in Europe to build a 'metaverse' : NPR", "url": "https://www.npr.org/2021/10/18/1047033994/facebook-metaverse-10-000-workers-europe-virtual-reality", "author": "No author found", "published_date": "2021-10-18", "content": "", "section": "Business", "disclaimer": ""}, "2021-10-18-1046994856": {"title": "House lawmakers ask Amazon to prove Bezos and other execs didn't lie to Congress : NPR", "url": "https://www.npr.org/2021/10/18/1046994856/house-lawmakers-ask-amazon-to-prove-bezos-and-other-execs-didnt-lie-to-congress", "author": "No author found", "published_date": "2021-10-18", "content": "", "section": "Business", "disclaimer": ""}, "2021-10-19-1047360268": {"title": "Here's how drones might airlift dogs stranded by the volcano in La Palma : NPR", "url": "https://www.npr.org/2021/10/19/1047360268/drone-rescue-dogs-volcano-la-palma-spain", "author": "No author found", "published_date": "2021-10-19", "content": "", "section": "Europe", "disclaimer": ""}, "2021-10-19-1047303425": {"title": "Complaints about spam texts were up 146% last year : NPR", "url": "https://www.npr.org/2021/10/19/1047303425/complaints-about-spam-texts-fcc-robocalls", "author": "No author found", "published_date": "2021-10-19", "content": "", "section": "Technology", "disclaimer": ""}, "2021-10-19-1047302978": {"title": "Bones or no bones: Noodle the pug predicts the internet's mood   : NPR", "url": "https://www.npr.org/2021/10/19/1047302978/noodles-pug-bones-no-bones-day-tiktok-mood-prediction", "author": "No author found", "published_date": "2021-10-19", "content": "", "section": "Animals", "disclaimer": ""}, "2021-10-20-1047638842": {"title": "Xbox mini fridges snapped up on presale  : NPR", "url": "https://www.npr.org/2021/10/20/1047638842/xbox-mini-fridge-sold-out-meme-target-preorder", "author": "No author found", "published_date": "2021-10-20", "content": "", "section": "Business", "disclaimer": ""}, "2021-10-20-1047384050": {"title": "Here's why China may have tested a new intercontinental hypersonic missile : NPR", "url": "https://www.npr.org/2021/10/20/1047384050/behind-murky-claim-of-a-new-hypersonic-missile-test-there-lies-a-very-real-arms-", "author": "No author found", "published_date": "2021-10-20", "content": "SARAH MCCAMMON, HOST:  China has reportedly tested a powerful new kind of weapon - a long-range hypersonic missile. NPR's Geoff Brumfiel has more on what some fear is becoming a dangerous arms race. GEOFF BRUMFIEL, BYLINE: In July, the China Academy of Launch Vehicle Technology announced the 77th launch of one of its rockets. In late August, it announced the 79th. The question is what happened to launch No. 78. According to a report in the Financial Times this past weekend, it was a secret test of a powerful new kind of hypersonic missile. JEFFREY LEWIS: I think the simplest way to imagine this weapon system is to imagine the space shuttle, put a nuclear weapon in the cargo bay and then don't bother with the landing gear. BRUMFIEL: Jeffrey Lewis is a professor at the Middlebury Institute of International Studies. This hypersonic weapon launches briefly into orbit. . . LEWIS: And it glides back to the Earth, just like the space shuttle, except for when it gets where it's going, it goes boom. BRUMFIEL: The new weapon would be significant because it could attack the U. S. from an unexpected direction - even, say, the South Pole. The Pentagon would not comment on the report, and a Chinese Foreign Ministry spokesperson said it was an experimental spacecraft, not a weapon. But China has been investing heavily in shorter-range hypersonic missiles. They skim through the upper atmosphere at more than five times the speed of sound and can also change direction during flight. Tong Zhao is with the Carnegie Endowment for International Peace in Beijing. TONG ZHAO: Given the capability for hypersonic missiles to maneuver during flight and given their rather fast speed, they can better penetrate missile defense systems. BRUMFIEL: Zhao says that China sees U. S. missile defenses as a major threat. It's been building up its stockpile of shorter-range weapons. This long-distance one, if it was in fact tested, fits into that pattern. Zhao says, in the big picture, Chinese leadership wants to protect itself from what it sees as growing U. S. aggression. ZHAO: China feels it needs a greater overall military power, including a stronger nuclear power, to basically ensure the U. S. wouldn't be able to interfere in China's internal matters. BRUMFIEL: Not everyone agrees that China's buildup of hypersonic weapons is defensive. Michael Griffin is a former undersecretary of defense for research and engineering. He says China's hypersonic arsenal allows it to expand its influence in the region. MICHAEL GRIFFIN: One can target airfields and aircraft carriers, within 15 or 20 minutes of flight time, literally thousands of kilometers away from the Chinese mainland. BRUMFIEL: That puts the U. S. , which is trying to expand its military presence in the western Pacific, at risk. Griffin says that the U. S. needs to develop and stockpile hypersonic missiles of its own to counter the Chinese threat. And if that sounds like an arms race, well. . . GRIFFIN: I'm not one to mince words - it is an arms race. And critically, we didn't start it. BRUMFIEL: But Jeffrey Lewis says a race is supposed to have a finish line. This is more like the two sides are on treadmills. LEWIS: The only victory is to be first off the treadmill. So what we need to do is find a way to exit the arms race rather than accelerate it. BRUMFIEL: One way, he believes, is for the U. S. to be more open to limits on missile defenses, which are driving the hypersonic craze. If the latest reports of this nuclear-capable, long-range Chinese weapon are true, the race seems to be speeding up for now. And the Pentagon is doing what it can to keep pace. Today, it announced it had tested parts of its own hypersonic design. Geoff Brumfiel, NPR News. SARAH MCCAMMON, HOST:   China has reportedly tested a powerful new kind of weapon - a long-range hypersonic missile. NPR's Geoff Brumfiel has more on what some fear is becoming a dangerous arms race. GEOFF BRUMFIEL, BYLINE: In July, the China Academy of Launch Vehicle Technology announced the 77th launch of one of its rockets. In late August, it announced the 79th. The question is what happened to launch No. 78. According to a report in the Financial Times this past weekend, it was a secret test of a powerful new kind of hypersonic missile. JEFFREY LEWIS: I think the simplest way to imagine this weapon system is to imagine the space shuttle, put a nuclear weapon in the cargo bay and then don't bother with the landing gear. BRUMFIEL: Jeffrey Lewis is a professor at the Middlebury Institute of International Studies. This hypersonic weapon launches briefly into orbit. . . LEWIS: And it glides back to the Earth, just like the space shuttle, except for when it gets where it's going, it goes boom. BRUMFIEL: The new weapon would be significant because it could attack the U. S. from an unexpected direction - even, say, the South Pole. The Pentagon would not comment on the report, and a Chinese Foreign Ministry spokesperson said it was an experimental spacecraft, not a weapon. But China has been investing heavily in shorter-range hypersonic missiles. They skim through the upper atmosphere at more than five times the speed of sound and can also change direction during flight. Tong Zhao is with the Carnegie Endowment for International Peace in Beijing. TONG ZHAO: Given the capability for hypersonic missiles to maneuver during flight and given their rather fast speed, they can better penetrate missile defense systems. BRUMFIEL: Zhao says that China sees U. S. missile defenses as a major threat. It's been building up its stockpile of shorter-range weapons. This long-distance one, if it was in fact tested, fits into that pattern. Zhao says, in the big picture, Chinese leadership wants to protect itself from what it sees as growing U. S. aggression. ZHAO: China feels it needs a greater overall military power, including a stronger nuclear power, to basically ensure the U. S. wouldn't be able to interfere in China's internal matters. BRUMFIEL: Not everyone agrees that China's buildup of hypersonic weapons is defensive. Michael Griffin is a former undersecretary of defense for research and engineering. He says China's hypersonic arsenal allows it to expand its influence in the region. MICHAEL GRIFFIN: One can target airfields and aircraft carriers, within 15 or 20 minutes of flight time, literally thousands of kilometers away from the Chinese mainland. BRUMFIEL: That puts the U. S. , which is trying to expand its military presence in the western Pacific, at risk. Griffin says that the U. S. needs to develop and stockpile hypersonic missiles of its own to counter the Chinese threat. And if that sounds like an arms race, well. . . GRIFFIN: I'm not one to mince words - it is an arms race. And critically, we didn't start it. BRUMFIEL: But Jeffrey Lewis says a race is supposed to have a finish line. This is more like the two sides are on treadmills. LEWIS: The only victory is to be first off the treadmill. So what we need to do is find a way to exit the arms race rather than accelerate it. BRUMFIEL: One way, he believes, is for the U. S. to be more open to limits on missile defenses, which are driving the hypersonic craze. If the latest reports of this nuclear-capable, long-range Chinese weapon are true, the race seems to be speeding up for now. And the Pentagon is doing what it can to keep pace. Today, it announced it had tested parts of its own hypersonic design. Geoff Brumfiel, NPR News.", "section": "National Security", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-10-20-1047307202": {"title": "A Netflix walkout in support of trans employees is set for Wednesday : NPR", "url": "https://www.npr.org/2021/10/20/1047307202/netflix-fired-trans-nonbinary-walkout-organizer-speaks", "author": "No author found", "published_date": "2021-10-20", "content": "SCOTT DETROW, HOST:  Workers at Netflix are expected to stage a walkout today. It's the culmination of weeks of internal backlash the streaming company has faced from its transgender and non-binary employees over comedian Dave Chappelle's latest special, \"The Closer. \" Last week, Netflix fired an unnamed employee who had helped organize today's walkout, saying they leaked internal data to an outside source. NPR's Andrew Limbong caught up with that employee, who says they were not the leaker. ANDREW LIMBONG, BYLINE: The employee resource group at Netflix representing transgender and non-binary workers sent a list of demands to the company. And nowhere does it mention Dave Chappelle, his latest special or pulling anything off of the platform. Instead, the only Netflix property mentioned is the documentary \"Disclosure\" about the history of trans representation in media, featuring transgender writers, producers and actors, such as Angelica Ross. (SOUNDBITE OF DOCUMENTARY, \"DISCLOSURE\")ANGELICA ROSS: You see a fierceness that's coming from the girls that are coming up now. That's because we understand we ain't got nothing to lose. I already done lost that job. I done lost that job. LIMBONG: Because the walkout later today is about having more - more representation among the higher-ups, more warnings, especially for transphobic content, and of course, more TV shows and movies featuring transgender and non-binary people. Here's former Netflix employee B. Pagels-Minor, one of the walkout organizers. B PAGELS-MINOR: When Netflix talks about entertaining the world, when Netflix talks about creative freedom, when Netflix talks about the cultural values of the company, if you actually apply that rubric equally to all groups, you would suspect that there would be more representation across different content types of different groups. LIMBONG: They started at Netflix as a senior data product manager for membership and finance engineering before moving on to work at the company's game launch department. Pagels-Minor also co-led the employee resource group for trans workers and was a member of one for Black employees. Netflix fired them on Thursday, alleging they leaked sensitive internal information outside the company - you know, how much was spent on the Chappelle special versus others, as well as various performance metrics. Netflix is notoriously tight-lipped about this sort of stuff. PAGELS-MINOR: I did collect the data. But I did not leak the data. LIMBONG: They add that they weren't given an opportunity to prove their case. PAGELS-MINOR: It was just kind of like, hey, you're the person. You're gone. LIMBONG: In a statement, a Netflix spokesperson said Pagels-Minor's claims aren't supported by the facts and that they wiped their device, quote, \"making any further investigation impossible. \" Pagels-Minor says there was never any investigation to begin with. But beyond the back-and-forth, actions like the walkout at Netflix later today are a part of a growing trend of white-collar workers in tech speaking up about the direction of their companies, says Alan Hyde, professor of labor and employment law at Rutgers. ALAN HYDE: They want to have a say in the kinds of business their company does, the kind of workplace culture they have, who the clients are. So these have been important demands in motivating worker unrest over the years. LIMBONG: Hyde says we've seen this movie before. Employees make a lot of noise about something. Maybe the big companies change a thing or two, offer up an apology. And then everything calms down back to normal. But in the context of this year. . . HYDE: With 10,000 John Deere workers out on strike, with bakery workers and all - this tremendous upsurge in strike activity this year, I'm less positive that we've seen this movie before. LIMBONG: It's a tricky time to be a big company juggling internal pressures along with public outcries. But it's possibly an even trickier time being an employee putting your job on the line to change the culture at a company you really believe in. Andrew Limbong, NPR News. (SOUNDBITE OF FAODAIL'S \"NORTHBOUND\") SCOTT DETROW, HOST:   Workers at Netflix are expected to stage a walkout today. It's the culmination of weeks of internal backlash the streaming company has faced from its transgender and non-binary employees over comedian Dave Chappelle's latest special, \"The Closer. \" Last week, Netflix fired an unnamed employee who had helped organize today's walkout, saying they leaked internal data to an outside source. NPR's Andrew Limbong caught up with that employee, who says they were not the leaker. ANDREW LIMBONG, BYLINE: The employee resource group at Netflix representing transgender and non-binary workers sent a list of demands to the company. And nowhere does it mention Dave Chappelle, his latest special or pulling anything off of the platform. Instead, the only Netflix property mentioned is the documentary \"Disclosure\" about the history of trans representation in media, featuring transgender writers, producers and actors, such as Angelica Ross. (SOUNDBITE OF DOCUMENTARY, \"DISCLOSURE\") ANGELICA ROSS: You see a fierceness that's coming from the girls that are coming up now. That's because we understand we ain't got nothing to lose. I already done lost that job. I done lost that job. LIMBONG: Because the walkout later today is about having more - more representation among the higher-ups, more warnings, especially for transphobic content, and of course, more TV shows and movies featuring transgender and non-binary people. Here's former Netflix employee B. Pagels-Minor, one of the walkout organizers. B PAGELS-MINOR: When Netflix talks about entertaining the world, when Netflix talks about creative freedom, when Netflix talks about the cultural values of the company, if you actually apply that rubric equally to all groups, you would suspect that there would be more representation across different content types of different groups. LIMBONG: They started at Netflix as a senior data product manager for membership and finance engineering before moving on to work at the company's game launch department. Pagels-Minor also co-led the employee resource group for trans workers and was a member of one for Black employees. Netflix fired them on Thursday, alleging they leaked sensitive internal information outside the company - you know, how much was spent on the Chappelle special versus others, as well as various performance metrics. Netflix is notoriously tight-lipped about this sort of stuff. PAGELS-MINOR: I did collect the data. But I did not leak the data. LIMBONG: They add that they weren't given an opportunity to prove their case. PAGELS-MINOR: It was just kind of like, hey, you're the person. You're gone. LIMBONG: In a statement, a Netflix spokesperson said Pagels-Minor's claims aren't supported by the facts and that they wiped their device, quote, \"making any further investigation impossible. \" Pagels-Minor says there was never any investigation to begin with. But beyond the back-and-forth, actions like the walkout at Netflix later today are a part of a growing trend of white-collar workers in tech speaking up about the direction of their companies, says Alan Hyde, professor of labor and employment law at Rutgers. ALAN HYDE: They want to have a say in the kinds of business their company does, the kind of workplace culture they have, who the clients are. So these have been important demands in motivating worker unrest over the years. LIMBONG: Hyde says we've seen this movie before. Employees make a lot of noise about something. Maybe the big companies change a thing or two, offer up an apology. And then everything calms down back to normal. But in the context of this year. . . HYDE: With 10,000 John Deere workers out on strike, with bakery workers and all - this tremendous upsurge in strike activity this year, I'm less positive that we've seen this movie before. LIMBONG: It's a tricky time to be a big company juggling internal pressures along with public outcries. But it's possibly an even trickier time being an employee putting your job on the line to change the culture at a company you really believe in. Andrew Limbong, NPR News. (SOUNDBITE OF FAODAIL'S \"NORTHBOUND\")", "section": "Culture", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-10-21-1048038154": {"title": "From Apple to Google, tech workers say there's a cost to speaking out : NPR", "url": "https://www.npr.org/2021/10/21/1048038154/fired-apple-facebook-netflix-google-workers", "author": "No author found", "published_date": "2021-10-21", "content": "ARI SHAPIRO, HOST:  The tech industry is bringing down the hammer on its outspoken workers. Facebook has locked down internal message boards. Apple recently fired a worker who became a labor activist. Netflix terminated an employee accused of leaking documents. NPR's Bobby Allyn looks at the human cost of speaking out in the tech industry. BOBBY ALLYN, BYLINE: Former Apple employee Janneke Parrish got a message on Slack last month from her manager. JANNEKE PARRISH: I was told that I was under investigation. My devices were confiscated at that point. ALLYN: There was a leak. Someone shared with the press a company meeting with CEO Tim Cook and an internal memo. Parrish says it wasn't her, but Apple had its suspicions, then acted. PARRISH: I was told that I was being terminated for having deleted apps and files off my devices prior to turning them into the company. ALLYN: Parrish says she was targeted because of her activism. She helped organize #AppleToo, a nod to the #MeToo movement. It was a push to share anonymous accounts of Apple workers who say they were mistreated for things like alleged harassment and unequal pay. Parrish says the organizing came after numerous attempts to raise these concerns with her bosses at Apple. PARRISH: I absolutely believe that my #AppleToo involvement is at the heart of my termination. ALLYN: Apple wouldn't comment on the incident, saying they thoroughly investigate all company concerns. Across the tech industry, standoffs are intensifying. After a Facebook whistleblower shared thousands of internal documents with regulators in the press, the company reportedly began locking down its internal message boards and trying to identify other leakers. Netflix fired a trans employee whom the company said leaked confidential records. The ex-employee says that's false. But somehow, the public did learn how much Netflix paid to produce a Dave Chappelle special after some of his jokes offended transgender people. Netflix employees yesterday staged a walkout, chanting trans lives matter. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED CROWD: (Chanting) Trans lives matter. ALLYN: Chelsey Glasson is a former Google employee who left the company after blowing the whistle about what she saw as discrimination against pregnant employees. That was in 2019. And still, it's affecting her personal life and career. CHELSEY GLASSON: That holding a big tech company accountable following misconduct, observed or experienced, is truly a marathon. ALLYN: Glasson gave NPR a preview of a speech she's giving today to a small union at Google. Her message - speaking out in big tech comes with a cost - financial, mental and social. GLASSON: So to suddenly be alienated and to not have people reach out, or to people - to have people not respond to my emails and my correspondence, that's really hard. ALLYN: Glasson is now suing Google for discrimination. Google wouldn't discuss the case. These companies have long prided themselves for encouraging dissenters within their ranks. But now, more of those dissenters are emboldened to speak publicly, and that's put the companies on the defense. Silicon Valley historian Margaret O'Mara says tech workers, like employees everywhere, are using the pandemic to question the meaning of work in their lives. MARGARET O'MARA: But also, it's reflecting how enormous these companies have become. That is shifting the culture. There are more voices. There are more perspectives. There's less tolerance of just taking the executives at their word. ALLYN: Apple, Google and Netflix, all recent NPR financial supporters, wouldn't make any of their officials available for an interview. Former Apple worker Parrish says tech workers are no longer willing to take a high salary and generous perks in exchange for their loyalty. Now they want more. PARRISH: We want tech to be what it envisions itself to be. We want it to help forge that future. But the reality is that to forge the future, you have to take care of what's going on inside first. ALLYN: And what's happening on the inside is increasingly becoming an outside problem. Bobby Allyn, NPR News. (SOUNDBITE OF MUSIC) ARI SHAPIRO, HOST:   The tech industry is bringing down the hammer on its outspoken workers. Facebook has locked down internal message boards. Apple recently fired a worker who became a labor activist. Netflix terminated an employee accused of leaking documents. NPR's Bobby Allyn looks at the human cost of speaking out in the tech industry. BOBBY ALLYN, BYLINE: Former Apple employee Janneke Parrish got a message on Slack last month from her manager. JANNEKE PARRISH: I was told that I was under investigation. My devices were confiscated at that point. ALLYN: There was a leak. Someone shared with the press a company meeting with CEO Tim Cook and an internal memo. Parrish says it wasn't her, but Apple had its suspicions, then acted. PARRISH: I was told that I was being terminated for having deleted apps and files off my devices prior to turning them into the company. ALLYN: Parrish says she was targeted because of her activism. She helped organize #AppleToo, a nod to the #MeToo movement. It was a push to share anonymous accounts of Apple workers who say they were mistreated for things like alleged harassment and unequal pay. Parrish says the organizing came after numerous attempts to raise these concerns with her bosses at Apple. PARRISH: I absolutely believe that my #AppleToo involvement is at the heart of my termination. ALLYN: Apple wouldn't comment on the incident, saying they thoroughly investigate all company concerns. Across the tech industry, standoffs are intensifying. After a Facebook whistleblower shared thousands of internal documents with regulators in the press, the company reportedly began locking down its internal message boards and trying to identify other leakers. Netflix fired a trans employee whom the company said leaked confidential records. The ex-employee says that's false. But somehow, the public did learn how much Netflix paid to produce a Dave Chappelle special after some of his jokes offended transgender people. Netflix employees yesterday staged a walkout, chanting trans lives matter. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED CROWD: (Chanting) Trans lives matter. ALLYN: Chelsey Glasson is a former Google employee who left the company after blowing the whistle about what she saw as discrimination against pregnant employees. That was in 2019. And still, it's affecting her personal life and career. CHELSEY GLASSON: That holding a big tech company accountable following misconduct, observed or experienced, is truly a marathon. ALLYN: Glasson gave NPR a preview of a speech she's giving today to a small union at Google. Her message - speaking out in big tech comes with a cost - financial, mental and social. GLASSON: So to suddenly be alienated and to not have people reach out, or to people - to have people not respond to my emails and my correspondence, that's really hard. ALLYN: Glasson is now suing Google for discrimination. Google wouldn't discuss the case. These companies have long prided themselves for encouraging dissenters within their ranks. But now, more of those dissenters are emboldened to speak publicly, and that's put the companies on the defense. Silicon Valley historian Margaret O'Mara says tech workers, like employees everywhere, are using the pandemic to question the meaning of work in their lives. MARGARET O'MARA: But also, it's reflecting how enormous these companies have become. That is shifting the culture. There are more voices. There are more perspectives. There's less tolerance of just taking the executives at their word. ALLYN: Apple, Google and Netflix, all recent NPR financial supporters, wouldn't make any of their officials available for an interview. Former Apple worker Parrish says tech workers are no longer willing to take a high salary and generous perks in exchange for their loyalty. Now they want more. PARRISH: We want tech to be what it envisions itself to be. We want it to help forge that future. But the reality is that to forge the future, you have to take care of what's going on inside first. ALLYN: And what's happening on the inside is increasingly becoming an outside problem. Bobby Allyn, NPR News. (SOUNDBITE OF MUSIC)", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-10-21-1047950886": {"title": "Amazon warehouse workers on Staten Island push for union vote  : NPR", "url": "https://www.npr.org/2021/10/21/1047950886/amazon-warehouse-workers-on-staten-island-union-vote-alabama", "author": "No author found", "published_date": "2021-10-21", "content": "", "section": "Business", "disclaimer": ""}, "2021-10-21-1047928585": {"title": "Oversight Board slams Facebook for giving special treatment to high-profile users : NPR", "url": "https://www.npr.org/2021/10/21/1047928585/oversight-board-slams-facebook-for-giving-special-treatment-to-vip-users", "author": "No author found", "published_date": "2021-10-21", "content": "", "section": "Technology", "disclaimer": ""}, "2021-10-22-1048543513": {"title": "The Facebook whistleblower's documents show how 'Stop the Steal' evaded monitors : NPR", "url": "https://www.npr.org/2021/10/22/1048543513/facebook-groups-jan-6-insurrection", "author": "No author found", "published_date": "2021-10-22", "content": "SCOTT SIMON, HOST:  We begin the hour with fallout from the Facebook files. Internal documents show that Facebook employees raised the alarm about Stop the Steal, the rallying cry of that false claim that, somehow, the presidential election had been stolen from Donald Trump. That cry turned into a rally which turned into a deadly attack on Congress and the vice president and on democracy. NPR's tech correspondent Shannon Bond joins us. And we will note Facebook is among NPR's recent financial supporters. Shannon, thanks so much for being with us. SHANNON BOND, BYLINE: Thanks for having me, Scott. SIMON: You have been looking at internal documents from Facebook. What do they show? BOND: Well, we know Facebook spent years preparing for the 2020 election. It didn't want a repeat of what happened in 2016 - of course, when Russians used the platform to interfere. So the company had this emergency playbook. It called these break-the-glass measures. There were temporary steps to keep the platform safe. So, for example, it down-ranked posts that might break its rules against violence or hate speech. It means it made them less visible to other people to give them more time to check them out before they spread widely. But like you said, the election largely went off without these big issues. And so afterwards, Facebook started to turn off a lot of these emergency measures, and the ones that did keep in place didn't turn out to work so well. SIMON: And what did that mean for the Stop the Steal movement? BOND: Well, one thing that Facebook did was to try to limit just how fast these groups - it called civic groups that are related to politics - how fast they could add new members. So it put daily limits on invitations. But the Stop the Steal groups got around that. The first Stop the Steal group Facebook took down after just two days, but more kept popping up in its place, and that kept happening. It was this game of whack-a-mole. And these organizers were also able to elude detection by choosing their words really carefully and by posting these disappearing stories. And as a result, these groups - they were filled with calls for violence, lies about election fraud. And they were growing faster than Facebook could keep up. And this left a lot of employees inside Facebook really upset. These were researchers and folks who work on keeping the platform safe. And they had been warning, these documents show, that civic groups especially were a problem that Facebook needed to crack down on. But they said leadership just didn't take these warnings seriously enough. So, you know, on January 6, one wrote on Facebook's internal message board, quote, \"Rank-and-file workers have done their part to identify changes to improve our platform but have been actively held back. \" Some people I spoke to who have since left the company said, you know, Facebook really should have kept these emergency measures in place much longer after the election or even made permanent changes to how it works. SIMON: And what does Facebook say now? BOND: Well, the company says, look. The blame for January 6 lies with the people who stormed the Capitol and with the people who encouraged the violence. It says it took a lot of steps to protect its platform, and it's proud of the work it did. And when it comes to, you know, what it could have done, what it should have done - Facebook says, look. These emergency guardrails, these break-the-glass measures are blunt instruments with big trade-offs. Of course, if you slow down the platform for these bad groups, you'll also have to slow it down for everybody else. You know, that has an impact on growth. And Facebook is trying to strike this balance, right? It says it doesn't want its platform to be used to incite violence. It also doesn't want to be seen as censoring people, which, of course, is something Republicans and Donald Trump accuse it of doing. SIMON: Shannon, you've based your reporting on internal research and messages and documents. Please tell us how you got those. BOND: That's right. So recently, you know, we've heard about a former employee named Frances Haugen, who's come forward as a whistleblower. She worked on a team protecting the platform and left Facebook earlier this year with this trove of thousands of pages of internal documents. She says she came forward because she thinks Facebook is not making the right trade-offs when it comes to safety versus growth. So she turned those documents over to federal regulators, to Congress. They were also shared to a consortium of news organizations, including NPR. And I should say that Facebook widely disputes her claims. SIMON: NPR's Shannon Bond, thanks so much. BOND: Thank you. SCOTT SIMON, HOST:   We begin the hour with fallout from the Facebook files. Internal documents show that Facebook employees raised the alarm about Stop the Steal, the rallying cry of that false claim that, somehow, the presidential election had been stolen from Donald Trump. That cry turned into a rally which turned into a deadly attack on Congress and the vice president and on democracy. NPR's tech correspondent Shannon Bond joins us. And we will note Facebook is among NPR's recent financial supporters. Shannon, thanks so much for being with us. SHANNON BOND, BYLINE: Thanks for having me, Scott. SIMON: You have been looking at internal documents from Facebook. What do they show? BOND: Well, we know Facebook spent years preparing for the 2020 election. It didn't want a repeat of what happened in 2016 - of course, when Russians used the platform to interfere. So the company had this emergency playbook. It called these break-the-glass measures. There were temporary steps to keep the platform safe. So, for example, it down-ranked posts that might break its rules against violence or hate speech. It means it made them less visible to other people to give them more time to check them out before they spread widely. But like you said, the election largely went off without these big issues. And so afterwards, Facebook started to turn off a lot of these emergency measures, and the ones that did keep in place didn't turn out to work so well. SIMON: And what did that mean for the Stop the Steal movement? BOND: Well, one thing that Facebook did was to try to limit just how fast these groups - it called civic groups that are related to politics - how fast they could add new members. So it put daily limits on invitations. But the Stop the Steal groups got around that. The first Stop the Steal group Facebook took down after just two days, but more kept popping up in its place, and that kept happening. It was this game of whack-a-mole. And these organizers were also able to elude detection by choosing their words really carefully and by posting these disappearing stories. And as a result, these groups - they were filled with calls for violence, lies about election fraud. And they were growing faster than Facebook could keep up. And this left a lot of employees inside Facebook really upset. These were researchers and folks who work on keeping the platform safe. And they had been warning, these documents show, that civic groups especially were a problem that Facebook needed to crack down on. But they said leadership just didn't take these warnings seriously enough. So, you know, on January 6, one wrote on Facebook's internal message board, quote, \"Rank-and-file workers have done their part to identify changes to improve our platform but have been actively held back. \" Some people I spoke to who have since left the company said, you know, Facebook really should have kept these emergency measures in place much longer after the election or even made permanent changes to how it works. SIMON: And what does Facebook say now? BOND: Well, the company says, look. The blame for January 6 lies with the people who stormed the Capitol and with the people who encouraged the violence. It says it took a lot of steps to protect its platform, and it's proud of the work it did. And when it comes to, you know, what it could have done, what it should have done - Facebook says, look. These emergency guardrails, these break-the-glass measures are blunt instruments with big trade-offs. Of course, if you slow down the platform for these bad groups, you'll also have to slow it down for everybody else. You know, that has an impact on growth. And Facebook is trying to strike this balance, right? It says it doesn't want its platform to be used to incite violence. It also doesn't want to be seen as censoring people, which, of course, is something Republicans and Donald Trump accuse it of doing. SIMON: Shannon, you've based your reporting on internal research and messages and documents. Please tell us how you got those. BOND: That's right. So recently, you know, we've heard about a former employee named Frances Haugen, who's come forward as a whistleblower. She worked on a team protecting the platform and left Facebook earlier this year with this trove of thousands of pages of internal documents. She says she came forward because she thinks Facebook is not making the right trade-offs when it comes to safety versus growth. So she turned those documents over to federal regulators, to Congress. They were also shared to a consortium of news organizations, including NPR. And I should say that Facebook widely disputes her claims. SIMON: NPR's Shannon Bond, thanks so much. BOND: Thank you.", "section": "Untangling Disinformation", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-10-22-1048464033": {"title": "'Haunted Chocolatier' is the new game from 'Stardew Valley' creator ConcernedApe : NPR", "url": "https://www.npr.org/2021/10/22/1048464033/stardew-valley-creator-new-game-haunted-chocolatier", "author": "No author found", "published_date": "2021-10-22", "content": "", "section": "Gaming", "disclaimer": ""}, "2021-10-23-1048746697": {"title": "Facebook dithered in curbing divisive user content in India : NPR", "url": "https://www.npr.org/2021/10/23/1048746697/facebook-misinformation-india", "author": "No author found", "published_date": "2021-10-23", "content": "", "section": "Technology", "disclaimer": ""}, "2021-10-23-1048723026": {"title": "What does the future of driverless cars look like? : NPR", "url": "https://www.npr.org/2021/10/23/1048723026/what-does-the-future-of-driverless-cars-look-like", "author": "No author found", "published_date": "2021-10-23", "content": "DAVID FOLKENFLIK, HOST:  And finally today, in the near future, residents of Seattle may well be startled as they notice a fleet of new cars cruising down the city streets. These are to be cars without drivers behind the wheel. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED NEWS ANCHOR: (Laughter) It looks like a - maybe like a bus from the front and a toaster on the side. FOLKENFLIK: That's a local news anchor commenting on Amazon's autonomous car unit, Zoox, which will soon start test driving downtown there. Zoox engineers say the city's wet, windy and congested streets are the ideal testing ground for what are being called robotaxis. Their aim is to one day deploy a fleet of driverless taxis. Advocates for these cars say they'll solve a ton of problems, like reducing collisions and carbon emissions. Critics are casting doubts about how safe these vehicles are and questioned the motives propelling the embrace of this technology by tech giants. Someone who has studied and written about this issue is Peter Norton. He's the author of \"Autonorama: The Illusory Promise Of High-Tech Driving,\" and he teaches history in the Department of Engineering and Society at the University of Virginia. Peter Norton, thanks so much for being with us today. PETER NORTON: It's great to be here. FOLKENFLIK: Before we jump into the debate around these cars, Professor Norton, can you explain just what a driverless car is and how it works? NORTON: Well, it's a car where the steering, the braking and the other basic driving operations are performed by robotics, which is a combination of software, computers and hardware. And it's guided by sensors instead of human vision to detect what's around it and navigate through space that way. FOLKENFLIK: So what's the broader appeal here? NORTON: Well, you know, the promises - and I underline that this is a promise and not a reality - is that this will be primarily safer, that it will be less expensive for the operators because they won't have to eventually pay a human driver to be in the vehicle. Some companies also make claims about congestion relief, which really don't appear to be standing up at all. But that's the appeal. FOLKENFLIK: Take a moment. Let's drill down. Companies such as Zoox claim these driverless cars will improve traffic and mobility in urban areas like Seattle. You just said it doesn't really hold up. Why? NORTON: Well, I mean, you have to take it a piece at a time. Take safety, for example. One of the things that Zoox is claiming is that their vehicles will be safer. And the usual explanation is that these vehicles will not be susceptible to all the human feelings that human drivers have, like distraction, fatigue, impatience and so on, which is all true. But what they tend not to point out is that the vehicles are also susceptible to deficiencies that robotic drivers have that humans don't, discriminating between, say, a pedestrian waiting at the curb to cross the street and a pedestrian who's just, you know, looking in a store window. That's a hard thing for a robotic system to distinguish but something that human beings are very good at distinguishing. FOLKENFLIK: Based on your research, how would you characterize the environmental impacts of these self-driving cars versus, you know, prototypical human-driven counterparts? NORTON: Basically, all of the visions for autonomous vehicle futures have them being battery electric vehicles. And so there's an obvious advantage to electric vehicles over combustion engine vehicles. They're definitely cleaner. It depends a lot on the power grid that they're charged from. But there's also the problem of batteries. The world is going to be really straining to get the lithium, the cobalt, the nickel that it needs for these batteries. And there's some very high human and environmental costs that come with that as well, most notoriously in the Democratic Republic of the Congo, where 70-some percent of the cobalt comes from for the lithium ion batteries. And the labor conditions there are quite appalling. FOLKENFLIK: When this conversation was first suggested by one of my colleagues, what came to mind first was a string of past incidents in which driverless cars caused real-life harm to real people, to pedestrians in particular. There's one in 2018 where one of Uber's autonomous cars struck and killed a woman in Arizona. How much improvement have we seen on the technology side over the past few years? NORTON: So the answer to that is mixed. Machine learning is helping these cars perform better all the time. And so in that sense, there is steady improvement. The thing that hasn't changed at all is that the vehicles are going to have a bias that favors the experience of the vehicle's occupants, you know? They need to have people who are willing to pay money to get in one of these vehicles. And to be willing to pay money to get in a vehicle, you want to be sure that the vehicle gets you somewhere fairly soon and isn't constantly breaking on the small chance that it's detected something that might be a human being or something with a human being in or on it. In Seattle, of course, there are going to be pedestrians. And if they want to have it being a paying business proposition, the vehicles will have to take chances or be so slow and break so often that no one will be willing to pay to ride in them. FOLKENFLIK: Let's flash forward, say, 50 years from now or more. Assuming we're living in a society recognizable to the way we live now, people still need to get from A to B or A to B to C. What does that look like? How do we get there? NORTON: Well, I mean, what I do look forward to is a future where we have choices we don't have now, where - for example, if you live in a typical American suburb, you probably can't walk to a grocery store. And that's probably because your suburb is zoned for single-family residences only. But if we just relaxed our zoning rules, then it would be possible for people to actually walk for practical purposes, which was, of course, the primary mode of transportation for most people throughout history. For very low cost, we can make cityscapes that are bikeable, and we can learn from other countries where bikes are part of a public transit network, where you can take the bike to the train station, leave your bike there. And when you get to your destination train station, there's a public transport bike that you can pick up with the same card you used to ride the train. These are things we can do now with the technology we have now. We don't have to have mind-blowing machine learning to make that kind of thing work. We don't have to ask if it's possible because we already know that it's possible. FOLKENFLIK: That's Peter Norton. He's the author of \"Autonorama: The Illusory Promise Of High-Tech Driving\" and a professor at the University of Virginia. Peter Norton, thanks for joining us. NORTON: It's been my pleasure, David. Thanks very much. (SOUNDBITE OF SPACE'S \"MAGIC FLY\") DAVID FOLKENFLIK, HOST:   And finally today, in the near future, residents of Seattle may well be startled as they notice a fleet of new cars cruising down the city streets. These are to be cars without drivers behind the wheel. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED NEWS ANCHOR: (Laughter) It looks like a - maybe like a bus from the front and a toaster on the side. FOLKENFLIK: That's a local news anchor commenting on Amazon's autonomous car unit, Zoox, which will soon start test driving downtown there. Zoox engineers say the city's wet, windy and congested streets are the ideal testing ground for what are being called robotaxis. Their aim is to one day deploy a fleet of driverless taxis. Advocates for these cars say they'll solve a ton of problems, like reducing collisions and carbon emissions. Critics are casting doubts about how safe these vehicles are and questioned the motives propelling the embrace of this technology by tech giants. Someone who has studied and written about this issue is Peter Norton. He's the author of \"Autonorama: The Illusory Promise Of High-Tech Driving,\" and he teaches history in the Department of Engineering and Society at the University of Virginia. Peter Norton, thanks so much for being with us today. PETER NORTON: It's great to be here. FOLKENFLIK: Before we jump into the debate around these cars, Professor Norton, can you explain just what a driverless car is and how it works? NORTON: Well, it's a car where the steering, the braking and the other basic driving operations are performed by robotics, which is a combination of software, computers and hardware. And it's guided by sensors instead of human vision to detect what's around it and navigate through space that way. FOLKENFLIK: So what's the broader appeal here? NORTON: Well, you know, the promises - and I underline that this is a promise and not a reality - is that this will be primarily safer, that it will be less expensive for the operators because they won't have to eventually pay a human driver to be in the vehicle. Some companies also make claims about congestion relief, which really don't appear to be standing up at all. But that's the appeal. FOLKENFLIK: Take a moment. Let's drill down. Companies such as Zoox claim these driverless cars will improve traffic and mobility in urban areas like Seattle. You just said it doesn't really hold up. Why? NORTON: Well, I mean, you have to take it a piece at a time. Take safety, for example. One of the things that Zoox is claiming is that their vehicles will be safer. And the usual explanation is that these vehicles will not be susceptible to all the human feelings that human drivers have, like distraction, fatigue, impatience and so on, which is all true. But what they tend not to point out is that the vehicles are also susceptible to deficiencies that robotic drivers have that humans don't, discriminating between, say, a pedestrian waiting at the curb to cross the street and a pedestrian who's just, you know, looking in a store window. That's a hard thing for a robotic system to distinguish but something that human beings are very good at distinguishing. FOLKENFLIK: Based on your research, how would you characterize the environmental impacts of these self-driving cars versus, you know, prototypical human-driven counterparts? NORTON: Basically, all of the visions for autonomous vehicle futures have them being battery electric vehicles. And so there's an obvious advantage to electric vehicles over combustion engine vehicles. They're definitely cleaner. It depends a lot on the power grid that they're charged from. But there's also the problem of batteries. The world is going to be really straining to get the lithium, the cobalt, the nickel that it needs for these batteries. And there's some very high human and environmental costs that come with that as well, most notoriously in the Democratic Republic of the Congo, where 70-some percent of the cobalt comes from for the lithium ion batteries. And the labor conditions there are quite appalling. FOLKENFLIK: When this conversation was first suggested by one of my colleagues, what came to mind first was a string of past incidents in which driverless cars caused real-life harm to real people, to pedestrians in particular. There's one in 2018 where one of Uber's autonomous cars struck and killed a woman in Arizona. How much improvement have we seen on the technology side over the past few years? NORTON: So the answer to that is mixed. Machine learning is helping these cars perform better all the time. And so in that sense, there is steady improvement. The thing that hasn't changed at all is that the vehicles are going to have a bias that favors the experience of the vehicle's occupants, you know? They need to have people who are willing to pay money to get in one of these vehicles. And to be willing to pay money to get in a vehicle, you want to be sure that the vehicle gets you somewhere fairly soon and isn't constantly breaking on the small chance that it's detected something that might be a human being or something with a human being in or on it. In Seattle, of course, there are going to be pedestrians. And if they want to have it being a paying business proposition, the vehicles will have to take chances or be so slow and break so often that no one will be willing to pay to ride in them. FOLKENFLIK: Let's flash forward, say, 50 years from now or more. Assuming we're living in a society recognizable to the way we live now, people still need to get from A to B or A to B to C. What does that look like? How do we get there? NORTON: Well, I mean, what I do look forward to is a future where we have choices we don't have now, where - for example, if you live in a typical American suburb, you probably can't walk to a grocery store. And that's probably because your suburb is zoned for single-family residences only. But if we just relaxed our zoning rules, then it would be possible for people to actually walk for practical purposes, which was, of course, the primary mode of transportation for most people throughout history. For very low cost, we can make cityscapes that are bikeable, and we can learn from other countries where bikes are part of a public transit network, where you can take the bike to the train station, leave your bike there. And when you get to your destination train station, there's a public transport bike that you can pick up with the same card you used to ride the train. These are things we can do now with the technology we have now. We don't have to have mind-blowing machine learning to make that kind of thing work. We don't have to ask if it's possible because we already know that it's possible. FOLKENFLIK: That's Peter Norton. He's the author of \"Autonorama: The Illusory Promise Of High-Tech Driving\" and a professor at the University of Virginia. Peter Norton, thanks for joining us. NORTON: It's been my pleasure, David. Thanks very much. (SOUNDBITE OF SPACE'S \"MAGIC FLY\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-10-23-1048706632": {"title": "Apple released the first iPod 20 years ago : NPR", "url": "https://www.npr.org/2021/10/23/1048706632/20-years-ago-the-ipod-was-born", "author": "No author found", "published_date": "2021-10-23", "content": "", "section": "Technology", "disclaimer": ""}, "2021-10-23-1048699230": {"title": "Scientists used a tiny brain implant to help a blind teacher see letters again : NPR", "url": "https://www.npr.org/2021/10/23/1048699230/scientists-used-a-tiny-brain-implant-to-help-a-blind-teacher-see-letters-again", "author": "No author found", "published_date": "2021-10-23", "content": "", "section": "Science", "disclaimer": ""}, "2021-10-25-1048918722": {"title": "Yael Eisenstat, ex-Facebook employee, says company knew for years about problems : NPR", "url": "https://www.npr.org/2021/10/25/1048918722/ex-facebook-employee-speaks-out-about-the-spread-of-false-information", "author": "No author found", "published_date": "2021-10-25", "content": "RACHEL MARTIN, HOST:  We're going to focus now on another allegation against Facebook - that the company didn't do enough to prevent extremists from organizing online and ultimately attacking the U. S. Capitol on January 6. According to the documents, Facebook did put measures in place to deal with potential violence around the 2020 election. But when a movement built on a lie got traction - it was called Stop the Steal - those measures fell short. Yael Eisenstat was the global head of elections integrity operations at Facebook in 2018. I asked her how this misinformation was allowed to spread. YAEL EISENSTAT: This is something that was years in the making and - maybe not Stop the Steal in particular, but just the fact that for years people, whether it was people like myself, people who worked in the company, researchers, journalists, outside academics had been warning the company that the way their product is working, which is to - I mean, there's multiple things here - the way they amplify certain kind of content, the way they recommend people into certain groups was causing a situation that was already amplifying some of the most extreme voices. But then you couple that with what I believe was one of their most dangerous political decisions the company made - and this was actually around the time that I was working there - to not fact-check political actors, to allow some of the biggest voices with the biggest platforms to violate their own policies, these combined to make this perfect storm. So when they talk about all the measures that they put in place to protect the elections, that doesn't override all the things that they were not doing, such as really making sure that groups weren't engaging in this kind of activity, making sure that certain political elites were not using the platform to spread lies about the election. This was going on for years. It's not something they could have stopped suddenly in three days after an election. MARTIN: So it seems like there's two issues, as you just laid them out. It's vetting the potential of any particular actor to spread lies and misinformation but also, once it's out there, taking it down, right? EISENSTAT: So even more, I mean, content moderation - what to take down and what to leave up - is extremely difficult. And yes, that is something that is on the platforms to handle because that is definitely not government's area. But how your platform is designed, how you're monetizing it, what you're allowing and what you're not, basic guardrails - that's what's really missing here. I mean, as you said, once - if you, for years, have allowed an environment where you're not holding politicians to the same standards that you're holding the rest of us to on your platform because, really, you want to preserve your power and you're not sort of reining in these algorithms and recommendation engines that are pushing people to a lot of this content, which some of the documents - I mean, this piece about Carol's journey to QAnon is the perfect example. And that's really about not wanting to harm your own growth. So you're not reining in how your recommendation engines are pushing people into some of these groups. Those two things combined around a time where we have a really volatile situation in the U. S. around our election, it's a perfect storm. And let's be clear, Facebook had years to fix this. A lot of the documents are focusing on 2019 and 2020. But this is work that many people have been trying to get them to do, including my team when I was there, for years. MARTIN: What were you met with when you raised these red flags, when you raised these concerns? EISENSTAT: Sure. So in 2018, the very first thing I tried to do was ask why we were not putting any sort of fact-checking standards into political advertising. And why I did that was it was very clear to me that advertising, first of all, maybe not the most important thing on the platform, but it's paid speech. We're putting labels on the ads to make them look even more credible. And we're giving the political actors targeting tools to target people with these messaging. And if we weren't even fact-checking that and we were allowing politicians to use advertising to sow different messages to different groups, that was dangerous. And there was no appetite. I was pushed out for these kinds of ideas and for the ideas to try to build in voter suppression plans into political advertising. There just wasn't an appetite from leadership for that. MARTIN: You think that's likely to change now with all this pressure? EISENSTAT: I think it can only change through regulation, to be honest. They have made it clear they will not self-regulate. MARTIN: Yael Eisenstat, she's Facebook's former global head of elections integrity operations for political advertising. We appreciate all of your perspective. Thank you. EISENSTAT: Thank you. RACHEL MARTIN, HOST:   We're going to focus now on another allegation against Facebook - that the company didn't do enough to prevent extremists from organizing online and ultimately attacking the U. S. Capitol on January 6. According to the documents, Facebook did put measures in place to deal with potential violence around the 2020 election. But when a movement built on a lie got traction - it was called Stop the Steal - those measures fell short. Yael Eisenstat was the global head of elections integrity operations at Facebook in 2018. I asked her how this misinformation was allowed to spread. YAEL EISENSTAT: This is something that was years in the making and - maybe not Stop the Steal in particular, but just the fact that for years people, whether it was people like myself, people who worked in the company, researchers, journalists, outside academics had been warning the company that the way their product is working, which is to - I mean, there's multiple things here - the way they amplify certain kind of content, the way they recommend people into certain groups was causing a situation that was already amplifying some of the most extreme voices. But then you couple that with what I believe was one of their most dangerous political decisions the company made - and this was actually around the time that I was working there - to not fact-check political actors, to allow some of the biggest voices with the biggest platforms to violate their own policies, these combined to make this perfect storm. So when they talk about all the measures that they put in place to protect the elections, that doesn't override all the things that they were not doing, such as really making sure that groups weren't engaging in this kind of activity, making sure that certain political elites were not using the platform to spread lies about the election. This was going on for years. It's not something they could have stopped suddenly in three days after an election. MARTIN: So it seems like there's two issues, as you just laid them out. It's vetting the potential of any particular actor to spread lies and misinformation but also, once it's out there, taking it down, right? EISENSTAT: So even more, I mean, content moderation - what to take down and what to leave up - is extremely difficult. And yes, that is something that is on the platforms to handle because that is definitely not government's area. But how your platform is designed, how you're monetizing it, what you're allowing and what you're not, basic guardrails - that's what's really missing here. I mean, as you said, once - if you, for years, have allowed an environment where you're not holding politicians to the same standards that you're holding the rest of us to on your platform because, really, you want to preserve your power and you're not sort of reining in these algorithms and recommendation engines that are pushing people to a lot of this content, which some of the documents - I mean, this piece about Carol's journey to QAnon is the perfect example. And that's really about not wanting to harm your own growth. So you're not reining in how your recommendation engines are pushing people into some of these groups. Those two things combined around a time where we have a really volatile situation in the U. S. around our election, it's a perfect storm. And let's be clear, Facebook had years to fix this. A lot of the documents are focusing on 2019 and 2020. But this is work that many people have been trying to get them to do, including my team when I was there, for years. MARTIN: What were you met with when you raised these red flags, when you raised these concerns? EISENSTAT: Sure. So in 2018, the very first thing I tried to do was ask why we were not putting any sort of fact-checking standards into political advertising. And why I did that was it was very clear to me that advertising, first of all, maybe not the most important thing on the platform, but it's paid speech. We're putting labels on the ads to make them look even more credible. And we're giving the political actors targeting tools to target people with these messaging. And if we weren't even fact-checking that and we were allowing politicians to use advertising to sow different messages to different groups, that was dangerous. And there was no appetite. I was pushed out for these kinds of ideas and for the ideas to try to build in voter suppression plans into political advertising. There just wasn't an appetite from leadership for that. MARTIN: You think that's likely to change now with all this pressure? EISENSTAT: I think it can only change through regulation, to be honest. They have made it clear they will not self-regulate. MARTIN: Yael Eisenstat, she's Facebook's former global head of elections integrity operations for political advertising. We appreciate all of your perspective. Thank you. EISENSTAT: Thank you.", "section": "Business", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-10-25-1048918715": {"title": "How the 'Stop the Steal' movement outwitted Facebook ahead of the Jan. 6 riot : NPR", "url": "https://www.npr.org/2021/10/25/1048918715/how-stop-the-steal-movement-outwitted-facebook-ahead-of-the-jan-6-riot", "author": "No author found", "published_date": "2021-10-25", "content": "RACHEL MARTIN, HOST:  Facebook is in such a bad public relations crisis right now that it's reportedly going to announce a major rebranding this week. All of this stems from leaked documents from inside the company. NPR has reviewed some of that leaked material. Among the revelations, Facebook prepared for the possibility of violence around the 2020 election, but the company did not prepare for Trump supporters who used Facebook to help organize the January 6 siege on the U. S. Capitol. For more we've got NPR tech correspondent Shannon Bond with us this morning. And just a note - Facebook is among NPR's financial supporters. Shannon, thanks for being here. SHANNON BOND, BYLINE: Thanks for having me. MARTIN: All right. So as I just noted, Facebook, according to the leaked documents, was getting ready to deal with possible violence after or around the 2020 election. What did that preparation look like? BOND: I mean, that's right. The company had spent years preparing for hacks or foreign interference. It didn't want to have a repeat of 2016. So one thing it did was roll out what it calls break-the-glass measures. This was an emergency playbook to keep the platform safe by, you know, stemming the spread of potential misinformation, calls to violence. And largely, this seemed to work. There were not major incidents on Facebook on Election Day. Employees were feeling relieved. But then in the hours after voting ended, they started noticing this group called Stop the Steal growing really quickly. And it was calling for violence, claiming the election had been stolen from Donald Trump. All of these things broke Facebook's rules. MARTIN: OK. So it's in clear violation of Facebook's own protocols. What did the company do about it? BOND: It shut down the group, but new, similar groups started popping up and growing faster than Facebook could keep up with. Some of these break-the-glass measures I mentioned tried to slow this down and tried to limit the number of people who could join groups. But it just didn't work. Meanwhile, Facebook was also rolling back a lot of the other emergency measures, sort of reducing its ability to rein in, for example, some hate speech and misinformation. It's not really clear why Facebook decided to do that at this point. But internal messages from Facebook employees show many were really upset about the decision. The company's own researchers had been warning for a long time there were big problems with what Facebook calls civic groups that are devoted to politics. One posted on Facebook's internal message board on January 6, quote, \"Rank-and-file workers have done their part to identify changes to improve our platform but have been actively held back,\" referring to management. MARTIN: So what does Facebook's management have to say about that? BOND: Says the responsibility for January 6 lies with the people who stormed the Capitol and the people who incited them, not with how Facebook handled these groups. And the company says it invested a lot in planning for the election, did a lot of work to take down harmful groups and posts and that focusing just on these break-the-glass measures doesn't capture everything else it did to protect the election. MARTIN: So your reporting is just some of what we've heard come out in recent days based on these internal Facebook documents. Can you just remind us where they came from? BOND: That's right. They came from a whistleblower named Frances Haugen who worked at Facebook until earlier this year. And when she left, she took thousands of pages of internal research, discussions, other material. She first shared them with The Wall Street Journal, also with federal regulators and Congress. And then they have been recently shared with a consortium of media outlets, including NPR. So we can expect more news stories coming about Facebook as news organizations continue to dig through this material. Haugen is testifying to U. K. Parliament today. This afternoon Facebook released its quarterly earnings. It has this big developers conference later this week. So there's plenty of time for the company to address these criticisms head-on. We will see what it has to say. MARTIN: All right. NPR's Shannon Bond. We appreciate it, Shannon. Thank you. BOND: Thanks Rachel. RACHEL MARTIN, HOST:   Facebook is in such a bad public relations crisis right now that it's reportedly going to announce a major rebranding this week. All of this stems from leaked documents from inside the company. NPR has reviewed some of that leaked material. Among the revelations, Facebook prepared for the possibility of violence around the 2020 election, but the company did not prepare for Trump supporters who used Facebook to help organize the January 6 siege on the U. S. Capitol. For more we've got NPR tech correspondent Shannon Bond with us this morning. And just a note - Facebook is among NPR's financial supporters. Shannon, thanks for being here. SHANNON BOND, BYLINE: Thanks for having me. MARTIN: All right. So as I just noted, Facebook, according to the leaked documents, was getting ready to deal with possible violence after or around the 2020 election. What did that preparation look like? BOND: I mean, that's right. The company had spent years preparing for hacks or foreign interference. It didn't want to have a repeat of 2016. So one thing it did was roll out what it calls break-the-glass measures. This was an emergency playbook to keep the platform safe by, you know, stemming the spread of potential misinformation, calls to violence. And largely, this seemed to work. There were not major incidents on Facebook on Election Day. Employees were feeling relieved. But then in the hours after voting ended, they started noticing this group called Stop the Steal growing really quickly. And it was calling for violence, claiming the election had been stolen from Donald Trump. All of these things broke Facebook's rules. MARTIN: OK. So it's in clear violation of Facebook's own protocols. What did the company do about it? BOND: It shut down the group, but new, similar groups started popping up and growing faster than Facebook could keep up with. Some of these break-the-glass measures I mentioned tried to slow this down and tried to limit the number of people who could join groups. But it just didn't work. Meanwhile, Facebook was also rolling back a lot of the other emergency measures, sort of reducing its ability to rein in, for example, some hate speech and misinformation. It's not really clear why Facebook decided to do that at this point. But internal messages from Facebook employees show many were really upset about the decision. The company's own researchers had been warning for a long time there were big problems with what Facebook calls civic groups that are devoted to politics. One posted on Facebook's internal message board on January 6, quote, \"Rank-and-file workers have done their part to identify changes to improve our platform but have been actively held back,\" referring to management. MARTIN: So what does Facebook's management have to say about that? BOND: Says the responsibility for January 6 lies with the people who stormed the Capitol and the people who incited them, not with how Facebook handled these groups. And the company says it invested a lot in planning for the election, did a lot of work to take down harmful groups and posts and that focusing just on these break-the-glass measures doesn't capture everything else it did to protect the election. MARTIN: So your reporting is just some of what we've heard come out in recent days based on these internal Facebook documents. Can you just remind us where they came from? BOND: That's right. They came from a whistleblower named Frances Haugen who worked at Facebook until earlier this year. And when she left, she took thousands of pages of internal research, discussions, other material. She first shared them with The Wall Street Journal, also with federal regulators and Congress. And then they have been recently shared with a consortium of media outlets, including NPR. So we can expect more news stories coming about Facebook as news organizations continue to dig through this material. Haugen is testifying to U. K. Parliament today. This afternoon Facebook released its quarterly earnings. It has this big developers conference later this week. So there's plenty of time for the company to address these criticisms head-on. We will see what it has to say. MARTIN: All right. NPR's Shannon Bond. We appreciate it, Shannon. Thank you. BOND: Thanks Rachel.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-10-26-1049267501": {"title": "YouTube, Snapchat and TikTok child safety hearing: 4 key takeaways : NPR", "url": "https://www.npr.org/2021/10/26/1049267501/snapchat-tiktok-youtube-congress-child-safety-hearing", "author": "No author found", "published_date": "2021-10-26", "content": "", "section": "Business", "disclaimer": ""}, "2021-10-26-1049381380": {"title": "Youtube, Snapchat and TikTok officials testify to Senators on kids' online safety : NPR", "url": "https://www.npr.org/2021/10/26/1049381380/youtube-snapchat-and-tiktok-officials-testify-to-senators-on-kids-online-safety", "author": "No author found", "published_date": "2021-10-26", "content": "AILSA CHANG, HOST:  On Capitol Hill today, senators accused social media apps of endangering teens by making it too easy for them to buy illegal drugs or be bullied or encouraging them to hurt themselves by what they see online. Here's Democrat Richard Blumenthal of Connecticut. (SOUNDBITE OF ARCHIVED RECORDING)RICHARD BLUMENTHAL: More eyeballs means more dollars. Everything that you do is to add users, especially kids, and keep them on your apps for longer. CHANG: Senator Blumenthal was addressing officials from YouTube, TikTok and Snapchat, all apps that are popular with teenagers. To talk more about the testimony today, we're joined now by NPR tech correspondent Shannon Bond. Hi, Shannon. SHANNON BOND, BYLINE: Hi, Ailsa. CHANG: All right, so tell us more about some of the specific examples that senators brought up about how these apps directly harm kids or teens. BOND: Yeah. So Minnesota Democrat Amy Klobuchar talked about talking to the mother of a teen boy who died after buying painkillers from someone on Snapchat that turned out to contain fentanyl. And, you know, Snapchat responded that, you know, this is just devastating. It's dedicated to removing all drug dealers from its platforms but also said this is not a problem unique to its app. When it came to TikTok - which probably a lot of people associate with, you know, dance videos, comedy sketches - Republicans Marsha Blackburn of Tennessee and Ted Cruz of Texas really zeroed in on national security fears. They grilled the TikTok representative about how much data it shares with China because TikTok's parent company, ByteDance, is based in Beijing. And. . . CHANG: Right. BOND: You know, TikTok says - it has long said that it stores U. S. user data outside of China. CHANG: OK. Well, YouTube is bigger than either TikTok or Snapchat, and I'm curious. What questions did senators have for YouTube? BOND: Yeah. There was a lot of focus on this idea of, you know, kids getting pulled down rabbit holes, you know, giving examples of - you know, you might look for a video about dieting tips and then be recommended extreme videos about eating disorders. YouTube says it prohibits videos that glorify or promote eating disorders, but senators came armed with lots of examples. And more broadly, lawmakers want to know how these companies' algorithms work, how they're used to get kids hooked on these apps where they risk being exposed to some really harmful content. And senators were left frustrated. You know, afterwards, Senator Blumenthal told reporters that he thought YouTube had ducked making specific commitments, though I will say all three companies did say they will share data and research. It's not really clear what that's going to look like. CHANG: OK. Well, you have mentioned senators on both sides of the aisle citing their concerns. But are lawmakers offering up any actual solutions to this? BOND: Well, there are a ton of bills in the House and the Senate right now seeking to rein in tech. And today several senators tried to pin down the companies on whether they support some of these measures. So here's Democrat Ed Markey of Massachusetts adding - asking Snapchat's Jennifer Stout what she thinks of his proposal to expand kids' privacy protections. (SOUNDBITE OF ARCHIVED RECORDING)ED MARKEY: So you've had a chance to look at the child online privacy protection update that I've introduced. It's been out there for years. Do you support it or not? JENNIFER STOUT: I think, senator, we'd love to talk to you a bit more about some of the issues. . . MARKEY: No, no. We've been talking - listen. This is just what drives us crazy. We want to talk. We want to talk. We want to talk. This bill's been out there for years, and you still don't have a view on it. BOND: And you can hear the frustration as he's talking about overhauling. . . CHANG: Yeah. BOND: . . . The law that was originally passed more than 20 years ago, before any of these companies even existed. CHANG: Well, how did these companies defend themselves throughout the hearing today? BOND: Well, look. There was a big elephant in the room today, which is, of course, Facebook. This is the same committee that heard from the Facebook whistleblower who leaked documents showing, among other things, the company has studied the harms of its Instagram app on teenagers' mental health. And so we heard all three companies today taking great pains to distance themselves from Facebook. Snapchat talked about being built differently, you know, not coming at you with a bunch of posts you might be interested in but rather opening up on a camera. YouTube talked about how it built an entirely separate app for kids under 13 that - you know, with no autoplaying videos. But Blumenthal didn't buy it. (SOUNDBITE OF ARCHIVED RECORDING)BLUMENTHAL: Being different from Facebook is not a defense. That bar is in the gutter. It's not a defense to say that you are different. What we want is not a race to the bottom but really a race to the top. BOND: And that really reflects the tone here. You know, senators are skeptical these companies have young users' best interests at heart. CHANG: OK, Shannon. So what should we be looking for next? BOND: Well, Blumenthal wants Facebook CEO Mark Zuckerberg to come testify about the whistleblower disclosures. But look, Ailsa. Overall, there's no sign that any of these companies are backing down from their focus on attracting young users. Their future depends on grabbing that generation. And Zuckerberg just yesterday said, you know, his company is refocusing on attracting users under 30. CHANG: That is NPR's Shannon Bond. Thank you, Shannon. BOND: Thank you. AILSA CHANG, HOST:   On Capitol Hill today, senators accused social media apps of endangering teens by making it too easy for them to buy illegal drugs or be bullied or encouraging them to hurt themselves by what they see online. Here's Democrat Richard Blumenthal of Connecticut. (SOUNDBITE OF ARCHIVED RECORDING) RICHARD BLUMENTHAL: More eyeballs means more dollars. Everything that you do is to add users, especially kids, and keep them on your apps for longer. CHANG: Senator Blumenthal was addressing officials from YouTube, TikTok and Snapchat, all apps that are popular with teenagers. To talk more about the testimony today, we're joined now by NPR tech correspondent Shannon Bond. Hi, Shannon. SHANNON BOND, BYLINE: Hi, Ailsa. CHANG: All right, so tell us more about some of the specific examples that senators brought up about how these apps directly harm kids or teens. BOND: Yeah. So Minnesota Democrat Amy Klobuchar talked about talking to the mother of a teen boy who died after buying painkillers from someone on Snapchat that turned out to contain fentanyl. And, you know, Snapchat responded that, you know, this is just devastating. It's dedicated to removing all drug dealers from its platforms but also said this is not a problem unique to its app. When it came to TikTok - which probably a lot of people associate with, you know, dance videos, comedy sketches - Republicans Marsha Blackburn of Tennessee and Ted Cruz of Texas really zeroed in on national security fears. They grilled the TikTok representative about how much data it shares with China because TikTok's parent company, ByteDance, is based in Beijing. And. . . CHANG: Right. BOND: You know, TikTok says - it has long said that it stores U. S. user data outside of China. CHANG: OK. Well, YouTube is bigger than either TikTok or Snapchat, and I'm curious. What questions did senators have for YouTube? BOND: Yeah. There was a lot of focus on this idea of, you know, kids getting pulled down rabbit holes, you know, giving examples of - you know, you might look for a video about dieting tips and then be recommended extreme videos about eating disorders. YouTube says it prohibits videos that glorify or promote eating disorders, but senators came armed with lots of examples. And more broadly, lawmakers want to know how these companies' algorithms work, how they're used to get kids hooked on these apps where they risk being exposed to some really harmful content. And senators were left frustrated. You know, afterwards, Senator Blumenthal told reporters that he thought YouTube had ducked making specific commitments, though I will say all three companies did say they will share data and research. It's not really clear what that's going to look like. CHANG: OK. Well, you have mentioned senators on both sides of the aisle citing their concerns. But are lawmakers offering up any actual solutions to this? BOND: Well, there are a ton of bills in the House and the Senate right now seeking to rein in tech. And today several senators tried to pin down the companies on whether they support some of these measures. So here's Democrat Ed Markey of Massachusetts adding - asking Snapchat's Jennifer Stout what she thinks of his proposal to expand kids' privacy protections. (SOUNDBITE OF ARCHIVED RECORDING) ED MARKEY: So you've had a chance to look at the child online privacy protection update that I've introduced. It's been out there for years. Do you support it or not? JENNIFER STOUT: I think, senator, we'd love to talk to you a bit more about some of the issues. . . MARKEY: No, no. We've been talking - listen. This is just what drives us crazy. We want to talk. We want to talk. We want to talk. This bill's been out there for years, and you still don't have a view on it. BOND: And you can hear the frustration as he's talking about overhauling. . . CHANG: Yeah. BOND: . . . The law that was originally passed more than 20 years ago, before any of these companies even existed. CHANG: Well, how did these companies defend themselves throughout the hearing today? BOND: Well, look. There was a big elephant in the room today, which is, of course, Facebook. This is the same committee that heard from the Facebook whistleblower who leaked documents showing, among other things, the company has studied the harms of its Instagram app on teenagers' mental health. And so we heard all three companies today taking great pains to distance themselves from Facebook. Snapchat talked about being built differently, you know, not coming at you with a bunch of posts you might be interested in but rather opening up on a camera. YouTube talked about how it built an entirely separate app for kids under 13 that - you know, with no autoplaying videos. But Blumenthal didn't buy it. (SOUNDBITE OF ARCHIVED RECORDING) BLUMENTHAL: Being different from Facebook is not a defense. That bar is in the gutter. It's not a defense to say that you are different. What we want is not a race to the bottom but really a race to the top. BOND: And that really reflects the tone here. You know, senators are skeptical these companies have young users' best interests at heart. CHANG: OK, Shannon. So what should we be looking for next? BOND: Well, Blumenthal wants Facebook CEO Mark Zuckerberg to come testify about the whistleblower disclosures. But look, Ailsa. Overall, there's no sign that any of these companies are backing down from their focus on attracting young users. Their future depends on grabbing that generation. And Zuckerberg just yesterday said, you know, his company is refocusing on attracting users under 30. CHANG: That is NPR's Shannon Bond. Thank you, Shannon. BOND: Thank you.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-10-26-1049252333": {"title": "Lost hiker on Mount Elbert ignored rescuers' calls, thinking they were spam : NPR", "url": "https://www.npr.org/2021/10/26/1049252333/lost-hiker-mount-elbert-colorado-ignored-rescuers-phone-calls", "author": "No author found", "published_date": "2021-10-26", "content": "", "section": "National", "disclaimer": ""}, "2021-10-26-1049248403": {"title": "Snapchat, TikTok, YouTube leaders to face lawmakers about child safety : NPR", "url": "https://www.npr.org/2021/10/26/1049248403/snapchat-tiktok-youtube-child-safety-hearing-congress", "author": "No author found", "published_date": "2021-10-26", "content": "", "section": "Technology", "disclaimer": ""}, "2021-10-27-1049736477": {"title": "You can now ask Google to scrub images of minors from its search results : NPR", "url": "https://www.npr.org/2021/10/27/1049736477/google-minors-remove-images-search-results", "author": "No author found", "published_date": "2021-10-27", "content": "", "section": "Technology", "disclaimer": ""}, "2021-10-27-1049570918": {"title": "The U.S. is set to appeal the U.K.'s refusal to extradite WikiLeaks' Assange : NPR", "url": "https://www.npr.org/2021/10/27/1049570918/the-u-s-is-set-to-appeal-the-u-k-s-refusal-to-extradite-wikileaks-assange", "author": "No author found", "published_date": "2021-10-27", "content": "", "section": "Law", "disclaimer": ""}, "2021-10-27-1049566231": {"title": "A cyberattack paralyzed every gas station in Iran : NPR", "url": "https://www.npr.org/2021/10/27/1049566231/irans-president-says-cyberattack-was-meant-to-create-disorder-at-gas-pumps", "author": "No author found", "published_date": "2021-10-27", "content": "", "section": "Middle East", "disclaimer": ""}, "2021-10-28-1050280500": {"title": "What is the metaverse? Here's what's behind Facebook's new name : NPR", "url": "https://www.npr.org/2021/10/28/1050280500/what-metaverse-is-and-how-it-will-work", "author": "No author found", "published_date": "2021-10-28", "content": "", "section": "Business", "disclaimer": ""}, "2021-10-28-1050177199": {"title": "Facebook changes company name to Meta as it shifts focus to building its 'metaverse' : NPR", "url": "https://www.npr.org/2021/10/28/1050177199/facebook-changes-company-name-to-meta-as-it-shifts-focus-to-building-its-metaver", "author": "No author found", "published_date": "2021-10-28", "content": "AILSA CHANG, HOST:  OK. Facebook has a new name. CEO Mark Zuckerberg announced today that the company is rebranding itself as Meta. It'll be built on a futuristic, immersive social experience known as the metaverse. (SOUNDBITE OF ARCHIVED RECORDING)MARK ZUCKERBERG: Today we're seen as a social media company, but in our DNA, we're a company that builds technology to connect people. And the metaverse is the next frontier. CHANG: The metaverse comes as the company is being widely criticized for how it's managed the products it has now, namely Facebook and Instagram. NPR's Shannon Bond covers Facebook - or, shall we say, Meta - and joins us now. Hey, Shannon. SHANNON BOND, BYLINE: Hey, Ailsa. CHANG: All right. Can you just give us the basics here? What exactly is happening to this company? BOND: Yeah. So just to be clear, like, Facebook, the social network people use - that's still going to be Facebook. What's changing is the corporate name, and that's going to change to Meta. And so you can have this company, Meta, that owns these social media apps like Facebook, Instagram, WhatsApp. And then it's also doing all of this work in virtual reality that's about building these experiences that will make up this thing they are calling the metaverse. CHANG: Right - the metaverse. What is the metaverse, Shannon? Like, why is this such a big deal to Zuckerberg? BOND: Yeah. I mean, this term comes from science fiction, but it is popular right now in Silicon Valley. And it's used to describe these sort of immersive digital experiences where, like, you can do all kinds of things in real life but online and in virtual reality, whether going to concerts, meeting with your boss, working out. This already exists to some degree with video games like Fortnite. So today Zuckerberg emceed a glitzy presentation at this Connect conference the company holds, showing it all off while also admitting this is years away in the future. What I think is also important to understand about this, though, Ailsa, is this is also about the company's need to appeal to younger people. Facebook the social network, you know, is rapidly becoming the social network for old people. The teens are on TikTok. Zuckerberg knows this. He's been trying to redirect the company to chase after younger users, both on its existing social apps and now in these new virtual experiences that they see as the future. And if they can't do that, that's a real existential problem for this company. CHANG: Absolutely. Well, with this reorganization, is Zuckerberg's role at the company changing at all? BOND: No. I mean, he was the CEO of Facebook. Now he'll be the CEO of Meta - no hill change there, right? He still holds enormous control over this company. He has the majority of voting shares. And I think we saw today his enthusiasm for this vision of the metaverse suggests he's going to be very involved, very hands-on with these new products as we've seen him be with his social network. So this is still a Mark Zuckerberg production. CHANG: OK. Well, as we said earlier, the company is in the middle of a crisis over how Facebook affects young people, as well as, you know, the extent of misinformation on its platform. So what do you make of the timing of this whole announcement? BOND: Yeah. I mean, Facebook will say this has been in the works for a while. But, right, of course, in just the last month, this company has been battered by news stories stemming from a trove of leaked internal documents. It's being questioned by Congress, by regulators, even by the U. K. parliament today. I spoke with Prashant Malaviya. He's a marketing professor at Georgetown University. And he says with everything going on, no matter what the motivation is behind this name change, it kind of just ends up looking like the company is trying to run away from all this bad stuff. PRASHANT MALAVIYA: And the question really is, you know, is the timing simply unfortunate? Or is the timing actually misguided, that they are - they think that they can actually do this in order to overcome the negativity that is surrounding them right now? BOND: And look, Ailsa. You know, this company - Facebook, Meta, whatever you want to call it - it's been through many crises of its own making. Judging by its record profits, its business has not suffered, but its brand certainly has. So I think what's certain is no matter what it's called, it's going to face the same scrutiny and criticism over everything that it builds. CHANG: And we should note that Facebook or Meta is among NPR's financial supporters. That is NPR's Shannon Bond. Thank you, Shannon. BOND: Thank you. (SOUNDBITE OF DAVID KITT'S \"HAMMER TIME\") AILSA CHANG, HOST:   OK. Facebook has a new name. CEO Mark Zuckerberg announced today that the company is rebranding itself as Meta. It'll be built on a futuristic, immersive social experience known as the metaverse. (SOUNDBITE OF ARCHIVED RECORDING) MARK ZUCKERBERG: Today we're seen as a social media company, but in our DNA, we're a company that builds technology to connect people. And the metaverse is the next frontier. CHANG: The metaverse comes as the company is being widely criticized for how it's managed the products it has now, namely Facebook and Instagram. NPR's Shannon Bond covers Facebook - or, shall we say, Meta - and joins us now. Hey, Shannon. SHANNON BOND, BYLINE: Hey, Ailsa. CHANG: All right. Can you just give us the basics here? What exactly is happening to this company? BOND: Yeah. So just to be clear, like, Facebook, the social network people use - that's still going to be Facebook. What's changing is the corporate name, and that's going to change to Meta. And so you can have this company, Meta, that owns these social media apps like Facebook, Instagram, WhatsApp. And then it's also doing all of this work in virtual reality that's about building these experiences that will make up this thing they are calling the metaverse. CHANG: Right - the metaverse. What is the metaverse, Shannon? Like, why is this such a big deal to Zuckerberg? BOND: Yeah. I mean, this term comes from science fiction, but it is popular right now in Silicon Valley. And it's used to describe these sort of immersive digital experiences where, like, you can do all kinds of things in real life but online and in virtual reality, whether going to concerts, meeting with your boss, working out. This already exists to some degree with video games like Fortnite. So today Zuckerberg emceed a glitzy presentation at this Connect conference the company holds, showing it all off while also admitting this is years away in the future. What I think is also important to understand about this, though, Ailsa, is this is also about the company's need to appeal to younger people. Facebook the social network, you know, is rapidly becoming the social network for old people. The teens are on TikTok. Zuckerberg knows this. He's been trying to redirect the company to chase after younger users, both on its existing social apps and now in these new virtual experiences that they see as the future. And if they can't do that, that's a real existential problem for this company. CHANG: Absolutely. Well, with this reorganization, is Zuckerberg's role at the company changing at all? BOND: No. I mean, he was the CEO of Facebook. Now he'll be the CEO of Meta - no hill change there, right? He still holds enormous control over this company. He has the majority of voting shares. And I think we saw today his enthusiasm for this vision of the metaverse suggests he's going to be very involved, very hands-on with these new products as we've seen him be with his social network. So this is still a Mark Zuckerberg production. CHANG: OK. Well, as we said earlier, the company is in the middle of a crisis over how Facebook affects young people, as well as, you know, the extent of misinformation on its platform. So what do you make of the timing of this whole announcement? BOND: Yeah. I mean, Facebook will say this has been in the works for a while. But, right, of course, in just the last month, this company has been battered by news stories stemming from a trove of leaked internal documents. It's being questioned by Congress, by regulators, even by the U. K. parliament today. I spoke with Prashant Malaviya. He's a marketing professor at Georgetown University. And he says with everything going on, no matter what the motivation is behind this name change, it kind of just ends up looking like the company is trying to run away from all this bad stuff. PRASHANT MALAVIYA: And the question really is, you know, is the timing simply unfortunate? Or is the timing actually misguided, that they are - they think that they can actually do this in order to overcome the negativity that is surrounding them right now? BOND: And look, Ailsa. You know, this company - Facebook, Meta, whatever you want to call it - it's been through many crises of its own making. Judging by its record profits, its business has not suffered, but its brand certainly has. So I think what's certain is no matter what it's called, it's going to face the same scrutiny and criticism over everything that it builds. CHANG: And we should note that Facebook or Meta is among NPR's financial supporters. That is NPR's Shannon Bond. Thank you, Shannon. BOND: Thank you. (SOUNDBITE OF DAVID KITT'S \"HAMMER TIME\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-10-28-1049813246": {"title": "Facebook is changing its name to Meta, Zuckerberg announces : NPR", "url": "https://www.npr.org/2021/10/28/1049813246/facebook-new-name-meta-mark-zuckerberg", "author": "No author found", "published_date": "2021-10-28", "content": "", "section": "Technology", "disclaimer": ""}, "2021-10-29-1050315385": {"title": "Keller Rinaudo: How can delivery drones save lives? : NPR", "url": "https://www.npr.org/2021/10/29/1050315385/keller-rinaudo-how-can-delivery-drones-save-lives", "author": "No author found", "published_date": "2021-10-29", "content": "", "section": "TED Radio Hour", "disclaimer": ""}, "2021-10-29-1050308981": {"title": "Erika Hamden: What does it take to send a telescope into the stratosphere? : NPR", "url": "https://www.npr.org/2021/10/29/1050308981/erika-hamden-what-does-it-take-to-send-a-telescope-into-the-stratosphere", "author": "No author found", "published_date": "2021-10-29", "content": "", "section": "TED Radio Hour", "disclaimer": ""}, "2021-10-30-1050000708": {"title": "A signal from the stars was actually from Earth : NPR", "url": "https://www.npr.org/2021/10/30/1050000708/signal-stars-proxima-centauri-mystery", "author": "No author found", "published_date": "2021-10-30", "content": "", "section": "Space", "disclaimer": ""}, "2021-10-31-1050972129": {"title": "The video game platform Roblox says it's back online after outage : NPR", "url": "https://www.npr.org/2021/10/31/1050972129/the-video-game-platform-roblox-is-still-down-but-the-company-says-it-has-a-fix", "author": "No author found", "published_date": "2021-10-31", "content": "", "section": "Technology", "disclaimer": ""}, "2021-11-01-1051215631": {"title": "Scammers are stealing identities with fake job ads : NPR", "url": "https://www.npr.org/2021/11/01/1051215631/scammers-are-stealing-identities-with-fake-job-ads", "author": "No author found", "published_date": "2021-11-01", "content": "AILSA CHANG, HOST:  A hundred thousand dollars a year to work 35 hours a week, picking up travelers as an airport shuttle driver. That sounds pretty good, right? Maybe too good to be true? Well, that's because it is. But, you know, it is a real posting that has become ubiquitous on sites like LinkedIn and Facebook, luring would-be workers during one of the biggest upheavals in the labor market in recent history. And while this posting will not lead to a job, it will likely lead to identity theft. And it's only one of many sham job ads that have been popping up lately. Cezary Podkul is a reporter with ProPublica, and he recently did a deep dive into these fake ads. He joins us now. Welcome. CEZARY PODKUL: Thanks for having me. CHANG: So I just want to start with that airport shuttle driver ad. You tracked one of those ads down. And can you just tell us, where did that quest lead you? PODKUL: I just started taking the text of it and looking around at all the different places where it was showing up. And eventually, just by looking for it and looking for it, I saw a posting on a Nigerian scam board, where people just trade messages and exchange tips on how to basically do all sorts of scams. And it was basically this script for an airport shuttle job aimed at getting people to share their driver's license, their Social Security number, and once they do that, to really reel them in and try to get as much as you can to basically get their personal details and use them to commit fraud. CHANG: Kind of scary as people are looking really, really hard for jobs right now. I mean, to take a step back, how prevalent are these job ad scams right now, would you say? PODKUL: So they're growing. We don't have a precise figure right now because it's sort of an emerging threat. One company that I talked with that's helping both the federal government and state governments safeguard against identity theft has been tracking them, and they saw something like 3,000 of these fake job ads in March. And as of when I talked to them just a few days before we published the story, it had grown to, like, 36,000. CHANG: Wow. PODKUL: So it's something that people really should be on the lookout for, especially now, since so many people are quitting their jobs or thinking about quitting or still looking for a job. CHANG: Well, as you say, all of this is happening as there's been so much churn in the labor market. Can you talk about how these job ad scams seem to have evolved as the pandemic has worn on? PODKUL: Yeah. So basically, they're looking for industries like an airport shuttle driver - right? - like, stuff where they think that people will think, OK, maybe airports are reopening - there's more traffic. Or, for example, you know, restaurants - like, another person I interviewed had fallen to a fake job ad for restaurant chain Steak 'n Shake. And as we all know, right now in the restaurant and hospitality industry, so many people have quit. There's just a lot of demand. And she was applying for what she thought was a graphic designer job that turned out to be totally fake. The other thing that they're doing that's really weird is they'll just email you out of the blue for a job that you didn't apply for. So these are just phishing scams, where they'll send you an email, saying here's a job. And it's not a job. It's just a phishing scam to get your personal information. CHANG: Well, you're segueing beautifully into the last question. I was just going to ask you, you know, what advice do you have for people who are out looking for a job now, of course, who do not want to get scammed? Beyond, like, weird, sketchy URLs, are there any other particular red flags that you can advise people to try to spot? PODKUL: Yeah. So probably the most important thing is, you know, be wary of job ads that are touting the need to verify your identity upfront, like, right at the outset. And then, you know, there's a bunch of other things - right? - looking at the URL, looking at the job posting, seeing who's posting it, googling the text of it - does it show up all over the internet in different places, right? But probably the most important thing is just to not ignore that voice, that little voice in your head that you hear sometimes when something feels off. At the very least, get a second opinion from maybe your husband, your wife, a loved one, a friend. Ask them, like, hey, is this right? Should this person be asking - should I be giving them that information? And if they say, hey, no, that seems weird, or if it just doesn't feel right to you, you know, walk away. There's plenty of jobs out there right now. The last thing you need to do is get scammed. CHANG: That is ProPublica reporter Cezary Podkul. Thank you very much for your reporting. PODKUL: Thanks for having me. And good luck job hunting, everyone. AILSA CHANG, HOST:   A hundred thousand dollars a year to work 35 hours a week, picking up travelers as an airport shuttle driver. That sounds pretty good, right? Maybe too good to be true? Well, that's because it is. But, you know, it is a real posting that has become ubiquitous on sites like LinkedIn and Facebook, luring would-be workers during one of the biggest upheavals in the labor market in recent history. And while this posting will not lead to a job, it will likely lead to identity theft. And it's only one of many sham job ads that have been popping up lately. Cezary Podkul is a reporter with ProPublica, and he recently did a deep dive into these fake ads. He joins us now. Welcome. CEZARY PODKUL: Thanks for having me. CHANG: So I just want to start with that airport shuttle driver ad. You tracked one of those ads down. And can you just tell us, where did that quest lead you? PODKUL: I just started taking the text of it and looking around at all the different places where it was showing up. And eventually, just by looking for it and looking for it, I saw a posting on a Nigerian scam board, where people just trade messages and exchange tips on how to basically do all sorts of scams. And it was basically this script for an airport shuttle job aimed at getting people to share their driver's license, their Social Security number, and once they do that, to really reel them in and try to get as much as you can to basically get their personal details and use them to commit fraud. CHANG: Kind of scary as people are looking really, really hard for jobs right now. I mean, to take a step back, how prevalent are these job ad scams right now, would you say? PODKUL: So they're growing. We don't have a precise figure right now because it's sort of an emerging threat. One company that I talked with that's helping both the federal government and state governments safeguard against identity theft has been tracking them, and they saw something like 3,000 of these fake job ads in March. And as of when I talked to them just a few days before we published the story, it had grown to, like, 36,000. CHANG: Wow. PODKUL: So it's something that people really should be on the lookout for, especially now, since so many people are quitting their jobs or thinking about quitting or still looking for a job. CHANG: Well, as you say, all of this is happening as there's been so much churn in the labor market. Can you talk about how these job ad scams seem to have evolved as the pandemic has worn on? PODKUL: Yeah. So basically, they're looking for industries like an airport shuttle driver - right? - like, stuff where they think that people will think, OK, maybe airports are reopening - there's more traffic. Or, for example, you know, restaurants - like, another person I interviewed had fallen to a fake job ad for restaurant chain Steak 'n Shake. And as we all know, right now in the restaurant and hospitality industry, so many people have quit. There's just a lot of demand. And she was applying for what she thought was a graphic designer job that turned out to be totally fake. The other thing that they're doing that's really weird is they'll just email you out of the blue for a job that you didn't apply for. So these are just phishing scams, where they'll send you an email, saying here's a job. And it's not a job. It's just a phishing scam to get your personal information. CHANG: Well, you're segueing beautifully into the last question. I was just going to ask you, you know, what advice do you have for people who are out looking for a job now, of course, who do not want to get scammed? Beyond, like, weird, sketchy URLs, are there any other particular red flags that you can advise people to try to spot? PODKUL: Yeah. So probably the most important thing is, you know, be wary of job ads that are touting the need to verify your identity upfront, like, right at the outset. And then, you know, there's a bunch of other things - right? - looking at the URL, looking at the job posting, seeing who's posting it, googling the text of it - does it show up all over the internet in different places, right? But probably the most important thing is just to not ignore that voice, that little voice in your head that you hear sometimes when something feels off. At the very least, get a second opinion from maybe your husband, your wife, a loved one, a friend. Ask them, like, hey, is this right? Should this person be asking - should I be giving them that information? And if they say, hey, no, that seems weird, or if it just doesn't feel right to you, you know, walk away. There's plenty of jobs out there right now. The last thing you need to do is get scammed. CHANG: That is ProPublica reporter Cezary Podkul. Thank you very much for your reporting. PODKUL: Thanks for having me. And good luck job hunting, everyone.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-11-01-1051215567": {"title": "Hackers threaten to expose the user database of an Israeli LBGTQ dating site : NPR", "url": "https://www.npr.org/2021/11/01/1051215567/hackers-threaten-to-expose-the-user-database-of-an-israeli-lbgtq-dating-site", "author": "No author found", "published_date": "2021-11-01", "content": "AUDIE CORNISH, HOST:  Users of an LGBTQ dating site in Israel are on edge after a cyberattack there. Hackers have leaked some user data already and are threatening to expose more unless they're paid a million dollars. NPR's Daniel Estrin reports from Jerusalem. DANIEL ESTRIN, BYLINE: The hacking group Black Shadow has hit Israeli websites before but none as personal as Atraf, Israel's most prominent LGBTQ dating site, used primarily by gay men. This weekend, the hackers leaked a sample list of 1,000 users, including cellphone numbers, email addresses, sexual preferences and HIV status. They leaked it on their channel on the messaging app Telegram and threatened to post the entire user database sometime Tuesday if they're not paid a ransom. HILA PEER: And this is definitely a social crisis for the LGBTQ community in Israel. ESTRIN: Hila Peer is with the Aguda, an Israeli LGBTQ advocacy group. They've been fielding calls from users whose data was exposed. And they've heard from users in the closet from communities not welcoming of their sexuality, afraid they could be next. Telegram has been trying to block the hackers' accounts at Israel's request. PEER: So we're hoping Telegram will continue to cooperate with us 'cause this is really life-threatening for all those people potentially being outed. ESTRIN: Gil Missing, spokesman of the cybersecurity company Check Point, says the Black Shadow hackers appear to be located in Iran. GIL MESSING: Black Shadow uses a code that is duplicating or identical to codes that were used by attacks that originated from Iran. But it should be stressed that hackers that operated from Iran is not necessarily government entities or proxies of the government. ESTRIN: Israel's cybersecurity directorate said it warned the dating site it was vulnerable. The company tells NPR they have not paid the hackers' ransom and are consulting the Israeli government about what to do next. The clock is ticking. Daniel Estrin, NPR News, Jerusalem. (SOUNDBITE OF MUSIC) AUDIE CORNISH, HOST:   Users of an LGBTQ dating site in Israel are on edge after a cyberattack there. Hackers have leaked some user data already and are threatening to expose more unless they're paid a million dollars. NPR's Daniel Estrin reports from Jerusalem. DANIEL ESTRIN, BYLINE: The hacking group Black Shadow has hit Israeli websites before but none as personal as Atraf, Israel's most prominent LGBTQ dating site, used primarily by gay men. This weekend, the hackers leaked a sample list of 1,000 users, including cellphone numbers, email addresses, sexual preferences and HIV status. They leaked it on their channel on the messaging app Telegram and threatened to post the entire user database sometime Tuesday if they're not paid a ransom. HILA PEER: And this is definitely a social crisis for the LGBTQ community in Israel. ESTRIN: Hila Peer is with the Aguda, an Israeli LGBTQ advocacy group. They've been fielding calls from users whose data was exposed. And they've heard from users in the closet from communities not welcoming of their sexuality, afraid they could be next. Telegram has been trying to block the hackers' accounts at Israel's request. PEER: So we're hoping Telegram will continue to cooperate with us 'cause this is really life-threatening for all those people potentially being outed. ESTRIN: Gil Missing, spokesman of the cybersecurity company Check Point, says the Black Shadow hackers appear to be located in Iran. GIL MESSING: Black Shadow uses a code that is duplicating or identical to codes that were used by attacks that originated from Iran. But it should be stressed that hackers that operated from Iran is not necessarily government entities or proxies of the government. ESTRIN: Israel's cybersecurity directorate said it warned the dating site it was vulnerable. The company tells NPR they have not paid the hackers' ransom and are consulting the Israeli government about what to do next. The clock is ticking. Daniel Estrin, NPR News, Jerusalem. (SOUNDBITE OF MUSIC)", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-11-02-1051504165": {"title": "Facebook to delete users' facial-recognition data after privacy complaints : NPR", "url": "https://www.npr.org/2021/11/02/1051504165/facebook-delete-facial-recognition-data-privacy", "author": "No author found", "published_date": "2021-11-02", "content": "", "section": "Technology", "disclaimer": ""}, "2021-11-02-1051365892": {"title": "Mastercard unveils a new bank card to help blind customers : NPR", "url": "https://www.npr.org/2021/11/02/1051365892/mastercard-unveils-new-card-feature-to-help-blind-customers", "author": "No author found", "published_date": "2021-11-02", "content": "", "section": "Business", "disclaimer": ""}, "2021-11-03-1051289009": {"title": "Ordering food on an app is easy. Delivering it could mean injury and theft : NPR", "url": "https://www.npr.org/2021/11/03/1051289009/nyc-delivery-workers-risk-safety-to-bring-dinner", "author": "No author found", "published_date": "2021-11-03", "content": "", "section": "Technology", "disclaimer": ""}, "2021-11-03-1051773745": {"title": "A 14-year-old boy devises a computer program to make apps run faster : NPR", "url": "https://www.npr.org/2021/11/03/1051773745/a-14-year-old-boy-devises-a-computer-program-to-make-apps-run-faster", "author": "No author found", "published_date": "2021-11-03", "content": "NOEL KING, HOST:  Good morning. I'm Noel King. Fourteen-year-old Akilan Sankaran is on his school's track team. He plays the piano, the flute and the drums. And yet he still found time to devise a computer program that makes your apps run faster. His program calculates anti-prime numbers, which are used in everyday software, and his discoveries won him the top prize in the Broadcom Masters, which is an engineering competition for middle school kids. His next goal is to become an astrophysicist. It's MORNING EDITION. NOEL KING, HOST:   Good morning. I'm Noel King. Fourteen-year-old Akilan Sankaran is on his school's track team. He plays the piano, the flute and the drums. And yet he still found time to devise a computer program that makes your apps run faster. His program calculates anti-prime numbers, which are used in everyday software, and his discoveries won him the top prize in the Broadcom Masters, which is an engineering competition for middle school kids. His next goal is to become an astrophysicist. It's MORNING EDITION.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-11-04-1052153703": {"title": "Astronomers want a huge telescope optimized for studying alien worlds : NPR", "url": "https://www.npr.org/2021/11/04/1052153703/astronomers-want-nasa-to-build-a-giant-space-telescope-to-peer-at-alien-earths", "author": "No author found", "published_date": "2021-11-04", "content": "", "section": "Space", "disclaimer": ""}, "2021-11-04-1051381706": {"title": "In this case, politics is a (video) game : NPR", "url": "https://www.npr.org/2021/11/04/1051381706/in-this-case-politics-is-a-video-game", "author": "No author found", "published_date": "2021-11-04", "content": "AUDIE CORNISH, HOST:  Politics is often treated like it's a game. There's the strategy, the competition, neither side willing to reveal their full hand. Now the messy, real-life world of politics has been turned into a literal game. A forthcoming video game will let you shake up Washington as you explore all the ins and outs and, yeah, even the ugliness of politics. NPR's Juana Summers explains. JUANA SUMMERS, BYLINE: The trailer for Political Arena gives an early hint at the approach this game takes to politics. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED PERSON: Political Arena - what's it hiding? A game that lets you be a political hotshot and experience the high-stakes world of American power. SUMMERS: But it's more than just ugly attack ads. The game's creator is political journalist Eliot Nelson. ELIOT NELSON: You can legislate. You can campaign. You can navigate the media. You can weather scandals. You can try and pick apart the myriad interests on K Street and other special interests. SUMMERS: A player customizes their own politician and then can decide how to spend their time, what issues they prioritize and how weak or strong they are in certain skills. Nelson's been working on this game since 2018 and said he's drawn inspiration from his work as a journalist as well as from a lot of games already out there, like NBA 2K, the simulation game SimCity. . . (SOUNDBITE OF MUSIC)SUMMERS: . . . And the popular educational game Oregon Trail, where users set off across the country in a covered wagon hoping not to die of dysentery. NELSON: Oregon Trail never had any lessons in it. You never just stop and answer a quiz. It was just a game. It was a fun and immersive and, dare I even say, addictive game that did such a successful job of familiarizing tens of millions of people with this relatively arcane corner of American history. SUMMERS: The team behind Political Arena includes gaming industry veterans like producer Diana Williams. Williams runs Kinetic Energy Entertainment and is a former exec at Lucasfilm, the studio behind \"Star Wars. \" She hopes the game attracts people who are curious about the political process. But she wants to give them a more realistic view than, say, \"Schoolhouse Rock! \". . . (SOUNDBITE OF SONG, \"I'M JUST A BILL\")JACK SHELDON: (As the Bill, singing) I'm just a bill. Yes, I'm only a bill. And I'm sitting here on Capitol Hill. SUMMERS: . . . Where a cartoon bill on Capitol Hill waits for the chance to be signed into law. DIANA WILLIAMS: \"Schoolhouse Rock! \" didn't quite cover things, like talk about the fact that lobbyists show up with, like, great dinners and things to sway people's opinions. It's very gray. There's no black and white to the democratic process. SUMMERS: But Williams says, first and foremost, this game should be fun to play, even when politics seems really bleak. A number of veteran politicos are serving as advisers, including Jess McIntosh, a Democratic strategist who worked on Hillary Clinton's presidential campaign. JESS MCINTOSH: I come from a real gendered politics side of things. I spent a lot of years at EMILY's List, so I think some of my first questions were, how are you going to handle women candidates? Do they have different challenges than men do? How do we make sure that that's accurately reflected in the game? SUMMERS: Its considerations like these that help make any game feel more real when people play it. The Political Arena team has launched a campaign on Kickstarter with the goal of raising $100,000 by Saturday. They plan a full release for Election Day 2023. Juana Summers, NPR News. (SOUNDBITE OF ATMOSPHERE SONG, \"AIN'T NOBODY\") AUDIE CORNISH, HOST:   Politics is often treated like it's a game. There's the strategy, the competition, neither side willing to reveal their full hand. Now the messy, real-life world of politics has been turned into a literal game. A forthcoming video game will let you shake up Washington as you explore all the ins and outs and, yeah, even the ugliness of politics. NPR's Juana Summers explains. JUANA SUMMERS, BYLINE: The trailer for Political Arena gives an early hint at the approach this game takes to politics. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED PERSON: Political Arena - what's it hiding? A game that lets you be a political hotshot and experience the high-stakes world of American power. SUMMERS: But it's more than just ugly attack ads. The game's creator is political journalist Eliot Nelson. ELIOT NELSON: You can legislate. You can campaign. You can navigate the media. You can weather scandals. You can try and pick apart the myriad interests on K Street and other special interests. SUMMERS: A player customizes their own politician and then can decide how to spend their time, what issues they prioritize and how weak or strong they are in certain skills. Nelson's been working on this game since 2018 and said he's drawn inspiration from his work as a journalist as well as from a lot of games already out there, like NBA 2K, the simulation game SimCity. . . (SOUNDBITE OF MUSIC) SUMMERS: . . . And the popular educational game Oregon Trail, where users set off across the country in a covered wagon hoping not to die of dysentery. NELSON: Oregon Trail never had any lessons in it. You never just stop and answer a quiz. It was just a game. It was a fun and immersive and, dare I even say, addictive game that did such a successful job of familiarizing tens of millions of people with this relatively arcane corner of American history. SUMMERS: The team behind Political Arena includes gaming industry veterans like producer Diana Williams. Williams runs Kinetic Energy Entertainment and is a former exec at Lucasfilm, the studio behind \"Star Wars. \" She hopes the game attracts people who are curious about the political process. But she wants to give them a more realistic view than, say, \"Schoolhouse Rock! \". . . (SOUNDBITE OF SONG, \"I'M JUST A BILL\") JACK SHELDON: (As the Bill, singing) I'm just a bill. Yes, I'm only a bill. And I'm sitting here on Capitol Hill. SUMMERS: . . . Where a cartoon bill on Capitol Hill waits for the chance to be signed into law. DIANA WILLIAMS: \"Schoolhouse Rock! \" didn't quite cover things, like talk about the fact that lobbyists show up with, like, great dinners and things to sway people's opinions. It's very gray. There's no black and white to the democratic process. SUMMERS: But Williams says, first and foremost, this game should be fun to play, even when politics seems really bleak. A number of veteran politicos are serving as advisers, including Jess McIntosh, a Democratic strategist who worked on Hillary Clinton's presidential campaign. JESS MCINTOSH: I come from a real gendered politics side of things. I spent a lot of years at EMILY's List, so I think some of my first questions were, how are you going to handle women candidates? Do they have different challenges than men do? How do we make sure that that's accurately reflected in the game? SUMMERS: Its considerations like these that help make any game feel more real when people play it. The Political Arena team has launched a campaign on Kickstarter with the goal of raising $100,000 by Saturday. They plan a full release for Election Day 2023. Juana Summers, NPR News. (SOUNDBITE OF ATMOSPHERE SONG, \"AIN'T NOBODY\")", "section": "Politics", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-11-07-1052855054": {"title": "This Alaskan town is finally getting high-speed internet, thanks to the pandemic : NPR", "url": "https://www.npr.org/2021/11/07/1052855054/alaska-tribe-broadband-infrastructure", "author": "No author found", "published_date": "2021-11-07", "content": "", "section": "Technology", "disclaimer": ""}, "2021-11-08-1053647199": {"title": "Facebook bets its future on the metaverse : NPR", "url": "https://www.npr.org/2021/11/08/1053647199/facebook-bets-its-future-on-the-metaverse", "author": "No author found", "published_date": "2021-11-08", "content": "AUDIE CORNISH, HOST:  Mark Zuckerberg says the metaverse is not just the next chapter of his company. It's the next chapter of the internet. (SOUNDBITE OF ARCHIVED RECORDING)MARK ZUCKERBERG: The next platform and medium will be even more immersive, an embodied internet where you're in the experience, not just looking at it. And we call this the metaverse. CORNISH: Now, we're going to hear from the man he's put in charge of making that happen, Vishal Shah. But Zuckerberg's announcement about that vision for the future and about Facebook's rebrand as Meta lands at a moment in which the company is under intense scrutiny. Late-night hosts like Stephen Colbert found Zuckerberg's claim that the recent past had been humbling for the company weak. (SOUNDBITE OF TV SHOW, \"THE LATE SHOW WITH STEPHEN COLBERT\")ZUCKERBERG: We live for what we're building, and while we make mistakes, we keep learning and building and moving forward. STEPHEN COLBERT: And we will keep building and moving and making bigger and better mistakes. (LAUGHTER)COLBERT: There's no point in looking back at what anyone did or said or covered up or shredded or dumped into the river. River - what river? Building and learning. CORNISH: And even among those early adopters already sold on the metaverse, there's some skepticism. JASON MOORE: I think that the metaverse should not be built or operated by one sole entity. I think it should be completely open. I think it should be for everyone, and it should not be controlled by any one company. Certainly, it should not be controlled by a company who's demonstrated that they really put profits over people at every step of the juncture. CORNISH: Jason Moore teaches television and virtual reality at Brooklyn College. He's very excited about the metaverse. MOORE: The best way I can explain the metaverse as we know it now - it's the internet kind of 3. 0. It's an embodied, inhabited internet. CORNISH: And if you're still trying to wrap your head around, like, the idea of the metaverse, I get it. Some of us are in the same boat. Moore says to think of it this way. MOORE: These are virtual worlds that, when you're inside of them, feels like you're inside a kind of a cool video game. But it's so much more than a game because it's like the internet, where you're socially connected. So, you know, you can do just about anything in the metaverse. You can, you know, play a game with friends. You can go take a class. CORNISH: And Jason Moore is already in the metaverse. There are currently a bunch of distinct, mostly unconnected metaverse platforms - VRChat, NeosVR, Roblox and a handful of others. So right now Moore can strap on a virtual reality headset and enter an alternate online universe. MOORE: I arrive in my home world. It looks like just, you know, a little planet, basically. And from there, I can navigate around to different locations like different websites, basically. CORNISH: And see a live concert. MOORE: The show that I saw with all these people is called Mycelia, and it was set in an underground cavern. CORNISH: On this virtual stage, there was a synth player in an organic kind of mushroom-inspired costume. And above that, this dancer was suspended in mid-air. And the audience. . . MOORE: Most of us were kind of down floating in this water that - you could actually swim underwater during the performance and see. And you could also kind of explore the cave system around the central stage. CORNISH: The metaverse is where the digital world literally overlaps with the real world, and in many ways it feels like real life within limits. MOORE: You know, you're wearing an avatar. You look down at your hands, and you see hands. You might not be human. You know, my avatar is a big bulldog. So I look down and see these big, meaty paws. CORNISH: It's exciting and, yes, still a little niche. But this is where Facebook comes in with its nearly 3 billion active users - users that Meta hopes might one day be briefing colleagues in virtual metaverse conference rooms or buying virtual outfits in metaverse clothing shops or, if Mark Zuckerberg's keynote video is to be believed, playing cards on a virtual spaceship. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED PERSON #1: Oh, hey, Mark. ZUCKERBERG: Hey. What's going on? UNIDENTIFIED PERSON #2: Hey, Mark. UNIDENTIFIED PERSON #3: What's up, Mark? ZUCKERBERG: Whoa. We're floating in space. Who made this place? That's awesome. UNIDENTIFIED PERSON #2: Right? CORNISH: Now, lots of people are skeptical about a mainstream metaverse taking off. They argue internet connection speeds or just the human need for actual physical connection will stop this revolution in its tracks. But if Zuckerberg and Jason Moore are right and the future of the internet is in the metaverse, then Meta's next steps could be incredibly important. That's where this guy comes in. So first of all, Vishal, welcome to my office. VISHAL SHAH: Wonderful. CORNISH: I take it in the metaverse, I can make this look like - I don't know - like, the White House or something. SHAH: It's looking lovely as it is. But, yes, you can. You can definitely make it however you like. CORNISH: Vishal Shah became Meta's vice president of metaverse this year after six years with Instagram. We'll note here that Meta pays NPR to license NPR content. Now, Vishal Shah and I started by talking about the skepticism about the company's rebranding, for instance. Was it a well-timed distraction from the whistleblower who accuses Facebook with leaked documents to support her claims of repeatedly putting the company's image ahead of the public interest? SHAH: You know, I love the idea that we could have come up with a name change and a rollout of our brand in just a couple of weeks. Frankly, this has been in the works for a couple of years and in earnest in the last, you know, six or seven months. CORNISH: And we spoke about Meta's intentions around the metaverse. Does Meta want the metaverse to be a walled garden, an economy under its control? SHAH: No is the short answer to the question. The metaverse is not something any one company can own, can even build alone. We're explicitly not trying to build this alone. It's kind of like saying, you know, what company owns the internet? It doesn't really make sense if you frame it that way. But it is talking about the next generation of experiences that we want to build. And we've said pretty clearly that we want these experiences that get built to be as interoperable as possible because that creates the most value for creators, for consumers, for the economy that you just referenced. CORNISH: So the way I experience this right now is - let's say you have a mall. There are lots of different stores in the mall. They compete with each other, but someone owns the mall. It sounds like Meta will own the mall. Am I getting that right? SHAH: Well, if we get this right, then there might be an infinite number of malls that might all contribute in different ways. And maybe we aren't the - in fact, I hope we aren't the mall builder because there will be someone who creates a really amazing mall world. We want to build the underlying infrastructure that helps people build those malls. CORNISH: And that's a pretty big land grab, right? Like, that's saying you own the city (laughter). You own the streets, right? SHAH: Well, it's, I think, a little bit different because that's, like, a physical analogy. There's infinite potential land available in this new experience that we're talking about. That's even if you assume that land is the right analogy because in a digital experience, you know, you have worlds, and you have experience. I think the spatial model is the most important thing we're trying to create, which is that this is a sort of virtual spaces that people can be in together and the idea that there might be a mall experience for shopping together, a school experience to - for the future of education, thinking about the future of entertainment - you know, concerts and live events. And so there are certainly physical analogs. But because we don't have some of those same constraints, how those things might evolve, what they might look like, how they might feel might be pretty different than what we experience in the physical world. CORNISH: Mark Zuckerberg has said that, quote, \"privacy and safety need to be built into the metaverse from Day One. \" To you, what does that look like? And what would be the definition of safety in this environment? SHAH: I think the most important thing is that we are talking about it now and early. The vision that we've talked about is five, 10, 15 years out into the future. CORNISH: But can I stop you there? - because I don't think we all agree on what the it is. As Facebook, as Instagram, Meta has had a serious problem, a serious struggle to moderate harmful content. What do you have to do differently to make content moderation efficient in something like a metaverse? SHAH: I think these are really challenging topics and ones that we've had - as a company have had to deal with for the last, as I mentioned, 10 or 15 years. And I don't sit here pretending to say we've gotten it perfect, but I will say we've dealt with every single one of the issues that you've talked about. And if you're thinking about a company that's building the next generation of platform and technology, I think it's - I think we're in a better position because we have dealt with those things to ask the right questions upfront to ensure that we are thinking about them in a way that can be future-compatible. CORNISH: What I'm saying is if you can't handle the comments on Instagram, how can you handle the T-shirt that has hate speech on it in the metaverse? How can you handle the hate rally that might happen in the metaverse? You're creating a scenario where I don't see how it's clear that you moderate that or if you even see it as your responsibility in helping to create this infrastructure. SHAH: I think these are exactly the right types of questions to be asking now. I think a lot of times some of the challenges that we have talked about as a company are not a question of whether something should stay up or should come down from a legal perspective or from a specific policy perspective but what is the right balance between freedom of speech and freedom of expression and something that is harmful. And the rules and the lines on where those are are not something that we, I think, can define ourselves alone as a company. It's why we've asked for more explicit regulation to be able to define what some of those rules are. Now, that being said, the ability to detect some of those things, the technology to find them - we've invested for years. So I don't mean to say that this is not something that we're taking seriously, that this is not a responsibility that we shy away from. We're very much bringing our heritage and our past with us, both the good in terms of looking at this stuff and the challenges that we've faced. CORNISH: Do you think people want this? The headsets have been around for some time and augmented reality. I mean, what's your sense of actual demand? Or is this a if they build it, they will come scenario? SHAH: Well, you know, like with anything new, we've got your typical hype cycle, and then everyone kind of figures out where the real use cases might be. And I think we've seen early traction in gaming, certainly. At the same time, we're starting to see other use cases start to emerge. Fitness has become a really important category that we've seen, and education is a place we are certainly seeing some early traction. It is early. We've said this is five, 10, maybe even 15 years into the future. And I think it's rare for us certainly as a company to talk about something this early but as an industry for us to talk about something so early. But, yeah, this is this is many, many years into the future. CORNISH: Vishal Shah is the vice president of metaverse at Meta, formerly known as Facebook. (SOUNDBITE OF MISLED CHILDREN'S \"10\") AUDIE CORNISH, HOST:   Mark Zuckerberg says the metaverse is not just the next chapter of his company. It's the next chapter of the internet. (SOUNDBITE OF ARCHIVED RECORDING) MARK ZUCKERBERG: The next platform and medium will be even more immersive, an embodied internet where you're in the experience, not just looking at it. And we call this the metaverse. CORNISH: Now, we're going to hear from the man he's put in charge of making that happen, Vishal Shah. But Zuckerberg's announcement about that vision for the future and about Facebook's rebrand as Meta lands at a moment in which the company is under intense scrutiny. Late-night hosts like Stephen Colbert found Zuckerberg's claim that the recent past had been humbling for the company weak. (SOUNDBITE OF TV SHOW, \"THE LATE SHOW WITH STEPHEN COLBERT\") ZUCKERBERG: We live for what we're building, and while we make mistakes, we keep learning and building and moving forward. STEPHEN COLBERT: And we will keep building and moving and making bigger and better mistakes. (LAUGHTER) COLBERT: There's no point in looking back at what anyone did or said or covered up or shredded or dumped into the river. River - what river? Building and learning. CORNISH: And even among those early adopters already sold on the metaverse, there's some skepticism. JASON MOORE: I think that the metaverse should not be built or operated by one sole entity. I think it should be completely open. I think it should be for everyone, and it should not be controlled by any one company. Certainly, it should not be controlled by a company who's demonstrated that they really put profits over people at every step of the juncture. CORNISH: Jason Moore teaches television and virtual reality at Brooklyn College. He's very excited about the metaverse. MOORE: The best way I can explain the metaverse as we know it now - it's the internet kind of 3. 0. It's an embodied, inhabited internet. CORNISH: And if you're still trying to wrap your head around, like, the idea of the metaverse, I get it. Some of us are in the same boat. Moore says to think of it this way. MOORE: These are virtual worlds that, when you're inside of them, feels like you're inside a kind of a cool video game. But it's so much more than a game because it's like the internet, where you're socially connected. So, you know, you can do just about anything in the metaverse. You can, you know, play a game with friends. You can go take a class. CORNISH: And Jason Moore is already in the metaverse. There are currently a bunch of distinct, mostly unconnected metaverse platforms - VRChat, NeosVR, Roblox and a handful of others. So right now Moore can strap on a virtual reality headset and enter an alternate online universe. MOORE: I arrive in my home world. It looks like just, you know, a little planet, basically. And from there, I can navigate around to different locations like different websites, basically. CORNISH: And see a live concert. MOORE: The show that I saw with all these people is called Mycelia, and it was set in an underground cavern. CORNISH: On this virtual stage, there was a synth player in an organic kind of mushroom-inspired costume. And above that, this dancer was suspended in mid-air. And the audience. . . MOORE: Most of us were kind of down floating in this water that - you could actually swim underwater during the performance and see. And you could also kind of explore the cave system around the central stage. CORNISH: The metaverse is where the digital world literally overlaps with the real world, and in many ways it feels like real life within limits. MOORE: You know, you're wearing an avatar. You look down at your hands, and you see hands. You might not be human. You know, my avatar is a big bulldog. So I look down and see these big, meaty paws. CORNISH: It's exciting and, yes, still a little niche. But this is where Facebook comes in with its nearly 3 billion active users - users that Meta hopes might one day be briefing colleagues in virtual metaverse conference rooms or buying virtual outfits in metaverse clothing shops or, if Mark Zuckerberg's keynote video is to be believed, playing cards on a virtual spaceship. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED PERSON #1: Oh, hey, Mark. ZUCKERBERG: Hey. What's going on? UNIDENTIFIED PERSON #2: Hey, Mark. UNIDENTIFIED PERSON #3: What's up, Mark? ZUCKERBERG: Whoa. We're floating in space. Who made this place? That's awesome. UNIDENTIFIED PERSON #2: Right? CORNISH: Now, lots of people are skeptical about a mainstream metaverse taking off. They argue internet connection speeds or just the human need for actual physical connection will stop this revolution in its tracks. But if Zuckerberg and Jason Moore are right and the future of the internet is in the metaverse, then Meta's next steps could be incredibly important. That's where this guy comes in. So first of all, Vishal, welcome to my office. VISHAL SHAH: Wonderful. CORNISH: I take it in the metaverse, I can make this look like - I don't know - like, the White House or something. SHAH: It's looking lovely as it is. But, yes, you can. You can definitely make it however you like. CORNISH: Vishal Shah became Meta's vice president of metaverse this year after six years with Instagram. We'll note here that Meta pays NPR to license NPR content. Now, Vishal Shah and I started by talking about the skepticism about the company's rebranding, for instance. Was it a well-timed distraction from the whistleblower who accuses Facebook with leaked documents to support her claims of repeatedly putting the company's image ahead of the public interest? SHAH: You know, I love the idea that we could have come up with a name change and a rollout of our brand in just a couple of weeks. Frankly, this has been in the works for a couple of years and in earnest in the last, you know, six or seven months. CORNISH: And we spoke about Meta's intentions around the metaverse. Does Meta want the metaverse to be a walled garden, an economy under its control? SHAH: No is the short answer to the question. The metaverse is not something any one company can own, can even build alone. We're explicitly not trying to build this alone. It's kind of like saying, you know, what company owns the internet? It doesn't really make sense if you frame it that way. But it is talking about the next generation of experiences that we want to build. And we've said pretty clearly that we want these experiences that get built to be as interoperable as possible because that creates the most value for creators, for consumers, for the economy that you just referenced. CORNISH: So the way I experience this right now is - let's say you have a mall. There are lots of different stores in the mall. They compete with each other, but someone owns the mall. It sounds like Meta will own the mall. Am I getting that right? SHAH: Well, if we get this right, then there might be an infinite number of malls that might all contribute in different ways. And maybe we aren't the - in fact, I hope we aren't the mall builder because there will be someone who creates a really amazing mall world. We want to build the underlying infrastructure that helps people build those malls. CORNISH: And that's a pretty big land grab, right? Like, that's saying you own the city (laughter). You own the streets, right? SHAH: Well, it's, I think, a little bit different because that's, like, a physical analogy. There's infinite potential land available in this new experience that we're talking about. That's even if you assume that land is the right analogy because in a digital experience, you know, you have worlds, and you have experience. I think the spatial model is the most important thing we're trying to create, which is that this is a sort of virtual spaces that people can be in together and the idea that there might be a mall experience for shopping together, a school experience to - for the future of education, thinking about the future of entertainment - you know, concerts and live events. And so there are certainly physical analogs. But because we don't have some of those same constraints, how those things might evolve, what they might look like, how they might feel might be pretty different than what we experience in the physical world. CORNISH: Mark Zuckerberg has said that, quote, \"privacy and safety need to be built into the metaverse from Day One. \" To you, what does that look like? And what would be the definition of safety in this environment? SHAH: I think the most important thing is that we are talking about it now and early. The vision that we've talked about is five, 10, 15 years out into the future. CORNISH: But can I stop you there? - because I don't think we all agree on what the it is. As Facebook, as Instagram, Meta has had a serious problem, a serious struggle to moderate harmful content. What do you have to do differently to make content moderation efficient in something like a metaverse? SHAH: I think these are really challenging topics and ones that we've had - as a company have had to deal with for the last, as I mentioned, 10 or 15 years. And I don't sit here pretending to say we've gotten it perfect, but I will say we've dealt with every single one of the issues that you've talked about. And if you're thinking about a company that's building the next generation of platform and technology, I think it's - I think we're in a better position because we have dealt with those things to ask the right questions upfront to ensure that we are thinking about them in a way that can be future-compatible. CORNISH: What I'm saying is if you can't handle the comments on Instagram, how can you handle the T-shirt that has hate speech on it in the metaverse? How can you handle the hate rally that might happen in the metaverse? You're creating a scenario where I don't see how it's clear that you moderate that or if you even see it as your responsibility in helping to create this infrastructure. SHAH: I think these are exactly the right types of questions to be asking now. I think a lot of times some of the challenges that we have talked about as a company are not a question of whether something should stay up or should come down from a legal perspective or from a specific policy perspective but what is the right balance between freedom of speech and freedom of expression and something that is harmful. And the rules and the lines on where those are are not something that we, I think, can define ourselves alone as a company. It's why we've asked for more explicit regulation to be able to define what some of those rules are. Now, that being said, the ability to detect some of those things, the technology to find them - we've invested for years. So I don't mean to say that this is not something that we're taking seriously, that this is not a responsibility that we shy away from. We're very much bringing our heritage and our past with us, both the good in terms of looking at this stuff and the challenges that we've faced. CORNISH: Do you think people want this? The headsets have been around for some time and augmented reality. I mean, what's your sense of actual demand? Or is this a if they build it, they will come scenario? SHAH: Well, you know, like with anything new, we've got your typical hype cycle, and then everyone kind of figures out where the real use cases might be. And I think we've seen early traction in gaming, certainly. At the same time, we're starting to see other use cases start to emerge. Fitness has become a really important category that we've seen, and education is a place we are certainly seeing some early traction. It is early. We've said this is five, 10, maybe even 15 years into the future. And I think it's rare for us certainly as a company to talk about something this early but as an industry for us to talk about something so early. But, yeah, this is this is many, many years into the future. CORNISH: Vishal Shah is the vice president of metaverse at Meta, formerly known as Facebook. (SOUNDBITE OF MISLED CHILDREN'S \"10\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-11-08-1053599349": {"title": "Justice Department indicts two men over REvil ransomware attacks : NPR", "url": "https://www.npr.org/2021/11/08/1053599349/u-s-indicts-2-men-behind-ransomware-attacks-over-the-summer", "author": "No author found", "published_date": "2021-11-08", "content": "RACHEL MARTIN, HOST:  The Justice Department is fighting back against hackers, the kind who use ransomware to steal data and then hold that data hostage for a payout. Authorities have indicted two international cybercriminals from Russia and Ukraine. NPR national justice correspondent Carrie Johnson reports. CARRIE JOHNSON, BYLINE: Four months after hackers targeted the software company Kaseya and its clients, the Justice Department is striking back. Attorney General Merrick Garland announced the action in a press conference in Washington. (SOUNDBITE OF PRESS CONFERENCE)MERRICK GARLAND: The Justice Department is sparing no resource to identify and bring to justice anyone anywhere who targets the United States with a ransomware attack. JOHNSON: One hacker, a Russian national, remains at large, but the other, a Ukrainian, recently made the bad decision to travel to Poland, where he was taken into custody. American law enforcement wants to extradite him to the U. S. to face justice. LISA MONACO: Our message is that if you come for us, we are going to come for you. JOHNSON: That's deputy attorney general Lisa Monaco. Monaco established a task force to fight the threat from organized criminal gangs earlier this year. MONACO: We once again followed the money. We went after the cryptocurrency that was paid in ransom by the victims here, and we went and we traced it and we seized it. And now we'll be able to return that money to the victims. So we're using every tool at our disposal. We're using all of our authorities, and we're doing it at a scale and a speed that we haven't done before. JOHNSON: DOJ says it recovered more than $6 million in this case that will go back to the victims. The targets of the ransomware schemes include private businesses, schools, hospitals and 911 call centers. So Monaco says these cases can be deadly serious. MONACO: These attacks have hit hospitals. They have hit first responders. They have hit industries and sectors of our society where real lives are at stake. And so that's what we mean when we're talking about life and death. JOHNSON: The Biden administration is taking a coordinated approach to ransomware. The Treasury Department announced sanctions, and the State Department is offering a $10 million reward for information that leads to the capture of the leaders of the criminal gang known as REvil. But leaders of the Justice Department say they need Congress and their broader community to help, too. They're asking for a new law that would create a standard for reporting cyber incidents to federal authorities. And they want the victims to notify them quickly so they can recover lost money and prevent anyone else from being victimized. Carrie Johnson, NPR News, Washington. (SOUNDBITE OF KODOMO'S \"CONCEPT 11\") RACHEL MARTIN, HOST:   The Justice Department is fighting back against hackers, the kind who use ransomware to steal data and then hold that data hostage for a payout. Authorities have indicted two international cybercriminals from Russia and Ukraine. NPR national justice correspondent Carrie Johnson reports. CARRIE JOHNSON, BYLINE: Four months after hackers targeted the software company Kaseya and its clients, the Justice Department is striking back. Attorney General Merrick Garland announced the action in a press conference in Washington. (SOUNDBITE OF PRESS CONFERENCE) MERRICK GARLAND: The Justice Department is sparing no resource to identify and bring to justice anyone anywhere who targets the United States with a ransomware attack. JOHNSON: One hacker, a Russian national, remains at large, but the other, a Ukrainian, recently made the bad decision to travel to Poland, where he was taken into custody. American law enforcement wants to extradite him to the U. S. to face justice. LISA MONACO: Our message is that if you come for us, we are going to come for you. JOHNSON: That's deputy attorney general Lisa Monaco. Monaco established a task force to fight the threat from organized criminal gangs earlier this year. MONACO: We once again followed the money. We went after the cryptocurrency that was paid in ransom by the victims here, and we went and we traced it and we seized it. And now we'll be able to return that money to the victims. So we're using every tool at our disposal. We're using all of our authorities, and we're doing it at a scale and a speed that we haven't done before. JOHNSON: DOJ says it recovered more than $6 million in this case that will go back to the victims. The targets of the ransomware schemes include private businesses, schools, hospitals and 911 call centers. So Monaco says these cases can be deadly serious. MONACO: These attacks have hit hospitals. They have hit first responders. They have hit industries and sectors of our society where real lives are at stake. And so that's what we mean when we're talking about life and death. JOHNSON: The Biden administration is taking a coordinated approach to ransomware. The Treasury Department announced sanctions, and the State Department is offering a $10 million reward for information that leads to the capture of the leaders of the criminal gang known as REvil. But leaders of the Justice Department say they need Congress and their broader community to help, too. They're asking for a new law that would create a standard for reporting cyber incidents to federal authorities. And they want the victims to notify them quickly so they can recover lost money and prevent anyone else from being victimized. Carrie Johnson, NPR News, Washington. (SOUNDBITE OF KODOMO'S \"CONCEPT 11\")", "section": "Politics", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-11-08-1053511530": {"title": "Tesla shares fall after Elon Musk's bizarre Twitter poll : NPR", "url": "https://www.npr.org/2021/11/08/1053511530/elon-musk-twitter-poll-tesla", "author": "No author found", "published_date": "2021-11-08", "content": "", "section": "Business", "disclaimer": ""}, "2021-11-09-1054021911": {"title": "Facebook scraps ad targeting based on politics, race and other 'sensitive' topics : NPR", "url": "https://www.npr.org/2021/11/09/1054021911/facebook-scraps-ad-targeting-politics-race-sensitive-topics", "author": "No author found", "published_date": "2021-11-09", "content": "", "section": "Technology", "disclaimer": ""}, "2021-11-09-1053895250": {"title": "One of the first Apple computers sells for $400,000 : NPR", "url": "https://www.npr.org/2021/11/09/1053895250/an-original-apple-1-computer-sells-for-400-000", "author": "No author found", "published_date": "2021-11-09", "content": "RACHEL MARTIN, HOST:  A rare piece of computer history was auctioned off yesterday. An Apple-1 computer sold for $400,000. COREY COHEN: What we have with the Apple-1 is sort of like the holy grail of vintage computer collecting. STEVE INSKEEP, HOST:  Corey Cohen, who's an Apple historian, says the Apple-1 helped to launch the personal computer industry. COHEN: Yes, it was the first product of Apple Computer, but it was the first commonly available computer that was intended as a computer that had a keyboard. Today - right? - computers have keyboards or - whether it's a virtual keyboard or a real one. So that was key. INSKEEP: The first Apple PC was designed by Apple co-founder Steve Wozniak. COHEN: You were guaranteed when you got home and you plugged it in, it worked. I know we take that for granted today, but it really wasn't a common thing back in the mid-1970s. MARTIN: In 1976, an Apple-1 would cost you precisely $666. 66. So the $400,000 auction price reflects an increase of 60,000%. That's how the market for vintage tech is going. If your old device is in perfect shape. . . COHEN: Any of the surviving Apple-1s could probably be made to work. The question is, how original would they be? An analogy would be, sure, I could find, you know, a 1920s car, right? But would it have the original engine? Would it run just like it did back then? INSKEEP: If an old device around your house is not in that kind of shape, no problem. MARTIN: Just take a device you have now and set it aside for about 45 years. (SOUNDBITE OF SONG, \"COMPUTER AGE\")NEIL YOUNG: (Singing) Computer age, computer age, computer age. RACHEL MARTIN, HOST:   A rare piece of computer history was auctioned off yesterday. An Apple-1 computer sold for $400,000. COREY COHEN: What we have with the Apple-1 is sort of like the holy grail of vintage computer collecting. STEVE INSKEEP, HOST:   Corey Cohen, who's an Apple historian, says the Apple-1 helped to launch the personal computer industry. COHEN: Yes, it was the first product of Apple Computer, but it was the first commonly available computer that was intended as a computer that had a keyboard. Today - right? - computers have keyboards or - whether it's a virtual keyboard or a real one. So that was key. INSKEEP: The first Apple PC was designed by Apple co-founder Steve Wozniak. COHEN: You were guaranteed when you got home and you plugged it in, it worked. I know we take that for granted today, but it really wasn't a common thing back in the mid-1970s. MARTIN: In 1976, an Apple-1 would cost you precisely $666. 66. So the $400,000 auction price reflects an increase of 60,000%. That's how the market for vintage tech is going. If your old device is in perfect shape. . . COHEN: Any of the surviving Apple-1s could probably be made to work. The question is, how original would they be? An analogy would be, sure, I could find, you know, a 1920s car, right? But would it have the original engine? Would it run just like it did back then? INSKEEP: If an old device around your house is not in that kind of shape, no problem. MARTIN: Just take a device you have now and set it aside for about 45 years. (SOUNDBITE OF SONG, \"COMPUTER AGE\") NEIL YOUNG: (Singing) Computer age, computer age, computer age.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-11-09-1053924352": {"title": "Facebook is now revealing how often users see bullying or harassing posts : NPR", "url": "https://www.npr.org/2021/11/09/1053924352/facebook-instagram-bullying-harassment-numbers", "author": "No author found", "published_date": "2021-11-09", "content": "", "section": "Technology", "disclaimer": ""}, "2021-11-09-1053895408": {"title": "Rep. Alexandria Ocasio-Cortez slams Rep. Paul Gosar over edited anime video : NPR", "url": "https://www.npr.org/2021/11/09/1053895408/paul-gosar-alexandria-ocasio-cortez-anime-twitter-video-backlash", "author": "No author found", "published_date": "2021-11-09", "content": "", "section": "Politics", "disclaimer": ""}, "2021-11-10-1053844312": {"title": "Israel wants funding cut off for Palestinian activists hacked with NSO spyware  : NPR", "url": "https://www.npr.org/2021/11/10/1053844312/palestinians-israel-nso-spyware", "author": "No author found", "published_date": "2021-11-10", "content": "", "section": "World", "disclaimer": ""}, "2021-11-10-1054296657": {"title": "The U.K. will save thousands of its iconic red phone kiosks from being shut down : NPR", "url": "https://www.npr.org/2021/11/10/1054296657/u-k-will-save-its-red-phone-kiosks", "author": "No author found", "published_date": "2021-11-10", "content": "", "section": "Technology", "disclaimer": ""}, "2021-11-12-1054850363": {"title": "These researchers are trying to stop misinformation from derailing climate progress : NPR", "url": "https://www.npr.org/2021/11/12/1054850363/cop26-climate-summit-misinformation", "author": "No author found", "published_date": "2021-11-12", "content": "A MARTINEZ, HOST:  An international team of activists and online researchers has been tracking false and misleading claims about climate change in real time while world leaders meet at the high-stakes U. N. climate conference in Glasgow. NPR's tech correspondent Shanon Bond got a look inside their social media war room. SHANNON BOND, BYLINE: For the past two weeks, Sean Buchan has started each day at his computer in Barcelona tracking narratives about the climate summit known as COP26, like this one. SEAN BUCHAN: We had this story that emerged where they were using diesel generators to power a lot of the electric cars that were shipping people to and from COP in Glasgow. BOND: That isn't true. The cars were being recharged by generators burning lower-emission vegetable oil. BUCHAN: But you know, that was subtly left out of the information when it was tweeted or posted. And it makes it seem like the whole of COP26 is running on diesel. It's not false, but, you know, it is highly misleading. BOND: Buchan is an analyst at Stop Funding Heat, a British climate advocacy group. He's part of a team monitoring social media during the summit, coordinated by Jennie King of the Institute for Strategic Dialogue in London. It's long studied online extremism and terrorism, and King sees a lot of similarities in the climate claims she's now tracking. JENNIE KING: Climate is being co-opted into this universe of anti-government sentiment. It's being weaponized by groups that have extremist or conspiracist affiliations. They are spreading messages across social media platforms, and those communities are more and more coexisting and cross-pollinating across both mainstream and fringe platforms. BOND: So King and her partners built a set of dashboards to monitor Facebook, Twitter and other websites. Their concern was that climate deniers and conspiracists alike would create narratives that risked undermining the summit negotiations. That happened in 2009, when climate deniers used hacked emails from scientists to fuel doubts ahead of another U. N. summit in a manufactured scandal known as Climategate. King says her team has created an early warning system to prevent something like that from happening again. KING: What we have built is the infrastructure to look at the emergence of new narratives and of influence and impact across social media in real time. BOND: King sends out a daily email bulletin about the narratives gaining the most traction to hundreds of subscribers - climate organizations, media outlets, scientists and policymakers. She says before the summit started, she wondered whether she'd mainly see attacks on specific topics under negotiation, like carbon markets or curbing methane emissions. Instead. . . KING: Climate has absolutely become part of the culture wars. BOND: She says the past two weeks have illustrated how climate is part of a larger universe of doubt and mistrust that has only been accelerated by the pandemic. Many of the influencers the group has been tracking are longtime climate deniers. Some are linked to the fossil fuel industry. And increasingly, they include figures who post all kinds of hoaxes and conspiracies. So now those who've long claimed that climate change is a pretext for government overreach are pointing to similar falsehoods about COVID lockdowns. They're both framed as an excuse to strip people of their freedom. KING: Language around things like climate lockdown is bleeding into spaces that were formed around anti-vax sentiment or around QAnon-affiliated arguments. So these are not communities that were particularly interested or dedicated to climate to begin with. But they have found a way to connect those other worldviews or ideologies with fear about the future of climate change response. BOND: When climate falsehoods become embedded in a web of larger conspiracies, that makes them harder to fight. And it could hamper even more the world's ability to take big, bold action on a global crisis. Shannon Bond, NPR News. (SOUNDBITE OF L'INDECIS' \"SOULFUL\") A MARTINEZ, HOST:   An international team of activists and online researchers has been tracking false and misleading claims about climate change in real time while world leaders meet at the high-stakes U. N. climate conference in Glasgow. NPR's tech correspondent Shanon Bond got a look inside their social media war room. SHANNON BOND, BYLINE: For the past two weeks, Sean Buchan has started each day at his computer in Barcelona tracking narratives about the climate summit known as COP26, like this one. SEAN BUCHAN: We had this story that emerged where they were using diesel generators to power a lot of the electric cars that were shipping people to and from COP in Glasgow. BOND: That isn't true. The cars were being recharged by generators burning lower-emission vegetable oil. BUCHAN: But you know, that was subtly left out of the information when it was tweeted or posted. And it makes it seem like the whole of COP26 is running on diesel. It's not false, but, you know, it is highly misleading. BOND: Buchan is an analyst at Stop Funding Heat, a British climate advocacy group. He's part of a team monitoring social media during the summit, coordinated by Jennie King of the Institute for Strategic Dialogue in London. It's long studied online extremism and terrorism, and King sees a lot of similarities in the climate claims she's now tracking. JENNIE KING: Climate is being co-opted into this universe of anti-government sentiment. It's being weaponized by groups that have extremist or conspiracist affiliations. They are spreading messages across social media platforms, and those communities are more and more coexisting and cross-pollinating across both mainstream and fringe platforms. BOND: So King and her partners built a set of dashboards to monitor Facebook, Twitter and other websites. Their concern was that climate deniers and conspiracists alike would create narratives that risked undermining the summit negotiations. That happened in 2009, when climate deniers used hacked emails from scientists to fuel doubts ahead of another U. N. summit in a manufactured scandal known as Climategate. King says her team has created an early warning system to prevent something like that from happening again. KING: What we have built is the infrastructure to look at the emergence of new narratives and of influence and impact across social media in real time. BOND: King sends out a daily email bulletin about the narratives gaining the most traction to hundreds of subscribers - climate organizations, media outlets, scientists and policymakers. She says before the summit started, she wondered whether she'd mainly see attacks on specific topics under negotiation, like carbon markets or curbing methane emissions. Instead. . . KING: Climate has absolutely become part of the culture wars. BOND: She says the past two weeks have illustrated how climate is part of a larger universe of doubt and mistrust that has only been accelerated by the pandemic. Many of the influencers the group has been tracking are longtime climate deniers. Some are linked to the fossil fuel industry. And increasingly, they include figures who post all kinds of hoaxes and conspiracies. So now those who've long claimed that climate change is a pretext for government overreach are pointing to similar falsehoods about COVID lockdowns. They're both framed as an excuse to strip people of their freedom. KING: Language around things like climate lockdown is bleeding into spaces that were formed around anti-vax sentiment or around QAnon-affiliated arguments. So these are not communities that were particularly interested or dedicated to climate to begin with. But they have found a way to connect those other worldviews or ideologies with fear about the future of climate change response. BOND: When climate falsehoods become embedded in a web of larger conspiracies, that makes them harder to fight. And it could hamper even more the world's ability to take big, bold action on a global crisis. Shannon Bond, NPR News. (SOUNDBITE OF L'INDECIS' \"SOULFUL\")", "section": "The COP26 summit", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-11-13-1055589999": {"title": "Hackers sent spam emails from FBI accounts, agency confirms : NPR", "url": "https://www.npr.org/2021/11/13/1055589999/hackers-sent-spam-emails-from-fbi-accounts-agency-confirms", "author": "No author found", "published_date": "2021-11-13", "content": "", "section": "National Security", "disclaimer": ""}, "2021-11-15-1055936688": {"title": "Privacy experts say to choose vaccination apps wisely : NPR", "url": "https://www.npr.org/2021/11/15/1055936688/privacy-experts-vaccination-app-clear", "author": "No author found", "published_date": "2021-11-15", "content": "AILSA CHANG, HOST:  Showing proof of vaccination is becoming more routine in places like New York City and Los Angeles. And while your vaccination card will usually get you into, say, a restaurant, big venues are starting to ask people to use phone apps. NPR's Martin Kaste reports on one app that's quickly gaining ground, even as privacy experts raise concerns. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED PERSON: Welcome to Climate Pledge Arena. MARTIN KASTE, BYLINE: Thousands of Seattle hockey fans line up for a game. They're eager to get out of the rain and into the arena, and they've got their cell phones out in anticipation. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED PERSON: Please have your mobile ticket and CLEAR Health Pass ready for scanning. KASTE: That CLEAR Health Pass they're asking for at the door is from the same CLEAR company that you see in airports selling shortcuts through security. Here, it's an app that shows your photo against a green background. The gate attendants just glance at that and wave you through. Further back in the line, people are getting the app ready, photographing their vaccination cards, their government IDs and then taking selfies. The selfie is for facial recognition. ERIC SCHOSSOW: For some reason right now it's just not catching our face, and it's making us, like, re-establish our face. . . JENNY BRITT: Re-verify identity. KASTE: Eric Schossow and Jenny Britt like the app, even if it's being a little touchy at the moment. Britt tries the selfie from a different angle. BRITT: It worked. SCHOSSOW: It worked. BRITT: It worked. KASTE: But others waiting to get into the arena have their doubts. John Howie happens to work in internet security, and he can't help but notice how much personal data CLEAR is getting from this crowd. JOHN HOWIE: I'm all for proving that you're vaccinated to get in. Using an app where you have to upload very personal, sensitive information is a bit concerning to me - use of biometrics, especially. KASTE: The Electronic Frontier Foundation has been saying something similar since the COVID vaccinations first rolled out. JON CALLAS: We are against proof of vaccination that creates a surveillance system. KASTE: The EFF's Jon Callas warns against tech companies that take advantage of new pandemic protocols to gather information they wouldn't otherwise get, something he calls COVID washing. CALLAS: This gives them a database that you have, quote, quote, \"consented to. \" And thus, they could do all sorts of things with it. KASTE: For instance, he says, that facial recognition that you give to CLEAR to get into a game today could end up allowing some other company to ID your face next year. But CLEAR says that's not what's happening. Its privacy policy promises not to rent or sell personal information, though it can share the data with companies it calls service providers. Rich Tucker is CLEAR's senior VP for privacy matters. RICH TUCKER: Core to CLEAR's values as a company are honoring member privacy. And we do that by empowering members, by giving them control over their information and by being transparent with how we use them. KASTE: CLEAR does hold on to that facial recognition information that people upload, except in Illinois, where state law doesn't allow open-ended retention of biometric data. In other states, customers can email CLEAR a request to delete their data. Tucker says the company is offering this free vaccination app in hopes that the people who sign up will choose to buy CLEAR's other services. TUCKER: CLEAR is never mandatory in any experience or opportunity. No one has to become a CLEAR member. That would be completely contrary to our identity as a company that's entirely opt-in. KASTE: In practice, though, you can find events that say everyone should use CLEAR, or they make it seem impractical for you not to. And it's understandable that big venues prefer this uniformity. In this, CLEAR is filling a void left by the government when the White House pledged in April not to create a national vaccine passport system. Mary Beth Kurilo is with the American Immunization Registry Association. MARY BETH KURILO: Because of the sort of decentralized nature of our health system and certainly our public health system, I think we are a little bit behind because we don't have some of the tools that we could leverage, like a national health identifier or a unique health identifier. So I think that does put us a little bit behind. KASTE: In the absence of a national system, some states are now offering their own vaccination apps, which follow a voluntary public-private standard called SMART Health Cards. They show proof of vaccination without gathering unnecessary personal information, such as facial recognition. Kurilo hopes the standard catches on, though she says for now, it's also important that venues keep accepting the old-fashioned paper vaccination cards so that no one's shut out because they can't or won't use an app. Martin Kaste, NPR News. AILSA CHANG, HOST:   Showing proof of vaccination is becoming more routine in places like New York City and Los Angeles. And while your vaccination card will usually get you into, say, a restaurant, big venues are starting to ask people to use phone apps. NPR's Martin Kaste reports on one app that's quickly gaining ground, even as privacy experts raise concerns. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED PERSON: Welcome to Climate Pledge Arena. MARTIN KASTE, BYLINE: Thousands of Seattle hockey fans line up for a game. They're eager to get out of the rain and into the arena, and they've got their cell phones out in anticipation. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED PERSON: Please have your mobile ticket and CLEAR Health Pass ready for scanning. KASTE: That CLEAR Health Pass they're asking for at the door is from the same CLEAR company that you see in airports selling shortcuts through security. Here, it's an app that shows your photo against a green background. The gate attendants just glance at that and wave you through. Further back in the line, people are getting the app ready, photographing their vaccination cards, their government IDs and then taking selfies. The selfie is for facial recognition. ERIC SCHOSSOW: For some reason right now it's just not catching our face, and it's making us, like, re-establish our face. . . JENNY BRITT: Re-verify identity. KASTE: Eric Schossow and Jenny Britt like the app, even if it's being a little touchy at the moment. Britt tries the selfie from a different angle. BRITT: It worked. SCHOSSOW: It worked. BRITT: It worked. KASTE: But others waiting to get into the arena have their doubts. John Howie happens to work in internet security, and he can't help but notice how much personal data CLEAR is getting from this crowd. JOHN HOWIE: I'm all for proving that you're vaccinated to get in. Using an app where you have to upload very personal, sensitive information is a bit concerning to me - use of biometrics, especially. KASTE: The Electronic Frontier Foundation has been saying something similar since the COVID vaccinations first rolled out. JON CALLAS: We are against proof of vaccination that creates a surveillance system. KASTE: The EFF's Jon Callas warns against tech companies that take advantage of new pandemic protocols to gather information they wouldn't otherwise get, something he calls COVID washing. CALLAS: This gives them a database that you have, quote, quote, \"consented to. \" And thus, they could do all sorts of things with it. KASTE: For instance, he says, that facial recognition that you give to CLEAR to get into a game today could end up allowing some other company to ID your face next year. But CLEAR says that's not what's happening. Its privacy policy promises not to rent or sell personal information, though it can share the data with companies it calls service providers. Rich Tucker is CLEAR's senior VP for privacy matters. RICH TUCKER: Core to CLEAR's values as a company are honoring member privacy. And we do that by empowering members, by giving them control over their information and by being transparent with how we use them. KASTE: CLEAR does hold on to that facial recognition information that people upload, except in Illinois, where state law doesn't allow open-ended retention of biometric data. In other states, customers can email CLEAR a request to delete their data. Tucker says the company is offering this free vaccination app in hopes that the people who sign up will choose to buy CLEAR's other services. TUCKER: CLEAR is never mandatory in any experience or opportunity. No one has to become a CLEAR member. That would be completely contrary to our identity as a company that's entirely opt-in. KASTE: In practice, though, you can find events that say everyone should use CLEAR, or they make it seem impractical for you not to. And it's understandable that big venues prefer this uniformity. In this, CLEAR is filling a void left by the government when the White House pledged in April not to create a national vaccine passport system. Mary Beth Kurilo is with the American Immunization Registry Association. MARY BETH KURILO: Because of the sort of decentralized nature of our health system and certainly our public health system, I think we are a little bit behind because we don't have some of the tools that we could leverage, like a national health identifier or a unique health identifier. So I think that does put us a little bit behind. KASTE: In the absence of a national system, some states are now offering their own vaccination apps, which follow a voluntary public-private standard called SMART Health Cards. They show proof of vaccination without gathering unnecessary personal information, such as facial recognition. Kurilo hopes the standard catches on, though she says for now, it's also important that venues keep accepting the old-fashioned paper vaccination cards so that no one's shut out because they can't or won't use an app. Martin Kaste, NPR News.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-11-15-1053917252": {"title": "The infrastructure law could be a lifeline for students without internet : NPR", "url": "https://www.npr.org/2021/11/15/1053917252/infrastructure-bill-broadband-internet-rural-college-students", "author": "No author found", "published_date": "2021-11-15", "content": "NOEL KING, HOST:  In the infrastructure bill that President Biden is going to sign into law today, there are $65 billion for broadband access in rural areas and tribal communities. Among the beneficiaries - college students who are still going to class online. NPR's Elissa Nadworny is following this one. Hey, Elissa. ELISSA NADWORNY, BYLINE: Good morning. KING: So what could this mean for college students? NADWORNY: Well, according to research from the Hope Center at Temple University, about 40% of college students have struggled with internet access during the pandemics. The real number could be much higher. And poor internet might be one factor that enrollment is down across the board, especially at community colleges. KING: OK, 40% is a very high number, and you say it might not even be the real number. I would imagine this is a particularly big problem in rural areas, yeah? NADWORNY: Absolutely, yeah, in parts of Appalachia and tribal communities. You know, for a long time, the logic here was there isn't a market, right? There's not enough people. They live too far apart from each other to merit high-quality, high-speed, affordable broadband. And the infrastructure bill could change that, especially for people living in tribal communities like the Navajo Nation, the largest reservation in the U. S. Here's how Christopher Ali, who studies internet access at the University of Virginia, explains it. CHRISTOPHER ALI: We know, we know, we know this problem is solvable because it's not a matter of technology. It's a matter of politics and market, right? By constantly prioritizing not only the private market, but prioritizing the largest providers who have no incentive - no financial incentive - to serve the Navajo Nation, they're not going to get served. NADWORNY: So the infrastructure bill aims to kind of realign those incentives. KING: You went to the Navajo Nation. NADWORNY: Yeah. KING: And what did you hear there? NADWORNY: Well, I spent a week there talking with students about how their lives have been affected by poor internet connections. And I want to introduce you to a student I met there. Faylene Begay lives on the Navajo Nation reservation in Arizona. And her home, where she lives with her four children, has Navajo teachings and blessings pinned up on the wall. FAYLENE BEGAY: This one is don't get mad - is (non-English language spoken). NADWORNY: She's been taking college classes for several years at Dine College, the nation's oldest tribal college. BEGAY: Oh, can we just - can I just sign on to my Zoom real quick? NADWORNY: She's working towards a degree in health occupations. She's logged into a pre-calculus class when we visit. UNIDENTIFIED PERSON: Faylene, you're actually taking your knowledge check now, aren't you? BEGAY: Yes, I'm doing the tools tutorials. NADWORNY: She does the practice problems in a notebook with her daughter's bright pink marker. BEGAY: The markers are more fun and vivid (laughter). NADWORNY: Her college education - it almost got completely derailed when campuses closed in spring of 2020. Internet access was a major challenge. She didn't have a home connection. All she had was an old cellphone, and it wasn't powerful enough to upload assignments. BEGAY: Doing the work alone is a lot of work, but not even able to submit it is just more tragic. NADWORNY: Her professors were understanding. But if they couldn't see her work, she couldn't get credit for it. She ended up passing but didn't do so well. BEGAY: That alone just kind of, like, depleted my purpose or, like, made me feel like I was defeated by the internet. NADWORNY: Begay didn't sign up for classes the next semester. She was sick of fighting with the internet. Around that time, about three hours away at Dine College's main campus in Tsaile, Ariz. , Charles \"Monty\" Roessel, the college's president, was focused on transitioning classes online, too. CHARLES MONTY ROESSEL: I remember sitting back in my chair. I said, we did it. We're done. NADWORNY: He quickly realized that students like Faylene Begay weren't able to receive the signal the college was sending out. ROESSEL: We didn't think about the idea that somebody has to access the course, right? It was just a one-way. It's online. NADWORNY: So the college shifted its focus to student access. It used federal CARES Act money to help purchase Wi-Fi hotspots and laptops for students. The college - which serves students across 27,000 square miles on the reservation, which spans multiple states - also built two additional microcampuses with internet in Utah and New Mexico so students didn't have to drive as far to get connected. But internet, Roessel says, is still a major problem. ROESSEL: We've got to look at the big picture and not just these little wins. NADWORNY: Sure, Wi-Fi hotspots, the new microcampuses help, he says, but they have limitations. ROESSEL: Don't get me wrong, it is helpful. But there's a larger issue here. NADWORNY: The much bigger need is for adequate infrastructure to provide reliable, quality home internet service. But those little wins - they did help Faylene Begay. Last spring, she decided it was time to go back to school. BEGAY: Everything just revolves around the internet. So if you don't have it. . . NADWORNY: She trails off, looking out the window. BEGAY: It's kind of like, you have to make sure that you do. NADWORNY: She now has a free Wi-Fi hotspot from the college and home internet, though neither option is particularly strong. Her internet can cut in and out, especially when it's windy. Twice now, she's had to give class presentations without her planned visuals because the internet wasn't stable enough. Her online chemistry labs require too much bandwidth to do at home, so she drives to a satellite campus - now open with limited hours - to use the school's internet. BEGAY: I do the best that I can, and I just try to stay positive. And I do not let bad internet bother me anymore. NADWORNY: Being back in class though has offered her a lifeline, a connection to professors and classmates at a time when she feels really alone. BEGAY: I went through a really bad depression during the time that the pandemic hit. NADWORNY: She was dealing with domestic violence, homelessness and a recent miscarriage. She mentions the Navajo word hozho to describe her reenrollment. It means balance and beauty, a state of harmony. Her persistence and focus - it's left an impression on her children. On her fridge, she's taped up a photo of herself in a lab coat looking into a microscope. BEGAY: My son, when he sees this, he says, you know, my mom's a scientist. I'm going to be a scientist, too. KING: I appreciate her ambition and his. And this big investment from the infrastructure bill is hopefully going to help students like Faylene. What is the next step, though? NADWORNY: So experts say getting good internet to rural communities is going to take a while, whether it's months or years. That's going to be up to states and localities, because they've got to decide where they're going to use the money and then they've got to actually implement programs, dig wire, build the infrastructure. And then, of course, they've got to maintain those programs once they're established. KING: Thanks for your reporting, Elissa. We appreciate it. NADWORNY: Oh, you're welcome. Thank you. KING: NPR's Elissa Nadworny. (SOUNDBITE OF RYKARD'S \"NORTH CORMORANT OBSCURITY\") NOEL KING, HOST:   In the infrastructure bill that President Biden is going to sign into law today, there are $65 billion for broadband access in rural areas and tribal communities. Among the beneficiaries - college students who are still going to class online. NPR's Elissa Nadworny is following this one. Hey, Elissa. ELISSA NADWORNY, BYLINE: Good morning. KING: So what could this mean for college students? NADWORNY: Well, according to research from the Hope Center at Temple University, about 40% of college students have struggled with internet access during the pandemics. The real number could be much higher. And poor internet might be one factor that enrollment is down across the board, especially at community colleges. KING: OK, 40% is a very high number, and you say it might not even be the real number. I would imagine this is a particularly big problem in rural areas, yeah? NADWORNY: Absolutely, yeah, in parts of Appalachia and tribal communities. You know, for a long time, the logic here was there isn't a market, right? There's not enough people. They live too far apart from each other to merit high-quality, high-speed, affordable broadband. And the infrastructure bill could change that, especially for people living in tribal communities like the Navajo Nation, the largest reservation in the U. S. Here's how Christopher Ali, who studies internet access at the University of Virginia, explains it. CHRISTOPHER ALI: We know, we know, we know this problem is solvable because it's not a matter of technology. It's a matter of politics and market, right? By constantly prioritizing not only the private market, but prioritizing the largest providers who have no incentive - no financial incentive - to serve the Navajo Nation, they're not going to get served. NADWORNY: So the infrastructure bill aims to kind of realign those incentives. KING: You went to the Navajo Nation. NADWORNY: Yeah. KING: And what did you hear there? NADWORNY: Well, I spent a week there talking with students about how their lives have been affected by poor internet connections. And I want to introduce you to a student I met there. Faylene Begay lives on the Navajo Nation reservation in Arizona. And her home, where she lives with her four children, has Navajo teachings and blessings pinned up on the wall. FAYLENE BEGAY: This one is don't get mad - is (non-English language spoken). NADWORNY: She's been taking college classes for several years at Dine College, the nation's oldest tribal college. BEGAY: Oh, can we just - can I just sign on to my Zoom real quick? NADWORNY: She's working towards a degree in health occupations. She's logged into a pre-calculus class when we visit. UNIDENTIFIED PERSON: Faylene, you're actually taking your knowledge check now, aren't you? BEGAY: Yes, I'm doing the tools tutorials. NADWORNY: She does the practice problems in a notebook with her daughter's bright pink marker. BEGAY: The markers are more fun and vivid (laughter). NADWORNY: Her college education - it almost got completely derailed when campuses closed in spring of 2020. Internet access was a major challenge. She didn't have a home connection. All she had was an old cellphone, and it wasn't powerful enough to upload assignments. BEGAY: Doing the work alone is a lot of work, but not even able to submit it is just more tragic. NADWORNY: Her professors were understanding. But if they couldn't see her work, she couldn't get credit for it. She ended up passing but didn't do so well. BEGAY: That alone just kind of, like, depleted my purpose or, like, made me feel like I was defeated by the internet. NADWORNY: Begay didn't sign up for classes the next semester. She was sick of fighting with the internet. Around that time, about three hours away at Dine College's main campus in Tsaile, Ariz. , Charles \"Monty\" Roessel, the college's president, was focused on transitioning classes online, too. CHARLES MONTY ROESSEL: I remember sitting back in my chair. I said, we did it. We're done. NADWORNY: He quickly realized that students like Faylene Begay weren't able to receive the signal the college was sending out. ROESSEL: We didn't think about the idea that somebody has to access the course, right? It was just a one-way. It's online. NADWORNY: So the college shifted its focus to student access. It used federal CARES Act money to help purchase Wi-Fi hotspots and laptops for students. The college - which serves students across 27,000 square miles on the reservation, which spans multiple states - also built two additional microcampuses with internet in Utah and New Mexico so students didn't have to drive as far to get connected. But internet, Roessel says, is still a major problem. ROESSEL: We've got to look at the big picture and not just these little wins. NADWORNY: Sure, Wi-Fi hotspots, the new microcampuses help, he says, but they have limitations. ROESSEL: Don't get me wrong, it is helpful. But there's a larger issue here. NADWORNY: The much bigger need is for adequate infrastructure to provide reliable, quality home internet service. But those little wins - they did help Faylene Begay. Last spring, she decided it was time to go back to school. BEGAY: Everything just revolves around the internet. So if you don't have it. . . NADWORNY: She trails off, looking out the window. BEGAY: It's kind of like, you have to make sure that you do. NADWORNY: She now has a free Wi-Fi hotspot from the college and home internet, though neither option is particularly strong. Her internet can cut in and out, especially when it's windy. Twice now, she's had to give class presentations without her planned visuals because the internet wasn't stable enough. Her online chemistry labs require too much bandwidth to do at home, so she drives to a satellite campus - now open with limited hours - to use the school's internet. BEGAY: I do the best that I can, and I just try to stay positive. And I do not let bad internet bother me anymore. NADWORNY: Being back in class though has offered her a lifeline, a connection to professors and classmates at a time when she feels really alone. BEGAY: I went through a really bad depression during the time that the pandemic hit. NADWORNY: She was dealing with domestic violence, homelessness and a recent miscarriage. She mentions the Navajo word hozho to describe her reenrollment. It means balance and beauty, a state of harmony. Her persistence and focus - it's left an impression on her children. On her fridge, she's taped up a photo of herself in a lab coat looking into a microscope. BEGAY: My son, when he sees this, he says, you know, my mom's a scientist. I'm going to be a scientist, too. KING: I appreciate her ambition and his. And this big investment from the infrastructure bill is hopefully going to help students like Faylene. What is the next step, though? NADWORNY: So experts say getting good internet to rural communities is going to take a while, whether it's months or years. That's going to be up to states and localities, because they've got to decide where they're going to use the money and then they've got to actually implement programs, dig wire, build the infrastructure. And then, of course, they've got to maintain those programs once they're established. KING: Thanks for your reporting, Elissa. We appreciate it. NADWORNY: Oh, you're welcome. Thank you. KING: NPR's Elissa Nadworny. (SOUNDBITE OF RYKARD'S \"NORTH CORMORANT OBSCURITY\")", "section": "Education", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-11-17-1056535646": {"title": "Apple Self Service Repair will enable customers to fix some of their own devices : NPR", "url": "https://www.npr.org/2021/11/17/1056535646/apple-self-service-repair-fix-iphones-mac-computers", "author": "No author found", "published_date": "2021-11-17", "content": "", "section": "Technology", "disclaimer": ""}, "2021-11-18-1056916140": {"title": "Facebook will examine whether it treats Black users differently : NPR", "url": "https://www.npr.org/2021/11/18/1056916140/facebook-to-study-black-users-experience", "author": "No author found", "published_date": "2021-11-18", "content": "", "section": "Technology", "disclaimer": ""}, "2021-11-18-1056941762": {"title": "States are investigating how Instagram recruits and affects children : NPR", "url": "https://www.npr.org/2021/11/18/1056941762/instagram-harm-to-kids-states-investigate", "author": "No author found", "published_date": "2021-11-18", "content": "", "section": "Technology", "disclaimer": ""}, "2021-11-18-1055387297": {"title": "What role should Meta, formerly Facebook, play in the metaverse? : NPR", "url": "https://www.npr.org/2021/11/18/1055387297/the-metaverse-is-already-here-the-debate-is-now-over-who-should-own-it", "author": "No author found", "published_date": "2021-11-18", "content": "", "section": "Technology", "disclaimer": ""}, "2021-11-20-1057693528": {"title": "A hiccup at Tesla left some owners stranded and searching for the user manual : NPR", "url": "https://www.npr.org/2021/11/20/1057693528/tesla-app-outage-drivers-stranded", "author": "No author found", "published_date": "2021-11-20", "content": "", "section": "Technology", "disclaimer": ""}, "2021-11-21-1056988346": {"title": "People are talking about Web3. Is it the Internet of the future or just a buzzword? : NPR", "url": "https://www.npr.org/2021/11/21/1056988346/web3-internet-jargon-or-future-vision", "author": "No author found", "published_date": "2021-11-21", "content": "AUDIE CORNISH, HOST:  There's a growing movement among cryptocurrency fans who say the internet will look a lot different in the future. People won't be relying as much on big players like Facebook, Google and Amazon. And the movement is called Web3, short for Web 3. 0. To help us understand this, we're joined by NPR tech reporter Bobby Allyn. And, Bobby, first, give us a better sense of how this all will work. BOBBY ALLYN, BYLINE: Yeah. Well, to answer that, I think we should take a few steps back. So the very early days of the internet are known as Web 1. 0 - right? - the era of dial-up, AOL, GeoCities, CompuServe, aka the Stone Age, right? Then came Web 2. 0 with social networks and search engines like Facebook and Google. Over time, as we all know, these companies became enormous, and it's now hard to use the internet without them. That's when this new movement, Web3, comes in. It says, let's build a brand-new internet that doesn't need these tech giants where, you know, new social media sites and search engines are created that are not tracking our data. I talked to Mat Dryhurst. He teaches at NYU's campus in Berlin, and he says the Web3 movement is about having regular people like you and me, Audie, own a piece of the internet along with the Mark Zuckerbergs of the world. MAT DRYHURST: There's a small group of people who kind of own all this stuff, and then there's us who use it. And despite the fact that we contribute, quite obviously, to the success of these platforms, we don't really have anything to show for it. ALLYN: Right. He's saying that Web3 is about owning a stake in the sites that we own - kind of like being a shareholder - so that, you know, we all have a say in how these platforms operate. CORNISH: Are big tech companies going to get a run for their money in this environment? I mean, how would it work? ALLYN: Yeah, so it gets a little wonky when you get into the details, so just try to bear with me, Audie. You know, all of our favorite sites, according to this idea, would move to what's known as the blockchain. And don't tune out just yet. Blockchains support cryptocurrencies like Bitcoin. It's basically like a bunch of different computers all over the world keeping track of our data. The idea is kind of like how Wikipedia is maintained by not just one person but lots of people at once. So imagine, instead of going to Google to try to find something online, you might go to this other site. And instead of being powered by a bunch of servers owned by Google, this search would be on the blockchain. In plain English, it's that a bunch of different servers around the world - it creates a record that cannot be changed. And it's not owned by one company. It's owned collectively by everyone. And these advocates say you'll want to use these sites because we'll all be partial owners of them. Every time it makes a decision, you can vote on it. And every time this company makes money, you can earn some cash. CORNISH: What would take the concept mainstream? ALLYN: Right. So it's hard to say right now. There's plenty of naysayers. And I think listeners might know why - because it might just kind of sound like a bunch of technobabble. Is it really going to take offers? There's just a bunch of nonsense, right? And yet, Audie, people are really taking this seriously. I was recently at a tech conference in Lisbon, and about half the sessions were about Web3. Major social media companies have teams out here in Silicon Valley dedicated to Web3. If you're a really cool tech person, Audie, what you do to show it these days is to put Web3 in your Twitter bio. Is it ever going to come to pass? We'll just have to wait and see, but it's the only thing that people out here in Silicon Valley are buzzing about. CORNISH: That's NPR tech reporter Bobby Allyn. Thanks so much. ALLYN: Thanks, Audie. (SOUNDBITE OF IMOGEN HEAP SONG, \"TIDAL\") AUDIE CORNISH, HOST:   There's a growing movement among cryptocurrency fans who say the internet will look a lot different in the future. People won't be relying as much on big players like Facebook, Google and Amazon. And the movement is called Web3, short for Web 3. 0. To help us understand this, we're joined by NPR tech reporter Bobby Allyn. And, Bobby, first, give us a better sense of how this all will work. BOBBY ALLYN, BYLINE: Yeah. Well, to answer that, I think we should take a few steps back. So the very early days of the internet are known as Web 1. 0 - right? - the era of dial-up, AOL, GeoCities, CompuServe, aka the Stone Age, right? Then came Web 2. 0 with social networks and search engines like Facebook and Google. Over time, as we all know, these companies became enormous, and it's now hard to use the internet without them. That's when this new movement, Web3, comes in. It says, let's build a brand-new internet that doesn't need these tech giants where, you know, new social media sites and search engines are created that are not tracking our data. I talked to Mat Dryhurst. He teaches at NYU's campus in Berlin, and he says the Web3 movement is about having regular people like you and me, Audie, own a piece of the internet along with the Mark Zuckerbergs of the world. MAT DRYHURST: There's a small group of people who kind of own all this stuff, and then there's us who use it. And despite the fact that we contribute, quite obviously, to the success of these platforms, we don't really have anything to show for it. ALLYN: Right. He's saying that Web3 is about owning a stake in the sites that we own - kind of like being a shareholder - so that, you know, we all have a say in how these platforms operate. CORNISH: Are big tech companies going to get a run for their money in this environment? I mean, how would it work? ALLYN: Yeah, so it gets a little wonky when you get into the details, so just try to bear with me, Audie. You know, all of our favorite sites, according to this idea, would move to what's known as the blockchain. And don't tune out just yet. Blockchains support cryptocurrencies like Bitcoin. It's basically like a bunch of different computers all over the world keeping track of our data. The idea is kind of like how Wikipedia is maintained by not just one person but lots of people at once. So imagine, instead of going to Google to try to find something online, you might go to this other site. And instead of being powered by a bunch of servers owned by Google, this search would be on the blockchain. In plain English, it's that a bunch of different servers around the world - it creates a record that cannot be changed. And it's not owned by one company. It's owned collectively by everyone. And these advocates say you'll want to use these sites because we'll all be partial owners of them. Every time it makes a decision, you can vote on it. And every time this company makes money, you can earn some cash. CORNISH: What would take the concept mainstream? ALLYN: Right. So it's hard to say right now. There's plenty of naysayers. And I think listeners might know why - because it might just kind of sound like a bunch of technobabble. Is it really going to take offers? There's just a bunch of nonsense, right? And yet, Audie, people are really taking this seriously. I was recently at a tech conference in Lisbon, and about half the sessions were about Web3. Major social media companies have teams out here in Silicon Valley dedicated to Web3. If you're a really cool tech person, Audie, what you do to show it these days is to put Web3 in your Twitter bio. Is it ever going to come to pass? We'll just have to wait and see, but it's the only thing that people out here in Silicon Valley are buzzing about. CORNISH: That's NPR tech reporter Bobby Allyn. Thanks so much. ALLYN: Thanks, Audie. (SOUNDBITE OF IMOGEN HEAP SONG, \"TIDAL\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-11-22-1053847627": {"title": "Tiny Tech Tips: The Best Wireless Earbuds : NPR", "url": "https://www.npr.org/2021/11/22/1053847627/tiny-tech-tips-the-best-wireless-earbuds", "author": "No author found", "published_date": "2021-11-22", "content": "", "section": "Tiny Tech Tips", "disclaimer": ""}, "2021-11-22-1037941547": {"title": "Rural broadband access remains a daily issue in remote Nevada : NPR", "url": "https://www.npr.org/2021/11/22/1037941547/life-without-reliable-broadband-internet-remains-a-daily-struggle-in-nevada", "author": "No author found", "published_date": "2021-11-22", "content": "", "section": "National", "disclaimer": ""}, "2021-11-23-1058019802": {"title": "Ex-Theranos CEO Elizabeth Holmes takes the witness stand in her fraud trial : NPR", "url": "https://www.npr.org/2021/11/23/1058019802/elizabeth-holmes-theranos-trial-testimony", "author": "No author found", "published_date": "2021-11-23", "content": "STEVE INSKEEP, HOST:  Lawyers say it is always risky when people accused of crimes testify in their own defense. Elizabeth Holmes is taking that risk. The founder of the blood testing company Theranos is accused of wire fraud and conspiracy connected to allegedly founding a successful tech company on lies, promoting blood testing that rarely worked. NPR's Bobby Allyn has been in the courthouse for the trial. Hey there, Bobby. BOBBY ALLYN, BYLINE: Morning, Steve. INSKEEP: What are you learning as Elizabeth Holmes talks? ALLYN: Yeah, so going into Holmes' testimony, prosecutors alleged that Theranos sent these forged documents to potential investors and business partners of Theranos, including retail chains like Walgreens. And these documents were reports supporting Theranos technology written on the letterhead of drug companies like Pfizer. Now, Steve, the big problem here is Pfizer wanted nothing to do with Theranos. Elizabeth Holmes said from the stand that she personally placed drug company logos, like Pfizer's logo, on these documents, and she said she did it to a knowledge past work Theranos did with Pfizer. And look; Theranos did have some small contracts with Pfizer, but they never consented to these letters. INSKEEP: I'm trying to figure out why you would get up on the stand to testify to this. She's saying, I faked documents, in effect. How did she justify that? ALLYN: Well, the prosecutors kind of got her here. So she did concede this, right? Holmes said, you know, she never intended to deceive anyone, and that's key here because prosecutors need to prove intent in order to convict. But she said, you know, she wishes she handled the whole thing a little differently. And I got to really underscore here that, you know, Holmes even admitting that is a really big deal because her core defense, this - since she's got on the stand was - it has been basically to point the finger at other people, medical experts on the board of directors, lab scientists, her deputy at Theranos. She's suggesting that everyone at the company except for her was responsible for the company's failures. INSKEEP: Except that she faked the letterhead, she says in her own testimony. How does that revelation fit in with the broader prosecution story of what Holmes did? ALLYN: Yeah, prosecutors say Holmes ran an operation full of deception, not just this letterhead. It goes far beyond that, according to prosecutors. And, you know, that basically this company was struggling, and she allegedly misrepresented the financials of the company. She misrepresented what these blood tests were capable of. You know, prosecutors played for a jury recordings of Holmes bragging about partnerships that never panned out. I mean, they even had former Defense Secretary Jim Mattis go on the stand and talk about how he thought Theranos was about to develop blood tests that could save lives on the battlefield. That never happened. Prosecutors say for years Elizabeth Holmes put on a charm, lots of charm. You know, she puffed up the company and made investors lose millions of dollars and provided faulty or just flat-out wrong tests to patients. Like, there was one woman who said that a Theranos test said she was having a miscarriage, Steve, when in fact she was really carrying a healthy baby. INSKEEP: So what goes next in this trial? ALLYN: Yeah, so the jury so far has only heard Holmes answer pretty easy questions from her own lawyer, but soon that is going to change because federal prosecutors will have their turn to pepper Holmes with much tougher questions. That could get dramatic. And, you know, whether her credibility survives that grilling, you know, that could have a big influence on how the jury feels going into deliberations over the fate of Holmes. Of course, she's at this trial because she's long maintained her innocence, but if she is convicted, she could face, you know, some pretty hefty prison time here. INSKEEP: Now she's trying to tell her story. NPR's Bobby Allyn, thanks. ALLYN: Thanks. STEVE INSKEEP, HOST:   Lawyers say it is always risky when people accused of crimes testify in their own defense. Elizabeth Holmes is taking that risk. The founder of the blood testing company Theranos is accused of wire fraud and conspiracy connected to allegedly founding a successful tech company on lies, promoting blood testing that rarely worked. NPR's Bobby Allyn has been in the courthouse for the trial. Hey there, Bobby. BOBBY ALLYN, BYLINE: Morning, Steve. INSKEEP: What are you learning as Elizabeth Holmes talks? ALLYN: Yeah, so going into Holmes' testimony, prosecutors alleged that Theranos sent these forged documents to potential investors and business partners of Theranos, including retail chains like Walgreens. And these documents were reports supporting Theranos technology written on the letterhead of drug companies like Pfizer. Now, Steve, the big problem here is Pfizer wanted nothing to do with Theranos. Elizabeth Holmes said from the stand that she personally placed drug company logos, like Pfizer's logo, on these documents, and she said she did it to a knowledge past work Theranos did with Pfizer. And look; Theranos did have some small contracts with Pfizer, but they never consented to these letters. INSKEEP: I'm trying to figure out why you would get up on the stand to testify to this. She's saying, I faked documents, in effect. How did she justify that? ALLYN: Well, the prosecutors kind of got her here. So she did concede this, right? Holmes said, you know, she never intended to deceive anyone, and that's key here because prosecutors need to prove intent in order to convict. But she said, you know, she wishes she handled the whole thing a little differently. And I got to really underscore here that, you know, Holmes even admitting that is a really big deal because her core defense, this - since she's got on the stand was - it has been basically to point the finger at other people, medical experts on the board of directors, lab scientists, her deputy at Theranos. She's suggesting that everyone at the company except for her was responsible for the company's failures. INSKEEP: Except that she faked the letterhead, she says in her own testimony. How does that revelation fit in with the broader prosecution story of what Holmes did? ALLYN: Yeah, prosecutors say Holmes ran an operation full of deception, not just this letterhead. It goes far beyond that, according to prosecutors. And, you know, that basically this company was struggling, and she allegedly misrepresented the financials of the company. She misrepresented what these blood tests were capable of. You know, prosecutors played for a jury recordings of Holmes bragging about partnerships that never panned out. I mean, they even had former Defense Secretary Jim Mattis go on the stand and talk about how he thought Theranos was about to develop blood tests that could save lives on the battlefield. That never happened. Prosecutors say for years Elizabeth Holmes put on a charm, lots of charm. You know, she puffed up the company and made investors lose millions of dollars and provided faulty or just flat-out wrong tests to patients. Like, there was one woman who said that a Theranos test said she was having a miscarriage, Steve, when in fact she was really carrying a healthy baby. INSKEEP: So what goes next in this trial? ALLYN: Yeah, so the jury so far has only heard Holmes answer pretty easy questions from her own lawyer, but soon that is going to change because federal prosecutors will have their turn to pepper Holmes with much tougher questions. That could get dramatic. And, you know, whether her credibility survives that grilling, you know, that could have a big influence on how the jury feels going into deliberations over the fate of Holmes. Of course, she's at this trial because she's long maintained her innocence, but if she is convicted, she could face, you know, some pretty hefty prison time here. INSKEEP: Now she's trying to tell her story. NPR's Bobby Allyn, thanks. ALLYN: Thanks.", "section": "Business", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-11-24-1058770506": {"title": "Samsung Announces Plans For $17 Billion Semiconductor Factory Outside Austin : NPR", "url": "https://www.npr.org/2021/11/24/1058770506/samsung-says-it-will-build-17b-chip-factory-in-texas", "author": "No author found", "published_date": "2021-11-24", "content": "", "section": "National", "disclaimer": ""}, "2021-11-25-1059262101": {"title": "A new website promises better Thanksgiving dinner conversations : NPR", "url": "https://www.npr.org/2021/11/25/1059262101/a-new-website-promises-better-thanksgiving-dinner-conversations", "author": "No author found", "published_date": "2021-11-25", "content": "AUDIE CORNISH, HOST:  This year, you can add an insurrection, vaccination status and the nature of truth itself to the list of topics that could threaten to derail your Thanksgiving dinner. And since we're well into the day, maybe they already have. But if it's not too late and you're - I don't know - looking for an escape hatch from a wine-soaked political debate, David Orlic wants to help. DAVID ORLIC: We created this game to help reduce Thanksgiving anxiety, or \"Thanxiety,\" and make this holiday lovely. CORNISH: Thanxiety. com is a project of a startup called Anyone. Orlic is its CEO. And the game is basically a conversation prompt generator. ORLIC: So you can either swipe between them until you find a topic that you like or that you think would work around the table or you can shuffle and get a random topic. CORNISH: Some of the prompts are lighter fare. For instance - what's your all-time favorite condiment? Or take two sitcom characters from different shows and match them to co-star in a brand-new show of your own creation. But some are deeper. Here's one of Orlic's favorites. ORLIC: What's a lesson your parents taught you, either actively or by example, that sticks with you to this day? That question, you know, in itself can tell your whole life story. Like, the values that we're brought up with tend to stick with us. And it's a great way to understand where someone is coming from. CORNISH: Full disclosure - some of the prompts do seem to flirt with those dreaded political topics. You might see, quote, \"what do you think is the role or responsibility of billionaires in our society? \" Mortality is also on the menu. For instance - what happens after we die? But Orlic says even fraught topics can yield productive conversations with the right approach. ORLIC: Just that act, the act of asking something and listening rather than coming in full force and telling people how things are, I think produces a completely different result. CORNISH: But if that still seems dicey, you could always retreat to that safest of topics - Tom Hanks. ORLIC: What is your favorite Tom Hanks movie and why? I mean, is it \"Castaway? \" Is it \"Forrest Gump? \" Is it \"Toy Story? \" Is it \"A League Of Their Own? \" Resort to pop culture if all else fails. CORNISH: Although, if your uncle answers \"The Polar Express,\" it's OK to ask him to leave. This is NPR News. AUDIE CORNISH, HOST:   This year, you can add an insurrection, vaccination status and the nature of truth itself to the list of topics that could threaten to derail your Thanksgiving dinner. And since we're well into the day, maybe they already have. But if it's not too late and you're - I don't know - looking for an escape hatch from a wine-soaked political debate, David Orlic wants to help. DAVID ORLIC: We created this game to help reduce Thanksgiving anxiety, or \"Thanxiety,\" and make this holiday lovely. CORNISH: Thanxiety. com is a project of a startup called Anyone. Orlic is its CEO. And the game is basically a conversation prompt generator. ORLIC: So you can either swipe between them until you find a topic that you like or that you think would work around the table or you can shuffle and get a random topic. CORNISH: Some of the prompts are lighter fare. For instance - what's your all-time favorite condiment? Or take two sitcom characters from different shows and match them to co-star in a brand-new show of your own creation. But some are deeper. Here's one of Orlic's favorites. ORLIC: What's a lesson your parents taught you, either actively or by example, that sticks with you to this day? That question, you know, in itself can tell your whole life story. Like, the values that we're brought up with tend to stick with us. And it's a great way to understand where someone is coming from. CORNISH: Full disclosure - some of the prompts do seem to flirt with those dreaded political topics. You might see, quote, \"what do you think is the role or responsibility of billionaires in our society? \" Mortality is also on the menu. For instance - what happens after we die? But Orlic says even fraught topics can yield productive conversations with the right approach. ORLIC: Just that act, the act of asking something and listening rather than coming in full force and telling people how things are, I think produces a completely different result. CORNISH: But if that still seems dicey, you could always retreat to that safest of topics - Tom Hanks. ORLIC: What is your favorite Tom Hanks movie and why? I mean, is it \"Castaway? \" Is it \"Forrest Gump? \" Is it \"Toy Story? \" Is it \"A League Of Their Own? \" Resort to pop culture if all else fails. CORNISH: Although, if your uncle answers \"The Polar Express,\" it's OK to ask him to leave. This is NPR News.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-11-25-1059026412": {"title": "Here's what's open on Thanksgiving Day 2021 : NPR", "url": "https://www.npr.org/2021/11/25/1059026412/whats-open-thanksgiving-black-friday", "author": "No author found", "published_date": "2021-11-25", "content": "", "section": "Business", "disclaimer": ""}, "2021-11-26-1059413217": {"title": "Can a group of crypto investors buy an NBA team? : NPR", "url": "https://www.npr.org/2021/11/26/1059413217/crypto-enthusiasts-want-to-buy-an-nba-team-after-failing-to-purchase-us-constitu", "author": "No author found", "published_date": "2021-11-26", "content": "", "section": "Technology", "disclaimer": ""}, "2021-11-29-1059916883": {"title": "Elizabeth Holmes testifies about alleged abuse by Romesh 'Sunny' Balwani : NPR", "url": "https://www.npr.org/2021/11/29/1059916883/elizabeth-holmes-testimony-trial-theranos", "author": "No author found", "published_date": "2021-11-29", "content": "", "section": "Technology", "disclaimer": ""}, "2021-11-29-1059821677": {"title": "Ex-Google workers sue company, saying it betrayed 'Don't Be Evil' motto : NPR", "url": "https://www.npr.org/2021/11/29/1059821677/google-dont-be-evil-lawsuit", "author": "No author found", "published_date": "2021-11-29", "content": "", "section": "Technology", "disclaimer": ""}, "2021-11-29-1059756077": {"title": "Jack Dorsey steps down as Twitter CEO; Parag Agrawal succeeds him : NPR", "url": "https://www.npr.org/2021/11/29/1059756077/jack-dorsey-steps-down-as-twitter-ceo", "author": "No author found", "published_date": "2021-11-29", "content": "AUDIE CORNISH, HOST:  It's the end of an era at Twitter. Co-founder Jack Dorsey, known for his long beard, love of globetrotting and Bitcoin, has stepped down as CEO. NPR's tech correspondent Shannon Bond has more. SHANNON BOND, BYLINE: Jack Dorsey has often seemed uncomfortable with the power that comes with leading a high-profile tech company, unlike Facebook founder Mark Zuckerberg. Last year, when the New York Times Daily podcast asked if he believes he's one of the most powerful people on Earth, Dorsey said no. (SOUNDBITE OF ARCHIVED RECORDING)JACK DORSEY: Everything that has made Twitter powerful has come from the people using it. The people really pushed the direction of where the service goes and what it is and what it wants to be. And our job as a company - my job as an individual at the company is to be a checkpoint on that. BOND: Now, Dorsey says, it's time for him to move on from Twitter. In an email to staff, he says a company being founder-led is, quote, \"severely limiting and a single point of failure. \" Over the years, though, Dorsey has been criticized by investors and employees for not being focused enough on Twitter. In an unusual arrangement, he's also CEO of another public company, the payment processor Square. Last year, Dorsey survived an attempt by activist shareholders to force him out of the top job at Twitter. He acknowledged to investors in February the company has been slow to change, unlike its social media peers. (SOUNDBITE OF ARCHIVED RECORDING)DORSEY: Why don't we start with why folks don't believe in us? It comes down to three critiques. We're slow, we're not innovative, and we're not trusted. BOND: In an effort to attract new users and double annual revenue, Twitter has rolled out new features, including subscriptions and audio chat. Meanwhile, Dorsey has also been attacked by conservatives, who claim Twitter censors them, as when it banned then-President Donald Trump after the January 6 Capitol insurrection. Now these questions of Twitter's power will be up to Parag Agarwal, the company's technology chief. He's taking over as CEO immediately, leaving Dorsey free to pursue his other interests. Shannon Bond, NPR News. (SOUNDBITE OF MYLO'S \"ZENOPHILE\") AUDIE CORNISH, HOST:   It's the end of an era at Twitter. Co-founder Jack Dorsey, known for his long beard, love of globetrotting and Bitcoin, has stepped down as CEO. NPR's tech correspondent Shannon Bond has more. SHANNON BOND, BYLINE: Jack Dorsey has often seemed uncomfortable with the power that comes with leading a high-profile tech company, unlike Facebook founder Mark Zuckerberg. Last year, when the New York Times Daily podcast asked if he believes he's one of the most powerful people on Earth, Dorsey said no. (SOUNDBITE OF ARCHIVED RECORDING) JACK DORSEY: Everything that has made Twitter powerful has come from the people using it. The people really pushed the direction of where the service goes and what it is and what it wants to be. And our job as a company - my job as an individual at the company is to be a checkpoint on that. BOND: Now, Dorsey says, it's time for him to move on from Twitter. In an email to staff, he says a company being founder-led is, quote, \"severely limiting and a single point of failure. \" Over the years, though, Dorsey has been criticized by investors and employees for not being focused enough on Twitter. In an unusual arrangement, he's also CEO of another public company, the payment processor Square. Last year, Dorsey survived an attempt by activist shareholders to force him out of the top job at Twitter. He acknowledged to investors in February the company has been slow to change, unlike its social media peers. (SOUNDBITE OF ARCHIVED RECORDING) DORSEY: Why don't we start with why folks don't believe in us? It comes down to three critiques. We're slow, we're not innovative, and we're not trusted. BOND: In an effort to attract new users and double annual revenue, Twitter has rolled out new features, including subscriptions and audio chat. Meanwhile, Dorsey has also been attacked by conservatives, who claim Twitter censors them, as when it banned then-President Donald Trump after the January 6 Capitol insurrection. Now these questions of Twitter's power will be up to Parag Agarwal, the company's technology chief. He's taking over as CEO immediately, leaving Dorsey free to pursue his other interests. Shannon Bond, NPR News. (SOUNDBITE OF MYLO'S \"ZENOPHILE\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-11-30-1060154461": {"title": "Elizabeth Holmes grilled by prosecutors on witness stand : NPR", "url": "https://www.npr.org/2021/11/30/1060154461/elizabeth-holmes-theranos-trial-testimony", "author": "No author found", "published_date": "2021-11-30", "content": "ARI SHAPIRO, HOST:  The woman once seen as the female Steve Jobs is trying to convince a jury that she is not guilty of fraud. Elizabeth Holmes is the founder of the now-collapsed biotech startup Theranos, and she's been testifying before a jury for five days in Silicon Valley. NPR's Bobby Allyn has been in the courtroom. Hi, Bobby. BOBBY ALLYN, BYLINE: Hey, Ari. SHAPIRO: Before you describe her defense, remind us what crimes Elizabeth Holmes is charged with. ALLYN: Prosecutors say she intentionally lied to investors and patients and doctors about what Theranos could do. Remember, Theranos was hailed for creating this medical breakthrough - being able to test for, you know, hundreds of conditions with just this tiny little pinprick of blood from the tip of your finger. That would mean no big needles if it were true. But prosecutors already say, you know, the problem is she duped investors about the technology and delivered false results to patients, and in the process, she got rich. Holmes was once considered the world's youngest self-made female billionaire. SHAPIRO: And she's been testifying for five days. What is she saying in her defense? ALLYN: Yeah, her defense is really twofold. She's told the jury that, look, she made mistakes. She now regrets those mistakes, but she never broke the law. And then there's this more controversial part of her defense, and it involves her ex-boyfriend and business partner, Sunny Balwani. She says he emotionally and sexually abused her. She says that alleged abuse clouded her judgment. And, you know, when she was describing this, Ari, the courtroom got really emotional. I mean, she was speaking haltingly. She was dabbing her eyes with a tissue. It was a really intense moment. And when I talked to legal experts about what they made of this - you know, bringing in abuse charges in a white-collar criminal trial - there was a lot of debate about whether it would benefit or not benefit her. I talked to Tom Mesereau. He's a longtime criminal defense lawyer, and he's represented Michael Jackson and Bill Cosby. THOMAS MESEREAU: We live in the #MeToo era, where jurors tend to be much more open and receptive to allegations of abuse in relationships. So from where I sit, I think the defense is smart to present it. SHAPIRO: How have prosecutors responded to the abuse allegations in court? ALLYN: Yeah. They said, you know, since Holmes was CEO of Theranos, she could have fired Balwani, her No. 2, whenever she wanted. And prosecutors also said Holmes' relationship with Balwani just wasn't as bad as she was saying. The main prosecutor here in the trial - his name is Robert Leach. He showed the jury dozens of these lovey-dovey text messages where Holmes called Balwani, quote, \"my king\" and, quote, \"my tiger. \" It was pretty awkward to hear this. And, you know, legal experts say when Holmes introduced the abuse allegations, she was setting herself up for this line of questioning, for the government to confront her on this. Balwani, we should note, has a separate trial next year. SHAPIRO: It's risky for Holmes to take the stand in her defense, right? Why did they decide to put her on? ALLYN: It is risky. But remember; Holmes' superpower is her charm. That is how she landed on magazine covers, and that is how she raised millions of dollars from very savvy investors. But over this three-month trial, Ari, you know, the government has had company whistleblowers, patients, former board members of the company testify against her. You know, they have documents, they say, that show that, you know, Holmes, you know, forged these documents to try to win business. And they have recordings that they played for the jury about business partnerships Holmes was bragging about that never panned out. And so in light of all of that pretty strong evidence, I asked defense attorney Mesereau, would you have put her on the stand? And here's what he said. MESEREAU: If she doesn't do that, she remains an abstraction. It's much easier to attack an abstraction than it is a likable, believable, relatable human being. ALLYN: That's Mesereau's opinion. We'll see what the jury thinks about whether or not Elizabeth Holmes is believable. Next week, the jury will be deliberating - probably at the end of the week. SHAPIRO: NPR's Bobby Allyn. Thank you. ALLYN: Thanks, Ari. (SOUNDBITE OF MUSIC) ARI SHAPIRO, HOST:   The woman once seen as the female Steve Jobs is trying to convince a jury that she is not guilty of fraud. Elizabeth Holmes is the founder of the now-collapsed biotech startup Theranos, and she's been testifying before a jury for five days in Silicon Valley. NPR's Bobby Allyn has been in the courtroom. Hi, Bobby. BOBBY ALLYN, BYLINE: Hey, Ari. SHAPIRO: Before you describe her defense, remind us what crimes Elizabeth Holmes is charged with. ALLYN: Prosecutors say she intentionally lied to investors and patients and doctors about what Theranos could do. Remember, Theranos was hailed for creating this medical breakthrough - being able to test for, you know, hundreds of conditions with just this tiny little pinprick of blood from the tip of your finger. That would mean no big needles if it were true. But prosecutors already say, you know, the problem is she duped investors about the technology and delivered false results to patients, and in the process, she got rich. Holmes was once considered the world's youngest self-made female billionaire. SHAPIRO: And she's been testifying for five days. What is she saying in her defense? ALLYN: Yeah, her defense is really twofold. She's told the jury that, look, she made mistakes. She now regrets those mistakes, but she never broke the law. And then there's this more controversial part of her defense, and it involves her ex-boyfriend and business partner, Sunny Balwani. She says he emotionally and sexually abused her. She says that alleged abuse clouded her judgment. And, you know, when she was describing this, Ari, the courtroom got really emotional. I mean, she was speaking haltingly. She was dabbing her eyes with a tissue. It was a really intense moment. And when I talked to legal experts about what they made of this - you know, bringing in abuse charges in a white-collar criminal trial - there was a lot of debate about whether it would benefit or not benefit her. I talked to Tom Mesereau. He's a longtime criminal defense lawyer, and he's represented Michael Jackson and Bill Cosby. THOMAS MESEREAU: We live in the #MeToo era, where jurors tend to be much more open and receptive to allegations of abuse in relationships. So from where I sit, I think the defense is smart to present it. SHAPIRO: How have prosecutors responded to the abuse allegations in court? ALLYN: Yeah. They said, you know, since Holmes was CEO of Theranos, she could have fired Balwani, her No. 2, whenever she wanted. And prosecutors also said Holmes' relationship with Balwani just wasn't as bad as she was saying. The main prosecutor here in the trial - his name is Robert Leach. He showed the jury dozens of these lovey-dovey text messages where Holmes called Balwani, quote, \"my king\" and, quote, \"my tiger. \" It was pretty awkward to hear this. And, you know, legal experts say when Holmes introduced the abuse allegations, she was setting herself up for this line of questioning, for the government to confront her on this. Balwani, we should note, has a separate trial next year. SHAPIRO: It's risky for Holmes to take the stand in her defense, right? Why did they decide to put her on? ALLYN: It is risky. But remember; Holmes' superpower is her charm. That is how she landed on magazine covers, and that is how she raised millions of dollars from very savvy investors. But over this three-month trial, Ari, you know, the government has had company whistleblowers, patients, former board members of the company testify against her. You know, they have documents, they say, that show that, you know, Holmes, you know, forged these documents to try to win business. And they have recordings that they played for the jury about business partnerships Holmes was bragging about that never panned out. And so in light of all of that pretty strong evidence, I asked defense attorney Mesereau, would you have put her on the stand? And here's what he said. MESEREAU: If she doesn't do that, she remains an abstraction. It's much easier to attack an abstraction than it is a likable, believable, relatable human being. ALLYN: That's Mesereau's opinion. We'll see what the jury thinks about whether or not Elizabeth Holmes is believable. Next week, the jury will be deliberating - probably at the end of the week. SHAPIRO: NPR's Bobby Allyn. Thank you. ALLYN: Thanks, Ari. (SOUNDBITE OF MUSIC)", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-11-30-1060035782": {"title": "Meet Parag Agrawal, Twitter's new CEO : NPR", "url": "https://www.npr.org/2021/11/30/1060035782/parag-agarwal-twitter-ceo", "author": "No author found", "published_date": "2021-11-30", "content": "", "section": "Technology", "disclaimer": ""}, "2021-11-30-1059990217": {"title": "Twitter CTO Parag Agrawal succeeds Jack Dorsey as the company's CEO : NPR", "url": "https://www.npr.org/2021/11/30/1059990217/twitter-cto-parag-agrawal-succeeds-jack-dorsey-as-the-companys-ceo", "author": "No author found", "published_date": "2021-11-30", "content": "A MARTINEZ, HOST:  There's been a changing of the guard at Twitter. CEO Jack Dorsey, the eccentric co-founder known for his dedication to meditation, fasting and Bitcoin, has stepped down. Replacing him is a Twitter veteran few outside the company have heard of. NPR's tech correspondent Shannon Bond has more. SHANNON BOND, BYLINE: Jack Dorsey left Twitter once before. In 2008, he was pushed out as CEO after clashing with a fellow co-founder. He told employees in an email yesterday, this time, he's leaving on his own terms. The handover comes at a critical moment for big social media platforms. MARGARET O'MARA: There's a lot of heat and a lot of friction and politics associated with being these social networks on which so much public conversation plays out. BOND: Margaret O'Mara is a Silicon Valley historian. She points to Facebook's recent pivot to building the so-called metaverse. O'MARA: So too, perhaps, Twitter is looking at, what is the next-gen social network going to be? BOND: Now the man responsible for answering that question is Parag Agrawal. He's a Stanford-trained computer scientist who joined Twitter as a software engineer a decade ago. He became chief technology officer in 2017. Twitter insiders say Agrawal is a close confidant of Dorsey who shares his vision of a future in which Twitter runs on technology that gives users greater control. They expect cryptocurrency and the blockchain to play big roles. Dorsey has been talking up this vision to investors for a while. Here he is on an earnings call this summer. (SOUNDBITE OF ARCHIVED RECORDING)JACK DORSEY: So obviously, I've been reading and talking a lot about Bitcoin. So I thought it was important to explain a little bit more as to why. BOND: While some current and former employees told NPR they were surprised, Agrawal was tapped for the role, Dorsey says his trust in his successor is, quote, \"bone deep. \" As technology chief, Agrawal worked on machine learning and other technical advances that have allowed Twitter to roll out new features and products more quickly as it's tried to shake off a reputation for being slow to innovate. Historian O'Mara says choosing Agrawal to succeed Dorsey is a signal. . . O'MARA: That the technology itself, the technology of the platform and redesigning what social media is like will be something that Twitter is trying to center going forward. BOND: Now it will be Agrawal, not Dorsey, who's the public face of that vision. Shannon Bond, NPR News. (SOUNDBITE OF MARLEY CARROLL'S \"STARLINGS\") A MARTINEZ, HOST:   There's been a changing of the guard at Twitter. CEO Jack Dorsey, the eccentric co-founder known for his dedication to meditation, fasting and Bitcoin, has stepped down. Replacing him is a Twitter veteran few outside the company have heard of. NPR's tech correspondent Shannon Bond has more. SHANNON BOND, BYLINE: Jack Dorsey left Twitter once before. In 2008, he was pushed out as CEO after clashing with a fellow co-founder. He told employees in an email yesterday, this time, he's leaving on his own terms. The handover comes at a critical moment for big social media platforms. MARGARET O'MARA: There's a lot of heat and a lot of friction and politics associated with being these social networks on which so much public conversation plays out. BOND: Margaret O'Mara is a Silicon Valley historian. She points to Facebook's recent pivot to building the so-called metaverse. O'MARA: So too, perhaps, Twitter is looking at, what is the next-gen social network going to be? BOND: Now the man responsible for answering that question is Parag Agrawal. He's a Stanford-trained computer scientist who joined Twitter as a software engineer a decade ago. He became chief technology officer in 2017. Twitter insiders say Agrawal is a close confidant of Dorsey who shares his vision of a future in which Twitter runs on technology that gives users greater control. They expect cryptocurrency and the blockchain to play big roles. Dorsey has been talking up this vision to investors for a while. Here he is on an earnings call this summer. (SOUNDBITE OF ARCHIVED RECORDING) JACK DORSEY: So obviously, I've been reading and talking a lot about Bitcoin. So I thought it was important to explain a little bit more as to why. BOND: While some current and former employees told NPR they were surprised, Agrawal was tapped for the role, Dorsey says his trust in his successor is, quote, \"bone deep. \" As technology chief, Agrawal worked on machine learning and other technical advances that have allowed Twitter to roll out new features and products more quickly as it's tried to shake off a reputation for being slow to innovate. Historian O'Mara says choosing Agrawal to succeed Dorsey is a signal. . . O'MARA: That the technology itself, the technology of the platform and redesigning what social media is like will be something that Twitter is trying to center going forward. BOND: Now it will be Agrawal, not Dorsey, who's the public face of that vision. Shannon Bond, NPR News. (SOUNDBITE OF MARLEY CARROLL'S \"STARLINGS\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-12-01-1060635724": {"title": "Meta is reversing policy that kept Kyle Rittenhouse from Facebook and Instagram : NPR", "url": "https://www.npr.org/2021/12/01/1060635724/meta-facebook-instagram-kyle-rittenhouse", "author": "No author found", "published_date": "2021-12-01", "content": "", "section": "Technology", "disclaimer": ""}, "2021-12-01-1060645940": {"title": "Facebook takes down China-based network spreading false COVID-19 claims : NPR", "url": "https://www.npr.org/2021/12/01/1060645940/facebook-takes-down-china-based-fake-covid-claims", "author": "No author found", "published_date": "2021-12-01", "content": "", "section": "Technology", "disclaimer": ""}, "2021-12-01-1060600043": {"title": "Twitter policy aimed at improving privacy sparks concerns over misuse : NPR", "url": "https://www.npr.org/2021/12/01/1060600043/twitter-photo-removal-policy-aimed-at-improving-privacy-sparks-concerns-over-mis", "author": "No author found", "published_date": "2021-12-01", "content": "", "section": "Technology", "disclaimer": ""}, "2021-12-01-1060027395": {"title": "Living robots known as xenobots can self-replicate : NPR", "url": "https://www.npr.org/2021/12/01/1060027395/robots-xenobots-living-self-replicating-copy", "author": "No author found", "published_date": "2021-12-01", "content": "", "section": "Science", "disclaimer": ""}, "2021-12-02-1061012795": {"title": "FTC sued to block Nvidia-Arm merger, which would be largest in chip industry : NPR", "url": "https://www.npr.org/2021/12/02/1061012795/ftc-sues-to-block-nvidia-arm-merger", "author": "No author found", "published_date": "2021-12-02", "content": "", "section": "Technology", "disclaimer": ""}, "2021-12-02-1060597759": {"title": "Debt collectors can now text you, email you and DM you on social media : NPR", "url": "https://www.npr.org/2021/12/02/1060597759/debt-collectors-can-now-text-email-and-dm-you-on-social-media", "author": "No author found", "published_date": "2021-12-02", "content": "", "section": "Business", "disclaimer": ""}, "2021-12-03-1061232540": {"title": "Netflix developing film about viral Thanksgiving grandma text : NPR", "url": "https://www.npr.org/2021/12/03/1061232540/netflix-is-making-a-feature-film-about-the-thanksgiving-grandma-text-mix-up", "author": "No author found", "published_date": "2021-12-03", "content": "", "section": "Movies", "disclaimer": ""}, "2021-12-03-1061219965": {"title": "Didi Chuxing, Chinese ride-hailing company, delists from New York Stock Exchange : NPR", "url": "https://www.npr.org/2021/12/03/1061219965/a-top-chinese-tech-company-delists-from-the-nyse-just-months-after-its-ipo", "author": "No author found", "published_date": "2021-12-03", "content": "", "section": "Business", "disclaimer": ""}, "2021-12-04-1061539843": {"title": "European values are starting to define U.S. tech privacy, says journalist : NPR", "url": "https://www.npr.org/2021/12/04/1061539843/european-values-are-starting-to-define-u-s-tech-privacy-says-journalist", "author": "No author found", "published_date": "2021-12-04", "content": "DAVID FOLKENFLIK, HOST:  The social media giant Twitter introduced a new CEO and announced major leadership changes this week after co-founder and longtime head Jack Dorsey stepped down Monday. And that's far from the only news the site generated this week. On Tuesday, the platform made another announcement. It will ban users from sharing photos or videos of private individuals without their permission in an acknowledgment of concerns about privacy. The new policy sparked some criticism it would stifle free speech, but as my next guest notes, it's not exactly new for Twitter. Twitter's had it in place for the past five years in the European Union. The tech journalist Casey Newton argues that European values are starting to define the experience of Americans on the internet. Newton runs the Substack publication Platformer, and he joins us now. Hey, Casey. CASEY NEWTON: Hey, David. FOLKENFLIK: So start us off. Tell us, what does this policy actually do? NEWTON: So the idea of the policy is that if you're an average citizen and someone takes a photo or video of you and you don't like it because you feel like it's harassing you or making fun of you in some way, you can request that Twitter takes it down. And if Twitter looks at it and they think, yep, you're being harassed, they will go ahead and remove it. There are a lot of exceptions to that policy, though, which we should probably also talk about. FOLKENFLIK: OK. NEWTON: So for example, if you're at a public protest, protesting, Twitter says they will keep photos and videos of you up. You're participating in the public discourse. If you are a celebrity or a politician or an activist or a journalist, you will not have the same ability to get media of yourself removed that average citizens do. So Twitter says that when this policy is enforced properly, it should only serve to protect people who don't have, you know, the blue check or the other credentials. FOLKENFLIK: In your recent piece, you've written that, quote, \"the American internet is becoming increasingly European. \" What do you mean by that? NEWTON: So in the European Union, they take a different view toward free expression than we do here in the United States. European lawmakers, regulators, courts, they're much more likely to weigh it against the potential harms that speech might cause. So one famous example is in Germany, where you're not allowed to praise the Nazi Party. They've sort of made the determination that that would be more harmful than allowing people to say whatever they wanted about the Nazis. One of the more novel things that they've come up with over there is something they call the right to be forgotten. And the basic idea is if you commit a crime when you're young, Europe doesn't think that should follow your search results around with you for the rest of your life. And so in the middle of the last decade, they started requiring platforms like Google to remove search results in some cases when they determined that someone had the right to be forgotten. And it's actually sort of in that recognition of a human right that Twitter's policy that we're talking about ultimately stemmed from. FOLKENFLIK: Google has largely fought back against this idea the right to be forgotten in Europe. However, folks at Twitter told you they acted in the absence of any steps, of any overt pressure from Congress or other federal officials to make them do this. How likely is it that tech companies that, you know, span across geographical boundaries will look to Europe for guidance? NEWTON: I think you're already seeing it in a bunch of different ways that we could name. These companies want to spend basically as little time and effort as possible in complying with regulations, right? They just want to sort of make money and do their thing. FOLKENFLIK: The right to be left alone. NEWTON: (Laughter) Yes. The tech platforms too would love the right to be left alone. And so what that means is when new regulations are passed around the world, a platform is likely to say, how can we implement this thing everywhere, right? The last thing that they want to do is to develop a different policy for every country, even though I think that would also probably do a lot of good. But because there has been such inaction in the United States when it comes to tech regulation, by default, it is Europe that is becoming America's tech regulator. FOLKENFLIK: I mean, Twitter officials used to boast of their free speech aspirations and principles. I think it was their British top executive who once claimed that Twitter was the free speech wing of the free speech party. How would you describe where Twitter finds itself now? NEWTON: Well, Twitter has officially disavowed the idea that it is the free speech wing of the free speech party, and there's an important reason why. In the middle of the last decade, the company was struggling. They were trying to sell themselves. And Disney took a long look at it. But they said, you know what? There is so much harassment and abuse and toxicity on this platform that we don't see any way that we can own you. And Twitter was really shaken by that experience. And so over the past five years or so, they've invested a lot more in trying to remove some of that harassment and abuse, make it easier for people to report it, basically to keep people safer online. And it turns out that the way to keep people safe online is you dramatically reduce the amount of free expression that people have. So I understand how Twitter got to this place. FOLKENFLIK: From your standpoint, for the average user or even the average frequent user who may not be a professional journalist, is that striking a better or worse balance of concerns? NEWTON: Well, I like to say that your real policy is what you enforce. And it remains to be seen how this policy is enforced in the United States. You're already seeing cases where right-wing activists have been using this policy even as it has just been enacted to get photos of themselves removed at protests. It speaks to the fact that this stuff is really, really difficult to enforce. And most tech platforms are really mediocre at best when it comes to making these kinds of nuanced judgments about which photo and video is truly in the public interest. FOLKENFLIK: We've been focused largely on anti-harassment policy, but you recently wrote that Europe is ahead of the U. S. also in how they're thinking about regulating the algorithms promoting harmful content on these platforms. What does that say about where the future regulation on the internet is headed? NEWTON: Well, you know, if you can bring yourself to care about European tech policy, I highly recommend that you spend five or 10 minutes reading up on the Digital Services Act and the Digital Markets Act because they're really landmark pieces of legislation that would change things in a big way here in the United States. And that Digital Service Act goes directly at some of these issues that Congress holds endless hearings about about, you know, the toxic speech online. What are we going to do about it? How are we going to rein in tech companies' power? So I think sometime in the next year, that bill could move through the EU's arcane legal process and actually become law. And if so, then Europe will continue to be both way ahead of us but also, essentially, regulating our version of the internet. FOLKENFLIK: In a sense Congress, outsourcing its own obligations across the Atlantic. NEWTON: Yeah, although I don't think they would put it that way. It's funny. You watch these hearings, and the self-regard that these members of Congress have for themselves never ceases to amaze me given. . . FOLKENFLIK: A lot of very sober faces, a lot of very sonorous statements. NEWTON: Yes. And, of course, they take this very seriously. And, you know, the tech companies are going to get away with this anymore. And yet, you know, no legislation ever manages to make it to the president's desk. FOLKENFLIK: That was Casey Newton. He's a contributing editor for The Verge, and he covers technology and democracy for his publication on Substack called Platformer. Casey Newton, thanks so much for your time. NEWTON: Thanks for having me, David. DAVID FOLKENFLIK, HOST:   The social media giant Twitter introduced a new CEO and announced major leadership changes this week after co-founder and longtime head Jack Dorsey stepped down Monday. And that's far from the only news the site generated this week. On Tuesday, the platform made another announcement. It will ban users from sharing photos or videos of private individuals without their permission in an acknowledgment of concerns about privacy. The new policy sparked some criticism it would stifle free speech, but as my next guest notes, it's not exactly new for Twitter. Twitter's had it in place for the past five years in the European Union. The tech journalist Casey Newton argues that European values are starting to define the experience of Americans on the internet. Newton runs the Substack publication Platformer, and he joins us now. Hey, Casey. CASEY NEWTON: Hey, David. FOLKENFLIK: So start us off. Tell us, what does this policy actually do? NEWTON: So the idea of the policy is that if you're an average citizen and someone takes a photo or video of you and you don't like it because you feel like it's harassing you or making fun of you in some way, you can request that Twitter takes it down. And if Twitter looks at it and they think, yep, you're being harassed, they will go ahead and remove it. There are a lot of exceptions to that policy, though, which we should probably also talk about. FOLKENFLIK: OK. NEWTON: So for example, if you're at a public protest, protesting, Twitter says they will keep photos and videos of you up. You're participating in the public discourse. If you are a celebrity or a politician or an activist or a journalist, you will not have the same ability to get media of yourself removed that average citizens do. So Twitter says that when this policy is enforced properly, it should only serve to protect people who don't have, you know, the blue check or the other credentials. FOLKENFLIK: In your recent piece, you've written that, quote, \"the American internet is becoming increasingly European. \" What do you mean by that? NEWTON: So in the European Union, they take a different view toward free expression than we do here in the United States. European lawmakers, regulators, courts, they're much more likely to weigh it against the potential harms that speech might cause. So one famous example is in Germany, where you're not allowed to praise the Nazi Party. They've sort of made the determination that that would be more harmful than allowing people to say whatever they wanted about the Nazis. One of the more novel things that they've come up with over there is something they call the right to be forgotten. And the basic idea is if you commit a crime when you're young, Europe doesn't think that should follow your search results around with you for the rest of your life. And so in the middle of the last decade, they started requiring platforms like Google to remove search results in some cases when they determined that someone had the right to be forgotten. And it's actually sort of in that recognition of a human right that Twitter's policy that we're talking about ultimately stemmed from. FOLKENFLIK: Google has largely fought back against this idea the right to be forgotten in Europe. However, folks at Twitter told you they acted in the absence of any steps, of any overt pressure from Congress or other federal officials to make them do this. How likely is it that tech companies that, you know, span across geographical boundaries will look to Europe for guidance? NEWTON: I think you're already seeing it in a bunch of different ways that we could name. These companies want to spend basically as little time and effort as possible in complying with regulations, right? They just want to sort of make money and do their thing. FOLKENFLIK: The right to be left alone. NEWTON: (Laughter) Yes. The tech platforms too would love the right to be left alone. And so what that means is when new regulations are passed around the world, a platform is likely to say, how can we implement this thing everywhere, right? The last thing that they want to do is to develop a different policy for every country, even though I think that would also probably do a lot of good. But because there has been such inaction in the United States when it comes to tech regulation, by default, it is Europe that is becoming America's tech regulator. FOLKENFLIK: I mean, Twitter officials used to boast of their free speech aspirations and principles. I think it was their British top executive who once claimed that Twitter was the free speech wing of the free speech party. How would you describe where Twitter finds itself now? NEWTON: Well, Twitter has officially disavowed the idea that it is the free speech wing of the free speech party, and there's an important reason why. In the middle of the last decade, the company was struggling. They were trying to sell themselves. And Disney took a long look at it. But they said, you know what? There is so much harassment and abuse and toxicity on this platform that we don't see any way that we can own you. And Twitter was really shaken by that experience. And so over the past five years or so, they've invested a lot more in trying to remove some of that harassment and abuse, make it easier for people to report it, basically to keep people safer online. And it turns out that the way to keep people safe online is you dramatically reduce the amount of free expression that people have. So I understand how Twitter got to this place. FOLKENFLIK: From your standpoint, for the average user or even the average frequent user who may not be a professional journalist, is that striking a better or worse balance of concerns? NEWTON: Well, I like to say that your real policy is what you enforce. And it remains to be seen how this policy is enforced in the United States. You're already seeing cases where right-wing activists have been using this policy even as it has just been enacted to get photos of themselves removed at protests. It speaks to the fact that this stuff is really, really difficult to enforce. And most tech platforms are really mediocre at best when it comes to making these kinds of nuanced judgments about which photo and video is truly in the public interest. FOLKENFLIK: We've been focused largely on anti-harassment policy, but you recently wrote that Europe is ahead of the U. S. also in how they're thinking about regulating the algorithms promoting harmful content on these platforms. What does that say about where the future regulation on the internet is headed? NEWTON: Well, you know, if you can bring yourself to care about European tech policy, I highly recommend that you spend five or 10 minutes reading up on the Digital Services Act and the Digital Markets Act because they're really landmark pieces of legislation that would change things in a big way here in the United States. And that Digital Service Act goes directly at some of these issues that Congress holds endless hearings about about, you know, the toxic speech online. What are we going to do about it? How are we going to rein in tech companies' power? So I think sometime in the next year, that bill could move through the EU's arcane legal process and actually become law. And if so, then Europe will continue to be both way ahead of us but also, essentially, regulating our version of the internet. FOLKENFLIK: In a sense Congress, outsourcing its own obligations across the Atlantic. NEWTON: Yeah, although I don't think they would put it that way. It's funny. You watch these hearings, and the self-regard that these members of Congress have for themselves never ceases to amaze me given. . . FOLKENFLIK: A lot of very sober faces, a lot of very sonorous statements. NEWTON: Yes. And, of course, they take this very seriously. And, you know, the tech companies are going to get away with this anymore. And yet, you know, no legislation ever manages to make it to the president's desk. FOLKENFLIK: That was Casey Newton. He's a contributing editor for The Verge, and he covers technology and democracy for his publication on Substack called Platformer. Casey Newton, thanks so much for your time. NEWTON: Thanks for having me, David.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-12-05-1061600383": {"title": "It's not science fiction. Scientists have really made robots that reproduce : NPR", "url": "https://www.npr.org/2021/12/05/1061600383/its-not-science-fiction-scientists-have-really-made-robots-that-reproduce", "author": "No author found", "published_date": "2021-12-05", "content": "AYESHA RASCOE, HOST:  Get ready to be amazed and possibly a bit horrified. Scientists have created a robot that can reproduce. Yes, you heard me right. This week, four researchers published a paper that describes what sounds like a scene from a sci-fi movie. Using artificial intelligence and frog cells, living robots, xenobots, are making, well, babies. We're joined now by one of those researchers, Dr. Sam Kriegman, a postdoctoral researcher at Harvard University. Welcome. SAM KRIEGMAN: Hi. Thanks, Ayesha, for having me on the program. It's my pleasure. RASCOE: Thanks. So what exactly is a xenobot? I feel like I've heard of this, but I'm not quite sure. KRIEGMAN: Yeah, I'm not sure, either. I think xenobots are somewhat of an enigma. They're a robot, and yet they're not a robot. They're an organism, and yet they're not an organism. We're not quite sure what xenobots are at the moment. They're robots in the sense that they're designed to behave in specific ways, but they're organisms in the sense that they're made entirely of frog cells. RASCOE: Even though they're made from organic material, they're programmed to behave a certain way. KRIEGMAN: Yeah. A robot is defined by what it does more than what it's made out of. It's actually interesting. The first robots - the first time the word robot was used was 100 years ago in a play called \"Rossum's Universal Robots. \" And those robots were made out of living flesh. RASCOE: So these robots have learned to replicate themselves in a completely new way. Can you tell us a bit about how that happened and, like, the significance of that? KRIEGMAN: Sure. So we've been building robots since the 1940s, for about 70 years, and even around the very first robots that we were building, roboticists and mathematicians were thinking about would it be possible for a robot to build a copy of itself? How do you store a complete copy of yourself inside of yourself and then read that description? It seemed like that'd be weird, because if you have a copy inside of yourself, wouldn't that copy also have to have a copy inside of itself and a copy and a copy. . . RASCOE: And it would just - like a loop. KRIEGMAN: Yeah, it's like looking at a mirror, and then there's another mirror on the other side, and there's this infinite reflection. So they thought, well, maybe this is not possible. But a mathematician named John von Neumann proved that it actually was possible. RASCOE: And they have all these different shapes. Like, some of them look like Pac-Man. Some of them look like a Cheesy Poof. And their shape affects how they function. Like, can you give a little more details on that? KRIEGMAN: Let me just describe that process because it's actually much simpler than it sounds like. The little xenobot shaped like Pac-Man move around in their dish, and they act like little snowplows. There's loose cells in the dish. They pile those loose cells into piles, and those piles develop into mobile little offspring of their own. So it's like snowplows building snowplows. RASCOE: Oh, OK. There's no, like, romance involved. KRIEGMAN: None that we know of. RASCOE: (Laughter) So I do have to ask, why do this? KRIEGMAN: So this gives us a system to study self-replication, which is important. It's a fundamental property of life. We want to understand it better. And it's a safe platform to try to understand it better and also to learn how to control it. We face lots of self-replicating problems. COVID is just one example. And this is not a useful technology yet, but it is telling us things about how to create self-replicating solutions in the future and also how to just create robots that can work in the real world. We've struggled to do that so far. RASCOE: That was computer scientist Dr. Sam Kriegman, postdoctoral researcher at Harvard University. Thank you so much. KRIEGMAN: Thanks a lot. (SOUNDBITE OF RADIOHEAD SONG, \"LET DOWN\") AYESHA RASCOE, HOST:   Get ready to be amazed and possibly a bit horrified. Scientists have created a robot that can reproduce. Yes, you heard me right. This week, four researchers published a paper that describes what sounds like a scene from a sci-fi movie. Using artificial intelligence and frog cells, living robots, xenobots, are making, well, babies. We're joined now by one of those researchers, Dr. Sam Kriegman, a postdoctoral researcher at Harvard University. Welcome. SAM KRIEGMAN: Hi. Thanks, Ayesha, for having me on the program. It's my pleasure. RASCOE: Thanks. So what exactly is a xenobot? I feel like I've heard of this, but I'm not quite sure. KRIEGMAN: Yeah, I'm not sure, either. I think xenobots are somewhat of an enigma. They're a robot, and yet they're not a robot. They're an organism, and yet they're not an organism. We're not quite sure what xenobots are at the moment. They're robots in the sense that they're designed to behave in specific ways, but they're organisms in the sense that they're made entirely of frog cells. RASCOE: Even though they're made from organic material, they're programmed to behave a certain way. KRIEGMAN: Yeah. A robot is defined by what it does more than what it's made out of. It's actually interesting. The first robots - the first time the word robot was used was 100 years ago in a play called \"Rossum's Universal Robots. \" And those robots were made out of living flesh. RASCOE: So these robots have learned to replicate themselves in a completely new way. Can you tell us a bit about how that happened and, like, the significance of that? KRIEGMAN: Sure. So we've been building robots since the 1940s, for about 70 years, and even around the very first robots that we were building, roboticists and mathematicians were thinking about would it be possible for a robot to build a copy of itself? How do you store a complete copy of yourself inside of yourself and then read that description? It seemed like that'd be weird, because if you have a copy inside of yourself, wouldn't that copy also have to have a copy inside of itself and a copy and a copy. . . RASCOE: And it would just - like a loop. KRIEGMAN: Yeah, it's like looking at a mirror, and then there's another mirror on the other side, and there's this infinite reflection. So they thought, well, maybe this is not possible. But a mathematician named John von Neumann proved that it actually was possible. RASCOE: And they have all these different shapes. Like, some of them look like Pac-Man. Some of them look like a Cheesy Poof. And their shape affects how they function. Like, can you give a little more details on that? KRIEGMAN: Let me just describe that process because it's actually much simpler than it sounds like. The little xenobot shaped like Pac-Man move around in their dish, and they act like little snowplows. There's loose cells in the dish. They pile those loose cells into piles, and those piles develop into mobile little offspring of their own. So it's like snowplows building snowplows. RASCOE: Oh, OK. There's no, like, romance involved. KRIEGMAN: None that we know of. RASCOE: (Laughter) So I do have to ask, why do this? KRIEGMAN: So this gives us a system to study self-replication, which is important. It's a fundamental property of life. We want to understand it better. And it's a safe platform to try to understand it better and also to learn how to control it. We face lots of self-replicating problems. COVID is just one example. And this is not a useful technology yet, but it is telling us things about how to create self-replicating solutions in the future and also how to just create robots that can work in the real world. We've struggled to do that so far. RASCOE: That was computer scientist Dr. Sam Kriegman, postdoctoral researcher at Harvard University. Thank you so much. KRIEGMAN: Thanks a lot. (SOUNDBITE OF RADIOHEAD SONG, \"LET DOWN\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-12-06-1060838850": {"title": "Criminal hackers are now going after phone lines, too : NPR", "url": "https://www.npr.org/2021/12/06/1060838850/criminal-hackers-are-now-going-after-phone-lines-too", "author": "No author found", "published_date": "2021-12-06", "content": "AUDIE CORNISH, HOST:  So your smartphone - that thing you can't live without that does just about everything - well, it's vulnerable in ways that might surprise you. NPR's cybersecurity correspondent Jenna McLaughlin has more. (SOUNDBITE OF PHONE RINGING)JENNA MCLAUGHLIN, BYLINE: In the early 1900s, the Bell Telephone Company advertised the landline telephone as the sentinel that's always on duty. MATTHEW PRINCE: The phone system was really built with an incredible amount of reliability and robustness. The Bell System really prided itself in making sure that you would always be able to get a dial tone. MCLAUGHLIN: Matthew Prince is the CEO of Cloudflare, a website security company. Prince says most phone calls these days don't actually take place purely over a landline. PRINCE: Today, many of the phone calls that you make, especially if you're using a mobile device, your voice is actually being transmitted across the same connection, the same wires, that you'd also use to run a Google search or, you know, find your funny cat photos. MCLAUGHLIN: While it's now easy and cheap to connect phone lines over the internet, it's not exactly the most secure. Prince says criminals have recently been launching a wave of denial-of-service attacks against digital phone providers. Think of a tsunami of digital traffic, and because of all that extra garbage, normal calls can't get through. To make it stop, the bad guys demand payment. Prince shared one ransom note. We will completely destroy your reputation, it read. Your services will remain offline until you pay. FRED POSNER: My name is Fred Posner. I grew up loving phones. And I was born in New York City, and my parents tell stories of having to cross the street to avoid me trying to play with a payphone. MCLAUGHLIN: When it comes to the inner workings of digital voice technology, Fred Posner knows more than just about anyone. POSNER: So Voice over IP is a way of taking your regular phone conversation that you would normally have through a handset or even, you know, today's cell phones and then instead of using a wire that you would back in the day, we take that voice and we turn it into ones and zeros, and then on the other end is some device that changes that back into voice. MCLAUGHLIN: Posner says audio was never meant to travel in real time over the internet. As a result, experts created special tools to make it work. It's all a bit of a trapeze act. POSNER: Because we're digitizing voice and because of the way that voice needs to transmit over the internet, we have to do many, many tiny little packets. MCLAUGHLIN: Packets are little bits of digitized audio. Lots of them travel together in an orderly line so you hear the other person's voice in real time without skips or breaks. Posner said that digital phone lines are vulnerable because the audio has to sound seamless. It doesn't take a lot of extra traffic to disrupt a call. These attacks, Posner adds, are a big deal in his community. POSNER: Yes. In layman's terms, people are freaking out (laughter). CHESTER WISNIEWSKI: Well, yeah. I mean, I'm actually calling you on the VoIP provider that's been up and down like a yo-yo for, gosh, well over a month now. MCLAUGHLIN: Chet Wisniewski is a researcher at the security firm Sophos. He's been making phone calls over the internet for years now, ever since he moved from the U. S. to Vancouver. Wisniewski says he's been having trouble calling friends and family, even buzzing in the Amazon deliveryman to his apartment building. Small things, but it could get a lot more serious. WISNIEWSKI: When that reliability is intentionally threatened, like we're seeing with these Voice over IP situations, I would hope it would be getting an equal amount of serious attention that we are seeing with ransomware and other types of cyberthreats because this is potentially able to disrupt people's ability to call 911 emergency lines. Literally, people can die from this. MCLAUGHLIN: The good news is that the cybersecurity experts I spoke with said the fight to protect the phone lines is going pretty well. But they say it's smart to plan for a worst-case scenario. Companies and individuals should think about what they'd do if their phone lines go dead. Jenna McLaughlin, NPR News, Washington. (SOUNDBITE OF RODRIGO Y GABRIELA'S \"THE RUSSIAN MESSENGER\") AUDIE CORNISH, HOST:   So your smartphone - that thing you can't live without that does just about everything - well, it's vulnerable in ways that might surprise you. NPR's cybersecurity correspondent Jenna McLaughlin has more. (SOUNDBITE OF PHONE RINGING) JENNA MCLAUGHLIN, BYLINE: In the early 1900s, the Bell Telephone Company advertised the landline telephone as the sentinel that's always on duty. MATTHEW PRINCE: The phone system was really built with an incredible amount of reliability and robustness. The Bell System really prided itself in making sure that you would always be able to get a dial tone. MCLAUGHLIN: Matthew Prince is the CEO of Cloudflare, a website security company. Prince says most phone calls these days don't actually take place purely over a landline. PRINCE: Today, many of the phone calls that you make, especially if you're using a mobile device, your voice is actually being transmitted across the same connection, the same wires, that you'd also use to run a Google search or, you know, find your funny cat photos. MCLAUGHLIN: While it's now easy and cheap to connect phone lines over the internet, it's not exactly the most secure. Prince says criminals have recently been launching a wave of denial-of-service attacks against digital phone providers. Think of a tsunami of digital traffic, and because of all that extra garbage, normal calls can't get through. To make it stop, the bad guys demand payment. Prince shared one ransom note. We will completely destroy your reputation, it read. Your services will remain offline until you pay. FRED POSNER: My name is Fred Posner. I grew up loving phones. And I was born in New York City, and my parents tell stories of having to cross the street to avoid me trying to play with a payphone. MCLAUGHLIN: When it comes to the inner workings of digital voice technology, Fred Posner knows more than just about anyone. POSNER: So Voice over IP is a way of taking your regular phone conversation that you would normally have through a handset or even, you know, today's cell phones and then instead of using a wire that you would back in the day, we take that voice and we turn it into ones and zeros, and then on the other end is some device that changes that back into voice. MCLAUGHLIN: Posner says audio was never meant to travel in real time over the internet. As a result, experts created special tools to make it work. It's all a bit of a trapeze act. POSNER: Because we're digitizing voice and because of the way that voice needs to transmit over the internet, we have to do many, many tiny little packets. MCLAUGHLIN: Packets are little bits of digitized audio. Lots of them travel together in an orderly line so you hear the other person's voice in real time without skips or breaks. Posner said that digital phone lines are vulnerable because the audio has to sound seamless. It doesn't take a lot of extra traffic to disrupt a call. These attacks, Posner adds, are a big deal in his community. POSNER: Yes. In layman's terms, people are freaking out (laughter). CHESTER WISNIEWSKI: Well, yeah. I mean, I'm actually calling you on the VoIP provider that's been up and down like a yo-yo for, gosh, well over a month now. MCLAUGHLIN: Chet Wisniewski is a researcher at the security firm Sophos. He's been making phone calls over the internet for years now, ever since he moved from the U. S. to Vancouver. Wisniewski says he's been having trouble calling friends and family, even buzzing in the Amazon deliveryman to his apartment building. Small things, but it could get a lot more serious. WISNIEWSKI: When that reliability is intentionally threatened, like we're seeing with these Voice over IP situations, I would hope it would be getting an equal amount of serious attention that we are seeing with ransomware and other types of cyberthreats because this is potentially able to disrupt people's ability to call 911 emergency lines. Literally, people can die from this. MCLAUGHLIN: The good news is that the cybersecurity experts I spoke with said the fight to protect the phone lines is going pretty well. But they say it's smart to plan for a worst-case scenario. Companies and individuals should think about what they'd do if their phone lines go dead. Jenna McLaughlin, NPR News, Washington. (SOUNDBITE OF RODRIGO Y GABRIELA'S \"THE RUSSIAN MESSENGER\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-12-07-1062178628": {"title": "Far right is using Twitter's new policy against extremism researchers and activists : NPR", "url": "https://www.npr.org/2021/12/07/1062178628/far-right-is-using-twitters-new-policy-against-extremism-researchers-and-activis", "author": "No author found", "published_date": "2021-12-07", "content": "ARI SHAPIRO, HOST:  A new policy at Twitter aims to limit harassment. The so-called private media rules make it more difficult for users to post photos and videos of people without their consent. Almost as soon as the policy took effect last week, far-right trolls began a transparent campaign to exploit it for their gain. Their targets include antifa activists, independent journalists and extremism researchers who say this is already having a chilling effect on public interest reporting. Here to explain are NPR's Shannon Bond, who covers tech, and Odette Yousef, who covers domestic extremism. Odette, I believe you've been talking to some of the people who were affected by this. What have you heard? ODETTE YOUSEF, BYLINE: That's right. So I spoke with Gwen Snyder. She's an organizer and extremism researcher who documents activities of the far right in her hometown of Philadelphia. Last week, she got notification that a Twitter thread she'd put out back in May of 2019 had been flagged under the new policy. It was a thread that was regarding a Proud Boys event held in Philadelphia. GWEN SNYDER: This was a thread that was documenting this public march by right-wing extremists and people very publicly affiliated with the Republican Party in Philadelphia. And I walked through and identified both the extremists and the politicians. And I got a notification at about 2:30 a. m. on Friday, I believe, saying that the thread had been reported under the new Twitter privacy policy and that I had a choice of either deleting, appealing or permanently having my account suspended. YOUSEF: And, Ari, ultimately, she opted to delete it. But she says that Twitter later acknowledged in other reporting that this never should have been flagged. You know, this was a thread where she documented a public event in a public space. SHAPIRO: Shannon, I understand Twitter acknowledged that the policy has been misapplied in some cases. What have they said? SHANNON BOND, BYLINE: Well, what they said is - well, maybe let's back up, actually, and talk about what this policy is. SHAPIRO: Sure. BOND: The idea is if someone tweets a photo or a video of you in a way that you feel is threatening or harassing, you can ask the company to take it down. And what Twitter says this is about is to stop abuse, right? It's seen these kind of photos and videos used to go after people, especially women, activists, members of minority communities. An example Twitter gave me is, you know, there was an incident where a victim of sexual assault was publicly identified against their will but in a post that didn't break any Twitter rules. So this policy about these photos gives the company a basis to take something like that down. SHAPIRO: OK. BOND: But Twitter says what had happened last week is that it saw the policy being exploited by extremists who were, sort of in a coordinated way, using it to target activists. And then when Twitter's own trust and safety team reviewed the reports, it actually messed up, the company says, and suspended these accounts. SHAPIRO: So Shannon, what does Twitter say is going wrong here? BOND: Well, it says, you know, that this was a mistake in enforcement that - you know, that when it was overwhelmed with these reports, these coordinated reports, you know, it made mistakes and content like what Gwen posted should not have been take down - taken down. And Twitter, you know, has had this policy in place in other countries since at least 2014, in countries that have legal rights to privacy. But as far as we can tell, it has not been abused in this same way there the way it's been abused here in just the past week. SHAPIRO: Odette, aside from how this is affecting individual accounts, what are people saying about the wider implications of these restrictions? YOUSEF: So there's been concern in some channels that have been working to identify participants of the January 6 riot at the Capitol that the work that they've been doing over the past nearly year might go away, that they might be flagged for violations and have to delete research and findings that they've published on Twitter. You know, you - I would note that Twitter has been a really key platform for these so-called sedition hunters to organize themselves, solicit leads and ultimately share information pertaining to important federal investigations. One person I spoke with about this is Chad Loder. They're an antifa activist and citizen journalist based in LA. And they say probably the big accounts that are doing that work won't be affected, but other people who are kind of doing the hyperlocal, in the weeds investigations may be. Here's what Chad said. CHAD LODER: I think that ongoing work from the individual researchers is at risk more so than, let's say, the bigger accounts that have 60,000 followers that are recorded in multiple news articles, which essentially function as aggregators of research that's been done so far. YOUSEF: You know, Ari, I think some people listening may be thinking, you know, so what? It's just a Twitter account. But for researchers and activists like Gwen who have their eyes on extremist activity in hyperlocal settings, Twitter's really important. It lets them, you know, publish a report in real time and reach press and politicians, and ultimately help paint a picture of trends that we're seeing in this country. And they're saying that the uncertainty around this rule is having a chilling effect on them. You know, they don't want to lose access to their accounts, but they also aren't sure what they're allowed to publish anymore. SHAPIRO: Shannon, what does Twitter say to that? BOND: Well, you know, Twitter is - I think it wants - what's important to note here is that there are a lot of exceptions to this policy. And so Twitter's saying, you know, this shouldn't have happened in the first place. This policy is not supposed to apply, for example, to public figures, and it's not supposed to apply in cases of public interest or newsworthiness. And Twitter specifically says things like public events, like protests, don't violate these rules. But what it comes down to here, Ari, is really a question of - you know, these are judgment calls, right? Deciding if a photo is in the public interest, you know, even if I identify as a private person, you know, is a judgment call that this company has to make, that its team that's reviewing these reports has to make. And we've seen already how this can be gamed, how this can be exploited. And so now, you know, Twitter says it is doing a top-to-bottom internal review to make sure the policy is actually being applied the way it's intended - to curb harassment and not actually be used to harass people. But ultimately, you know, this is a real tension here that tech companies face to balance safety against free expression and, you know, to make these kinds of decisions. It's a problem none of these companies, including Twitter, has really solved. And so I think we're going to have to look to them to see what they tell us about, you know, the transparency about making these decisions and whether they're more effective at enforcing this policy in the future. SHAPIRO: Does this have anything to do with Twitter getting a new CEO? BOND: No, the company tells me that this policy change was well in the works before the new CEO was announced last week. SHAPIRO: NPR's Shannon Bond and Odette Yousef, thank you both. YOUSEF: Thank you. BOND: Thanks. (SOUNDBITE OF MUSIC) ARI SHAPIRO, HOST:   A new policy at Twitter aims to limit harassment. The so-called private media rules make it more difficult for users to post photos and videos of people without their consent. Almost as soon as the policy took effect last week, far-right trolls began a transparent campaign to exploit it for their gain. Their targets include antifa activists, independent journalists and extremism researchers who say this is already having a chilling effect on public interest reporting. Here to explain are NPR's Shannon Bond, who covers tech, and Odette Yousef, who covers domestic extremism. Odette, I believe you've been talking to some of the people who were affected by this. What have you heard? ODETTE YOUSEF, BYLINE: That's right. So I spoke with Gwen Snyder. She's an organizer and extremism researcher who documents activities of the far right in her hometown of Philadelphia. Last week, she got notification that a Twitter thread she'd put out back in May of 2019 had been flagged under the new policy. It was a thread that was regarding a Proud Boys event held in Philadelphia. GWEN SNYDER: This was a thread that was documenting this public march by right-wing extremists and people very publicly affiliated with the Republican Party in Philadelphia. And I walked through and identified both the extremists and the politicians. And I got a notification at about 2:30 a. m. on Friday, I believe, saying that the thread had been reported under the new Twitter privacy policy and that I had a choice of either deleting, appealing or permanently having my account suspended. YOUSEF: And, Ari, ultimately, she opted to delete it. But she says that Twitter later acknowledged in other reporting that this never should have been flagged. You know, this was a thread where she documented a public event in a public space. SHAPIRO: Shannon, I understand Twitter acknowledged that the policy has been misapplied in some cases. What have they said? SHANNON BOND, BYLINE: Well, what they said is - well, maybe let's back up, actually, and talk about what this policy is. SHAPIRO: Sure. BOND: The idea is if someone tweets a photo or a video of you in a way that you feel is threatening or harassing, you can ask the company to take it down. And what Twitter says this is about is to stop abuse, right? It's seen these kind of photos and videos used to go after people, especially women, activists, members of minority communities. An example Twitter gave me is, you know, there was an incident where a victim of sexual assault was publicly identified against their will but in a post that didn't break any Twitter rules. So this policy about these photos gives the company a basis to take something like that down. SHAPIRO: OK. BOND: But Twitter says what had happened last week is that it saw the policy being exploited by extremists who were, sort of in a coordinated way, using it to target activists. And then when Twitter's own trust and safety team reviewed the reports, it actually messed up, the company says, and suspended these accounts. SHAPIRO: So Shannon, what does Twitter say is going wrong here? BOND: Well, it says, you know, that this was a mistake in enforcement that - you know, that when it was overwhelmed with these reports, these coordinated reports, you know, it made mistakes and content like what Gwen posted should not have been take down - taken down. And Twitter, you know, has had this policy in place in other countries since at least 2014, in countries that have legal rights to privacy. But as far as we can tell, it has not been abused in this same way there the way it's been abused here in just the past week. SHAPIRO: Odette, aside from how this is affecting individual accounts, what are people saying about the wider implications of these restrictions? YOUSEF: So there's been concern in some channels that have been working to identify participants of the January 6 riot at the Capitol that the work that they've been doing over the past nearly year might go away, that they might be flagged for violations and have to delete research and findings that they've published on Twitter. You know, you - I would note that Twitter has been a really key platform for these so-called sedition hunters to organize themselves, solicit leads and ultimately share information pertaining to important federal investigations. One person I spoke with about this is Chad Loder. They're an antifa activist and citizen journalist based in LA. And they say probably the big accounts that are doing that work won't be affected, but other people who are kind of doing the hyperlocal, in the weeds investigations may be. Here's what Chad said. CHAD LODER: I think that ongoing work from the individual researchers is at risk more so than, let's say, the bigger accounts that have 60,000 followers that are recorded in multiple news articles, which essentially function as aggregators of research that's been done so far. YOUSEF: You know, Ari, I think some people listening may be thinking, you know, so what? It's just a Twitter account. But for researchers and activists like Gwen who have their eyes on extremist activity in hyperlocal settings, Twitter's really important. It lets them, you know, publish a report in real time and reach press and politicians, and ultimately help paint a picture of trends that we're seeing in this country. And they're saying that the uncertainty around this rule is having a chilling effect on them. You know, they don't want to lose access to their accounts, but they also aren't sure what they're allowed to publish anymore. SHAPIRO: Shannon, what does Twitter say to that? BOND: Well, you know, Twitter is - I think it wants - what's important to note here is that there are a lot of exceptions to this policy. And so Twitter's saying, you know, this shouldn't have happened in the first place. This policy is not supposed to apply, for example, to public figures, and it's not supposed to apply in cases of public interest or newsworthiness. And Twitter specifically says things like public events, like protests, don't violate these rules. But what it comes down to here, Ari, is really a question of - you know, these are judgment calls, right? Deciding if a photo is in the public interest, you know, even if I identify as a private person, you know, is a judgment call that this company has to make, that its team that's reviewing these reports has to make. And we've seen already how this can be gamed, how this can be exploited. And so now, you know, Twitter says it is doing a top-to-bottom internal review to make sure the policy is actually being applied the way it's intended - to curb harassment and not actually be used to harass people. But ultimately, you know, this is a real tension here that tech companies face to balance safety against free expression and, you know, to make these kinds of decisions. It's a problem none of these companies, including Twitter, has really solved. And so I think we're going to have to look to them to see what they tell us about, you know, the transparency about making these decisions and whether they're more effective at enforcing this policy in the future. SHAPIRO: Does this have anything to do with Twitter getting a new CEO? BOND: No, the company tells me that this policy change was well in the works before the new CEO was announced last week. SHAPIRO: NPR's Shannon Bond and Odette Yousef, thank you both. YOUSEF: Thank you. BOND: Thanks. (SOUNDBITE OF MUSIC)", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-12-07-1062131365": {"title": "Amazon announces progress after an outage disrupted sites across the internet : NPR", "url": "https://www.npr.org/2021/12/07/1062131365/amazon-outage-is-causing-significant-problems-for-sites-and-apps-across-the-inte", "author": "No author found", "published_date": "2021-12-07", "content": "", "section": "Technology", "disclaimer": ""}, "2021-12-07-1061808098": {"title": "Instagram unveils new teen safety tools ahead of Senate hearing : NPR", "url": "https://www.npr.org/2021/12/07/1061808098/instagram-teens-safety-tools", "author": "No author found", "published_date": "2021-12-07", "content": "", "section": "Technology", "disclaimer": ""}, "2021-12-08-1062576576": {"title": "Highlights: Instagram CEO Adam Mosseri grilled by senators on kids' safety : NPR", "url": "https://www.npr.org/2021/12/08/1062576576/instagrams-ceo-adam-mosseri-hears-senators-brush-aside-his-promises-to-self-poli", "author": "No author found", "published_date": "2021-12-08", "content": "", "section": "Technology", "disclaimer": ""}, "2021-12-08-1062400809": {"title": "Elizabeth Holmes spent 7 days defending herself against fraud. Will the jury buy it? : NPR", "url": "https://www.npr.org/2021/12/08/1062400809/elizabeth-holmes-trial-defending-herself", "author": "No author found", "published_date": "2021-12-08", "content": "", "section": "Technology", "disclaimer": ""}, "2021-12-09-1062791766": {"title": "Can companies police the biases found in artificial intelligence? : NPR", "url": "https://www.npr.org/2021/12/09/1062791766/can-companies-police-the-biases-found-in-artificial-intelligence", "author": "No author found", "published_date": "2021-12-09", "content": "AUDIE CORNISH, HOST:  Artificial intelligence has seeped into almost every corner of our lives, including how people are hired for work. AI is used to screen and evaluate applicants, but there's a problem with that. Research has shown that AI can produce biased results, especially against women and minorities. That's something that Kenneth Chenault, chairman and managing director at the venture capital firm General Catalyst, is trying to address with his Data and Trust Alliance. Chenault is the co-chair of the organization. He joins me now. Welcome to ALL THINGS CONSIDERED. KENNETH CHENAULT: Thank you. Great to be here. CORNISH: Now, you have announced that your organization has signed up major companies like CVS, Deloitte, Humana, Meta, Walmart to work together to detect and combat algorithmic bias. Help us understand how data is being used in the human resources process. If you're a top executive, what is HR handing you in the way of data that somehow is, like, helpful in finding talent? CHENAULT: You look at different indicators. What are people's experiences? What schools did they go to? How long were they in a job? Where do they live? So there are literally hundreds of variables that go into determining if someone is selected for an interview. And given the sheer volume that major companies have to deal with in sorting through applications, you want to winnow down the pool to say, who are the prospects? The problem is if you have some criteria that, in fact, is biased. And what I would like to hope is that most companies do not create standards that contain bias. But given some of the algorithms that can be put in place, there are situations where there are unintended biases that unfairly disadvantage certain groups. CORNISH: It's interesting. You're saying unintended, but when I think of some of the criteria, you could easily see how this happens, right? If a company decides, draw a circle around everybody who went to this kind of school, did this kind of X, Y, it's sort of like bad data in, bad data out. CHENAULT: That's right. But what I'm saying is that is something upfront that companies can screen out. But then there are other variables that when they're connected, they create bias. And so what I think is very, very important here is you had 10-plus companies, large companies, coming together, not just issuing a principle but, in fact, agreeing to take concrete actions to ensure that they're preventing unintended bias. CORNISH: So I understand this involves a questionnaire. Talk about how that works and if you get a sense that companies are willing to use it. CHENAULT: Well, here's the point. Every company that is involved in this has agreed to follow every step, and this is something that we will measure with these companies. CORNISH: At the end of the day, is this really work that can be outsourced to a machine? CHENAULT: Yes, it can. I think there are a number of process steps that absolutely can be outsourced. But what is important is that we have the right controls and approaches and processes in place. The reality is that no matter what business companies are in, they're all becoming data enterprises. And so what we have to do is we have to use this data responsibly. That's the focus. CORNISH: Kenneth Chenault is chairman and managing director of the venture capital firm General Catalyst. He's also a former chairman and CEO of American Express. Thank you so much for speaking with us. CHENAULT: Thank you very much. AUDIE CORNISH, HOST:   Artificial intelligence has seeped into almost every corner of our lives, including how people are hired for work. AI is used to screen and evaluate applicants, but there's a problem with that. Research has shown that AI can produce biased results, especially against women and minorities. That's something that Kenneth Chenault, chairman and managing director at the venture capital firm General Catalyst, is trying to address with his Data and Trust Alliance. Chenault is the co-chair of the organization. He joins me now. Welcome to ALL THINGS CONSIDERED. KENNETH CHENAULT: Thank you. Great to be here. CORNISH: Now, you have announced that your organization has signed up major companies like CVS, Deloitte, Humana, Meta, Walmart to work together to detect and combat algorithmic bias. Help us understand how data is being used in the human resources process. If you're a top executive, what is HR handing you in the way of data that somehow is, like, helpful in finding talent? CHENAULT: You look at different indicators. What are people's experiences? What schools did they go to? How long were they in a job? Where do they live? So there are literally hundreds of variables that go into determining if someone is selected for an interview. And given the sheer volume that major companies have to deal with in sorting through applications, you want to winnow down the pool to say, who are the prospects? The problem is if you have some criteria that, in fact, is biased. And what I would like to hope is that most companies do not create standards that contain bias. But given some of the algorithms that can be put in place, there are situations where there are unintended biases that unfairly disadvantage certain groups. CORNISH: It's interesting. You're saying unintended, but when I think of some of the criteria, you could easily see how this happens, right? If a company decides, draw a circle around everybody who went to this kind of school, did this kind of X, Y, it's sort of like bad data in, bad data out. CHENAULT: That's right. But what I'm saying is that is something upfront that companies can screen out. But then there are other variables that when they're connected, they create bias. And so what I think is very, very important here is you had 10-plus companies, large companies, coming together, not just issuing a principle but, in fact, agreeing to take concrete actions to ensure that they're preventing unintended bias. CORNISH: So I understand this involves a questionnaire. Talk about how that works and if you get a sense that companies are willing to use it. CHENAULT: Well, here's the point. Every company that is involved in this has agreed to follow every step, and this is something that we will measure with these companies. CORNISH: At the end of the day, is this really work that can be outsourced to a machine? CHENAULT: Yes, it can. I think there are a number of process steps that absolutely can be outsourced. But what is important is that we have the right controls and approaches and processes in place. The reality is that no matter what business companies are in, they're all becoming data enterprises. And so what we have to do is we have to use this data responsibly. That's the focus. CORNISH: Kenneth Chenault is chairman and managing director of the venture capital firm General Catalyst. He's also a former chairman and CEO of American Express. Thank you so much for speaking with us. CHENAULT: Thank you very much.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-12-09-1062614961": {"title": "Instagram CEO tells Senate panel it takes the mental health of children seriously : NPR", "url": "https://www.npr.org/2021/12/09/1062614961/instagram-ceo-tells-senate-panel-it-takes-the-mental-health-of-children-seriousl", "author": "No author found", "published_date": "2021-12-09", "content": "STEVE INSKEEP, HOST:  Adam Mosseri, the head of Instagram, knew he faced a tough audience at a Senate hearing yesterday. (SOUNDBITE OF ARCHIVED RECORDING)ADAM MOSSERI: Now, I recognize that many in this room have deep reservations about our company. But I want to assure you that we do have the same goal. We all want teens to be safe online. INSKEEP: He was defending Instagram after a whistleblower revealed documents showing just how much that company knew about its effect on young people. NPR's Shannon Bond covered the hearing and joins us now. Shannon, good morning. SHANNON BOND, BYLINE: Morning, Steve. INSKEEP: And I guess we should note that Instagram's parent company, Meta, pays NPR to license NPR content. I also want to note, Shannon, in an earlier feed of this program, I referred to Instagram's parent country, Meta, which was a mistake but seems almost appropriate in a way - giant, giant corporation here. Instagram is part of it. Why were lawmakers eager to hear from its head? BOND: Well, he is the highest ranking executive to come before Congress since these whistleblower leaks came out, this trove of internal documents about the potential harms of these platforms. And that included internal research about how Instagram affects its youngest users, including a survey in which some teen girls said the app makes their body image issues worse. Here's what Democrat Amy Klobuchar of Minnesota said at the hearing yesterday. (SOUNDBITE OF ARCHIVED RECORDING)AMY KLOBUCHAR: I think that we are in diametrically opposed goals - the goals of parents out there and the goals of your company. Our kids aren't cash cows. BOND: And that's what we heard from both Democrats and Republicans, really outrage at this portrait that's emerged from the whistleblower documents that Instagram knows it may actually be toxic to users but that it's brushed aside those concerns in the name of growth because it needs to capture especially this younger age group to ensure its continued longevity. INSKEEP: Well, Instagram does try to capture users and deliver them to advertisers. So how did Mosseri defend that? BOND: Well, he acknowledged these concerns. You know, he said several times he's a dad of three kids, that he really cares about safety. He talked about new features the company is rolling out, like reminders to take a break from scrolling and these forthcoming parental controls. But Mosseri also pushed back on the idea that Instagram is harmful. He says the research that found it exacerbated body image issues was more nuanced than it had been portrayed. (SOUNDBITE OF ARCHIVED RECORDING)MOSSERI: Research actually shows that on 11 of 12 difficult issues that teens face, teens are struggling, said Instagram helps more than harms. BOND: And what he suggested is that tech companies really should come together to propose safety standards for kids on social media because he says this is not just about one company, Instagram. It's about its competitors like TikTok and YouTube, where kids are actually spending even more of their time. INSKEEP: And it's even bigger than that because it's also about free speech. So what did senators think of what Mosseri had to say? BOND: Well, they were really deeply skeptical of everything that they heard from him yesterday. Here's Republican Marsha Blackburn of Tennessee on a call with reporters after the hearing. (SOUNDBITE OF ARCHIVED RECORDING)MARSHA BLACKBURN: He does not understand the intensity of opposition that the American public has to how they are managing the Instagram platform. BOND: Blackburn said these safety changes the company has announced are just too little, too late. So Republicans and Democrats, lawmakers, are saying it's time for new laws to regulate tech. They're not going to wait on the companies to do anything about this. But, of course, this is what we've heard them saying for a while, Steve. And we are still waiting on any of these legislative proposals to move forward. INSKEEP: NPR's Shannon Bond, thanks so much. BOND: Thanks, Steve. STEVE INSKEEP, HOST:   Adam Mosseri, the head of Instagram, knew he faced a tough audience at a Senate hearing yesterday. (SOUNDBITE OF ARCHIVED RECORDING) ADAM MOSSERI: Now, I recognize that many in this room have deep reservations about our company. But I want to assure you that we do have the same goal. We all want teens to be safe online. INSKEEP: He was defending Instagram after a whistleblower revealed documents showing just how much that company knew about its effect on young people. NPR's Shannon Bond covered the hearing and joins us now. Shannon, good morning. SHANNON BOND, BYLINE: Morning, Steve. INSKEEP: And I guess we should note that Instagram's parent company, Meta, pays NPR to license NPR content. I also want to note, Shannon, in an earlier feed of this program, I referred to Instagram's parent country, Meta, which was a mistake but seems almost appropriate in a way - giant, giant corporation here. Instagram is part of it. Why were lawmakers eager to hear from its head? BOND: Well, he is the highest ranking executive to come before Congress since these whistleblower leaks came out, this trove of internal documents about the potential harms of these platforms. And that included internal research about how Instagram affects its youngest users, including a survey in which some teen girls said the app makes their body image issues worse. Here's what Democrat Amy Klobuchar of Minnesota said at the hearing yesterday. (SOUNDBITE OF ARCHIVED RECORDING) AMY KLOBUCHAR: I think that we are in diametrically opposed goals - the goals of parents out there and the goals of your company. Our kids aren't cash cows. BOND: And that's what we heard from both Democrats and Republicans, really outrage at this portrait that's emerged from the whistleblower documents that Instagram knows it may actually be toxic to users but that it's brushed aside those concerns in the name of growth because it needs to capture especially this younger age group to ensure its continued longevity. INSKEEP: Well, Instagram does try to capture users and deliver them to advertisers. So how did Mosseri defend that? BOND: Well, he acknowledged these concerns. You know, he said several times he's a dad of three kids, that he really cares about safety. He talked about new features the company is rolling out, like reminders to take a break from scrolling and these forthcoming parental controls. But Mosseri also pushed back on the idea that Instagram is harmful. He says the research that found it exacerbated body image issues was more nuanced than it had been portrayed. (SOUNDBITE OF ARCHIVED RECORDING) MOSSERI: Research actually shows that on 11 of 12 difficult issues that teens face, teens are struggling, said Instagram helps more than harms. BOND: And what he suggested is that tech companies really should come together to propose safety standards for kids on social media because he says this is not just about one company, Instagram. It's about its competitors like TikTok and YouTube, where kids are actually spending even more of their time. INSKEEP: And it's even bigger than that because it's also about free speech. So what did senators think of what Mosseri had to say? BOND: Well, they were really deeply skeptical of everything that they heard from him yesterday. Here's Republican Marsha Blackburn of Tennessee on a call with reporters after the hearing. (SOUNDBITE OF ARCHIVED RECORDING) MARSHA BLACKBURN: He does not understand the intensity of opposition that the American public has to how they are managing the Instagram platform. BOND: Blackburn said these safety changes the company has announced are just too little, too late. So Republicans and Democrats, lawmakers, are saying it's time for new laws to regulate tech. They're not going to wait on the companies to do anything about this. But, of course, this is what we've heard them saying for a while, Steve. And we are still waiting on any of these legislative proposals to move forward. INSKEEP: NPR's Shannon Bond, thanks so much. BOND: Thanks, Steve.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-12-09-1062516250": {"title": "Researchers explain why they believe Facebook mishandles political ads : NPR", "url": "https://www.npr.org/2021/12/09/1062516250/researchers-explain-why-they-believe-facebook-mishandles-political-ads", "author": "No author found", "published_date": "2021-12-09", "content": "", "section": "Media", "disclaimer": ""}, "2021-12-10-1063230658": {"title": "Embattled Activision Blizzard to employees: 'consider the consequences' of unionizing : NPR", "url": "https://www.npr.org/2021/12/10/1063230658/embattled-activision-blizzard-to-employees-consider-the-consequences-of-unionizi", "author": "No author found", "published_date": "2021-12-10", "content": "", "section": "Technology", "disclaimer": ""}, "2021-12-10-1063278227": {"title": "'Minecraft' users were quick to exploit critical software flaw : NPR", "url": "https://www.npr.org/2021/12/10/1063278227/minecraft-software-flaw", "author": "No author found", "published_date": "2021-12-10", "content": "", "section": "Technology", "disclaimer": ""}, "2021-12-10-1063218669": {"title": "Nobel Peace laureates blast tech giants and warn against rising authoritarianism : NPR", "url": "https://www.npr.org/2021/12/10/1063218669/nobel-peace-laureates-blast-tech-giants-and-warn-against-rising-authoritarianism", "author": "No author found", "published_date": "2021-12-10", "content": "", "section": "Media", "disclaimer": ""}, "2021-12-10-1063204745": {"title": "Masayuki Uemura, lead architect behind Nintendo's iconic NES console, has died : NPR", "url": "https://www.npr.org/2021/12/10/1063204745/the-video-game-pioneer-behind-nintendos-groundbreaking-console-has-died", "author": "No author found", "published_date": "2021-12-10", "content": "AUDIE CORNISH, HOST:  You may not be familiar with the name Masayuki Uemura, but odds are high you've spent hours with his revolutionary work. (SOUNDBITE OF KOJI KONDO'S \"SUPER MARIO BROS. THEME SONG\")MARY LOUISE KELLY, HOST:  With games like Mario Bros. and Donkey Kong, the Nintendo Entertainment System, or NES, dominated the home video game industry in the '80s and '90s. Uemura was its chief architect. CORNISH: He died this week at the age of 78. Uemura grew up in Tokyo. He became an electrical engineer. He joined Nintendo in 1972 and was soon working on the predecessor to early hit Duck Hunt. (SOUNDBITE OF DUCK HUNT SOUND EFFECTS)KELLY: In the early '80s, he was tasked with creating a home console to rival Atari. Nintendo's president asked Uemura to come up with a game using cartridges. CORNISH: The result was Famicom, or the Family Computer. It hit the U. S. market in 1985. And if Santa didn't hook you up, the 8-bit gaming system ran around $150. (SOUNDBITE OF COMMERCIAL)UNIDENTIFIED ANNOUNCER: When you play the system with the most arcade hits, you're playing with power. KELLY: Back before we were worried about screen time. We're remembering the work of Masayuki Uemura. He died this week. (SOUNDBITE OF MUSIC) AUDIE CORNISH, HOST:   You may not be familiar with the name Masayuki Uemura, but odds are high you've spent hours with his revolutionary work. (SOUNDBITE OF KOJI KONDO'S \"SUPER MARIO BROS. THEME SONG\") MARY LOUISE KELLY, HOST:   With games like Mario Bros. and Donkey Kong, the Nintendo Entertainment System, or NES, dominated the home video game industry in the '80s and '90s. Uemura was its chief architect. CORNISH: He died this week at the age of 78. Uemura grew up in Tokyo. He became an electrical engineer. He joined Nintendo in 1972 and was soon working on the predecessor to early hit Duck Hunt. (SOUNDBITE OF DUCK HUNT SOUND EFFECTS) KELLY: In the early '80s, he was tasked with creating a home console to rival Atari. Nintendo's president asked Uemura to come up with a game using cartridges. CORNISH: The result was Famicom, or the Family Computer. It hit the U. S. market in 1985. And if Santa didn't hook you up, the 8-bit gaming system ran around $150. (SOUNDBITE OF COMMERCIAL) UNIDENTIFIED ANNOUNCER: When you play the system with the most arcade hits, you're playing with power. KELLY: Back before we were worried about screen time. We're remembering the work of Masayuki Uemura. He died this week. (SOUNDBITE OF MUSIC)", "section": "Games & Humor", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-12-13-1063824300": {"title": "Miami and New York City compete to become the center of the crypto industry : NPR", "url": "https://www.npr.org/2021/12/13/1063824300/miami-and-new-york-city-compete-to-become-the-center-of-the-crypto-industry", "author": "No author found", "published_date": "2021-12-13", "content": "AUDIE CORNISH, HOST:  As cryptocurrencies enter the mainstream, they are attracting money, investors and entrepreneurs. As a result, many U. S. cities are vying for the title of crypto capital. And as NPR's David Gura reports, one of the biggest rivals for that title is between the cities of Miami and New York. DAVID GURA, BYLINE: When Eric Adams was elected mayor of New York City, he had grand visions of making it a crypto destination. (SOUNDBITE OF MONTAGE)SHEPARD SMITH: Eric Adams pledging to take his first three paychecks in bitcoin. MARIA BARTIROMO: He tweeted yesterday, New York City is going to be the center of the cryptocurrency industry. GURA: But it turns out it's impossible for New York City employees to get paid in bitcoin, at least right now. Adams' pledge was an attempt on his part to one-up Miami, which has become New York's crypto rival. Adams fears the financial capital of the world, the city that never sleeps, is sleeping on what he believes is the future of finance. (SOUNDBITE OF RADIO SHOW, \"BLOOMBERG RADIO\")ERIC ADAMS: We need to look at what's preventing the growth of bitcoins and cryptocurrency in our city. What is in the way of that? GURA: Well, for one thing, New York is playing catch-up to a city that's gone all in. In Miami, the mayor's office says he is converting his pay into bitcoin. And last year, Miami hosted one of the world's largest crypto conferences. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED PERSON: Welcome to Bitcoin 2021. Are y'all ready to make some history? GURA: Miami's Mayor, Francis Suarez, was on hand to kick things off. (SOUNDBITE OF ARCHIVED RECORDING)FRANCIS SUAREZ: What I love about the bitcoin community is the enthusiasm, the energy, the energy for innovation. And that's something that's going to define our city and our world going forward. God bless you. Thank you. (CHEERING, APPLAUSE)GURA: Suarez says Miami was first out of the gate with its own cryptocurrency called MiamiCoin. And he's perfected his pitch to crypto entrepreneurs. (SOUNDBITE OF ARCHIVED RECORDING)SUAREZ: There's a cost-of-living differential, which is about 2 to 1 right now. It's twice as expensive to live in New York as it is to live in Miami. GURA: That's already motivated traditional financial firms to move to South Florida and some crypto companies, including blockchain. com. Peter Smith is its co-founder and CEO. PETER SMITH: It's the gateway to Latin America. It's on the East Coast time zone. And more importantly, it's probably the most excited city in the world about crypto right now. GURA: In New York City, Mayor-Elect Adams is trying to capture some of that excitement, but a lot stands in his way. Unlike Florida, New York does have a state income tax, and New York state has crypto regulations Florida doesn't. But New York City is still New York City. Brock Pierce, the chairman of the Bitcoin Foundation, has been a kind of unofficial adviser to the mayor-elect on crypto. He told Bloomberg News he's tried to help Adams understand both the value of crypto and how it could extend New York's influence. (SOUNDBITE OF TV SHOW, \"BLOOMBERG QUICKTAKE\")BROCK PIERCE: Certainly the financial capital or the capital of capital - cultural capital. And what happens here in New York City doesn't just affect New York City, it affects the whole country and the world. GURA: Crypto entrepreneur Patrick Stanley welcomes the competition we're seeing among cities. He's part of a loose collective called CityCoins that created that MiamiCoin. Stanley says the rivalry is a response to how attitudes have changed during the pandemic. PATRICK STANLEY: People who are working in information-based fields are kind of choosing cities the way they choose products. GURA: And they're looking for leaders who are, as Stanley puts it, technological progressives. He considers Adams one of them. So far, Adams hasn't put forward any concrete proposals, but he's floated adding crypto to the school's curriculum. And he says that if New York City embraces crypto, it'll lead to higher-paying jobs. With Adams' inauguration just a few weeks away, the mayor of Miami has some advice for New York City's mayor-elect. (SOUNDBITE OF ARCHIVED RECORDING)SUAREZ: Hang on tight. There's a lot of things coming. And listen; being No. 2 is - there's no shame in being No. 2. GURA: Oof - something no self-respecting New Yorker wants to hear. David Gura, NPR News. (SOUNDBITE OF WHITEFIELD BROTHERS' \"SAFARI STRUT\") AUDIE CORNISH, HOST:   As cryptocurrencies enter the mainstream, they are attracting money, investors and entrepreneurs. As a result, many U. S. cities are vying for the title of crypto capital. And as NPR's David Gura reports, one of the biggest rivals for that title is between the cities of Miami and New York. DAVID GURA, BYLINE: When Eric Adams was elected mayor of New York City, he had grand visions of making it a crypto destination. (SOUNDBITE OF MONTAGE) SHEPARD SMITH: Eric Adams pledging to take his first three paychecks in bitcoin. MARIA BARTIROMO: He tweeted yesterday, New York City is going to be the center of the cryptocurrency industry. GURA: But it turns out it's impossible for New York City employees to get paid in bitcoin, at least right now. Adams' pledge was an attempt on his part to one-up Miami, which has become New York's crypto rival. Adams fears the financial capital of the world, the city that never sleeps, is sleeping on what he believes is the future of finance. (SOUNDBITE OF RADIO SHOW, \"BLOOMBERG RADIO\") ERIC ADAMS: We need to look at what's preventing the growth of bitcoins and cryptocurrency in our city. What is in the way of that? GURA: Well, for one thing, New York is playing catch-up to a city that's gone all in. In Miami, the mayor's office says he is converting his pay into bitcoin. And last year, Miami hosted one of the world's largest crypto conferences. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED PERSON: Welcome to Bitcoin 2021. Are y'all ready to make some history? GURA: Miami's Mayor, Francis Suarez, was on hand to kick things off. (SOUNDBITE OF ARCHIVED RECORDING) FRANCIS SUAREZ: What I love about the bitcoin community is the enthusiasm, the energy, the energy for innovation. And that's something that's going to define our city and our world going forward. God bless you. Thank you. (CHEERING, APPLAUSE) GURA: Suarez says Miami was first out of the gate with its own cryptocurrency called MiamiCoin. And he's perfected his pitch to crypto entrepreneurs. (SOUNDBITE OF ARCHIVED RECORDING) SUAREZ: There's a cost-of-living differential, which is about 2 to 1 right now. It's twice as expensive to live in New York as it is to live in Miami. GURA: That's already motivated traditional financial firms to move to South Florida and some crypto companies, including blockchain. com. Peter Smith is its co-founder and CEO. PETER SMITH: It's the gateway to Latin America. It's on the East Coast time zone. And more importantly, it's probably the most excited city in the world about crypto right now. GURA: In New York City, Mayor-Elect Adams is trying to capture some of that excitement, but a lot stands in his way. Unlike Florida, New York does have a state income tax, and New York state has crypto regulations Florida doesn't. But New York City is still New York City. Brock Pierce, the chairman of the Bitcoin Foundation, has been a kind of unofficial adviser to the mayor-elect on crypto. He told Bloomberg News he's tried to help Adams understand both the value of crypto and how it could extend New York's influence. (SOUNDBITE OF TV SHOW, \"BLOOMBERG QUICKTAKE\") BROCK PIERCE: Certainly the financial capital or the capital of capital - cultural capital. And what happens here in New York City doesn't just affect New York City, it affects the whole country and the world. GURA: Crypto entrepreneur Patrick Stanley welcomes the competition we're seeing among cities. He's part of a loose collective called CityCoins that created that MiamiCoin. Stanley says the rivalry is a response to how attitudes have changed during the pandemic. PATRICK STANLEY: People who are working in information-based fields are kind of choosing cities the way they choose products. GURA: And they're looking for leaders who are, as Stanley puts it, technological progressives. He considers Adams one of them. So far, Adams hasn't put forward any concrete proposals, but he's floated adding crypto to the school's curriculum. And he says that if New York City embraces crypto, it'll lead to higher-paying jobs. With Adams' inauguration just a few weeks away, the mayor of Miami has some advice for New York City's mayor-elect. (SOUNDBITE OF ARCHIVED RECORDING) SUAREZ: Hang on tight. There's a lot of things coming. And listen; being No. 2 is - there's no shame in being No. 2. GURA: Oof - something no self-respecting New Yorker wants to hear. David Gura, NPR News. (SOUNDBITE OF WHITEFIELD BROTHERS' \"SAFARI STRUT\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-12-14-1064247651": {"title": "Kronos ransomware attack: Will my paycheck be affected by the hack? : NPR", "url": "https://www.npr.org/2021/12/14/1064247651/kronos-hack-paychecks", "author": "No author found", "published_date": "2021-12-14", "content": "", "section": "Technology", "disclaimer": ""}, "2021-12-14-1064123144": {"title": "Log4j vulnerability: Companies scramble to gird against hackers : NPR", "url": "https://www.npr.org/2021/12/14/1064123144/companies-scramble-to-defend-against-newly-discovered-log4j-digital-flaw", "author": "No author found", "published_date": "2021-12-14", "content": "AUDIE CORNISH, HOST:  A new and dangerous digital security flaw was publicly disclosed in an unexpected way - through Minecraft, the online game. To tell us more about it, we have NPR's cybersecurity correspondent Jenna McLaughlin. Welcome, Jenna. JENNA MCLAUGHLIN, BYLINE: Hi, Audie. Thanks. CORNISH: So help us understand the intersection here. How did Minecraft get involved? MCLAUGHLIN: So late last week, Minecraft game developers published a blog post where they revealed that they were impacted by a software bug where hackers can take over with one command using a digital hole that no one knew about before. So Minecraft did release a patch. But what the broader cybersecurity community quickly realized is that this was actually a much bigger problem and that it could impact big and small companies, even big names like Amazon and Apple, and potentially billions of devices. So it was a really rough weekend for digital defenders. Experts I spoke with didn't leave their desks. They were working on trying to figure out who might be at risk and what to do about it. CORNISH: How does it work? MCLAUGHLIN: So it's a really huge problem. When programmers write software, they don't want to have to create everything from scratch. So what they do is they often borrow basic building blocks that most programs need to function, and they take it from what's called open source code, which is free for anyone to use. So this flaw happened to be inside one of those very common open source tools, so common and simple that most developers don't even really think about it. So this program is called Log4j. It's a library. It does basically what it sounds like. It logs everything that happens on a device. So a couple of days ago, a Chinese researcher discovered it and privately alerted the software developers before Minecraft actually published that blog post. He realized that a hacker could send a message to the logger and take over the device and make it do whatever they wanted. CORNISH: Like what? MCLAUGHLIN: It could let them inside the network, where they could steal data, take your files hostage, all kinds of bad things. CORNISH: Right now, though, is this theoretical, or is there evidence of wrongdoing? MCLAUGHLIN: So right now experts are seeing the early stages of attacks. The bad guys are scanning the internet for potentially vulnerable devices. For example, crypto miners are hijacking computers to mine Bitcoin, for example, and we could see worse attacks in the coming days and weeks. Meanwhile, the good guys out there are looking for these same devices to protect them. One cybersecurity expert called it a race between the hackers and defenders. And this is what normally happens when a new cyber flaw is discovered. So this is a really bad bug, but it might not be as dire as some are saying. I spoke to Katie Nickels, who's the head of intelligence at cybersecurity firm Red Canary. She doesn't think people should panic. Here's what she had to say. KATIE NICKELS: Think of it as the unlocked door. An adversary has to charge through it somehow. That's what's reassuring about this, if anything - is that, yes, it's a new vulnerability. But the techniques, the behaviors that adversaries are using and the malware that they're deploying - it's known malware. CORNISH: So, Jenna, how can people protect themselves from these kinds of attacks? MCLAUGHLIN: So the U. S. government is reaching out to businesses to help. The burden right now really lies on the companies that make the software to fix it, and they're taking this problem very seriously. But it's going to take time. Nickels told me her advice to individuals is actually pretty basic. NICKELS: It's not very exciting, but the average person should just do their normal security best practices. MCLAUGHLIN: She says if a company reaches out and asks you to download a patch, do it immediately, and use antivirus software. CORNISH: That's NPR's cybersecurity correspondent Jenna McLaughlin. Thanks so much. MCLAUGHLIN: Thank you so much. (SOUNDBITE OF NEU! 'S \"WEISSENSEE\") AUDIE CORNISH, HOST:   A new and dangerous digital security flaw was publicly disclosed in an unexpected way - through Minecraft, the online game. To tell us more about it, we have NPR's cybersecurity correspondent Jenna McLaughlin. Welcome, Jenna. JENNA MCLAUGHLIN, BYLINE: Hi, Audie. Thanks. CORNISH: So help us understand the intersection here. How did Minecraft get involved? MCLAUGHLIN: So late last week, Minecraft game developers published a blog post where they revealed that they were impacted by a software bug where hackers can take over with one command using a digital hole that no one knew about before. So Minecraft did release a patch. But what the broader cybersecurity community quickly realized is that this was actually a much bigger problem and that it could impact big and small companies, even big names like Amazon and Apple, and potentially billions of devices. So it was a really rough weekend for digital defenders. Experts I spoke with didn't leave their desks. They were working on trying to figure out who might be at risk and what to do about it. CORNISH: How does it work? MCLAUGHLIN: So it's a really huge problem. When programmers write software, they don't want to have to create everything from scratch. So what they do is they often borrow basic building blocks that most programs need to function, and they take it from what's called open source code, which is free for anyone to use. So this flaw happened to be inside one of those very common open source tools, so common and simple that most developers don't even really think about it. So this program is called Log4j. It's a library. It does basically what it sounds like. It logs everything that happens on a device. So a couple of days ago, a Chinese researcher discovered it and privately alerted the software developers before Minecraft actually published that blog post. He realized that a hacker could send a message to the logger and take over the device and make it do whatever they wanted. CORNISH: Like what? MCLAUGHLIN: It could let them inside the network, where they could steal data, take your files hostage, all kinds of bad things. CORNISH: Right now, though, is this theoretical, or is there evidence of wrongdoing? MCLAUGHLIN: So right now experts are seeing the early stages of attacks. The bad guys are scanning the internet for potentially vulnerable devices. For example, crypto miners are hijacking computers to mine Bitcoin, for example, and we could see worse attacks in the coming days and weeks. Meanwhile, the good guys out there are looking for these same devices to protect them. One cybersecurity expert called it a race between the hackers and defenders. And this is what normally happens when a new cyber flaw is discovered. So this is a really bad bug, but it might not be as dire as some are saying. I spoke to Katie Nickels, who's the head of intelligence at cybersecurity firm Red Canary. She doesn't think people should panic. Here's what she had to say. KATIE NICKELS: Think of it as the unlocked door. An adversary has to charge through it somehow. That's what's reassuring about this, if anything - is that, yes, it's a new vulnerability. But the techniques, the behaviors that adversaries are using and the malware that they're deploying - it's known malware. CORNISH: So, Jenna, how can people protect themselves from these kinds of attacks? MCLAUGHLIN: So the U. S. government is reaching out to businesses to help. The burden right now really lies on the companies that make the software to fix it, and they're taking this problem very seriously. But it's going to take time. Nickels told me her advice to individuals is actually pretty basic. NICKELS: It's not very exciting, but the average person should just do their normal security best practices. MCLAUGHLIN: She says if a company reaches out and asks you to download a patch, do it immediately, and use antivirus software. CORNISH: That's NPR's cybersecurity correspondent Jenna McLaughlin. Thanks so much. MCLAUGHLIN: Thank you so much. (SOUNDBITE OF NEU! 'S \"WEISSENSEE\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-12-14-1063706605": {"title": "343 Industries makes great first-person shooter game  : NPR", "url": "https://www.npr.org/2021/12/14/1063706605/halo-infinite-wows-on-both-single-and-multiplayer-but-needs-more-legacy-features", "author": "No author found", "published_date": "2021-12-14", "content": "", "section": "Gaming", "disclaimer": ""}, "2021-12-16-1064628654": {"title": "Facebook bans 7 'surveillance-for-hire' companies that spied on 50,000 users : NPR", "url": "https://www.npr.org/2021/12/16/1064628654/facebook-bans-surveillance-firms-that-spied-on-50000-people", "author": "No author found", "published_date": "2021-12-16", "content": "AUDIE CORNISH, HOST:  Seven surveillance firms have been banned from Facebook, Instagram and WhatsApp. The parent company of those apps, Meta, says the surveillance companies abused platforms to target 50,000 unsuspecting people around the world. NPR tech correspondent Shannon Bond has more. And a note - Meta does pay NPR to license NPR content. SHANNON BOND, BYLINE: Meta says these companies are mercenaries who sell their spying services to anyone willing to pay. In a new report, Meta details how these seven firms created fake Facebook and Instagram accounts that let them infiltrate groups, befriend targets and trick them into sharing sensitive information like banking and email passwords. Some used WhatsApp messages to infect people's phones with spyware. NATHANIEL GLEICHER: We see them targeting journalists, politicians, activists, human rights defenders. BOND: That's Nathaniel Gleicher, head of security policy at Meta. GLEICHER: We also see them targeting celebrities and also ordinary people, people who bank online, people who might be party to a lawsuit. BOND: His team links these seven companies to around 1,500 accounts on Facebook and Instagram. GLEICHER: We've seen some of these firms, for example, create fake accounts designed to look like journalists so that they could reach out to people or fake accounts designed to look like a grad student or someone they might know, and they'll build trust with them. BOND: Gleicher says it's not always clear who is hiring these firms, but in some cases, it's governments going after critics and opposition. One of the companies, based in China, was working for Chinese law enforcement to spy on people in Xinjiang and Hong Kong. The crackdown builds on a lawsuit WhatsApp filed in 2019 accusing the Israeli company NSO Group of helping governments hack 1,400 phones through WhatsApp messages. Pressure has been growing on the surveillance industry, with watchdog groups and lawmakers calling for the U. S. government to impose sanctions on companies. John Scott-Railton is a cybersecurity researcher at the University of Toronto's Citizen Lab. He says these firms enable human rights abuses. JOHN SCOTT-RAILTON: Almost every autocrat and dictator around the world is being pitched this kind of technology. And it's really important that we get to a place where there are big global norms and regulations. Otherwise, it's just gas on the authoritarian fire. BOND: Meta says that's why it's making its actions public - to draw attention to a shadowy industry that extends far beyond the companies it's banning today. Shannon Bond, NPR News. (SOUNDBITE OF VEGYN SONG, \"DEBOLD\") AUDIE CORNISH, HOST:   Seven surveillance firms have been banned from Facebook, Instagram and WhatsApp. The parent company of those apps, Meta, says the surveillance companies abused platforms to target 50,000 unsuspecting people around the world. NPR tech correspondent Shannon Bond has more. And a note - Meta does pay NPR to license NPR content. SHANNON BOND, BYLINE: Meta says these companies are mercenaries who sell their spying services to anyone willing to pay. In a new report, Meta details how these seven firms created fake Facebook and Instagram accounts that let them infiltrate groups, befriend targets and trick them into sharing sensitive information like banking and email passwords. Some used WhatsApp messages to infect people's phones with spyware. NATHANIEL GLEICHER: We see them targeting journalists, politicians, activists, human rights defenders. BOND: That's Nathaniel Gleicher, head of security policy at Meta. GLEICHER: We also see them targeting celebrities and also ordinary people, people who bank online, people who might be party to a lawsuit. BOND: His team links these seven companies to around 1,500 accounts on Facebook and Instagram. GLEICHER: We've seen some of these firms, for example, create fake accounts designed to look like journalists so that they could reach out to people or fake accounts designed to look like a grad student or someone they might know, and they'll build trust with them. BOND: Gleicher says it's not always clear who is hiring these firms, but in some cases, it's governments going after critics and opposition. One of the companies, based in China, was working for Chinese law enforcement to spy on people in Xinjiang and Hong Kong. The crackdown builds on a lawsuit WhatsApp filed in 2019 accusing the Israeli company NSO Group of helping governments hack 1,400 phones through WhatsApp messages. Pressure has been growing on the surveillance industry, with watchdog groups and lawmakers calling for the U. S. government to impose sanctions on companies. John Scott-Railton is a cybersecurity researcher at the University of Toronto's Citizen Lab. He says these firms enable human rights abuses. JOHN SCOTT-RAILTON: Almost every autocrat and dictator around the world is being pitched this kind of technology. And it's really important that we get to a place where there are big global norms and regulations. Otherwise, it's just gas on the authoritarian fire. BOND: Meta says that's why it's making its actions public - to draw attention to a shadowy industry that extends far beyond the companies it's banning today. Shannon Bond, NPR News. (SOUNDBITE OF VEGYN SONG, \"DEBOLD\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-12-17-1065444892": {"title": "Elizabeth Holmes' fraud case is now in the jury's hands : NPR", "url": "https://www.npr.org/2021/12/17/1065444892/elizabeth-holmes-fraud-case-is-now-in-the-jurys-hands", "author": "No author found", "published_date": "2021-12-17", "content": "", "section": "Business", "disclaimer": ""}, "2021-12-17-1065119990": {"title": "Amy Webb: A Glimpse Into The Future : NPR", "url": "https://www.npr.org/2021/12/17/1065119990/amy-webb-a-glimpse-into-the-future", "author": "No author found", "published_date": "2021-12-17", "content": "MANOUSH ZOMORODI, HOST:  It's the TED Radio Hour from NPR. I'm Manoush Zomorodi. (SOUNDBITE OF MUSIC)ZOMORODI: And ask anyone to predict the future these days, they will likely decline. (SOUNDBITE OF MONTAGE)ANTHONY FAUCI: You know, I'm not going to speculate on that. I want to see what happens right now. ANTHONY MASON: No one can forecast exactly how 2021 will unfold. ELON MUSK: Well, I think this is one of those things that's quite difficult to predict. FAUCI: We just can't predict that. We don't know. ZOMORODI: For many of us, the world feels erratic, volatile. Trying to guess what will happen next seems futile unless you're Amy Webb. AMY WEBB: I'm Amy Webb. I am the CEO of the Future Today Institute and a professor of strategic foresight at the NYU Stern School of Business. ZOMORODI: And, Amy, is it fair to say you're a futurist? WEBB: I am. I'm a quantitative futurist. ZOMORODI: Coolest job title, but can you explain what a quantitative futurist is? Do you see, like - I don't know - spreadsheets in your crystal ball? WEBB: So futurists do not make predictions. Instead, we collect signal data. We model those data, looking for patterns and try to anticipate many plausible futures. (SOUNDBITE OF MUSIC)ZOMORODI: Big corporations and governments use Amy's projections to prepare for all kinds of scenarios, including pandemics. WEBB: The type of work that we do results in very big bets, you know, sometimes involving billions or multiple billions of dollars that chief executives and their teams have to place. And we want to make sure that they're prepared. ZOMORODI: But Amy says her research into scientific innovation and technology trends, well, more just regular people need to know about them as well. WEBB: Manoush, like you, I'm a regular person, too. And. . . (SOUNDBITE OF MUSIC)WEBB: . . . Here's the plight of the regular person. The problem is that we're living through this great transformation. And every one of us who's living today, we're going to have to start making some really difficult choices that impact how we spend our time and what we want our kids to do and the people that we vote for. You know, these are going to be complex decisions. And the good news is that on the horizon, there's a lot of opportunity for, you know, personal growth, for economic growth. But that opportunity comes with some serious associated risks. ZOMORODI: So today on the show, Amy Webb talks us through four categories of innovation and explains how these inventions and ideas could upend the future of travel, wellness and what we value in the world. Amy has actually been on the show before talking about her memoir and TED Talk - both called \"Data, A Love Story\" - about how she hacked an online dating platform. But today, she is back to give us A Glimpse Into the Future. (SOUNDBITE OF MUSIC)ZOMORODI: OK. So Amy, you have generously agreed to return to the show. But we are going to do something completely different. You are going to guide us through a selection of TED Talks about some of the big trends in technology. But they're very specific innovations. And you're going to help us put these innovations into context, break down the hype from the real change that could stem from them, and help us understand the impact that they might have on the way that the internet and our lives work. So lots to talk about. WEBB: It'll be fun. ZOMORODI: And I want to start with a category that truly does affect us all, transportation. We can't teleport yet, Amy, but we still need to move our bodies from point A to point B. And this first speaker thinks that one way we will do that is with something called the hyperloop. Josh Giegel is the CEO and co-founder of the Virgin Hyperloop. His 2021 talk is called \"Super Speed, Magnetic Levitation And The Vision Behind The Hyperloop. \" And if you've never heard of the hyperloop - I had not - here is how he describes it. (SOUNDBITE OF TED TALK)JOSH GIEGEL: So hyperloop is a transit system that has a vehicle called a pod inside of a tube about the same size as a subway tunnel, where we suck most but not all of the air out of it - be the equivalent of flying at about 200,000 feet of altitude. This allows us to glide at airline speeds without turbulence for a fraction of the energy consumption - about one-tenth, to be precise, of an aircraft. And that's important because we, as humans, have an innate need for speed. But this obsession with speed and volume is destroying the planet around us. In fact, in the United States, the transportation industry is the single largest contributor to greenhouse gas emissions. A hyperloop system can begin to change this trend before the end of the decade by transforming short haul journeys and commutes from hours to minutes. ZOMORODI: OK. This sounds amazing. I'm levitating. I'm getting sucked through a kind of more efficient subway tunnel, essentially, but going as fast as a plane, using one-tenth of the energy that airline travel uses. Amy, tell us more about how it actually works. WEBB: Yeah. OK. So do you remember pneumatic tubes at banks? You put your money in that little canister thing. And then it gets sucked up and delivered to the teller on the inside of the building. So this is not entirely how hyperloop works. But, you know, it gives you at least a visual. ZOMORODI: Yeah. WEBB: So imagine being inside of a very comfortable pod, a closed container, that's capable of traveling, you know, at very, very fast speeds. So if you've ever been at the bank drive-through and you've seen what that tube looks like and how fast things are going, it's kind of the same thing. So we're talking about sort of a pod that is hovering inside of a vacuum tube. And using electric propulsion, it can accelerate gradually, pick up speed and then really take off. And the pods are able to glide along the track using magnetic levitation, which is actually already in use in some train systems, just in a different way around the world - so, like, maglev trains in Japan and China, for example. ZOMORODI: So is it kind of like a subway? Like, would there be stops along the way? What kind of travel or commute would the Hyperloop be best suited for? WEBB: Well, you know, a lot of these plans project speeds of between 700 and 800 miles an hour. ZOMORODI: Holy moly. WEBB: So that's pretty fast. So by the time you get one of these things up to speed, you know, you're not going to want to make a stop every couple of blocks. So instead, this would be more of an equivalent of a - like, a round trip between San Francisco and Los Angeles, which would normally take 12 hours on the road but being able to do it in just one hour. ZOMORODI: It's interesting to me that, like, what you're describing sounds really futuristic. But Josh Giegel says the idea of a hyperloop has actually been around for a while. (SOUNDBITE OF TED TALK)GIEGEL: And 118 years ago, before the Wright brothers' first flight, the thought of humans flying was inconceivable. It was crazy, even. Yet today, we get into a plane 30,000 feet above the ground and think nothing of it. A year after the Wright brothers' historic first flight, another inventor, an American physicist named Robert Goddard, proposed an entirely new form of transportation - the vactrain. He envisioned a high-speed mass transit system where people would travel on the ground, with little to no air resistance, inside of a tube. And today, these renderings of some of the earliest renderings what we call a hyperloop. ZOMORODI: (Laughter) The vactrain. OK, so we've been thinking about zipping our bodies around the Earth for decades. But I got to say, Amy, the newest mode of transport that I have taken recently is, like, a motorized scooter. Have we kind of been at a lull when it comes to innovating transportation? I'm not ready to sign up for Jeff Bezos's visit to the outer edge of the atmosphere. I just want to get places on the planet. And, you know, I feel like we've heard a lot about making all our cars electric, but that's not terribly futuristic. So where are we when it comes to innovating in transportation? WEBB: You know, historically, when we think about the future of transportation, we tend to think of things in the air, not things above the ground slightly or even under the ground. And, you know, we tend to reference \"The Jetsons. \"ZOMORODI: Right. WEBB: Now, when we think about transportation and the future, we tend to reference \"The Jetsons\" because of that scene with the flying car at the beginning, right? ZOMORODI: Right. Yes. WEBB: And, you know - and even if you haven't watched an episode of \"The Jetsons,\" if somebody says Jetsons car, everybody immediately knows what you mean. But here's what's interesting. It was 1917 when a guy named Glenn Curtiss filed a patent for an autoplane (ph), and it was a car with some wings attached to it. So it hopped in the air kind of a few times, and it never really, really flew. But every decade since then, there have been multiple flying car patents and actual flying cars that got designed. ZOMORODI: Wow. WEBB: So the question is, why are we stuck in this vicious cycle of the future of transportation being a thing we already have that happens to be up in the air that doesn't really solve any problems? ZOMORODI: And I - just to get back to the Hyperloop. The - not only have the plans been drawn up, but I was intrigued to hear that the - that they're testing it now with, like, real humans in it, including Josh Giegel himself. Its first ride with real passengers was in November of 2020, and here's him describing what happened. (SOUNDBITE OF TED TALK)GIEGEL: We've created a test track in the deserts outside of Las Vegas. We've operated the system over 500 times and had countless other tests on our subsystems. So by October of 2020, we had run hundreds of tests. We had an independent safety auditor give us the green light, but still, it was nerve-wracking. And on November 8, 2020, we made our first attempt. So at our test site, my colleague Sara and I climbed into that can-like vehicle, suspended by magnetic levitation, at a near-vacuum environment, and the countdown began. In those 15 seconds, we showed the world that what was deemed ludicrous over a hundred years ago was, in fact, possible. This is the start of a systemic change in the way we travel. ZOMORODI: So, Amy, you've watched the video. It's pretty fun to watch because it's Josh and a colleague, like, zipping around at whatever - 700 miles per hour with their cheeks, like, flapping in the wind. They look like they're on a roller coaster ride. Is this the start of a systemic change in the way we travel? I'm not so sure I want to travel like that. WEBB: (Laughter) Listen, I hope it is. I hope it's the start of systemic change. Why can't we be open to alternative options for the future? The real future of a hyperloop isn't necessarily people with their cheeks flapping in the wind, looking pretty uncomfortable, moving at speeds that are absolutely terrifying. This is the beginning, right? The very first plane that took flight, the very first car, the very first Sumerians who invented, millennia ago, a way to get around on a cart using horses - you know, these are technologies that - they evolve over longer periods of time. So I, for one, welcome our Hyperloop future, but it's going to take us some time to get there. (SOUNDBITE OF MUSIC)ZOMORODI: In a minute, more glimpses into the future with Amy Webb, including looking at a new kind of bra that could change health care for women. I'm Manoush Zomorodi, and you're listening to the TED Radio Hour from NPR. Stay with us. It's the TED Radio Hour from NPR. I'm Manoush Zomorodi. On the show today, A Glimpse Into the Future. We are talking to futurist Amy Webb about where science and technology are headed next, including some fascinating and unusual inventions from TED speakers. And one of the categories where Amy sees some of the most innovation is in health and wellness. WEBB: We're looking at sort of a vast constellation of things that range from devices that connect to our personal data - so that would be a smartwatch like a Fitbit or an Apple Watch - to the onslaught of wearable devices that are coming to market - smart glasses. ZOMORODI: Yeah. WEBB: You can buy a ring that has a digital assistant and a speaker and a microphone built in that you wear on your finger that let you know if you're getting enough oxygen, wristbands that detect your emotion, your stress, your exercise habits. There are smart yoga pants that you can wear that will reveal whether or not you're doing postures correctly during the poses. So it's just all of these different devices that are collecting our data, helping us understand ourselves better and, in some cases, connecting your body directly to your physician for remote patient monitoring. ZOMORODI: I mean, some of those sound really cool. The example that we have got in this health and wellness category is, again, an old technology updated for the digital age, something specifically for women. In 2021 engineer and entrepreneur Alicia Chong Rodriguez - she gave a talk about her invention, a smart bra for better heart health. And she started her talk by explaining that there is a big problem for women in health care right now because of the way that research is done. (SOUNDBITE OF TED TALK)ALICIA CHONG RODRIGUEZ: Heart disease and stroke are the leading causes of death and disability worldwide, and for women, it is not only harder to recognize, diagnose and treat. But after a heart attack or a stroke, women also face higher mortality. There are about 44 million women living in the U. S. with heart disease, and the incidences for women under 65 are on the rise. So what's going on? The answer lies at the intersection of two areas - data and medical devices. When I was doing cardiovascular research at MIT, I had access to huge datasets. Realizing that women were one of the largest subgroups underrepresented was eye-opening. In fact, women were basically excluded from cardiovascular clinical trials until the NIH mandated inclusion in 1993. This is why existing technologies and therapies often fall short - because most of them have been designed using data primarily from male animals and men. And as artificial intelligence helps turbocharge digital health, there's a danger that algorithms mostly trained with male data and biases will actually perpetuate the problem. ZOMORODI: Amy, hearing Alicia explain the huge gap that exists in data about women's health simply because their data was not being collected - also, that data sounds really old. I mean, I guess I shouldn't be surprised, but I was. What was your reaction? WEBB: Well, I'm not surprised. This TED talk really resonated with me because I do a lot of long distance bike riding on the weekends. And, you know, you can buy a heart rate monitor to track your heart rate and all the metrics that you would want to be tracking. And those monitors are best when they are attached to your chest and basically, like, pretty close to your heart. For those of you who are women who wear sports bras, you know that that is impractical. The way that sports bras are designed, the way that these chest monitors are designed - they're just - they don't work together very well. They're uncomfortable. They move around. You know, these are devices that are clearly designed for men by men. So this is a tiny, small example of a way that, as a woman, I'm being left out. And I'm somebody who desperately wants to and knows how to mine and refine my own data. There's a biometric data divide. ZOMORODI: And it's not just women, right? I mean, I've heard of dermatologists who say that a lot of the data being collected is only on white skin and not Black skin. And therefore, new treatments are biased in some ways because not only do they not know how they work; they don't know if they work on different kinds of skin. WEBB: That's absolutely correct. And the trick here is that as we ask artificial intelligence AI systems to play a greater role in pattern recognition and precision medicine and rapid drug discovery, unfortunately, we are making, in some cases, life and death decisions based on a very narrow dataset. And that's something that should concern everybody. ZOMORODI: So let's go back to Alicia. Her solution to one of the problems is collecting the right data with something she calls the smart bra. Here's how it works. (SOUNDBITE OF TED TALK)CHONG RODRIGUEZ: Our idea is to turn the everyday bra into an actual lifesaver. This is our augmented garment platform. It gives women the ability to continuously and remotely acquire physiological data. By wearing this bra, a woman can view insights and patterns and keep an automated journal in her phone, giving her a simple way to track symptoms and collect lifesaving data to share with her doctor for early detection and targeted management. It can even track the safety and efficacy of certain therapies. We've built medical-grade textile sensors that can adapt to multiple bra styles and sizes for continuous, reliable and repeatable data all around her torso and her heart. We can track heart rhythm, breathing, temperature, posture and movement. And by applying algorithms, we can use this data to decode symptoms, articulate arrhythmia triggers and generate personalized digital biomarkers. (SOUNDBITE OF MUSIC)ZOMORODI: What do you think of this, Amy? What do you think of her promise that this is an easy way to collect a lot of data on a personal level, but also a collective level - right? - that if you get enough women wearing these bras, then we can start to create new data sets and really understand what is happening for women and their cardiovascular health? WEBB: Well, obviously, if you have better sources of data to start and you're able to use those data, then you're going to get better outcomes on the other side. This is the beginning of a different path. And I think that's important because, you know, we're moving into an era where algorithms are making more and more decisions about us and, in fact, optimizing our health for us on a daily basis. And we want to make sure that we're optimizing for everybody, which means we need bigger pools of data. We need more opportunities for people to contribute data. And importantly, we need trust. Because without trust and faith in the systems that are collecting, housing and protecting these data, you know, then we create more problems down the road. ZOMORODI: Yeah. I mean, that concerns me. Like, well, you're collecting pretty intimate data here. What are you going to do with it? Who's in charge of it? All of those things. But on the flip side, if you tell me that by wearing this, I am contributing to an anonymized set of information that could maybe get more funding for research into how to treat cardiovascular problems for women, like that's intriguing to me. I'm excited by that. WEBB: Yeah. But again, this comes down to trust. I can give you a. . . ZOMORODI: Right. WEBB: . . . Quick example of what happens when you misplace or abuse trust. So there's. . . ZOMORODI: Yeah. WEBB: . . . A tribe that has lived in what is now Arizona for centuries, the Havasupai tribe. This tribe has had some issues with diabetes over time, and so they allowed researchers from Arizona State University in to conduct a study in 1990. And the idea was to collect health data, learn and eventually help the tribe eradicate diabetes. But then, unbeknownst to the tribe, the researchers changed the scope of their project to encompass a lot more data; so genetic markers for alcoholism, for different disorders like schizophrenia. And the researchers went on to publish a whole bunch of papers in academic journals highlighting these results. And the articles resulted in news stories. And the news stories really reflected badly on this tribe. They were completely, understandably, horrified and humiliated, which led to the Navajo Nation, which was the second - or, I guess, is the second largest group of indigenous people in the United States, to ban all genetic sequencing, all analysis; basically, all related research on its members. And that makes sense, right? Because nobody wants to be exploited in that way. But that caused this other problem, which is that the pool of genetic data in the U. S. doesn't really include indigenous people. And, you know, there are similar stories that I could tell you about America's Black population, you know, about various populations in the United States. And this all goes back to trust. So I think it's a good idea that we have more, better data, but we also have to do so in a way that is traceable and accountable, and we have to be good custodians of people's personal private data. ZOMORODI: Yeah. We need to remember that when we - remember why some people are vaccine hesitant. From what I understand, Alicia hopes to bring her smart bra to the market, like, pretty soon, actually. What are some other personal health devices that you think are going to be out there pretty soon? WEBB: Well, I got to tell you, the thing that I'm looking forward to is a toilet. ZOMORODI: (Laughter). WEBB: So this is, like, a weird turn that we're about to take, but. . . ZOMORODI: Do it, Amy. WEBB: . . . Do it. So, like, in the 2010s, there was some research at Stanford University on a device that you would have in your home. So this is a smart toilet, which was outfitted with litmus strips and some pressure sensors and things. And the idea was to be able to more effectively monitor patients in living facilities, in their homes. Now, there's actually a lot of very valuable data that you can retrieve that you, let's say, leave behind, right? ZOMORODI: (Laughter). WEBB: So with one brief trip to the bathroom, we can tell a lot about you, like whether you have prostate inflammation or your blood sugar level is high or whether, you know, you've got certain inflammation in your gut. And these data tell a story about your gut health and about your overall health. The problem is that we tend not to collect those data unless there is something wrong, when we show up at a doctor's office. Wouldn't it be awesome if we were able to collect those data every day? I mean, can you imagine knowing what your gut flora baseline is the way that you know what your normal temperature is? ZOMORODI: Oh, I'm in. WEBB: Yeah. That would be incredibly useful, actionable information. And then, interestingly enough, earlier this year, Toto, which is a Japanese company famous for making toilets, debuted its own wellness toilet. And this is a toilet outfitted with sensors, collection tools, you know, basically all the type of technology that you really don't want recognizing you in that particular place, you know what I mean? ZOMORODI: So not only would it be like, wow, I should eat more sauerkraut, but also could it potentially - like, I'm thinking of last - when the pandemic began and people started - there was a collection from sewer systems and they started to be able to tell, you know, from fecal matter where there was about to be a coronavirus outbreak. Is that another way that this could be sort of collectively? WEBB: Yeah, totally. I mean, you could pool - two things with the beginnings of the outbreak. You know, a lot of men, men of a certain age, they get a lot of prostate infections, and a prostate infection, in some ways, mirrors the symptoms of COVID-19. You get all-over body aches. You run a fever. You feel kind of achy, right? And I would imagine at the beginning of the crisis, there were probably a lot of men out there who were at the beginning stages of a prostate infection worrying that they had COVID and also probably without the ability to easily get into a doctor's office to take a test. So a smart toilet would have alleviated, you know, some of that challenge - right? - because you would have known, oh, I've got a prostate infection. My toilet is going to connect to my local pharmacy and shoot over a prescription for Cipro, right? And that'll be that. And yeah, if we were able to anonymize and pull those data in a way that protected privacy, then yeah, we would probably have been able to track pockets of outbreak. In the future, we'll be able to track pockets of poor nutrition or areas where diabetes is starting to spike, and you'll be able to do a lot on a micro-community level. ZOMORODI: OK. I want to switch gears now, and I want to talk about something in a realm that has largely been devoid of technological innovation. The next speaker gave a talk in 2021. Her name is Karoli Hindriks. She's an entrepreneur, and her talk is called Why The Passport Needs An Upgrade. Karoli thinks they are cumbersome, bureaucratic, essentially logistical nightmares for people who live in the global economy. And, you know, this is not a problem that she thinks is new. She started thinking about the issues that come with passports while she was growing up in Estonia under Soviet occupation. (SOUNDBITE OF TED TALK)KAROLI HINDRIKS: Having lived in that level of darkness made me wonder why are borders and movement between countries constructed the way they are? According to the World Economic Forum, human capital is the driving force for economic growth. So why are the barriers to global mobility so high? Why is the process so time-consuming, so dreadful and taunting, so very scary? And I know it's scary because I was detained at San Francisco Airport for two hours just to get on this stage. In 2020, the World Economic Forum reported that the top three countries where the highly educated migrants came from were India, China and Philippines, which, according to 2021 Henley Passport Index, ranked among the least travel-friendly passports in the world, ranking respectively 85th, 70th and 77th out of 110. The problem starts from what we call a passport. ZOMORODI: OK, so Karoli is wondering, why? If we need mobility to get human labor and capital to the places that need it, what is the point in making it so hard to do so? And the way that we currently track people is essentially based on nationality rather than the idea that people exist as part of an international, I guess, workforce is what she's saying. WEBB: Yeah, I mean, if you stop and think what is a passport really - right? - it's just a number that's tied to a database. And it represents us, I guess, in a way, but it doesn't do much more than that. And most of us now are global. You know, we work in different places. We move around to different places. And the value sometimes that we place on a person and therefore their ability to move around is very much hindered by wherever that passport came from. So she absolutely has a point. ZOMORODI: She gives another example of a highly skilled specialist from Yemen, a divorced single mother of two who's working for a Malaysian tech company. And the company wants to transfer her to their European office. But because she has a Yemeni passport, she has to fly thousands of miles back and forth multiple times, different embassies to get visas for her and her kids - I mean, clearly not good for her family, not good for the company, not good for the environment. So why does it continue to work this way if none of us like it? WEBB: Well, we tend to keep things in motion - right? - and we don't like to make huge or big changes. The passport was first introduced as a globally required travel document during World War I, just after Henry Ford introduced affordable automobiles. And today, our passports are still pretty much the same way that they were a century ago. I think there was a flaw in the way that the passport system was built. The modern passport system was designed by a Western-centric organization. ZOMORODI: Right. WEBB: And it became an object for people in Western countries, but it became a burden for others. ZOMORODI: When we come back, how Karoli wants to fix the passport problem and whether futurist Amy Webb thinks it will work. On the show today, A Glimpse Into the Future. I'm Manoush Zomorodi, and you're listening to the TED Radio Hour from NPR. We'll be right back. It's the TED Radio Hour from NPR. I'm Manoush Zomorodi. And on the show today, glimpses into the future. We are spending the hour with futurist Amy Webb, talking about innovations that could revolutionize how we live, interact and travel. Amy, we were just talking about how outmoded the paper passport is in a global economy. And we were hearing from entrepreneur Karoli Hindriks, who believes that digital passports are the answer. And she came to this by experience, by growing up in Estonia, a country which has put all of its citizens' information online. WEBB: Yeah. It's really difficult to overstate just what a quantum leap Estonia has made when it comes to digitalization. You know, from creating e-passports and electronic registry systems to even creating a system like a national registry for genetic data to make it easier to run experiments in a totally ethical way, you know, Estonia is just leaps and bounds ahead of most of the rest of the world when it comes to digitalization and creating decentralized systems that are fair and equitable and serve its citizens. Now, to be fair, Estonia is also a teeny, tiny country, very - you know, like, a few million people in north central Europe. So, you know, how that might scale in Western Europe or in a place like the United States is a little bit more complicated. But the story of Estonia and the story that she's telling is a fascinating example of an alternative future. (SOUNDBITE OF TED TALK)HINDRIKS: One of the keys to Estonia's success in digitalization was the focus to build one digital identity for each individual that allows public and private databases to link up and operate in harmony. Estonia is going to do everything online other than get married or divorced. The digitalization saves Estonia a stack of paper as high as the Eiffel Tower every month. On top of that, the digital signature alone enables Estonia to save 2% of its GDP every year. That's a whole lot of money being wasted because public sectors are not adapting to existing technologies. We can tackle that by creating a secure, universal digital identity where all the users need to do is upload their data and documents such as passport, marriage and education certificates into our smart system, which then converts that data into pieces that can be matched to relevant government forms in different countries. The beauty of it is the once-only rule. The user needs to add that data once, as it is then stored for the future use. ZOMORODI: So what she means by universal identity is that all of our important information would exist online in a single system not controlled by any one country and eliminating the current bureaucracy of travel and working in other countries. But, Amy, Karoli kind of skims over the technology that would be needed to make this even possible. She refers to it as a smart system. What is that? WEBB: Right. So she's talking about - and please stay with me as I say this - the blockchain. ZOMORODI: Oh, that word, right? WEBB: I know. I know. It's horrible, right? But here's what's important. We're talking about something akin to, like, a huge, public spreadsheet where anybody can write information to it. And it's authenticated, and it's accurate, and it's anonymous. So you don't know whose stuff is what. But it also can't be erased or modified. And here's why this matters - because she's talking about forums. But this is not just about forms. You know, the average person has I don't know how many passwords and documents. Manoush, when I got married, I legally changed my last name to my husband's last name. ZOMORODI: Oh. WEBB: And I cannot begin - like, some ladies who are listening here know the apocalyptic horror of what it's like before and after you change your name. It's like I had to carry around a marriage certificate with me for a year because of, you know, trying to get on planes and, you know, waiting for this, like, cascade of correct documentation to arrive. It was horrible. I'm still me, right? I've just adopted a different last name. So what she's talking about here is making this easier so that the set of credentials that is you - that they're stored in a place, and they can't be altered. But they can be authenticated and used by a trusted third party. We already have sort of parts of this in existence today in the form of, you know, a credit card or a bank account, things like that. What she's talking about here is something much more bigger. It's much more comprehensive. And it's part of the blockchain. . . ZOMORODI: Yeah, yeah. WEBB: . . . Like a smart contract. ZOMORODI: I mean, there are lots of things still being worked out with blockchain, like who governs it, who authenticates it. But the case that I keep thinking about is my vaccine card because right now I have this little slip of paper from Walgreens that says I've been vaccinated. And here in New York, we have an app on our phones that shows our vaccination status, but that only works here in New York City. I went to California, and they were like, cool. Can I see your piece of paper? WEBB: Yep. ZOMORODI: Anyone can fake a little piece of paper. This - in a global pandemic, don't we need a global way of tracking vaccinations? WEBB: So something like a centralized digital ID solves a lot of these problems. And I will tell you that because the work that we do, you know, there's a lot of governments that are in progress on building singular digital identities. And I think the challenge going forward is we're going to have competing systems, which, I think, presents some new types of problems. ZOMORODI: So we're coming in for the finish here. Most of the innovations that we've discussed so far are in testing or prototype form. They're not necessarily available to the average person. But the last thing we're going to talk about - and there are going to be people who groan when I say this. . . WEBB: (Laughter). ZOMORODI: . . . And other people who say, wait, what? It's NFTs. That stands for non-fungible tokens. And this is a digital way of buying ephemeral things like artwork. Any of us can use them. And one believer in this new technology is Kayvon Tehranian. He's a technologist and entrepreneur. And his talk is called \"How NFTs Are Building The Internet Of The Future. \"(SOUNDBITE OF TED TALK)KAYVON TEHRANIAN: We've uploaded trillions of photos and videos and even cat memes to the internet for free. And what business model has allowed this information to be free? Advertising. Advertising is the internet's default business model, not because that's what we want, but because that's what pays the bills. Right now, the few large corporations that run the most effective ad networks control most of the value on today's internet, not the people creating its content. On today's internet, we don't get paid for the work we do with our minds. And what's more, the content we upload to these services is trapped there. These services not only make money from our content, they control it - until NFTs. NFTs are a technological breakthrough. They offer us the opportunity to break away from that broken system. It's a certificate of ownership registered on the blockchain for everyone to see. It's not too dissimilar to the deed you get when you buy a house in the physical world. But instead of a house, an NFT denotes ownership of a file on the internet. ZOMORODI: OK. So let's say it again. NFTs stand for non-fungible tokens. Kayvon describes it like a deed to a house. But, I mean, is it really like a deed to a house? Amy, help me out. What is the right analogy here? And I think we need to use the word blockchain again. WEBB: (Laughter). ZOMORODI: Lord, help us. WEBB: All right. So non-fungible basically means that whatever it is is unique. You can't make another one, right? So a dollar bill is fungible because if you have one dollar bill, you could trade it in for another dollar bill and get the same value, unless there's extenuating circumstances like you've got an ultra-rare dollar bill or something. OK. Here's where this actually becomes practical. So if you've bought a super-expensive collectible item, like a fancy handbag, it comes with a certificate of authenticity. But there have been some problems with things that look real but aren't. Or paper certificates have a habit of getting lost. So let's say you get your physical, fancy handbag. But in addition to that, you also get a non-fungible token, which is sort of a registration that you yourself own this particular bag, right? Now, people could take snapshots of that handbag. They could sell those handbag pictures to other people. It doesn't preclude somebody else from sharing it. But legally, you own both the object and the rights or the certificate to it. Now, let's say that you've bought a digital collectible, like a super-rare baseball card or something that happens to be a digital versus a physical one, this is an asset. It's money at rest that you can hold that may accumulate value over time if somebody else wants to purchase it from you. ZOMORODI: And I guess it'll increase value. Like, let's say I post on my Instagram or my other social media and I'm like, look at this. This thing is cool. And lots of people are like, whoa, that digital baseball card is really beautiful. Lots of likes, lots of likes, lots of likes. So now if somebody else wants to buy it from me, the price goes up, potentially. WEBB: Right. Volatility is a piece of that story. And that's because this is a very emotionally driven area right now. People are throwing money at NFTs. They're throwing money at all different types of new, digital assets. And the values of these things are swinging wildly. (SOUNDBITE OF TED TALK)TEHRANIAN: Let's take an example, Nyan Cat, a wildly popular, instantly recognizable cat meme. Since it was uploaded to the internet a decade ago, it has accumulated hundreds of millions of views. And precisely because of that virality, when it was auctioned as an NFT, it sold for 300 eth - or the equivalent of over $600,000. And the person who now owns this NFT, they're not preventing anyone from liking, resharing or remixing Nyan Cat. Nyan Cat is free to travel the internet as it always has. What's different now is that as Nyan Cat's popularity continues to grow, so can the value of the NFT. ZOMORODI: So the example that we heard was about Nyan Cat. I mean, who cares, Amy? WEBB: (Laughter). ZOMORODI: I'm sorry. But, like, what is the point? Why do NFTs matter? WEBB: Well, I also don't care. But here - at least about the cat. ZOMORODI: (Laughter). WEBB: But we need to update our systems, you know, whether that's how artists get compensated for their work as their work scales, or how we shop for things and how we sell things. You know, a lot of our current systems were created in the days before the internet, before, with a simple click of a button, you could mint an infinite number of copies of things. And if you're an artist and your work is suddenly shared infinite ways, you know, that work loses value. So what we're talking about here is something called provenance. (SOUNDBITE OF MUSIC)WEBB: And that's being able to prove the origin of whatever it might be - whether it's a TED Talk or a digital copy of a fancy handbag - and making sure that the people who should be compensated are fairly compensated and that the records associated with whatever it is are also very clear and available, you know, to bring better transparency to the systems that we have. (SOUNDBITE OF TED TALK)TEHRANIAN: Because of NFTs, Chris Torres, Nyan Cat's creator, has received direct compensation for his creation. But what's more is he'll continue to receive compensation every single time the NFT is resold. This is because of the royalty system baked into the smart contracts that govern NFTs. NFTs are software. They can be programmed. And with something as complicated as royalties, which require enormous amounts of legal and manual labor to implement in our analog world, we can now express them in a few simple lines of code. This represents a breakthrough innovation for any industry predicated on royalty payments, such as publishing or music. And just as blogs and MP3s re-architected these industries in decades past, NFTs will catalyze their next evolution. The internet dissolved our geographic boundaries. NFTs dissolve economic boundaries. ZOMORODI: OK, so those are some big promises, especially for a technology that many people think is just a fad, maybe even a scam, a way to get rich. I mean, Amy, there is a lot of fraud out there when it comes to cryptocurrencies, blockchain projects. But there are also a lot of believers. Is that just how innovation works - you get the dark side with the early adopters? WEBB: So again, with everything, you know, this is the beginning of a transformation. And the trick here is to figure out what's trendy versus what's the trend, right? As a futurist, there are some rules that I use to sort of figure this out, and that represents a long-term movement into the future. You know, is an NFT meeting sort of basic human needs, and is this catalyzed by new technology? Yes, probably. Is it timely and going to persist over a long period of time? The NFT itself - probably not. But what it represents - and blockchain, that's probably here to stay. And finally, is this likely to evolve as it emerges? Because the long-term trends that matter tend not to be static. So, you know, we think about NFT and art and collectibles. That's trendy. The real trend is evolving from our current systems, from our current ways to authenticate people and the way that we're doing contracts, to more modern systems that represent the world as it is today. And that implies new types of authorities, new types of contracts, new types of authentication. It also probably means we're looking at a whole bunch of new types of cybercrime, right? Because any time you get a technology that's helpful, people find harmful uses for it. ZOMORODI: OK. So I think that brings me to my last question. A big part of your job, which you described earlier, is advising governments and corporations on the state of innovation. But, Amy, just remind us - like, why should we care about all this stuff? Why should we pay attention? Because it does sometimes feel like these topics - NFTs, blockchain, smart technology - they're kind of removed from our day-to-day lives. And some of them won't necessarily be ready for years to come, but I find it really exciting. So I'm just kind of curious about what you think. WEBB: The problem is that these are tricky subjects, and sometimes they really feel inaccessible. And I know that we all have - I'm a - you know, I think you and I are both very busy parents. The last thing I want to do at the end of a workday and dealing with homework and cooking dinner and everything else is, like - now I'm supposed to have any brainpower left to, like, talk about blockchain? Are you crazy? (LAUGHTER)WEBB: That is not what I want to do right now. I want to tuck in and, like - I want to go read a book or watch \"The Real Housewives. \"ZOMORODI: Yes. WEBB: For real, that's like - you know. But we can't close our eyes and sleep through this great awakening that's happening around us because we have fundamental technologies coming online that are going to reshape what the rest of humanity looks like. So I totally get it, but I also really care about our futures. And we all have a stake in it. ZOMORODI: That's Amy Webb. She's the founder and CEO of the Future Today Institute. Her new book is called \"The Genesis Machine: Our Quest To Rewrite Life In The Age Of Synthetic Biology. \" You can see her TED Talk and all the talks that we discussed at TED. com. Thank you so much for listening to our show today - A Glimpse Into the Future. To see hundreds more TED Talks, you can also check out the TED app. This episode was produced by Diba Mohtasham and Harrison Vijay Tsui. It was edited by Sanaz Meshkinpour. Our production staff at NPR also includes Jeff Rogers, James Delahoussaye, Rachel Faulkner, Katie Monteleone, Matthew Cloutier and Fiona Geiran. Our audio engineer is Brian Jarboe. Our intern is Katherine Sypher. Our theme music was written by Ramtin Arablouei. Our partners at TED are Chris Anderson, Colin Helms, Anna Phelan and Michelle Quint. I'm Manoush Zomorodi, and you've been listening to the TED Radio Hour from NPR. MANOUSH ZOMORODI, HOST:   It's the TED Radio Hour from NPR. I'm Manoush Zomorodi. (SOUNDBITE OF MUSIC) ZOMORODI: And ask anyone to predict the future these days, they will likely decline. (SOUNDBITE OF MONTAGE) ANTHONY FAUCI: You know, I'm not going to speculate on that. I want to see what happens right now. ANTHONY MASON: No one can forecast exactly how 2021 will unfold. ELON MUSK: Well, I think this is one of those things that's quite difficult to predict. FAUCI: We just can't predict that. We don't know. ZOMORODI: For many of us, the world feels erratic, volatile. Trying to guess what will happen next seems futile unless you're Amy Webb. AMY WEBB: I'm Amy Webb. I am the CEO of the Future Today Institute and a professor of strategic foresight at the NYU Stern School of Business. ZOMORODI: And, Amy, is it fair to say you're a futurist? WEBB: I am. I'm a quantitative futurist. ZOMORODI: Coolest job title, but can you explain what a quantitative futurist is? Do you see, like - I don't know - spreadsheets in your crystal ball? WEBB: So futurists do not make predictions. Instead, we collect signal data. We model those data, looking for patterns and try to anticipate many plausible futures. (SOUNDBITE OF MUSIC) ZOMORODI: Big corporations and governments use Amy's projections to prepare for all kinds of scenarios, including pandemics. WEBB: The type of work that we do results in very big bets, you know, sometimes involving billions or multiple billions of dollars that chief executives and their teams have to place. And we want to make sure that they're prepared. ZOMORODI: But Amy says her research into scientific innovation and technology trends, well, more just regular people need to know about them as well. WEBB: Manoush, like you, I'm a regular person, too. And. . . (SOUNDBITE OF MUSIC) WEBB: . . . Here's the plight of the regular person. The problem is that we're living through this great transformation. And every one of us who's living today, we're going to have to start making some really difficult choices that impact how we spend our time and what we want our kids to do and the people that we vote for. You know, these are going to be complex decisions. And the good news is that on the horizon, there's a lot of opportunity for, you know, personal growth, for economic growth. But that opportunity comes with some serious associated risks. ZOMORODI: So today on the show, Amy Webb talks us through four categories of innovation and explains how these inventions and ideas could upend the future of travel, wellness and what we value in the world. Amy has actually been on the show before talking about her memoir and TED Talk - both called \"Data, A Love Story\" - about how she hacked an online dating platform. But today, she is back to give us A Glimpse Into the Future. (SOUNDBITE OF MUSIC) ZOMORODI: OK. So Amy, you have generously agreed to return to the show. But we are going to do something completely different. You are going to guide us through a selection of TED Talks about some of the big trends in technology. But they're very specific innovations. And you're going to help us put these innovations into context, break down the hype from the real change that could stem from them, and help us understand the impact that they might have on the way that the internet and our lives work. So lots to talk about. WEBB: It'll be fun. ZOMORODI: And I want to start with a category that truly does affect us all, transportation. We can't teleport yet, Amy, but we still need to move our bodies from point A to point B. And this first speaker thinks that one way we will do that is with something called the hyperloop. Josh Giegel is the CEO and co-founder of the Virgin Hyperloop. His 2021 talk is called \"Super Speed, Magnetic Levitation And The Vision Behind The Hyperloop. \" And if you've never heard of the hyperloop - I had not - here is how he describes it. (SOUNDBITE OF TED TALK) JOSH GIEGEL: So hyperloop is a transit system that has a vehicle called a pod inside of a tube about the same size as a subway tunnel, where we suck most but not all of the air out of it - be the equivalent of flying at about 200,000 feet of altitude. This allows us to glide at airline speeds without turbulence for a fraction of the energy consumption - about one-tenth, to be precise, of an aircraft. And that's important because we, as humans, have an innate need for speed. But this obsession with speed and volume is destroying the planet around us. In fact, in the United States, the transportation industry is the single largest contributor to greenhouse gas emissions. A hyperloop system can begin to change this trend before the end of the decade by transforming short haul journeys and commutes from hours to minutes. ZOMORODI: OK. This sounds amazing. I'm levitating. I'm getting sucked through a kind of more efficient subway tunnel, essentially, but going as fast as a plane, using one-tenth of the energy that airline travel uses. Amy, tell us more about how it actually works. WEBB: Yeah. OK. So do you remember pneumatic tubes at banks? You put your money in that little canister thing. And then it gets sucked up and delivered to the teller on the inside of the building. So this is not entirely how hyperloop works. But, you know, it gives you at least a visual. ZOMORODI: Yeah. WEBB: So imagine being inside of a very comfortable pod, a closed container, that's capable of traveling, you know, at very, very fast speeds. So if you've ever been at the bank drive-through and you've seen what that tube looks like and how fast things are going, it's kind of the same thing. So we're talking about sort of a pod that is hovering inside of a vacuum tube. And using electric propulsion, it can accelerate gradually, pick up speed and then really take off. And the pods are able to glide along the track using magnetic levitation, which is actually already in use in some train systems, just in a different way around the world - so, like, maglev trains in Japan and China, for example. ZOMORODI: So is it kind of like a subway? Like, would there be stops along the way? What kind of travel or commute would the Hyperloop be best suited for? WEBB: Well, you know, a lot of these plans project speeds of between 700 and 800 miles an hour. ZOMORODI: Holy moly. WEBB: So that's pretty fast. So by the time you get one of these things up to speed, you know, you're not going to want to make a stop every couple of blocks. So instead, this would be more of an equivalent of a - like, a round trip between San Francisco and Los Angeles, which would normally take 12 hours on the road but being able to do it in just one hour. ZOMORODI: It's interesting to me that, like, what you're describing sounds really futuristic. But Josh Giegel says the idea of a hyperloop has actually been around for a while. (SOUNDBITE OF TED TALK) GIEGEL: And 118 years ago, before the Wright brothers' first flight, the thought of humans flying was inconceivable. It was crazy, even. Yet today, we get into a plane 30,000 feet above the ground and think nothing of it. A year after the Wright brothers' historic first flight, another inventor, an American physicist named Robert Goddard, proposed an entirely new form of transportation - the vactrain. He envisioned a high-speed mass transit system where people would travel on the ground, with little to no air resistance, inside of a tube. And today, these renderings of some of the earliest renderings what we call a hyperloop. ZOMORODI: (Laughter) The vactrain. OK, so we've been thinking about zipping our bodies around the Earth for decades. But I got to say, Amy, the newest mode of transport that I have taken recently is, like, a motorized scooter. Have we kind of been at a lull when it comes to innovating transportation? I'm not ready to sign up for Jeff Bezos's visit to the outer edge of the atmosphere. I just want to get places on the planet. And, you know, I feel like we've heard a lot about making all our cars electric, but that's not terribly futuristic. So where are we when it comes to innovating in transportation? WEBB: You know, historically, when we think about the future of transportation, we tend to think of things in the air, not things above the ground slightly or even under the ground. And, you know, we tend to reference \"The Jetsons. \" ZOMORODI: Right. WEBB: Now, when we think about transportation and the future, we tend to reference \"The Jetsons\" because of that scene with the flying car at the beginning, right? ZOMORODI: Right. Yes. WEBB: And, you know - and even if you haven't watched an episode of \"The Jetsons,\" if somebody says Jetsons car, everybody immediately knows what you mean. But here's what's interesting. It was 1917 when a guy named Glenn Curtiss filed a patent for an autoplane (ph), and it was a car with some wings attached to it. So it hopped in the air kind of a few times, and it never really, really flew. But every decade since then, there have been multiple flying car patents and actual flying cars that got designed. ZOMORODI: Wow. WEBB: So the question is, why are we stuck in this vicious cycle of the future of transportation being a thing we already have that happens to be up in the air that doesn't really solve any problems? ZOMORODI: And I - just to get back to the Hyperloop. The - not only have the plans been drawn up, but I was intrigued to hear that the - that they're testing it now with, like, real humans in it, including Josh Giegel himself. Its first ride with real passengers was in November of 2020, and here's him describing what happened. (SOUNDBITE OF TED TALK) GIEGEL: We've created a test track in the deserts outside of Las Vegas. We've operated the system over 500 times and had countless other tests on our subsystems. So by October of 2020, we had run hundreds of tests. We had an independent safety auditor give us the green light, but still, it was nerve-wracking. And on November 8, 2020, we made our first attempt. So at our test site, my colleague Sara and I climbed into that can-like vehicle, suspended by magnetic levitation, at a near-vacuum environment, and the countdown began. In those 15 seconds, we showed the world that what was deemed ludicrous over a hundred years ago was, in fact, possible. This is the start of a systemic change in the way we travel. ZOMORODI: So, Amy, you've watched the video. It's pretty fun to watch because it's Josh and a colleague, like, zipping around at whatever - 700 miles per hour with their cheeks, like, flapping in the wind. They look like they're on a roller coaster ride. Is this the start of a systemic change in the way we travel? I'm not so sure I want to travel like that. WEBB: (Laughter) Listen, I hope it is. I hope it's the start of systemic change. Why can't we be open to alternative options for the future? The real future of a hyperloop isn't necessarily people with their cheeks flapping in the wind, looking pretty uncomfortable, moving at speeds that are absolutely terrifying. This is the beginning, right? The very first plane that took flight, the very first car, the very first Sumerians who invented, millennia ago, a way to get around on a cart using horses - you know, these are technologies that - they evolve over longer periods of time. So I, for one, welcome our Hyperloop future, but it's going to take us some time to get there. (SOUNDBITE OF MUSIC) ZOMORODI: In a minute, more glimpses into the future with Amy Webb, including looking at a new kind of bra that could change health care for women. I'm Manoush Zomorodi, and you're listening to the TED Radio Hour from NPR. Stay with us. It's the TED Radio Hour from NPR. I'm Manoush Zomorodi. On the show today, A Glimpse Into the Future. We are talking to futurist Amy Webb about where science and technology are headed next, including some fascinating and unusual inventions from TED speakers. And one of the categories where Amy sees some of the most innovation is in health and wellness. WEBB: We're looking at sort of a vast constellation of things that range from devices that connect to our personal data - so that would be a smartwatch like a Fitbit or an Apple Watch - to the onslaught of wearable devices that are coming to market - smart glasses. ZOMORODI: Yeah. WEBB: You can buy a ring that has a digital assistant and a speaker and a microphone built in that you wear on your finger that let you know if you're getting enough oxygen, wristbands that detect your emotion, your stress, your exercise habits. There are smart yoga pants that you can wear that will reveal whether or not you're doing postures correctly during the poses. So it's just all of these different devices that are collecting our data, helping us understand ourselves better and, in some cases, connecting your body directly to your physician for remote patient monitoring. ZOMORODI: I mean, some of those sound really cool. The example that we have got in this health and wellness category is, again, an old technology updated for the digital age, something specifically for women. In 2021 engineer and entrepreneur Alicia Chong Rodriguez - she gave a talk about her invention, a smart bra for better heart health. And she started her talk by explaining that there is a big problem for women in health care right now because of the way that research is done. (SOUNDBITE OF TED TALK) ALICIA CHONG RODRIGUEZ: Heart disease and stroke are the leading causes of death and disability worldwide, and for women, it is not only harder to recognize, diagnose and treat. But after a heart attack or a stroke, women also face higher mortality. There are about 44 million women living in the U. S. with heart disease, and the incidences for women under 65 are on the rise. So what's going on? The answer lies at the intersection of two areas - data and medical devices. When I was doing cardiovascular research at MIT, I had access to huge datasets. Realizing that women were one of the largest subgroups underrepresented was eye-opening. In fact, women were basically excluded from cardiovascular clinical trials until the NIH mandated inclusion in 1993. This is why existing technologies and therapies often fall short - because most of them have been designed using data primarily from male animals and men. And as artificial intelligence helps turbocharge digital health, there's a danger that algorithms mostly trained with male data and biases will actually perpetuate the problem. ZOMORODI: Amy, hearing Alicia explain the huge gap that exists in data about women's health simply because their data was not being collected - also, that data sounds really old. I mean, I guess I shouldn't be surprised, but I was. What was your reaction? WEBB: Well, I'm not surprised. This TED talk really resonated with me because I do a lot of long distance bike riding on the weekends. And, you know, you can buy a heart rate monitor to track your heart rate and all the metrics that you would want to be tracking. And those monitors are best when they are attached to your chest and basically, like, pretty close to your heart. For those of you who are women who wear sports bras, you know that that is impractical. The way that sports bras are designed, the way that these chest monitors are designed - they're just - they don't work together very well. They're uncomfortable. They move around. You know, these are devices that are clearly designed for men by men. So this is a tiny, small example of a way that, as a woman, I'm being left out. And I'm somebody who desperately wants to and knows how to mine and refine my own data. There's a biometric data divide. ZOMORODI: And it's not just women, right? I mean, I've heard of dermatologists who say that a lot of the data being collected is only on white skin and not Black skin. And therefore, new treatments are biased in some ways because not only do they not know how they work; they don't know if they work on different kinds of skin. WEBB: That's absolutely correct. And the trick here is that as we ask artificial intelligence AI systems to play a greater role in pattern recognition and precision medicine and rapid drug discovery, unfortunately, we are making, in some cases, life and death decisions based on a very narrow dataset. And that's something that should concern everybody. ZOMORODI: So let's go back to Alicia. Her solution to one of the problems is collecting the right data with something she calls the smart bra. Here's how it works. (SOUNDBITE OF TED TALK) CHONG RODRIGUEZ: Our idea is to turn the everyday bra into an actual lifesaver. This is our augmented garment platform. It gives women the ability to continuously and remotely acquire physiological data. By wearing this bra, a woman can view insights and patterns and keep an automated journal in her phone, giving her a simple way to track symptoms and collect lifesaving data to share with her doctor for early detection and targeted management. It can even track the safety and efficacy of certain therapies. We've built medical-grade textile sensors that can adapt to multiple bra styles and sizes for continuous, reliable and repeatable data all around her torso and her heart. We can track heart rhythm, breathing, temperature, posture and movement. And by applying algorithms, we can use this data to decode symptoms, articulate arrhythmia triggers and generate personalized digital biomarkers. (SOUNDBITE OF MUSIC) ZOMORODI: What do you think of this, Amy? What do you think of her promise that this is an easy way to collect a lot of data on a personal level, but also a collective level - right? - that if you get enough women wearing these bras, then we can start to create new data sets and really understand what is happening for women and their cardiovascular health? WEBB: Well, obviously, if you have better sources of data to start and you're able to use those data, then you're going to get better outcomes on the other side. This is the beginning of a different path. And I think that's important because, you know, we're moving into an era where algorithms are making more and more decisions about us and, in fact, optimizing our health for us on a daily basis. And we want to make sure that we're optimizing for everybody, which means we need bigger pools of data. We need more opportunities for people to contribute data. And importantly, we need trust. Because without trust and faith in the systems that are collecting, housing and protecting these data, you know, then we create more problems down the road. ZOMORODI: Yeah. I mean, that concerns me. Like, well, you're collecting pretty intimate data here. What are you going to do with it? Who's in charge of it? All of those things. But on the flip side, if you tell me that by wearing this, I am contributing to an anonymized set of information that could maybe get more funding for research into how to treat cardiovascular problems for women, like that's intriguing to me. I'm excited by that. WEBB: Yeah. But again, this comes down to trust. I can give you a. . . ZOMORODI: Right. WEBB: . . . Quick example of what happens when you misplace or abuse trust. So there's. . . ZOMORODI: Yeah. WEBB: . . . A tribe that has lived in what is now Arizona for centuries, the Havasupai tribe. This tribe has had some issues with diabetes over time, and so they allowed researchers from Arizona State University in to conduct a study in 1990. And the idea was to collect health data, learn and eventually help the tribe eradicate diabetes. But then, unbeknownst to the tribe, the researchers changed the scope of their project to encompass a lot more data; so genetic markers for alcoholism, for different disorders like schizophrenia. And the researchers went on to publish a whole bunch of papers in academic journals highlighting these results. And the articles resulted in news stories. And the news stories really reflected badly on this tribe. They were completely, understandably, horrified and humiliated, which led to the Navajo Nation, which was the second - or, I guess, is the second largest group of indigenous people in the United States, to ban all genetic sequencing, all analysis; basically, all related research on its members. And that makes sense, right? Because nobody wants to be exploited in that way. But that caused this other problem, which is that the pool of genetic data in the U. S. doesn't really include indigenous people. And, you know, there are similar stories that I could tell you about America's Black population, you know, about various populations in the United States. And this all goes back to trust. So I think it's a good idea that we have more, better data, but we also have to do so in a way that is traceable and accountable, and we have to be good custodians of people's personal private data. ZOMORODI: Yeah. We need to remember that when we - remember why some people are vaccine hesitant. From what I understand, Alicia hopes to bring her smart bra to the market, like, pretty soon, actually. What are some other personal health devices that you think are going to be out there pretty soon? WEBB: Well, I got to tell you, the thing that I'm looking forward to is a toilet. ZOMORODI: (Laughter). WEBB: So this is, like, a weird turn that we're about to take, but. . . ZOMORODI: Do it, Amy. WEBB: . . . Do it. So, like, in the 2010s, there was some research at Stanford University on a device that you would have in your home. So this is a smart toilet, which was outfitted with litmus strips and some pressure sensors and things. And the idea was to be able to more effectively monitor patients in living facilities, in their homes. Now, there's actually a lot of very valuable data that you can retrieve that you, let's say, leave behind, right? ZOMORODI: (Laughter). WEBB: So with one brief trip to the bathroom, we can tell a lot about you, like whether you have prostate inflammation or your blood sugar level is high or whether, you know, you've got certain inflammation in your gut. And these data tell a story about your gut health and about your overall health. The problem is that we tend not to collect those data unless there is something wrong, when we show up at a doctor's office. Wouldn't it be awesome if we were able to collect those data every day? I mean, can you imagine knowing what your gut flora baseline is the way that you know what your normal temperature is? ZOMORODI: Oh, I'm in. WEBB: Yeah. That would be incredibly useful, actionable information. And then, interestingly enough, earlier this year, Toto, which is a Japanese company famous for making toilets, debuted its own wellness toilet. And this is a toilet outfitted with sensors, collection tools, you know, basically all the type of technology that you really don't want recognizing you in that particular place, you know what I mean? ZOMORODI: So not only would it be like, wow, I should eat more sauerkraut, but also could it potentially - like, I'm thinking of last - when the pandemic began and people started - there was a collection from sewer systems and they started to be able to tell, you know, from fecal matter where there was about to be a coronavirus outbreak. Is that another way that this could be sort of collectively? WEBB: Yeah, totally. I mean, you could pool - two things with the beginnings of the outbreak. You know, a lot of men, men of a certain age, they get a lot of prostate infections, and a prostate infection, in some ways, mirrors the symptoms of COVID-19. You get all-over body aches. You run a fever. You feel kind of achy, right? And I would imagine at the beginning of the crisis, there were probably a lot of men out there who were at the beginning stages of a prostate infection worrying that they had COVID and also probably without the ability to easily get into a doctor's office to take a test. So a smart toilet would have alleviated, you know, some of that challenge - right? - because you would have known, oh, I've got a prostate infection. My toilet is going to connect to my local pharmacy and shoot over a prescription for Cipro, right? And that'll be that. And yeah, if we were able to anonymize and pull those data in a way that protected privacy, then yeah, we would probably have been able to track pockets of outbreak. In the future, we'll be able to track pockets of poor nutrition or areas where diabetes is starting to spike, and you'll be able to do a lot on a micro-community level. ZOMORODI: OK. I want to switch gears now, and I want to talk about something in a realm that has largely been devoid of technological innovation. The next speaker gave a talk in 2021. Her name is Karoli Hindriks. She's an entrepreneur, and her talk is called Why The Passport Needs An Upgrade. Karoli thinks they are cumbersome, bureaucratic, essentially logistical nightmares for people who live in the global economy. And, you know, this is not a problem that she thinks is new. She started thinking about the issues that come with passports while she was growing up in Estonia under Soviet occupation. (SOUNDBITE OF TED TALK) KAROLI HINDRIKS: Having lived in that level of darkness made me wonder why are borders and movement between countries constructed the way they are? According to the World Economic Forum, human capital is the driving force for economic growth. So why are the barriers to global mobility so high? Why is the process so time-consuming, so dreadful and taunting, so very scary? And I know it's scary because I was detained at San Francisco Airport for two hours just to get on this stage. In 2020, the World Economic Forum reported that the top three countries where the highly educated migrants came from were India, China and Philippines, which, according to 2021 Henley Passport Index, ranked among the least travel-friendly passports in the world, ranking respectively 85th, 70th and 77th out of 110. The problem starts from what we call a passport. ZOMORODI: OK, so Karoli is wondering, why? If we need mobility to get human labor and capital to the places that need it, what is the point in making it so hard to do so? And the way that we currently track people is essentially based on nationality rather than the idea that people exist as part of an international, I guess, workforce is what she's saying. WEBB: Yeah, I mean, if you stop and think what is a passport really - right? - it's just a number that's tied to a database. And it represents us, I guess, in a way, but it doesn't do much more than that. And most of us now are global. You know, we work in different places. We move around to different places. And the value sometimes that we place on a person and therefore their ability to move around is very much hindered by wherever that passport came from. So she absolutely has a point. ZOMORODI: She gives another example of a highly skilled specialist from Yemen, a divorced single mother of two who's working for a Malaysian tech company. And the company wants to transfer her to their European office. But because she has a Yemeni passport, she has to fly thousands of miles back and forth multiple times, different embassies to get visas for her and her kids - I mean, clearly not good for her family, not good for the company, not good for the environment. So why does it continue to work this way if none of us like it? WEBB: Well, we tend to keep things in motion - right? - and we don't like to make huge or big changes. The passport was first introduced as a globally required travel document during World War I, just after Henry Ford introduced affordable automobiles. And today, our passports are still pretty much the same way that they were a century ago. I think there was a flaw in the way that the passport system was built. The modern passport system was designed by a Western-centric organization. ZOMORODI: Right. WEBB: And it became an object for people in Western countries, but it became a burden for others. ZOMORODI: When we come back, how Karoli wants to fix the passport problem and whether futurist Amy Webb thinks it will work. On the show today, A Glimpse Into the Future. I'm Manoush Zomorodi, and you're listening to the TED Radio Hour from NPR. We'll be right back. It's the TED Radio Hour from NPR. I'm Manoush Zomorodi. And on the show today, glimpses into the future. We are spending the hour with futurist Amy Webb, talking about innovations that could revolutionize how we live, interact and travel. Amy, we were just talking about how outmoded the paper passport is in a global economy. And we were hearing from entrepreneur Karoli Hindriks, who believes that digital passports are the answer. And she came to this by experience, by growing up in Estonia, a country which has put all of its citizens' information online. WEBB: Yeah. It's really difficult to overstate just what a quantum leap Estonia has made when it comes to digitalization. You know, from creating e-passports and electronic registry systems to even creating a system like a national registry for genetic data to make it easier to run experiments in a totally ethical way, you know, Estonia is just leaps and bounds ahead of most of the rest of the world when it comes to digitalization and creating decentralized systems that are fair and equitable and serve its citizens. Now, to be fair, Estonia is also a teeny, tiny country, very - you know, like, a few million people in north central Europe. So, you know, how that might scale in Western Europe or in a place like the United States is a little bit more complicated. But the story of Estonia and the story that she's telling is a fascinating example of an alternative future. (SOUNDBITE OF TED TALK) HINDRIKS: One of the keys to Estonia's success in digitalization was the focus to build one digital identity for each individual that allows public and private databases to link up and operate in harmony. Estonia is going to do everything online other than get married or divorced. The digitalization saves Estonia a stack of paper as high as the Eiffel Tower every month. On top of that, the digital signature alone enables Estonia to save 2% of its GDP every year. That's a whole lot of money being wasted because public sectors are not adapting to existing technologies. We can tackle that by creating a secure, universal digital identity where all the users need to do is upload their data and documents such as passport, marriage and education certificates into our smart system, which then converts that data into pieces that can be matched to relevant government forms in different countries. The beauty of it is the once-only rule. The user needs to add that data once, as it is then stored for the future use. ZOMORODI: So what she means by universal identity is that all of our important information would exist online in a single system not controlled by any one country and eliminating the current bureaucracy of travel and working in other countries. But, Amy, Karoli kind of skims over the technology that would be needed to make this even possible. She refers to it as a smart system. What is that? WEBB: Right. So she's talking about - and please stay with me as I say this - the blockchain. ZOMORODI: Oh, that word, right? WEBB: I know. I know. It's horrible, right? But here's what's important. We're talking about something akin to, like, a huge, public spreadsheet where anybody can write information to it. And it's authenticated, and it's accurate, and it's anonymous. So you don't know whose stuff is what. But it also can't be erased or modified. And here's why this matters - because she's talking about forums. But this is not just about forms. You know, the average person has I don't know how many passwords and documents. Manoush, when I got married, I legally changed my last name to my husband's last name. ZOMORODI: Oh. WEBB: And I cannot begin - like, some ladies who are listening here know the apocalyptic horror of what it's like before and after you change your name. It's like I had to carry around a marriage certificate with me for a year because of, you know, trying to get on planes and, you know, waiting for this, like, cascade of correct documentation to arrive. It was horrible. I'm still me, right? I've just adopted a different last name. So what she's talking about here is making this easier so that the set of credentials that is you - that they're stored in a place, and they can't be altered. But they can be authenticated and used by a trusted third party. We already have sort of parts of this in existence today in the form of, you know, a credit card or a bank account, things like that. What she's talking about here is something much more bigger. It's much more comprehensive. And it's part of the blockchain. . . ZOMORODI: Yeah, yeah. WEBB: . . . Like a smart contract. ZOMORODI: I mean, there are lots of things still being worked out with blockchain, like who governs it, who authenticates it. But the case that I keep thinking about is my vaccine card because right now I have this little slip of paper from Walgreens that says I've been vaccinated. And here in New York, we have an app on our phones that shows our vaccination status, but that only works here in New York City. I went to California, and they were like, cool. Can I see your piece of paper? WEBB: Yep. ZOMORODI: Anyone can fake a little piece of paper. This - in a global pandemic, don't we need a global way of tracking vaccinations? WEBB: So something like a centralized digital ID solves a lot of these problems. And I will tell you that because the work that we do, you know, there's a lot of governments that are in progress on building singular digital identities. And I think the challenge going forward is we're going to have competing systems, which, I think, presents some new types of problems. ZOMORODI: So we're coming in for the finish here. Most of the innovations that we've discussed so far are in testing or prototype form. They're not necessarily available to the average person. But the last thing we're going to talk about - and there are going to be people who groan when I say this. . . WEBB: (Laughter). ZOMORODI: . . . And other people who say, wait, what? It's NFTs. That stands for non-fungible tokens. And this is a digital way of buying ephemeral things like artwork. Any of us can use them. And one believer in this new technology is Kayvon Tehranian. He's a technologist and entrepreneur. And his talk is called \"How NFTs Are Building The Internet Of The Future. \" (SOUNDBITE OF TED TALK) KAYVON TEHRANIAN: We've uploaded trillions of photos and videos and even cat memes to the internet for free. And what business model has allowed this information to be free? Advertising. Advertising is the internet's default business model, not because that's what we want, but because that's what pays the bills. Right now, the few large corporations that run the most effective ad networks control most of the value on today's internet, not the people creating its content. On today's internet, we don't get paid for the work we do with our minds. And what's more, the content we upload to these services is trapped there. These services not only make money from our content, they control it - until NFTs. NFTs are a technological breakthrough. They offer us the opportunity to break away from that broken system. It's a certificate of ownership registered on the blockchain for everyone to see. It's not too dissimilar to the deed you get when you buy a house in the physical world. But instead of a house, an NFT denotes ownership of a file on the internet. ZOMORODI: OK. So let's say it again. NFTs stand for non-fungible tokens. Kayvon describes it like a deed to a house. But, I mean, is it really like a deed to a house? Amy, help me out. What is the right analogy here? And I think we need to use the word blockchain again. WEBB: (Laughter). ZOMORODI: Lord, help us. WEBB: All right. So non-fungible basically means that whatever it is is unique. You can't make another one, right? So a dollar bill is fungible because if you have one dollar bill, you could trade it in for another dollar bill and get the same value, unless there's extenuating circumstances like you've got an ultra-rare dollar bill or something. OK. Here's where this actually becomes practical. So if you've bought a super-expensive collectible item, like a fancy handbag, it comes with a certificate of authenticity. But there have been some problems with things that look real but aren't. Or paper certificates have a habit of getting lost. So let's say you get your physical, fancy handbag. But in addition to that, you also get a non-fungible token, which is sort of a registration that you yourself own this particular bag, right? Now, people could take snapshots of that handbag. They could sell those handbag pictures to other people. It doesn't preclude somebody else from sharing it. But legally, you own both the object and the rights or the certificate to it. Now, let's say that you've bought a digital collectible, like a super-rare baseball card or something that happens to be a digital versus a physical one, this is an asset. It's money at rest that you can hold that may accumulate value over time if somebody else wants to purchase it from you. ZOMORODI: And I guess it'll increase value. Like, let's say I post on my Instagram or my other social media and I'm like, look at this. This thing is cool. And lots of people are like, whoa, that digital baseball card is really beautiful. Lots of likes, lots of likes, lots of likes. So now if somebody else wants to buy it from me, the price goes up, potentially. WEBB: Right. Volatility is a piece of that story. And that's because this is a very emotionally driven area right now. People are throwing money at NFTs. They're throwing money at all different types of new, digital assets. And the values of these things are swinging wildly. (SOUNDBITE OF TED TALK) TEHRANIAN: Let's take an example, Nyan Cat, a wildly popular, instantly recognizable cat meme. Since it was uploaded to the internet a decade ago, it has accumulated hundreds of millions of views. And precisely because of that virality, when it was auctioned as an NFT, it sold for 300 eth - or the equivalent of over $600,000. And the person who now owns this NFT, they're not preventing anyone from liking, resharing or remixing Nyan Cat. Nyan Cat is free to travel the internet as it always has. What's different now is that as Nyan Cat's popularity continues to grow, so can the value of the NFT. ZOMORODI: So the example that we heard was about Nyan Cat. I mean, who cares, Amy? WEBB: (Laughter). ZOMORODI: I'm sorry. But, like, what is the point? Why do NFTs matter? WEBB: Well, I also don't care. But here - at least about the cat. ZOMORODI: (Laughter). WEBB: But we need to update our systems, you know, whether that's how artists get compensated for their work as their work scales, or how we shop for things and how we sell things. You know, a lot of our current systems were created in the days before the internet, before, with a simple click of a button, you could mint an infinite number of copies of things. And if you're an artist and your work is suddenly shared infinite ways, you know, that work loses value. So what we're talking about here is something called provenance. (SOUNDBITE OF MUSIC) WEBB: And that's being able to prove the origin of whatever it might be - whether it's a TED Talk or a digital copy of a fancy handbag - and making sure that the people who should be compensated are fairly compensated and that the records associated with whatever it is are also very clear and available, you know, to bring better transparency to the systems that we have. (SOUNDBITE OF TED TALK) TEHRANIAN: Because of NFTs, Chris Torres, Nyan Cat's creator, has received direct compensation for his creation. But what's more is he'll continue to receive compensation every single time the NFT is resold. This is because of the royalty system baked into the smart contracts that govern NFTs. NFTs are software. They can be programmed. And with something as complicated as royalties, which require enormous amounts of legal and manual labor to implement in our analog world, we can now express them in a few simple lines of code. This represents a breakthrough innovation for any industry predicated on royalty payments, such as publishing or music. And just as blogs and MP3s re-architected these industries in decades past, NFTs will catalyze their next evolution. The internet dissolved our geographic boundaries. NFTs dissolve economic boundaries. ZOMORODI: OK, so those are some big promises, especially for a technology that many people think is just a fad, maybe even a scam, a way to get rich. I mean, Amy, there is a lot of fraud out there when it comes to cryptocurrencies, blockchain projects. But there are also a lot of believers. Is that just how innovation works - you get the dark side with the early adopters? WEBB: So again, with everything, you know, this is the beginning of a transformation. And the trick here is to figure out what's trendy versus what's the trend, right? As a futurist, there are some rules that I use to sort of figure this out, and that represents a long-term movement into the future. You know, is an NFT meeting sort of basic human needs, and is this catalyzed by new technology? Yes, probably. Is it timely and going to persist over a long period of time? The NFT itself - probably not. But what it represents - and blockchain, that's probably here to stay. And finally, is this likely to evolve as it emerges? Because the long-term trends that matter tend not to be static. So, you know, we think about NFT and art and collectibles. That's trendy. The real trend is evolving from our current systems, from our current ways to authenticate people and the way that we're doing contracts, to more modern systems that represent the world as it is today. And that implies new types of authorities, new types of contracts, new types of authentication. It also probably means we're looking at a whole bunch of new types of cybercrime, right? Because any time you get a technology that's helpful, people find harmful uses for it. ZOMORODI: OK. So I think that brings me to my last question. A big part of your job, which you described earlier, is advising governments and corporations on the state of innovation. But, Amy, just remind us - like, why should we care about all this stuff? Why should we pay attention? Because it does sometimes feel like these topics - NFTs, blockchain, smart technology - they're kind of removed from our day-to-day lives. And some of them won't necessarily be ready for years to come, but I find it really exciting. So I'm just kind of curious about what you think. WEBB: The problem is that these are tricky subjects, and sometimes they really feel inaccessible. And I know that we all have - I'm a - you know, I think you and I are both very busy parents. The last thing I want to do at the end of a workday and dealing with homework and cooking dinner and everything else is, like - now I'm supposed to have any brainpower left to, like, talk about blockchain? Are you crazy? (LAUGHTER) WEBB: That is not what I want to do right now. I want to tuck in and, like - I want to go read a book or watch \"The Real Housewives. \" ZOMORODI: Yes. WEBB: For real, that's like - you know. But we can't close our eyes and sleep through this great awakening that's happening around us because we have fundamental technologies coming online that are going to reshape what the rest of humanity looks like. So I totally get it, but I also really care about our futures. And we all have a stake in it. ZOMORODI: That's Amy Webb. She's the founder and CEO of the Future Today Institute. Her new book is called \"The Genesis Machine: Our Quest To Rewrite Life In The Age Of Synthetic Biology. \" You can see her TED Talk and all the talks that we discussed at TED. com. Thank you so much for listening to our show today - A Glimpse Into the Future. To see hundreds more TED Talks, you can also check out the TED app. This episode was produced by Diba Mohtasham and Harrison Vijay Tsui. It was edited by Sanaz Meshkinpour. Our production staff at NPR also includes Jeff Rogers, James Delahoussaye, Rachel Faulkner, Katie Monteleone, Matthew Cloutier and Fiona Geiran. Our audio engineer is Brian Jarboe. Our intern is Katherine Sypher. Our theme music was written by Ramtin Arablouei. Our partners at TED are Chris Anderson, Colin Helms, Anna Phelan and Michelle Quint. I'm Manoush Zomorodi, and you've been listening to the TED Radio Hour from NPR.", "section": "TED Radio Hour", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-12-18-1064973064": {"title": "You might still have time to buy holiday gifts online and get same-day delivery : NPR", "url": "https://www.npr.org/2021/12/18/1064973064/you-might-still-have-time-to-buy-holiday-gifts-online-and-get-same-day-delivery", "author": "No author found", "published_date": "2021-12-18", "content": "", "section": "Business", "disclaimer": ""}, "2021-12-18-1064945778": {"title": "Top five video games of 2021 according to NPR staff : NPR", "url": "https://www.npr.org/2021/12/18/1064945778/top-five-video-games-2021", "author": "No author found", "published_date": "2021-12-18", "content": "AMART\u00cdNEZ, HOST:  While the game industry was hobbled by an ongoing pandemic, video games themselves provided fun and sanity in a year when both were in short supply. NPR surveyed staff and contributors for their favorite games of 2021. And the results are diverse - ranging from the cozy to the scary. NPR's James Mastromarino oversaw the final list, which you can read right now at npr. org. James, let's talk about some of the highlights. NPR staffers focused in on about 20 games in particular. But we're going to talk about the most nominated. And it all starts with It Takes Two. What was so special about this one? JAMES MASTROMARINO, BYLINE: Well, It Takes Two - just like the name would say, you can't play it alone. You have to have a real, human partner with you playing alongside - either online or right next to you. The story is just wild. You play a couple who wants to get a divorce. Their daughter is understandably distraught by this. She cries on some dolls, does some magic, accidentally transports you into the bodies of these dolls. And then you have to run through this crazy house full of fantastically imaginative levels to try to get back to normal. At one point, you're flying on fidget spinners over a sea of playpen balls, for example. (SOUNDBITE OF VIDEO GAME, IT TAKES TWO)ANNABELLE DOWLER: (As May) Woo-hoo. Wow, this is cool. JOSEPH BALDERRAMA: (As Cody) I told you they'd come in handy. DOWLER: (As May) I love them. BALDERRAMA: (As Cody) Spin, spin away, May. MASTROMARINO: This happens to be our most nominated game this year. It was hugely popular. It also won game of the year at the Game Awards. And I think this all tells you that people really wanted games that bring us together. Games that let you do that and gave you a common purpose to work towards - they were really special. MART\u00cdNEZ: All right. I also noticed there's a horror title from the long-running series on the top five - Resident Evil Village. Why do you think this is here? MASTROMARINO: Well, you know, there's always some catharsis in horror. And this series has been long-running. It started as, like, a zombie survival game. But it's really mutated in the decades since. And Resident Evil Village puts you in a snowy town, isolated somewhere in Europe. And before too long, you're trapped in the mansion of a nine-foot-tall vampire, Lady Dimitrescu. (SOUNDBITE OF VIDEO GAME, RESIDENT EVIL VILLAGE)MAGGIE ROBERTSON: (As Lady Dimitrescu) You escaped my little brother's idiot games, did you? Let's see how special you are. MASTROMARINO: Our reviewer, Louie Micheli, described Resident Evil Village as a perfect ease into this series. It's scary. It's goofy - an absolute thrill ride. And it's gorgeous to look at. MART\u00cdNEZ: You know what they always say, James. It takes a Resident Evil Village to entertain a gamer. At least, that's what I've heard. MASTROMARINO: (Laughter) That's right. MART\u00cdNEZ: All right. Now, finally, I see there is this other game - Life Is Strange: True Colors. It actually features some folks dressed just like everyday people. So what's going on with this one? MASTROMARINO: So we're coming down now. We're no longer in a gothic village. We're in Colorado - a small town. You play as Alex Chen, a young woman who moves there to reunite with her brother. And just as she's settling in, her brother dies in an accident, and she begins to investigate the mysterious circumstances surrounding that. Oh, and I should mention, she's got these empathic superpowers that manifest as colorful auras around the people she sees. (SOUNDBITE OF VIDEO GAME, LIFE IS STRANGE: TRUE COLORS)ERIKA MORI: (As Alex Chen) I know what other people are feeling. And if they feel strongly enough - if they're angry or sad or afraid - I feel it too. And then I lose control. MASTROMARINO: I'll let our contributor, Brittany Vincent, have the last word here. She said, from its gripping story to its realistic portrayals of trauma and human relationships, Life Is Strange: True Colors is a masterful exercise in storytelling that you'll not soon forget. And that can be said of a lot of games on this list. Many found playful ways to take difficult themes head-on. And I think we're only going to see more of this as games respond to the difficult years we've all been having, just as other media do. MART\u00cdNEZ: That's NPR's James Mastromarino. He surveyed NPR staff for their favorite video games of the year. And you can read more about them at npr. org. James, thanks. MASTROMARINO: Thank you. (SOUNDBITE OF ANGUS AND JULIA STONE SONG, \"TAKE ME HOME\") AMART\u00cdNEZ, HOST:   While the game industry was hobbled by an ongoing pandemic, video games themselves provided fun and sanity in a year when both were in short supply. NPR surveyed staff and contributors for their favorite games of 2021. And the results are diverse - ranging from the cozy to the scary. NPR's James Mastromarino oversaw the final list, which you can read right now at npr. org. James, let's talk about some of the highlights. NPR staffers focused in on about 20 games in particular. But we're going to talk about the most nominated. And it all starts with It Takes Two. What was so special about this one? JAMES MASTROMARINO, BYLINE: Well, It Takes Two - just like the name would say, you can't play it alone. You have to have a real, human partner with you playing alongside - either online or right next to you. The story is just wild. You play a couple who wants to get a divorce. Their daughter is understandably distraught by this. She cries on some dolls, does some magic, accidentally transports you into the bodies of these dolls. And then you have to run through this crazy house full of fantastically imaginative levels to try to get back to normal. At one point, you're flying on fidget spinners over a sea of playpen balls, for example. (SOUNDBITE OF VIDEO GAME, IT TAKES TWO) ANNABELLE DOWLER: (As May) Woo-hoo. Wow, this is cool. JOSEPH BALDERRAMA: (As Cody) I told you they'd come in handy. DOWLER: (As May) I love them. BALDERRAMA: (As Cody) Spin, spin away, May. MASTROMARINO: This happens to be our most nominated game this year. It was hugely popular. It also won game of the year at the Game Awards. And I think this all tells you that people really wanted games that bring us together. Games that let you do that and gave you a common purpose to work towards - they were really special. MART\u00cdNEZ: All right. I also noticed there's a horror title from the long-running series on the top five - Resident Evil Village. Why do you think this is here? MASTROMARINO: Well, you know, there's always some catharsis in horror. And this series has been long-running. It started as, like, a zombie survival game. But it's really mutated in the decades since. And Resident Evil Village puts you in a snowy town, isolated somewhere in Europe. And before too long, you're trapped in the mansion of a nine-foot-tall vampire, Lady Dimitrescu. (SOUNDBITE OF VIDEO GAME, RESIDENT EVIL VILLAGE) MAGGIE ROBERTSON: (As Lady Dimitrescu) You escaped my little brother's idiot games, did you? Let's see how special you are. MASTROMARINO: Our reviewer, Louie Micheli, described Resident Evil Village as a perfect ease into this series. It's scary. It's goofy - an absolute thrill ride. And it's gorgeous to look at. MART\u00cdNEZ: You know what they always say, James. It takes a Resident Evil Village to entertain a gamer. At least, that's what I've heard. MASTROMARINO: (Laughter) That's right. MART\u00cdNEZ: All right. Now, finally, I see there is this other game - Life Is Strange: True Colors. It actually features some folks dressed just like everyday people. So what's going on with this one? MASTROMARINO: So we're coming down now. We're no longer in a gothic village. We're in Colorado - a small town. You play as Alex Chen, a young woman who moves there to reunite with her brother. And just as she's settling in, her brother dies in an accident, and she begins to investigate the mysterious circumstances surrounding that. Oh, and I should mention, she's got these empathic superpowers that manifest as colorful auras around the people she sees. (SOUNDBITE OF VIDEO GAME, LIFE IS STRANGE: TRUE COLORS) ERIKA MORI: (As Alex Chen) I know what other people are feeling. And if they feel strongly enough - if they're angry or sad or afraid - I feel it too. And then I lose control. MASTROMARINO: I'll let our contributor, Brittany Vincent, have the last word here. She said, from its gripping story to its realistic portrayals of trauma and human relationships, Life Is Strange: True Colors is a masterful exercise in storytelling that you'll not soon forget. And that can be said of a lot of games on this list. Many found playful ways to take difficult themes head-on. And I think we're only going to see more of this as games respond to the difficult years we've all been having, just as other media do. MART\u00cdNEZ: That's NPR's James Mastromarino. He surveyed NPR staff for their favorite video games of the year. And you can read more about them at npr. org. James, thanks. MASTROMARINO: Thank you. (SOUNDBITE OF ANGUS AND JULIA STONE SONG, \"TAKE ME HOME\")", "section": "Gaming", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-12-19-1065413330": {"title": "Elizabeth Holmes' fraud case is now in jurors' hands : NPR", "url": "https://www.npr.org/2021/12/19/1065413330/jury-deliberations-elizabeth-holmes-fraud-trial", "author": "No author found", "published_date": "2021-12-19", "content": "", "section": "Technology", "disclaimer": ""}, "2021-12-21-1066240779": {"title": "Boeing, Airbus urge delay in 5G wireless service over aircraft safety concerns : NPR", "url": "https://www.npr.org/2021/12/21/1066240779/boeing-airbus-5g-wireless-delay-aircraft-safety-concerns", "author": "No author found", "published_date": "2021-12-21", "content": "", "section": "Technology", "disclaimer": ""}, "2021-12-21-1065210206": {"title": "Hallmark greeting cards and others add personal videos to the mix : NPR", "url": "https://www.npr.org/2021/12/21/1065210206/are-you-ready-for-your-close-up-hallmark-cards-now-come-with-video-greetings", "author": "No author found", "published_date": "2021-12-21", "content": "SCOTT DETROW, HOST:  It is the season for holiday greeting cards, but it's growing more and more likely that you will need a smartphone to read what's inside. Hallmark has a new card that lets the sender personalize it with video messages. The company is the latest to bank on group video greetings as more consumers get comfortable on camera. Shannon Mullen reports. SHANNON MULLEN, BYLINE: Hallmark is famous for saying things its customers can't. But with its new video greetings, the message comes straight from the sender - or senders. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED ACTORS: (As characters) Happy holidays from the Blacks (ph). MULLEN: To send one of these, you choose from a list of special occasions, then invite the people you want to submit videos. Once they do, Hallmark edits it all together with music and graphics. (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED ACTOR #1: (As character) Happy, happy birthday, baby girl. UNIDENTIFIED ACTOR #2: (As character) We wish that we were there. UNIDENTIFIED ACTOR #3: (As character) Happy birthday, sis. MULLEN: A digital version you can send by text or email costs $4. 99. For a buck more, a paper card arrives by mail with a link inside that the recipient can scan with a cellphone to watch the video. Either way, it expires in six months but can be downloaded for keeps. KRISTA MASILIONIS: It just makes for something that's unforgettable. MULLEN: Krista Masilionis is Hallmark's global innovation director. MASILIONIS: We've been around for 110 years. I want us to be around for another 110 more, so we've got to be there as the way people are connecting changes. And digital is how they're doing it. MULLEN: Hallmark is the biggest brand to start packaging group videos for a price. The greetings industry term is digital expressions, and a handful of smaller companies already sell them. One called Tribute claims it was the first, starting in 2015. Its montages range from $29 for a version you edit yourself to a full-service option for 100. CEO Andrew Horne says Tribute has sold 5 million and counting, 4 million of those just since the start of COVID-19. ANDREW HORN: There's been this absolute, you know, shift in consumer behavior over the past two years in the pandemic, where people are now, all of a sudden, comfortable, for better or worse, on video. MULLEN: Some more than others - Horn says 80% of the people his customers invite to make videos for these greetings put off doing them until the deadline or after. HORN: It does tend to take more effort. But now people are also starting to see that, like many things in life, some of the most rewarding things that we do are those that are challenging. And so people are embracing that challenge because they're seeing that the impact is actually profound and legitimate. MULLEN: As for seeing themselves on camera, much less sharing feelings, Horn says awkwardness can lead to more meaningful connections. BERNIE HOGAN: What's bad is when that is an inorganic process. MULLEN: That's Dr. Bernie Hogan, a sociologist and senior research fellow at Oxford University's Internet Institute. He worries with digital greetings, people might feel pressured to make the videos, and the final product might not reflect the time and effort they put into them. HOGAN: And so you come to resent these cards. And we don't (laughter) - you don't want a practice that leads to resentment. MULLEN: At the Emily Post Institute, author and etiquette expert Lizzie Post says the person buying the greeting should make it optional for contributors and take the pressure off. LIZZIE POST: Really encouraging people to not feel like they have to go over the top, to not even feel like they need to put on makeup or do their hair or something like that. And frankly, I think sometimes the ums and the ahs or the starts or the, like, squirrel moments that someone might have on camera - right? - are, like, actually so much more exactly who they are. MULLEN: Post warns, when recording videos, always assume they could go public, and don't rush. But, she adds from personal experience, doing too many takes can take the fun out. For NPR News, I'm Shannon Mullen. (SOUNDBITE OF SHIGETO'S \"A CHILD'S MIND\") SCOTT DETROW, HOST:   It is the season for holiday greeting cards, but it's growing more and more likely that you will need a smartphone to read what's inside. Hallmark has a new card that lets the sender personalize it with video messages. The company is the latest to bank on group video greetings as more consumers get comfortable on camera. Shannon Mullen reports. SHANNON MULLEN, BYLINE: Hallmark is famous for saying things its customers can't. But with its new video greetings, the message comes straight from the sender - or senders. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED ACTORS: (As characters) Happy holidays from the Blacks (ph). MULLEN: To send one of these, you choose from a list of special occasions, then invite the people you want to submit videos. Once they do, Hallmark edits it all together with music and graphics. (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED ACTOR #1: (As character) Happy, happy birthday, baby girl. UNIDENTIFIED ACTOR #2: (As character) We wish that we were there. UNIDENTIFIED ACTOR #3: (As character) Happy birthday, sis. MULLEN: A digital version you can send by text or email costs $4. 99. For a buck more, a paper card arrives by mail with a link inside that the recipient can scan with a cellphone to watch the video. Either way, it expires in six months but can be downloaded for keeps. KRISTA MASILIONIS: It just makes for something that's unforgettable. MULLEN: Krista Masilionis is Hallmark's global innovation director. MASILIONIS: We've been around for 110 years. I want us to be around for another 110 more, so we've got to be there as the way people are connecting changes. And digital is how they're doing it. MULLEN: Hallmark is the biggest brand to start packaging group videos for a price. The greetings industry term is digital expressions, and a handful of smaller companies already sell them. One called Tribute claims it was the first, starting in 2015. Its montages range from $29 for a version you edit yourself to a full-service option for 100. CEO Andrew Horne says Tribute has sold 5 million and counting, 4 million of those just since the start of COVID-19. ANDREW HORN: There's been this absolute, you know, shift in consumer behavior over the past two years in the pandemic, where people are now, all of a sudden, comfortable, for better or worse, on video. MULLEN: Some more than others - Horn says 80% of the people his customers invite to make videos for these greetings put off doing them until the deadline or after. HORN: It does tend to take more effort. But now people are also starting to see that, like many things in life, some of the most rewarding things that we do are those that are challenging. And so people are embracing that challenge because they're seeing that the impact is actually profound and legitimate. MULLEN: As for seeing themselves on camera, much less sharing feelings, Horn says awkwardness can lead to more meaningful connections. BERNIE HOGAN: What's bad is when that is an inorganic process. MULLEN: That's Dr. Bernie Hogan, a sociologist and senior research fellow at Oxford University's Internet Institute. He worries with digital greetings, people might feel pressured to make the videos, and the final product might not reflect the time and effort they put into them. HOGAN: And so you come to resent these cards. And we don't (laughter) - you don't want a practice that leads to resentment. MULLEN: At the Emily Post Institute, author and etiquette expert Lizzie Post says the person buying the greeting should make it optional for contributors and take the pressure off. LIZZIE POST: Really encouraging people to not feel like they have to go over the top, to not even feel like they need to put on makeup or do their hair or something like that. And frankly, I think sometimes the ums and the ahs or the starts or the, like, squirrel moments that someone might have on camera - right? - are, like, actually so much more exactly who they are. MULLEN: Post warns, when recording videos, always assume they could go public, and don't rush. But, she adds from personal experience, doing too many takes can take the fun out. For NPR News, I'm Shannon Mullen. (SOUNDBITE OF SHIGETO'S \"A CHILD'S MIND\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-12-22-1066710272": {"title": "Tesla is under investigation over the potential for drivers to play video games : NPR", "url": "https://www.npr.org/2021/12/22/1066710272/tesla-video-games-investigation", "author": "No author found", "published_date": "2021-12-22", "content": "", "section": "Business", "disclaimer": ""}, "2021-12-22-1064598337": {"title": "Why self-driving cars still require a lot of human supervision : NPR", "url": "https://www.npr.org/2021/12/22/1064598337/cars-are-getting-better-at-driving-themselves-but-you-still-cant-sit-back-and-na", "author": "No author found", "published_date": "2021-12-22", "content": "A MARTINEZ, HOST:  Automakers are pouring billions of dollars into self-driving technology. Driverless taxis and trucks are already being tested. So how far away are we from being able to own a self-driving car? NPR's Camila Domonoske takes us on a ride to find out. CAMILA DOMONOSKE, BYLINE: A few weeks ago, my family settled in for a long drive down the Pennsylvania Turnpike. UNIDENTIFIED CHILD: I don't want to take a nap. DOMONOSKE: You don't have to take a nap. You can just look out the window and think about things. In fact, my toddler did take a nap. And as he did, I took my foot off the gas pedal and my hands off the steering wheel. I was borrowing an Escalade with GM's latest Super Cruise technology. All right. The steering wheel has a green light on top, and my hands are off. It's the road trip dream, right? Kids sleeping, traffic moving, computer handling the driving. OK - back to reality. UNIDENTIFIED CHILD: (Crying). DOMONOSKE: The kid woke up. Oh - Super Cruise disengaging. Take vehicle control. And the computer needed help. In construction zones or sometimes for no reason at all, the steering wheel would flash red. And all of a sudden, I would need to be driving again. Whether or not my kid was napping, there was no way that I could take a nap. In fact, the Escalade had a camera by the steering wheel, and Super Cruise would only work if my eyes stayed on the road. Ron Arnesen runs GM's automated driving programs. He says that's an essential safety feature. RON ARNESEN: Because if you're always paying attention, you can take over within a matter of, you know, a split second if you needed to. DOMONOSKE: And at some point, you'll definitely need to take over. This is true for every high-tech vehicle sold today, even Tesla, which has heavily promoted the dream of a truly autonomous vehicle. Victoria Scruggs is testing out Tesla's full self-driving software. The name is misleading. She keeps her hands on the wheel and eyes on the road. VICTORIA SCRUGGS: And I like to keep my foot, like, hovering in-between the gas and the brakes. You really don't know what it's going to do sometimes. DOMONOSKE: Scruggs took me for a spin around ordinary city streets, and the car did some inexplicable things, like suddenly scoot very close to the vehicle in front of us at a stoplight. SCRUGGS: Oh. Ooh. Well, that was a little scary. DOMONOSKE: Even simple right turns can confuse the software. Scruggs says the car can manage itself really well on highways, and it's pretty good at going in a straight line. SCRUGGS: But when you throw turns in the mix, it's a little bit iffy. DOMONOSKE: Tesla has come under scrutiny for deploying this software on public streets. And its more limited Autopilot technology has been involved in deadly crashes, including when it didn't seem to notice a parked emergency vehicle. The key point is that no vehicles for sale today are a hundred percent self-driving. But a lot of them can do some driving, and it's not just cutting-edge Escalades and Teslas. Kelly Funkhouser is with Consumer Reports, and she says about half of new models can control speed and steering and freeway situations. And they're pretty good at that. KELLY FUNKHOUSER: A lot of the systems out there do very, very well at essentially driving. DOMONOSKE: And these systems can make driving a lot easier. But we can't rely on them 100% of the time, which means they need constant supervision. And Funkhouser says that's hard. FUNKHOUSER: When an already boring task like driving becomes even more boring, you know, it's human nature, really, to just kind of want to zone out and find something exciting to do other than watch the car drive. It's just like watching paint dry, right? DOMONOSKE: The smarter our cars get, the more tempting it'll be to let our minds wander. But it's a dangerous temptation because, for now, the responsibility for driving safely is still firmly in human hands. Camila Domonoske, NPR News. A MARTINEZ, HOST:   Automakers are pouring billions of dollars into self-driving technology. Driverless taxis and trucks are already being tested. So how far away are we from being able to own a self-driving car? NPR's Camila Domonoske takes us on a ride to find out. CAMILA DOMONOSKE, BYLINE: A few weeks ago, my family settled in for a long drive down the Pennsylvania Turnpike. UNIDENTIFIED CHILD: I don't want to take a nap. DOMONOSKE: You don't have to take a nap. You can just look out the window and think about things. In fact, my toddler did take a nap. And as he did, I took my foot off the gas pedal and my hands off the steering wheel. I was borrowing an Escalade with GM's latest Super Cruise technology. All right. The steering wheel has a green light on top, and my hands are off. It's the road trip dream, right? Kids sleeping, traffic moving, computer handling the driving. OK - back to reality. UNIDENTIFIED CHILD: (Crying). DOMONOSKE: The kid woke up. Oh - Super Cruise disengaging. Take vehicle control. And the computer needed help. In construction zones or sometimes for no reason at all, the steering wheel would flash red. And all of a sudden, I would need to be driving again. Whether or not my kid was napping, there was no way that I could take a nap. In fact, the Escalade had a camera by the steering wheel, and Super Cruise would only work if my eyes stayed on the road. Ron Arnesen runs GM's automated driving programs. He says that's an essential safety feature. RON ARNESEN: Because if you're always paying attention, you can take over within a matter of, you know, a split second if you needed to. DOMONOSKE: And at some point, you'll definitely need to take over. This is true for every high-tech vehicle sold today, even Tesla, which has heavily promoted the dream of a truly autonomous vehicle. Victoria Scruggs is testing out Tesla's full self-driving software. The name is misleading. She keeps her hands on the wheel and eyes on the road. VICTORIA SCRUGGS: And I like to keep my foot, like, hovering in-between the gas and the brakes. You really don't know what it's going to do sometimes. DOMONOSKE: Scruggs took me for a spin around ordinary city streets, and the car did some inexplicable things, like suddenly scoot very close to the vehicle in front of us at a stoplight. SCRUGGS: Oh. Ooh. Well, that was a little scary. DOMONOSKE: Even simple right turns can confuse the software. Scruggs says the car can manage itself really well on highways, and it's pretty good at going in a straight line. SCRUGGS: But when you throw turns in the mix, it's a little bit iffy. DOMONOSKE: Tesla has come under scrutiny for deploying this software on public streets. And its more limited Autopilot technology has been involved in deadly crashes, including when it didn't seem to notice a parked emergency vehicle. The key point is that no vehicles for sale today are a hundred percent self-driving. But a lot of them can do some driving, and it's not just cutting-edge Escalades and Teslas. Kelly Funkhouser is with Consumer Reports, and she says about half of new models can control speed and steering and freeway situations. And they're pretty good at that. KELLY FUNKHOUSER: A lot of the systems out there do very, very well at essentially driving. DOMONOSKE: And these systems can make driving a lot easier. But we can't rely on them 100% of the time, which means they need constant supervision. And Funkhouser says that's hard. FUNKHOUSER: When an already boring task like driving becomes even more boring, you know, it's human nature, really, to just kind of want to zone out and find something exciting to do other than watch the car drive. It's just like watching paint dry, right? DOMONOSKE: The smarter our cars get, the more tempting it'll be to let our minds wander. But it's a dangerous temptation because, for now, the responsibility for driving safely is still firmly in human hands. Camila Domonoske, NPR News.", "section": "Business", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-12-24-1067902504": {"title": "Tesla disables video games on center touch screens in moving cars : NPR", "url": "https://www.npr.org/2021/12/24/1067902504/tesla-disables-video-games-on-center-touch-screens-in-moving-cars", "author": "No author found", "published_date": "2021-12-24", "content": "", "section": "Business", "disclaimer": ""}, "2021-12-24-1063057224": {"title": "4 of the biggest archeological finds of 2021 \u2014 including a 'game changer' : NPR", "url": "https://www.npr.org/2021/12/24/1063057224/archeology-science-discovery-2021-dna-mammoth", "author": "No author found", "published_date": "2021-12-24", "content": "", "section": "Science", "disclaimer": ""}, "2021-12-26-1068063564": {"title": "TikTok is driving book sales. Here are the titles #BookTok recommends : NPR", "url": "https://www.npr.org/2021/12/26/1068063564/booktok-is-a-new-force-driving-book-sales-and-publishing-deals", "author": "No author found", "published_date": "2021-12-26", "content": "EYDER PERALTA, HOST:  People are buying a lot more books these days. That's partly because the pandemic trapped everyone indoors with little to do. But there's another reason. The social media site TikTok, where users download short videos they create themselves, has become a big power among younger readers. Jim Zarroli reports. JIM ZARROLI, BYLINE: The novel \"It Ends With Us\" came out in 2016. It sold well for a while. Then late last year, something weird happened, says the author Colleen Hoover. The book shot to the top of the New York Times bestseller list. COLLEEN HOOVER: You know, at first, I didn't really know what was going on. And even my publishers were going, why are we seeing an uptick in sales? ZARROLI: Hoover soon discovered that a lot of young readers were talking about the book on TikTok using the hashtag #BookTok. That's B-O-O-K-T-O-K. HOOVER: You know, my life is very normal. It's very much the same as it's always been. But then when I log on to the internet, I'm like, what is going on? Who are these people that are sending me these messages? And yeah, it's been insane. ZARROLI: It's hard to quantify how big BookTok is because TikTok doesn't release a lot of numbers, but publishers say it has become a major driver of sales, especially in the market for young adult and contemporary romance books. Scroll through the app, and you find countless videos from people talking about their favorite books. (SOUNDBITE OF TIKTOK VIDEO)UNIDENTIFIED PERSON #1: It's so good - friends to lovers, slow burn. I will die for this book. I will die defending it. ZARROLI: BookTok fans are mostly young and female, and they are ardent readers. (SOUNDBITE OF TIKTOK VIDEO)UNIDENTIFIED PERSON #2: If you know me at all, you know that this book has my heart. ZARROLI: The BookTok crowd likes books that are passionate and emotional, and they expect a good cry. (SOUNDBITE OF TIKTOK VIDEO)UNIDENTIFIED PERSON #3: I loved this book, and I think it is so beautiful. Definitely worth a read, but I didn't cry at all. And everybody said I would sob, and I didn't. ZARROLI: So this isn't exactly the New York Review of Books. Allison Derose posts videos using the #BookTok hashtag. She says some of the most popular BookTok titles are the kind that some people look down upon, like contemporary romance novels. But she says that's OK. ALLISON DEROSE: There's kind of, like, a comfort in BookTok that, like, we're all reading the same things. We're all enjoying it. And there's so many people. You know, a video has a million views, hundreds of thousands of likes, lots of engagement. Like, there are people out there who also like reading these books. ZARROLI: Not surprisingly, book publishers are more than a little excited about BookTok. Libby McGuire, who heads Simon and Schuster's Atria division, says the book business has always depended heavily on reader recommendations - someone who loves a book and tells friends about it. BookTok can turbocharge that process. LIBBY MCGUIRE: It just warms my heart as a book publisher, you know, because that's what we always strive for is that word-of-mouth. And we know that that's what takes a book from one level to the stratosphere. ZARROLI: And BookTok has come along at a time when the pandemic has closed off many of the traditional ways of reaching readers like book signings, says publishing executive Nellie Kurtzman. NELLIE KURTZMAN: There are a lot of book festivals where, you know, fans would gather and just celebrate reading. And now they - not being able to do that, at least they're able to do it virtually. ZARROLI: Kurtzman is vice president at HarperCollins, which published the surprise BookTok bestseller \"They Both Die At The End\" by Adam Silvera. Big publishers have even started reaching out to the most popular video creators, offering them free books or paying them to recommend titles. Bestselling author Chloe Gong produces a lot of her own BookTok videos about her life and her work, but she doesn't think these videos increase her sales much. CHLOE GONG: A lot of the reason why book sales are moving so fast on TikTok is not because of the authors themselves. It's because the readers are so passionate. ZARROLI: Gong says some books just appeal to readers organically, and that kind of connection can't really be manufactured. But BookTok is a reminder of just how powerful that connection can be. For NPR News, I'm Jim Zarroli in New York. (SOUNDBITE OF DOJA CAT SONG, \"STREETS\") EYDER PERALTA, HOST:   People are buying a lot more books these days. That's partly because the pandemic trapped everyone indoors with little to do. But there's another reason. The social media site TikTok, where users download short videos they create themselves, has become a big power among younger readers. Jim Zarroli reports. JIM ZARROLI, BYLINE: The novel \"It Ends With Us\" came out in 2016. It sold well for a while. Then late last year, something weird happened, says the author Colleen Hoover. The book shot to the top of the New York Times bestseller list. COLLEEN HOOVER: You know, at first, I didn't really know what was going on. And even my publishers were going, why are we seeing an uptick in sales? ZARROLI: Hoover soon discovered that a lot of young readers were talking about the book on TikTok using the hashtag #BookTok. That's B-O-O-K-T-O-K. HOOVER: You know, my life is very normal. It's very much the same as it's always been. But then when I log on to the internet, I'm like, what is going on? Who are these people that are sending me these messages? And yeah, it's been insane. ZARROLI: It's hard to quantify how big BookTok is because TikTok doesn't release a lot of numbers, but publishers say it has become a major driver of sales, especially in the market for young adult and contemporary romance books. Scroll through the app, and you find countless videos from people talking about their favorite books. (SOUNDBITE OF TIKTOK VIDEO) UNIDENTIFIED PERSON #1: It's so good - friends to lovers, slow burn. I will die for this book. I will die defending it. ZARROLI: BookTok fans are mostly young and female, and they are ardent readers. (SOUNDBITE OF TIKTOK VIDEO) UNIDENTIFIED PERSON #2: If you know me at all, you know that this book has my heart. ZARROLI: The BookTok crowd likes books that are passionate and emotional, and they expect a good cry. (SOUNDBITE OF TIKTOK VIDEO) UNIDENTIFIED PERSON #3: I loved this book, and I think it is so beautiful. Definitely worth a read, but I didn't cry at all. And everybody said I would sob, and I didn't. ZARROLI: So this isn't exactly the New York Review of Books. Allison Derose posts videos using the #BookTok hashtag. She says some of the most popular BookTok titles are the kind that some people look down upon, like contemporary romance novels. But she says that's OK. ALLISON DEROSE: There's kind of, like, a comfort in BookTok that, like, we're all reading the same things. We're all enjoying it. And there's so many people. You know, a video has a million views, hundreds of thousands of likes, lots of engagement. Like, there are people out there who also like reading these books. ZARROLI: Not surprisingly, book publishers are more than a little excited about BookTok. Libby McGuire, who heads Simon and Schuster's Atria division, says the book business has always depended heavily on reader recommendations - someone who loves a book and tells friends about it. BookTok can turbocharge that process. LIBBY MCGUIRE: It just warms my heart as a book publisher, you know, because that's what we always strive for is that word-of-mouth. And we know that that's what takes a book from one level to the stratosphere. ZARROLI: And BookTok has come along at a time when the pandemic has closed off many of the traditional ways of reaching readers like book signings, says publishing executive Nellie Kurtzman. NELLIE KURTZMAN: There are a lot of book festivals where, you know, fans would gather and just celebrate reading. And now they - not being able to do that, at least they're able to do it virtually. ZARROLI: Kurtzman is vice president at HarperCollins, which published the surprise BookTok bestseller \"They Both Die At The End\" by Adam Silvera. Big publishers have even started reaching out to the most popular video creators, offering them free books or paying them to recommend titles. Bestselling author Chloe Gong produces a lot of her own BookTok videos about her life and her work, but she doesn't think these videos increase her sales much. CHLOE GONG: A lot of the reason why book sales are moving so fast on TikTok is not because of the authors themselves. It's because the readers are so passionate. ZARROLI: Gong says some books just appeal to readers organically, and that kind of connection can't really be manufactured. But BookTok is a reminder of just how powerful that connection can be. For NPR News, I'm Jim Zarroli in New York. (SOUNDBITE OF DOJA CAT SONG, \"STREETS\")", "section": "Book News & Features", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-12-27-1067012922": {"title": "This Instagram account crowdsources vintage children's books  : NPR", "url": "https://www.npr.org/2021/12/27/1067012922/instagram-vintage-childrens-books-crowdsourcing", "author": "No author found", "published_date": "2021-12-27", "content": "", "section": "Books", "disclaimer": ""}, "2021-12-28-1068610154": {"title": "Companies are working on technology to get cars to detect and prevent drunk driving : NPR", "url": "https://www.npr.org/2021/12/28/1068610154/companies-are-working-on-technology-to-get-cars-to-detect-and-prevent-drunk-driv", "author": "No author found", "published_date": "2021-12-28", "content": "ARI SHAPIRO, HOST:  What if cars could stop people from driving drunk? In fact, a new federal law requires just that, starting about five years from now. Some companies have already been figuring out how to do it. NPR's Camila Domonoske takes a look. CAMILA DOMONOSKE, BYLINE: There are a few different ways that cars could detect drunk driving. They're all still works in progress. One group of researchers supported by both the auto industry and the government have been working on a supersensitive kind of breathalyzer. FERHAT DJOUADI: How you doing? DOMONOSKE: Hi - doing great. How are you? At a press event in Richmond, Va. , mechanical engineer Ferhat Djouadi slips behind the wheel of a Chevy Malibu to demonstrate. It's 10 a. m. on a Wednesday, and everyone here is sober, so he sprays some Listerine in his mouth to trick the sensors. (SOUNDBITE OF BOTTLE SPRITZING)DOMONOSKE: It's got a lot of alcohol in it. He says the words to activate the system. . . DJOUADI: I am driven to protect. Verify me. DOMONOSKE: . . . And blows a puff of air in the general direction of the dashboard. DJOUADI: I like to refer to it as a candle blow - you know, just kind of a (exhaling). DOMONOSKE: Eventually, engineers want to make the sensors good enough to sample regular breaths. But for now, Djouadi still has to puff. When the car catches a whiff of that mouthwash. . . AUTOMATED VOICE: Warning - alcohol detected. Use alternate safe ride. Car not started. DOMONOSKE: This tech is being tested in trucks right now. The same team also has a prototype of a touch-based system. It would shine a light into a driver's finger, maybe while they're touching an ignition button, and measure the alcohol content of their blood. Or there's also a totally different approach that might work using cameras that some vehicles already have. Sam Abuelsamid is an analyst with Guidehouse Insights. SAM ABUELSAMID: They consist of a small camera that's typically mounted on the steering column that's looking at the driver, and they use infrared so that it can see in the dark. If you're driving at night or if you're wearing sunglasses, it can still see your eyes. DOMONOSKE: These cameras make sure that drivers are watching the road, but they could look for other things. LAVONDA BROWN: Your eyes - they show it all. It's just a matter of knowing how to look for it. DOMONOSKE: LaVonda Brown's Ph. D. research used computers to watch people's eyes to see where their attention was focused. But then she was in a relationship with someone with a drinking problem, and she realized his eyes told her a lot more than just where he was looking. Some of those signs can be measured. A drunk person's eyes get glossy. Their pupils respond differently to light. And think of a police officer asking a driver to follow a pencil with their eyes. BROWN: They're looking for this involuntary twitching that happens in the corner. Depending on how fast that happens, how far from the center that happens, that also tells us what you're under the influence of and by how much. DOMONOSKE: Eventually, Brown founded a company called EyeGage. It's gathering data to build software that considers all these signs and detects intoxication just from looking at eyes. All of these tools are still being refined. Regulators will have years to figure out what exactly should be required in vehicles, and there will likely be some pushback. The ACLU has already raised privacy concerns. But whatever the ultimate approach is, safety advocates are very excited. DAVID HARKEY: I actually think this particular technology could save more lives than airbags. DOMONOSKE: David Harkey is the president of the Insurance Institute for Highway Safety. HARKEY: We're talking about more than 10,000 people that are losing their lives annually. DOMONOSKE: So several years from now, if all new cars can detect drunk driving, Harkey says it will save a lot of lives. Camila Domonoske, NPR News. (SOUNDBITE OF TSHA'S \"SACRED\") ARI SHAPIRO, HOST:   What if cars could stop people from driving drunk? In fact, a new federal law requires just that, starting about five years from now. Some companies have already been figuring out how to do it. NPR's Camila Domonoske takes a look. CAMILA DOMONOSKE, BYLINE: There are a few different ways that cars could detect drunk driving. They're all still works in progress. One group of researchers supported by both the auto industry and the government have been working on a supersensitive kind of breathalyzer. FERHAT DJOUADI: How you doing? DOMONOSKE: Hi - doing great. How are you? At a press event in Richmond, Va. , mechanical engineer Ferhat Djouadi slips behind the wheel of a Chevy Malibu to demonstrate. It's 10 a. m. on a Wednesday, and everyone here is sober, so he sprays some Listerine in his mouth to trick the sensors. (SOUNDBITE OF BOTTLE SPRITZING) DOMONOSKE: It's got a lot of alcohol in it. He says the words to activate the system. . . DJOUADI: I am driven to protect. Verify me. DOMONOSKE: . . . And blows a puff of air in the general direction of the dashboard. DJOUADI: I like to refer to it as a candle blow - you know, just kind of a (exhaling). DOMONOSKE: Eventually, engineers want to make the sensors good enough to sample regular breaths. But for now, Djouadi still has to puff. When the car catches a whiff of that mouthwash. . . AUTOMATED VOICE: Warning - alcohol detected. Use alternate safe ride. Car not started. DOMONOSKE: This tech is being tested in trucks right now. The same team also has a prototype of a touch-based system. It would shine a light into a driver's finger, maybe while they're touching an ignition button, and measure the alcohol content of their blood. Or there's also a totally different approach that might work using cameras that some vehicles already have. Sam Abuelsamid is an analyst with Guidehouse Insights. SAM ABUELSAMID: They consist of a small camera that's typically mounted on the steering column that's looking at the driver, and they use infrared so that it can see in the dark. If you're driving at night or if you're wearing sunglasses, it can still see your eyes. DOMONOSKE: These cameras make sure that drivers are watching the road, but they could look for other things. LAVONDA BROWN: Your eyes - they show it all. It's just a matter of knowing how to look for it. DOMONOSKE: LaVonda Brown's Ph. D. research used computers to watch people's eyes to see where their attention was focused. But then she was in a relationship with someone with a drinking problem, and she realized his eyes told her a lot more than just where he was looking. Some of those signs can be measured. A drunk person's eyes get glossy. Their pupils respond differently to light. And think of a police officer asking a driver to follow a pencil with their eyes. BROWN: They're looking for this involuntary twitching that happens in the corner. Depending on how fast that happens, how far from the center that happens, that also tells us what you're under the influence of and by how much. DOMONOSKE: Eventually, Brown founded a company called EyeGage. It's gathering data to build software that considers all these signs and detects intoxication just from looking at eyes. All of these tools are still being refined. Regulators will have years to figure out what exactly should be required in vehicles, and there will likely be some pushback. The ACLU has already raised privacy concerns. But whatever the ultimate approach is, safety advocates are very excited. DAVID HARKEY: I actually think this particular technology could save more lives than airbags. DOMONOSKE: David Harkey is the president of the Insurance Institute for Highway Safety. HARKEY: We're talking about more than 10,000 people that are losing their lives annually. DOMONOSKE: So several years from now, if all new cars can detect drunk driving, Harkey says it will save a lot of lives. Camila Domonoske, NPR News. (SOUNDBITE OF TSHA'S \"SACRED\")", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-12-28-1068587803": {"title": "What's on the social media horizon in the year ahead : NPR", "url": "https://www.npr.org/2021/12/28/1068587803/what-s-on-the-social-media-horizon-in-the-year-ahead", "author": "No author found", "published_date": "2021-12-28", "content": "ARI SHAPIRO, HOST:  Social media companies are in for a tense year in 2022 if this past year is any guide. Facebook, Twitter and YouTube started this year by banning the sitting president of the United States after the January 6 riots. MARY LOUISE KELLY, HOST:  They said that then-President Trump used their platforms to incite violence, which felt like a line in the sand. But criticism of social media companies only grew louder. (SOUNDBITE OF ARCHIVED RECORDING)STEVE SCALISE: This article was censored by Twitter when it was originally sent out. KELLY: Republican Congressman Steve Scalise accusing Twitter of suppressing journalism favorable to conservatives in one of many congressional hearings about Big Tech this year. A few months later. . . (SOUNDBITE OF ARCHIVED RECORDING)UNIDENTIFIED REPORTER: On COVID misinformation, what's your message to platforms like Facebook? PRESIDENT JOE BIDEN: They're killing people. SHAPIRO: President Joe Biden expressed his frustration that tech companies have not acted fast enough to curb virus and vaccine misinformation. Accusations kept coming in from both sides of the aisle, among other places. (SOUNDBITE OF ARCHIVED RECORDING)FRANCES HAUGEN: My name is Frances Haugen. I used to work at Facebook. KELLY: She handed over thousands of pages of internal documents to regulators, also to members of Congress and The Wall Street Journal, showing that Facebook knows about its potential harms to users, including how Instagram can be toxic for teenagers. SHAPIRO: After this year, it seems like just about everyone in Congress wants something to be done. But federal lawmakers still haven't actually done it. So what are the prospects for regulating social media? Our co-host Audie Cornish asked NPR's tech correspondent Shannon Bond to break it down. AUDIE CORNISH, BYLINE: So this was a year when Congress held a lot of hearings. We were hearing lawmakers talk about how it was sort of finally time to regulate tech companies. But is there actually consensus in Washington about what that means? SHANNON BOND, BYLINE: Well, there's consensus that these companies are too powerful, but I'm not sure how much consensus there is beyond that. For all of the concerns that they have raised about social media, about the power of tech, there's still a lot of, you know, really partisan divide over what to do about those concerns. So Democrats say that tech companies should be taking down more harmful content, more misinformation, more hate speech, you know, all of these issues that we see them grappling with. Republicans, on the other hand, have long argued that they are censored, that conservative views are suppressed and that, you know, tech companies are taking down too much. So not a lot of middle ground there. But what we have seen this year is a lot of bills introduced dealing with everything from privacy to requiring more transparency about how companies operate, attempting to wade into what content should be allowed online - and bills tackling competition, you know, these issues of power. That includes beefing up the ability of the two Big Tech regulators, the Federal Trade Commission and the Justice Department, to take on these companies. CORNISH: Let's get into that a little bit more 'cause I understand those agencies have actually even brought lawsuits against tech companies. What should we be looking out for in 2022? BOND: Yeah. I mean, of course, these legal battles are a long process. But you know, let's take the FTC. It's taken this big swing at Facebook with a lawsuit accusing it of buying or burying competitors. It wants the court to force Facebook to sell WhatsApp and Instagram, you know, these apps Facebook paid a lot of money for years ago. Now, the FTC these days is led by Lina Khan, who's a young, dynamic critic of corporate power. She has these really bold ideas about breaking up companies that are too powerful. It's this vision that her detractors like to call hipster antitrust. And for the FTC under Khan's leadership, this Facebook lawsuit is a major test, so we'll be watching to see, you know, whether the courts let it go ahead because Facebook is trying to get the lawsuit thrown out. So that's what's to watch there. CORNISH: And, you know, I want to ask about Europe because regulators there have been much more active when it comes to confronting powerful tech companies. Are we in the U. S. going to feel the effects of that next year? BOND: I think we certainly could. You know, these companies operate globally. And if they are forced to make big changes in Europe, you know, it can often be simpler for them to apply those changes everywhere. And frankly, with all of the sort of slow rolling that's happened in the U. S. , European regulators have moved ahead. They have passed big privacy laws. They also take a much more muscular attitude about the government's role in protecting its citizens. So right now, the EU is trying to create strict new rules that would prevent big companies from giving preference to their own products and services. So if you go on Amazon, you know, maybe you see Amazon pushing items it sells over the third-party sellers. You know, that would be banned or regulated. And so we may see something similar play out when it comes to kids online, as well. The U. K. has just passed new rules about how apps for kids can be designed, and that will affect companies like Instagram and Snapchat and TikTok. CORNISH: You know, it's interesting. Compared to other years where maybe surveillance was the big issue, child safety seemed to be the concern this year. Let's look ahead on that. BOND: That's right. I mean, this is an area of rare bipartisan unity, maybe consensus that that's something that lawmakers do want to take on. I think we may finally see efforts to update the national child data privacy law succeed. That currently protects kids under age 13. The idea would be to expand it to older teens. There are also lawmakers and child safety advocates who want the U. S. to adopt its own version of these new U. K. rules about designing apps for kids. The question is, how much will that change what companies are doing? You know, kids are an important market for Instagram, Snapchat, TikTok. It's their next generation of users. Right? They're essential to their growth. Now, under a lot of pressure, this year, Instagram paused work on a version of the app it was building for kids under age 13. But that was only a pause. And the head of Instagram, Adam Mosseri, made clear to Congress this month that the company is not backing away from building this app. You know, what he says is, you know, kids under 13 are already on Instagram, even though they're not supposed to be. And so it would be better for everybody to create a specific version just for them with parental supervision and controls. CORNISH: And of course, 2022 is an election year. How prepared are Facebook, Twitter and other companies? BOND: And I think these companies have learned a lot. But of course, these challenges keep evolving, and they're not going away. So, you know, of course, all of these platforms did ban Donald Trump after January 6. But, you know, that was really an outlier. They still are not especially clear on their policies for anything that sort of smacks of politics where you could argue that these people - these are people expressing political opinions, even when that veers into misinformation, including misinformation about COVID, about climate change. So I think we can expect that political partisans and even elected officials will keep spreading misinformation. And that is going to be a challenge for these companies to deal with, you know. And there are obviously hurdles to Congress passing laws about speech online. And so the question that we still don't have a good answer for is, what role do we think that unelected corporate executives, like Mark Zuckerberg at Facebook, should play in deciding what people can say on the internet? Zuckerberg and other leaders at these tech companies have made very clear they are uncomfortable with that role. But who ultimately do we want to make those calls? CORNISH: That's NPR's tech correspondent Shannon Bond. Thanks so much. BOND: Thanks, Audie. KELLY: And we'll note that Amazon, Apple and Google are among NPR's financial supporters. And Facebook's parent company, Meta, pays NPR to license NPR content. ARI SHAPIRO, HOST:   Social media companies are in for a tense year in 2022 if this past year is any guide. Facebook, Twitter and YouTube started this year by banning the sitting president of the United States after the January 6 riots. MARY LOUISE KELLY, HOST:   They said that then-President Trump used their platforms to incite violence, which felt like a line in the sand. But criticism of social media companies only grew louder. (SOUNDBITE OF ARCHIVED RECORDING) STEVE SCALISE: This article was censored by Twitter when it was originally sent out. KELLY: Republican Congressman Steve Scalise accusing Twitter of suppressing journalism favorable to conservatives in one of many congressional hearings about Big Tech this year. A few months later. . . (SOUNDBITE OF ARCHIVED RECORDING) UNIDENTIFIED REPORTER: On COVID misinformation, what's your message to platforms like Facebook? PRESIDENT JOE BIDEN: They're killing people. SHAPIRO: President Joe Biden expressed his frustration that tech companies have not acted fast enough to curb virus and vaccine misinformation. Accusations kept coming in from both sides of the aisle, among other places. (SOUNDBITE OF ARCHIVED RECORDING) FRANCES HAUGEN: My name is Frances Haugen. I used to work at Facebook. KELLY: She handed over thousands of pages of internal documents to regulators, also to members of Congress and The Wall Street Journal, showing that Facebook knows about its potential harms to users, including how Instagram can be toxic for teenagers. SHAPIRO: After this year, it seems like just about everyone in Congress wants something to be done. But federal lawmakers still haven't actually done it. So what are the prospects for regulating social media? Our co-host Audie Cornish asked NPR's tech correspondent Shannon Bond to break it down. AUDIE CORNISH, BYLINE: So this was a year when Congress held a lot of hearings. We were hearing lawmakers talk about how it was sort of finally time to regulate tech companies. But is there actually consensus in Washington about what that means? SHANNON BOND, BYLINE: Well, there's consensus that these companies are too powerful, but I'm not sure how much consensus there is beyond that. For all of the concerns that they have raised about social media, about the power of tech, there's still a lot of, you know, really partisan divide over what to do about those concerns. So Democrats say that tech companies should be taking down more harmful content, more misinformation, more hate speech, you know, all of these issues that we see them grappling with. Republicans, on the other hand, have long argued that they are censored, that conservative views are suppressed and that, you know, tech companies are taking down too much. So not a lot of middle ground there. But what we have seen this year is a lot of bills introduced dealing with everything from privacy to requiring more transparency about how companies operate, attempting to wade into what content should be allowed online - and bills tackling competition, you know, these issues of power. That includes beefing up the ability of the two Big Tech regulators, the Federal Trade Commission and the Justice Department, to take on these companies. CORNISH: Let's get into that a little bit more 'cause I understand those agencies have actually even brought lawsuits against tech companies. What should we be looking out for in 2022? BOND: Yeah. I mean, of course, these legal battles are a long process. But you know, let's take the FTC. It's taken this big swing at Facebook with a lawsuit accusing it of buying or burying competitors. It wants the court to force Facebook to sell WhatsApp and Instagram, you know, these apps Facebook paid a lot of money for years ago. Now, the FTC these days is led by Lina Khan, who's a young, dynamic critic of corporate power. She has these really bold ideas about breaking up companies that are too powerful. It's this vision that her detractors like to call hipster antitrust. And for the FTC under Khan's leadership, this Facebook lawsuit is a major test, so we'll be watching to see, you know, whether the courts let it go ahead because Facebook is trying to get the lawsuit thrown out. So that's what's to watch there. CORNISH: And, you know, I want to ask about Europe because regulators there have been much more active when it comes to confronting powerful tech companies. Are we in the U. S. going to feel the effects of that next year? BOND: I think we certainly could. You know, these companies operate globally. And if they are forced to make big changes in Europe, you know, it can often be simpler for them to apply those changes everywhere. And frankly, with all of the sort of slow rolling that's happened in the U. S. , European regulators have moved ahead. They have passed big privacy laws. They also take a much more muscular attitude about the government's role in protecting its citizens. So right now, the EU is trying to create strict new rules that would prevent big companies from giving preference to their own products and services. So if you go on Amazon, you know, maybe you see Amazon pushing items it sells over the third-party sellers. You know, that would be banned or regulated. And so we may see something similar play out when it comes to kids online, as well. The U. K. has just passed new rules about how apps for kids can be designed, and that will affect companies like Instagram and Snapchat and TikTok. CORNISH: You know, it's interesting. Compared to other years where maybe surveillance was the big issue, child safety seemed to be the concern this year. Let's look ahead on that. BOND: That's right. I mean, this is an area of rare bipartisan unity, maybe consensus that that's something that lawmakers do want to take on. I think we may finally see efforts to update the national child data privacy law succeed. That currently protects kids under age 13. The idea would be to expand it to older teens. There are also lawmakers and child safety advocates who want the U. S. to adopt its own version of these new U. K. rules about designing apps for kids. The question is, how much will that change what companies are doing? You know, kids are an important market for Instagram, Snapchat, TikTok. It's their next generation of users. Right? They're essential to their growth. Now, under a lot of pressure, this year, Instagram paused work on a version of the app it was building for kids under age 13. But that was only a pause. And the head of Instagram, Adam Mosseri, made clear to Congress this month that the company is not backing away from building this app. You know, what he says is, you know, kids under 13 are already on Instagram, even though they're not supposed to be. And so it would be better for everybody to create a specific version just for them with parental supervision and controls. CORNISH: And of course, 2022 is an election year. How prepared are Facebook, Twitter and other companies? BOND: And I think these companies have learned a lot. But of course, these challenges keep evolving, and they're not going away. So, you know, of course, all of these platforms did ban Donald Trump after January 6. But, you know, that was really an outlier. They still are not especially clear on their policies for anything that sort of smacks of politics where you could argue that these people - these are people expressing political opinions, even when that veers into misinformation, including misinformation about COVID, about climate change. So I think we can expect that political partisans and even elected officials will keep spreading misinformation. And that is going to be a challenge for these companies to deal with, you know. And there are obviously hurdles to Congress passing laws about speech online. And so the question that we still don't have a good answer for is, what role do we think that unelected corporate executives, like Mark Zuckerberg at Facebook, should play in deciding what people can say on the internet? Zuckerberg and other leaders at these tech companies have made very clear they are uncomfortable with that role. But who ultimately do we want to make those calls? CORNISH: That's NPR's tech correspondent Shannon Bond. Thanks so much. BOND: Thanks, Audie. KELLY: And we'll note that Amazon, Apple and Google are among NPR's financial supporters. And Facebook's parent company, Meta, pays NPR to license NPR content.", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}, "2021-12-29-1068639311": {"title": "Waiting for a Elizabeth Holmes trial verdict? Experts say fraud is complicated : NPR", "url": "https://www.npr.org/2021/12/29/1068639311/elizabeth-holmes-jury-theranos-fraud-case", "author": "No author found", "published_date": "2021-12-29", "content": "", "section": "Technology", "disclaimer": ""}, "2021-12-30-1068580723": {"title": "Want to hear the first ad for a soda, recorded a century ago? Now you can : NPR", "url": "https://www.npr.org/2021/12/30/1068580723/want-to-hear-the-first-ad-for-a-soda-recorded-a-century-ago-now-you-can", "author": "No author found", "published_date": "2021-12-30", "content": "", "section": "Technology", "disclaimer": ""}, "2021-12-30-1069027478": {"title": "The mummy of an Egyptian pharaoh has been 'digitally unwrapped'  : NPR", "url": "https://www.npr.org/2021/12/30/1069027478/the-mummy-of-an-egyptian-pharaoh-has-been-digitally-unwrapped", "author": "No author found", "published_date": "2021-12-30", "content": "SARAH MCCAMMON, HOST:  About 3,500 years ago, a pharaoh died. Amenhotep was wrapped tightly in perfect linens and mummified, and nobody knew what was under those linens - that is, until now. SAHAR SALEEM: This mummy is very special. It's the only mummy that has never been unwrapped in modern times. STEVE INSKEEP, HOST:  Dr. Sahar Saleem is a radiologist at Cairo University and part of the Egyptian Mummy Project. Dr. Saleem put the pharaoh's mummy through a CT scanner to find out just what he looked like without having to unwrap all that delicate cloth. SALEEM: There were 30 amulets in between the wrapping and also inside. And also, the king was wearing a wonderful belt made of 34 gold beads. INSKEEP: But the real surprise was his teeth. SALEEM: I looked at the teeth of the other kings and queens. Most of them - they had bad teeth. But it was amazing that the Amenhotep the king had nice teeth. Maybe he had good hygiene. MCCAMMON: Dr. Saleem says these ancient remains offer some insights for our own time. SALEEM: They are like a time capsule. We can know their health condition, their teeth hygiene, the ancient diseases that they had. These are all important for our modern understanding of the natural history of diseases, our modern understanding of civilization. INSKEEP: Which, for Dr. Saleem, is the point. SALEEM: Doing this work is a blessing. It has the joy of unwrapping a Christmas gift. INSKEEP: Although in this case, she got the gift without unwrapping it. (SOUNDBITE OF MUSIC) SARAH MCCAMMON, HOST:   About 3,500 years ago, a pharaoh died. Amenhotep was wrapped tightly in perfect linens and mummified, and nobody knew what was under those linens - that is, until now. SAHAR SALEEM: This mummy is very special. It's the only mummy that has never been unwrapped in modern times. STEVE INSKEEP, HOST:   Dr. Sahar Saleem is a radiologist at Cairo University and part of the Egyptian Mummy Project. Dr. Saleem put the pharaoh's mummy through a CT scanner to find out just what he looked like without having to unwrap all that delicate cloth. SALEEM: There were 30 amulets in between the wrapping and also inside. And also, the king was wearing a wonderful belt made of 34 gold beads. INSKEEP: But the real surprise was his teeth. SALEEM: I looked at the teeth of the other kings and queens. Most of them - they had bad teeth. But it was amazing that the Amenhotep the king had nice teeth. Maybe he had good hygiene. MCCAMMON: Dr. Saleem says these ancient remains offer some insights for our own time. SALEEM: They are like a time capsule. We can know their health condition, their teeth hygiene, the ancient diseases that they had. These are all important for our modern understanding of the natural history of diseases, our modern understanding of civilization. INSKEEP: Which, for Dr. Saleem, is the point. SALEEM: Doing this work is a blessing. It has the joy of unwrapping a Christmas gift. INSKEEP: Although in this case, she got the gift without unwrapping it. (SOUNDBITE OF MUSIC)", "section": "Technology", "disclaimer": " Copyright \u00a9 2021 NPR.  All rights reserved.  Visit our website terms of use and permissions pages at www.npr.org for further information. NPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR\u2019s programming is the audio record."}}